2023-01-05 00:52:24,726 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/f537efcb4358b601001f3077efa89dd1/2023_01_04-214450",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-05 00:52:24,745 INFO: Starting stage: BUILD FEATURIZERS
2023-01-05 00:52:24,747 INFO:   Creating esm representation model
2023-01-05 00:52:24,748 INFO:   Done esm representation model
2023-01-05 00:52:24,748 INFO: Done with stage: BUILD FEATURIZERS
2023-01-05 00:52:24,748 INFO: Starting stage: BUILDING DATASET
2023-01-05 00:52:24,803 INFO: Done with stage: BUILDING DATASET
2023-01-05 00:52:24,803 INFO: Starting stage: FEATURIZING DATA
2023-01-05 00:52:24,803 INFO:   Featurizing proteins
2023-01-05 00:52:24,805 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-05 00:52:24,846 INFO:   Loaded feature cache of size 489
2023-01-05 00:52:24,847 INFO:   Starting to pool ESM Embeddings
2023-01-05 00:52:24,966 INFO:   Featurizing molecules
2023-01-05 00:52:24,968 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-05 00:52:24,970 INFO:   Loaded feature cache of size 498
2023-01-05 00:52:26,315 INFO: Done with stage: FEATURIZING DATA
2023-01-05 00:52:26,315 INFO: Starting stage: RUNNING SPLITS
2023-01-05 00:52:26,323 INFO:   Leaving out SEQ value Fold_0
2023-01-05 00:52:26,337 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 00:52:26,337 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:52:27,000 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:52:27,000 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:52:27,068 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:52:27,068 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:52:27,069 INFO:     No hyperparam tuning for this model
2023-01-05 00:52:27,069 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:52:27,069 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:52:27,069 INFO:     None feature selector for col prot
2023-01-05 00:52:27,070 INFO:     None feature selector for col prot
2023-01-05 00:52:27,070 INFO:     None feature selector for col prot
2023-01-05 00:52:27,070 INFO:     None feature selector for col chem
2023-01-05 00:52:27,070 INFO:     None feature selector for col chem
2023-01-05 00:52:27,070 INFO:     None feature selector for col chem
2023-01-05 00:52:27,070 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:52:27,071 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:52:27,072 INFO:     Number of params in model 72931
2023-01-05 00:52:27,072 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:52:27,072 INFO:   Starting stage: TRAINING
2023-01-05 00:52:28,731 INFO:     Val loss before train {'Reaction outcome loss': 1.1182827313741048, 'Total loss': 1.1182827313741048}
2023-01-05 00:52:28,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:28,732 INFO:     Epoch: 0
2023-01-05 00:52:30,902 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9151429732640585, 'Total loss': 0.9151429732640585} | train loss {'Reaction outcome loss': 0.9468835692702632, 'Total loss': 0.9468835692702632}
2023-01-05 00:52:30,902 INFO:     Found new best model at epoch 0
2023-01-05 00:52:30,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:30,904 INFO:     Epoch: 1
2023-01-05 00:52:33,107 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6081018368403117, 'Total loss': 0.6081018368403117} | train loss {'Reaction outcome loss': 0.6895575717146143, 'Total loss': 0.6895575717146143}
2023-01-05 00:52:33,108 INFO:     Found new best model at epoch 1
2023-01-05 00:52:33,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:33,109 INFO:     Epoch: 2
2023-01-05 00:52:35,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6010756691296896, 'Total loss': 0.6010756691296896} | train loss {'Reaction outcome loss': 0.5523504513305623, 'Total loss': 0.5523504513305623}
2023-01-05 00:52:35,342 INFO:     Found new best model at epoch 2
2023-01-05 00:52:35,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:35,344 INFO:     Epoch: 3
2023-01-05 00:52:37,399 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5369868516921997, 'Total loss': 0.5369868516921997} | train loss {'Reaction outcome loss': 0.5150229166169743, 'Total loss': 0.5150229166169743}
2023-01-05 00:52:37,399 INFO:     Found new best model at epoch 3
2023-01-05 00:52:37,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:37,400 INFO:     Epoch: 4
2023-01-05 00:52:39,217 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5151346981525421, 'Total loss': 0.5151346981525421} | train loss {'Reaction outcome loss': 0.48272062641578717, 'Total loss': 0.48272062641578717}
2023-01-05 00:52:39,217 INFO:     Found new best model at epoch 4
2023-01-05 00:52:39,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:39,218 INFO:     Epoch: 5
2023-01-05 00:52:41,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5260044932365417, 'Total loss': 0.5260044932365417} | train loss {'Reaction outcome loss': 0.46763006982567545, 'Total loss': 0.46763006982567545}
2023-01-05 00:52:41,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:41,074 INFO:     Epoch: 6
2023-01-05 00:52:43,281 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5251301765441895, 'Total loss': 0.5251301765441895} | train loss {'Reaction outcome loss': 0.44993642338247963, 'Total loss': 0.44993642338247963}
2023-01-05 00:52:43,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:43,281 INFO:     Epoch: 7
2023-01-05 00:52:45,447 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49432177245616915, 'Total loss': 0.49432177245616915} | train loss {'Reaction outcome loss': 0.42717590829828284, 'Total loss': 0.42717590829828284}
2023-01-05 00:52:45,447 INFO:     Found new best model at epoch 7
2023-01-05 00:52:45,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:45,449 INFO:     Epoch: 8
2023-01-05 00:52:47,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5502270539601644, 'Total loss': 0.5502270539601644} | train loss {'Reaction outcome loss': 0.4156588285670176, 'Total loss': 0.4156588285670176}
2023-01-05 00:52:47,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:47,673 INFO:     Epoch: 9
2023-01-05 00:52:49,878 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5265174488226573, 'Total loss': 0.5265174488226573} | train loss {'Reaction outcome loss': 0.4065401540598372, 'Total loss': 0.4065401540598372}
2023-01-05 00:52:49,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:49,878 INFO:     Epoch: 10
2023-01-05 00:52:52,110 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5327346841494243, 'Total loss': 0.5327346841494243} | train loss {'Reaction outcome loss': 0.3946319617085404, 'Total loss': 0.3946319617085404}
2023-01-05 00:52:52,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:52,111 INFO:     Epoch: 11
2023-01-05 00:52:54,316 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49805577397346495, 'Total loss': 0.49805577397346495} | train loss {'Reaction outcome loss': 0.37929709763317315, 'Total loss': 0.37929709763317315}
2023-01-05 00:52:54,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:54,316 INFO:     Epoch: 12
2023-01-05 00:52:56,575 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5175085157155991, 'Total loss': 0.5175085157155991} | train loss {'Reaction outcome loss': 0.3671379052648396, 'Total loss': 0.3671379052648396}
2023-01-05 00:52:56,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:56,575 INFO:     Epoch: 13
2023-01-05 00:52:58,821 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.50496653119723, 'Total loss': 0.50496653119723} | train loss {'Reaction outcome loss': 0.3518769544832436, 'Total loss': 0.3518769544832436}
2023-01-05 00:52:58,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:58,821 INFO:     Epoch: 14
2023-01-05 00:53:01,069 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5035483141740164, 'Total loss': 0.5035483141740164} | train loss {'Reaction outcome loss': 0.34917375961175334, 'Total loss': 0.34917375961175334}
2023-01-05 00:53:01,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:01,070 INFO:     Epoch: 15
2023-01-05 00:53:03,322 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5234065175056457, 'Total loss': 0.5234065175056457} | train loss {'Reaction outcome loss': 0.33645046352248487, 'Total loss': 0.33645046352248487}
2023-01-05 00:53:03,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:03,322 INFO:     Epoch: 16
2023-01-05 00:53:05,548 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4792101114988327, 'Total loss': 0.4792101114988327} | train loss {'Reaction outcome loss': 0.32724380995327734, 'Total loss': 0.32724380995327734}
2023-01-05 00:53:05,549 INFO:     Found new best model at epoch 16
2023-01-05 00:53:05,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:05,550 INFO:     Epoch: 17
2023-01-05 00:53:07,790 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5288936297098795, 'Total loss': 0.5288936297098795} | train loss {'Reaction outcome loss': 0.32095376617742544, 'Total loss': 0.32095376617742544}
2023-01-05 00:53:07,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:07,791 INFO:     Epoch: 18
2023-01-05 00:53:10,012 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5030301084121068, 'Total loss': 0.5030301084121068} | train loss {'Reaction outcome loss': 0.31616968385902516, 'Total loss': 0.31616968385902516}
2023-01-05 00:53:10,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:10,012 INFO:     Epoch: 19
2023-01-05 00:53:12,254 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4787782594561577, 'Total loss': 0.4787782594561577} | train loss {'Reaction outcome loss': 0.3052975428682981, 'Total loss': 0.3052975428682981}
2023-01-05 00:53:12,254 INFO:     Found new best model at epoch 19
2023-01-05 00:53:12,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:12,255 INFO:     Epoch: 20
2023-01-05 00:53:14,488 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5148832142353058, 'Total loss': 0.5148832142353058} | train loss {'Reaction outcome loss': 0.2951379453715606, 'Total loss': 0.2951379453715606}
2023-01-05 00:53:14,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:14,488 INFO:     Epoch: 21
2023-01-05 00:53:16,702 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5309495677550634, 'Total loss': 0.5309495677550634} | train loss {'Reaction outcome loss': 0.2903590284274284, 'Total loss': 0.2903590284274284}
2023-01-05 00:53:16,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:16,702 INFO:     Epoch: 22
2023-01-05 00:53:18,956 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5101165980100631, 'Total loss': 0.5101165980100631} | train loss {'Reaction outcome loss': 0.2891592984480081, 'Total loss': 0.2891592984480081}
2023-01-05 00:53:18,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:18,956 INFO:     Epoch: 23
2023-01-05 00:53:21,206 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5386195659637452, 'Total loss': 0.5386195659637452} | train loss {'Reaction outcome loss': 0.28074666454828595, 'Total loss': 0.28074666454828595}
2023-01-05 00:53:21,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:21,207 INFO:     Epoch: 24
2023-01-05 00:53:23,425 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5754442135492961, 'Total loss': 0.5754442135492961} | train loss {'Reaction outcome loss': 0.2728526940153086, 'Total loss': 0.2728526940153086}
2023-01-05 00:53:23,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:23,426 INFO:     Epoch: 25
2023-01-05 00:53:25,643 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5547769467035929, 'Total loss': 0.5547769467035929} | train loss {'Reaction outcome loss': 0.27567525905294293, 'Total loss': 0.27567525905294293}
2023-01-05 00:53:25,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:25,643 INFO:     Epoch: 26
2023-01-05 00:53:27,738 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4945052499572436, 'Total loss': 0.4945052499572436} | train loss {'Reaction outcome loss': 0.2678603991429448, 'Total loss': 0.2678603991429448}
2023-01-05 00:53:27,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:27,738 INFO:     Epoch: 27
2023-01-05 00:53:29,908 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5364092389742533, 'Total loss': 0.5364092389742533} | train loss {'Reaction outcome loss': 0.257713731262328, 'Total loss': 0.257713731262328}
2023-01-05 00:53:29,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:29,908 INFO:     Epoch: 28
2023-01-05 00:53:32,125 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5272183020909628, 'Total loss': 0.5272183020909628} | train loss {'Reaction outcome loss': 0.2580456329789354, 'Total loss': 0.2580456329789354}
2023-01-05 00:53:32,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:32,126 INFO:     Epoch: 29
2023-01-05 00:53:34,246 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5508348912000656, 'Total loss': 0.5508348912000656} | train loss {'Reaction outcome loss': 0.2518791686743498, 'Total loss': 0.2518791686743498}
2023-01-05 00:53:34,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:34,246 INFO:     Epoch: 30
2023-01-05 00:53:36,431 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5730519890785217, 'Total loss': 0.5730519890785217} | train loss {'Reaction outcome loss': 0.2447254345667013, 'Total loss': 0.2447254345667013}
2023-01-05 00:53:36,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:36,431 INFO:     Epoch: 31
2023-01-05 00:53:38,597 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5162769101560116, 'Total loss': 0.5162769101560116} | train loss {'Reaction outcome loss': 0.24902589886957582, 'Total loss': 0.24902589886957582}
2023-01-05 00:53:38,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:38,599 INFO:     Epoch: 32
2023-01-05 00:53:40,800 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49942577083905537, 'Total loss': 0.49942577083905537} | train loss {'Reaction outcome loss': 0.2422294656135442, 'Total loss': 0.2422294656135442}
2023-01-05 00:53:40,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:40,800 INFO:     Epoch: 33
2023-01-05 00:53:42,975 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5103782773017883, 'Total loss': 0.5103782773017883} | train loss {'Reaction outcome loss': 0.2379940386124692, 'Total loss': 0.2379940386124692}
2023-01-05 00:53:42,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:42,975 INFO:     Epoch: 34
2023-01-05 00:53:45,158 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.534713359673818, 'Total loss': 0.534713359673818} | train loss {'Reaction outcome loss': 0.2327489450969648, 'Total loss': 0.2327489450969648}
2023-01-05 00:53:45,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:45,159 INFO:     Epoch: 35
2023-01-05 00:53:47,380 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5214454273382823, 'Total loss': 0.5214454273382823} | train loss {'Reaction outcome loss': 0.2388218159927226, 'Total loss': 0.2388218159927226}
2023-01-05 00:53:47,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:47,380 INFO:     Epoch: 36
2023-01-05 00:53:49,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5575150310993194, 'Total loss': 0.5575150310993194} | train loss {'Reaction outcome loss': 0.22692915947336853, 'Total loss': 0.22692915947336853}
2023-01-05 00:53:49,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:49,597 INFO:     Epoch: 37
2023-01-05 00:53:51,804 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5153995913763841, 'Total loss': 0.5153995913763841} | train loss {'Reaction outcome loss': 0.22460341564082836, 'Total loss': 0.22460341564082836}
2023-01-05 00:53:51,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:51,804 INFO:     Epoch: 38
2023-01-05 00:53:53,942 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5294424454371135, 'Total loss': 0.5294424454371135} | train loss {'Reaction outcome loss': 0.22253386810381007, 'Total loss': 0.22253386810381007}
2023-01-05 00:53:53,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:53,942 INFO:     Epoch: 39
2023-01-05 00:53:56,128 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5207193632920583, 'Total loss': 0.5207193632920583} | train loss {'Reaction outcome loss': 0.22006410732865334, 'Total loss': 0.22006410732865334}
2023-01-05 00:53:56,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:56,128 INFO:     Epoch: 40
2023-01-05 00:53:58,173 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5003239291409651, 'Total loss': 0.5003239291409651} | train loss {'Reaction outcome loss': 0.21703326126949474, 'Total loss': 0.21703326126949474}
2023-01-05 00:53:58,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:53:58,174 INFO:     Epoch: 41
2023-01-05 00:54:00,407 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5424649725357692, 'Total loss': 0.5424649725357692} | train loss {'Reaction outcome loss': 0.2201055451859157, 'Total loss': 0.2201055451859157}
2023-01-05 00:54:00,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:00,407 INFO:     Epoch: 42
2023-01-05 00:54:02,629 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5760790010293325, 'Total loss': 0.5760790010293325} | train loss {'Reaction outcome loss': 0.22325752593999926, 'Total loss': 0.22325752593999926}
2023-01-05 00:54:02,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:02,629 INFO:     Epoch: 43
2023-01-05 00:54:04,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5244248410065969, 'Total loss': 0.5244248410065969} | train loss {'Reaction outcome loss': 0.21221304156275078, 'Total loss': 0.21221304156275078}
2023-01-05 00:54:04,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:04,842 INFO:     Epoch: 44
2023-01-05 00:54:07,080 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5091721266508102, 'Total loss': 0.5091721266508102} | train loss {'Reaction outcome loss': 0.21697417991884024, 'Total loss': 0.21697417991884024}
2023-01-05 00:54:07,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:07,080 INFO:     Epoch: 45
2023-01-05 00:54:09,252 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.54749489625295, 'Total loss': 0.54749489625295} | train loss {'Reaction outcome loss': 0.20897551290963814, 'Total loss': 0.20897551290963814}
2023-01-05 00:54:09,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:09,254 INFO:     Epoch: 46
2023-01-05 00:54:11,485 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5226198767622312, 'Total loss': 0.5226198767622312} | train loss {'Reaction outcome loss': 0.20689337679454478, 'Total loss': 0.20689337679454478}
2023-01-05 00:54:11,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:11,485 INFO:     Epoch: 47
2023-01-05 00:54:13,690 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5145364284515381, 'Total loss': 0.5145364284515381} | train loss {'Reaction outcome loss': 0.20644169952208688, 'Total loss': 0.20644169952208688}
2023-01-05 00:54:13,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:13,690 INFO:     Epoch: 48
2023-01-05 00:54:15,891 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5657690366109213, 'Total loss': 0.5657690366109213} | train loss {'Reaction outcome loss': 0.20363230534894017, 'Total loss': 0.20363230534894017}
2023-01-05 00:54:15,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:15,892 INFO:     Epoch: 49
2023-01-05 00:54:18,136 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5252526640892029, 'Total loss': 0.5252526640892029} | train loss {'Reaction outcome loss': 0.20323430099643958, 'Total loss': 0.20323430099643958}
2023-01-05 00:54:18,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:18,136 INFO:     Epoch: 50
2023-01-05 00:54:20,382 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5306717435518901, 'Total loss': 0.5306717435518901} | train loss {'Reaction outcome loss': 0.2001849352330952, 'Total loss': 0.2001849352330952}
2023-01-05 00:54:20,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:20,382 INFO:     Epoch: 51
2023-01-05 00:54:22,587 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5363186130921046, 'Total loss': 0.5363186130921046} | train loss {'Reaction outcome loss': 0.20052226711467128, 'Total loss': 0.20052226711467128}
2023-01-05 00:54:22,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:22,587 INFO:     Epoch: 52
2023-01-05 00:54:24,834 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46979340227941674, 'Total loss': 0.46979340227941674} | train loss {'Reaction outcome loss': 0.20202479866630102, 'Total loss': 0.20202479866630102}
2023-01-05 00:54:24,834 INFO:     Found new best model at epoch 52
2023-01-05 00:54:24,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:24,835 INFO:     Epoch: 53
2023-01-05 00:54:27,030 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5021214508761962, 'Total loss': 0.5021214508761962} | train loss {'Reaction outcome loss': 0.1972316568410331, 'Total loss': 0.1972316568410331}
2023-01-05 00:54:27,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:27,031 INFO:     Epoch: 54
2023-01-05 00:54:29,202 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5288284689188003, 'Total loss': 0.5288284689188003} | train loss {'Reaction outcome loss': 0.19591221190484126, 'Total loss': 0.19591221190484126}
2023-01-05 00:54:29,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:29,203 INFO:     Epoch: 55
2023-01-05 00:54:31,441 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5086570133765539, 'Total loss': 0.5086570133765539} | train loss {'Reaction outcome loss': 0.20273020709677167, 'Total loss': 0.20273020709677167}
2023-01-05 00:54:31,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:31,441 INFO:     Epoch: 56
2023-01-05 00:54:33,680 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5319932706654071, 'Total loss': 0.5319932706654071} | train loss {'Reaction outcome loss': 0.19493810499202965, 'Total loss': 0.19493810499202965}
2023-01-05 00:54:33,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:33,680 INFO:     Epoch: 57
2023-01-05 00:54:35,915 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5182670628031095, 'Total loss': 0.5182670628031095} | train loss {'Reaction outcome loss': 0.1949403963423583, 'Total loss': 0.1949403963423583}
2023-01-05 00:54:35,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:35,916 INFO:     Epoch: 58
2023-01-05 00:54:38,067 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5316135446230571, 'Total loss': 0.5316135446230571} | train loss {'Reaction outcome loss': 0.18942631966001167, 'Total loss': 0.18942631966001167}
2023-01-05 00:54:38,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:38,068 INFO:     Epoch: 59
2023-01-05 00:54:40,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5295191526412963, 'Total loss': 0.5295191526412963} | train loss {'Reaction outcome loss': 0.19048791458564146, 'Total loss': 0.19048791458564146}
2023-01-05 00:54:40,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:40,278 INFO:     Epoch: 60
2023-01-05 00:54:42,506 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.517200963695844, 'Total loss': 0.517200963695844} | train loss {'Reaction outcome loss': 0.18707786497213083, 'Total loss': 0.18707786497213083}
2023-01-05 00:54:42,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:42,506 INFO:     Epoch: 61
2023-01-05 00:54:44,726 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5049804826577504, 'Total loss': 0.5049804826577504} | train loss {'Reaction outcome loss': 0.18376361961295698, 'Total loss': 0.18376361961295698}
2023-01-05 00:54:44,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:44,727 INFO:     Epoch: 62
2023-01-05 00:54:46,958 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5102337544163068, 'Total loss': 0.5102337544163068} | train loss {'Reaction outcome loss': 0.19337915974727152, 'Total loss': 0.19337915974727152}
2023-01-05 00:54:46,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:46,959 INFO:     Epoch: 63
2023-01-05 00:54:49,155 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4946409886082013, 'Total loss': 0.4946409886082013} | train loss {'Reaction outcome loss': 0.18502575621322725, 'Total loss': 0.18502575621322725}
2023-01-05 00:54:49,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:49,155 INFO:     Epoch: 64
2023-01-05 00:54:51,368 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5163561364014944, 'Total loss': 0.5163561364014944} | train loss {'Reaction outcome loss': 0.1939637590636373, 'Total loss': 0.1939637590636373}
2023-01-05 00:54:51,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:51,368 INFO:     Epoch: 65
2023-01-05 00:54:53,562 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5622934708992641, 'Total loss': 0.5622934708992641} | train loss {'Reaction outcome loss': 0.1941794676590206, 'Total loss': 0.1941794676590206}
2023-01-05 00:54:53,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:53,563 INFO:     Epoch: 66
2023-01-05 00:54:55,775 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5073481465379397, 'Total loss': 0.5073481465379397} | train loss {'Reaction outcome loss': 0.18239422267193706, 'Total loss': 0.18239422267193706}
2023-01-05 00:54:55,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:55,775 INFO:     Epoch: 67
2023-01-05 00:54:57,979 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5348327000935872, 'Total loss': 0.5348327000935872} | train loss {'Reaction outcome loss': 0.1795326679460568, 'Total loss': 0.1795326679460568}
2023-01-05 00:54:57,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:54:57,979 INFO:     Epoch: 68
2023-01-05 00:55:00,152 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5048128177722295, 'Total loss': 0.5048128177722295} | train loss {'Reaction outcome loss': 0.17734612298160518, 'Total loss': 0.17734612298160518}
2023-01-05 00:55:00,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:00,153 INFO:     Epoch: 69
2023-01-05 00:55:02,333 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5162638346354167, 'Total loss': 0.5162638346354167} | train loss {'Reaction outcome loss': 0.18017252497613812, 'Total loss': 0.18017252497613812}
2023-01-05 00:55:02,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:02,333 INFO:     Epoch: 70
2023-01-05 00:55:04,545 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5171835243701934, 'Total loss': 0.5171835243701934} | train loss {'Reaction outcome loss': 0.1796234710715138, 'Total loss': 0.1796234710715138}
2023-01-05 00:55:04,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:04,545 INFO:     Epoch: 71
2023-01-05 00:55:06,750 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5212595701217652, 'Total loss': 0.5212595701217652} | train loss {'Reaction outcome loss': 0.18054600137937474, 'Total loss': 0.18054600137937474}
2023-01-05 00:55:06,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:06,750 INFO:     Epoch: 72
2023-01-05 00:55:08,960 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5259253074725468, 'Total loss': 0.5259253074725468} | train loss {'Reaction outcome loss': 0.17782270611560608, 'Total loss': 0.17782270611560608}
2023-01-05 00:55:08,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:08,960 INFO:     Epoch: 73
2023-01-05 00:55:11,163 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4911894659201304, 'Total loss': 0.4911894659201304} | train loss {'Reaction outcome loss': 0.17722533948057684, 'Total loss': 0.17722533948057684}
2023-01-05 00:55:11,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:11,165 INFO:     Epoch: 74
2023-01-05 00:55:13,260 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.53700110912323, 'Total loss': 0.53700110912323} | train loss {'Reaction outcome loss': 0.1726670944858547, 'Total loss': 0.1726670944858547}
2023-01-05 00:55:13,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:13,260 INFO:     Epoch: 75
2023-01-05 00:55:15,458 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5117252846558888, 'Total loss': 0.5117252846558888} | train loss {'Reaction outcome loss': 0.17480333900972927, 'Total loss': 0.17480333900972927}
2023-01-05 00:55:15,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:15,458 INFO:     Epoch: 76
2023-01-05 00:55:17,660 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5370979840091119, 'Total loss': 0.5370979840091119} | train loss {'Reaction outcome loss': 0.17902698656100602, 'Total loss': 0.17902698656100602}
2023-01-05 00:55:17,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:17,661 INFO:     Epoch: 77
2023-01-05 00:55:19,852 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5598760147889456, 'Total loss': 0.5598760147889456} | train loss {'Reaction outcome loss': 0.17670381519493167, 'Total loss': 0.17670381519493167}
2023-01-05 00:55:19,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:19,852 INFO:     Epoch: 78
2023-01-05 00:55:22,004 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49499725277225176, 'Total loss': 0.49499725277225176} | train loss {'Reaction outcome loss': 0.1746737398411874, 'Total loss': 0.1746737398411874}
2023-01-05 00:55:22,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:22,004 INFO:     Epoch: 79
2023-01-05 00:55:24,146 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4920804023742676, 'Total loss': 0.4920804023742676} | train loss {'Reaction outcome loss': 0.17126517529657362, 'Total loss': 0.17126517529657362}
2023-01-05 00:55:24,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:24,146 INFO:     Epoch: 80
2023-01-05 00:55:26,328 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5326128154993057, 'Total loss': 0.5326128154993057} | train loss {'Reaction outcome loss': 0.16699384003127124, 'Total loss': 0.16699384003127124}
2023-01-05 00:55:26,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:26,329 INFO:     Epoch: 81
2023-01-05 00:55:28,515 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5109582235415776, 'Total loss': 0.5109582235415776} | train loss {'Reaction outcome loss': 0.16808884295774795, 'Total loss': 0.16808884295774795}
2023-01-05 00:55:28,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:28,515 INFO:     Epoch: 82
2023-01-05 00:55:30,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5504959841569265, 'Total loss': 0.5504959841569265} | train loss {'Reaction outcome loss': 0.17161330950511244, 'Total loss': 0.17161330950511244}
2023-01-05 00:55:30,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:30,717 INFO:     Epoch: 83
2023-01-05 00:55:32,877 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5127799756204089, 'Total loss': 0.5127799756204089} | train loss {'Reaction outcome loss': 0.16728480019685113, 'Total loss': 0.16728480019685113}
2023-01-05 00:55:32,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:32,877 INFO:     Epoch: 84
2023-01-05 00:55:35,061 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.549685463309288, 'Total loss': 0.549685463309288} | train loss {'Reaction outcome loss': 0.17103810364128033, 'Total loss': 0.17103810364128033}
2023-01-05 00:55:35,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:35,062 INFO:     Epoch: 85
2023-01-05 00:55:37,257 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5110212047894795, 'Total loss': 0.5110212047894795} | train loss {'Reaction outcome loss': 0.16854861380034314, 'Total loss': 0.16854861380034314}
2023-01-05 00:55:37,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:37,257 INFO:     Epoch: 86
2023-01-05 00:55:39,481 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5237628281116485, 'Total loss': 0.5237628281116485} | train loss {'Reaction outcome loss': 0.16886922239493102, 'Total loss': 0.16886922239493102}
2023-01-05 00:55:39,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:39,482 INFO:     Epoch: 87
2023-01-05 00:55:41,688 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5184439798196157, 'Total loss': 0.5184439798196157} | train loss {'Reaction outcome loss': 0.16454231583141474, 'Total loss': 0.16454231583141474}
2023-01-05 00:55:41,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:41,688 INFO:     Epoch: 88
2023-01-05 00:55:43,861 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5455794513225556, 'Total loss': 0.5455794513225556} | train loss {'Reaction outcome loss': 0.16577345795840734, 'Total loss': 0.16577345795840734}
2023-01-05 00:55:43,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:43,861 INFO:     Epoch: 89
2023-01-05 00:55:45,976 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5395186245441437, 'Total loss': 0.5395186245441437} | train loss {'Reaction outcome loss': 0.1655169633616294, 'Total loss': 0.1655169633616294}
2023-01-05 00:55:45,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:45,977 INFO:     Epoch: 90
2023-01-05 00:55:48,158 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5217418412367503, 'Total loss': 0.5217418412367503} | train loss {'Reaction outcome loss': 0.16908600752757036, 'Total loss': 0.16908600752757036}
2023-01-05 00:55:48,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:48,159 INFO:     Epoch: 91
2023-01-05 00:55:50,345 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5555124978224436, 'Total loss': 0.5555124978224436} | train loss {'Reaction outcome loss': 0.1617570753608431, 'Total loss': 0.1617570753608431}
2023-01-05 00:55:50,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:50,346 INFO:     Epoch: 92
2023-01-05 00:55:52,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5602636973063151, 'Total loss': 0.5602636973063151} | train loss {'Reaction outcome loss': 0.16802260121194162, 'Total loss': 0.16802260121194162}
2023-01-05 00:55:52,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:52,553 INFO:     Epoch: 93
2023-01-05 00:55:54,783 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5408828496932984, 'Total loss': 0.5408828496932984} | train loss {'Reaction outcome loss': 0.16982159298083885, 'Total loss': 0.16982159298083885}
2023-01-05 00:55:54,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:54,783 INFO:     Epoch: 94
2023-01-05 00:55:56,951 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.547730541229248, 'Total loss': 0.547730541229248} | train loss {'Reaction outcome loss': 0.16342048493944, 'Total loss': 0.16342048493944}
2023-01-05 00:55:56,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:56,952 INFO:     Epoch: 95
2023-01-05 00:55:59,140 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5113079845905304, 'Total loss': 0.5113079845905304} | train loss {'Reaction outcome loss': 0.16328389295155094, 'Total loss': 0.16328389295155094}
2023-01-05 00:55:59,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:55:59,140 INFO:     Epoch: 96
2023-01-05 00:56:01,300 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5336218525966009, 'Total loss': 0.5336218525966009} | train loss {'Reaction outcome loss': 0.15790154058707967, 'Total loss': 0.15790154058707967}
2023-01-05 00:56:01,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:01,300 INFO:     Epoch: 97
2023-01-05 00:56:03,524 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5226897458235423, 'Total loss': 0.5226897458235423} | train loss {'Reaction outcome loss': 0.16578863974960842, 'Total loss': 0.16578863974960842}
2023-01-05 00:56:03,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:03,525 INFO:     Epoch: 98
2023-01-05 00:56:05,756 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.547542009751002, 'Total loss': 0.547542009751002} | train loss {'Reaction outcome loss': 0.16110339281473296, 'Total loss': 0.16110339281473296}
2023-01-05 00:56:05,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:05,757 INFO:     Epoch: 99
2023-01-05 00:56:07,963 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5379090597232182, 'Total loss': 0.5379090597232182} | train loss {'Reaction outcome loss': 0.1675455159227954, 'Total loss': 0.1675455159227954}
2023-01-05 00:56:07,964 INFO:     Best model found after epoch 53 of 100.
2023-01-05 00:56:07,964 INFO:   Done with stage: TRAINING
2023-01-05 00:56:07,964 INFO:   Starting stage: EVALUATION
2023-01-05 00:56:08,109 INFO:   Done with stage: EVALUATION
2023-01-05 00:56:08,109 INFO:   Leaving out SEQ value Fold_1
2023-01-05 00:56:08,122 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:56:08,122 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:56:08,780 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:56:08,781 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:56:08,850 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:56:08,851 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:56:08,851 INFO:     No hyperparam tuning for this model
2023-01-05 00:56:08,851 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:56:08,851 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:56:08,851 INFO:     None feature selector for col prot
2023-01-05 00:56:08,852 INFO:     None feature selector for col prot
2023-01-05 00:56:08,852 INFO:     None feature selector for col prot
2023-01-05 00:56:08,852 INFO:     None feature selector for col chem
2023-01-05 00:56:08,852 INFO:     None feature selector for col chem
2023-01-05 00:56:08,852 INFO:     None feature selector for col chem
2023-01-05 00:56:08,852 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:56:08,852 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:56:08,854 INFO:     Number of params in model 72931
2023-01-05 00:56:08,857 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:56:08,857 INFO:   Starting stage: TRAINING
2023-01-05 00:56:08,918 INFO:     Val loss before train {'Reaction outcome loss': 1.089173714319865, 'Total loss': 1.089173714319865}
2023-01-05 00:56:08,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:08,918 INFO:     Epoch: 0
2023-01-05 00:56:11,106 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7398837745189667, 'Total loss': 0.7398837745189667} | train loss {'Reaction outcome loss': 0.9135018890534622, 'Total loss': 0.9135018890534622}
2023-01-05 00:56:11,106 INFO:     Found new best model at epoch 0
2023-01-05 00:56:11,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:11,108 INFO:     Epoch: 1
2023-01-05 00:56:13,265 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5978557884693145, 'Total loss': 0.5978557884693145} | train loss {'Reaction outcome loss': 0.6082361740856499, 'Total loss': 0.6082361740856499}
2023-01-05 00:56:13,266 INFO:     Found new best model at epoch 1
2023-01-05 00:56:13,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:13,267 INFO:     Epoch: 2
2023-01-05 00:56:15,506 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5575490931669871, 'Total loss': 0.5575490931669871} | train loss {'Reaction outcome loss': 0.5384908503610464, 'Total loss': 0.5384908503610464}
2023-01-05 00:56:15,506 INFO:     Found new best model at epoch 2
2023-01-05 00:56:15,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:15,507 INFO:     Epoch: 3
2023-01-05 00:56:17,773 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5720179736614227, 'Total loss': 0.5720179736614227} | train loss {'Reaction outcome loss': 0.4955146349283219, 'Total loss': 0.4955146349283219}
2023-01-05 00:56:17,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:17,773 INFO:     Epoch: 4
2023-01-05 00:56:19,897 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5174339115619659, 'Total loss': 0.5174339115619659} | train loss {'Reaction outcome loss': 0.46322673984526563, 'Total loss': 0.46322673984526563}
2023-01-05 00:56:19,897 INFO:     Found new best model at epoch 4
2023-01-05 00:56:19,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:19,898 INFO:     Epoch: 5
2023-01-05 00:56:22,121 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.496176278591156, 'Total loss': 0.496176278591156} | train loss {'Reaction outcome loss': 0.4401369396604739, 'Total loss': 0.4401369396604739}
2023-01-05 00:56:22,123 INFO:     Found new best model at epoch 5
2023-01-05 00:56:22,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:22,124 INFO:     Epoch: 6
2023-01-05 00:56:24,371 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4907044470310211, 'Total loss': 0.4907044470310211} | train loss {'Reaction outcome loss': 0.4200787601899304, 'Total loss': 0.4200787601899304}
2023-01-05 00:56:24,371 INFO:     Found new best model at epoch 6
2023-01-05 00:56:24,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:24,372 INFO:     Epoch: 7
2023-01-05 00:56:26,631 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48328924377759297, 'Total loss': 0.48328924377759297} | train loss {'Reaction outcome loss': 0.4064186515549765, 'Total loss': 0.4064186515549765}
2023-01-05 00:56:26,631 INFO:     Found new best model at epoch 7
2023-01-05 00:56:26,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:26,632 INFO:     Epoch: 8
2023-01-05 00:56:28,854 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49931853612264, 'Total loss': 0.49931853612264} | train loss {'Reaction outcome loss': 0.3910381815203964, 'Total loss': 0.3910381815203964}
2023-01-05 00:56:28,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:28,855 INFO:     Epoch: 9
2023-01-05 00:56:31,097 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5028030773003896, 'Total loss': 0.5028030773003896} | train loss {'Reaction outcome loss': 0.37965398756922153, 'Total loss': 0.37965398756922153}
2023-01-05 00:56:31,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:31,097 INFO:     Epoch: 10
2023-01-05 00:56:33,295 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4782548904418945, 'Total loss': 0.4782548904418945} | train loss {'Reaction outcome loss': 0.38037932742441044, 'Total loss': 0.38037932742441044}
2023-01-05 00:56:33,295 INFO:     Found new best model at epoch 10
2023-01-05 00:56:33,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:33,296 INFO:     Epoch: 11
2023-01-05 00:56:35,502 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5010267476240794, 'Total loss': 0.5010267476240794} | train loss {'Reaction outcome loss': 0.36171910901548865, 'Total loss': 0.36171910901548865}
2023-01-05 00:56:35,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:35,502 INFO:     Epoch: 12
2023-01-05 00:56:37,730 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5091373642285665, 'Total loss': 0.5091373642285665} | train loss {'Reaction outcome loss': 0.3516702573928658, 'Total loss': 0.3516702573928658}
2023-01-05 00:56:37,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:37,730 INFO:     Epoch: 13
2023-01-05 00:56:39,992 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.490316367149353, 'Total loss': 0.490316367149353} | train loss {'Reaction outcome loss': 0.34046112161461456, 'Total loss': 0.34046112161461456}
2023-01-05 00:56:39,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:39,993 INFO:     Epoch: 14
2023-01-05 00:56:42,265 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5079136749108633, 'Total loss': 0.5079136749108633} | train loss {'Reaction outcome loss': 0.3327237061324876, 'Total loss': 0.3327237061324876}
2023-01-05 00:56:42,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:42,266 INFO:     Epoch: 15
2023-01-05 00:56:44,533 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4997694373130798, 'Total loss': 0.4997694373130798} | train loss {'Reaction outcome loss': 0.32791910303827876, 'Total loss': 0.32791910303827876}
2023-01-05 00:56:44,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:44,534 INFO:     Epoch: 16
2023-01-05 00:56:46,721 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5070739815632502, 'Total loss': 0.5070739815632502} | train loss {'Reaction outcome loss': 0.3173220334979503, 'Total loss': 0.3173220334979503}
2023-01-05 00:56:46,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:46,722 INFO:     Epoch: 17
2023-01-05 00:56:48,944 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47103007435798644, 'Total loss': 0.47103007435798644} | train loss {'Reaction outcome loss': 0.31936322934115713, 'Total loss': 0.31936322934115713}
2023-01-05 00:56:48,944 INFO:     Found new best model at epoch 17
2023-01-05 00:56:48,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:48,945 INFO:     Epoch: 18
2023-01-05 00:56:51,179 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4752332846323649, 'Total loss': 0.4752332846323649} | train loss {'Reaction outcome loss': 0.305379546476879, 'Total loss': 0.305379546476879}
2023-01-05 00:56:51,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:51,179 INFO:     Epoch: 19
2023-01-05 00:56:53,401 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45551695823669436, 'Total loss': 0.45551695823669436} | train loss {'Reaction outcome loss': 0.30400437632526545, 'Total loss': 0.30400437632526545}
2023-01-05 00:56:53,402 INFO:     Found new best model at epoch 19
2023-01-05 00:56:53,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:53,404 INFO:     Epoch: 20
2023-01-05 00:56:55,646 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4642048756281535, 'Total loss': 0.4642048756281535} | train loss {'Reaction outcome loss': 0.2913113515081721, 'Total loss': 0.2913113515081721}
2023-01-05 00:56:55,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:55,647 INFO:     Epoch: 21
2023-01-05 00:56:57,896 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44628536502520244, 'Total loss': 0.44628536502520244} | train loss {'Reaction outcome loss': 0.2819765840009179, 'Total loss': 0.2819765840009179}
2023-01-05 00:56:57,896 INFO:     Found new best model at epoch 21
2023-01-05 00:56:57,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:56:57,897 INFO:     Epoch: 22
2023-01-05 00:57:00,149 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46325051387151084, 'Total loss': 0.46325051387151084} | train loss {'Reaction outcome loss': 0.27950374653353693, 'Total loss': 0.27950374653353693}
2023-01-05 00:57:00,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:00,150 INFO:     Epoch: 23
2023-01-05 00:57:02,408 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4732510363062223, 'Total loss': 0.4732510363062223} | train loss {'Reaction outcome loss': 0.269409595670025, 'Total loss': 0.269409595670025}
2023-01-05 00:57:02,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:02,408 INFO:     Epoch: 24
2023-01-05 00:57:04,622 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4991799215475718, 'Total loss': 0.4991799215475718} | train loss {'Reaction outcome loss': 0.26685887981422135, 'Total loss': 0.26685887981422135}
2023-01-05 00:57:04,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:04,622 INFO:     Epoch: 25
2023-01-05 00:57:06,878 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4717431863149007, 'Total loss': 0.4717431863149007} | train loss {'Reaction outcome loss': 0.26619951553183835, 'Total loss': 0.26619951553183835}
2023-01-05 00:57:06,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:06,878 INFO:     Epoch: 26
2023-01-05 00:57:09,141 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4661572761833668, 'Total loss': 0.4661572761833668} | train loss {'Reaction outcome loss': 0.26111214667026367, 'Total loss': 0.26111214667026367}
2023-01-05 00:57:09,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:09,142 INFO:     Epoch: 27
2023-01-05 00:57:11,348 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46917877594629925, 'Total loss': 0.46917877594629925} | train loss {'Reaction outcome loss': 0.2529126342514233, 'Total loss': 0.2529126342514233}
2023-01-05 00:57:11,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:11,348 INFO:     Epoch: 28
2023-01-05 00:57:13,593 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.480444073677063, 'Total loss': 0.480444073677063} | train loss {'Reaction outcome loss': 0.25406652267977314, 'Total loss': 0.25406652267977314}
2023-01-05 00:57:13,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:13,594 INFO:     Epoch: 29
2023-01-05 00:57:15,857 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4649264693260193, 'Total loss': 0.4649264693260193} | train loss {'Reaction outcome loss': 0.24825233460296, 'Total loss': 0.24825233460296}
2023-01-05 00:57:15,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:15,858 INFO:     Epoch: 30
2023-01-05 00:57:18,044 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46882496525843936, 'Total loss': 0.46882496525843936} | train loss {'Reaction outcome loss': 0.24708871196734422, 'Total loss': 0.24708871196734422}
2023-01-05 00:57:18,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:18,045 INFO:     Epoch: 31
2023-01-05 00:57:20,250 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4878878340125084, 'Total loss': 0.4878878340125084} | train loss {'Reaction outcome loss': 0.2472879978711295, 'Total loss': 0.2472879978711295}
2023-01-05 00:57:20,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:20,250 INFO:     Epoch: 32
2023-01-05 00:57:22,452 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4822746440768242, 'Total loss': 0.4822746440768242} | train loss {'Reaction outcome loss': 0.23899316054640635, 'Total loss': 0.23899316054640635}
2023-01-05 00:57:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:22,453 INFO:     Epoch: 33
2023-01-05 00:57:24,700 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47438287536303203, 'Total loss': 0.47438287536303203} | train loss {'Reaction outcome loss': 0.2390930554266508, 'Total loss': 0.2390930554266508}
2023-01-05 00:57:24,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:24,700 INFO:     Epoch: 34
2023-01-05 00:57:26,880 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5084789236386617, 'Total loss': 0.5084789236386617} | train loss {'Reaction outcome loss': 0.23672248103442448, 'Total loss': 0.23672248103442448}
2023-01-05 00:57:26,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:26,880 INFO:     Epoch: 35
2023-01-05 00:57:29,090 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4773825019598007, 'Total loss': 0.4773825019598007} | train loss {'Reaction outcome loss': 0.23298027260782386, 'Total loss': 0.23298027260782386}
2023-01-05 00:57:29,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:29,091 INFO:     Epoch: 36
2023-01-05 00:57:31,341 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4897563815116882, 'Total loss': 0.4897563815116882} | train loss {'Reaction outcome loss': 0.22949933189142874, 'Total loss': 0.22949933189142874}
2023-01-05 00:57:31,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:31,342 INFO:     Epoch: 37
2023-01-05 00:57:33,568 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4576446106036504, 'Total loss': 0.4576446106036504} | train loss {'Reaction outcome loss': 0.2241746252335176, 'Total loss': 0.2241746252335176}
2023-01-05 00:57:33,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:33,568 INFO:     Epoch: 38
2023-01-05 00:57:35,773 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47400365670522054, 'Total loss': 0.47400365670522054} | train loss {'Reaction outcome loss': 0.2257645732378992, 'Total loss': 0.2257645732378992}
2023-01-05 00:57:35,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:35,773 INFO:     Epoch: 39
2023-01-05 00:57:37,960 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49930492639541624, 'Total loss': 0.49930492639541624} | train loss {'Reaction outcome loss': 0.22125802204296316, 'Total loss': 0.22125802204296316}
2023-01-05 00:57:37,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:37,960 INFO:     Epoch: 40
2023-01-05 00:57:40,224 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46516145865122477, 'Total loss': 0.46516145865122477} | train loss {'Reaction outcome loss': 0.22290773181969376, 'Total loss': 0.22290773181969376}
2023-01-05 00:57:40,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:40,225 INFO:     Epoch: 41
2023-01-05 00:57:42,447 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46530399918556214, 'Total loss': 0.46530399918556214} | train loss {'Reaction outcome loss': 0.2193760967187489, 'Total loss': 0.2193760967187489}
2023-01-05 00:57:42,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:42,448 INFO:     Epoch: 42
2023-01-05 00:57:44,689 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5289610167344411, 'Total loss': 0.5289610167344411} | train loss {'Reaction outcome loss': 0.21100232606092334, 'Total loss': 0.21100232606092334}
2023-01-05 00:57:44,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:44,689 INFO:     Epoch: 43
2023-01-05 00:57:46,931 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4918295790751775, 'Total loss': 0.4918295790751775} | train loss {'Reaction outcome loss': 0.21480616197220734, 'Total loss': 0.21480616197220734}
2023-01-05 00:57:46,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:46,931 INFO:     Epoch: 44
2023-01-05 00:57:49,113 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.50609004398187, 'Total loss': 0.50609004398187} | train loss {'Reaction outcome loss': 0.22086905698845352, 'Total loss': 0.22086905698845352}
2023-01-05 00:57:49,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:49,113 INFO:     Epoch: 45
2023-01-05 00:57:51,359 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48726992309093475, 'Total loss': 0.48726992309093475} | train loss {'Reaction outcome loss': 0.2109015694063535, 'Total loss': 0.2109015694063535}
2023-01-05 00:57:51,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:51,359 INFO:     Epoch: 46
2023-01-05 00:57:53,621 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.501435124874115, 'Total loss': 0.501435124874115} | train loss {'Reaction outcome loss': 0.20906503674695673, 'Total loss': 0.20906503674695673}
2023-01-05 00:57:53,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:53,621 INFO:     Epoch: 47
2023-01-05 00:57:55,883 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4702983538309733, 'Total loss': 0.4702983538309733} | train loss {'Reaction outcome loss': 0.2083269764578132, 'Total loss': 0.2083269764578132}
2023-01-05 00:57:55,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:55,883 INFO:     Epoch: 48
2023-01-05 00:57:58,150 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4868211458126704, 'Total loss': 0.4868211458126704} | train loss {'Reaction outcome loss': 0.20353635381721635, 'Total loss': 0.20353635381721635}
2023-01-05 00:57:58,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:57:58,151 INFO:     Epoch: 49
2023-01-05 00:58:00,413 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4938643664121628, 'Total loss': 0.4938643664121628} | train loss {'Reaction outcome loss': 0.20684956372522958, 'Total loss': 0.20684956372522958}
2023-01-05 00:58:00,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:00,414 INFO:     Epoch: 50
2023-01-05 00:58:02,652 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5103761911392212, 'Total loss': 0.5103761911392212} | train loss {'Reaction outcome loss': 0.20537916918713733, 'Total loss': 0.20537916918713733}
2023-01-05 00:58:02,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:02,652 INFO:     Epoch: 51
2023-01-05 00:58:04,700 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4890604813893636, 'Total loss': 0.4890604813893636} | train loss {'Reaction outcome loss': 0.20177906042511534, 'Total loss': 0.20177906042511534}
2023-01-05 00:58:04,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:04,701 INFO:     Epoch: 52
2023-01-05 00:58:06,938 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4639266520738602, 'Total loss': 0.4639266520738602} | train loss {'Reaction outcome loss': 0.20183215027943183, 'Total loss': 0.20183215027943183}
2023-01-05 00:58:06,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:06,938 INFO:     Epoch: 53
2023-01-05 00:58:09,174 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4954786837100983, 'Total loss': 0.4954786837100983} | train loss {'Reaction outcome loss': 0.19683444673580158, 'Total loss': 0.19683444673580158}
2023-01-05 00:58:09,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:09,174 INFO:     Epoch: 54
2023-01-05 00:58:11,404 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45746173361937204, 'Total loss': 0.45746173361937204} | train loss {'Reaction outcome loss': 0.2144106702771092, 'Total loss': 0.2144106702771092}
2023-01-05 00:58:11,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:11,405 INFO:     Epoch: 55
2023-01-05 00:58:13,651 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5100052406390508, 'Total loss': 0.5100052406390508} | train loss {'Reaction outcome loss': 0.24904821072603858, 'Total loss': 0.24904821072603858}
2023-01-05 00:58:13,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:13,651 INFO:     Epoch: 56
2023-01-05 00:58:15,875 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48850279351075493, 'Total loss': 0.48850279351075493} | train loss {'Reaction outcome loss': 0.20166447321663736, 'Total loss': 0.20166447321663736}
2023-01-05 00:58:15,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:15,875 INFO:     Epoch: 57
2023-01-05 00:58:18,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5220278754830361, 'Total loss': 0.5220278754830361} | train loss {'Reaction outcome loss': 0.1943035383306594, 'Total loss': 0.1943035383306594}
2023-01-05 00:58:18,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:18,081 INFO:     Epoch: 58
2023-01-05 00:58:20,345 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5372320890426636, 'Total loss': 0.5372320890426636} | train loss {'Reaction outcome loss': 0.2096119790499949, 'Total loss': 0.2096119790499949}
2023-01-05 00:58:20,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:20,345 INFO:     Epoch: 59
2023-01-05 00:58:22,584 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5073448449373246, 'Total loss': 0.5073448449373246} | train loss {'Reaction outcome loss': 0.24933127361104185, 'Total loss': 0.24933127361104185}
2023-01-05 00:58:22,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:22,584 INFO:     Epoch: 60
2023-01-05 00:58:24,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5092294752597809, 'Total loss': 0.5092294752597809} | train loss {'Reaction outcome loss': 0.1967822947181707, 'Total loss': 0.1967822947181707}
2023-01-05 00:58:24,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:24,841 INFO:     Epoch: 61
2023-01-05 00:58:27,075 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47234598696231844, 'Total loss': 0.47234598696231844} | train loss {'Reaction outcome loss': 0.19593414458311112, 'Total loss': 0.19593414458311112}
2023-01-05 00:58:27,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:27,075 INFO:     Epoch: 62
2023-01-05 00:58:29,327 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4995651920636495, 'Total loss': 0.4995651920636495} | train loss {'Reaction outcome loss': 0.19128998401562136, 'Total loss': 0.19128998401562136}
2023-01-05 00:58:29,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:29,328 INFO:     Epoch: 63
2023-01-05 00:58:31,564 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5212463319301606, 'Total loss': 0.5212463319301606} | train loss {'Reaction outcome loss': 0.19312669716516434, 'Total loss': 0.19312669716516434}
2023-01-05 00:58:31,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:31,564 INFO:     Epoch: 64
2023-01-05 00:58:33,794 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4656768001616001, 'Total loss': 0.4656768001616001} | train loss {'Reaction outcome loss': 0.1921014866143789, 'Total loss': 0.1921014866143789}
2023-01-05 00:58:33,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:33,794 INFO:     Epoch: 65
2023-01-05 00:58:36,055 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5114526808261871, 'Total loss': 0.5114526808261871} | train loss {'Reaction outcome loss': 0.2035205111076167, 'Total loss': 0.2035205111076167}
2023-01-05 00:58:36,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:36,057 INFO:     Epoch: 66
2023-01-05 00:58:38,323 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48762795627117156, 'Total loss': 0.48762795627117156} | train loss {'Reaction outcome loss': 0.19725543821055064, 'Total loss': 0.19725543821055064}
2023-01-05 00:58:38,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:38,323 INFO:     Epoch: 67
2023-01-05 00:58:40,536 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4962346971035004, 'Total loss': 0.4962346971035004} | train loss {'Reaction outcome loss': 0.2122801487421384, 'Total loss': 0.2122801487421384}
2023-01-05 00:58:40,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:40,536 INFO:     Epoch: 68
2023-01-05 00:58:42,785 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46805479700366653, 'Total loss': 0.46805479700366653} | train loss {'Reaction outcome loss': 0.19452655273725858, 'Total loss': 0.19452655273725858}
2023-01-05 00:58:42,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:42,786 INFO:     Epoch: 69
2023-01-05 00:58:44,997 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48190514047940575, 'Total loss': 0.48190514047940575} | train loss {'Reaction outcome loss': 0.18691457012848162, 'Total loss': 0.18691457012848162}
2023-01-05 00:58:44,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:44,997 INFO:     Epoch: 70
2023-01-05 00:58:47,184 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5113882919152578, 'Total loss': 0.5113882919152578} | train loss {'Reaction outcome loss': 0.18607133403260168, 'Total loss': 0.18607133403260168}
2023-01-05 00:58:47,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:47,184 INFO:     Epoch: 71
2023-01-05 00:58:49,434 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5212959994872411, 'Total loss': 0.5212959994872411} | train loss {'Reaction outcome loss': 0.19271392000677146, 'Total loss': 0.19271392000677146}
2023-01-05 00:58:49,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:49,434 INFO:     Epoch: 72
2023-01-05 00:58:51,622 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4774632275104523, 'Total loss': 0.4774632275104523} | train loss {'Reaction outcome loss': 0.20053706547506686, 'Total loss': 0.20053706547506686}
2023-01-05 00:58:51,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:51,622 INFO:     Epoch: 73
2023-01-05 00:58:53,845 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5147906055053075, 'Total loss': 0.5147906055053075} | train loss {'Reaction outcome loss': 0.19498443289362974, 'Total loss': 0.19498443289362974}
2023-01-05 00:58:53,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:53,845 INFO:     Epoch: 74
2023-01-05 00:58:56,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5376529529690742, 'Total loss': 0.5376529529690742} | train loss {'Reaction outcome loss': 0.18589536793402606, 'Total loss': 0.18589536793402606}
2023-01-05 00:58:56,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:56,100 INFO:     Epoch: 75
2023-01-05 00:58:58,342 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5149264514446259, 'Total loss': 0.5149264514446259} | train loss {'Reaction outcome loss': 0.18575333752222292, 'Total loss': 0.18575333752222292}
2023-01-05 00:58:58,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:58:58,342 INFO:     Epoch: 76
2023-01-05 00:59:00,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5337855617205302, 'Total loss': 0.5337855617205302} | train loss {'Reaction outcome loss': 0.1826064715590463, 'Total loss': 0.1826064715590463}
2023-01-05 00:59:00,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:00,603 INFO:     Epoch: 77
2023-01-05 00:59:02,864 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5421332856019337, 'Total loss': 0.5421332856019337} | train loss {'Reaction outcome loss': 0.18264507694571427, 'Total loss': 0.18264507694571427}
2023-01-05 00:59:02,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:02,865 INFO:     Epoch: 78
2023-01-05 00:59:05,102 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5296287948886553, 'Total loss': 0.5296287948886553} | train loss {'Reaction outcome loss': 0.1792590474866776, 'Total loss': 0.1792590474866776}
2023-01-05 00:59:05,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:05,103 INFO:     Epoch: 79
2023-01-05 00:59:07,348 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5457263390223185, 'Total loss': 0.5457263390223185} | train loss {'Reaction outcome loss': 0.1790489701887555, 'Total loss': 0.1790489701887555}
2023-01-05 00:59:07,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:07,348 INFO:     Epoch: 80
2023-01-05 00:59:09,599 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4834442433745911, 'Total loss': 0.4834442433745911} | train loss {'Reaction outcome loss': 0.17744718801254022, 'Total loss': 0.17744718801254022}
2023-01-05 00:59:09,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:09,600 INFO:     Epoch: 81
2023-01-05 00:59:11,859 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4997711986303329, 'Total loss': 0.4997711986303329} | train loss {'Reaction outcome loss': 0.1815498132601151, 'Total loss': 0.1815498132601151}
2023-01-05 00:59:11,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:11,860 INFO:     Epoch: 82
2023-01-05 00:59:14,044 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5238603959480922, 'Total loss': 0.5238603959480922} | train loss {'Reaction outcome loss': 0.17427103052867335, 'Total loss': 0.17427103052867335}
2023-01-05 00:59:14,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:14,044 INFO:     Epoch: 83
2023-01-05 00:59:16,235 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.510962450504303, 'Total loss': 0.510962450504303} | train loss {'Reaction outcome loss': 0.17481300616843023, 'Total loss': 0.17481300616843023}
2023-01-05 00:59:16,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:16,235 INFO:     Epoch: 84
2023-01-05 00:59:18,500 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5040699840833743, 'Total loss': 0.5040699840833743} | train loss {'Reaction outcome loss': 0.17504556027099327, 'Total loss': 0.17504556027099327}
2023-01-05 00:59:18,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:18,501 INFO:     Epoch: 85
2023-01-05 00:59:20,751 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49783450762430825, 'Total loss': 0.49783450762430825} | train loss {'Reaction outcome loss': 0.17171975301175404, 'Total loss': 0.17171975301175404}
2023-01-05 00:59:20,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:20,751 INFO:     Epoch: 86
2023-01-05 00:59:22,927 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5051071961720784, 'Total loss': 0.5051071961720784} | train loss {'Reaction outcome loss': 0.1785964913787725, 'Total loss': 0.1785964913787725}
2023-01-05 00:59:22,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:22,928 INFO:     Epoch: 87
2023-01-05 00:59:25,133 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4971100995937983, 'Total loss': 0.4971100995937983} | train loss {'Reaction outcome loss': 0.17744446494759977, 'Total loss': 0.17744446494759977}
2023-01-05 00:59:25,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:25,134 INFO:     Epoch: 88
2023-01-05 00:59:27,351 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5085351924101512, 'Total loss': 0.5085351924101512} | train loss {'Reaction outcome loss': 0.17675622693681414, 'Total loss': 0.17675622693681414}
2023-01-05 00:59:27,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:27,352 INFO:     Epoch: 89
2023-01-05 00:59:29,533 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48464126338561375, 'Total loss': 0.48464126338561375} | train loss {'Reaction outcome loss': 0.17381275354369607, 'Total loss': 0.17381275354369607}
2023-01-05 00:59:29,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:29,534 INFO:     Epoch: 90
2023-01-05 00:59:31,741 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.494321246460701, 'Total loss': 0.494321246460701} | train loss {'Reaction outcome loss': 0.172796023268914, 'Total loss': 0.172796023268914}
2023-01-05 00:59:31,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:31,742 INFO:     Epoch: 91
2023-01-05 00:59:33,992 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4921672782084594, 'Total loss': 0.4921672782084594} | train loss {'Reaction outcome loss': 0.17299950414079693, 'Total loss': 0.17299950414079693}
2023-01-05 00:59:33,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:33,993 INFO:     Epoch: 92
2023-01-05 00:59:36,251 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48361696898937223, 'Total loss': 0.48361696898937223} | train loss {'Reaction outcome loss': 0.17015849874039396, 'Total loss': 0.17015849874039396}
2023-01-05 00:59:36,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:36,252 INFO:     Epoch: 93
2023-01-05 00:59:38,514 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4958180397748947, 'Total loss': 0.4958180397748947} | train loss {'Reaction outcome loss': 0.17660815924308196, 'Total loss': 0.17660815924308196}
2023-01-05 00:59:38,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:38,515 INFO:     Epoch: 94
2023-01-05 00:59:40,745 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5209376732508342, 'Total loss': 0.5209376732508342} | train loss {'Reaction outcome loss': 0.1782287808680954, 'Total loss': 0.1782287808680954}
2023-01-05 00:59:40,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:40,746 INFO:     Epoch: 95
2023-01-05 00:59:42,999 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5464767485857009, 'Total loss': 0.5464767485857009} | train loss {'Reaction outcome loss': 0.17604910444102986, 'Total loss': 0.17604910444102986}
2023-01-05 00:59:42,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:42,999 INFO:     Epoch: 96
2023-01-05 00:59:45,177 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5197370345393817, 'Total loss': 0.5197370345393817} | train loss {'Reaction outcome loss': 0.17236596273690247, 'Total loss': 0.17236596273690247}
2023-01-05 00:59:45,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:45,177 INFO:     Epoch: 97
2023-01-05 00:59:47,437 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5054401338100434, 'Total loss': 0.5054401338100434} | train loss {'Reaction outcome loss': 0.17415131679070697, 'Total loss': 0.17415131679070697}
2023-01-05 00:59:47,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:47,438 INFO:     Epoch: 98
2023-01-05 00:59:49,647 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5162615646918615, 'Total loss': 0.5162615646918615} | train loss {'Reaction outcome loss': 0.16767649524895797, 'Total loss': 0.16767649524895797}
2023-01-05 00:59:49,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:49,647 INFO:     Epoch: 99
2023-01-05 00:59:51,644 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5055836260318756, 'Total loss': 0.5055836260318756} | train loss {'Reaction outcome loss': 0.16969234431314323, 'Total loss': 0.16969234431314323}
2023-01-05 00:59:51,644 INFO:     Best model found after epoch 22 of 100.
2023-01-05 00:59:51,645 INFO:   Done with stage: TRAINING
2023-01-05 00:59:51,645 INFO:   Starting stage: EVALUATION
2023-01-05 00:59:51,777 INFO:   Done with stage: EVALUATION
2023-01-05 00:59:51,777 INFO:   Leaving out SEQ value Fold_2
2023-01-05 00:59:51,790 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 00:59:51,790 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:59:52,448 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:59:52,448 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:59:52,518 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:59:52,518 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:59:52,518 INFO:     No hyperparam tuning for this model
2023-01-05 00:59:52,518 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:59:52,518 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:59:52,519 INFO:     None feature selector for col prot
2023-01-05 00:59:52,519 INFO:     None feature selector for col prot
2023-01-05 00:59:52,519 INFO:     None feature selector for col prot
2023-01-05 00:59:52,519 INFO:     None feature selector for col chem
2023-01-05 00:59:52,519 INFO:     None feature selector for col chem
2023-01-05 00:59:52,520 INFO:     None feature selector for col chem
2023-01-05 00:59:52,520 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:59:52,520 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:59:52,521 INFO:     Number of params in model 72931
2023-01-05 00:59:52,524 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:59:52,524 INFO:   Starting stage: TRAINING
2023-01-05 00:59:52,573 INFO:     Val loss before train {'Reaction outcome loss': 0.9192410826683044, 'Total loss': 0.9192410826683044}
2023-01-05 00:59:52,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:52,573 INFO:     Epoch: 0
2023-01-05 00:59:54,382 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6748064696788788, 'Total loss': 0.6748064696788788} | train loss {'Reaction outcome loss': 0.947166933304202, 'Total loss': 0.947166933304202}
2023-01-05 00:59:54,382 INFO:     Found new best model at epoch 0
2023-01-05 00:59:54,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:54,384 INFO:     Epoch: 1
2023-01-05 00:59:56,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5120652794837952, 'Total loss': 0.5120652794837952} | train loss {'Reaction outcome loss': 0.6263559416045238, 'Total loss': 0.6263559416045238}
2023-01-05 00:59:56,465 INFO:     Found new best model at epoch 1
2023-01-05 00:59:56,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:56,466 INFO:     Epoch: 2
2023-01-05 00:59:58,717 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48905892471472423, 'Total loss': 0.48905892471472423} | train loss {'Reaction outcome loss': 0.5201104492710454, 'Total loss': 0.5201104492710454}
2023-01-05 00:59:58,717 INFO:     Found new best model at epoch 2
2023-01-05 00:59:58,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:59:58,719 INFO:     Epoch: 3
2023-01-05 01:00:00,965 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4998805065949758, 'Total loss': 0.4998805065949758} | train loss {'Reaction outcome loss': 0.47827644765812116, 'Total loss': 0.47827644765812116}
2023-01-05 01:00:00,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:00,966 INFO:     Epoch: 4
2023-01-05 01:00:03,216 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4702560106913249, 'Total loss': 0.4702560106913249} | train loss {'Reaction outcome loss': 0.44164417613379275, 'Total loss': 0.44164417613379275}
2023-01-05 01:00:03,216 INFO:     Found new best model at epoch 4
2023-01-05 01:00:03,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:03,217 INFO:     Epoch: 5
2023-01-05 01:00:05,469 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45309275686740874, 'Total loss': 0.45309275686740874} | train loss {'Reaction outcome loss': 0.4236086379655086, 'Total loss': 0.4236086379655086}
2023-01-05 01:00:05,470 INFO:     Found new best model at epoch 5
2023-01-05 01:00:05,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:05,471 INFO:     Epoch: 6
2023-01-05 01:00:07,671 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44338516891002655, 'Total loss': 0.44338516891002655} | train loss {'Reaction outcome loss': 0.39757149968377864, 'Total loss': 0.39757149968377864}
2023-01-05 01:00:07,671 INFO:     Found new best model at epoch 6
2023-01-05 01:00:07,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:07,672 INFO:     Epoch: 7
2023-01-05 01:00:09,907 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43617122769355776, 'Total loss': 0.43617122769355776} | train loss {'Reaction outcome loss': 0.3761545737294385, 'Total loss': 0.3761545737294385}
2023-01-05 01:00:09,908 INFO:     Found new best model at epoch 7
2023-01-05 01:00:09,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:09,909 INFO:     Epoch: 8
2023-01-05 01:00:12,146 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.410845814148585, 'Total loss': 0.410845814148585} | train loss {'Reaction outcome loss': 0.3706992088008101, 'Total loss': 0.3706992088008101}
2023-01-05 01:00:12,146 INFO:     Found new best model at epoch 8
2023-01-05 01:00:12,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:12,148 INFO:     Epoch: 9
2023-01-05 01:00:14,359 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41278754274050394, 'Total loss': 0.41278754274050394} | train loss {'Reaction outcome loss': 0.35463112062455093, 'Total loss': 0.35463112062455093}
2023-01-05 01:00:14,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:14,360 INFO:     Epoch: 10
2023-01-05 01:00:16,602 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3820409838420649, 'Total loss': 0.3820409838420649} | train loss {'Reaction outcome loss': 0.34429786007606633, 'Total loss': 0.34429786007606633}
2023-01-05 01:00:16,603 INFO:     Found new best model at epoch 10
2023-01-05 01:00:16,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:16,604 INFO:     Epoch: 11
2023-01-05 01:00:18,813 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4401142617066701, 'Total loss': 0.4401142617066701} | train loss {'Reaction outcome loss': 0.3385186286738319, 'Total loss': 0.3385186286738319}
2023-01-05 01:00:18,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:18,813 INFO:     Epoch: 12
2023-01-05 01:00:21,064 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.411903178691864, 'Total loss': 0.411903178691864} | train loss {'Reaction outcome loss': 0.3270363110477907, 'Total loss': 0.3270363110477907}
2023-01-05 01:00:21,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:21,064 INFO:     Epoch: 13
2023-01-05 01:00:23,313 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3795735135674477, 'Total loss': 0.3795735135674477} | train loss {'Reaction outcome loss': 0.3172588387137129, 'Total loss': 0.3172588387137129}
2023-01-05 01:00:23,314 INFO:     Found new best model at epoch 13
2023-01-05 01:00:23,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:23,315 INFO:     Epoch: 14
2023-01-05 01:00:25,563 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4266601622104645, 'Total loss': 0.4266601622104645} | train loss {'Reaction outcome loss': 0.31039210431359326, 'Total loss': 0.31039210431359326}
2023-01-05 01:00:25,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:25,563 INFO:     Epoch: 15
2023-01-05 01:00:27,777 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38084795127312343, 'Total loss': 0.38084795127312343} | train loss {'Reaction outcome loss': 0.30098939937179103, 'Total loss': 0.30098939937179103}
2023-01-05 01:00:27,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:27,778 INFO:     Epoch: 16
2023-01-05 01:00:29,938 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3750828385353088, 'Total loss': 0.3750828385353088} | train loss {'Reaction outcome loss': 0.29397889400023397, 'Total loss': 0.29397889400023397}
2023-01-05 01:00:29,938 INFO:     Found new best model at epoch 16
2023-01-05 01:00:29,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:29,939 INFO:     Epoch: 17
2023-01-05 01:00:32,167 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3933918515841166, 'Total loss': 0.3933918515841166} | train loss {'Reaction outcome loss': 0.2899925030332847, 'Total loss': 0.2899925030332847}
2023-01-05 01:00:32,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:32,167 INFO:     Epoch: 18
2023-01-05 01:00:34,389 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3952187051375707, 'Total loss': 0.3952187051375707} | train loss {'Reaction outcome loss': 0.2813276532004132, 'Total loss': 0.2813276532004132}
2023-01-05 01:00:34,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:34,389 INFO:     Epoch: 19
2023-01-05 01:00:36,623 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4001830518245697, 'Total loss': 0.4001830518245697} | train loss {'Reaction outcome loss': 0.2728718922738611, 'Total loss': 0.2728718922738611}
2023-01-05 01:00:36,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:36,624 INFO:     Epoch: 20
2023-01-05 01:00:38,812 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4190894385178884, 'Total loss': 0.4190894385178884} | train loss {'Reaction outcome loss': 0.2733537534075062, 'Total loss': 0.2733537534075062}
2023-01-05 01:00:38,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:38,812 INFO:     Epoch: 21
2023-01-05 01:00:41,043 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3956394612789154, 'Total loss': 0.3956394612789154} | train loss {'Reaction outcome loss': 0.26714392531880715, 'Total loss': 0.26714392531880715}
2023-01-05 01:00:41,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:41,043 INFO:     Epoch: 22
2023-01-05 01:00:43,261 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39169317682584126, 'Total loss': 0.39169317682584126} | train loss {'Reaction outcome loss': 0.2594308588028389, 'Total loss': 0.2594308588028389}
2023-01-05 01:00:43,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:43,262 INFO:     Epoch: 23
2023-01-05 01:00:45,503 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39256657535831135, 'Total loss': 0.39256657535831135} | train loss {'Reaction outcome loss': 0.25724095991221224, 'Total loss': 0.25724095991221224}
2023-01-05 01:00:45,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:45,504 INFO:     Epoch: 24
2023-01-05 01:00:47,752 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3858858019113541, 'Total loss': 0.3858858019113541} | train loss {'Reaction outcome loss': 0.25259940647078255, 'Total loss': 0.25259940647078255}
2023-01-05 01:00:47,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:47,753 INFO:     Epoch: 25
2023-01-05 01:00:49,994 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4150989532470703, 'Total loss': 0.4150989532470703} | train loss {'Reaction outcome loss': 0.2436420235946013, 'Total loss': 0.2436420235946013}
2023-01-05 01:00:49,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:49,995 INFO:     Epoch: 26
2023-01-05 01:00:52,251 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4117015262444814, 'Total loss': 0.4117015262444814} | train loss {'Reaction outcome loss': 0.24533391450225872, 'Total loss': 0.24533391450225872}
2023-01-05 01:00:52,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:52,252 INFO:     Epoch: 27
2023-01-05 01:00:54,410 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4195245606203874, 'Total loss': 0.4195245606203874} | train loss {'Reaction outcome loss': 0.240582749777793, 'Total loss': 0.240582749777793}
2023-01-05 01:00:54,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:54,411 INFO:     Epoch: 28
2023-01-05 01:00:56,612 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3892700523138046, 'Total loss': 0.3892700523138046} | train loss {'Reaction outcome loss': 0.23810520462256712, 'Total loss': 0.23810520462256712}
2023-01-05 01:00:56,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:56,612 INFO:     Epoch: 29
2023-01-05 01:00:58,855 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4173711175719897, 'Total loss': 0.4173711175719897} | train loss {'Reaction outcome loss': 0.23012827805168654, 'Total loss': 0.23012827805168654}
2023-01-05 01:00:58,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:00:58,856 INFO:     Epoch: 30
2023-01-05 01:01:01,086 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4110958069562912, 'Total loss': 0.4110958069562912} | train loss {'Reaction outcome loss': 0.23026413990211855, 'Total loss': 0.23026413990211855}
2023-01-05 01:01:01,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:01,086 INFO:     Epoch: 31
2023-01-05 01:01:03,318 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42984243532021843, 'Total loss': 0.42984243532021843} | train loss {'Reaction outcome loss': 0.23229720151854039, 'Total loss': 0.23229720151854039}
2023-01-05 01:01:03,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:03,318 INFO:     Epoch: 32
2023-01-05 01:01:05,518 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3762518430749575, 'Total loss': 0.3762518430749575} | train loss {'Reaction outcome loss': 0.22373363795098813, 'Total loss': 0.22373363795098813}
2023-01-05 01:01:05,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:05,518 INFO:     Epoch: 33
2023-01-05 01:01:07,793 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41578953166802723, 'Total loss': 0.41578953166802723} | train loss {'Reaction outcome loss': 0.22088366730587325, 'Total loss': 0.22088366730587325}
2023-01-05 01:01:07,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:07,793 INFO:     Epoch: 34
2023-01-05 01:01:10,049 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4172262728214264, 'Total loss': 0.4172262728214264} | train loss {'Reaction outcome loss': 0.23099436853624825, 'Total loss': 0.23099436853624825}
2023-01-05 01:01:10,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:10,050 INFO:     Epoch: 35
2023-01-05 01:01:12,223 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40131181726853055, 'Total loss': 0.40131181726853055} | train loss {'Reaction outcome loss': 0.21519868035059775, 'Total loss': 0.21519868035059775}
2023-01-05 01:01:12,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:12,224 INFO:     Epoch: 36
2023-01-05 01:01:14,388 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44852498869101204, 'Total loss': 0.44852498869101204} | train loss {'Reaction outcome loss': 0.21411283505251155, 'Total loss': 0.21411283505251155}
2023-01-05 01:01:14,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:14,388 INFO:     Epoch: 37
2023-01-05 01:01:16,558 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38456633339325585, 'Total loss': 0.38456633339325585} | train loss {'Reaction outcome loss': 0.21686915850545532, 'Total loss': 0.21686915850545532}
2023-01-05 01:01:16,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:16,558 INFO:     Epoch: 38
2023-01-05 01:01:18,768 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40787633856137595, 'Total loss': 0.40787633856137595} | train loss {'Reaction outcome loss': 0.21806911650677993, 'Total loss': 0.21806911650677993}
2023-01-05 01:01:18,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:18,769 INFO:     Epoch: 39
2023-01-05 01:01:20,958 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4072403391202291, 'Total loss': 0.4072403391202291} | train loss {'Reaction outcome loss': 0.21276098112813638, 'Total loss': 0.21276098112813638}
2023-01-05 01:01:20,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:20,958 INFO:     Epoch: 40
2023-01-05 01:01:23,179 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4166436252494653, 'Total loss': 0.4166436252494653} | train loss {'Reaction outcome loss': 0.2065524355555973, 'Total loss': 0.2065524355555973}
2023-01-05 01:01:23,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:23,180 INFO:     Epoch: 41
2023-01-05 01:01:25,369 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39613470137119294, 'Total loss': 0.39613470137119294} | train loss {'Reaction outcome loss': 0.2084685535387673, 'Total loss': 0.2084685535387673}
2023-01-05 01:01:25,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:25,369 INFO:     Epoch: 42
2023-01-05 01:01:27,604 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4063372184832891, 'Total loss': 0.4063372184832891} | train loss {'Reaction outcome loss': 0.20515436423520972, 'Total loss': 0.20515436423520972}
2023-01-05 01:01:27,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:27,605 INFO:     Epoch: 43
2023-01-05 01:01:29,853 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4685790777206421, 'Total loss': 0.4685790777206421} | train loss {'Reaction outcome loss': 0.20513881476133736, 'Total loss': 0.20513881476133736}
2023-01-05 01:01:29,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:29,854 INFO:     Epoch: 44
2023-01-05 01:01:32,166 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40698403666416805, 'Total loss': 0.40698403666416805} | train loss {'Reaction outcome loss': 0.2059054964147236, 'Total loss': 0.2059054964147236}
2023-01-05 01:01:32,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:32,166 INFO:     Epoch: 45
2023-01-05 01:01:34,472 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40497124592463174, 'Total loss': 0.40497124592463174} | train loss {'Reaction outcome loss': 0.20020812888541362, 'Total loss': 0.20020812888541362}
2023-01-05 01:01:34,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:34,472 INFO:     Epoch: 46
2023-01-05 01:01:36,793 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4099301661054293, 'Total loss': 0.4099301661054293} | train loss {'Reaction outcome loss': 0.19868516268031874, 'Total loss': 0.19868516268031874}
2023-01-05 01:01:36,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:36,794 INFO:     Epoch: 47
2023-01-05 01:01:39,109 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3809100871284803, 'Total loss': 0.3809100871284803} | train loss {'Reaction outcome loss': 0.19570095754180947, 'Total loss': 0.19570095754180947}
2023-01-05 01:01:39,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:39,109 INFO:     Epoch: 48
2023-01-05 01:01:41,400 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40072839688509704, 'Total loss': 0.40072839688509704} | train loss {'Reaction outcome loss': 0.19522613590841528, 'Total loss': 0.19522613590841528}
2023-01-05 01:01:41,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:41,401 INFO:     Epoch: 49
2023-01-05 01:01:43,622 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3868065863847733, 'Total loss': 0.3868065863847733} | train loss {'Reaction outcome loss': 0.1979053406772224, 'Total loss': 0.1979053406772224}
2023-01-05 01:01:43,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:43,623 INFO:     Epoch: 50
2023-01-05 01:01:45,849 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3951784441868464, 'Total loss': 0.3951784441868464} | train loss {'Reaction outcome loss': 0.19326890322012677, 'Total loss': 0.19326890322012677}
2023-01-05 01:01:45,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:45,849 INFO:     Epoch: 51
2023-01-05 01:01:48,107 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3826937545401355, 'Total loss': 0.3826937545401355} | train loss {'Reaction outcome loss': 0.19463049998017448, 'Total loss': 0.19463049998017448}
2023-01-05 01:01:48,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:48,107 INFO:     Epoch: 52
2023-01-05 01:01:50,256 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4410093531012535, 'Total loss': 0.4410093531012535} | train loss {'Reaction outcome loss': 0.1908017475426496, 'Total loss': 0.1908017475426496}
2023-01-05 01:01:50,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:50,257 INFO:     Epoch: 53
2023-01-05 01:01:52,482 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3955368767182032, 'Total loss': 0.3955368767182032} | train loss {'Reaction outcome loss': 0.18752471374239038, 'Total loss': 0.18752471374239038}
2023-01-05 01:01:52,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:52,482 INFO:     Epoch: 54
2023-01-05 01:01:54,734 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38558356265227, 'Total loss': 0.38558356265227} | train loss {'Reaction outcome loss': 0.1908774064908171, 'Total loss': 0.1908774064908171}
2023-01-05 01:01:54,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:54,734 INFO:     Epoch: 55
2023-01-05 01:01:56,953 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4089024777213732, 'Total loss': 0.4089024777213732} | train loss {'Reaction outcome loss': 0.1909878912388626, 'Total loss': 0.1909878912388626}
2023-01-05 01:01:56,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:56,953 INFO:     Epoch: 56
2023-01-05 01:01:59,196 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40260461568832395, 'Total loss': 0.40260461568832395} | train loss {'Reaction outcome loss': 0.18521560568797546, 'Total loss': 0.18521560568797546}
2023-01-05 01:01:59,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:01:59,197 INFO:     Epoch: 57
2023-01-05 01:02:01,428 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41788663566112516, 'Total loss': 0.41788663566112516} | train loss {'Reaction outcome loss': 0.18254175439585735, 'Total loss': 0.18254175439585735}
2023-01-05 01:02:01,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:01,428 INFO:     Epoch: 58
2023-01-05 01:02:03,655 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4026558836301168, 'Total loss': 0.4026558836301168} | train loss {'Reaction outcome loss': 0.1796350120906684, 'Total loss': 0.1796350120906684}
2023-01-05 01:02:03,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:03,655 INFO:     Epoch: 59
2023-01-05 01:02:05,875 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38775437474250796, 'Total loss': 0.38775437474250796} | train loss {'Reaction outcome loss': 0.18663387026902914, 'Total loss': 0.18663387026902914}
2023-01-05 01:02:05,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:05,876 INFO:     Epoch: 60
2023-01-05 01:02:08,107 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3944269468386968, 'Total loss': 0.3944269468386968} | train loss {'Reaction outcome loss': 0.18434921624801753, 'Total loss': 0.18434921624801753}
2023-01-05 01:02:08,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:08,107 INFO:     Epoch: 61
2023-01-05 01:02:10,165 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4066391910115878, 'Total loss': 0.4066391910115878} | train loss {'Reaction outcome loss': 0.1832644160901516, 'Total loss': 0.1832644160901516}
2023-01-05 01:02:10,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:10,165 INFO:     Epoch: 62
2023-01-05 01:02:12,326 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4221587797005971, 'Total loss': 0.4221587797005971} | train loss {'Reaction outcome loss': 0.18347796046576142, 'Total loss': 0.18347796046576142}
2023-01-05 01:02:12,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:12,327 INFO:     Epoch: 63
2023-01-05 01:02:14,564 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4018853892882665, 'Total loss': 0.4018853892882665} | train loss {'Reaction outcome loss': 0.18084231294338068, 'Total loss': 0.18084231294338068}
2023-01-05 01:02:14,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:14,565 INFO:     Epoch: 64
2023-01-05 01:02:16,788 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41434390644232433, 'Total loss': 0.41434390644232433} | train loss {'Reaction outcome loss': 0.18231368876728535, 'Total loss': 0.18231368876728535}
2023-01-05 01:02:16,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:16,789 INFO:     Epoch: 65
2023-01-05 01:02:19,026 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40243948101997373, 'Total loss': 0.40243948101997373} | train loss {'Reaction outcome loss': 0.18174910103310796, 'Total loss': 0.18174910103310796}
2023-01-05 01:02:19,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:19,027 INFO:     Epoch: 66
2023-01-05 01:02:21,254 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40291534960269926, 'Total loss': 0.40291534960269926} | train loss {'Reaction outcome loss': 0.17910272152550574, 'Total loss': 0.17910272152550574}
2023-01-05 01:02:21,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:21,255 INFO:     Epoch: 67
2023-01-05 01:02:23,494 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4344092845916748, 'Total loss': 0.4344092845916748} | train loss {'Reaction outcome loss': 0.17902078969152577, 'Total loss': 0.17902078969152577}
2023-01-05 01:02:23,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:23,494 INFO:     Epoch: 68
2023-01-05 01:02:25,693 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3991780010362466, 'Total loss': 0.3991780010362466} | train loss {'Reaction outcome loss': 0.17498254534332966, 'Total loss': 0.17498254534332966}
2023-01-05 01:02:25,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:25,693 INFO:     Epoch: 69
2023-01-05 01:02:27,909 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40258733838175736, 'Total loss': 0.40258733838175736} | train loss {'Reaction outcome loss': 0.17575886230371948, 'Total loss': 0.17575886230371948}
2023-01-05 01:02:27,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:27,910 INFO:     Epoch: 70
2023-01-05 01:02:30,133 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40821212232112886, 'Total loss': 0.40821212232112886} | train loss {'Reaction outcome loss': 0.1748055087327685, 'Total loss': 0.1748055087327685}
2023-01-05 01:02:30,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:30,133 INFO:     Epoch: 71
2023-01-05 01:02:32,351 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4112347183128198, 'Total loss': 0.4112347183128198} | train loss {'Reaction outcome loss': 0.17274856787297305, 'Total loss': 0.17274856787297305}
2023-01-05 01:02:32,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:32,351 INFO:     Epoch: 72
2023-01-05 01:02:34,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.435442058245341, 'Total loss': 0.435442058245341} | train loss {'Reaction outcome loss': 0.17466733394952041, 'Total loss': 0.17466733394952041}
2023-01-05 01:02:34,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:34,511 INFO:     Epoch: 73
2023-01-05 01:02:36,699 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40496156811714173, 'Total loss': 0.40496156811714173} | train loss {'Reaction outcome loss': 0.17301230172008059, 'Total loss': 0.17301230172008059}
2023-01-05 01:02:36,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:36,699 INFO:     Epoch: 74
2023-01-05 01:02:38,901 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39621864060560863, 'Total loss': 0.39621864060560863} | train loss {'Reaction outcome loss': 0.17124431657802014, 'Total loss': 0.17124431657802014}
2023-01-05 01:02:38,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:38,902 INFO:     Epoch: 75
2023-01-05 01:02:41,145 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40785150627295175, 'Total loss': 0.40785150627295175} | train loss {'Reaction outcome loss': 0.16884715976975315, 'Total loss': 0.16884715976975315}
2023-01-05 01:02:41,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:41,146 INFO:     Epoch: 76
2023-01-05 01:02:43,396 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37592869500319165, 'Total loss': 0.37592869500319165} | train loss {'Reaction outcome loss': 0.17337443860907134, 'Total loss': 0.17337443860907134}
2023-01-05 01:02:43,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:43,397 INFO:     Epoch: 77
2023-01-05 01:02:45,632 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41142585972944895, 'Total loss': 0.41142585972944895} | train loss {'Reaction outcome loss': 0.16691594178122163, 'Total loss': 0.16691594178122163}
2023-01-05 01:02:45,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:45,632 INFO:     Epoch: 78
2023-01-05 01:02:47,876 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41219219863414763, 'Total loss': 0.41219219863414763} | train loss {'Reaction outcome loss': 0.17049341966792342, 'Total loss': 0.17049341966792342}
2023-01-05 01:02:47,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:47,876 INFO:     Epoch: 79
2023-01-05 01:02:50,038 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4109952911734581, 'Total loss': 0.4109952911734581} | train loss {'Reaction outcome loss': 0.16523696891079745, 'Total loss': 0.16523696891079745}
2023-01-05 01:02:50,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:50,039 INFO:     Epoch: 80
2023-01-05 01:02:52,266 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.382783846060435, 'Total loss': 0.382783846060435} | train loss {'Reaction outcome loss': 0.166285539968755, 'Total loss': 0.166285539968755}
2023-01-05 01:02:52,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:52,266 INFO:     Epoch: 81
2023-01-05 01:02:54,484 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3974339207013448, 'Total loss': 0.3974339207013448} | train loss {'Reaction outcome loss': 0.1691753072086314, 'Total loss': 0.1691753072086314}
2023-01-05 01:02:54,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:54,485 INFO:     Epoch: 82
2023-01-05 01:02:56,675 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4078877617915471, 'Total loss': 0.4078877617915471} | train loss {'Reaction outcome loss': 0.17195127888609837, 'Total loss': 0.17195127888609837}
2023-01-05 01:02:56,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:56,676 INFO:     Epoch: 83
2023-01-05 01:02:58,927 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4145353724559148, 'Total loss': 0.4145353724559148} | train loss {'Reaction outcome loss': 0.16484199605209168, 'Total loss': 0.16484199605209168}
2023-01-05 01:02:58,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:02:58,927 INFO:     Epoch: 84
2023-01-05 01:03:01,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3938647319873174, 'Total loss': 0.3938647319873174} | train loss {'Reaction outcome loss': 0.16195017857694605, 'Total loss': 0.16195017857694605}
2023-01-05 01:03:01,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:01,145 INFO:     Epoch: 85
2023-01-05 01:03:03,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40671873092651367, 'Total loss': 0.40671873092651367} | train loss {'Reaction outcome loss': 0.1580051007089171, 'Total loss': 0.1580051007089171}
2023-01-05 01:03:03,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:03,361 INFO:     Epoch: 86
2023-01-05 01:03:05,573 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40562158487737177, 'Total loss': 0.40562158487737177} | train loss {'Reaction outcome loss': 0.15873088394325688, 'Total loss': 0.15873088394325688}
2023-01-05 01:03:05,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:05,573 INFO:     Epoch: 87
2023-01-05 01:03:07,797 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.405242320895195, 'Total loss': 0.405242320895195} | train loss {'Reaction outcome loss': 0.15744595210591372, 'Total loss': 0.15744595210591372}
2023-01-05 01:03:07,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:07,797 INFO:     Epoch: 88
2023-01-05 01:03:10,014 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4081982652346293, 'Total loss': 0.4081982652346293} | train loss {'Reaction outcome loss': 0.15859056451616224, 'Total loss': 0.15859056451616224}
2023-01-05 01:03:10,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:10,014 INFO:     Epoch: 89
2023-01-05 01:03:12,178 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4236030494173368, 'Total loss': 0.4236030494173368} | train loss {'Reaction outcome loss': 0.16413939181361756, 'Total loss': 0.16413939181361756}
2023-01-05 01:03:12,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:12,180 INFO:     Epoch: 90
2023-01-05 01:03:14,396 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40712028592824934, 'Total loss': 0.40712028592824934} | train loss {'Reaction outcome loss': 0.159685885521794, 'Total loss': 0.159685885521794}
2023-01-05 01:03:14,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:14,397 INFO:     Epoch: 91
2023-01-05 01:03:16,639 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38480838934580486, 'Total loss': 0.38480838934580486} | train loss {'Reaction outcome loss': 0.15672452172203274, 'Total loss': 0.15672452172203274}
2023-01-05 01:03:16,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:16,640 INFO:     Epoch: 92
2023-01-05 01:03:18,877 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43149716407060623, 'Total loss': 0.43149716407060623} | train loss {'Reaction outcome loss': 0.16437591882558525, 'Total loss': 0.16437591882558525}
2023-01-05 01:03:18,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:18,878 INFO:     Epoch: 93
2023-01-05 01:03:21,025 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4097688684860865, 'Total loss': 0.4097688684860865} | train loss {'Reaction outcome loss': 0.16307626042453857, 'Total loss': 0.16307626042453857}
2023-01-05 01:03:21,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:21,025 INFO:     Epoch: 94
2023-01-05 01:03:23,263 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4005271750191847, 'Total loss': 0.4005271750191847} | train loss {'Reaction outcome loss': 0.15562206086869196, 'Total loss': 0.15562206086869196}
2023-01-05 01:03:23,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:23,263 INFO:     Epoch: 95
2023-01-05 01:03:25,451 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41423509319623314, 'Total loss': 0.41423509319623314} | train loss {'Reaction outcome loss': 0.15317369737648778, 'Total loss': 0.15317369737648778}
2023-01-05 01:03:25,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:25,451 INFO:     Epoch: 96
2023-01-05 01:03:27,686 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42196263174215953, 'Total loss': 0.42196263174215953} | train loss {'Reaction outcome loss': 0.16328912923268865, 'Total loss': 0.16328912923268865}
2023-01-05 01:03:27,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:27,686 INFO:     Epoch: 97
2023-01-05 01:03:29,885 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4109088400999705, 'Total loss': 0.4109088400999705} | train loss {'Reaction outcome loss': 0.15930178602919473, 'Total loss': 0.15930178602919473}
2023-01-05 01:03:29,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:29,885 INFO:     Epoch: 98
2023-01-05 01:03:32,127 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3943972029684422, 'Total loss': 0.3943972029684422} | train loss {'Reaction outcome loss': 0.1579356639268706, 'Total loss': 0.1579356639268706}
2023-01-05 01:03:32,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:32,128 INFO:     Epoch: 99
2023-01-05 01:03:34,374 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.390638130903244, 'Total loss': 0.390638130903244} | train loss {'Reaction outcome loss': 0.15250164131977234, 'Total loss': 0.15250164131977234}
2023-01-05 01:03:34,374 INFO:     Best model found after epoch 17 of 100.
2023-01-05 01:03:34,374 INFO:   Done with stage: TRAINING
2023-01-05 01:03:34,374 INFO:   Starting stage: EVALUATION
2023-01-05 01:03:34,516 INFO:   Done with stage: EVALUATION
2023-01-05 01:03:34,516 INFO:   Leaving out SEQ value Fold_3
2023-01-05 01:03:34,529 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 01:03:34,529 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:03:35,172 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:03:35,172 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:03:35,242 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:03:35,242 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:03:35,242 INFO:     No hyperparam tuning for this model
2023-01-05 01:03:35,242 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:03:35,242 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:03:35,243 INFO:     None feature selector for col prot
2023-01-05 01:03:35,243 INFO:     None feature selector for col prot
2023-01-05 01:03:35,243 INFO:     None feature selector for col prot
2023-01-05 01:03:35,243 INFO:     None feature selector for col chem
2023-01-05 01:03:35,244 INFO:     None feature selector for col chem
2023-01-05 01:03:35,244 INFO:     None feature selector for col chem
2023-01-05 01:03:35,244 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:03:35,244 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:03:35,245 INFO:     Number of params in model 72931
2023-01-05 01:03:35,248 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:03:35,249 INFO:   Starting stage: TRAINING
2023-01-05 01:03:35,309 INFO:     Val loss before train {'Reaction outcome loss': 0.962587316830953, 'Total loss': 0.962587316830953}
2023-01-05 01:03:35,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:35,309 INFO:     Epoch: 0
2023-01-05 01:03:37,518 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7755603949228923, 'Total loss': 0.7755603949228923} | train loss {'Reaction outcome loss': 0.9731888725207403, 'Total loss': 0.9731888725207403}
2023-01-05 01:03:37,519 INFO:     Found new best model at epoch 0
2023-01-05 01:03:37,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:37,520 INFO:     Epoch: 1
2023-01-05 01:03:39,759 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4996975302696228, 'Total loss': 0.4996975302696228} | train loss {'Reaction outcome loss': 0.6647811099723145, 'Total loss': 0.6647811099723145}
2023-01-05 01:03:39,759 INFO:     Found new best model at epoch 1
2023-01-05 01:03:39,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:39,760 INFO:     Epoch: 2
2023-01-05 01:03:41,899 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4854931354522705, 'Total loss': 0.4854931354522705} | train loss {'Reaction outcome loss': 0.5437646616837044, 'Total loss': 0.5437646616837044}
2023-01-05 01:03:41,907 INFO:     Found new best model at epoch 2
2023-01-05 01:03:41,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:41,908 INFO:     Epoch: 3
2023-01-05 01:03:44,129 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4730313887198766, 'Total loss': 0.4730313887198766} | train loss {'Reaction outcome loss': 0.5008480860254704, 'Total loss': 0.5008480860254704}
2023-01-05 01:03:44,129 INFO:     Found new best model at epoch 3
2023-01-05 01:03:44,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:44,131 INFO:     Epoch: 4
2023-01-05 01:03:46,328 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4189397762219111, 'Total loss': 0.4189397762219111} | train loss {'Reaction outcome loss': 0.4657988538453867, 'Total loss': 0.4657988538453867}
2023-01-05 01:03:46,328 INFO:     Found new best model at epoch 4
2023-01-05 01:03:46,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:46,330 INFO:     Epoch: 5
2023-01-05 01:03:48,556 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40745130081971487, 'Total loss': 0.40745130081971487} | train loss {'Reaction outcome loss': 0.44603170203420267, 'Total loss': 0.44603170203420267}
2023-01-05 01:03:48,557 INFO:     Found new best model at epoch 5
2023-01-05 01:03:48,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:48,559 INFO:     Epoch: 6
2023-01-05 01:03:50,744 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4342985769112905, 'Total loss': 0.4342985769112905} | train loss {'Reaction outcome loss': 0.4300838898826431, 'Total loss': 0.4300838898826431}
2023-01-05 01:03:50,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:50,745 INFO:     Epoch: 7
2023-01-05 01:03:52,968 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39010854562123615, 'Total loss': 0.39010854562123615} | train loss {'Reaction outcome loss': 0.4112151672060673, 'Total loss': 0.4112151672060673}
2023-01-05 01:03:52,968 INFO:     Found new best model at epoch 7
2023-01-05 01:03:52,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:52,970 INFO:     Epoch: 8
2023-01-05 01:03:55,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40804266929626465, 'Total loss': 0.40804266929626465} | train loss {'Reaction outcome loss': 0.3985706291164889, 'Total loss': 0.3985706291164889}
2023-01-05 01:03:55,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:55,104 INFO:     Epoch: 9
2023-01-05 01:03:57,349 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39665358811616896, 'Total loss': 0.39665358811616896} | train loss {'Reaction outcome loss': 0.38148962340621284, 'Total loss': 0.38148962340621284}
2023-01-05 01:03:57,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:57,349 INFO:     Epoch: 10
2023-01-05 01:03:59,554 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42862025101979573, 'Total loss': 0.42862025101979573} | train loss {'Reaction outcome loss': 0.3729478174568096, 'Total loss': 0.3729478174568096}
2023-01-05 01:03:59,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:03:59,554 INFO:     Epoch: 11
2023-01-05 01:04:01,731 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40695289671421053, 'Total loss': 0.40695289671421053} | train loss {'Reaction outcome loss': 0.3667063273953431, 'Total loss': 0.3667063273953431}
2023-01-05 01:04:01,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:01,732 INFO:     Epoch: 12
2023-01-05 01:04:03,932 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40245798925558723, 'Total loss': 0.40245798925558723} | train loss {'Reaction outcome loss': 0.3558382238278459, 'Total loss': 0.3558382238278459}
2023-01-05 01:04:03,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:03,933 INFO:     Epoch: 13
2023-01-05 01:04:06,128 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4321359395980835, 'Total loss': 0.4321359395980835} | train loss {'Reaction outcome loss': 0.345141731994056, 'Total loss': 0.345141731994056}
2023-01-05 01:04:06,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:06,128 INFO:     Epoch: 14
2023-01-05 01:04:08,329 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43431408405303956, 'Total loss': 0.43431408405303956} | train loss {'Reaction outcome loss': 0.338605375366879, 'Total loss': 0.338605375366879}
2023-01-05 01:04:08,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:08,329 INFO:     Epoch: 15
2023-01-05 01:04:10,534 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4377326409022013, 'Total loss': 0.4377326409022013} | train loss {'Reaction outcome loss': 0.3328724833198519, 'Total loss': 0.3328724833198519}
2023-01-05 01:04:10,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:10,534 INFO:     Epoch: 16
2023-01-05 01:04:12,755 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4455880383650462, 'Total loss': 0.4455880383650462} | train loss {'Reaction outcome loss': 0.32850124883455234, 'Total loss': 0.32850124883455234}
2023-01-05 01:04:12,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:12,755 INFO:     Epoch: 17
2023-01-05 01:04:15,012 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.426810210943222, 'Total loss': 0.426810210943222} | train loss {'Reaction outcome loss': 0.3195864561221975, 'Total loss': 0.3195864561221975}
2023-01-05 01:04:15,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:15,012 INFO:     Epoch: 18
2023-01-05 01:04:17,315 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40854360461235045, 'Total loss': 0.40854360461235045} | train loss {'Reaction outcome loss': 0.3092887988348147, 'Total loss': 0.3092887988348147}
2023-01-05 01:04:17,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:17,316 INFO:     Epoch: 19
2023-01-05 01:04:19,619 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40544964869817096, 'Total loss': 0.40544964869817096} | train loss {'Reaction outcome loss': 0.3060097790002523, 'Total loss': 0.3060097790002523}
2023-01-05 01:04:19,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:19,620 INFO:     Epoch: 20
2023-01-05 01:04:21,908 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40860283772150674, 'Total loss': 0.40860283772150674} | train loss {'Reaction outcome loss': 0.2975715236540461, 'Total loss': 0.2975715236540461}
2023-01-05 01:04:21,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:21,908 INFO:     Epoch: 21
2023-01-05 01:04:24,184 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42375790774822236, 'Total loss': 0.42375790774822236} | train loss {'Reaction outcome loss': 0.29659297838534193, 'Total loss': 0.29659297838534193}
2023-01-05 01:04:24,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:24,185 INFO:     Epoch: 22
2023-01-05 01:04:26,331 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41759240031242373, 'Total loss': 0.41759240031242373} | train loss {'Reaction outcome loss': 0.2933524725583447, 'Total loss': 0.2933524725583447}
2023-01-05 01:04:26,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:26,331 INFO:     Epoch: 23
2023-01-05 01:04:28,539 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39557435512542727, 'Total loss': 0.39557435512542727} | train loss {'Reaction outcome loss': 0.285972184382188, 'Total loss': 0.285972184382188}
2023-01-05 01:04:28,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:28,540 INFO:     Epoch: 24
2023-01-05 01:04:30,772 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4023208477223913, 'Total loss': 0.4023208477223913} | train loss {'Reaction outcome loss': 0.2832697898067616, 'Total loss': 0.2832697898067616}
2023-01-05 01:04:30,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:30,772 INFO:     Epoch: 25
2023-01-05 01:04:32,965 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42874212662378947, 'Total loss': 0.42874212662378947} | train loss {'Reaction outcome loss': 0.27790666711363166, 'Total loss': 0.27790666711363166}
2023-01-05 01:04:32,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:32,965 INFO:     Epoch: 26
2023-01-05 01:04:35,109 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43353155652681985, 'Total loss': 0.43353155652681985} | train loss {'Reaction outcome loss': 0.2692435754005944, 'Total loss': 0.2692435754005944}
2023-01-05 01:04:35,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:35,110 INFO:     Epoch: 27
2023-01-05 01:04:37,309 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.424854967991511, 'Total loss': 0.424854967991511} | train loss {'Reaction outcome loss': 0.27123710925898925, 'Total loss': 0.27123710925898925}
2023-01-05 01:04:37,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:37,310 INFO:     Epoch: 28
2023-01-05 01:04:39,516 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4287635346253713, 'Total loss': 0.4287635346253713} | train loss {'Reaction outcome loss': 0.2638973650068809, 'Total loss': 0.2638973650068809}
2023-01-05 01:04:39,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:39,516 INFO:     Epoch: 29
2023-01-05 01:04:41,741 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40667019759615264, 'Total loss': 0.40667019759615264} | train loss {'Reaction outcome loss': 0.2591449777278435, 'Total loss': 0.2591449777278435}
2023-01-05 01:04:41,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:41,741 INFO:     Epoch: 30
2023-01-05 01:04:43,953 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42769117703040443, 'Total loss': 0.42769117703040443} | train loss {'Reaction outcome loss': 0.25772658966126893, 'Total loss': 0.25772658966126893}
2023-01-05 01:04:43,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:43,953 INFO:     Epoch: 31
2023-01-05 01:04:46,151 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4417009174823761, 'Total loss': 0.4417009174823761} | train loss {'Reaction outcome loss': 0.2539878218629203, 'Total loss': 0.2539878218629203}
2023-01-05 01:04:46,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:46,152 INFO:     Epoch: 32
2023-01-05 01:04:48,293 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4561261316140493, 'Total loss': 0.4561261316140493} | train loss {'Reaction outcome loss': 0.2491308825274745, 'Total loss': 0.2491308825274745}
2023-01-05 01:04:48,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:48,294 INFO:     Epoch: 33
2023-01-05 01:04:50,514 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42236248354117073, 'Total loss': 0.42236248354117073} | train loss {'Reaction outcome loss': 0.24611734746249167, 'Total loss': 0.24611734746249167}
2023-01-05 01:04:50,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:50,515 INFO:     Epoch: 34
2023-01-05 01:04:52,655 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42990876932938893, 'Total loss': 0.42990876932938893} | train loss {'Reaction outcome loss': 0.23978118702339438, 'Total loss': 0.23978118702339438}
2023-01-05 01:04:52,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:52,655 INFO:     Epoch: 35
2023-01-05 01:04:54,834 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43117724657058715, 'Total loss': 0.43117724657058715} | train loss {'Reaction outcome loss': 0.24063462124038965, 'Total loss': 0.24063462124038965}
2023-01-05 01:04:54,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:54,835 INFO:     Epoch: 36
2023-01-05 01:04:56,999 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4007371837894122, 'Total loss': 0.4007371837894122} | train loss {'Reaction outcome loss': 0.241929690841408, 'Total loss': 0.241929690841408}
2023-01-05 01:04:56,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:56,999 INFO:     Epoch: 37
2023-01-05 01:04:59,173 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4593589613835017, 'Total loss': 0.4593589613835017} | train loss {'Reaction outcome loss': 0.23671690750553276, 'Total loss': 0.23671690750553276}
2023-01-05 01:04:59,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:04:59,174 INFO:     Epoch: 38
2023-01-05 01:05:01,393 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4300272534290949, 'Total loss': 0.4300272534290949} | train loss {'Reaction outcome loss': 0.234857843165378, 'Total loss': 0.234857843165378}
2023-01-05 01:05:01,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:01,394 INFO:     Epoch: 39
2023-01-05 01:05:03,599 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40743931122124194, 'Total loss': 0.40743931122124194} | train loss {'Reaction outcome loss': 0.2334671460173942, 'Total loss': 0.2334671460173942}
2023-01-05 01:05:03,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:03,599 INFO:     Epoch: 40
2023-01-05 01:05:05,816 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40531457861264547, 'Total loss': 0.40531457861264547} | train loss {'Reaction outcome loss': 0.22916215830124342, 'Total loss': 0.22916215830124342}
2023-01-05 01:05:05,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:05,816 INFO:     Epoch: 41
2023-01-05 01:05:08,046 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4350564330816269, 'Total loss': 0.4350564330816269} | train loss {'Reaction outcome loss': 0.2297414287569977, 'Total loss': 0.2297414287569977}
2023-01-05 01:05:08,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:08,046 INFO:     Epoch: 42
2023-01-05 01:05:10,267 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4341972192128499, 'Total loss': 0.4341972192128499} | train loss {'Reaction outcome loss': 0.22236787992437462, 'Total loss': 0.22236787992437462}
2023-01-05 01:05:10,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:10,268 INFO:     Epoch: 43
2023-01-05 01:05:12,435 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.426028381784757, 'Total loss': 0.426028381784757} | train loss {'Reaction outcome loss': 0.22462168657272072, 'Total loss': 0.22462168657272072}
2023-01-05 01:05:12,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:12,435 INFO:     Epoch: 44
2023-01-05 01:05:14,664 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42717677454153696, 'Total loss': 0.42717677454153696} | train loss {'Reaction outcome loss': 0.22587380873852994, 'Total loss': 0.22587380873852994}
2023-01-05 01:05:14,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:14,665 INFO:     Epoch: 45
2023-01-05 01:05:16,886 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.440479306379954, 'Total loss': 0.440479306379954} | train loss {'Reaction outcome loss': 0.22329166966862293, 'Total loss': 0.22329166966862293}
2023-01-05 01:05:16,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:16,887 INFO:     Epoch: 46
2023-01-05 01:05:19,031 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4313821365435918, 'Total loss': 0.4313821365435918} | train loss {'Reaction outcome loss': 0.2173307606807122, 'Total loss': 0.2173307606807122}
2023-01-05 01:05:19,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:19,032 INFO:     Epoch: 47
2023-01-05 01:05:21,186 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43956137796243033, 'Total loss': 0.43956137796243033} | train loss {'Reaction outcome loss': 0.21245168117403765, 'Total loss': 0.21245168117403765}
2023-01-05 01:05:21,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:21,187 INFO:     Epoch: 48
2023-01-05 01:05:23,417 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4200448969999949, 'Total loss': 0.4200448969999949} | train loss {'Reaction outcome loss': 0.219184797942884, 'Total loss': 0.219184797942884}
2023-01-05 01:05:23,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:23,418 INFO:     Epoch: 49
2023-01-05 01:05:25,630 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42642789979775747, 'Total loss': 0.42642789979775747} | train loss {'Reaction outcome loss': 0.21309345346217082, 'Total loss': 0.21309345346217082}
2023-01-05 01:05:25,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:25,631 INFO:     Epoch: 50
2023-01-05 01:05:27,875 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4244426488876343, 'Total loss': 0.4244426488876343} | train loss {'Reaction outcome loss': 0.21090978637146643, 'Total loss': 0.21090978637146643}
2023-01-05 01:05:27,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:27,876 INFO:     Epoch: 51
2023-01-05 01:05:30,100 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40737958401441576, 'Total loss': 0.40737958401441576} | train loss {'Reaction outcome loss': 0.21341561492286867, 'Total loss': 0.21341561492286867}
2023-01-05 01:05:30,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:30,102 INFO:     Epoch: 52
2023-01-05 01:05:32,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4005044996738434, 'Total loss': 0.4005044996738434} | train loss {'Reaction outcome loss': 0.2079839571191496, 'Total loss': 0.2079839571191496}
2023-01-05 01:05:32,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:32,319 INFO:     Epoch: 53
2023-01-05 01:05:34,500 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43172709743181864, 'Total loss': 0.43172709743181864} | train loss {'Reaction outcome loss': 0.21017719658207654, 'Total loss': 0.21017719658207654}
2023-01-05 01:05:34,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:34,500 INFO:     Epoch: 54
2023-01-05 01:05:36,661 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45695826411247253, 'Total loss': 0.45695826411247253} | train loss {'Reaction outcome loss': 0.200026786877627, 'Total loss': 0.200026786877627}
2023-01-05 01:05:36,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:36,662 INFO:     Epoch: 55
2023-01-05 01:05:38,860 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43903042872746784, 'Total loss': 0.43903042872746784} | train loss {'Reaction outcome loss': 0.20554944148266707, 'Total loss': 0.20554944148266707}
2023-01-05 01:05:38,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:38,861 INFO:     Epoch: 56
2023-01-05 01:05:41,073 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45781411826610563, 'Total loss': 0.45781411826610563} | train loss {'Reaction outcome loss': 0.20484269679875383, 'Total loss': 0.20484269679875383}
2023-01-05 01:05:41,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:41,073 INFO:     Epoch: 57
2023-01-05 01:05:43,264 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4161145100990931, 'Total loss': 0.4161145100990931} | train loss {'Reaction outcome loss': 0.20201168381250822, 'Total loss': 0.20201168381250822}
2023-01-05 01:05:43,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:43,264 INFO:     Epoch: 58
2023-01-05 01:05:45,407 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4379470775524775, 'Total loss': 0.4379470775524775} | train loss {'Reaction outcome loss': 0.20254683809102456, 'Total loss': 0.20254683809102456}
2023-01-05 01:05:45,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:45,407 INFO:     Epoch: 59
2023-01-05 01:05:47,564 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45186888178189594, 'Total loss': 0.45186888178189594} | train loss {'Reaction outcome loss': 0.19805546594449344, 'Total loss': 0.19805546594449344}
2023-01-05 01:05:47,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:47,564 INFO:     Epoch: 60
2023-01-05 01:05:49,762 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43681101004282635, 'Total loss': 0.43681101004282635} | train loss {'Reaction outcome loss': 0.19811584156146445, 'Total loss': 0.19811584156146445}
2023-01-05 01:05:49,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:49,763 INFO:     Epoch: 61
2023-01-05 01:05:51,981 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44371073246002196, 'Total loss': 0.44371073246002196} | train loss {'Reaction outcome loss': 0.19812862202866283, 'Total loss': 0.19812862202866283}
2023-01-05 01:05:51,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:51,981 INFO:     Epoch: 62
2023-01-05 01:05:54,222 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4288035035133362, 'Total loss': 0.4288035035133362} | train loss {'Reaction outcome loss': 0.19853170272372253, 'Total loss': 0.19853170272372253}
2023-01-05 01:05:54,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:54,223 INFO:     Epoch: 63
2023-01-05 01:05:56,403 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3991615389784177, 'Total loss': 0.3991615389784177} | train loss {'Reaction outcome loss': 0.1969106718659019, 'Total loss': 0.1969106718659019}
2023-01-05 01:05:56,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:56,404 INFO:     Epoch: 64
2023-01-05 01:05:58,583 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45077051023642223, 'Total loss': 0.45077051023642223} | train loss {'Reaction outcome loss': 0.1977872668148015, 'Total loss': 0.1977872668148015}
2023-01-05 01:05:58,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:05:58,583 INFO:     Epoch: 65
2023-01-05 01:06:00,806 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4499716520309448, 'Total loss': 0.4499716520309448} | train loss {'Reaction outcome loss': 0.19673337394050955, 'Total loss': 0.19673337394050955}
2023-01-05 01:06:00,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:00,807 INFO:     Epoch: 66
2023-01-05 01:06:03,008 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40448429534832636, 'Total loss': 0.40448429534832636} | train loss {'Reaction outcome loss': 0.19379377714272983, 'Total loss': 0.19379377714272983}
2023-01-05 01:06:03,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:03,008 INFO:     Epoch: 67
2023-01-05 01:06:05,240 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3883931565408905, 'Total loss': 0.3883931565408905} | train loss {'Reaction outcome loss': 0.19330050520967323, 'Total loss': 0.19330050520967323}
2023-01-05 01:06:05,240 INFO:     Found new best model at epoch 67
2023-01-05 01:06:05,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:05,241 INFO:     Epoch: 68
2023-01-05 01:06:07,453 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4019035855929057, 'Total loss': 0.4019035855929057} | train loss {'Reaction outcome loss': 0.1905974948321616, 'Total loss': 0.1905974948321616}
2023-01-05 01:06:07,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:07,454 INFO:     Epoch: 69
2023-01-05 01:06:09,699 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44273979564507804, 'Total loss': 0.44273979564507804} | train loss {'Reaction outcome loss': 0.19269065302711375, 'Total loss': 0.19269065302711375}
2023-01-05 01:06:09,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:09,699 INFO:     Epoch: 70
2023-01-05 01:06:11,888 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4283630132675171, 'Total loss': 0.4283630132675171} | train loss {'Reaction outcome loss': 0.18849355341259377, 'Total loss': 0.18849355341259377}
2023-01-05 01:06:11,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:11,888 INFO:     Epoch: 71
2023-01-05 01:06:14,060 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49039524495601655, 'Total loss': 0.49039524495601655} | train loss {'Reaction outcome loss': 0.18351454372456358, 'Total loss': 0.18351454372456358}
2023-01-05 01:06:14,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:14,060 INFO:     Epoch: 72
2023-01-05 01:06:16,090 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4229982207218806, 'Total loss': 0.4229982207218806} | train loss {'Reaction outcome loss': 0.18497091851149422, 'Total loss': 0.18497091851149422}
2023-01-05 01:06:16,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:16,091 INFO:     Epoch: 73
2023-01-05 01:06:18,294 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4164560168981552, 'Total loss': 0.4164560168981552} | train loss {'Reaction outcome loss': 0.1859574720396527, 'Total loss': 0.1859574720396527}
2023-01-05 01:06:18,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:18,294 INFO:     Epoch: 74
2023-01-05 01:06:20,484 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41478720009326936, 'Total loss': 0.41478720009326936} | train loss {'Reaction outcome loss': 0.1889923191168806, 'Total loss': 0.1889923191168806}
2023-01-05 01:06:20,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:20,485 INFO:     Epoch: 75
2023-01-05 01:06:22,649 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4371643394231796, 'Total loss': 0.4371643394231796} | train loss {'Reaction outcome loss': 0.18229287174520092, 'Total loss': 0.18229287174520092}
2023-01-05 01:06:22,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:22,649 INFO:     Epoch: 76
2023-01-05 01:06:24,803 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4614498650034269, 'Total loss': 0.4614498650034269} | train loss {'Reaction outcome loss': 0.18010562266676855, 'Total loss': 0.18010562266676855}
2023-01-05 01:06:24,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:24,803 INFO:     Epoch: 77
2023-01-05 01:06:27,029 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46623773376146954, 'Total loss': 0.46623773376146954} | train loss {'Reaction outcome loss': 0.18119901446830278, 'Total loss': 0.18119901446830278}
2023-01-05 01:06:27,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:27,029 INFO:     Epoch: 78
2023-01-05 01:06:29,227 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4409242401520411, 'Total loss': 0.4409242401520411} | train loss {'Reaction outcome loss': 0.18227579993206067, 'Total loss': 0.18227579993206067}
2023-01-05 01:06:29,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:29,228 INFO:     Epoch: 79
2023-01-05 01:06:31,447 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44014623314142226, 'Total loss': 0.44014623314142226} | train loss {'Reaction outcome loss': 0.18010085962385267, 'Total loss': 0.18010085962385267}
2023-01-05 01:06:31,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:31,448 INFO:     Epoch: 80
2023-01-05 01:06:33,670 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46626727481683095, 'Total loss': 0.46626727481683095} | train loss {'Reaction outcome loss': 0.17581650645953123, 'Total loss': 0.17581650645953123}
2023-01-05 01:06:33,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:33,670 INFO:     Epoch: 81
2023-01-05 01:06:35,845 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47136616508165996, 'Total loss': 0.47136616508165996} | train loss {'Reaction outcome loss': 0.17328054344984312, 'Total loss': 0.17328054344984312}
2023-01-05 01:06:35,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:35,846 INFO:     Epoch: 82
2023-01-05 01:06:38,087 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4351185252269109, 'Total loss': 0.4351185252269109} | train loss {'Reaction outcome loss': 0.17591246143461037, 'Total loss': 0.17591246143461037}
2023-01-05 01:06:38,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:38,088 INFO:     Epoch: 83
2023-01-05 01:06:40,205 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4434015249212583, 'Total loss': 0.4434015249212583} | train loss {'Reaction outcome loss': 0.17398495224369315, 'Total loss': 0.17398495224369315}
2023-01-05 01:06:40,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:40,205 INFO:     Epoch: 84
2023-01-05 01:06:42,390 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43924905558427174, 'Total loss': 0.43924905558427174} | train loss {'Reaction outcome loss': 0.1770808237021441, 'Total loss': 0.1770808237021441}
2023-01-05 01:06:42,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:42,390 INFO:     Epoch: 85
2023-01-05 01:06:44,613 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4144799123207728, 'Total loss': 0.4144799123207728} | train loss {'Reaction outcome loss': 0.1866301573410412, 'Total loss': 0.1866301573410412}
2023-01-05 01:06:44,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:44,613 INFO:     Epoch: 86
2023-01-05 01:06:46,831 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44437166253725685, 'Total loss': 0.44437166253725685} | train loss {'Reaction outcome loss': 0.17106278334154096, 'Total loss': 0.17106278334154096}
2023-01-05 01:06:46,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:46,832 INFO:     Epoch: 87
2023-01-05 01:06:49,023 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.407239298025767, 'Total loss': 0.407239298025767} | train loss {'Reaction outcome loss': 0.17021633138122794, 'Total loss': 0.17021633138122794}
2023-01-05 01:06:49,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:49,023 INFO:     Epoch: 88
2023-01-05 01:06:51,184 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4125483016173045, 'Total loss': 0.4125483016173045} | train loss {'Reaction outcome loss': 0.16995038559844533, 'Total loss': 0.16995038559844533}
2023-01-05 01:06:51,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:51,185 INFO:     Epoch: 89
2023-01-05 01:06:53,390 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47480053901672364, 'Total loss': 0.47480053901672364} | train loss {'Reaction outcome loss': 0.16985981410962867, 'Total loss': 0.16985981410962867}
2023-01-05 01:06:53,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:53,390 INFO:     Epoch: 90
2023-01-05 01:06:55,620 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43931909557431936, 'Total loss': 0.43931909557431936} | train loss {'Reaction outcome loss': 0.17099297660379073, 'Total loss': 0.17099297660379073}
2023-01-05 01:06:55,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:55,621 INFO:     Epoch: 91
2023-01-05 01:06:57,830 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40608204404513043, 'Total loss': 0.40608204404513043} | train loss {'Reaction outcome loss': 0.16662883745922602, 'Total loss': 0.16662883745922602}
2023-01-05 01:06:57,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:06:57,831 INFO:     Epoch: 92
2023-01-05 01:07:00,070 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43689959247907, 'Total loss': 0.43689959247907} | train loss {'Reaction outcome loss': 0.16837302874091453, 'Total loss': 0.16837302874091453}
2023-01-05 01:07:00,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:00,070 INFO:     Epoch: 93
2023-01-05 01:07:02,262 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4463254342476527, 'Total loss': 0.4463254342476527} | train loss {'Reaction outcome loss': 0.17187987193089974, 'Total loss': 0.17187987193089974}
2023-01-05 01:07:02,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:02,264 INFO:     Epoch: 94
2023-01-05 01:07:04,503 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4560587878028552, 'Total loss': 0.4560587878028552} | train loss {'Reaction outcome loss': 0.16907872857641934, 'Total loss': 0.16907872857641934}
2023-01-05 01:07:04,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:04,504 INFO:     Epoch: 95
2023-01-05 01:07:06,741 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4598109672466914, 'Total loss': 0.4598109672466914} | train loss {'Reaction outcome loss': 0.16162266024224625, 'Total loss': 0.16162266024224625}
2023-01-05 01:07:06,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:06,741 INFO:     Epoch: 96
2023-01-05 01:07:08,984 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43988360663255055, 'Total loss': 0.43988360663255055} | train loss {'Reaction outcome loss': 0.16513740404034818, 'Total loss': 0.16513740404034818}
2023-01-05 01:07:08,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:08,985 INFO:     Epoch: 97
2023-01-05 01:07:11,197 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48613699823617934, 'Total loss': 0.48613699823617934} | train loss {'Reaction outcome loss': 0.16504275352837375, 'Total loss': 0.16504275352837375}
2023-01-05 01:07:11,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:11,197 INFO:     Epoch: 98
2023-01-05 01:07:13,426 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48371928731600444, 'Total loss': 0.48371928731600444} | train loss {'Reaction outcome loss': 0.16438265417398878, 'Total loss': 0.16438265417398878}
2023-01-05 01:07:13,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:13,427 INFO:     Epoch: 99
2023-01-05 01:07:15,666 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4287659754355749, 'Total loss': 0.4287659754355749} | train loss {'Reaction outcome loss': 0.16114646262547253, 'Total loss': 0.16114646262547253}
2023-01-05 01:07:15,666 INFO:     Best model found after epoch 68 of 100.
2023-01-05 01:07:15,667 INFO:   Done with stage: TRAINING
2023-01-05 01:07:15,667 INFO:   Starting stage: EVALUATION
2023-01-05 01:07:15,815 INFO:   Done with stage: EVALUATION
2023-01-05 01:07:15,815 INFO:   Leaving out SEQ value Fold_4
2023-01-05 01:07:15,828 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 01:07:15,828 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:07:16,486 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:07:16,486 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:07:16,555 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:07:16,555 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:07:16,556 INFO:     No hyperparam tuning for this model
2023-01-05 01:07:16,556 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:07:16,556 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:07:16,556 INFO:     None feature selector for col prot
2023-01-05 01:07:16,557 INFO:     None feature selector for col prot
2023-01-05 01:07:16,557 INFO:     None feature selector for col prot
2023-01-05 01:07:16,557 INFO:     None feature selector for col chem
2023-01-05 01:07:16,557 INFO:     None feature selector for col chem
2023-01-05 01:07:16,557 INFO:     None feature selector for col chem
2023-01-05 01:07:16,557 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:07:16,557 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:07:16,559 INFO:     Number of params in model 72931
2023-01-05 01:07:16,562 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:07:16,562 INFO:   Starting stage: TRAINING
2023-01-05 01:07:16,621 INFO:     Val loss before train {'Reaction outcome loss': 1.0462920308113097, 'Total loss': 1.0462920308113097}
2023-01-05 01:07:16,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:16,622 INFO:     Epoch: 0
2023-01-05 01:07:18,893 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7982032974561055, 'Total loss': 0.7982032974561055} | train loss {'Reaction outcome loss': 0.9493851275435423, 'Total loss': 0.9493851275435423}
2023-01-05 01:07:18,893 INFO:     Found new best model at epoch 0
2023-01-05 01:07:18,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:18,894 INFO:     Epoch: 1
2023-01-05 01:07:21,164 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6221006790796916, 'Total loss': 0.6221006790796916} | train loss {'Reaction outcome loss': 0.7052460937401017, 'Total loss': 0.7052460937401017}
2023-01-05 01:07:21,164 INFO:     Found new best model at epoch 1
2023-01-05 01:07:21,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:21,166 INFO:     Epoch: 2
2023-01-05 01:07:23,496 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5464650412400563, 'Total loss': 0.5464650412400563} | train loss {'Reaction outcome loss': 0.5779892207267913, 'Total loss': 0.5779892207267913}
2023-01-05 01:07:23,497 INFO:     Found new best model at epoch 2
2023-01-05 01:07:23,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:23,498 INFO:     Epoch: 3
2023-01-05 01:07:25,752 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5357632597287496, 'Total loss': 0.5357632597287496} | train loss {'Reaction outcome loss': 0.5122855537527304, 'Total loss': 0.5122855537527304}
2023-01-05 01:07:25,753 INFO:     Found new best model at epoch 3
2023-01-05 01:07:25,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:25,754 INFO:     Epoch: 4
2023-01-05 01:07:28,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5034879008928935, 'Total loss': 0.5034879008928935} | train loss {'Reaction outcome loss': 0.48318528983782344, 'Total loss': 0.48318528983782344}
2023-01-05 01:07:28,001 INFO:     Found new best model at epoch 4
2023-01-05 01:07:28,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:28,003 INFO:     Epoch: 5
2023-01-05 01:07:30,277 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4961583177248637, 'Total loss': 0.4961583177248637} | train loss {'Reaction outcome loss': 0.4605578231736211, 'Total loss': 0.4605578231736211}
2023-01-05 01:07:30,277 INFO:     Found new best model at epoch 5
2023-01-05 01:07:30,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:30,278 INFO:     Epoch: 6
2023-01-05 01:07:32,462 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4867094695568085, 'Total loss': 0.4867094695568085} | train loss {'Reaction outcome loss': 0.44190522721743325, 'Total loss': 0.44190522721743325}
2023-01-05 01:07:32,463 INFO:     Found new best model at epoch 6
2023-01-05 01:07:32,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:32,464 INFO:     Epoch: 7
2023-01-05 01:07:34,733 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5035965412855148, 'Total loss': 0.5035965412855148} | train loss {'Reaction outcome loss': 0.42756418937595314, 'Total loss': 0.42756418937595314}
2023-01-05 01:07:34,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:34,733 INFO:     Epoch: 8
2023-01-05 01:07:37,010 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4871307909488678, 'Total loss': 0.4871307909488678} | train loss {'Reaction outcome loss': 0.41713699077118177, 'Total loss': 0.41713699077118177}
2023-01-05 01:07:37,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:37,010 INFO:     Epoch: 9
2023-01-05 01:07:39,244 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4579109768072764, 'Total loss': 0.4579109768072764} | train loss {'Reaction outcome loss': 0.40312173088427483, 'Total loss': 0.40312173088427483}
2023-01-05 01:07:39,245 INFO:     Found new best model at epoch 9
2023-01-05 01:07:39,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:39,247 INFO:     Epoch: 10
2023-01-05 01:07:41,490 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4638164947430293, 'Total loss': 0.4638164947430293} | train loss {'Reaction outcome loss': 0.39036540502836986, 'Total loss': 0.39036540502836986}
2023-01-05 01:07:41,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:41,490 INFO:     Epoch: 11
2023-01-05 01:07:43,764 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46982743342717487, 'Total loss': 0.46982743342717487} | train loss {'Reaction outcome loss': 0.3821212536914254, 'Total loss': 0.3821212536914254}
2023-01-05 01:07:43,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:43,764 INFO:     Epoch: 12
2023-01-05 01:07:45,987 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45575200219949086, 'Total loss': 0.45575200219949086} | train loss {'Reaction outcome loss': 0.369804119294516, 'Total loss': 0.369804119294516}
2023-01-05 01:07:45,987 INFO:     Found new best model at epoch 12
2023-01-05 01:07:45,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:45,989 INFO:     Epoch: 13
2023-01-05 01:07:48,259 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4397864123185476, 'Total loss': 0.4397864123185476} | train loss {'Reaction outcome loss': 0.3629879148589575, 'Total loss': 0.3629879148589575}
2023-01-05 01:07:48,259 INFO:     Found new best model at epoch 13
2023-01-05 01:07:48,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:48,260 INFO:     Epoch: 14
2023-01-05 01:07:50,538 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.444595139225324, 'Total loss': 0.444595139225324} | train loss {'Reaction outcome loss': 0.35092168217961967, 'Total loss': 0.35092168217961967}
2023-01-05 01:07:50,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:50,538 INFO:     Epoch: 15
2023-01-05 01:07:52,762 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44552307228247323, 'Total loss': 0.44552307228247323} | train loss {'Reaction outcome loss': 0.34541601894779755, 'Total loss': 0.34541601894779755}
2023-01-05 01:07:52,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:52,763 INFO:     Epoch: 16
2023-01-05 01:07:55,022 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4480427319804827, 'Total loss': 0.4480427319804827} | train loss {'Reaction outcome loss': 0.33808910287244226, 'Total loss': 0.33808910287244226}
2023-01-05 01:07:55,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:55,022 INFO:     Epoch: 17
2023-01-05 01:07:57,225 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46370418220758436, 'Total loss': 0.46370418220758436} | train loss {'Reaction outcome loss': 0.3246958812006114, 'Total loss': 0.3246958812006114}
2023-01-05 01:07:57,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:57,225 INFO:     Epoch: 18
2023-01-05 01:07:59,459 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45147622674703597, 'Total loss': 0.45147622674703597} | train loss {'Reaction outcome loss': 0.3175281557499932, 'Total loss': 0.3175281557499932}
2023-01-05 01:07:59,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:07:59,459 INFO:     Epoch: 19
2023-01-05 01:08:01,630 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.461885725458463, 'Total loss': 0.461885725458463} | train loss {'Reaction outcome loss': 0.31344218332898743, 'Total loss': 0.31344218332898743}
2023-01-05 01:08:01,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:01,630 INFO:     Epoch: 20
2023-01-05 01:08:03,898 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4435393710931142, 'Total loss': 0.4435393710931142} | train loss {'Reaction outcome loss': 0.3035802054034028, 'Total loss': 0.3035802054034028}
2023-01-05 01:08:03,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:03,898 INFO:     Epoch: 21
2023-01-05 01:08:06,182 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4574112117290497, 'Total loss': 0.4574112117290497} | train loss {'Reaction outcome loss': 0.30100220037012326, 'Total loss': 0.30100220037012326}
2023-01-05 01:08:06,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:06,182 INFO:     Epoch: 22
2023-01-05 01:08:08,450 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44971036513646445, 'Total loss': 0.44971036513646445} | train loss {'Reaction outcome loss': 0.29350915737450123, 'Total loss': 0.29350915737450123}
2023-01-05 01:08:08,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:08,452 INFO:     Epoch: 23
2023-01-05 01:08:10,737 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44491417755683266, 'Total loss': 0.44491417755683266} | train loss {'Reaction outcome loss': 0.28782583913002635, 'Total loss': 0.28782583913002635}
2023-01-05 01:08:10,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:10,737 INFO:     Epoch: 24
2023-01-05 01:08:13,013 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4495591511329015, 'Total loss': 0.4495591511329015} | train loss {'Reaction outcome loss': 0.2871670442959462, 'Total loss': 0.2871670442959462}
2023-01-05 01:08:13,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:13,013 INFO:     Epoch: 25
2023-01-05 01:08:15,271 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44484046498934426, 'Total loss': 0.44484046498934426} | train loss {'Reaction outcome loss': 0.282817360524774, 'Total loss': 0.282817360524774}
2023-01-05 01:08:15,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:15,272 INFO:     Epoch: 26
2023-01-05 01:08:17,532 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4368999133507411, 'Total loss': 0.4368999133507411} | train loss {'Reaction outcome loss': 0.275953593236875, 'Total loss': 0.275953593236875}
2023-01-05 01:08:17,532 INFO:     Found new best model at epoch 26
2023-01-05 01:08:17,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:17,534 INFO:     Epoch: 27
2023-01-05 01:08:19,789 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43292094965775807, 'Total loss': 0.43292094965775807} | train loss {'Reaction outcome loss': 0.2703451745427257, 'Total loss': 0.2703451745427257}
2023-01-05 01:08:19,789 INFO:     Found new best model at epoch 27
2023-01-05 01:08:19,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:19,791 INFO:     Epoch: 28
2023-01-05 01:08:22,033 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42324122538169223, 'Total loss': 0.42324122538169223} | train loss {'Reaction outcome loss': 0.2692139944337335, 'Total loss': 0.2692139944337335}
2023-01-05 01:08:22,033 INFO:     Found new best model at epoch 28
2023-01-05 01:08:22,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:22,035 INFO:     Epoch: 29
2023-01-05 01:08:24,295 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44030697097380955, 'Total loss': 0.44030697097380955} | train loss {'Reaction outcome loss': 0.26557538542721676, 'Total loss': 0.26557538542721676}
2023-01-05 01:08:24,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:24,296 INFO:     Epoch: 30
2023-01-05 01:08:26,558 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4390250106652578, 'Total loss': 0.4390250106652578} | train loss {'Reaction outcome loss': 0.2628447222271228, 'Total loss': 0.2628447222271228}
2023-01-05 01:08:26,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:26,558 INFO:     Epoch: 31
2023-01-05 01:08:28,832 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4280233358343442, 'Total loss': 0.4280233358343442} | train loss {'Reaction outcome loss': 0.2573840510543933, 'Total loss': 0.2573840510543933}
2023-01-05 01:08:28,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:28,833 INFO:     Epoch: 32
2023-01-05 01:08:31,062 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43098501587907473, 'Total loss': 0.43098501587907473} | train loss {'Reaction outcome loss': 0.25198418499115144, 'Total loss': 0.25198418499115144}
2023-01-05 01:08:31,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:31,062 INFO:     Epoch: 33
2023-01-05 01:08:33,320 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42364826798439026, 'Total loss': 0.42364826798439026} | train loss {'Reaction outcome loss': 0.25409250127467653, 'Total loss': 0.25409250127467653}
2023-01-05 01:08:33,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:33,321 INFO:     Epoch: 34
2023-01-05 01:08:35,588 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4417202134927114, 'Total loss': 0.4417202134927114} | train loss {'Reaction outcome loss': 0.25045833816005436, 'Total loss': 0.25045833816005436}
2023-01-05 01:08:35,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:35,589 INFO:     Epoch: 35
2023-01-05 01:08:37,783 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4368628144264221, 'Total loss': 0.4368628144264221} | train loss {'Reaction outcome loss': 0.24628364698228422, 'Total loss': 0.24628364698228422}
2023-01-05 01:08:37,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:37,784 INFO:     Epoch: 36
2023-01-05 01:08:40,029 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4120824416478475, 'Total loss': 0.4120824416478475} | train loss {'Reaction outcome loss': 0.2390962849616574, 'Total loss': 0.2390962849616574}
2023-01-05 01:08:40,029 INFO:     Found new best model at epoch 36
2023-01-05 01:08:40,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:40,031 INFO:     Epoch: 37
2023-01-05 01:08:42,293 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4138488550980886, 'Total loss': 0.4138488550980886} | train loss {'Reaction outcome loss': 0.24047434836162074, 'Total loss': 0.24047434836162074}
2023-01-05 01:08:42,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:42,293 INFO:     Epoch: 38
2023-01-05 01:08:44,539 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44257034063339235, 'Total loss': 0.44257034063339235} | train loss {'Reaction outcome loss': 0.2375870824888994, 'Total loss': 0.2375870824888994}
2023-01-05 01:08:44,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:44,540 INFO:     Epoch: 39
2023-01-05 01:08:46,818 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41335944732030233, 'Total loss': 0.41335944732030233} | train loss {'Reaction outcome loss': 0.23531153687487763, 'Total loss': 0.23531153687487763}
2023-01-05 01:08:46,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:46,818 INFO:     Epoch: 40
2023-01-05 01:08:49,061 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4209343502918879, 'Total loss': 0.4209343502918879} | train loss {'Reaction outcome loss': 0.23476571588363457, 'Total loss': 0.23476571588363457}
2023-01-05 01:08:49,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:49,061 INFO:     Epoch: 41
2023-01-05 01:08:51,341 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4232625315586726, 'Total loss': 0.4232625315586726} | train loss {'Reaction outcome loss': 0.23249356261377194, 'Total loss': 0.23249356261377194}
2023-01-05 01:08:51,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:51,342 INFO:     Epoch: 42
2023-01-05 01:08:53,618 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43710919419924416, 'Total loss': 0.43710919419924416} | train loss {'Reaction outcome loss': 0.23245058807843644, 'Total loss': 0.23245058807843644}
2023-01-05 01:08:53,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:53,619 INFO:     Epoch: 43
2023-01-05 01:08:55,850 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4771008908748627, 'Total loss': 0.4771008908748627} | train loss {'Reaction outcome loss': 0.22894024483805744, 'Total loss': 0.22894024483805744}
2023-01-05 01:08:55,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:55,850 INFO:     Epoch: 44
2023-01-05 01:08:58,100 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43796491287648676, 'Total loss': 0.43796491287648676} | train loss {'Reaction outcome loss': 0.22340891238920632, 'Total loss': 0.22340891238920632}
2023-01-05 01:08:58,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:08:58,100 INFO:     Epoch: 45
2023-01-05 01:09:00,376 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4259922136863073, 'Total loss': 0.4259922136863073} | train loss {'Reaction outcome loss': 0.2290871116107444, 'Total loss': 0.2290871116107444}
2023-01-05 01:09:00,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:00,376 INFO:     Epoch: 46
2023-01-05 01:09:02,621 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43254644771416983, 'Total loss': 0.43254644771416983} | train loss {'Reaction outcome loss': 0.2194799153732694, 'Total loss': 0.2194799153732694}
2023-01-05 01:09:02,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:02,622 INFO:     Epoch: 47
2023-01-05 01:09:04,893 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4401857574780782, 'Total loss': 0.4401857574780782} | train loss {'Reaction outcome loss': 0.2177564353893918, 'Total loss': 0.2177564353893918}
2023-01-05 01:09:04,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:04,894 INFO:     Epoch: 48
2023-01-05 01:09:07,127 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44858214060465496, 'Total loss': 0.44858214060465496} | train loss {'Reaction outcome loss': 0.2231479384448877, 'Total loss': 0.2231479384448877}
2023-01-05 01:09:07,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:07,128 INFO:     Epoch: 49
2023-01-05 01:09:09,417 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.429134339094162, 'Total loss': 0.429134339094162} | train loss {'Reaction outcome loss': 0.21802658662334462, 'Total loss': 0.21802658662334462}
2023-01-05 01:09:09,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:09,417 INFO:     Epoch: 50
2023-01-05 01:09:11,669 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41191272338231405, 'Total loss': 0.41191272338231405} | train loss {'Reaction outcome loss': 0.21433378185148919, 'Total loss': 0.21433378185148919}
2023-01-05 01:09:11,669 INFO:     Found new best model at epoch 50
2023-01-05 01:09:11,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:11,670 INFO:     Epoch: 51
2023-01-05 01:09:13,904 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43226926351586975, 'Total loss': 0.43226926351586975} | train loss {'Reaction outcome loss': 0.21924523271902696, 'Total loss': 0.21924523271902696}
2023-01-05 01:09:13,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:13,905 INFO:     Epoch: 52
2023-01-05 01:09:16,178 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40437199274698893, 'Total loss': 0.40437199274698893} | train loss {'Reaction outcome loss': 0.20990342565136375, 'Total loss': 0.20990342565136375}
2023-01-05 01:09:16,178 INFO:     Found new best model at epoch 52
2023-01-05 01:09:16,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:16,179 INFO:     Epoch: 53
2023-01-05 01:09:18,407 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4118970463673274, 'Total loss': 0.4118970463673274} | train loss {'Reaction outcome loss': 0.2084165324561217, 'Total loss': 0.2084165324561217}
2023-01-05 01:09:18,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:18,408 INFO:     Epoch: 54
2023-01-05 01:09:20,667 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43148289024829867, 'Total loss': 0.43148289024829867} | train loss {'Reaction outcome loss': 0.20798205572856246, 'Total loss': 0.20798205572856246}
2023-01-05 01:09:20,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:20,668 INFO:     Epoch: 55
2023-01-05 01:09:22,843 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4314054648081462, 'Total loss': 0.4314054648081462} | train loss {'Reaction outcome loss': 0.20265616780140233, 'Total loss': 0.20265616780140233}
2023-01-05 01:09:22,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:22,843 INFO:     Epoch: 56
2023-01-05 01:09:25,104 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.438114936153094, 'Total loss': 0.438114936153094} | train loss {'Reaction outcome loss': 0.20458720362533409, 'Total loss': 0.20458720362533409}
2023-01-05 01:09:25,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:25,104 INFO:     Epoch: 57
2023-01-05 01:09:27,386 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4457448278864225, 'Total loss': 0.4457448278864225} | train loss {'Reaction outcome loss': 0.20544422647179464, 'Total loss': 0.20544422647179464}
2023-01-05 01:09:27,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:27,386 INFO:     Epoch: 58
2023-01-05 01:09:29,736 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42665022412935893, 'Total loss': 0.42665022412935893} | train loss {'Reaction outcome loss': 0.2028599013053284, 'Total loss': 0.2028599013053284}
2023-01-05 01:09:29,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:29,736 INFO:     Epoch: 59
2023-01-05 01:09:31,958 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4238500485817591, 'Total loss': 0.4238500485817591} | train loss {'Reaction outcome loss': 0.20137423447195427, 'Total loss': 0.20137423447195427}
2023-01-05 01:09:31,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:31,958 INFO:     Epoch: 60
2023-01-05 01:09:34,232 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45048367281754814, 'Total loss': 0.45048367281754814} | train loss {'Reaction outcome loss': 0.19617054204621254, 'Total loss': 0.19617054204621254}
2023-01-05 01:09:34,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:34,233 INFO:     Epoch: 61
2023-01-05 01:09:36,461 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4415239175160726, 'Total loss': 0.4415239175160726} | train loss {'Reaction outcome loss': 0.20352117544954595, 'Total loss': 0.20352117544954595}
2023-01-05 01:09:36,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:36,461 INFO:     Epoch: 62
2023-01-05 01:09:38,753 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4037636031707128, 'Total loss': 0.4037636031707128} | train loss {'Reaction outcome loss': 0.19782485090707183, 'Total loss': 0.19782485090707183}
2023-01-05 01:09:38,753 INFO:     Found new best model at epoch 62
2023-01-05 01:09:38,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:38,755 INFO:     Epoch: 63
2023-01-05 01:09:41,039 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43778004348278043, 'Total loss': 0.43778004348278043} | train loss {'Reaction outcome loss': 0.1951419155614363, 'Total loss': 0.1951419155614363}
2023-01-05 01:09:41,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:41,040 INFO:     Epoch: 64
2023-01-05 01:09:43,314 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41827212870121, 'Total loss': 0.41827212870121} | train loss {'Reaction outcome loss': 0.1955010883496664, 'Total loss': 0.1955010883496664}
2023-01-05 01:09:43,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:43,315 INFO:     Epoch: 65
2023-01-05 01:09:45,517 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.459596719344457, 'Total loss': 0.459596719344457} | train loss {'Reaction outcome loss': 0.19223670682631136, 'Total loss': 0.19223670682631136}
2023-01-05 01:09:45,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:45,518 INFO:     Epoch: 66
2023-01-05 01:09:47,790 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4526949286460876, 'Total loss': 0.4526949286460876} | train loss {'Reaction outcome loss': 0.1938674190327095, 'Total loss': 0.1938674190327095}
2023-01-05 01:09:47,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:47,790 INFO:     Epoch: 67
2023-01-05 01:09:50,043 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44068405715127784, 'Total loss': 0.44068405715127784} | train loss {'Reaction outcome loss': 0.19673271360218741, 'Total loss': 0.19673271360218741}
2023-01-05 01:09:50,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:50,044 INFO:     Epoch: 68
2023-01-05 01:09:52,325 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4338433429598808, 'Total loss': 0.4338433429598808} | train loss {'Reaction outcome loss': 0.1883032443573436, 'Total loss': 0.1883032443573436}
2023-01-05 01:09:52,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:52,325 INFO:     Epoch: 69
2023-01-05 01:09:54,594 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45698461929957074, 'Total loss': 0.45698461929957074} | train loss {'Reaction outcome loss': 0.18965431225792057, 'Total loss': 0.18965431225792057}
2023-01-05 01:09:54,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:54,594 INFO:     Epoch: 70
2023-01-05 01:09:56,878 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4637163589398066, 'Total loss': 0.4637163589398066} | train loss {'Reaction outcome loss': 0.18960861296355994, 'Total loss': 0.18960861296355994}
2023-01-05 01:09:56,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:56,879 INFO:     Epoch: 71
2023-01-05 01:09:59,146 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41809330123166244, 'Total loss': 0.41809330123166244} | train loss {'Reaction outcome loss': 0.18678837082607652, 'Total loss': 0.18678837082607652}
2023-01-05 01:09:59,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:09:59,146 INFO:     Epoch: 72
2023-01-05 01:10:01,431 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43296783516804377, 'Total loss': 0.43296783516804377} | train loss {'Reaction outcome loss': 0.1896401863000507, 'Total loss': 0.1896401863000507}
2023-01-05 01:10:01,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:01,431 INFO:     Epoch: 73
2023-01-05 01:10:03,689 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45217675119638445, 'Total loss': 0.45217675119638445} | train loss {'Reaction outcome loss': 0.18352584992720333, 'Total loss': 0.18352584992720333}
2023-01-05 01:10:03,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:03,690 INFO:     Epoch: 74
2023-01-05 01:10:05,953 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4544079636534055, 'Total loss': 0.4544079636534055} | train loss {'Reaction outcome loss': 0.18417282681407857, 'Total loss': 0.18417282681407857}
2023-01-05 01:10:05,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:05,953 INFO:     Epoch: 75
2023-01-05 01:10:08,240 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44682419995466865, 'Total loss': 0.44682419995466865} | train loss {'Reaction outcome loss': 0.18264444549954648, 'Total loss': 0.18264444549954648}
2023-01-05 01:10:08,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:08,240 INFO:     Epoch: 76
2023-01-05 01:10:10,518 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4592978596687317, 'Total loss': 0.4592978596687317} | train loss {'Reaction outcome loss': 0.18298119737763321, 'Total loss': 0.18298119737763321}
2023-01-05 01:10:10,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:10,519 INFO:     Epoch: 77
2023-01-05 01:10:12,808 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4514387895663579, 'Total loss': 0.4514387895663579} | train loss {'Reaction outcome loss': 0.18447289867696456, 'Total loss': 0.18447289867696456}
2023-01-05 01:10:12,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:12,808 INFO:     Epoch: 78
2023-01-05 01:10:15,055 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4485363076130549, 'Total loss': 0.4485363076130549} | train loss {'Reaction outcome loss': 0.1796180969490821, 'Total loss': 0.1796180969490821}
2023-01-05 01:10:15,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:15,056 INFO:     Epoch: 79
2023-01-05 01:10:17,321 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4734577159086863, 'Total loss': 0.4734577159086863} | train loss {'Reaction outcome loss': 0.18485682564602646, 'Total loss': 0.18485682564602646}
2023-01-05 01:10:17,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:17,322 INFO:     Epoch: 80
2023-01-05 01:10:19,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4450863198066751, 'Total loss': 0.4450863198066751} | train loss {'Reaction outcome loss': 0.1770636376988694, 'Total loss': 0.1770636376988694}
2023-01-05 01:10:19,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:19,621 INFO:     Epoch: 81
2023-01-05 01:10:21,885 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45585992832978567, 'Total loss': 0.45585992832978567} | train loss {'Reaction outcome loss': 0.17544312927609693, 'Total loss': 0.17544312927609693}
2023-01-05 01:10:21,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:21,885 INFO:     Epoch: 82
2023-01-05 01:10:23,970 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46309453845024107, 'Total loss': 0.46309453845024107} | train loss {'Reaction outcome loss': 0.17464359256939876, 'Total loss': 0.17464359256939876}
2023-01-05 01:10:23,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:23,971 INFO:     Epoch: 83
2023-01-05 01:10:26,244 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4482503722111384, 'Total loss': 0.4482503722111384} | train loss {'Reaction outcome loss': 0.17776448386536392, 'Total loss': 0.17776448386536392}
2023-01-05 01:10:26,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:26,245 INFO:     Epoch: 84
2023-01-05 01:10:28,502 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4687563230593999, 'Total loss': 0.4687563230593999} | train loss {'Reaction outcome loss': 0.17561750746557375, 'Total loss': 0.17561750746557375}
2023-01-05 01:10:28,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:28,503 INFO:     Epoch: 85
2023-01-05 01:10:30,783 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.493257940808932, 'Total loss': 0.493257940808932} | train loss {'Reaction outcome loss': 0.17297497312017188, 'Total loss': 0.17297497312017188}
2023-01-05 01:10:30,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:30,783 INFO:     Epoch: 86
2023-01-05 01:10:32,967 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4562941759824753, 'Total loss': 0.4562941759824753} | train loss {'Reaction outcome loss': 0.17604514576884706, 'Total loss': 0.17604514576884706}
2023-01-05 01:10:32,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:32,968 INFO:     Epoch: 87
2023-01-05 01:10:35,197 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46528495152791344, 'Total loss': 0.46528495152791344} | train loss {'Reaction outcome loss': 0.17874733385182784, 'Total loss': 0.17874733385182784}
2023-01-05 01:10:35,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:35,197 INFO:     Epoch: 88
2023-01-05 01:10:37,498 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45460416078567506, 'Total loss': 0.45460416078567506} | train loss {'Reaction outcome loss': 0.17033726202882155, 'Total loss': 0.17033726202882155}
2023-01-05 01:10:37,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:37,498 INFO:     Epoch: 89
2023-01-05 01:10:39,763 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49360721508661903, 'Total loss': 0.49360721508661903} | train loss {'Reaction outcome loss': 0.16913764101254758, 'Total loss': 0.16913764101254758}
2023-01-05 01:10:39,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:39,763 INFO:     Epoch: 90
2023-01-05 01:10:42,044 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45612880984942117, 'Total loss': 0.45612880984942117} | train loss {'Reaction outcome loss': 0.16647578945672575, 'Total loss': 0.16647578945672575}
2023-01-05 01:10:42,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:42,044 INFO:     Epoch: 91
2023-01-05 01:10:44,324 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4359901001056035, 'Total loss': 0.4359901001056035} | train loss {'Reaction outcome loss': 0.1692867369965956, 'Total loss': 0.1692867369965956}
2023-01-05 01:10:44,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:44,324 INFO:     Epoch: 92
2023-01-05 01:10:46,583 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44127887388070425, 'Total loss': 0.44127887388070425} | train loss {'Reaction outcome loss': 0.17342463039561085, 'Total loss': 0.17342463039561085}
2023-01-05 01:10:46,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:46,584 INFO:     Epoch: 93
2023-01-05 01:10:48,864 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4818835218747457, 'Total loss': 0.4818835218747457} | train loss {'Reaction outcome loss': 0.17046168890011762, 'Total loss': 0.17046168890011762}
2023-01-05 01:10:48,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:48,864 INFO:     Epoch: 94
2023-01-05 01:10:51,118 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4904882748921712, 'Total loss': 0.4904882748921712} | train loss {'Reaction outcome loss': 0.16906319041517884, 'Total loss': 0.16906319041517884}
2023-01-05 01:10:51,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:51,118 INFO:     Epoch: 95
2023-01-05 01:10:53,357 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46797664364178976, 'Total loss': 0.46797664364178976} | train loss {'Reaction outcome loss': 0.16894121755028838, 'Total loss': 0.16894121755028838}
2023-01-05 01:10:53,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:53,357 INFO:     Epoch: 96
2023-01-05 01:10:55,620 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45570094982783, 'Total loss': 0.45570094982783} | train loss {'Reaction outcome loss': 0.1658972249574798, 'Total loss': 0.1658972249574798}
2023-01-05 01:10:55,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:55,620 INFO:     Epoch: 97
2023-01-05 01:10:57,821 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46610316733519236, 'Total loss': 0.46610316733519236} | train loss {'Reaction outcome loss': 0.16363778424076064, 'Total loss': 0.16363778424076064}
2023-01-05 01:10:57,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:10:57,822 INFO:     Epoch: 98
2023-01-05 01:11:00,086 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49578391313552855, 'Total loss': 0.49578391313552855} | train loss {'Reaction outcome loss': 0.16287659789311165, 'Total loss': 0.16287659789311165}
2023-01-05 01:11:00,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:00,087 INFO:     Epoch: 99
2023-01-05 01:11:02,334 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47649845480918884, 'Total loss': 0.47649845480918884} | train loss {'Reaction outcome loss': 0.1617999249003451, 'Total loss': 0.1617999249003451}
2023-01-05 01:11:02,335 INFO:     Best model found after epoch 63 of 100.
2023-01-05 01:11:02,335 INFO:   Done with stage: TRAINING
2023-01-05 01:11:02,335 INFO:   Starting stage: EVALUATION
2023-01-05 01:11:02,463 INFO:   Done with stage: EVALUATION
2023-01-05 01:11:02,463 INFO:   Leaving out SEQ value Fold_5
2023-01-05 01:11:02,476 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 01:11:02,476 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:11:03,148 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:11:03,148 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:11:03,218 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:11:03,218 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:11:03,218 INFO:     No hyperparam tuning for this model
2023-01-05 01:11:03,218 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:11:03,218 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:11:03,219 INFO:     None feature selector for col prot
2023-01-05 01:11:03,219 INFO:     None feature selector for col prot
2023-01-05 01:11:03,219 INFO:     None feature selector for col prot
2023-01-05 01:11:03,220 INFO:     None feature selector for col chem
2023-01-05 01:11:03,220 INFO:     None feature selector for col chem
2023-01-05 01:11:03,220 INFO:     None feature selector for col chem
2023-01-05 01:11:03,220 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:11:03,220 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:11:03,222 INFO:     Number of params in model 72931
2023-01-05 01:11:03,225 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:11:03,225 INFO:   Starting stage: TRAINING
2023-01-05 01:11:03,285 INFO:     Val loss before train {'Reaction outcome loss': 0.9940452496210734, 'Total loss': 0.9940452496210734}
2023-01-05 01:11:03,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:03,285 INFO:     Epoch: 0
2023-01-05 01:11:05,548 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7313845813274383, 'Total loss': 0.7313845813274383} | train loss {'Reaction outcome loss': 0.9454992469467411, 'Total loss': 0.9454992469467411}
2023-01-05 01:11:05,549 INFO:     Found new best model at epoch 0
2023-01-05 01:11:05,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:05,550 INFO:     Epoch: 1
2023-01-05 01:11:07,795 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5084684977928797, 'Total loss': 0.5084684977928797} | train loss {'Reaction outcome loss': 0.6301921932060366, 'Total loss': 0.6301921932060366}
2023-01-05 01:11:07,795 INFO:     Found new best model at epoch 1
2023-01-05 01:11:07,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:07,797 INFO:     Epoch: 2
2023-01-05 01:11:10,051 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45336185495058695, 'Total loss': 0.45336185495058695} | train loss {'Reaction outcome loss': 0.5344752286315395, 'Total loss': 0.5344752286315395}
2023-01-05 01:11:10,051 INFO:     Found new best model at epoch 2
2023-01-05 01:11:10,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:10,053 INFO:     Epoch: 3
2023-01-05 01:11:12,298 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4326959530512492, 'Total loss': 0.4326959530512492} | train loss {'Reaction outcome loss': 0.48520409646662566, 'Total loss': 0.48520409646662566}
2023-01-05 01:11:12,298 INFO:     Found new best model at epoch 3
2023-01-05 01:11:12,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:12,299 INFO:     Epoch: 4
2023-01-05 01:11:14,445 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4240520139535268, 'Total loss': 0.4240520139535268} | train loss {'Reaction outcome loss': 0.455549596314611, 'Total loss': 0.455549596314611}
2023-01-05 01:11:14,445 INFO:     Found new best model at epoch 4
2023-01-05 01:11:14,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:14,446 INFO:     Epoch: 5
2023-01-05 01:11:16,710 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4504571934541067, 'Total loss': 0.4504571934541067} | train loss {'Reaction outcome loss': 0.43615090664113043, 'Total loss': 0.43615090664113043}
2023-01-05 01:11:16,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:16,710 INFO:     Epoch: 6
2023-01-05 01:11:18,946 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44520430465539296, 'Total loss': 0.44520430465539296} | train loss {'Reaction outcome loss': 0.41676654077609093, 'Total loss': 0.41676654077609093}
2023-01-05 01:11:18,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:18,947 INFO:     Epoch: 7
2023-01-05 01:11:21,173 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4072444985310237, 'Total loss': 0.4072444985310237} | train loss {'Reaction outcome loss': 0.404728943475317, 'Total loss': 0.404728943475317}
2023-01-05 01:11:21,174 INFO:     Found new best model at epoch 7
2023-01-05 01:11:21,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:21,175 INFO:     Epoch: 8
2023-01-05 01:11:23,428 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4183926443258921, 'Total loss': 0.4183926443258921} | train loss {'Reaction outcome loss': 0.38782875847730397, 'Total loss': 0.38782875847730397}
2023-01-05 01:11:23,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:23,429 INFO:     Epoch: 9
2023-01-05 01:11:25,691 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40023534099260966, 'Total loss': 0.40023534099260966} | train loss {'Reaction outcome loss': 0.379631959628112, 'Total loss': 0.379631959628112}
2023-01-05 01:11:25,691 INFO:     Found new best model at epoch 9
2023-01-05 01:11:25,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:25,692 INFO:     Epoch: 10
2023-01-05 01:11:27,907 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40678038001060485, 'Total loss': 0.40678038001060485} | train loss {'Reaction outcome loss': 0.37073695309971216, 'Total loss': 0.37073695309971216}
2023-01-05 01:11:27,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:27,907 INFO:     Epoch: 11
2023-01-05 01:11:30,088 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3917637412746747, 'Total loss': 0.3917637412746747} | train loss {'Reaction outcome loss': 0.3603351563080769, 'Total loss': 0.3603351563080769}
2023-01-05 01:11:30,088 INFO:     Found new best model at epoch 11
2023-01-05 01:11:30,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:30,089 INFO:     Epoch: 12
2023-01-05 01:11:32,274 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41532841821511585, 'Total loss': 0.41532841821511585} | train loss {'Reaction outcome loss': 0.3511250009121447, 'Total loss': 0.3511250009121447}
2023-01-05 01:11:32,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:32,275 INFO:     Epoch: 13
2023-01-05 01:11:34,487 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3861967066923777, 'Total loss': 0.3861967066923777} | train loss {'Reaction outcome loss': 0.3419088034719121, 'Total loss': 0.3419088034719121}
2023-01-05 01:11:34,487 INFO:     Found new best model at epoch 13
2023-01-05 01:11:34,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:34,489 INFO:     Epoch: 14
2023-01-05 01:11:36,739 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40384119053681694, 'Total loss': 0.40384119053681694} | train loss {'Reaction outcome loss': 0.3332525577248219, 'Total loss': 0.3332525577248219}
2023-01-05 01:11:36,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:36,739 INFO:     Epoch: 15
2023-01-05 01:11:38,958 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39083091616630555, 'Total loss': 0.39083091616630555} | train loss {'Reaction outcome loss': 0.330600905127904, 'Total loss': 0.330600905127904}
2023-01-05 01:11:38,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:38,959 INFO:     Epoch: 16
2023-01-05 01:11:41,213 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41266999989748, 'Total loss': 0.41266999989748} | train loss {'Reaction outcome loss': 0.3226172596969329, 'Total loss': 0.3226172596969329}
2023-01-05 01:11:41,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:41,214 INFO:     Epoch: 17
2023-01-05 01:11:43,428 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39723855803410213, 'Total loss': 0.39723855803410213} | train loss {'Reaction outcome loss': 0.3114897508160732, 'Total loss': 0.3114897508160732}
2023-01-05 01:11:43,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:43,429 INFO:     Epoch: 18
2023-01-05 01:11:45,728 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39685441156228385, 'Total loss': 0.39685441156228385} | train loss {'Reaction outcome loss': 0.3052307364635089, 'Total loss': 0.3052307364635089}
2023-01-05 01:11:45,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:45,728 INFO:     Epoch: 19
2023-01-05 01:11:48,015 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4162113398313522, 'Total loss': 0.4162113398313522} | train loss {'Reaction outcome loss': 0.30441930650696425, 'Total loss': 0.30441930650696425}
2023-01-05 01:11:48,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:48,016 INFO:     Epoch: 20
2023-01-05 01:11:50,269 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38775493403275807, 'Total loss': 0.38775493403275807} | train loss {'Reaction outcome loss': 0.2953960646602867, 'Total loss': 0.2953960646602867}
2023-01-05 01:11:50,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:50,269 INFO:     Epoch: 21
2023-01-05 01:11:52,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40578035910924276, 'Total loss': 0.40578035910924276} | train loss {'Reaction outcome loss': 0.29327388675311844, 'Total loss': 0.29327388675311844}
2023-01-05 01:11:52,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:52,554 INFO:     Epoch: 22
2023-01-05 01:11:54,816 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40361505150794985, 'Total loss': 0.40361505150794985} | train loss {'Reaction outcome loss': 0.288803069573232, 'Total loss': 0.288803069573232}
2023-01-05 01:11:54,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:54,817 INFO:     Epoch: 23
2023-01-05 01:11:57,102 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4174871931473414, 'Total loss': 0.4174871931473414} | train loss {'Reaction outcome loss': 0.2820779595268547, 'Total loss': 0.2820779595268547}
2023-01-05 01:11:57,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:57,102 INFO:     Epoch: 24
2023-01-05 01:11:59,390 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3851263364156087, 'Total loss': 0.3851263364156087} | train loss {'Reaction outcome loss': 0.2785930498049255, 'Total loss': 0.2785930498049255}
2023-01-05 01:11:59,391 INFO:     Found new best model at epoch 24
2023-01-05 01:11:59,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:11:59,392 INFO:     Epoch: 25
2023-01-05 01:12:01,668 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40891379018624624, 'Total loss': 0.40891379018624624} | train loss {'Reaction outcome loss': 0.27387532903829637, 'Total loss': 0.27387532903829637}
2023-01-05 01:12:01,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:01,668 INFO:     Epoch: 26
2023-01-05 01:12:03,938 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.398893803358078, 'Total loss': 0.398893803358078} | train loss {'Reaction outcome loss': 0.2737787301628598, 'Total loss': 0.2737787301628598}
2023-01-05 01:12:03,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:03,938 INFO:     Epoch: 27
2023-01-05 01:12:06,120 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4041667799154917, 'Total loss': 0.4041667799154917} | train loss {'Reaction outcome loss': 0.2648376428760884, 'Total loss': 0.2648376428760884}
2023-01-05 01:12:06,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:06,120 INFO:     Epoch: 28
2023-01-05 01:12:08,392 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39726836085319517, 'Total loss': 0.39726836085319517} | train loss {'Reaction outcome loss': 0.2661067397881716, 'Total loss': 0.2661067397881716}
2023-01-05 01:12:08,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:08,393 INFO:     Epoch: 29
2023-01-05 01:12:10,586 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.425972385207812, 'Total loss': 0.425972385207812} | train loss {'Reaction outcome loss': 0.2617483183351557, 'Total loss': 0.2617483183351557}
2023-01-05 01:12:10,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:10,586 INFO:     Epoch: 30
2023-01-05 01:12:12,797 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.397582021355629, 'Total loss': 0.397582021355629} | train loss {'Reaction outcome loss': 0.2537369233512384, 'Total loss': 0.2537369233512384}
2023-01-05 01:12:12,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:12,798 INFO:     Epoch: 31
2023-01-05 01:12:14,795 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40665793406466644, 'Total loss': 0.40665793406466644} | train loss {'Reaction outcome loss': 0.25372508431815066, 'Total loss': 0.25372508431815066}
2023-01-05 01:12:14,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:14,796 INFO:     Epoch: 32
2023-01-05 01:12:16,628 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4171227862437566, 'Total loss': 0.4171227862437566} | train loss {'Reaction outcome loss': 0.25379321779316083, 'Total loss': 0.25379321779316083}
2023-01-05 01:12:16,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:16,628 INFO:     Epoch: 33
2023-01-05 01:12:18,642 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40777755081653594, 'Total loss': 0.40777755081653594} | train loss {'Reaction outcome loss': 0.24529457495746199, 'Total loss': 0.24529457495746199}
2023-01-05 01:12:18,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:18,643 INFO:     Epoch: 34
2023-01-05 01:12:20,870 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40144416044155756, 'Total loss': 0.40144416044155756} | train loss {'Reaction outcome loss': 0.2432560733509408, 'Total loss': 0.2432560733509408}
2023-01-05 01:12:20,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:20,870 INFO:     Epoch: 35
2023-01-05 01:12:23,150 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3771568566560745, 'Total loss': 0.3771568566560745} | train loss {'Reaction outcome loss': 0.24203852829708306, 'Total loss': 0.24203852829708306}
2023-01-05 01:12:23,150 INFO:     Found new best model at epoch 35
2023-01-05 01:12:23,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:23,151 INFO:     Epoch: 36
2023-01-05 01:12:25,426 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37996474041913947, 'Total loss': 0.37996474041913947} | train loss {'Reaction outcome loss': 0.23671353582817295, 'Total loss': 0.23671353582817295}
2023-01-05 01:12:25,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:25,426 INFO:     Epoch: 37
2023-01-05 01:12:27,688 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4015885372956594, 'Total loss': 0.4015885372956594} | train loss {'Reaction outcome loss': 0.23582977699351224, 'Total loss': 0.23582977699351224}
2023-01-05 01:12:27,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:27,688 INFO:     Epoch: 38
2023-01-05 01:12:29,933 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40919906497001646, 'Total loss': 0.40919906497001646} | train loss {'Reaction outcome loss': 0.23215462555201044, 'Total loss': 0.23215462555201044}
2023-01-05 01:12:29,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:29,933 INFO:     Epoch: 39
2023-01-05 01:12:32,194 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3963830759127935, 'Total loss': 0.3963830759127935} | train loss {'Reaction outcome loss': 0.23058215572434856, 'Total loss': 0.23058215572434856}
2023-01-05 01:12:32,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:32,194 INFO:     Epoch: 40
2023-01-05 01:12:34,438 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3993713652094205, 'Total loss': 0.3993713652094205} | train loss {'Reaction outcome loss': 0.22560266473259952, 'Total loss': 0.22560266473259952}
2023-01-05 01:12:34,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:34,438 INFO:     Epoch: 41
2023-01-05 01:12:36,687 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3903460780779521, 'Total loss': 0.3903460780779521} | train loss {'Reaction outcome loss': 0.23034258432928406, 'Total loss': 0.23034258432928406}
2023-01-05 01:12:36,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:36,687 INFO:     Epoch: 42
2023-01-05 01:12:38,957 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4058654566605886, 'Total loss': 0.4058654566605886} | train loss {'Reaction outcome loss': 0.22592838768534604, 'Total loss': 0.22592838768534604}
2023-01-05 01:12:38,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:38,958 INFO:     Epoch: 43
2023-01-05 01:12:41,187 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3981210877497991, 'Total loss': 0.3981210877497991} | train loss {'Reaction outcome loss': 0.22356981357781466, 'Total loss': 0.22356981357781466}
2023-01-05 01:12:41,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:41,187 INFO:     Epoch: 44
2023-01-05 01:12:43,406 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40793113311131796, 'Total loss': 0.40793113311131796} | train loss {'Reaction outcome loss': 0.22462333331980644, 'Total loss': 0.22462333331980644}
2023-01-05 01:12:43,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:43,407 INFO:     Epoch: 45
2023-01-05 01:12:45,634 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3942617957790693, 'Total loss': 0.3942617957790693} | train loss {'Reaction outcome loss': 0.2179483330273994, 'Total loss': 0.2179483330273994}
2023-01-05 01:12:45,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:45,635 INFO:     Epoch: 46
2023-01-05 01:12:47,851 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4055306643247604, 'Total loss': 0.4055306643247604} | train loss {'Reaction outcome loss': 0.2179699633438611, 'Total loss': 0.2179699633438611}
2023-01-05 01:12:47,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:47,851 INFO:     Epoch: 47
2023-01-05 01:12:50,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4066938819984595, 'Total loss': 0.4066938819984595} | train loss {'Reaction outcome loss': 0.21793552028143018, 'Total loss': 0.21793552028143018}
2023-01-05 01:12:50,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:50,073 INFO:     Epoch: 48
2023-01-05 01:12:52,277 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40708016554514564, 'Total loss': 0.40708016554514564} | train loss {'Reaction outcome loss': 0.21074487422912344, 'Total loss': 0.21074487422912344}
2023-01-05 01:12:52,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:52,278 INFO:     Epoch: 49
2023-01-05 01:12:54,475 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39484468996524813, 'Total loss': 0.39484468996524813} | train loss {'Reaction outcome loss': 0.21194264938254648, 'Total loss': 0.21194264938254648}
2023-01-05 01:12:54,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:54,476 INFO:     Epoch: 50
2023-01-05 01:12:56,733 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3935482711531222, 'Total loss': 0.3935482711531222} | train loss {'Reaction outcome loss': 0.2120270351963353, 'Total loss': 0.2120270351963353}
2023-01-05 01:12:56,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:56,733 INFO:     Epoch: 51
2023-01-05 01:12:58,969 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40689574082692465, 'Total loss': 0.40689574082692465} | train loss {'Reaction outcome loss': 0.20872541782967344, 'Total loss': 0.20872541782967344}
2023-01-05 01:12:58,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:12:58,970 INFO:     Epoch: 52
2023-01-05 01:13:01,220 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4119190474351247, 'Total loss': 0.4119190474351247} | train loss {'Reaction outcome loss': 0.20888966616471752, 'Total loss': 0.20888966616471752}
2023-01-05 01:13:01,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:01,220 INFO:     Epoch: 53
2023-01-05 01:13:03,448 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41285830438137056, 'Total loss': 0.41285830438137056} | train loss {'Reaction outcome loss': 0.2037826917783125, 'Total loss': 0.2037826917783125}
2023-01-05 01:13:03,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:03,448 INFO:     Epoch: 54
2023-01-05 01:13:05,681 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40323563317457833, 'Total loss': 0.40323563317457833} | train loss {'Reaction outcome loss': 0.2042705647324612, 'Total loss': 0.2042705647324612}
2023-01-05 01:13:05,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:05,682 INFO:     Epoch: 55
2023-01-05 01:13:07,837 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39664585987726847, 'Total loss': 0.39664585987726847} | train loss {'Reaction outcome loss': 0.20493996306742787, 'Total loss': 0.20493996306742787}
2023-01-05 01:13:07,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:07,837 INFO:     Epoch: 56
2023-01-05 01:13:10,101 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40810391505559285, 'Total loss': 0.40810391505559285} | train loss {'Reaction outcome loss': 0.19893464497509092, 'Total loss': 0.19893464497509092}
2023-01-05 01:13:10,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:10,101 INFO:     Epoch: 57
2023-01-05 01:13:12,355 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4119187186161677, 'Total loss': 0.4119187186161677} | train loss {'Reaction outcome loss': 0.1985993456593059, 'Total loss': 0.1985993456593059}
2023-01-05 01:13:12,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:12,356 INFO:     Epoch: 58
2023-01-05 01:13:14,549 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4302598128716151, 'Total loss': 0.4302598128716151} | train loss {'Reaction outcome loss': 0.19549496198032684, 'Total loss': 0.19549496198032684}
2023-01-05 01:13:14,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:14,551 INFO:     Epoch: 59
2023-01-05 01:13:16,817 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4251112868388494, 'Total loss': 0.4251112868388494} | train loss {'Reaction outcome loss': 0.1934114297656914, 'Total loss': 0.1934114297656914}
2023-01-05 01:13:16,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:16,818 INFO:     Epoch: 60
2023-01-05 01:13:19,069 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4394735356171926, 'Total loss': 0.4394735356171926} | train loss {'Reaction outcome loss': 0.19602660152940113, 'Total loss': 0.19602660152940113}
2023-01-05 01:13:19,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:19,070 INFO:     Epoch: 61
2023-01-05 01:13:21,342 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3901617407798767, 'Total loss': 0.3901617407798767} | train loss {'Reaction outcome loss': 0.19406916466054072, 'Total loss': 0.19406916466054072}
2023-01-05 01:13:21,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:21,343 INFO:     Epoch: 62
2023-01-05 01:13:23,559 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41142656753460566, 'Total loss': 0.41142656753460566} | train loss {'Reaction outcome loss': 0.19079870611785604, 'Total loss': 0.19079870611785604}
2023-01-05 01:13:23,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:23,559 INFO:     Epoch: 63
2023-01-05 01:13:25,718 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43491769085327786, 'Total loss': 0.43491769085327786} | train loss {'Reaction outcome loss': 0.19266202728455678, 'Total loss': 0.19266202728455678}
2023-01-05 01:13:25,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:25,718 INFO:     Epoch: 64
2023-01-05 01:13:27,990 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.400112513701121, 'Total loss': 0.400112513701121} | train loss {'Reaction outcome loss': 0.19027853356707936, 'Total loss': 0.19027853356707936}
2023-01-05 01:13:27,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:27,990 INFO:     Epoch: 65
2023-01-05 01:13:30,241 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4029023049399257, 'Total loss': 0.4029023049399257} | train loss {'Reaction outcome loss': 0.19303925458126658, 'Total loss': 0.19303925458126658}
2023-01-05 01:13:30,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:30,241 INFO:     Epoch: 66
2023-01-05 01:13:32,452 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4170695802817742, 'Total loss': 0.4170695802817742} | train loss {'Reaction outcome loss': 0.18351527246468388, 'Total loss': 0.18351527246468388}
2023-01-05 01:13:32,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:32,452 INFO:     Epoch: 67
2023-01-05 01:13:34,721 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4077470675110817, 'Total loss': 0.4077470675110817} | train loss {'Reaction outcome loss': 0.18758136709136652, 'Total loss': 0.18758136709136652}
2023-01-05 01:13:34,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:34,722 INFO:     Epoch: 68
2023-01-05 01:13:36,976 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42251938382784526, 'Total loss': 0.42251938382784526} | train loss {'Reaction outcome loss': 0.18512538522952623, 'Total loss': 0.18512538522952623}
2023-01-05 01:13:36,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:36,976 INFO:     Epoch: 69
2023-01-05 01:13:39,159 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4251894474029541, 'Total loss': 0.4251894474029541} | train loss {'Reaction outcome loss': 0.18607148014526773, 'Total loss': 0.18607148014526773}
2023-01-05 01:13:39,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:39,159 INFO:     Epoch: 70
2023-01-05 01:13:41,408 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4019522337708622, 'Total loss': 0.4019522337708622} | train loss {'Reaction outcome loss': 0.1824934842091874, 'Total loss': 0.1824934842091874}
2023-01-05 01:13:41,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:41,408 INFO:     Epoch: 71
2023-01-05 01:13:43,620 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4366732229789098, 'Total loss': 0.4366732229789098} | train loss {'Reaction outcome loss': 0.1826975875086948, 'Total loss': 0.1826975875086948}
2023-01-05 01:13:43,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:43,621 INFO:     Epoch: 72
2023-01-05 01:13:45,855 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41979100505510963, 'Total loss': 0.41979100505510963} | train loss {'Reaction outcome loss': 0.17937261713433353, 'Total loss': 0.17937261713433353}
2023-01-05 01:13:45,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:45,855 INFO:     Epoch: 73
2023-01-05 01:13:48,087 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43827123461912076, 'Total loss': 0.43827123461912076} | train loss {'Reaction outcome loss': 0.18129540743501285, 'Total loss': 0.18129540743501285}
2023-01-05 01:13:48,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:48,087 INFO:     Epoch: 74
2023-01-05 01:13:50,345 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4359508881966273, 'Total loss': 0.4359508881966273} | train loss {'Reaction outcome loss': 0.17931604748322807, 'Total loss': 0.17931604748322807}
2023-01-05 01:13:50,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:50,347 INFO:     Epoch: 75
2023-01-05 01:13:52,616 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41975775361061096, 'Total loss': 0.41975775361061096} | train loss {'Reaction outcome loss': 0.1776606398432882, 'Total loss': 0.1776606398432882}
2023-01-05 01:13:52,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:52,616 INFO:     Epoch: 76
2023-01-05 01:13:54,910 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4075027589996656, 'Total loss': 0.4075027589996656} | train loss {'Reaction outcome loss': 0.1787968103602421, 'Total loss': 0.1787968103602421}
2023-01-05 01:13:54,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:54,910 INFO:     Epoch: 77
2023-01-05 01:13:57,199 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4394513914982478, 'Total loss': 0.4394513914982478} | train loss {'Reaction outcome loss': 0.17415539863845503, 'Total loss': 0.17415539863845503}
2023-01-05 01:13:57,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:57,200 INFO:     Epoch: 78
2023-01-05 01:13:59,485 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4090147982041041, 'Total loss': 0.4090147982041041} | train loss {'Reaction outcome loss': 0.1759457851639051, 'Total loss': 0.1759457851639051}
2023-01-05 01:13:59,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:13:59,485 INFO:     Epoch: 79
2023-01-05 01:14:01,751 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43365193009376524, 'Total loss': 0.43365193009376524} | train loss {'Reaction outcome loss': 0.1744979502942534, 'Total loss': 0.1744979502942534}
2023-01-05 01:14:01,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:01,751 INFO:     Epoch: 80
2023-01-05 01:14:03,991 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43230027208725613, 'Total loss': 0.43230027208725613} | train loss {'Reaction outcome loss': 0.17513699981548725, 'Total loss': 0.17513699981548725}
2023-01-05 01:14:03,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:03,991 INFO:     Epoch: 81
2023-01-05 01:14:06,193 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4185303191343943, 'Total loss': 0.4185303191343943} | train loss {'Reaction outcome loss': 0.17109040254289923, 'Total loss': 0.17109040254289923}
2023-01-05 01:14:06,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:06,193 INFO:     Epoch: 82
2023-01-05 01:14:08,448 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44807271361351014, 'Total loss': 0.44807271361351014} | train loss {'Reaction outcome loss': 0.1733610237787212, 'Total loss': 0.1733610237787212}
2023-01-05 01:14:08,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:08,449 INFO:     Epoch: 83
2023-01-05 01:14:10,715 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42830758889516196, 'Total loss': 0.42830758889516196} | train loss {'Reaction outcome loss': 0.1734382245144958, 'Total loss': 0.1734382245144958}
2023-01-05 01:14:10,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:10,716 INFO:     Epoch: 84
2023-01-05 01:14:12,948 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.413631775478522, 'Total loss': 0.413631775478522} | train loss {'Reaction outcome loss': 0.1694375432200649, 'Total loss': 0.1694375432200649}
2023-01-05 01:14:12,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:12,948 INFO:     Epoch: 85
2023-01-05 01:14:15,228 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41902048339446385, 'Total loss': 0.41902048339446385} | train loss {'Reaction outcome loss': 0.1663216318000471, 'Total loss': 0.1663216318000471}
2023-01-05 01:14:15,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:15,229 INFO:     Epoch: 86
2023-01-05 01:14:17,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41492233872413636, 'Total loss': 0.41492233872413636} | train loss {'Reaction outcome loss': 0.1678397219211186, 'Total loss': 0.1678397219211186}
2023-01-05 01:14:17,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:17,518 INFO:     Epoch: 87
2023-01-05 01:14:19,839 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4073156942923864, 'Total loss': 0.4073156942923864} | train loss {'Reaction outcome loss': 0.1652263768171952, 'Total loss': 0.1652263768171952}
2023-01-05 01:14:19,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:19,839 INFO:     Epoch: 88
2023-01-05 01:14:22,110 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4287115047375361, 'Total loss': 0.4287115047375361} | train loss {'Reaction outcome loss': 0.16334244545165866, 'Total loss': 0.16334244545165866}
2023-01-05 01:14:22,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:22,111 INFO:     Epoch: 89
2023-01-05 01:14:24,314 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40991863210995994, 'Total loss': 0.40991863210995994} | train loss {'Reaction outcome loss': 0.16715391556016213, 'Total loss': 0.16715391556016213}
2023-01-05 01:14:24,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:24,314 INFO:     Epoch: 90
2023-01-05 01:14:26,550 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41609977167099715, 'Total loss': 0.41609977167099715} | train loss {'Reaction outcome loss': 0.16778467067715708, 'Total loss': 0.16778467067715708}
2023-01-05 01:14:26,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:26,552 INFO:     Epoch: 91
2023-01-05 01:14:28,819 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4310018589099248, 'Total loss': 0.4310018589099248} | train loss {'Reaction outcome loss': 0.16761864921152053, 'Total loss': 0.16761864921152053}
2023-01-05 01:14:28,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:28,819 INFO:     Epoch: 92
2023-01-05 01:14:30,984 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4363233081996441, 'Total loss': 0.4363233081996441} | train loss {'Reaction outcome loss': 0.1648640771857076, 'Total loss': 0.1648640771857076}
2023-01-05 01:14:30,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:30,985 INFO:     Epoch: 93
2023-01-05 01:14:33,221 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4451969633499781, 'Total loss': 0.4451969633499781} | train loss {'Reaction outcome loss': 0.16751258893926974, 'Total loss': 0.16751258893926974}
2023-01-05 01:14:33,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:33,222 INFO:     Epoch: 94
2023-01-05 01:14:35,451 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4458763172229131, 'Total loss': 0.4458763172229131} | train loss {'Reaction outcome loss': 0.1612743401617511, 'Total loss': 0.1612743401617511}
2023-01-05 01:14:35,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:35,451 INFO:     Epoch: 95
2023-01-05 01:14:37,693 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.434163569410642, 'Total loss': 0.434163569410642} | train loss {'Reaction outcome loss': 0.16012700308712757, 'Total loss': 0.16012700308712757}
2023-01-05 01:14:37,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:37,693 INFO:     Epoch: 96
2023-01-05 01:14:39,939 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4305711214741071, 'Total loss': 0.4305711214741071} | train loss {'Reaction outcome loss': 0.1597439920048932, 'Total loss': 0.1597439920048932}
2023-01-05 01:14:39,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:39,940 INFO:     Epoch: 97
2023-01-05 01:14:42,198 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4159739712874095, 'Total loss': 0.4159739712874095} | train loss {'Reaction outcome loss': 0.15936410509298693, 'Total loss': 0.15936410509298693}
2023-01-05 01:14:42,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:42,198 INFO:     Epoch: 98
2023-01-05 01:14:44,427 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4434743742148081, 'Total loss': 0.4434743742148081} | train loss {'Reaction outcome loss': 0.1580633432251344, 'Total loss': 0.1580633432251344}
2023-01-05 01:14:44,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:44,427 INFO:     Epoch: 99
2023-01-05 01:14:46,683 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46804474691549935, 'Total loss': 0.46804474691549935} | train loss {'Reaction outcome loss': 0.16413328906568272, 'Total loss': 0.16413328906568272}
2023-01-05 01:14:46,684 INFO:     Best model found after epoch 36 of 100.
2023-01-05 01:14:46,684 INFO:   Done with stage: TRAINING
2023-01-05 01:14:46,684 INFO:   Starting stage: EVALUATION
2023-01-05 01:14:46,811 INFO:   Done with stage: EVALUATION
2023-01-05 01:14:46,811 INFO:   Leaving out SEQ value Fold_6
2023-01-05 01:14:46,824 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 01:14:46,824 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:14:47,489 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:14:47,489 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:14:47,560 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:14:47,560 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:14:47,560 INFO:     No hyperparam tuning for this model
2023-01-05 01:14:47,560 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:14:47,560 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:14:47,561 INFO:     None feature selector for col prot
2023-01-05 01:14:47,561 INFO:     None feature selector for col prot
2023-01-05 01:14:47,561 INFO:     None feature selector for col prot
2023-01-05 01:14:47,562 INFO:     None feature selector for col chem
2023-01-05 01:14:47,562 INFO:     None feature selector for col chem
2023-01-05 01:14:47,562 INFO:     None feature selector for col chem
2023-01-05 01:14:47,562 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:14:47,562 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:14:47,564 INFO:     Number of params in model 72931
2023-01-05 01:14:47,567 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:14:47,567 INFO:   Starting stage: TRAINING
2023-01-05 01:14:47,628 INFO:     Val loss before train {'Reaction outcome loss': 0.9239234526952108, 'Total loss': 0.9239234526952108}
2023-01-05 01:14:47,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:47,628 INFO:     Epoch: 0
2023-01-05 01:14:49,897 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7458902657032013, 'Total loss': 0.7458902657032013} | train loss {'Reaction outcome loss': 0.9510611464615764, 'Total loss': 0.9510611464615764}
2023-01-05 01:14:49,897 INFO:     Found new best model at epoch 0
2023-01-05 01:14:49,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:49,898 INFO:     Epoch: 1
2023-01-05 01:14:52,129 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5373596618572871, 'Total loss': 0.5373596618572871} | train loss {'Reaction outcome loss': 0.6646295387822369, 'Total loss': 0.6646295387822369}
2023-01-05 01:14:52,129 INFO:     Found new best model at epoch 1
2023-01-05 01:14:52,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:52,131 INFO:     Epoch: 2
2023-01-05 01:14:54,403 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5031831701596577, 'Total loss': 0.5031831701596577} | train loss {'Reaction outcome loss': 0.5459180883659783, 'Total loss': 0.5459180883659783}
2023-01-05 01:14:54,403 INFO:     Found new best model at epoch 2
2023-01-05 01:14:54,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:54,405 INFO:     Epoch: 3
2023-01-05 01:14:56,677 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47476982374986015, 'Total loss': 0.47476982374986015} | train loss {'Reaction outcome loss': 0.5050289952582832, 'Total loss': 0.5050289952582832}
2023-01-05 01:14:56,677 INFO:     Found new best model at epoch 3
2023-01-05 01:14:56,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:56,679 INFO:     Epoch: 4
2023-01-05 01:14:58,944 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4682405153910319, 'Total loss': 0.4682405153910319} | train loss {'Reaction outcome loss': 0.4796375675321916, 'Total loss': 0.4796375675321916}
2023-01-05 01:14:58,945 INFO:     Found new best model at epoch 4
2023-01-05 01:14:58,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:14:58,946 INFO:     Epoch: 5
2023-01-05 01:15:01,185 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44358795682589214, 'Total loss': 0.44358795682589214} | train loss {'Reaction outcome loss': 0.45866936439856726, 'Total loss': 0.45866936439856726}
2023-01-05 01:15:01,185 INFO:     Found new best model at epoch 5
2023-01-05 01:15:01,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:01,187 INFO:     Epoch: 6
2023-01-05 01:15:03,445 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4569607804218928, 'Total loss': 0.4569607804218928} | train loss {'Reaction outcome loss': 0.44019433027570426, 'Total loss': 0.44019433027570426}
2023-01-05 01:15:03,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:03,447 INFO:     Epoch: 7
2023-01-05 01:15:05,700 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4214710017045339, 'Total loss': 0.4214710017045339} | train loss {'Reaction outcome loss': 0.4294430911540985, 'Total loss': 0.4294430911540985}
2023-01-05 01:15:05,700 INFO:     Found new best model at epoch 7
2023-01-05 01:15:05,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:05,701 INFO:     Epoch: 8
2023-01-05 01:15:07,973 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4054810032248497, 'Total loss': 0.4054810032248497} | train loss {'Reaction outcome loss': 0.4150570487664064, 'Total loss': 0.4150570487664064}
2023-01-05 01:15:07,973 INFO:     Found new best model at epoch 8
2023-01-05 01:15:07,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:07,975 INFO:     Epoch: 9
2023-01-05 01:15:10,228 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42647372086842855, 'Total loss': 0.42647372086842855} | train loss {'Reaction outcome loss': 0.4047515368364778, 'Total loss': 0.4047515368364778}
2023-01-05 01:15:10,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:10,229 INFO:     Epoch: 10
2023-01-05 01:15:12,479 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4204628308614095, 'Total loss': 0.4204628308614095} | train loss {'Reaction outcome loss': 0.39424134244880094, 'Total loss': 0.39424134244880094}
2023-01-05 01:15:12,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:12,480 INFO:     Epoch: 11
2023-01-05 01:15:14,721 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3822604313492775, 'Total loss': 0.3822604313492775} | train loss {'Reaction outcome loss': 0.3842884527270544, 'Total loss': 0.3842884527270544}
2023-01-05 01:15:14,722 INFO:     Found new best model at epoch 11
2023-01-05 01:15:14,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:14,723 INFO:     Epoch: 12
2023-01-05 01:15:16,961 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4102096567551295, 'Total loss': 0.4102096567551295} | train loss {'Reaction outcome loss': 0.3711894687386196, 'Total loss': 0.3711894687386196}
2023-01-05 01:15:16,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:16,961 INFO:     Epoch: 13
2023-01-05 01:15:19,208 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39972784419854485, 'Total loss': 0.39972784419854485} | train loss {'Reaction outcome loss': 0.3631516797232714, 'Total loss': 0.3631516797232714}
2023-01-05 01:15:19,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:19,208 INFO:     Epoch: 14
2023-01-05 01:15:21,468 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39833652873833975, 'Total loss': 0.39833652873833975} | train loss {'Reaction outcome loss': 0.3569584278262049, 'Total loss': 0.3569584278262049}
2023-01-05 01:15:21,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:21,468 INFO:     Epoch: 15
2023-01-05 01:15:23,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4133247057596842, 'Total loss': 0.4133247057596842} | train loss {'Reaction outcome loss': 0.3473863913694444, 'Total loss': 0.3473863913694444}
2023-01-05 01:15:23,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:23,734 INFO:     Epoch: 16
2023-01-05 01:15:25,924 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3746492365996043, 'Total loss': 0.3746492365996043} | train loss {'Reaction outcome loss': 0.33689649131431476, 'Total loss': 0.33689649131431476}
2023-01-05 01:15:25,924 INFO:     Found new best model at epoch 16
2023-01-05 01:15:25,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:25,925 INFO:     Epoch: 17
2023-01-05 01:15:28,194 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40774283905824027, 'Total loss': 0.40774283905824027} | train loss {'Reaction outcome loss': 0.33253820021283753, 'Total loss': 0.33253820021283753}
2023-01-05 01:15:28,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:28,194 INFO:     Epoch: 18
2023-01-05 01:15:30,466 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.370446248849233, 'Total loss': 0.370446248849233} | train loss {'Reaction outcome loss': 0.3278581549544627, 'Total loss': 0.3278581549544627}
2023-01-05 01:15:30,466 INFO:     Found new best model at epoch 18
2023-01-05 01:15:30,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:30,468 INFO:     Epoch: 19
2023-01-05 01:15:32,769 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40858719845612845, 'Total loss': 0.40858719845612845} | train loss {'Reaction outcome loss': 0.31887186981656923, 'Total loss': 0.31887186981656923}
2023-01-05 01:15:32,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:32,770 INFO:     Epoch: 20
2023-01-05 01:15:35,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3828107963005702, 'Total loss': 0.3828107963005702} | train loss {'Reaction outcome loss': 0.31070089306588206, 'Total loss': 0.31070089306588206}
2023-01-05 01:15:35,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:35,020 INFO:     Epoch: 21
2023-01-05 01:15:37,207 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3979910877843698, 'Total loss': 0.3979910877843698} | train loss {'Reaction outcome loss': 0.30561503396783063, 'Total loss': 0.30561503396783063}
2023-01-05 01:15:37,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:37,207 INFO:     Epoch: 22
2023-01-05 01:15:39,450 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4183460195859273, 'Total loss': 0.4183460195859273} | train loss {'Reaction outcome loss': 0.30448317694534893, 'Total loss': 0.30448317694534893}
2023-01-05 01:15:39,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:39,452 INFO:     Epoch: 23
2023-01-05 01:15:41,731 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3945237139860789, 'Total loss': 0.3945237139860789} | train loss {'Reaction outcome loss': 0.30020210150938603, 'Total loss': 0.30020210150938603}
2023-01-05 01:15:41,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:41,731 INFO:     Epoch: 24
2023-01-05 01:15:44,008 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38403427302837373, 'Total loss': 0.38403427302837373} | train loss {'Reaction outcome loss': 0.2891968887312748, 'Total loss': 0.2891968887312748}
2023-01-05 01:15:44,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:44,009 INFO:     Epoch: 25
2023-01-05 01:15:46,280 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3950708607832591, 'Total loss': 0.3950708607832591} | train loss {'Reaction outcome loss': 0.2921238351976398, 'Total loss': 0.2921238351976398}
2023-01-05 01:15:46,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:46,281 INFO:     Epoch: 26
2023-01-05 01:15:48,570 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42865343689918517, 'Total loss': 0.42865343689918517} | train loss {'Reaction outcome loss': 0.2821904567981455, 'Total loss': 0.2821904567981455}
2023-01-05 01:15:48,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:48,570 INFO:     Epoch: 27
2023-01-05 01:15:50,817 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39408214886983234, 'Total loss': 0.39408214886983234} | train loss {'Reaction outcome loss': 0.27963170871837906, 'Total loss': 0.27963170871837906}
2023-01-05 01:15:50,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:50,817 INFO:     Epoch: 28
2023-01-05 01:15:53,098 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40298068126042685, 'Total loss': 0.40298068126042685} | train loss {'Reaction outcome loss': 0.2738519653422415, 'Total loss': 0.2738519653422415}
2023-01-05 01:15:53,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:53,099 INFO:     Epoch: 29
2023-01-05 01:15:55,378 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4184000561634699, 'Total loss': 0.4184000561634699} | train loss {'Reaction outcome loss': 0.2730165370252481, 'Total loss': 0.2730165370252481}
2023-01-05 01:15:55,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:55,379 INFO:     Epoch: 30
2023-01-05 01:15:57,641 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4344496707121531, 'Total loss': 0.4344496707121531} | train loss {'Reaction outcome loss': 0.2729770504476146, 'Total loss': 0.2729770504476146}
2023-01-05 01:15:57,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:57,641 INFO:     Epoch: 31
2023-01-05 01:15:59,813 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4183493415514628, 'Total loss': 0.4183493415514628} | train loss {'Reaction outcome loss': 0.2641263939541116, 'Total loss': 0.2641263939541116}
2023-01-05 01:15:59,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:15:59,814 INFO:     Epoch: 32
2023-01-05 01:16:02,068 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.423002556959788, 'Total loss': 0.423002556959788} | train loss {'Reaction outcome loss': 0.260612217131128, 'Total loss': 0.260612217131128}
2023-01-05 01:16:02,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:02,068 INFO:     Epoch: 33
2023-01-05 01:16:04,223 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4166906148195267, 'Total loss': 0.4166906148195267} | train loss {'Reaction outcome loss': 0.257365659491196, 'Total loss': 0.257365659491196}
2023-01-05 01:16:04,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:04,223 INFO:     Epoch: 34
2023-01-05 01:16:06,501 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41063370803991955, 'Total loss': 0.41063370803991955} | train loss {'Reaction outcome loss': 0.2576884267555839, 'Total loss': 0.2576884267555839}
2023-01-05 01:16:06,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:06,501 INFO:     Epoch: 35
2023-01-05 01:16:08,729 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44215010305245717, 'Total loss': 0.44215010305245717} | train loss {'Reaction outcome loss': 0.25103545791405635, 'Total loss': 0.25103545791405635}
2023-01-05 01:16:08,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:08,731 INFO:     Epoch: 36
2023-01-05 01:16:10,978 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3833681444327037, 'Total loss': 0.3833681444327037} | train loss {'Reaction outcome loss': 0.24668600619350314, 'Total loss': 0.24668600619350314}
2023-01-05 01:16:10,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:10,978 INFO:     Epoch: 37
2023-01-05 01:16:13,290 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39592576026916504, 'Total loss': 0.39592576026916504} | train loss {'Reaction outcome loss': 0.24960904766802108, 'Total loss': 0.24960904766802108}
2023-01-05 01:16:13,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:13,290 INFO:     Epoch: 38
2023-01-05 01:16:15,613 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4096948007742564, 'Total loss': 0.4096948007742564} | train loss {'Reaction outcome loss': 0.2430582382995299, 'Total loss': 0.2430582382995299}
2023-01-05 01:16:15,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:15,614 INFO:     Epoch: 39
2023-01-05 01:16:17,935 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39831301420927046, 'Total loss': 0.39831301420927046} | train loss {'Reaction outcome loss': 0.2447313770302151, 'Total loss': 0.2447313770302151}
2023-01-05 01:16:17,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:17,936 INFO:     Epoch: 40
2023-01-05 01:16:20,199 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.406661464770635, 'Total loss': 0.406661464770635} | train loss {'Reaction outcome loss': 0.24505717213860703, 'Total loss': 0.24505717213860703}
2023-01-05 01:16:20,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:20,199 INFO:     Epoch: 41
2023-01-05 01:16:22,471 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42064309964577357, 'Total loss': 0.42064309964577357} | train loss {'Reaction outcome loss': 0.24205974299823765, 'Total loss': 0.24205974299823765}
2023-01-05 01:16:22,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:22,471 INFO:     Epoch: 42
2023-01-05 01:16:24,746 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4246151477098465, 'Total loss': 0.4246151477098465} | train loss {'Reaction outcome loss': 0.23749197515178244, 'Total loss': 0.23749197515178244}
2023-01-05 01:16:24,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:24,747 INFO:     Epoch: 43
2023-01-05 01:16:26,965 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38812187214692434, 'Total loss': 0.38812187214692434} | train loss {'Reaction outcome loss': 0.2399466134816247, 'Total loss': 0.2399466134816247}
2023-01-05 01:16:26,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:26,965 INFO:     Epoch: 44
2023-01-05 01:16:29,236 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4070615490277608, 'Total loss': 0.4070615490277608} | train loss {'Reaction outcome loss': 0.2350973421741371, 'Total loss': 0.2350973421741371}
2023-01-05 01:16:29,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:29,236 INFO:     Epoch: 45
2023-01-05 01:16:31,493 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39603006318211553, 'Total loss': 0.39603006318211553} | train loss {'Reaction outcome loss': 0.2319772757643612, 'Total loss': 0.2319772757643612}
2023-01-05 01:16:31,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:31,493 INFO:     Epoch: 46
2023-01-05 01:16:33,766 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40624527831872304, 'Total loss': 0.40624527831872304} | train loss {'Reaction outcome loss': 0.2328054522187701, 'Total loss': 0.2328054522187701}
2023-01-05 01:16:33,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:33,766 INFO:     Epoch: 47
2023-01-05 01:16:36,041 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4739548057317734, 'Total loss': 0.4739548057317734} | train loss {'Reaction outcome loss': 0.22485194657172752, 'Total loss': 0.22485194657172752}
2023-01-05 01:16:36,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:36,042 INFO:     Epoch: 48
2023-01-05 01:16:38,284 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4222167760133743, 'Total loss': 0.4222167760133743} | train loss {'Reaction outcome loss': 0.2302384477895466, 'Total loss': 0.2302384477895466}
2023-01-05 01:16:38,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:38,284 INFO:     Epoch: 49
2023-01-05 01:16:40,554 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4002817690372467, 'Total loss': 0.4002817690372467} | train loss {'Reaction outcome loss': 0.224984252549681, 'Total loss': 0.224984252549681}
2023-01-05 01:16:40,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:40,555 INFO:     Epoch: 50
2023-01-05 01:16:42,807 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40811682095130286, 'Total loss': 0.40811682095130286} | train loss {'Reaction outcome loss': 0.22208858448474092, 'Total loss': 0.22208858448474092}
2023-01-05 01:16:42,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:42,807 INFO:     Epoch: 51
2023-01-05 01:16:45,034 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38726030389467875, 'Total loss': 0.38726030389467875} | train loss {'Reaction outcome loss': 0.22154218785545457, 'Total loss': 0.22154218785545457}
2023-01-05 01:16:45,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:45,035 INFO:     Epoch: 52
2023-01-05 01:16:47,301 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41118577470382056, 'Total loss': 0.41118577470382056} | train loss {'Reaction outcome loss': 0.22022866525616672, 'Total loss': 0.22022866525616672}
2023-01-05 01:16:47,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:47,301 INFO:     Epoch: 53
2023-01-05 01:16:49,546 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3731426785389582, 'Total loss': 0.3731426785389582} | train loss {'Reaction outcome loss': 0.21463644626257866, 'Total loss': 0.21463644626257866}
2023-01-05 01:16:49,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:49,546 INFO:     Epoch: 54
2023-01-05 01:16:51,824 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3719058334827423, 'Total loss': 0.3719058334827423} | train loss {'Reaction outcome loss': 0.21882321497270776, 'Total loss': 0.21882321497270776}
2023-01-05 01:16:51,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:51,825 INFO:     Epoch: 55
2023-01-05 01:16:54,080 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38357093979914986, 'Total loss': 0.38357093979914986} | train loss {'Reaction outcome loss': 0.2152711651842732, 'Total loss': 0.2152711651842732}
2023-01-05 01:16:54,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:54,081 INFO:     Epoch: 56
2023-01-05 01:16:56,335 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4242355103294055, 'Total loss': 0.4242355103294055} | train loss {'Reaction outcome loss': 0.21504783596076904, 'Total loss': 0.21504783596076904}
2023-01-05 01:16:56,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:56,335 INFO:     Epoch: 57
2023-01-05 01:16:58,602 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4183954914410909, 'Total loss': 0.4183954914410909} | train loss {'Reaction outcome loss': 0.21071619618791643, 'Total loss': 0.21071619618791643}
2023-01-05 01:16:58,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:16:58,603 INFO:     Epoch: 58
2023-01-05 01:17:00,857 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38759622573852537, 'Total loss': 0.38759622573852537} | train loss {'Reaction outcome loss': 0.21165993249897816, 'Total loss': 0.21165993249897816}
2023-01-05 01:17:00,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:00,858 INFO:     Epoch: 59
2023-01-05 01:17:03,125 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40426164666811626, 'Total loss': 0.40426164666811626} | train loss {'Reaction outcome loss': 0.21000662714323629, 'Total loss': 0.21000662714323629}
2023-01-05 01:17:03,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:03,125 INFO:     Epoch: 60
2023-01-05 01:17:05,371 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39145655632019044, 'Total loss': 0.39145655632019044} | train loss {'Reaction outcome loss': 0.203812177128256, 'Total loss': 0.203812177128256}
2023-01-05 01:17:05,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:05,372 INFO:     Epoch: 61
2023-01-05 01:17:07,624 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4172035445769628, 'Total loss': 0.4172035445769628} | train loss {'Reaction outcome loss': 0.2036074450414372, 'Total loss': 0.2036074450414372}
2023-01-05 01:17:07,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:07,624 INFO:     Epoch: 62
2023-01-05 01:17:09,851 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4064376413822174, 'Total loss': 0.4064376413822174} | train loss {'Reaction outcome loss': 0.2020498982055738, 'Total loss': 0.2020498982055738}
2023-01-05 01:17:09,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:09,851 INFO:     Epoch: 63
2023-01-05 01:17:12,073 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40719006061553953, 'Total loss': 0.40719006061553953} | train loss {'Reaction outcome loss': 0.19953130185604095, 'Total loss': 0.19953130185604095}
2023-01-05 01:17:12,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:12,073 INFO:     Epoch: 64
2023-01-05 01:17:14,286 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4206942250331243, 'Total loss': 0.4206942250331243} | train loss {'Reaction outcome loss': 0.20435759316565005, 'Total loss': 0.20435759316565005}
2023-01-05 01:17:14,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:14,286 INFO:     Epoch: 65
2023-01-05 01:17:16,558 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4256720205148061, 'Total loss': 0.4256720205148061} | train loss {'Reaction outcome loss': 0.20234887183237055, 'Total loss': 0.20234887183237055}
2023-01-05 01:17:16,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:16,558 INFO:     Epoch: 66
2023-01-05 01:17:18,795 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4446705460548401, 'Total loss': 0.4446705460548401} | train loss {'Reaction outcome loss': 0.20100372206312117, 'Total loss': 0.20100372206312117}
2023-01-05 01:17:18,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:18,795 INFO:     Epoch: 67
2023-01-05 01:17:21,029 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4010860830545425, 'Total loss': 0.4010860830545425} | train loss {'Reaction outcome loss': 0.20111840935121375, 'Total loss': 0.20111840935121375}
2023-01-05 01:17:21,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:21,030 INFO:     Epoch: 68
2023-01-05 01:17:23,298 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44068043331305184, 'Total loss': 0.44068043331305184} | train loss {'Reaction outcome loss': 0.1946242617423031, 'Total loss': 0.1946242617423031}
2023-01-05 01:17:23,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:23,298 INFO:     Epoch: 69
2023-01-05 01:17:25,455 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4174398263295492, 'Total loss': 0.4174398263295492} | train loss {'Reaction outcome loss': 0.19567825097846211, 'Total loss': 0.19567825097846211}
2023-01-05 01:17:25,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:25,455 INFO:     Epoch: 70
2023-01-05 01:17:27,709 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43203006088733675, 'Total loss': 0.43203006088733675} | train loss {'Reaction outcome loss': 0.19791176224577944, 'Total loss': 0.19791176224577944}
2023-01-05 01:17:27,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:27,710 INFO:     Epoch: 71
2023-01-05 01:17:29,941 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42323387463887535, 'Total loss': 0.42323387463887535} | train loss {'Reaction outcome loss': 0.19328584604382193, 'Total loss': 0.19328584604382193}
2023-01-05 01:17:29,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:29,941 INFO:     Epoch: 72
2023-01-05 01:17:32,182 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41309160689512886, 'Total loss': 0.41309160689512886} | train loss {'Reaction outcome loss': 0.19501024422097937, 'Total loss': 0.19501024422097937}
2023-01-05 01:17:32,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:32,182 INFO:     Epoch: 73
2023-01-05 01:17:34,451 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43411442438761394, 'Total loss': 0.43411442438761394} | train loss {'Reaction outcome loss': 0.18931117616190377, 'Total loss': 0.18931117616190377}
2023-01-05 01:17:34,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:34,451 INFO:     Epoch: 74
2023-01-05 01:17:36,645 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4065287450949351, 'Total loss': 0.4065287450949351} | train loss {'Reaction outcome loss': 0.19711575478933993, 'Total loss': 0.19711575478933993}
2023-01-05 01:17:36,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:36,645 INFO:     Epoch: 75
2023-01-05 01:17:38,825 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40371154993772507, 'Total loss': 0.40371154993772507} | train loss {'Reaction outcome loss': 0.1884690394342645, 'Total loss': 0.1884690394342645}
2023-01-05 01:17:38,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:38,825 INFO:     Epoch: 76
2023-01-05 01:17:41,043 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4399857143561045, 'Total loss': 0.4399857143561045} | train loss {'Reaction outcome loss': 0.19779535906476772, 'Total loss': 0.19779535906476772}
2023-01-05 01:17:41,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:41,044 INFO:     Epoch: 77
2023-01-05 01:17:43,277 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44097196161746977, 'Total loss': 0.44097196161746977} | train loss {'Reaction outcome loss': 0.1892622236199408, 'Total loss': 0.1892622236199408}
2023-01-05 01:17:43,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:43,277 INFO:     Epoch: 78
2023-01-05 01:17:45,554 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41477834681669873, 'Total loss': 0.41477834681669873} | train loss {'Reaction outcome loss': 0.1864159538642594, 'Total loss': 0.1864159538642594}
2023-01-05 01:17:45,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:45,554 INFO:     Epoch: 79
2023-01-05 01:17:47,812 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4242509494225184, 'Total loss': 0.4242509494225184} | train loss {'Reaction outcome loss': 0.18496712165403884, 'Total loss': 0.18496712165403884}
2023-01-05 01:17:47,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:47,812 INFO:     Epoch: 80
2023-01-05 01:17:50,089 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4023648197452227, 'Total loss': 0.4023648197452227} | train loss {'Reaction outcome loss': 0.18952103859546598, 'Total loss': 0.18952103859546598}
2023-01-05 01:17:50,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:50,089 INFO:     Epoch: 81
2023-01-05 01:17:52,375 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41695985198020935, 'Total loss': 0.41695985198020935} | train loss {'Reaction outcome loss': 0.18582051293420124, 'Total loss': 0.18582051293420124}
2023-01-05 01:17:52,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:52,375 INFO:     Epoch: 82
2023-01-05 01:17:54,625 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39166428372263906, 'Total loss': 0.39166428372263906} | train loss {'Reaction outcome loss': 0.1886532274083258, 'Total loss': 0.1886532274083258}
2023-01-05 01:17:54,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:54,625 INFO:     Epoch: 83
2023-01-05 01:17:56,869 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4358635887503624, 'Total loss': 0.4358635887503624} | train loss {'Reaction outcome loss': 0.17932606991783914, 'Total loss': 0.17932606991783914}
2023-01-05 01:17:56,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:56,870 INFO:     Epoch: 84
2023-01-05 01:17:59,139 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4565414289633433, 'Total loss': 0.4565414289633433} | train loss {'Reaction outcome loss': 0.18143210263203305, 'Total loss': 0.18143210263203305}
2023-01-05 01:17:59,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:17:59,139 INFO:     Epoch: 85
2023-01-05 01:18:01,372 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44038571616013844, 'Total loss': 0.44038571616013844} | train loss {'Reaction outcome loss': 0.17791326196413715, 'Total loss': 0.17791326196413715}
2023-01-05 01:18:01,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:01,372 INFO:     Epoch: 86
2023-01-05 01:18:03,642 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4287912517786026, 'Total loss': 0.4287912517786026} | train loss {'Reaction outcome loss': 0.17890147737896453, 'Total loss': 0.17890147737896453}
2023-01-05 01:18:03,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:03,643 INFO:     Epoch: 87
2023-01-05 01:18:05,861 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4538580576578776, 'Total loss': 0.4538580576578776} | train loss {'Reaction outcome loss': 0.17557717233035539, 'Total loss': 0.17557717233035539}
2023-01-05 01:18:05,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:05,861 INFO:     Epoch: 88
2023-01-05 01:18:08,111 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4220264812310537, 'Total loss': 0.4220264812310537} | train loss {'Reaction outcome loss': 0.18073179958462177, 'Total loss': 0.18073179958462177}
2023-01-05 01:18:08,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:08,111 INFO:     Epoch: 89
2023-01-05 01:18:10,376 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43740652203559877, 'Total loss': 0.43740652203559877} | train loss {'Reaction outcome loss': 0.17813524402785602, 'Total loss': 0.17813524402785602}
2023-01-05 01:18:10,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:10,376 INFO:     Epoch: 90
2023-01-05 01:18:12,637 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4325865715742111, 'Total loss': 0.4325865715742111} | train loss {'Reaction outcome loss': 0.17686220472981137, 'Total loss': 0.17686220472981137}
2023-01-05 01:18:12,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:12,637 INFO:     Epoch: 91
2023-01-05 01:18:14,912 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.423220694065094, 'Total loss': 0.423220694065094} | train loss {'Reaction outcome loss': 0.17716499410455352, 'Total loss': 0.17716499410455352}
2023-01-05 01:18:14,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:14,912 INFO:     Epoch: 92
2023-01-05 01:18:17,172 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43396340707937875, 'Total loss': 0.43396340707937875} | train loss {'Reaction outcome loss': 0.1754055553072196, 'Total loss': 0.1754055553072196}
2023-01-05 01:18:17,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:17,173 INFO:     Epoch: 93
2023-01-05 01:18:19,446 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43360538184642794, 'Total loss': 0.43360538184642794} | train loss {'Reaction outcome loss': 0.17658459375669594, 'Total loss': 0.17658459375669594}
2023-01-05 01:18:19,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:19,446 INFO:     Epoch: 94
2023-01-05 01:18:21,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4149872109293938, 'Total loss': 0.4149872109293938} | train loss {'Reaction outcome loss': 0.18145610304004664, 'Total loss': 0.18145610304004664}
2023-01-05 01:18:21,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:21,754 INFO:     Epoch: 95
2023-01-05 01:18:24,008 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4304282866418362, 'Total loss': 0.4304282866418362} | train loss {'Reaction outcome loss': 0.17681344820939623, 'Total loss': 0.17681344820939623}
2023-01-05 01:18:24,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:24,008 INFO:     Epoch: 96
2023-01-05 01:18:26,235 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4218154420455297, 'Total loss': 0.4218154420455297} | train loss {'Reaction outcome loss': 0.1725609030672063, 'Total loss': 0.1725609030672063}
2023-01-05 01:18:26,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:26,235 INFO:     Epoch: 97
2023-01-05 01:18:28,489 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39510534380873047, 'Total loss': 0.39510534380873047} | train loss {'Reaction outcome loss': 0.1740152196057598, 'Total loss': 0.1740152196057598}
2023-01-05 01:18:28,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:28,490 INFO:     Epoch: 98
2023-01-05 01:18:30,768 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4164515773455302, 'Total loss': 0.4164515773455302} | train loss {'Reaction outcome loss': 0.17903734286171166, 'Total loss': 0.17903734286171166}
2023-01-05 01:18:30,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:30,768 INFO:     Epoch: 99
2023-01-05 01:18:33,020 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43575617323319116, 'Total loss': 0.43575617323319116} | train loss {'Reaction outcome loss': 0.17159430925912536, 'Total loss': 0.17159430925912536}
2023-01-05 01:18:33,021 INFO:     Best model found after epoch 19 of 100.
2023-01-05 01:18:33,022 INFO:   Done with stage: TRAINING
2023-01-05 01:18:33,022 INFO:   Starting stage: EVALUATION
2023-01-05 01:18:33,149 INFO:   Done with stage: EVALUATION
2023-01-05 01:18:33,149 INFO:   Leaving out SEQ value Fold_7
2023-01-05 01:18:33,162 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 01:18:33,162 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:18:33,803 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:18:33,804 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:18:33,873 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:18:33,873 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:18:33,873 INFO:     No hyperparam tuning for this model
2023-01-05 01:18:33,873 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:18:33,873 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:18:33,874 INFO:     None feature selector for col prot
2023-01-05 01:18:33,874 INFO:     None feature selector for col prot
2023-01-05 01:18:33,874 INFO:     None feature selector for col prot
2023-01-05 01:18:33,875 INFO:     None feature selector for col chem
2023-01-05 01:18:33,875 INFO:     None feature selector for col chem
2023-01-05 01:18:33,875 INFO:     None feature selector for col chem
2023-01-05 01:18:33,875 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:18:33,875 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:18:33,876 INFO:     Number of params in model 72931
2023-01-05 01:18:33,880 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:18:33,880 INFO:   Starting stage: TRAINING
2023-01-05 01:18:33,939 INFO:     Val loss before train {'Reaction outcome loss': 1.0886932889620462, 'Total loss': 1.0886932889620462}
2023-01-05 01:18:33,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:33,939 INFO:     Epoch: 0
2023-01-05 01:18:36,186 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7546052316824595, 'Total loss': 0.7546052316824595} | train loss {'Reaction outcome loss': 0.8958985864461123, 'Total loss': 0.8958985864461123}
2023-01-05 01:18:36,186 INFO:     Found new best model at epoch 0
2023-01-05 01:18:36,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:36,188 INFO:     Epoch: 1
2023-01-05 01:18:38,260 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6002745469411214, 'Total loss': 0.6002745469411214} | train loss {'Reaction outcome loss': 0.5926175206735894, 'Total loss': 0.5926175206735894}
2023-01-05 01:18:38,260 INFO:     Found new best model at epoch 1
2023-01-05 01:18:38,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:38,261 INFO:     Epoch: 2
2023-01-05 01:18:40,488 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5702620287736256, 'Total loss': 0.5702620287736256} | train loss {'Reaction outcome loss': 0.51416770922832, 'Total loss': 0.51416770922832}
2023-01-05 01:18:40,489 INFO:     Found new best model at epoch 2
2023-01-05 01:18:40,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:40,490 INFO:     Epoch: 3
2023-01-05 01:18:42,712 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5273929893970489, 'Total loss': 0.5273929893970489} | train loss {'Reaction outcome loss': 0.4754247006315451, 'Total loss': 0.4754247006315451}
2023-01-05 01:18:42,713 INFO:     Found new best model at epoch 3
2023-01-05 01:18:42,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:42,714 INFO:     Epoch: 4
2023-01-05 01:18:44,960 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5356967935959498, 'Total loss': 0.5356967935959498} | train loss {'Reaction outcome loss': 0.4500274112441273, 'Total loss': 0.4500274112441273}
2023-01-05 01:18:44,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:44,960 INFO:     Epoch: 5
2023-01-05 01:18:47,171 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49909047881762186, 'Total loss': 0.49909047881762186} | train loss {'Reaction outcome loss': 0.4293764330004939, 'Total loss': 0.4293764330004939}
2023-01-05 01:18:47,171 INFO:     Found new best model at epoch 5
2023-01-05 01:18:47,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:47,172 INFO:     Epoch: 6
2023-01-05 01:18:49,305 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5070053478082021, 'Total loss': 0.5070053478082021} | train loss {'Reaction outcome loss': 0.4170468639439115, 'Total loss': 0.4170468639439115}
2023-01-05 01:18:49,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:49,305 INFO:     Epoch: 7
2023-01-05 01:18:51,480 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48050286372502643, 'Total loss': 0.48050286372502643} | train loss {'Reaction outcome loss': 0.40069098448578694, 'Total loss': 0.40069098448578694}
2023-01-05 01:18:51,480 INFO:     Found new best model at epoch 7
2023-01-05 01:18:51,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:51,482 INFO:     Epoch: 8
2023-01-05 01:18:53,661 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5481078525384268, 'Total loss': 0.5481078525384268} | train loss {'Reaction outcome loss': 0.3866776789115544, 'Total loss': 0.3866776789115544}
2023-01-05 01:18:53,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:53,662 INFO:     Epoch: 9
2023-01-05 01:18:55,893 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49471996823946635, 'Total loss': 0.49471996823946635} | train loss {'Reaction outcome loss': 0.3765815033034964, 'Total loss': 0.3765815033034964}
2023-01-05 01:18:55,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:55,893 INFO:     Epoch: 10
2023-01-05 01:18:58,117 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4682285487651825, 'Total loss': 0.4682285487651825} | train loss {'Reaction outcome loss': 0.3693719846315873, 'Total loss': 0.3693719846315873}
2023-01-05 01:18:58,117 INFO:     Found new best model at epoch 10
2023-01-05 01:18:58,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:18:58,118 INFO:     Epoch: 11
2023-01-05 01:19:00,352 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5000150740146637, 'Total loss': 0.5000150740146637} | train loss {'Reaction outcome loss': 0.3591406972526194, 'Total loss': 0.3591406972526194}
2023-01-05 01:19:00,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:00,352 INFO:     Epoch: 12
2023-01-05 01:19:02,531 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5042900651693344, 'Total loss': 0.5042900651693344} | train loss {'Reaction outcome loss': 0.34241307131441195, 'Total loss': 0.34241307131441195}
2023-01-05 01:19:02,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:02,531 INFO:     Epoch: 13
2023-01-05 01:19:04,764 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49871575832366943, 'Total loss': 0.49871575832366943} | train loss {'Reaction outcome loss': 0.3405118092567056, 'Total loss': 0.3405118092567056}
2023-01-05 01:19:04,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:04,764 INFO:     Epoch: 14
2023-01-05 01:19:06,997 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49302681187788644, 'Total loss': 0.49302681187788644} | train loss {'Reaction outcome loss': 0.3315483741325773, 'Total loss': 0.3315483741325773}
2023-01-05 01:19:06,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:06,998 INFO:     Epoch: 15
2023-01-05 01:19:09,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4902823090553284, 'Total loss': 0.4902823090553284} | train loss {'Reaction outcome loss': 0.32463068528708083, 'Total loss': 0.32463068528708083}
2023-01-05 01:19:09,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:09,163 INFO:     Epoch: 16
2023-01-05 01:19:11,403 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47836694518725076, 'Total loss': 0.47836694518725076} | train loss {'Reaction outcome loss': 0.3155755423855432, 'Total loss': 0.3155755423855432}
2023-01-05 01:19:11,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:11,403 INFO:     Epoch: 17
2023-01-05 01:19:13,633 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48249961535135905, 'Total loss': 0.48249961535135905} | train loss {'Reaction outcome loss': 0.30954237742308566, 'Total loss': 0.30954237742308566}
2023-01-05 01:19:13,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:13,633 INFO:     Epoch: 18
2023-01-05 01:19:15,496 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5118685195843379, 'Total loss': 0.5118685195843379} | train loss {'Reaction outcome loss': 0.30209756540236893, 'Total loss': 0.30209756540236893}
2023-01-05 01:19:15,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:15,497 INFO:     Epoch: 19
2023-01-05 01:19:17,292 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47818090915679934, 'Total loss': 0.47818090915679934} | train loss {'Reaction outcome loss': 0.29750163967792803, 'Total loss': 0.29750163967792803}
2023-01-05 01:19:17,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:17,292 INFO:     Epoch: 20
2023-01-05 01:19:19,303 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5148481537898382, 'Total loss': 0.5148481537898382} | train loss {'Reaction outcome loss': 0.28962337133566757, 'Total loss': 0.28962337133566757}
2023-01-05 01:19:19,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:19,303 INFO:     Epoch: 21
2023-01-05 01:19:21,488 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5006253192822139, 'Total loss': 0.5006253192822139} | train loss {'Reaction outcome loss': 0.2901675062793078, 'Total loss': 0.2901675062793078}
2023-01-05 01:19:21,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:21,488 INFO:     Epoch: 22
2023-01-05 01:19:23,680 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5122015476226807, 'Total loss': 0.5122015476226807} | train loss {'Reaction outcome loss': 0.27893537282943726, 'Total loss': 0.27893537282943726}
2023-01-05 01:19:23,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:23,680 INFO:     Epoch: 23
2023-01-05 01:19:25,883 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45837890605131787, 'Total loss': 0.45837890605131787} | train loss {'Reaction outcome loss': 0.27835826613964176, 'Total loss': 0.27835826613964176}
2023-01-05 01:19:25,883 INFO:     Found new best model at epoch 23
2023-01-05 01:19:25,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:25,885 INFO:     Epoch: 24
2023-01-05 01:19:28,115 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47375001311302184, 'Total loss': 0.47375001311302184} | train loss {'Reaction outcome loss': 0.2666311370611409, 'Total loss': 0.2666311370611409}
2023-01-05 01:19:28,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:28,116 INFO:     Epoch: 25
2023-01-05 01:19:30,324 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4917779743671417, 'Total loss': 0.4917779743671417} | train loss {'Reaction outcome loss': 0.2652335172525911, 'Total loss': 0.2652335172525911}
2023-01-05 01:19:30,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:30,324 INFO:     Epoch: 26
2023-01-05 01:19:32,506 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47685627241929374, 'Total loss': 0.47685627241929374} | train loss {'Reaction outcome loss': 0.2630293990311387, 'Total loss': 0.2630293990311387}
2023-01-05 01:19:32,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:32,506 INFO:     Epoch: 27
2023-01-05 01:19:34,736 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5034186522165934, 'Total loss': 0.5034186522165934} | train loss {'Reaction outcome loss': 0.2600068784909043, 'Total loss': 0.2600068784909043}
2023-01-05 01:19:34,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:34,736 INFO:     Epoch: 28
2023-01-05 01:19:36,970 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5096424122651418, 'Total loss': 0.5096424122651418} | train loss {'Reaction outcome loss': 0.25525524171117026, 'Total loss': 0.25525524171117026}
2023-01-05 01:19:36,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:36,970 INFO:     Epoch: 29
2023-01-05 01:19:39,109 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5012572586536408, 'Total loss': 0.5012572586536408} | train loss {'Reaction outcome loss': 0.24969073592074514, 'Total loss': 0.24969073592074514}
2023-01-05 01:19:39,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:39,111 INFO:     Epoch: 30
2023-01-05 01:19:41,335 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.512274839480718, 'Total loss': 0.512274839480718} | train loss {'Reaction outcome loss': 0.24388806652891767, 'Total loss': 0.24388806652891767}
2023-01-05 01:19:41,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:41,336 INFO:     Epoch: 31
2023-01-05 01:19:43,557 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4718811959028244, 'Total loss': 0.4718811959028244} | train loss {'Reaction outcome loss': 0.25134872686759235, 'Total loss': 0.25134872686759235}
2023-01-05 01:19:43,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:43,558 INFO:     Epoch: 32
2023-01-05 01:19:45,804 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4869344413280487, 'Total loss': 0.4869344413280487} | train loss {'Reaction outcome loss': 0.24165324967750262, 'Total loss': 0.24165324967750262}
2023-01-05 01:19:45,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:45,805 INFO:     Epoch: 33
2023-01-05 01:19:48,044 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5016176521778106, 'Total loss': 0.5016176521778106} | train loss {'Reaction outcome loss': 0.23955917887171327, 'Total loss': 0.23955917887171327}
2023-01-05 01:19:48,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:48,045 INFO:     Epoch: 34
2023-01-05 01:19:50,270 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48306641578674314, 'Total loss': 0.48306641578674314} | train loss {'Reaction outcome loss': 0.2393531666270324, 'Total loss': 0.2393531666270324}
2023-01-05 01:19:50,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:50,271 INFO:     Epoch: 35
2023-01-05 01:19:52,508 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4861589014530182, 'Total loss': 0.4861589014530182} | train loss {'Reaction outcome loss': 0.23707796833153827, 'Total loss': 0.23707796833153827}
2023-01-05 01:19:52,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:52,508 INFO:     Epoch: 36
2023-01-05 01:19:54,699 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5123416185379028, 'Total loss': 0.5123416185379028} | train loss {'Reaction outcome loss': 0.23049514091167694, 'Total loss': 0.23049514091167694}
2023-01-05 01:19:54,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:54,699 INFO:     Epoch: 37
2023-01-05 01:19:56,948 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4696680918335915, 'Total loss': 0.4696680918335915} | train loss {'Reaction outcome loss': 0.22527454849741943, 'Total loss': 0.22527454849741943}
2023-01-05 01:19:56,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:56,949 INFO:     Epoch: 38
2023-01-05 01:19:59,207 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4554360777139664, 'Total loss': 0.4554360777139664} | train loss {'Reaction outcome loss': 0.22332112333522394, 'Total loss': 0.22332112333522394}
2023-01-05 01:19:59,208 INFO:     Found new best model at epoch 38
2023-01-05 01:19:59,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:19:59,210 INFO:     Epoch: 39
2023-01-05 01:20:01,474 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4877231369415919, 'Total loss': 0.4877231369415919} | train loss {'Reaction outcome loss': 0.22150540989806583, 'Total loss': 0.22150540989806583}
2023-01-05 01:20:01,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:01,474 INFO:     Epoch: 40
2023-01-05 01:20:03,729 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47582115133603414, 'Total loss': 0.47582115133603414} | train loss {'Reaction outcome loss': 0.22601237861037035, 'Total loss': 0.22601237861037035}
2023-01-05 01:20:03,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:03,730 INFO:     Epoch: 41
2023-01-05 01:20:05,947 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4880821297566096, 'Total loss': 0.4880821297566096} | train loss {'Reaction outcome loss': 0.21649064703574983, 'Total loss': 0.21649064703574983}
2023-01-05 01:20:05,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:05,947 INFO:     Epoch: 42
2023-01-05 01:20:08,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5033137500286102, 'Total loss': 0.5033137500286102} | train loss {'Reaction outcome loss': 0.21214632251241924, 'Total loss': 0.21214632251241924}
2023-01-05 01:20:08,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:08,183 INFO:     Epoch: 43
2023-01-05 01:20:10,424 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48897767861684166, 'Total loss': 0.48897767861684166} | train loss {'Reaction outcome loss': 0.2150678593024011, 'Total loss': 0.2150678593024011}
2023-01-05 01:20:10,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:10,424 INFO:     Epoch: 44
2023-01-05 01:20:12,644 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47733625570933025, 'Total loss': 0.47733625570933025} | train loss {'Reaction outcome loss': 0.21176781583809373, 'Total loss': 0.21176781583809373}
2023-01-05 01:20:12,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:12,644 INFO:     Epoch: 45
2023-01-05 01:20:14,854 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.505283389488856, 'Total loss': 0.505283389488856} | train loss {'Reaction outcome loss': 0.21266357578855732, 'Total loss': 0.21266357578855732}
2023-01-05 01:20:14,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:14,855 INFO:     Epoch: 46
2023-01-05 01:20:17,016 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4536785473426183, 'Total loss': 0.4536785473426183} | train loss {'Reaction outcome loss': 0.205785776294031, 'Total loss': 0.205785776294031}
2023-01-05 01:20:17,016 INFO:     Found new best model at epoch 46
2023-01-05 01:20:17,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:17,017 INFO:     Epoch: 47
2023-01-05 01:20:19,235 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4773294135928154, 'Total loss': 0.4773294135928154} | train loss {'Reaction outcome loss': 0.20358325405244207, 'Total loss': 0.20358325405244207}
2023-01-05 01:20:19,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:19,236 INFO:     Epoch: 48
2023-01-05 01:20:21,443 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47089781959851584, 'Total loss': 0.47089781959851584} | train loss {'Reaction outcome loss': 0.20593842618413025, 'Total loss': 0.20593842618413025}
2023-01-05 01:20:21,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:21,444 INFO:     Epoch: 49
2023-01-05 01:20:23,666 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47306743562221526, 'Total loss': 0.47306743562221526} | train loss {'Reaction outcome loss': 0.20110847596966086, 'Total loss': 0.20110847596966086}
2023-01-05 01:20:23,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:23,666 INFO:     Epoch: 50
2023-01-05 01:20:25,901 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5169446731607119, 'Total loss': 0.5169446731607119} | train loss {'Reaction outcome loss': 0.20498224982186716, 'Total loss': 0.20498224982186716}
2023-01-05 01:20:25,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:25,902 INFO:     Epoch: 51
2023-01-05 01:20:28,016 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4809099078178406, 'Total loss': 0.4809099078178406} | train loss {'Reaction outcome loss': 0.19696780331961591, 'Total loss': 0.19696780331961591}
2023-01-05 01:20:28,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:28,016 INFO:     Epoch: 52
2023-01-05 01:20:30,207 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46838874618212384, 'Total loss': 0.46838874618212384} | train loss {'Reaction outcome loss': 0.19660100332996894, 'Total loss': 0.19660100332996894}
2023-01-05 01:20:30,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:30,207 INFO:     Epoch: 53
2023-01-05 01:20:32,420 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5128867983818054, 'Total loss': 0.5128867983818054} | train loss {'Reaction outcome loss': 0.19499891375160808, 'Total loss': 0.19499891375160808}
2023-01-05 01:20:32,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:32,420 INFO:     Epoch: 54
2023-01-05 01:20:34,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47220799922943113, 'Total loss': 0.47220799922943113} | train loss {'Reaction outcome loss': 0.1912539327728661, 'Total loss': 0.1912539327728661}
2023-01-05 01:20:34,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:34,554 INFO:     Epoch: 55
2023-01-05 01:20:36,823 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5089040875434876, 'Total loss': 0.5089040875434876} | train loss {'Reaction outcome loss': 0.19180053299559013, 'Total loss': 0.19180053299559013}
2023-01-05 01:20:36,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:36,823 INFO:     Epoch: 56
2023-01-05 01:20:39,066 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4859682450691859, 'Total loss': 0.4859682450691859} | train loss {'Reaction outcome loss': 0.19082065528060818, 'Total loss': 0.19082065528060818}
2023-01-05 01:20:39,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:39,067 INFO:     Epoch: 57
2023-01-05 01:20:41,221 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4610621670881907, 'Total loss': 0.4610621670881907} | train loss {'Reaction outcome loss': 0.19153729690436697, 'Total loss': 0.19153729690436697}
2023-01-05 01:20:41,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:41,221 INFO:     Epoch: 58
2023-01-05 01:20:43,387 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4830818916360537, 'Total loss': 0.4830818916360537} | train loss {'Reaction outcome loss': 0.18427925746744642, 'Total loss': 0.18427925746744642}
2023-01-05 01:20:43,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:43,387 INFO:     Epoch: 59
2023-01-05 01:20:45,613 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46545480489730834, 'Total loss': 0.46545480489730834} | train loss {'Reaction outcome loss': 0.19267420914883798, 'Total loss': 0.19267420914883798}
2023-01-05 01:20:45,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:45,613 INFO:     Epoch: 60
2023-01-05 01:20:47,813 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.504825101296107, 'Total loss': 0.504825101296107} | train loss {'Reaction outcome loss': 0.1874279847518701, 'Total loss': 0.1874279847518701}
2023-01-05 01:20:47,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:47,813 INFO:     Epoch: 61
2023-01-05 01:20:50,025 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47508201996485394, 'Total loss': 0.47508201996485394} | train loss {'Reaction outcome loss': 0.18692408124455712, 'Total loss': 0.18692408124455712}
2023-01-05 01:20:50,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:50,026 INFO:     Epoch: 62
2023-01-05 01:20:52,178 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4978169997533162, 'Total loss': 0.4978169997533162} | train loss {'Reaction outcome loss': 0.1815633644544325, 'Total loss': 0.1815633644544325}
2023-01-05 01:20:52,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:52,179 INFO:     Epoch: 63
2023-01-05 01:20:54,390 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5240760366121928, 'Total loss': 0.5240760366121928} | train loss {'Reaction outcome loss': 0.17823399624176622, 'Total loss': 0.17823399624176622}
2023-01-05 01:20:54,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:54,390 INFO:     Epoch: 64
2023-01-05 01:20:56,617 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48389846583207446, 'Total loss': 0.48389846583207446} | train loss {'Reaction outcome loss': 0.1767568853530255, 'Total loss': 0.1767568853530255}
2023-01-05 01:20:56,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:56,617 INFO:     Epoch: 65
2023-01-05 01:20:58,866 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5140400489171346, 'Total loss': 0.5140400489171346} | train loss {'Reaction outcome loss': 0.1805161972403963, 'Total loss': 0.1805161972403963}
2023-01-05 01:20:58,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:20:58,867 INFO:     Epoch: 66
2023-01-05 01:21:01,116 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5021595736344655, 'Total loss': 0.5021595736344655} | train loss {'Reaction outcome loss': 0.1786870725688289, 'Total loss': 0.1786870725688289}
2023-01-05 01:21:01,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:01,117 INFO:     Epoch: 67
2023-01-05 01:21:03,296 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5041946431001028, 'Total loss': 0.5041946431001028} | train loss {'Reaction outcome loss': 0.18774016473728877, 'Total loss': 0.18774016473728877}
2023-01-05 01:21:03,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:03,296 INFO:     Epoch: 68
2023-01-05 01:21:05,533 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4778729965289434, 'Total loss': 0.4778729965289434} | train loss {'Reaction outcome loss': 0.17411580811861915, 'Total loss': 0.17411580811861915}
2023-01-05 01:21:05,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:05,533 INFO:     Epoch: 69
2023-01-05 01:21:07,762 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47638774911562604, 'Total loss': 0.47638774911562604} | train loss {'Reaction outcome loss': 0.1695101668157584, 'Total loss': 0.1695101668157584}
2023-01-05 01:21:07,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:07,762 INFO:     Epoch: 70
2023-01-05 01:21:10,004 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.504638119538625, 'Total loss': 0.504638119538625} | train loss {'Reaction outcome loss': 0.17254011826453247, 'Total loss': 0.17254011826453247}
2023-01-05 01:21:10,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:10,004 INFO:     Epoch: 71
2023-01-05 01:21:12,246 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5006616691748301, 'Total loss': 0.5006616691748301} | train loss {'Reaction outcome loss': 0.1731158526556314, 'Total loss': 0.1731158526556314}
2023-01-05 01:21:12,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:12,246 INFO:     Epoch: 72
2023-01-05 01:21:14,385 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48467848300933836, 'Total loss': 0.48467848300933836} | train loss {'Reaction outcome loss': 0.1769563083762078, 'Total loss': 0.1769563083762078}
2023-01-05 01:21:14,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:14,385 INFO:     Epoch: 73
2023-01-05 01:21:16,625 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5312949031591415, 'Total loss': 0.5312949031591415} | train loss {'Reaction outcome loss': 0.17211063114769293, 'Total loss': 0.17211063114769293}
2023-01-05 01:21:16,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:16,625 INFO:     Epoch: 74
2023-01-05 01:21:18,853 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5179885218540827, 'Total loss': 0.5179885218540827} | train loss {'Reaction outcome loss': 0.17129037515584367, 'Total loss': 0.17129037515584367}
2023-01-05 01:21:18,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:18,854 INFO:     Epoch: 75
2023-01-05 01:21:21,043 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47135717595616977, 'Total loss': 0.47135717595616977} | train loss {'Reaction outcome loss': 0.1695504196093933, 'Total loss': 0.1695504196093933}
2023-01-05 01:21:21,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:21,044 INFO:     Epoch: 76
2023-01-05 01:21:23,223 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4928297926982244, 'Total loss': 0.4928297926982244} | train loss {'Reaction outcome loss': 0.1681254996539472, 'Total loss': 0.1681254996539472}
2023-01-05 01:21:23,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:23,223 INFO:     Epoch: 77
2023-01-05 01:21:25,459 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4911213040351868, 'Total loss': 0.4911213040351868} | train loss {'Reaction outcome loss': 0.17066142207519885, 'Total loss': 0.17066142207519885}
2023-01-05 01:21:25,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:25,459 INFO:     Epoch: 78
2023-01-05 01:21:27,665 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4909883643190066, 'Total loss': 0.4909883643190066} | train loss {'Reaction outcome loss': 0.17076241402398973, 'Total loss': 0.17076241402398973}
2023-01-05 01:21:27,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:27,666 INFO:     Epoch: 79
2023-01-05 01:21:29,882 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5450659573078156, 'Total loss': 0.5450659573078156} | train loss {'Reaction outcome loss': 0.16895380707444016, 'Total loss': 0.16895380707444016}
2023-01-05 01:21:29,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:29,883 INFO:     Epoch: 80
2023-01-05 01:21:32,127 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5471531480550766, 'Total loss': 0.5471531480550766} | train loss {'Reaction outcome loss': 0.16558125931189666, 'Total loss': 0.16558125931189666}
2023-01-05 01:21:32,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:32,127 INFO:     Epoch: 81
2023-01-05 01:21:34,373 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5267951548099518, 'Total loss': 0.5267951548099518} | train loss {'Reaction outcome loss': 0.17330418031273798, 'Total loss': 0.17330418031273798}
2023-01-05 01:21:34,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:34,373 INFO:     Epoch: 82
2023-01-05 01:21:36,598 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49050895174344383, 'Total loss': 0.49050895174344383} | train loss {'Reaction outcome loss': 0.16844530531031254, 'Total loss': 0.16844530531031254}
2023-01-05 01:21:36,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:36,598 INFO:     Epoch: 83
2023-01-05 01:21:38,803 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5091681698958079, 'Total loss': 0.5091681698958079} | train loss {'Reaction outcome loss': 0.17079153905141647, 'Total loss': 0.17079153905141647}
2023-01-05 01:21:38,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:38,803 INFO:     Epoch: 84
2023-01-05 01:21:40,983 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4869026064872742, 'Total loss': 0.4869026064872742} | train loss {'Reaction outcome loss': 0.16661135385652165, 'Total loss': 0.16661135385652165}
2023-01-05 01:21:40,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:40,983 INFO:     Epoch: 85
2023-01-05 01:21:43,222 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48830457183842857, 'Total loss': 0.48830457183842857} | train loss {'Reaction outcome loss': 0.1684120232904596, 'Total loss': 0.1684120232904596}
2023-01-05 01:21:43,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:43,222 INFO:     Epoch: 86
2023-01-05 01:21:45,404 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5403380533059438, 'Total loss': 0.5403380533059438} | train loss {'Reaction outcome loss': 0.16117406346333715, 'Total loss': 0.16117406346333715}
2023-01-05 01:21:45,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:45,405 INFO:     Epoch: 87
2023-01-05 01:21:47,632 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5021142775813738, 'Total loss': 0.5021142775813738} | train loss {'Reaction outcome loss': 0.163817662315873, 'Total loss': 0.163817662315873}
2023-01-05 01:21:47,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:47,633 INFO:     Epoch: 88
2023-01-05 01:21:49,826 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5229468762874603, 'Total loss': 0.5229468762874603} | train loss {'Reaction outcome loss': 0.16774860968226532, 'Total loss': 0.16774860968226532}
2023-01-05 01:21:49,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:49,826 INFO:     Epoch: 89
2023-01-05 01:21:52,043 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5599983255068461, 'Total loss': 0.5599983255068461} | train loss {'Reaction outcome loss': 0.1648183544251672, 'Total loss': 0.1648183544251672}
2023-01-05 01:21:52,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:52,044 INFO:     Epoch: 90
2023-01-05 01:21:54,225 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5234144429365793, 'Total loss': 0.5234144429365793} | train loss {'Reaction outcome loss': 0.16189231770454254, 'Total loss': 0.16189231770454254}
2023-01-05 01:21:54,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:54,225 INFO:     Epoch: 91
2023-01-05 01:21:56,408 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5258576606710752, 'Total loss': 0.5258576606710752} | train loss {'Reaction outcome loss': 0.16643168225512592, 'Total loss': 0.16643168225512592}
2023-01-05 01:21:56,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:56,409 INFO:     Epoch: 92
2023-01-05 01:21:58,617 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4920941650867462, 'Total loss': 0.4920941650867462} | train loss {'Reaction outcome loss': 0.1639725630864119, 'Total loss': 0.1639725630864119}
2023-01-05 01:21:58,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:21:58,618 INFO:     Epoch: 93
2023-01-05 01:22:00,846 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.523549974958102, 'Total loss': 0.523549974958102} | train loss {'Reaction outcome loss': 0.16460889590146777, 'Total loss': 0.16460889590146777}
2023-01-05 01:22:00,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:00,846 INFO:     Epoch: 94
2023-01-05 01:22:03,035 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5143600647648175, 'Total loss': 0.5143600647648175} | train loss {'Reaction outcome loss': 0.16208339621732523, 'Total loss': 0.16208339621732523}
2023-01-05 01:22:03,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:03,036 INFO:     Epoch: 95
2023-01-05 01:22:05,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47948845078547797, 'Total loss': 0.47948845078547797} | train loss {'Reaction outcome loss': 0.16061492054979062, 'Total loss': 0.16061492054979062}
2023-01-05 01:22:05,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:05,207 INFO:     Epoch: 96
2023-01-05 01:22:07,511 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5162044381101926, 'Total loss': 0.5162044381101926} | train loss {'Reaction outcome loss': 0.1612058808709812, 'Total loss': 0.1612058808709812}
2023-01-05 01:22:07,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:07,512 INFO:     Epoch: 97
2023-01-05 01:22:09,806 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5262980898221333, 'Total loss': 0.5262980898221333} | train loss {'Reaction outcome loss': 0.16030716623994948, 'Total loss': 0.16030716623994948}
2023-01-05 01:22:09,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:09,806 INFO:     Epoch: 98
2023-01-05 01:22:12,118 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5088368346293767, 'Total loss': 0.5088368346293767} | train loss {'Reaction outcome loss': 0.1627044144338986, 'Total loss': 0.1627044144338986}
2023-01-05 01:22:12,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:12,118 INFO:     Epoch: 99
2023-01-05 01:22:14,379 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5100601563851038, 'Total loss': 0.5100601563851038} | train loss {'Reaction outcome loss': 0.16803127566639048, 'Total loss': 0.16803127566639048}
2023-01-05 01:22:14,379 INFO:     Best model found after epoch 47 of 100.
2023-01-05 01:22:14,379 INFO:   Done with stage: TRAINING
2023-01-05 01:22:14,379 INFO:   Starting stage: EVALUATION
2023-01-05 01:22:14,526 INFO:   Done with stage: EVALUATION
2023-01-05 01:22:14,526 INFO:   Leaving out SEQ value Fold_8
2023-01-05 01:22:14,538 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 01:22:14,538 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:22:15,189 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:22:15,189 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:22:15,258 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:22:15,259 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:22:15,259 INFO:     No hyperparam tuning for this model
2023-01-05 01:22:15,259 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:22:15,259 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:22:15,259 INFO:     None feature selector for col prot
2023-01-05 01:22:15,260 INFO:     None feature selector for col prot
2023-01-05 01:22:15,260 INFO:     None feature selector for col prot
2023-01-05 01:22:15,260 INFO:     None feature selector for col chem
2023-01-05 01:22:15,260 INFO:     None feature selector for col chem
2023-01-05 01:22:15,260 INFO:     None feature selector for col chem
2023-01-05 01:22:15,260 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:22:15,260 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:22:15,262 INFO:     Number of params in model 72931
2023-01-05 01:22:15,265 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:22:15,265 INFO:   Starting stage: TRAINING
2023-01-05 01:22:15,327 INFO:     Val loss before train {'Reaction outcome loss': 0.9431151390075684, 'Total loss': 0.9431151390075684}
2023-01-05 01:22:15,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:15,327 INFO:     Epoch: 0
2023-01-05 01:22:17,505 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7189449608325958, 'Total loss': 0.7189449608325958} | train loss {'Reaction outcome loss': 0.942976713936398, 'Total loss': 0.942976713936398}
2023-01-05 01:22:17,506 INFO:     Found new best model at epoch 0
2023-01-05 01:22:17,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:17,507 INFO:     Epoch: 1
2023-01-05 01:22:19,780 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5332614362239838, 'Total loss': 0.5332614362239838} | train loss {'Reaction outcome loss': 0.6143769647224225, 'Total loss': 0.6143769647224225}
2023-01-05 01:22:19,780 INFO:     Found new best model at epoch 1
2023-01-05 01:22:19,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:19,781 INFO:     Epoch: 2
2023-01-05 01:22:22,049 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5046525816122691, 'Total loss': 0.5046525816122691} | train loss {'Reaction outcome loss': 0.5254841623912174, 'Total loss': 0.5254841623912174}
2023-01-05 01:22:22,049 INFO:     Found new best model at epoch 2
2023-01-05 01:22:22,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:22,051 INFO:     Epoch: 3
2023-01-05 01:22:24,265 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5009760191043218, 'Total loss': 0.5009760191043218} | train loss {'Reaction outcome loss': 0.4913583095556638, 'Total loss': 0.4913583095556638}
2023-01-05 01:22:24,265 INFO:     Found new best model at epoch 3
2023-01-05 01:22:24,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:24,266 INFO:     Epoch: 4
2023-01-05 01:22:26,533 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4751469482978185, 'Total loss': 0.4751469482978185} | train loss {'Reaction outcome loss': 0.4936097044551718, 'Total loss': 0.4936097044551718}
2023-01-05 01:22:26,533 INFO:     Found new best model at epoch 4
2023-01-05 01:22:26,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:26,535 INFO:     Epoch: 5
2023-01-05 01:22:28,778 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4561849961678187, 'Total loss': 0.4561849961678187} | train loss {'Reaction outcome loss': 0.4487944892405168, 'Total loss': 0.4487944892405168}
2023-01-05 01:22:28,780 INFO:     Found new best model at epoch 5
2023-01-05 01:22:28,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:28,781 INFO:     Epoch: 6
2023-01-05 01:22:31,013 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4485891570647558, 'Total loss': 0.4485891570647558} | train loss {'Reaction outcome loss': 0.4301936242668687, 'Total loss': 0.4301936242668687}
2023-01-05 01:22:31,013 INFO:     Found new best model at epoch 6
2023-01-05 01:22:31,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:31,015 INFO:     Epoch: 7
2023-01-05 01:22:33,296 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45153018534183503, 'Total loss': 0.45153018534183503} | train loss {'Reaction outcome loss': 0.417373590056609, 'Total loss': 0.417373590056609}
2023-01-05 01:22:33,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:33,296 INFO:     Epoch: 8
2023-01-05 01:22:35,595 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4616063197453817, 'Total loss': 0.4616063197453817} | train loss {'Reaction outcome loss': 0.4047295678730892, 'Total loss': 0.4047295678730892}
2023-01-05 01:22:35,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:35,596 INFO:     Epoch: 9
2023-01-05 01:22:37,822 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4560807834068934, 'Total loss': 0.4560807834068934} | train loss {'Reaction outcome loss': 0.3919193148478002, 'Total loss': 0.3919193148478002}
2023-01-05 01:22:37,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:37,822 INFO:     Epoch: 10
2023-01-05 01:22:40,041 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4482868144909541, 'Total loss': 0.4482868144909541} | train loss {'Reaction outcome loss': 0.3818708096594597, 'Total loss': 0.3818708096594597}
2023-01-05 01:22:40,041 INFO:     Found new best model at epoch 10
2023-01-05 01:22:40,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:40,043 INFO:     Epoch: 11
2023-01-05 01:22:42,281 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4488728543122609, 'Total loss': 0.4488728543122609} | train loss {'Reaction outcome loss': 0.37326991992565617, 'Total loss': 0.37326991992565617}
2023-01-05 01:22:42,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:42,281 INFO:     Epoch: 12
2023-01-05 01:22:44,390 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4422105928262075, 'Total loss': 0.4422105928262075} | train loss {'Reaction outcome loss': 0.37434361084107903, 'Total loss': 0.37434361084107903}
2023-01-05 01:22:44,390 INFO:     Found new best model at epoch 12
2023-01-05 01:22:44,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:44,392 INFO:     Epoch: 13
2023-01-05 01:22:46,525 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43498320306340854, 'Total loss': 0.43498320306340854} | train loss {'Reaction outcome loss': 0.36244917002488, 'Total loss': 0.36244917002488}
2023-01-05 01:22:46,525 INFO:     Found new best model at epoch 13
2023-01-05 01:22:46,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:46,526 INFO:     Epoch: 14
2023-01-05 01:22:48,680 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46526799698670707, 'Total loss': 0.46526799698670707} | train loss {'Reaction outcome loss': 0.34066876560530585, 'Total loss': 0.34066876560530585}
2023-01-05 01:22:48,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:48,681 INFO:     Epoch: 15
2023-01-05 01:22:50,887 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4463013599316279, 'Total loss': 0.4463013599316279} | train loss {'Reaction outcome loss': 0.33429026793037075, 'Total loss': 0.33429026793037075}
2023-01-05 01:22:50,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:50,887 INFO:     Epoch: 16
2023-01-05 01:22:53,089 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4598571221033732, 'Total loss': 0.4598571221033732} | train loss {'Reaction outcome loss': 0.32975297969550005, 'Total loss': 0.32975297969550005}
2023-01-05 01:22:53,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:53,089 INFO:     Epoch: 17
2023-01-05 01:22:55,317 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48747556656599045, 'Total loss': 0.48747556656599045} | train loss {'Reaction outcome loss': 0.320509646632, 'Total loss': 0.320509646632}
2023-01-05 01:22:55,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:55,317 INFO:     Epoch: 18
2023-01-05 01:22:57,541 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4589388092358907, 'Total loss': 0.4589388092358907} | train loss {'Reaction outcome loss': 0.31899118264192255, 'Total loss': 0.31899118264192255}
2023-01-05 01:22:57,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:57,541 INFO:     Epoch: 19
2023-01-05 01:22:59,765 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4880289415518443, 'Total loss': 0.4880289415518443} | train loss {'Reaction outcome loss': 0.3156074959703762, 'Total loss': 0.3156074959703762}
2023-01-05 01:22:59,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:22:59,765 INFO:     Epoch: 20
2023-01-05 01:23:01,911 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4415400455395381, 'Total loss': 0.4415400455395381} | train loss {'Reaction outcome loss': 0.3222522033391979, 'Total loss': 0.3222522033391979}
2023-01-05 01:23:01,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:01,912 INFO:     Epoch: 21
2023-01-05 01:23:04,129 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4463585833708445, 'Total loss': 0.4463585833708445} | train loss {'Reaction outcome loss': 0.3050032014000243, 'Total loss': 0.3050032014000243}
2023-01-05 01:23:04,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:04,130 INFO:     Epoch: 22
2023-01-05 01:23:06,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4708463966846466, 'Total loss': 0.4708463966846466} | train loss {'Reaction outcome loss': 0.3084430162584465, 'Total loss': 0.3084430162584465}
2023-01-05 01:23:06,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:06,360 INFO:     Epoch: 23
2023-01-05 01:23:08,627 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4523237695296605, 'Total loss': 0.4523237695296605} | train loss {'Reaction outcome loss': 0.2919454868411328, 'Total loss': 0.2919454868411328}
2023-01-05 01:23:08,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:08,627 INFO:     Epoch: 24
2023-01-05 01:23:10,876 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5172302385171255, 'Total loss': 0.5172302385171255} | train loss {'Reaction outcome loss': 0.2853391347216793, 'Total loss': 0.2853391347216793}
2023-01-05 01:23:10,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:10,877 INFO:     Epoch: 25
2023-01-05 01:23:13,107 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4601562708616257, 'Total loss': 0.4601562708616257} | train loss {'Reaction outcome loss': 0.2843267407902665, 'Total loss': 0.2843267407902665}
2023-01-05 01:23:13,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:13,107 INFO:     Epoch: 26
2023-01-05 01:23:15,358 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45967518985271455, 'Total loss': 0.45967518985271455} | train loss {'Reaction outcome loss': 0.27861391890294634, 'Total loss': 0.27861391890294634}
2023-01-05 01:23:15,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:15,359 INFO:     Epoch: 27
2023-01-05 01:23:17,615 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4576103885968526, 'Total loss': 0.4576103885968526} | train loss {'Reaction outcome loss': 0.27742847720535635, 'Total loss': 0.27742847720535635}
2023-01-05 01:23:17,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:17,615 INFO:     Epoch: 28
2023-01-05 01:23:19,893 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5033182203769684, 'Total loss': 0.5033182203769684} | train loss {'Reaction outcome loss': 0.2745428199468997, 'Total loss': 0.2745428199468997}
2023-01-05 01:23:19,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:19,893 INFO:     Epoch: 29
2023-01-05 01:23:22,136 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4719230107963085, 'Total loss': 0.4719230107963085} | train loss {'Reaction outcome loss': 0.2689069848696607, 'Total loss': 0.2689069848696607}
2023-01-05 01:23:22,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:22,136 INFO:     Epoch: 30
2023-01-05 01:23:24,404 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48395136594772337, 'Total loss': 0.48395136594772337} | train loss {'Reaction outcome loss': 0.26341679868747253, 'Total loss': 0.26341679868747253}
2023-01-05 01:23:24,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:24,405 INFO:     Epoch: 31
2023-01-05 01:23:26,616 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4615381181240082, 'Total loss': 0.4615381181240082} | train loss {'Reaction outcome loss': 0.26017727548310504, 'Total loss': 0.26017727548310504}
2023-01-05 01:23:26,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:26,617 INFO:     Epoch: 32
2023-01-05 01:23:28,863 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49282273153464, 'Total loss': 0.49282273153464} | train loss {'Reaction outcome loss': 0.25455448427659366, 'Total loss': 0.25455448427659366}
2023-01-05 01:23:28,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:28,864 INFO:     Epoch: 33
2023-01-05 01:23:31,105 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49990443189938866, 'Total loss': 0.49990443189938866} | train loss {'Reaction outcome loss': 0.2552270151681496, 'Total loss': 0.2552270151681496}
2023-01-05 01:23:31,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:31,105 INFO:     Epoch: 34
2023-01-05 01:23:33,355 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47525164087613425, 'Total loss': 0.47525164087613425} | train loss {'Reaction outcome loss': 0.2504591934072475, 'Total loss': 0.2504591934072475}
2023-01-05 01:23:33,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:33,355 INFO:     Epoch: 35
2023-01-05 01:23:35,612 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49689116279284157, 'Total loss': 0.49689116279284157} | train loss {'Reaction outcome loss': 0.24750759071279047, 'Total loss': 0.24750759071279047}
2023-01-05 01:23:35,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:35,612 INFO:     Epoch: 36
2023-01-05 01:23:37,793 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4965073128541311, 'Total loss': 0.4965073128541311} | train loss {'Reaction outcome loss': 0.24877903353341896, 'Total loss': 0.24877903353341896}
2023-01-05 01:23:37,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:37,793 INFO:     Epoch: 37
2023-01-05 01:23:40,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48053201138973234, 'Total loss': 0.48053201138973234} | train loss {'Reaction outcome loss': 0.2453964999455122, 'Total loss': 0.2453964999455122}
2023-01-05 01:23:40,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:40,053 INFO:     Epoch: 38
2023-01-05 01:23:42,303 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48453193058570226, 'Total loss': 0.48453193058570226} | train loss {'Reaction outcome loss': 0.2382628914134145, 'Total loss': 0.2382628914134145}
2023-01-05 01:23:42,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:42,304 INFO:     Epoch: 39
2023-01-05 01:23:44,563 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4860769311587016, 'Total loss': 0.4860769311587016} | train loss {'Reaction outcome loss': 0.23842817558265844, 'Total loss': 0.23842817558265844}
2023-01-05 01:23:44,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:44,563 INFO:     Epoch: 40
2023-01-05 01:23:46,814 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4729475180308024, 'Total loss': 0.4729475180308024} | train loss {'Reaction outcome loss': 0.2347448130975059, 'Total loss': 0.2347448130975059}
2023-01-05 01:23:46,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:46,815 INFO:     Epoch: 41
2023-01-05 01:23:49,073 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4785093049208323, 'Total loss': 0.4785093049208323} | train loss {'Reaction outcome loss': 0.23634533447118988, 'Total loss': 0.23634533447118988}
2023-01-05 01:23:49,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:49,073 INFO:     Epoch: 42
2023-01-05 01:23:51,324 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48351362645626067, 'Total loss': 0.48351362645626067} | train loss {'Reaction outcome loss': 0.23236486367017462, 'Total loss': 0.23236486367017462}
2023-01-05 01:23:51,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:51,325 INFO:     Epoch: 43
2023-01-05 01:23:53,591 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.426374163866664, 'Total loss': 0.426374163866664} | train loss {'Reaction outcome loss': 0.23783170840149556, 'Total loss': 0.23783170840149556}
2023-01-05 01:23:53,591 INFO:     Found new best model at epoch 43
2023-01-05 01:23:53,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:53,592 INFO:     Epoch: 44
2023-01-05 01:23:55,854 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4735515147447586, 'Total loss': 0.4735515147447586} | train loss {'Reaction outcome loss': 0.2294115531427003, 'Total loss': 0.2294115531427003}
2023-01-05 01:23:55,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:55,854 INFO:     Epoch: 45
2023-01-05 01:23:58,101 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5110725581645965, 'Total loss': 0.5110725581645965} | train loss {'Reaction outcome loss': 0.22512740212107968, 'Total loss': 0.22512740212107968}
2023-01-05 01:23:58,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:23:58,101 INFO:     Epoch: 46
2023-01-05 01:24:00,372 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46358497540156046, 'Total loss': 0.46358497540156046} | train loss {'Reaction outcome loss': 0.2473763696026003, 'Total loss': 0.2473763696026003}
2023-01-05 01:24:00,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:00,373 INFO:     Epoch: 47
2023-01-05 01:24:02,588 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4858029504617055, 'Total loss': 0.4858029504617055} | train loss {'Reaction outcome loss': 0.22560517028298066, 'Total loss': 0.22560517028298066}
2023-01-05 01:24:02,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:02,588 INFO:     Epoch: 48
2023-01-05 01:24:04,852 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4730894605318705, 'Total loss': 0.4730894605318705} | train loss {'Reaction outcome loss': 0.22156105250579075, 'Total loss': 0.22156105250579075}
2023-01-05 01:24:04,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:04,853 INFO:     Epoch: 49
2023-01-05 01:24:07,115 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45029874593019487, 'Total loss': 0.45029874593019487} | train loss {'Reaction outcome loss': 0.2176514932290192, 'Total loss': 0.2176514932290192}
2023-01-05 01:24:07,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:07,115 INFO:     Epoch: 50
2023-01-05 01:24:09,343 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4551673392454783, 'Total loss': 0.4551673392454783} | train loss {'Reaction outcome loss': 0.21423231543680968, 'Total loss': 0.21423231543680968}
2023-01-05 01:24:09,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:09,344 INFO:     Epoch: 51
2023-01-05 01:24:11,617 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.516801177461942, 'Total loss': 0.516801177461942} | train loss {'Reaction outcome loss': 0.21144803283074737, 'Total loss': 0.21144803283074737}
2023-01-05 01:24:11,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:11,617 INFO:     Epoch: 52
2023-01-05 01:24:13,884 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5348551174004873, 'Total loss': 0.5348551174004873} | train loss {'Reaction outcome loss': 0.21197805756051769, 'Total loss': 0.21197805756051769}
2023-01-05 01:24:13,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:13,884 INFO:     Epoch: 53
2023-01-05 01:24:16,143 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5005831847588221, 'Total loss': 0.5005831847588221} | train loss {'Reaction outcome loss': 0.20932050987123174, 'Total loss': 0.20932050987123174}
2023-01-05 01:24:16,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:16,145 INFO:     Epoch: 54
2023-01-05 01:24:18,413 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5134801973899206, 'Total loss': 0.5134801973899206} | train loss {'Reaction outcome loss': 0.2050223049709398, 'Total loss': 0.2050223049709398}
2023-01-05 01:24:18,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:18,413 INFO:     Epoch: 55
2023-01-05 01:24:20,634 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47997712219754857, 'Total loss': 0.47997712219754857} | train loss {'Reaction outcome loss': 0.2060215715183944, 'Total loss': 0.2060215715183944}
2023-01-05 01:24:20,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:20,635 INFO:     Epoch: 56
2023-01-05 01:24:22,879 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4566564748684565, 'Total loss': 0.4566564748684565} | train loss {'Reaction outcome loss': 0.20636734442550864, 'Total loss': 0.20636734442550864}
2023-01-05 01:24:22,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:22,880 INFO:     Epoch: 57
2023-01-05 01:24:25,125 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48961104949315387, 'Total loss': 0.48961104949315387} | train loss {'Reaction outcome loss': 0.20424655562332508, 'Total loss': 0.20424655562332508}
2023-01-05 01:24:25,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:25,125 INFO:     Epoch: 58
2023-01-05 01:24:27,341 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44403078556060793, 'Total loss': 0.44403078556060793} | train loss {'Reaction outcome loss': 0.20454268315286067, 'Total loss': 0.20454268315286067}
2023-01-05 01:24:27,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:27,341 INFO:     Epoch: 59
2023-01-05 01:24:29,599 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47187465031941733, 'Total loss': 0.47187465031941733} | train loss {'Reaction outcome loss': 0.1962325810834401, 'Total loss': 0.1962325810834401}
2023-01-05 01:24:29,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:29,599 INFO:     Epoch: 60
2023-01-05 01:24:31,829 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4675665318965912, 'Total loss': 0.4675665318965912} | train loss {'Reaction outcome loss': 0.1994914698800025, 'Total loss': 0.1994914698800025}
2023-01-05 01:24:31,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:31,830 INFO:     Epoch: 61
2023-01-05 01:24:34,072 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46170215054104724, 'Total loss': 0.46170215054104724} | train loss {'Reaction outcome loss': 0.1942327886778082, 'Total loss': 0.1942327886778082}
2023-01-05 01:24:34,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:34,072 INFO:     Epoch: 62
2023-01-05 01:24:36,311 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4940657993157705, 'Total loss': 0.4940657993157705} | train loss {'Reaction outcome loss': 0.1973264144591825, 'Total loss': 0.1973264144591825}
2023-01-05 01:24:36,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:36,312 INFO:     Epoch: 63
2023-01-05 01:24:38,564 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49004007478555045, 'Total loss': 0.49004007478555045} | train loss {'Reaction outcome loss': 0.19004029865069585, 'Total loss': 0.19004029865069585}
2023-01-05 01:24:38,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:38,565 INFO:     Epoch: 64
2023-01-05 01:24:40,836 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4671436920762062, 'Total loss': 0.4671436920762062} | train loss {'Reaction outcome loss': 0.19266650149306835, 'Total loss': 0.19266650149306835}
2023-01-05 01:24:40,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:40,837 INFO:     Epoch: 65
2023-01-05 01:24:43,063 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4754673381646474, 'Total loss': 0.4754673381646474} | train loss {'Reaction outcome loss': 0.1919082740746687, 'Total loss': 0.1919082740746687}
2023-01-05 01:24:43,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:43,063 INFO:     Epoch: 66
2023-01-05 01:24:45,301 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46685511469841, 'Total loss': 0.46685511469841} | train loss {'Reaction outcome loss': 0.18923757479237596, 'Total loss': 0.18923757479237596}
2023-01-05 01:24:45,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:45,301 INFO:     Epoch: 67
2023-01-05 01:24:47,561 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46368543477728963, 'Total loss': 0.46368543477728963} | train loss {'Reaction outcome loss': 0.18515603253221413, 'Total loss': 0.18515603253221413}
2023-01-05 01:24:47,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:47,561 INFO:     Epoch: 68
2023-01-05 01:24:49,800 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4816674361626307, 'Total loss': 0.4816674361626307} | train loss {'Reaction outcome loss': 0.18865984834669886, 'Total loss': 0.18865984834669886}
2023-01-05 01:24:49,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:49,800 INFO:     Epoch: 69
2023-01-05 01:24:52,030 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45413274864355724, 'Total loss': 0.45413274864355724} | train loss {'Reaction outcome loss': 0.18277535854207783, 'Total loss': 0.18277535854207783}
2023-01-05 01:24:52,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:52,032 INFO:     Epoch: 70
2023-01-05 01:24:54,190 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47356453438599905, 'Total loss': 0.47356453438599905} | train loss {'Reaction outcome loss': 0.18687496351502478, 'Total loss': 0.18687496351502478}
2023-01-05 01:24:54,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:54,191 INFO:     Epoch: 71
2023-01-05 01:24:56,435 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45305706521806616, 'Total loss': 0.45305706521806616} | train loss {'Reaction outcome loss': 0.19067807480770743, 'Total loss': 0.19067807480770743}
2023-01-05 01:24:56,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:56,435 INFO:     Epoch: 72
2023-01-05 01:24:58,688 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4964676823777457, 'Total loss': 0.4964676823777457} | train loss {'Reaction outcome loss': 0.18448926199926063, 'Total loss': 0.18448926199926063}
2023-01-05 01:24:58,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:24:58,689 INFO:     Epoch: 73
2023-01-05 01:25:00,947 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5479067822297414, 'Total loss': 0.5479067822297414} | train loss {'Reaction outcome loss': 0.18478657219025807, 'Total loss': 0.18478657219025807}
2023-01-05 01:25:00,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:00,947 INFO:     Epoch: 74
2023-01-05 01:25:03,207 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5007329940795898, 'Total loss': 0.5007329940795898} | train loss {'Reaction outcome loss': 0.18436998546720765, 'Total loss': 0.18436998546720765}
2023-01-05 01:25:03,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:03,207 INFO:     Epoch: 75
2023-01-05 01:25:05,466 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47894665201505027, 'Total loss': 0.47894665201505027} | train loss {'Reaction outcome loss': 0.17580944713225347, 'Total loss': 0.17580944713225347}
2023-01-05 01:25:05,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:05,467 INFO:     Epoch: 76
2023-01-05 01:25:07,714 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4923826555411021, 'Total loss': 0.4923826555411021} | train loss {'Reaction outcome loss': 0.2024641350397597, 'Total loss': 0.2024641350397597}
2023-01-05 01:25:07,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:07,715 INFO:     Epoch: 77
2023-01-05 01:25:09,980 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4978148063023885, 'Total loss': 0.4978148063023885} | train loss {'Reaction outcome loss': 0.18066726448064993, 'Total loss': 0.18066726448064993}
2023-01-05 01:25:09,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:09,981 INFO:     Epoch: 78
2023-01-05 01:25:12,201 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4697769681612651, 'Total loss': 0.4697769681612651} | train loss {'Reaction outcome loss': 0.17844780437493077, 'Total loss': 0.17844780437493077}
2023-01-05 01:25:12,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:12,202 INFO:     Epoch: 79
2023-01-05 01:25:14,421 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48004262944062553, 'Total loss': 0.48004262944062553} | train loss {'Reaction outcome loss': 0.17836455924291353, 'Total loss': 0.17836455924291353}
2023-01-05 01:25:14,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:14,421 INFO:     Epoch: 80
2023-01-05 01:25:16,681 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5063920458157857, 'Total loss': 0.5063920458157857} | train loss {'Reaction outcome loss': 0.17727646665593635, 'Total loss': 0.17727646665593635}
2023-01-05 01:25:16,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:16,682 INFO:     Epoch: 81
2023-01-05 01:25:18,926 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49009254574775696, 'Total loss': 0.49009254574775696} | train loss {'Reaction outcome loss': 0.17836275926548179, 'Total loss': 0.17836275926548179}
2023-01-05 01:25:18,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:18,926 INFO:     Epoch: 82
2023-01-05 01:25:21,192 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49394439458847045, 'Total loss': 0.49394439458847045} | train loss {'Reaction outcome loss': 0.17357880982867294, 'Total loss': 0.17357880982867294}
2023-01-05 01:25:21,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:21,192 INFO:     Epoch: 83
2023-01-05 01:25:23,450 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.517464651664098, 'Total loss': 0.517464651664098} | train loss {'Reaction outcome loss': 0.17457354487513826, 'Total loss': 0.17457354487513826}
2023-01-05 01:25:23,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:23,450 INFO:     Epoch: 84
2023-01-05 01:25:25,693 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46358597427606585, 'Total loss': 0.46358597427606585} | train loss {'Reaction outcome loss': 0.17258370431912792, 'Total loss': 0.17258370431912792}
2023-01-05 01:25:25,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:25,693 INFO:     Epoch: 85
2023-01-05 01:25:27,955 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48071272174517315, 'Total loss': 0.48071272174517315} | train loss {'Reaction outcome loss': 0.17173223584920735, 'Total loss': 0.17173223584920735}
2023-01-05 01:25:27,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:27,956 INFO:     Epoch: 86
2023-01-05 01:25:30,229 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49522722562154137, 'Total loss': 0.49522722562154137} | train loss {'Reaction outcome loss': 0.17245531425565855, 'Total loss': 0.17245531425565855}
2023-01-05 01:25:30,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:30,229 INFO:     Epoch: 87
2023-01-05 01:25:32,502 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.506644931435585, 'Total loss': 0.506644931435585} | train loss {'Reaction outcome loss': 0.17376457664278755, 'Total loss': 0.17376457664278755}
2023-01-05 01:25:32,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:32,503 INFO:     Epoch: 88
2023-01-05 01:25:34,768 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4917446464300156, 'Total loss': 0.4917446464300156} | train loss {'Reaction outcome loss': 0.17770517571741526, 'Total loss': 0.17770517571741526}
2023-01-05 01:25:34,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:34,769 INFO:     Epoch: 89
2023-01-05 01:25:37,019 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5034665378431479, 'Total loss': 0.5034665378431479} | train loss {'Reaction outcome loss': 0.16918753774919332, 'Total loss': 0.16918753774919332}
2023-01-05 01:25:37,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:37,019 INFO:     Epoch: 90
2023-01-05 01:25:39,307 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49140066107114155, 'Total loss': 0.49140066107114155} | train loss {'Reaction outcome loss': 0.16839342994427314, 'Total loss': 0.16839342994427314}
2023-01-05 01:25:39,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:39,307 INFO:     Epoch: 91
2023-01-05 01:25:41,589 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4821048974990845, 'Total loss': 0.4821048974990845} | train loss {'Reaction outcome loss': 0.16737446430361952, 'Total loss': 0.16737446430361952}
2023-01-05 01:25:41,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:41,589 INFO:     Epoch: 92
2023-01-05 01:25:43,851 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5170204043388367, 'Total loss': 0.5170204043388367} | train loss {'Reaction outcome loss': 0.16814782203742862, 'Total loss': 0.16814782203742862}
2023-01-05 01:25:43,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:43,851 INFO:     Epoch: 93
2023-01-05 01:25:46,092 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4860006769498189, 'Total loss': 0.4860006769498189} | train loss {'Reaction outcome loss': 0.1745007879622078, 'Total loss': 0.1745007879622078}
2023-01-05 01:25:46,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:46,092 INFO:     Epoch: 94
2023-01-05 01:25:48,345 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5213435490926107, 'Total loss': 0.5213435490926107} | train loss {'Reaction outcome loss': 0.166609091859267, 'Total loss': 0.166609091859267}
2023-01-05 01:25:48,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:48,346 INFO:     Epoch: 95
2023-01-05 01:25:50,606 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47661009232203166, 'Total loss': 0.47661009232203166} | train loss {'Reaction outcome loss': 0.1651466871270964, 'Total loss': 0.1651466871270964}
2023-01-05 01:25:50,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:50,606 INFO:     Epoch: 96
2023-01-05 01:25:52,882 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5367672423521678, 'Total loss': 0.5367672423521678} | train loss {'Reaction outcome loss': 0.17101873880407462, 'Total loss': 0.17101873880407462}
2023-01-05 01:25:52,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:52,882 INFO:     Epoch: 97
2023-01-05 01:25:55,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4687164107958476, 'Total loss': 0.4687164107958476} | train loss {'Reaction outcome loss': 0.16647405825864078, 'Total loss': 0.16647405825864078}
2023-01-05 01:25:55,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:55,137 INFO:     Epoch: 98
2023-01-05 01:25:57,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4742703942582011, 'Total loss': 0.4742703942582011} | train loss {'Reaction outcome loss': 0.1868252618326063, 'Total loss': 0.1868252618326063}
2023-01-05 01:25:57,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:25:57,438 INFO:     Epoch: 99
2023-01-05 01:25:59,665 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4820585770532489, 'Total loss': 0.4820585770532489} | train loss {'Reaction outcome loss': 0.17708355453113278, 'Total loss': 0.17708355453113278}
2023-01-05 01:25:59,666 INFO:     Best model found after epoch 44 of 100.
2023-01-05 01:25:59,666 INFO:   Done with stage: TRAINING
2023-01-05 01:25:59,666 INFO:   Starting stage: EVALUATION
2023-01-05 01:25:59,801 INFO:   Done with stage: EVALUATION
2023-01-05 01:25:59,801 INFO:   Leaving out SEQ value Fold_9
2023-01-05 01:25:59,814 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 01:25:59,814 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:26:00,460 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:26:00,460 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:26:00,531 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:26:00,531 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:26:00,531 INFO:     No hyperparam tuning for this model
2023-01-05 01:26:00,531 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:26:00,531 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:26:00,532 INFO:     None feature selector for col prot
2023-01-05 01:26:00,532 INFO:     None feature selector for col prot
2023-01-05 01:26:00,532 INFO:     None feature selector for col prot
2023-01-05 01:26:00,533 INFO:     None feature selector for col chem
2023-01-05 01:26:00,533 INFO:     None feature selector for col chem
2023-01-05 01:26:00,533 INFO:     None feature selector for col chem
2023-01-05 01:26:00,533 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:26:00,533 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:26:00,534 INFO:     Number of params in model 72931
2023-01-05 01:26:00,538 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:26:00,538 INFO:   Starting stage: TRAINING
2023-01-05 01:26:00,600 INFO:     Val loss before train {'Reaction outcome loss': 1.0019671181837717, 'Total loss': 1.0019671181837717}
2023-01-05 01:26:00,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:00,601 INFO:     Epoch: 0
2023-01-05 01:26:02,868 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8121168573697408, 'Total loss': 0.8121168573697408} | train loss {'Reaction outcome loss': 0.936947275115096, 'Total loss': 0.936947275115096}
2023-01-05 01:26:02,869 INFO:     Found new best model at epoch 0
2023-01-05 01:26:02,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:02,871 INFO:     Epoch: 1
2023-01-05 01:26:05,006 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5881965756416321, 'Total loss': 0.5881965756416321} | train loss {'Reaction outcome loss': 0.6560407577808424, 'Total loss': 0.6560407577808424}
2023-01-05 01:26:05,006 INFO:     Found new best model at epoch 1
2023-01-05 01:26:05,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:05,008 INFO:     Epoch: 2
2023-01-05 01:26:07,294 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.539040344953537, 'Total loss': 0.539040344953537} | train loss {'Reaction outcome loss': 0.5583468606506569, 'Total loss': 0.5583468606506569}
2023-01-05 01:26:07,294 INFO:     Found new best model at epoch 2
2023-01-05 01:26:07,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:07,296 INFO:     Epoch: 3
2023-01-05 01:26:09,580 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5122118214766185, 'Total loss': 0.5122118214766185} | train loss {'Reaction outcome loss': 0.5071826884000009, 'Total loss': 0.5071826884000009}
2023-01-05 01:26:09,581 INFO:     Found new best model at epoch 3
2023-01-05 01:26:09,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:09,582 INFO:     Epoch: 4
2023-01-05 01:26:11,818 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47212562958399457, 'Total loss': 0.47212562958399457} | train loss {'Reaction outcome loss': 0.4720356769368822, 'Total loss': 0.4720356769368822}
2023-01-05 01:26:11,818 INFO:     Found new best model at epoch 4
2023-01-05 01:26:11,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:11,820 INFO:     Epoch: 5
2023-01-05 01:26:14,091 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.465008940299352, 'Total loss': 0.465008940299352} | train loss {'Reaction outcome loss': 0.4471937138688467, 'Total loss': 0.4471937138688467}
2023-01-05 01:26:14,092 INFO:     Found new best model at epoch 5
2023-01-05 01:26:14,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:14,093 INFO:     Epoch: 6
2023-01-05 01:26:16,367 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4361320545276006, 'Total loss': 0.4361320545276006} | train loss {'Reaction outcome loss': 0.4270932254317365, 'Total loss': 0.4270932254317365}
2023-01-05 01:26:16,367 INFO:     Found new best model at epoch 6
2023-01-05 01:26:16,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:16,368 INFO:     Epoch: 7
2023-01-05 01:26:18,632 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43567972878615063, 'Total loss': 0.43567972878615063} | train loss {'Reaction outcome loss': 0.4095412080810554, 'Total loss': 0.4095412080810554}
2023-01-05 01:26:18,632 INFO:     Found new best model at epoch 7
2023-01-05 01:26:18,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:18,634 INFO:     Epoch: 8
2023-01-05 01:26:20,916 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.433549165725708, 'Total loss': 0.433549165725708} | train loss {'Reaction outcome loss': 0.41097527607411577, 'Total loss': 0.41097527607411577}
2023-01-05 01:26:20,916 INFO:     Found new best model at epoch 8
2023-01-05 01:26:20,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:20,917 INFO:     Epoch: 9
2023-01-05 01:26:23,180 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4427332808574041, 'Total loss': 0.4427332808574041} | train loss {'Reaction outcome loss': 0.39343966114540596, 'Total loss': 0.39343966114540596}
2023-01-05 01:26:23,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:23,181 INFO:     Epoch: 10
2023-01-05 01:26:25,462 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4112364242474238, 'Total loss': 0.4112364242474238} | train loss {'Reaction outcome loss': 0.37878925044197537, 'Total loss': 0.37878925044197537}
2023-01-05 01:26:25,462 INFO:     Found new best model at epoch 10
2023-01-05 01:26:25,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:25,463 INFO:     Epoch: 11
2023-01-05 01:26:27,738 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4140803207953771, 'Total loss': 0.4140803207953771} | train loss {'Reaction outcome loss': 0.36754152333984774, 'Total loss': 0.36754152333984774}
2023-01-05 01:26:27,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:27,738 INFO:     Epoch: 12
2023-01-05 01:26:30,006 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4303222169478734, 'Total loss': 0.4303222169478734} | train loss {'Reaction outcome loss': 0.36080977213324344, 'Total loss': 0.36080977213324344}
2023-01-05 01:26:30,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:30,006 INFO:     Epoch: 13
2023-01-05 01:26:32,283 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42938945492108666, 'Total loss': 0.42938945492108666} | train loss {'Reaction outcome loss': 0.3563146387375351, 'Total loss': 0.3563146387375351}
2023-01-05 01:26:32,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:32,284 INFO:     Epoch: 14
2023-01-05 01:26:34,558 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4486396292845408, 'Total loss': 0.4486396292845408} | train loss {'Reaction outcome loss': 0.3551776026395838, 'Total loss': 0.3551776026395838}
2023-01-05 01:26:34,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:34,560 INFO:     Epoch: 15
2023-01-05 01:26:36,833 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41547137399514517, 'Total loss': 0.41547137399514517} | train loss {'Reaction outcome loss': 0.34289648099903663, 'Total loss': 0.34289648099903663}
2023-01-05 01:26:36,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:36,833 INFO:     Epoch: 16
2023-01-05 01:26:39,113 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46264272928237915, 'Total loss': 0.46264272928237915} | train loss {'Reaction outcome loss': 0.3370614235147672, 'Total loss': 0.3370614235147672}
2023-01-05 01:26:39,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:39,113 INFO:     Epoch: 17
2023-01-05 01:26:41,377 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4469560985763868, 'Total loss': 0.4469560985763868} | train loss {'Reaction outcome loss': 0.3288122639869866, 'Total loss': 0.3288122639869866}
2023-01-05 01:26:41,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:41,378 INFO:     Epoch: 18
2023-01-05 01:26:43,666 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44799544910589856, 'Total loss': 0.44799544910589856} | train loss {'Reaction outcome loss': 0.3332173807598799, 'Total loss': 0.3332173807598799}
2023-01-05 01:26:43,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:43,666 INFO:     Epoch: 19
2023-01-05 01:26:45,942 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42850978871186574, 'Total loss': 0.42850978871186574} | train loss {'Reaction outcome loss': 0.30927256544701, 'Total loss': 0.30927256544701}
2023-01-05 01:26:45,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:45,943 INFO:     Epoch: 20
2023-01-05 01:26:48,209 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44975536564985913, 'Total loss': 0.44975536564985913} | train loss {'Reaction outcome loss': 0.30123192399227317, 'Total loss': 0.30123192399227317}
2023-01-05 01:26:48,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:48,209 INFO:     Epoch: 21
2023-01-05 01:26:50,490 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43810255924860636, 'Total loss': 0.43810255924860636} | train loss {'Reaction outcome loss': 0.2948854218871481, 'Total loss': 0.2948854218871481}
2023-01-05 01:26:50,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:50,491 INFO:     Epoch: 22
2023-01-05 01:26:52,731 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48806718190511067, 'Total loss': 0.48806718190511067} | train loss {'Reaction outcome loss': 0.29018885153261403, 'Total loss': 0.29018885153261403}
2023-01-05 01:26:52,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:52,731 INFO:     Epoch: 23
2023-01-05 01:26:54,853 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4317980229854584, 'Total loss': 0.4317980229854584} | train loss {'Reaction outcome loss': 0.2843197847082131, 'Total loss': 0.2843197847082131}
2023-01-05 01:26:54,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:54,854 INFO:     Epoch: 24
2023-01-05 01:26:57,117 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46133669316768644, 'Total loss': 0.46133669316768644} | train loss {'Reaction outcome loss': 0.2825069697506294, 'Total loss': 0.2825069697506294}
2023-01-05 01:26:57,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:57,118 INFO:     Epoch: 25
2023-01-05 01:26:59,360 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46119747757911683, 'Total loss': 0.46119747757911683} | train loss {'Reaction outcome loss': 0.2773624273772905, 'Total loss': 0.2773624273772905}
2023-01-05 01:26:59,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:26:59,360 INFO:     Epoch: 26
2023-01-05 01:27:01,604 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43740623792012534, 'Total loss': 0.43740623792012534} | train loss {'Reaction outcome loss': 0.2746912302462843, 'Total loss': 0.2746912302462843}
2023-01-05 01:27:01,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:01,604 INFO:     Epoch: 27
2023-01-05 01:27:03,820 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44415781994660697, 'Total loss': 0.44415781994660697} | train loss {'Reaction outcome loss': 0.26799524433311267, 'Total loss': 0.26799524433311267}
2023-01-05 01:27:03,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:03,820 INFO:     Epoch: 28
2023-01-05 01:27:06,059 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4727196514606476, 'Total loss': 0.4727196514606476} | train loss {'Reaction outcome loss': 0.25898731789430196, 'Total loss': 0.25898731789430196}
2023-01-05 01:27:06,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:06,059 INFO:     Epoch: 29
2023-01-05 01:27:08,295 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43269221285978954, 'Total loss': 0.43269221285978954} | train loss {'Reaction outcome loss': 0.2604910589431012, 'Total loss': 0.2604910589431012}
2023-01-05 01:27:08,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:08,295 INFO:     Epoch: 30
2023-01-05 01:27:10,523 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4478510876496633, 'Total loss': 0.4478510876496633} | train loss {'Reaction outcome loss': 0.25054750870280573, 'Total loss': 0.25054750870280573}
2023-01-05 01:27:10,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:10,524 INFO:     Epoch: 31
2023-01-05 01:27:12,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43788502116998035, 'Total loss': 0.43788502116998035} | train loss {'Reaction outcome loss': 0.2511196021915184, 'Total loss': 0.2511196021915184}
2023-01-05 01:27:12,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:12,794 INFO:     Epoch: 32
2023-01-05 01:27:15,051 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4323682144284248, 'Total loss': 0.4323682144284248} | train loss {'Reaction outcome loss': 0.24659171409608013, 'Total loss': 0.24659171409608013}
2023-01-05 01:27:15,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:15,051 INFO:     Epoch: 33
2023-01-05 01:27:17,293 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43736892491579055, 'Total loss': 0.43736892491579055} | train loss {'Reaction outcome loss': 0.24064263457894677, 'Total loss': 0.24064263457894677}
2023-01-05 01:27:17,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:17,294 INFO:     Epoch: 34
2023-01-05 01:27:19,562 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45425522526105244, 'Total loss': 0.45425522526105244} | train loss {'Reaction outcome loss': 0.266499256549835, 'Total loss': 0.266499256549835}
2023-01-05 01:27:19,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:19,562 INFO:     Epoch: 35
2023-01-05 01:27:21,804 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45489388803641, 'Total loss': 0.45489388803641} | train loss {'Reaction outcome loss': 0.23756530805679876, 'Total loss': 0.23756530805679876}
2023-01-05 01:27:21,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:21,804 INFO:     Epoch: 36
2023-01-05 01:27:24,052 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46136099894841515, 'Total loss': 0.46136099894841515} | train loss {'Reaction outcome loss': 0.23354109440612997, 'Total loss': 0.23354109440612997}
2023-01-05 01:27:24,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:24,052 INFO:     Epoch: 37
2023-01-05 01:27:26,230 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47425005038579304, 'Total loss': 0.47425005038579304} | train loss {'Reaction outcome loss': 0.22967403009014548, 'Total loss': 0.22967403009014548}
2023-01-05 01:27:26,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:26,230 INFO:     Epoch: 38
2023-01-05 01:27:28,491 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4936515380938848, 'Total loss': 0.4936515380938848} | train loss {'Reaction outcome loss': 0.2403940186849323, 'Total loss': 0.2403940186849323}
2023-01-05 01:27:28,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:28,491 INFO:     Epoch: 39
2023-01-05 01:27:30,731 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43954573074976605, 'Total loss': 0.43954573074976605} | train loss {'Reaction outcome loss': 0.25608009510619595, 'Total loss': 0.25608009510619595}
2023-01-05 01:27:30,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:30,732 INFO:     Epoch: 40
2023-01-05 01:27:32,993 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4377743249138196, 'Total loss': 0.4377743249138196} | train loss {'Reaction outcome loss': 0.2250919929217122, 'Total loss': 0.2250919929217122}
2023-01-05 01:27:32,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:32,993 INFO:     Epoch: 41
2023-01-05 01:27:35,249 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4806268498301506, 'Total loss': 0.4806268498301506} | train loss {'Reaction outcome loss': 0.22152707145289532, 'Total loss': 0.22152707145289532}
2023-01-05 01:27:35,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:35,249 INFO:     Epoch: 42
2023-01-05 01:27:37,467 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4467920278509458, 'Total loss': 0.4467920278509458} | train loss {'Reaction outcome loss': 0.23380406653049632, 'Total loss': 0.23380406653049632}
2023-01-05 01:27:37,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:37,467 INFO:     Epoch: 43
2023-01-05 01:27:39,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43083378312488396, 'Total loss': 0.43083378312488396} | train loss {'Reaction outcome loss': 0.21818615089693555, 'Total loss': 0.21818615089693555}
2023-01-05 01:27:39,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:39,674 INFO:     Epoch: 44
2023-01-05 01:27:41,937 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4507798115412394, 'Total loss': 0.4507798115412394} | train loss {'Reaction outcome loss': 0.21468863893128204, 'Total loss': 0.21468863893128204}
2023-01-05 01:27:41,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:41,938 INFO:     Epoch: 45
2023-01-05 01:27:44,207 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46126472353935244, 'Total loss': 0.46126472353935244} | train loss {'Reaction outcome loss': 0.22106351158784135, 'Total loss': 0.22106351158784135}
2023-01-05 01:27:44,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:44,207 INFO:     Epoch: 46
2023-01-05 01:27:46,448 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4480984956026077, 'Total loss': 0.4480984956026077} | train loss {'Reaction outcome loss': 0.2227524715995389, 'Total loss': 0.2227524715995389}
2023-01-05 01:27:46,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:46,448 INFO:     Epoch: 47
2023-01-05 01:27:48,711 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4647336443265279, 'Total loss': 0.4647336443265279} | train loss {'Reaction outcome loss': 0.24159451161065829, 'Total loss': 0.24159451161065829}
2023-01-05 01:27:48,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:48,712 INFO:     Epoch: 48
2023-01-05 01:27:50,948 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.489641597867012, 'Total loss': 0.489641597867012} | train loss {'Reaction outcome loss': 0.21070289162147396, 'Total loss': 0.21070289162147396}
2023-01-05 01:27:50,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:50,948 INFO:     Epoch: 49
2023-01-05 01:27:53,204 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4843307207028071, 'Total loss': 0.4843307207028071} | train loss {'Reaction outcome loss': 0.20277682411403436, 'Total loss': 0.20277682411403436}
2023-01-05 01:27:53,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:53,204 INFO:     Epoch: 50
2023-01-05 01:27:55,451 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48965475559234617, 'Total loss': 0.48965475559234617} | train loss {'Reaction outcome loss': 0.2015874167138358, 'Total loss': 0.2015874167138358}
2023-01-05 01:27:55,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:55,452 INFO:     Epoch: 51
2023-01-05 01:27:57,646 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47303620278835296, 'Total loss': 0.47303620278835296} | train loss {'Reaction outcome loss': 0.19885546442094273, 'Total loss': 0.19885546442094273}
2023-01-05 01:27:57,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:57,647 INFO:     Epoch: 52
2023-01-05 01:27:59,873 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46966524521509806, 'Total loss': 0.46966524521509806} | train loss {'Reaction outcome loss': 0.2004929956359168, 'Total loss': 0.2004929956359168}
2023-01-05 01:27:59,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:27:59,874 INFO:     Epoch: 53
2023-01-05 01:28:02,066 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4798033356666565, 'Total loss': 0.4798033356666565} | train loss {'Reaction outcome loss': 0.20338942286722106, 'Total loss': 0.20338942286722106}
2023-01-05 01:28:02,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:02,068 INFO:     Epoch: 54
2023-01-05 01:28:04,279 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4514991064866384, 'Total loss': 0.4514991064866384} | train loss {'Reaction outcome loss': 0.1980035142573204, 'Total loss': 0.1980035142573204}
2023-01-05 01:28:04,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:04,279 INFO:     Epoch: 55
2023-01-05 01:28:06,506 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4465606838464737, 'Total loss': 0.4465606838464737} | train loss {'Reaction outcome loss': 0.19452120144381732, 'Total loss': 0.19452120144381732}
2023-01-05 01:28:06,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:06,507 INFO:     Epoch: 56
2023-01-05 01:28:08,742 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.475690329571565, 'Total loss': 0.475690329571565} | train loss {'Reaction outcome loss': 0.19602247783193993, 'Total loss': 0.19602247783193993}
2023-01-05 01:28:08,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:08,743 INFO:     Epoch: 57
2023-01-05 01:28:11,007 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4504217435916265, 'Total loss': 0.4504217435916265} | train loss {'Reaction outcome loss': 0.19139781638817943, 'Total loss': 0.19139781638817943}
2023-01-05 01:28:11,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:11,007 INFO:     Epoch: 58
2023-01-05 01:28:13,273 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4611528379842639, 'Total loss': 0.4611528379842639} | train loss {'Reaction outcome loss': 0.18971119707524506, 'Total loss': 0.18971119707524506}
2023-01-05 01:28:13,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:13,273 INFO:     Epoch: 59
2023-01-05 01:28:15,497 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4619454135497411, 'Total loss': 0.4619454135497411} | train loss {'Reaction outcome loss': 0.18936485005110296, 'Total loss': 0.18936485005110296}
2023-01-05 01:28:15,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:15,497 INFO:     Epoch: 60
2023-01-05 01:28:17,765 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44664037426312764, 'Total loss': 0.44664037426312764} | train loss {'Reaction outcome loss': 0.18895107920727003, 'Total loss': 0.18895107920727003}
2023-01-05 01:28:17,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:17,767 INFO:     Epoch: 61
2023-01-05 01:28:20,006 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4601036339998245, 'Total loss': 0.4601036339998245} | train loss {'Reaction outcome loss': 0.18666600437153238, 'Total loss': 0.18666600437153238}
2023-01-05 01:28:20,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:20,007 INFO:     Epoch: 62
2023-01-05 01:28:22,269 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44075816571712495, 'Total loss': 0.44075816571712495} | train loss {'Reaction outcome loss': 0.18702063179330583, 'Total loss': 0.18702063179330583}
2023-01-05 01:28:22,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:22,269 INFO:     Epoch: 63
2023-01-05 01:28:24,532 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4764350938300292, 'Total loss': 0.4764350938300292} | train loss {'Reaction outcome loss': 0.18250626048272048, 'Total loss': 0.18250626048272048}
2023-01-05 01:28:24,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:24,533 INFO:     Epoch: 64
2023-01-05 01:28:26,799 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5019110639890035, 'Total loss': 0.5019110639890035} | train loss {'Reaction outcome loss': 0.18264810796962053, 'Total loss': 0.18264810796962053}
2023-01-05 01:28:26,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:26,799 INFO:     Epoch: 65
2023-01-05 01:28:29,059 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49035220841566723, 'Total loss': 0.49035220841566723} | train loss {'Reaction outcome loss': 0.18494937726232372, 'Total loss': 0.18494937726232372}
2023-01-05 01:28:29,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:29,059 INFO:     Epoch: 66
2023-01-05 01:28:31,255 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4921084225177765, 'Total loss': 0.4921084225177765} | train loss {'Reaction outcome loss': 0.185207969254723, 'Total loss': 0.185207969254723}
2023-01-05 01:28:31,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:31,256 INFO:     Epoch: 67
2023-01-05 01:28:33,468 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5012457887331645, 'Total loss': 0.5012457887331645} | train loss {'Reaction outcome loss': 0.17961126999854468, 'Total loss': 0.17961126999854468}
2023-01-05 01:28:33,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:33,468 INFO:     Epoch: 68
2023-01-05 01:28:35,711 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49623206655184426, 'Total loss': 0.49623206655184426} | train loss {'Reaction outcome loss': 0.1833292769889353, 'Total loss': 0.1833292769889353}
2023-01-05 01:28:35,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:35,711 INFO:     Epoch: 69
2023-01-05 01:28:37,911 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5222222199042638, 'Total loss': 0.5222222199042638} | train loss {'Reaction outcome loss': 0.18173524697187426, 'Total loss': 0.18173524697187426}
2023-01-05 01:28:37,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:37,912 INFO:     Epoch: 70
2023-01-05 01:28:40,173 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47770377397537234, 'Total loss': 0.47770377397537234} | train loss {'Reaction outcome loss': 0.18003194055020594, 'Total loss': 0.18003194055020594}
2023-01-05 01:28:40,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:40,174 INFO:     Epoch: 71
2023-01-05 01:28:42,402 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4964354674021403, 'Total loss': 0.4964354674021403} | train loss {'Reaction outcome loss': 0.17534538892441956, 'Total loss': 0.17534538892441956}
2023-01-05 01:28:42,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:42,402 INFO:     Epoch: 72
2023-01-05 01:28:44,642 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47959083517392476, 'Total loss': 0.47959083517392476} | train loss {'Reaction outcome loss': 0.17340466784239456, 'Total loss': 0.17340466784239456}
2023-01-05 01:28:44,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:44,642 INFO:     Epoch: 73
2023-01-05 01:28:46,902 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49754888117313384, 'Total loss': 0.49754888117313384} | train loss {'Reaction outcome loss': 0.17562426945559031, 'Total loss': 0.17562426945559031}
2023-01-05 01:28:46,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:46,903 INFO:     Epoch: 74
2023-01-05 01:28:49,119 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46553473273913065, 'Total loss': 0.46553473273913065} | train loss {'Reaction outcome loss': 0.17523344180549233, 'Total loss': 0.17523344180549233}
2023-01-05 01:28:49,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:49,119 INFO:     Epoch: 75
2023-01-05 01:28:51,379 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4817730374634266, 'Total loss': 0.4817730374634266} | train loss {'Reaction outcome loss': 0.1757630510441284, 'Total loss': 0.1757630510441284}
2023-01-05 01:28:51,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:51,379 INFO:     Epoch: 76
2023-01-05 01:28:53,642 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48893373608589175, 'Total loss': 0.48893373608589175} | train loss {'Reaction outcome loss': 0.18547803721984552, 'Total loss': 0.18547803721984552}
2023-01-05 01:28:53,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:53,643 INFO:     Epoch: 77
2023-01-05 01:28:55,886 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4680557683110237, 'Total loss': 0.4680557683110237} | train loss {'Reaction outcome loss': 0.21817809858834336, 'Total loss': 0.21817809858834336}
2023-01-05 01:28:55,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:55,886 INFO:     Epoch: 78
2023-01-05 01:28:58,082 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4688804119825363, 'Total loss': 0.4688804119825363} | train loss {'Reaction outcome loss': 0.1776448174993899, 'Total loss': 0.1776448174993899}
2023-01-05 01:28:58,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:28:58,082 INFO:     Epoch: 79
2023-01-05 01:29:00,332 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4733362649256984, 'Total loss': 0.4733362649256984} | train loss {'Reaction outcome loss': 0.17152036932816703, 'Total loss': 0.17152036932816703}
2023-01-05 01:29:00,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:00,332 INFO:     Epoch: 80
2023-01-05 01:29:02,585 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48216889003912605, 'Total loss': 0.48216889003912605} | train loss {'Reaction outcome loss': 0.17088156646028385, 'Total loss': 0.17088156646028385}
2023-01-05 01:29:02,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:02,585 INFO:     Epoch: 81
2023-01-05 01:29:04,847 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4663351615269979, 'Total loss': 0.4663351615269979} | train loss {'Reaction outcome loss': 0.1676081213216067, 'Total loss': 0.1676081213216067}
2023-01-05 01:29:04,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:04,848 INFO:     Epoch: 82
2023-01-05 01:29:07,100 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48112861116727196, 'Total loss': 0.48112861116727196} | train loss {'Reaction outcome loss': 0.16649440737345014, 'Total loss': 0.16649440737345014}
2023-01-05 01:29:07,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:07,101 INFO:     Epoch: 83
2023-01-05 01:29:09,349 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4570271037518978, 'Total loss': 0.4570271037518978} | train loss {'Reaction outcome loss': 0.17305594198852844, 'Total loss': 0.17305594198852844}
2023-01-05 01:29:09,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:09,349 INFO:     Epoch: 84
2023-01-05 01:29:11,597 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46068523577414455, 'Total loss': 0.46068523577414455} | train loss {'Reaction outcome loss': 0.16870539310131816, 'Total loss': 0.16870539310131816}
2023-01-05 01:29:11,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:11,597 INFO:     Epoch: 85
2023-01-05 01:29:13,843 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4767069578170776, 'Total loss': 0.4767069578170776} | train loss {'Reaction outcome loss': 0.16441209145072525, 'Total loss': 0.16441209145072525}
2023-01-05 01:29:13,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:13,843 INFO:     Epoch: 86
2023-01-05 01:29:16,104 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47398682435353595, 'Total loss': 0.47398682435353595} | train loss {'Reaction outcome loss': 0.16530257481950894, 'Total loss': 0.16530257481950894}
2023-01-05 01:29:16,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:16,105 INFO:     Epoch: 87
2023-01-05 01:29:18,330 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5037917216618856, 'Total loss': 0.5037917216618856} | train loss {'Reaction outcome loss': 0.16236116345401347, 'Total loss': 0.16236116345401347}
2023-01-05 01:29:18,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:18,330 INFO:     Epoch: 88
2023-01-05 01:29:20,545 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.535060715675354, 'Total loss': 0.535060715675354} | train loss {'Reaction outcome loss': 0.16397755057593147, 'Total loss': 0.16397755057593147}
2023-01-05 01:29:20,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:20,546 INFO:     Epoch: 89
2023-01-05 01:29:22,759 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5162763059139251, 'Total loss': 0.5162763059139251} | train loss {'Reaction outcome loss': 0.16012818607893112, 'Total loss': 0.16012818607893112}
2023-01-05 01:29:22,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:22,760 INFO:     Epoch: 90
2023-01-05 01:29:25,024 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4982145338008801, 'Total loss': 0.4982145338008801} | train loss {'Reaction outcome loss': 0.1716033925835475, 'Total loss': 0.1716033925835475}
2023-01-05 01:29:25,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:25,024 INFO:     Epoch: 91
2023-01-05 01:29:27,222 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4880534072717031, 'Total loss': 0.4880534072717031} | train loss {'Reaction outcome loss': 0.1604290335148951, 'Total loss': 0.1604290335148951}
2023-01-05 01:29:27,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:27,222 INFO:     Epoch: 92
2023-01-05 01:29:29,484 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4815133611361186, 'Total loss': 0.4815133611361186} | train loss {'Reaction outcome loss': 0.16278875721795688, 'Total loss': 0.16278875721795688}
2023-01-05 01:29:29,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:29,485 INFO:     Epoch: 93
2023-01-05 01:29:31,701 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5105660577615102, 'Total loss': 0.5105660577615102} | train loss {'Reaction outcome loss': 0.16622282919959855, 'Total loss': 0.16622282919959855}
2023-01-05 01:29:31,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:31,701 INFO:     Epoch: 94
2023-01-05 01:29:33,957 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4834523816903432, 'Total loss': 0.4834523816903432} | train loss {'Reaction outcome loss': 0.16715347883903145, 'Total loss': 0.16715347883903145}
2023-01-05 01:29:33,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:33,957 INFO:     Epoch: 95
2023-01-05 01:29:36,269 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48421410620212557, 'Total loss': 0.48421410620212557} | train loss {'Reaction outcome loss': 0.1642384042447109, 'Total loss': 0.1642384042447109}
2023-01-05 01:29:36,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:36,269 INFO:     Epoch: 96
2023-01-05 01:29:38,503 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5244912346204121, 'Total loss': 0.5244912346204121} | train loss {'Reaction outcome loss': 0.16404483091447628, 'Total loss': 0.16404483091447628}
2023-01-05 01:29:38,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:38,504 INFO:     Epoch: 97
2023-01-05 01:29:40,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49482891261577605, 'Total loss': 0.49482891261577605} | train loss {'Reaction outcome loss': 0.16067622656270902, 'Total loss': 0.16067622656270902}
2023-01-05 01:29:40,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:40,771 INFO:     Epoch: 98
2023-01-05 01:29:43,009 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5034789085388184, 'Total loss': 0.5034789085388184} | train loss {'Reaction outcome loss': 0.15953913303783865, 'Total loss': 0.15953913303783865}
2023-01-05 01:29:43,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:43,010 INFO:     Epoch: 99
2023-01-05 01:29:45,249 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5121709744135539, 'Total loss': 0.5121709744135539} | train loss {'Reaction outcome loss': 0.16313575694094534, 'Total loss': 0.16313575694094534}
2023-01-05 01:29:45,249 INFO:     Best model found after epoch 11 of 100.
2023-01-05 01:29:45,249 INFO:   Done with stage: TRAINING
2023-01-05 01:29:45,249 INFO:   Starting stage: EVALUATION
2023-01-05 01:29:45,385 INFO:   Done with stage: EVALUATION
2023-01-05 01:29:45,393 INFO:   Leaving out SEQ value Fold_0
2023-01-05 01:29:45,406 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 01:29:45,406 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:29:46,052 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:29:46,052 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:29:46,122 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:29:46,122 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:29:46,122 INFO:     No hyperparam tuning for this model
2023-01-05 01:29:46,122 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:29:46,123 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:29:46,123 INFO:     None feature selector for col prot
2023-01-05 01:29:46,123 INFO:     None feature selector for col prot
2023-01-05 01:29:46,124 INFO:     None feature selector for col prot
2023-01-05 01:29:46,124 INFO:     None feature selector for col chem
2023-01-05 01:29:46,124 INFO:     None feature selector for col chem
2023-01-05 01:29:46,124 INFO:     None feature selector for col chem
2023-01-05 01:29:46,124 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:29:46,124 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:29:46,126 INFO:     Number of params in model 72931
2023-01-05 01:29:46,129 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:29:46,129 INFO:   Starting stage: TRAINING
2023-01-05 01:29:46,191 INFO:     Val loss before train {'Reaction outcome loss': 1.0310769200325012, 'Total loss': 1.0310769200325012}
2023-01-05 01:29:46,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:46,191 INFO:     Epoch: 0
2023-01-05 01:29:48,452 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8673771897951762, 'Total loss': 0.8673771897951762} | train loss {'Reaction outcome loss': 0.9502423733904741, 'Total loss': 0.9502423733904741}
2023-01-05 01:29:48,453 INFO:     Found new best model at epoch 0
2023-01-05 01:29:48,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:48,454 INFO:     Epoch: 1
2023-01-05 01:29:50,688 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5652298927307129, 'Total loss': 0.5652298927307129} | train loss {'Reaction outcome loss': 0.649360867244178, 'Total loss': 0.649360867244178}
2023-01-05 01:29:50,688 INFO:     Found new best model at epoch 1
2023-01-05 01:29:50,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:50,689 INFO:     Epoch: 2
2023-01-05 01:29:52,861 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.518968857328097, 'Total loss': 0.518968857328097} | train loss {'Reaction outcome loss': 0.5414708452164263, 'Total loss': 0.5414708452164263}
2023-01-05 01:29:52,861 INFO:     Found new best model at epoch 2
2023-01-05 01:29:52,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:52,862 INFO:     Epoch: 3
2023-01-05 01:29:55,104 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4727695753177007, 'Total loss': 0.4727695753177007} | train loss {'Reaction outcome loss': 0.5070782427623719, 'Total loss': 0.5070782427623719}
2023-01-05 01:29:55,104 INFO:     Found new best model at epoch 3
2023-01-05 01:29:55,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:55,106 INFO:     Epoch: 4
2023-01-05 01:29:57,355 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45552614629268645, 'Total loss': 0.45552614629268645} | train loss {'Reaction outcome loss': 0.4781071688200388, 'Total loss': 0.4781071688200388}
2023-01-05 01:29:57,355 INFO:     Found new best model at epoch 4
2023-01-05 01:29:57,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:57,356 INFO:     Epoch: 5
2023-01-05 01:29:59,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4510339180628459, 'Total loss': 0.4510339180628459} | train loss {'Reaction outcome loss': 0.4637607688327198, 'Total loss': 0.4637607688327198}
2023-01-05 01:29:59,628 INFO:     Found new best model at epoch 5
2023-01-05 01:29:59,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:29:59,629 INFO:     Epoch: 6
2023-01-05 01:30:01,893 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4380697468916575, 'Total loss': 0.4380697468916575} | train loss {'Reaction outcome loss': 0.44950083294964355, 'Total loss': 0.44950083294964355}
2023-01-05 01:30:01,893 INFO:     Found new best model at epoch 6
2023-01-05 01:30:01,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:01,895 INFO:     Epoch: 7
2023-01-05 01:30:04,159 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4197753926118215, 'Total loss': 0.4197753926118215} | train loss {'Reaction outcome loss': 0.43273505166955833, 'Total loss': 0.43273505166955833}
2023-01-05 01:30:04,159 INFO:     Found new best model at epoch 7
2023-01-05 01:30:04,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:04,160 INFO:     Epoch: 8
2023-01-05 01:30:06,378 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42358336846033734, 'Total loss': 0.42358336846033734} | train loss {'Reaction outcome loss': 0.42205762627122895, 'Total loss': 0.42205762627122895}
2023-01-05 01:30:06,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:06,379 INFO:     Epoch: 9
2023-01-05 01:30:08,528 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40351562897364296, 'Total loss': 0.40351562897364296} | train loss {'Reaction outcome loss': 0.40960973757450964, 'Total loss': 0.40960973757450964}
2023-01-05 01:30:08,528 INFO:     Found new best model at epoch 9
2023-01-05 01:30:08,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:08,529 INFO:     Epoch: 10
2023-01-05 01:30:10,795 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4340649435917536, 'Total loss': 0.4340649435917536} | train loss {'Reaction outcome loss': 0.4012180865637661, 'Total loss': 0.4012180865637661}
2023-01-05 01:30:10,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:10,795 INFO:     Epoch: 11
2023-01-05 01:30:13,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4119002878665924, 'Total loss': 0.4119002878665924} | train loss {'Reaction outcome loss': 0.39116068902438966, 'Total loss': 0.39116068902438966}
2023-01-05 01:30:13,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:13,055 INFO:     Epoch: 12
2023-01-05 01:30:15,275 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4114193767309189, 'Total loss': 0.4114193767309189} | train loss {'Reaction outcome loss': 0.38611512981140916, 'Total loss': 0.38611512981140916}
2023-01-05 01:30:15,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:15,275 INFO:     Epoch: 13
2023-01-05 01:30:17,514 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39890310962994896, 'Total loss': 0.39890310962994896} | train loss {'Reaction outcome loss': 0.3734545541677938, 'Total loss': 0.3734545541677938}
2023-01-05 01:30:17,514 INFO:     Found new best model at epoch 13
2023-01-05 01:30:17,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:17,516 INFO:     Epoch: 14
2023-01-05 01:30:19,744 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40348256230354307, 'Total loss': 0.40348256230354307} | train loss {'Reaction outcome loss': 0.36283140212965564, 'Total loss': 0.36283140212965564}
2023-01-05 01:30:19,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:19,745 INFO:     Epoch: 15
2023-01-05 01:30:22,000 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4218233942985535, 'Total loss': 0.4218233942985535} | train loss {'Reaction outcome loss': 0.35536540699177893, 'Total loss': 0.35536540699177893}
2023-01-05 01:30:22,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:22,000 INFO:     Epoch: 16
2023-01-05 01:30:24,264 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4009053558111191, 'Total loss': 0.4009053558111191} | train loss {'Reaction outcome loss': 0.34888431243261026, 'Total loss': 0.34888431243261026}
2023-01-05 01:30:24,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:24,264 INFO:     Epoch: 17
2023-01-05 01:30:26,524 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39651172459125517, 'Total loss': 0.39651172459125517} | train loss {'Reaction outcome loss': 0.34059165400770103, 'Total loss': 0.34059165400770103}
2023-01-05 01:30:26,524 INFO:     Found new best model at epoch 17
2023-01-05 01:30:26,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:26,525 INFO:     Epoch: 18
2023-01-05 01:30:28,768 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40002314498027164, 'Total loss': 0.40002314498027164} | train loss {'Reaction outcome loss': 0.33343866234666336, 'Total loss': 0.33343866234666336}
2023-01-05 01:30:28,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:28,769 INFO:     Epoch: 19
2023-01-05 01:30:30,982 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3927016446987788, 'Total loss': 0.3927016446987788} | train loss {'Reaction outcome loss': 0.35015384318388026, 'Total loss': 0.35015384318388026}
2023-01-05 01:30:30,982 INFO:     Found new best model at epoch 19
2023-01-05 01:30:30,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:30,984 INFO:     Epoch: 20
2023-01-05 01:30:33,224 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40317546725273135, 'Total loss': 0.40317546725273135} | train loss {'Reaction outcome loss': 0.32052860132633343, 'Total loss': 0.32052860132633343}
2023-01-05 01:30:33,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:33,224 INFO:     Epoch: 21
2023-01-05 01:30:35,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4050843924283981, 'Total loss': 0.4050843924283981} | train loss {'Reaction outcome loss': 0.31363064293375076, 'Total loss': 0.31363064293375076}
2023-01-05 01:30:35,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:35,485 INFO:     Epoch: 22
2023-01-05 01:30:37,711 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3948568880558014, 'Total loss': 0.3948568880558014} | train loss {'Reaction outcome loss': 0.30854996591064054, 'Total loss': 0.30854996591064054}
2023-01-05 01:30:37,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:37,711 INFO:     Epoch: 23
2023-01-05 01:30:39,930 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42271403471628827, 'Total loss': 0.42271403471628827} | train loss {'Reaction outcome loss': 0.3075320737088855, 'Total loss': 0.3075320737088855}
2023-01-05 01:30:39,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:39,930 INFO:     Epoch: 24
2023-01-05 01:30:42,181 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38530238171418507, 'Total loss': 0.38530238171418507} | train loss {'Reaction outcome loss': 0.3005485447710785, 'Total loss': 0.3005485447710785}
2023-01-05 01:30:42,182 INFO:     Found new best model at epoch 24
2023-01-05 01:30:42,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:42,183 INFO:     Epoch: 25
2023-01-05 01:30:44,427 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4011191656192144, 'Total loss': 0.4011191656192144} | train loss {'Reaction outcome loss': 0.2933118491265351, 'Total loss': 0.2933118491265351}
2023-01-05 01:30:44,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:44,427 INFO:     Epoch: 26
2023-01-05 01:30:46,700 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3955526227752368, 'Total loss': 0.3955526227752368} | train loss {'Reaction outcome loss': 0.29745275627119816, 'Total loss': 0.29745275627119816}
2023-01-05 01:30:46,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:46,700 INFO:     Epoch: 27
2023-01-05 01:30:48,961 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39848669270674386, 'Total loss': 0.39848669270674386} | train loss {'Reaction outcome loss': 0.29873415050299273, 'Total loss': 0.29873415050299273}
2023-01-05 01:30:48,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:48,962 INFO:     Epoch: 28
2023-01-05 01:30:51,229 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3902232984701792, 'Total loss': 0.3902232984701792} | train loss {'Reaction outcome loss': 0.28509681034779205, 'Total loss': 0.28509681034779205}
2023-01-05 01:30:51,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:51,229 INFO:     Epoch: 29
2023-01-05 01:30:53,458 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4095241079727809, 'Total loss': 0.4095241079727809} | train loss {'Reaction outcome loss': 0.2784640904409689, 'Total loss': 0.2784640904409689}
2023-01-05 01:30:53,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:53,458 INFO:     Epoch: 30
2023-01-05 01:30:55,732 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4067606538534164, 'Total loss': 0.4067606538534164} | train loss {'Reaction outcome loss': 0.2754709762761511, 'Total loss': 0.2754709762761511}
2023-01-05 01:30:55,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:55,732 INFO:     Epoch: 31
2023-01-05 01:30:58,019 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3865603099266688, 'Total loss': 0.3865603099266688} | train loss {'Reaction outcome loss': 0.2685340575825767, 'Total loss': 0.2685340575825767}
2023-01-05 01:30:58,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:30:58,019 INFO:     Epoch: 32
2023-01-05 01:31:00,265 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42099573612213137, 'Total loss': 0.42099573612213137} | train loss {'Reaction outcome loss': 0.26598582105488394, 'Total loss': 0.26598582105488394}
2023-01-05 01:31:00,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:00,265 INFO:     Epoch: 33
2023-01-05 01:31:02,381 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3923842598994573, 'Total loss': 0.3923842598994573} | train loss {'Reaction outcome loss': 0.2702718541571074, 'Total loss': 0.2702718541571074}
2023-01-05 01:31:02,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:02,382 INFO:     Epoch: 34
2023-01-05 01:31:04,594 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40268741771578787, 'Total loss': 0.40268741771578787} | train loss {'Reaction outcome loss': 0.26075534049448545, 'Total loss': 0.26075534049448545}
2023-01-05 01:31:04,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:04,596 INFO:     Epoch: 35
2023-01-05 01:31:06,779 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39702104901274043, 'Total loss': 0.39702104901274043} | train loss {'Reaction outcome loss': 0.2618216005511636, 'Total loss': 0.2618216005511636}
2023-01-05 01:31:06,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:06,779 INFO:     Epoch: 36
2023-01-05 01:31:09,018 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4111009329557419, 'Total loss': 0.4111009329557419} | train loss {'Reaction outcome loss': 0.2529124348370385, 'Total loss': 0.2529124348370385}
2023-01-05 01:31:09,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:09,018 INFO:     Epoch: 37
2023-01-05 01:31:11,230 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4005250374476115, 'Total loss': 0.4005250374476115} | train loss {'Reaction outcome loss': 0.2531009406295092, 'Total loss': 0.2531009406295092}
2023-01-05 01:31:11,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:11,231 INFO:     Epoch: 38
2023-01-05 01:31:13,490 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4097797632217407, 'Total loss': 0.4097797632217407} | train loss {'Reaction outcome loss': 0.2525572915294923, 'Total loss': 0.2525572915294923}
2023-01-05 01:31:13,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:13,491 INFO:     Epoch: 39
2023-01-05 01:31:15,666 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3887616244455179, 'Total loss': 0.3887616244455179} | train loss {'Reaction outcome loss': 0.24942265345674494, 'Total loss': 0.24942265345674494}
2023-01-05 01:31:15,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:15,666 INFO:     Epoch: 40
2023-01-05 01:31:17,909 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4285577446222305, 'Total loss': 0.4285577446222305} | train loss {'Reaction outcome loss': 0.2452477703725732, 'Total loss': 0.2452477703725732}
2023-01-05 01:31:17,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:17,909 INFO:     Epoch: 41
2023-01-05 01:31:20,083 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3929099979499976, 'Total loss': 0.3929099979499976} | train loss {'Reaction outcome loss': 0.2440865001657242, 'Total loss': 0.2440865001657242}
2023-01-05 01:31:20,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:20,084 INFO:     Epoch: 42
2023-01-05 01:31:22,273 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44065236250559486, 'Total loss': 0.44065236250559486} | train loss {'Reaction outcome loss': 0.23514004617754836, 'Total loss': 0.23514004617754836}
2023-01-05 01:31:22,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:22,273 INFO:     Epoch: 43
2023-01-05 01:31:24,491 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39811763167381287, 'Total loss': 0.39811763167381287} | train loss {'Reaction outcome loss': 0.2369001238866063, 'Total loss': 0.2369001238866063}
2023-01-05 01:31:24,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:24,492 INFO:     Epoch: 44
2023-01-05 01:31:26,731 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4122466156880061, 'Total loss': 0.4122466156880061} | train loss {'Reaction outcome loss': 0.22965379124281649, 'Total loss': 0.22965379124281649}
2023-01-05 01:31:26,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:26,731 INFO:     Epoch: 45
2023-01-05 01:31:28,939 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4360357314348221, 'Total loss': 0.4360357314348221} | train loss {'Reaction outcome loss': 0.2326680144102758, 'Total loss': 0.2326680144102758}
2023-01-05 01:31:28,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:28,939 INFO:     Epoch: 46
2023-01-05 01:31:31,211 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42796725034713745, 'Total loss': 0.42796725034713745} | train loss {'Reaction outcome loss': 0.2325458383757918, 'Total loss': 0.2325458383757918}
2023-01-05 01:31:31,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:31,212 INFO:     Epoch: 47
2023-01-05 01:31:33,482 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44424692591031395, 'Total loss': 0.44424692591031395} | train loss {'Reaction outcome loss': 0.23035146424924766, 'Total loss': 0.23035146424924766}
2023-01-05 01:31:33,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:33,483 INFO:     Epoch: 48
2023-01-05 01:31:35,743 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4096953632930915, 'Total loss': 0.4096953632930915} | train loss {'Reaction outcome loss': 0.2294278643971336, 'Total loss': 0.2294278643971336}
2023-01-05 01:31:35,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:35,744 INFO:     Epoch: 49
2023-01-05 01:31:37,991 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3828376094500224, 'Total loss': 0.3828376094500224} | train loss {'Reaction outcome loss': 0.22449027197570473, 'Total loss': 0.22449027197570473}
2023-01-05 01:31:37,991 INFO:     Found new best model at epoch 49
2023-01-05 01:31:37,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:37,993 INFO:     Epoch: 50
2023-01-05 01:31:40,257 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40313827494780224, 'Total loss': 0.40313827494780224} | train loss {'Reaction outcome loss': 0.23174400474079818, 'Total loss': 0.23174400474079818}
2023-01-05 01:31:40,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:40,257 INFO:     Epoch: 51
2023-01-05 01:31:42,504 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38296564916769665, 'Total loss': 0.38296564916769665} | train loss {'Reaction outcome loss': 0.22136982762410884, 'Total loss': 0.22136982762410884}
2023-01-05 01:31:42,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:42,506 INFO:     Epoch: 52
2023-01-05 01:31:44,772 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44103130102157595, 'Total loss': 0.44103130102157595} | train loss {'Reaction outcome loss': 0.2190326955422516, 'Total loss': 0.2190326955422516}
2023-01-05 01:31:44,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:44,772 INFO:     Epoch: 53
2023-01-05 01:31:47,038 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40296148558457695, 'Total loss': 0.40296148558457695} | train loss {'Reaction outcome loss': 0.2180829630485172, 'Total loss': 0.2180829630485172}
2023-01-05 01:31:47,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:47,038 INFO:     Epoch: 54
2023-01-05 01:31:49,240 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45417586863040926, 'Total loss': 0.45417586863040926} | train loss {'Reaction outcome loss': 0.2122215147778068, 'Total loss': 0.2122215147778068}
2023-01-05 01:31:49,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:49,241 INFO:     Epoch: 55
2023-01-05 01:31:51,404 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4044982800881068, 'Total loss': 0.4044982800881068} | train loss {'Reaction outcome loss': 0.21199506128302176, 'Total loss': 0.21199506128302176}
2023-01-05 01:31:51,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:51,404 INFO:     Epoch: 56
2023-01-05 01:31:53,226 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39300960724552475, 'Total loss': 0.39300960724552475} | train loss {'Reaction outcome loss': 0.21456316523793814, 'Total loss': 0.21456316523793814}
2023-01-05 01:31:53,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:53,226 INFO:     Epoch: 57
2023-01-05 01:31:55,066 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41315062989791235, 'Total loss': 0.41315062989791235} | train loss {'Reaction outcome loss': 0.21047779662784297, 'Total loss': 0.21047779662784297}
2023-01-05 01:31:55,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:55,066 INFO:     Epoch: 58
2023-01-05 01:31:57,245 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4095347667733828, 'Total loss': 0.4095347667733828} | train loss {'Reaction outcome loss': 0.20556567630357703, 'Total loss': 0.20556567630357703}
2023-01-05 01:31:57,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:57,246 INFO:     Epoch: 59
2023-01-05 01:31:59,502 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41889002695679667, 'Total loss': 0.41889002695679667} | train loss {'Reaction outcome loss': 0.20554512510125936, 'Total loss': 0.20554512510125936}
2023-01-05 01:31:59,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:31:59,502 INFO:     Epoch: 60
2023-01-05 01:32:01,668 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.418959583590428, 'Total loss': 0.418959583590428} | train loss {'Reaction outcome loss': 0.20441174986099478, 'Total loss': 0.20441174986099478}
2023-01-05 01:32:01,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:01,669 INFO:     Epoch: 61
2023-01-05 01:32:03,823 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41491072028875353, 'Total loss': 0.41491072028875353} | train loss {'Reaction outcome loss': 0.2010163594177752, 'Total loss': 0.2010163594177752}
2023-01-05 01:32:03,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:03,823 INFO:     Epoch: 62
2023-01-05 01:32:06,089 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42737470269203187, 'Total loss': 0.42737470269203187} | train loss {'Reaction outcome loss': 0.1991801062998264, 'Total loss': 0.1991801062998264}
2023-01-05 01:32:06,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:06,089 INFO:     Epoch: 63
2023-01-05 01:32:08,329 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46151427626609803, 'Total loss': 0.46151427626609803} | train loss {'Reaction outcome loss': 0.19657732225934285, 'Total loss': 0.19657732225934285}
2023-01-05 01:32:08,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:08,329 INFO:     Epoch: 64
2023-01-05 01:32:10,563 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4463612268368403, 'Total loss': 0.4463612268368403} | train loss {'Reaction outcome loss': 0.1996826952242333, 'Total loss': 0.1996826952242333}
2023-01-05 01:32:10,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:10,563 INFO:     Epoch: 65
2023-01-05 01:32:12,821 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4366666592657566, 'Total loss': 0.4366666592657566} | train loss {'Reaction outcome loss': 0.20941386602656997, 'Total loss': 0.20941386602656997}
2023-01-05 01:32:12,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:12,822 INFO:     Epoch: 66
2023-01-05 01:32:15,070 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4304204354683558, 'Total loss': 0.4304204354683558} | train loss {'Reaction outcome loss': 0.20493131811119805, 'Total loss': 0.20493131811119805}
2023-01-05 01:32:15,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:15,070 INFO:     Epoch: 67
2023-01-05 01:32:17,337 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43944262762864433, 'Total loss': 0.43944262762864433} | train loss {'Reaction outcome loss': 0.19473098820726856, 'Total loss': 0.19473098820726856}
2023-01-05 01:32:17,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:17,337 INFO:     Epoch: 68
2023-01-05 01:32:19,570 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4387619152665138, 'Total loss': 0.4387619152665138} | train loss {'Reaction outcome loss': 0.19442959801307408, 'Total loss': 0.19442959801307408}
2023-01-05 01:32:19,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:19,571 INFO:     Epoch: 69
2023-01-05 01:32:21,740 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4511771284043789, 'Total loss': 0.4511771284043789} | train loss {'Reaction outcome loss': 0.18908920489427503, 'Total loss': 0.18908920489427503}
2023-01-05 01:32:21,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:21,740 INFO:     Epoch: 70
2023-01-05 01:32:23,968 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.405484605828921, 'Total loss': 0.405484605828921} | train loss {'Reaction outcome loss': 0.1992300163654864, 'Total loss': 0.1992300163654864}
2023-01-05 01:32:23,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:23,969 INFO:     Epoch: 71
2023-01-05 01:32:26,210 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41156075497468314, 'Total loss': 0.41156075497468314} | train loss {'Reaction outcome loss': 0.19404965462667134, 'Total loss': 0.19404965462667134}
2023-01-05 01:32:26,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:26,210 INFO:     Epoch: 72
2023-01-05 01:32:28,458 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4003180831670761, 'Total loss': 0.4003180831670761} | train loss {'Reaction outcome loss': 0.18869806007838316, 'Total loss': 0.18869806007838316}
2023-01-05 01:32:28,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:28,458 INFO:     Epoch: 73
2023-01-05 01:32:30,669 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42523386975129446, 'Total loss': 0.42523386975129446} | train loss {'Reaction outcome loss': 0.18894505529138056, 'Total loss': 0.18894505529138056}
2023-01-05 01:32:30,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:30,669 INFO:     Epoch: 74
2023-01-05 01:32:32,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4403680096069972, 'Total loss': 0.4403680096069972} | train loss {'Reaction outcome loss': 0.18401279912644025, 'Total loss': 0.18401279912644025}
2023-01-05 01:32:32,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:32,847 INFO:     Epoch: 75
2023-01-05 01:32:35,059 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45179786359270413, 'Total loss': 0.45179786359270413} | train loss {'Reaction outcome loss': 0.1865765214212276, 'Total loss': 0.1865765214212276}
2023-01-05 01:32:35,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:35,060 INFO:     Epoch: 76
2023-01-05 01:32:37,261 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4488360048582157, 'Total loss': 0.4488360048582157} | train loss {'Reaction outcome loss': 0.184688479433754, 'Total loss': 0.184688479433754}
2023-01-05 01:32:37,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:37,261 INFO:     Epoch: 77
2023-01-05 01:32:39,504 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4558165818452835, 'Total loss': 0.4558165818452835} | train loss {'Reaction outcome loss': 0.18515822447438224, 'Total loss': 0.18515822447438224}
2023-01-05 01:32:39,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:39,505 INFO:     Epoch: 78
2023-01-05 01:32:41,663 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42898827195167544, 'Total loss': 0.42898827195167544} | train loss {'Reaction outcome loss': 0.1854930449989152, 'Total loss': 0.1854930449989152}
2023-01-05 01:32:41,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:41,663 INFO:     Epoch: 79
2023-01-05 01:32:43,900 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4316097557544708, 'Total loss': 0.4316097557544708} | train loss {'Reaction outcome loss': 0.2093674787531094, 'Total loss': 0.2093674787531094}
2023-01-05 01:32:43,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:43,901 INFO:     Epoch: 80
2023-01-05 01:32:46,138 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5048136691252391, 'Total loss': 0.5048136691252391} | train loss {'Reaction outcome loss': 0.1953217079727978, 'Total loss': 0.1953217079727978}
2023-01-05 01:32:46,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:46,138 INFO:     Epoch: 81
2023-01-05 01:32:48,380 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45642218689123787, 'Total loss': 0.45642218689123787} | train loss {'Reaction outcome loss': 0.32697861840732506, 'Total loss': 0.32697861840732506}
2023-01-05 01:32:48,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:48,380 INFO:     Epoch: 82
2023-01-05 01:32:50,625 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42898475925127666, 'Total loss': 0.42898475925127666} | train loss {'Reaction outcome loss': 0.21578874252378044, 'Total loss': 0.21578874252378044}
2023-01-05 01:32:50,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:50,626 INFO:     Epoch: 83
2023-01-05 01:32:52,840 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43621786236763, 'Total loss': 0.43621786236763} | train loss {'Reaction outcome loss': 0.19460405231844904, 'Total loss': 0.19460405231844904}
2023-01-05 01:32:52,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:52,840 INFO:     Epoch: 84
2023-01-05 01:32:55,086 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38576760490735373, 'Total loss': 0.38576760490735373} | train loss {'Reaction outcome loss': 0.21216191230274306, 'Total loss': 0.21216191230274306}
2023-01-05 01:32:55,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:55,086 INFO:     Epoch: 85
2023-01-05 01:32:57,353 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4306404709815979, 'Total loss': 0.4306404709815979} | train loss {'Reaction outcome loss': 0.21759897737554612, 'Total loss': 0.21759897737554612}
2023-01-05 01:32:57,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:57,353 INFO:     Epoch: 86
2023-01-05 01:32:59,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4272256225347519, 'Total loss': 0.4272256225347519} | train loss {'Reaction outcome loss': 0.18553170226210647, 'Total loss': 0.18553170226210647}
2023-01-05 01:32:59,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:32:59,634 INFO:     Epoch: 87
2023-01-05 01:33:01,894 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41874464402596157, 'Total loss': 0.41874464402596157} | train loss {'Reaction outcome loss': 0.20349149022629295, 'Total loss': 0.20349149022629295}
2023-01-05 01:33:01,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:01,895 INFO:     Epoch: 88
2023-01-05 01:33:04,163 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41103255450725557, 'Total loss': 0.41103255450725557} | train loss {'Reaction outcome loss': 0.18006471480139952, 'Total loss': 0.18006471480139952}
2023-01-05 01:33:04,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:04,164 INFO:     Epoch: 89
2023-01-05 01:33:06,421 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44147392014662423, 'Total loss': 0.44147392014662423} | train loss {'Reaction outcome loss': 0.17731270447647135, 'Total loss': 0.17731270447647135}
2023-01-05 01:33:06,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:06,421 INFO:     Epoch: 90
2023-01-05 01:33:08,669 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4324537048737208, 'Total loss': 0.4324537048737208} | train loss {'Reaction outcome loss': 0.1749711243998678, 'Total loss': 0.1749711243998678}
2023-01-05 01:33:08,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:08,669 INFO:     Epoch: 91
2023-01-05 01:33:10,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4441618631283442, 'Total loss': 0.4441618631283442} | train loss {'Reaction outcome loss': 0.17118537206028966, 'Total loss': 0.17118537206028966}
2023-01-05 01:33:10,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:10,929 INFO:     Epoch: 92
2023-01-05 01:33:13,182 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43545264899730685, 'Total loss': 0.43545264899730685} | train loss {'Reaction outcome loss': 0.17449679721207562, 'Total loss': 0.17449679721207562}
2023-01-05 01:33:13,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:13,184 INFO:     Epoch: 93
2023-01-05 01:33:15,451 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4246488360067209, 'Total loss': 0.4246488360067209} | train loss {'Reaction outcome loss': 0.18068911748992253, 'Total loss': 0.18068911748992253}
2023-01-05 01:33:15,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:15,451 INFO:     Epoch: 94
2023-01-05 01:33:17,694 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41629140358418226, 'Total loss': 0.41629140358418226} | train loss {'Reaction outcome loss': 0.1705721819088322, 'Total loss': 0.1705721819088322}
2023-01-05 01:33:17,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:17,694 INFO:     Epoch: 95
2023-01-05 01:33:19,936 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4312295059363047, 'Total loss': 0.4312295059363047} | train loss {'Reaction outcome loss': 0.1678086569974793, 'Total loss': 0.1678086569974793}
2023-01-05 01:33:19,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:19,937 INFO:     Epoch: 96
2023-01-05 01:33:22,187 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41125468413035077, 'Total loss': 0.41125468413035077} | train loss {'Reaction outcome loss': 0.17519012340847478, 'Total loss': 0.17519012340847478}
2023-01-05 01:33:22,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:22,187 INFO:     Epoch: 97
2023-01-05 01:33:24,405 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41144322156906127, 'Total loss': 0.41144322156906127} | train loss {'Reaction outcome loss': 0.1792390784139043, 'Total loss': 0.1792390784139043}
2023-01-05 01:33:24,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:24,405 INFO:     Epoch: 98
2023-01-05 01:33:26,663 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4418480505545934, 'Total loss': 0.4418480505545934} | train loss {'Reaction outcome loss': 0.17288346254523881, 'Total loss': 0.17288346254523881}
2023-01-05 01:33:26,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:26,663 INFO:     Epoch: 99
2023-01-05 01:33:28,891 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47151177326838173, 'Total loss': 0.47151177326838173} | train loss {'Reaction outcome loss': 0.1680744688909845, 'Total loss': 0.1680744688909845}
2023-01-05 01:33:28,892 INFO:     Best model found after epoch 50 of 100.
2023-01-05 01:33:28,892 INFO:   Done with stage: TRAINING
2023-01-05 01:33:28,892 INFO:   Starting stage: EVALUATION
2023-01-05 01:33:29,027 INFO:   Done with stage: EVALUATION
2023-01-05 01:33:29,027 INFO:   Leaving out SEQ value Fold_1
2023-01-05 01:33:29,040 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 01:33:29,040 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:33:29,684 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:33:29,684 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:33:29,753 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:33:29,754 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:33:29,754 INFO:     No hyperparam tuning for this model
2023-01-05 01:33:29,754 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:33:29,754 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:33:29,754 INFO:     None feature selector for col prot
2023-01-05 01:33:29,755 INFO:     None feature selector for col prot
2023-01-05 01:33:29,755 INFO:     None feature selector for col prot
2023-01-05 01:33:29,755 INFO:     None feature selector for col chem
2023-01-05 01:33:29,755 INFO:     None feature selector for col chem
2023-01-05 01:33:29,755 INFO:     None feature selector for col chem
2023-01-05 01:33:29,755 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:33:29,755 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:33:29,757 INFO:     Number of params in model 72931
2023-01-05 01:33:29,760 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:33:29,760 INFO:   Starting stage: TRAINING
2023-01-05 01:33:29,820 INFO:     Val loss before train {'Reaction outcome loss': 1.0128151416778564, 'Total loss': 1.0128151416778564}
2023-01-05 01:33:29,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:29,820 INFO:     Epoch: 0
2023-01-05 01:33:32,082 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.773438827196757, 'Total loss': 0.773438827196757} | train loss {'Reaction outcome loss': 0.9251003283737362, 'Total loss': 0.9251003283737362}
2023-01-05 01:33:32,083 INFO:     Found new best model at epoch 0
2023-01-05 01:33:32,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:32,085 INFO:     Epoch: 1
2023-01-05 01:33:34,349 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5547260542710623, 'Total loss': 0.5547260542710623} | train loss {'Reaction outcome loss': 0.6156536477307478, 'Total loss': 0.6156536477307478}
2023-01-05 01:33:34,349 INFO:     Found new best model at epoch 1
2023-01-05 01:33:34,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:34,351 INFO:     Epoch: 2
2023-01-05 01:33:36,567 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5196486473083496, 'Total loss': 0.5196486473083496} | train loss {'Reaction outcome loss': 0.5321106567870879, 'Total loss': 0.5321106567870879}
2023-01-05 01:33:36,567 INFO:     Found new best model at epoch 2
2023-01-05 01:33:36,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:36,569 INFO:     Epoch: 3
2023-01-05 01:33:38,791 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4866004208723704, 'Total loss': 0.4866004208723704} | train loss {'Reaction outcome loss': 0.49071159229640837, 'Total loss': 0.49071159229640837}
2023-01-05 01:33:38,791 INFO:     Found new best model at epoch 3
2023-01-05 01:33:38,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:38,792 INFO:     Epoch: 4
2023-01-05 01:33:41,049 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47530936598777773, 'Total loss': 0.47530936598777773} | train loss {'Reaction outcome loss': 0.45286691023300035, 'Total loss': 0.45286691023300035}
2023-01-05 01:33:41,049 INFO:     Found new best model at epoch 4
2023-01-05 01:33:41,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:41,050 INFO:     Epoch: 5
2023-01-05 01:33:43,297 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4821587800979614, 'Total loss': 0.4821587800979614} | train loss {'Reaction outcome loss': 0.43128286399271176, 'Total loss': 0.43128286399271176}
2023-01-05 01:33:43,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:43,297 INFO:     Epoch: 6
2023-01-05 01:33:45,548 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46927684744199116, 'Total loss': 0.46927684744199116} | train loss {'Reaction outcome loss': 0.41657796382914175, 'Total loss': 0.41657796382914175}
2023-01-05 01:33:45,548 INFO:     Found new best model at epoch 6
2023-01-05 01:33:45,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:45,549 INFO:     Epoch: 7
2023-01-05 01:33:47,790 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4616428395112356, 'Total loss': 0.4616428395112356} | train loss {'Reaction outcome loss': 0.4054633962881306, 'Total loss': 0.4054633962881306}
2023-01-05 01:33:47,790 INFO:     Found new best model at epoch 7
2023-01-05 01:33:47,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:47,791 INFO:     Epoch: 8
2023-01-05 01:33:50,014 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4547038167715073, 'Total loss': 0.4547038167715073} | train loss {'Reaction outcome loss': 0.39509077176816115, 'Total loss': 0.39509077176816115}
2023-01-05 01:33:50,015 INFO:     Found new best model at epoch 8
2023-01-05 01:33:50,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:50,017 INFO:     Epoch: 9
2023-01-05 01:33:52,272 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46144859194755555, 'Total loss': 0.46144859194755555} | train loss {'Reaction outcome loss': 0.3758329110543881, 'Total loss': 0.3758329110543881}
2023-01-05 01:33:52,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:52,272 INFO:     Epoch: 10
2023-01-05 01:33:54,514 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44183024565378826, 'Total loss': 0.44183024565378826} | train loss {'Reaction outcome loss': 0.3684085286234393, 'Total loss': 0.3684085286234393}
2023-01-05 01:33:54,514 INFO:     Found new best model at epoch 10
2023-01-05 01:33:54,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:54,516 INFO:     Epoch: 11
2023-01-05 01:33:56,750 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43677759965260826, 'Total loss': 0.43677759965260826} | train loss {'Reaction outcome loss': 0.3580986046573093, 'Total loss': 0.3580986046573093}
2023-01-05 01:33:56,751 INFO:     Found new best model at epoch 11
2023-01-05 01:33:56,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:56,752 INFO:     Epoch: 12
2023-01-05 01:33:58,987 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4304995596408844, 'Total loss': 0.4304995596408844} | train loss {'Reaction outcome loss': 0.36302268267541693, 'Total loss': 0.36302268267541693}
2023-01-05 01:33:58,987 INFO:     Found new best model at epoch 12
2023-01-05 01:33:58,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:33:58,989 INFO:     Epoch: 13
2023-01-05 01:34:01,250 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45207199851671853, 'Total loss': 0.45207199851671853} | train loss {'Reaction outcome loss': 0.34882727357140486, 'Total loss': 0.34882727357140486}
2023-01-05 01:34:01,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:01,250 INFO:     Epoch: 14
2023-01-05 01:34:03,522 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4512486279010773, 'Total loss': 0.4512486279010773} | train loss {'Reaction outcome loss': 0.3456925906618868, 'Total loss': 0.3456925906618868}
2023-01-05 01:34:03,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:03,522 INFO:     Epoch: 15
2023-01-05 01:34:05,767 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4452701032161713, 'Total loss': 0.4452701032161713} | train loss {'Reaction outcome loss': 0.3367347698928653, 'Total loss': 0.3367347698928653}
2023-01-05 01:34:05,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:05,768 INFO:     Epoch: 16
2023-01-05 01:34:08,034 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4410727093617121, 'Total loss': 0.4410727093617121} | train loss {'Reaction outcome loss': 0.3228049050901419, 'Total loss': 0.3228049050901419}
2023-01-05 01:34:08,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:08,034 INFO:     Epoch: 17
2023-01-05 01:34:10,281 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42744131088256837, 'Total loss': 0.42744131088256837} | train loss {'Reaction outcome loss': 0.3159176111415339, 'Total loss': 0.3159176111415339}
2023-01-05 01:34:10,282 INFO:     Found new best model at epoch 17
2023-01-05 01:34:10,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:10,283 INFO:     Epoch: 18
2023-01-05 01:34:12,527 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4373254636923472, 'Total loss': 0.4373254636923472} | train loss {'Reaction outcome loss': 0.3134669396331183, 'Total loss': 0.3134669396331183}
2023-01-05 01:34:12,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:12,528 INFO:     Epoch: 19
2023-01-05 01:34:14,788 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4122390439112981, 'Total loss': 0.4122390439112981} | train loss {'Reaction outcome loss': 0.3054248458483135, 'Total loss': 0.3054248458483135}
2023-01-05 01:34:14,788 INFO:     Found new best model at epoch 19
2023-01-05 01:34:14,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:14,789 INFO:     Epoch: 20
2023-01-05 01:34:17,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44029293457667035, 'Total loss': 0.44029293457667035} | train loss {'Reaction outcome loss': 0.3022781101779243, 'Total loss': 0.3022781101779243}
2023-01-05 01:34:17,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:17,019 INFO:     Epoch: 21
2023-01-05 01:34:19,255 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4124019265174866, 'Total loss': 0.4124019265174866} | train loss {'Reaction outcome loss': 0.2957587100133516, 'Total loss': 0.2957587100133516}
2023-01-05 01:34:19,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:19,256 INFO:     Epoch: 22
2023-01-05 01:34:21,486 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42273907711108527, 'Total loss': 0.42273907711108527} | train loss {'Reaction outcome loss': 0.29045498309036094, 'Total loss': 0.29045498309036094}
2023-01-05 01:34:21,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:21,487 INFO:     Epoch: 23
2023-01-05 01:34:23,711 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41507556239763893, 'Total loss': 0.41507556239763893} | train loss {'Reaction outcome loss': 0.29144766229623253, 'Total loss': 0.29144766229623253}
2023-01-05 01:34:23,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:23,712 INFO:     Epoch: 24
2023-01-05 01:34:25,966 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40719298322995506, 'Total loss': 0.40719298322995506} | train loss {'Reaction outcome loss': 0.2831403115533117, 'Total loss': 0.2831403115533117}
2023-01-05 01:34:25,967 INFO:     Found new best model at epoch 24
2023-01-05 01:34:25,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:25,969 INFO:     Epoch: 25
2023-01-05 01:34:28,235 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4314728915691376, 'Total loss': 0.4314728915691376} | train loss {'Reaction outcome loss': 0.27854899909310177, 'Total loss': 0.27854899909310177}
2023-01-05 01:34:28,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:28,235 INFO:     Epoch: 26
2023-01-05 01:34:30,468 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4371831715106964, 'Total loss': 0.4371831715106964} | train loss {'Reaction outcome loss': 0.2777653330628274, 'Total loss': 0.2777653330628274}
2023-01-05 01:34:30,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:30,468 INFO:     Epoch: 27
2023-01-05 01:34:32,723 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4308990716934204, 'Total loss': 0.4308990716934204} | train loss {'Reaction outcome loss': 0.27760319228611374, 'Total loss': 0.27760319228611374}
2023-01-05 01:34:32,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:32,723 INFO:     Epoch: 28
2023-01-05 01:34:34,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4268269086877505, 'Total loss': 0.4268269086877505} | train loss {'Reaction outcome loss': 0.27070697754675493, 'Total loss': 0.27070697754675493}
2023-01-05 01:34:34,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:34,958 INFO:     Epoch: 29
2023-01-05 01:34:37,199 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4316056380669276, 'Total loss': 0.4316056380669276} | train loss {'Reaction outcome loss': 0.2640553118688041, 'Total loss': 0.2640553118688041}
2023-01-05 01:34:37,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:37,199 INFO:     Epoch: 30
2023-01-05 01:34:39,464 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46412912209828694, 'Total loss': 0.46412912209828694} | train loss {'Reaction outcome loss': 0.2596906251130639, 'Total loss': 0.2596906251130639}
2023-01-05 01:34:39,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:39,465 INFO:     Epoch: 31
2023-01-05 01:34:41,704 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42383191287517546, 'Total loss': 0.42383191287517546} | train loss {'Reaction outcome loss': 0.26303767233047687, 'Total loss': 0.26303767233047687}
2023-01-05 01:34:41,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:41,704 INFO:     Epoch: 32
2023-01-05 01:34:43,926 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43277241190274557, 'Total loss': 0.43277241190274557} | train loss {'Reaction outcome loss': 0.2557116034160203, 'Total loss': 0.2557116034160203}
2023-01-05 01:34:43,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:43,927 INFO:     Epoch: 33
2023-01-05 01:34:46,184 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43778575758139293, 'Total loss': 0.43778575758139293} | train loss {'Reaction outcome loss': 0.25737126708786556, 'Total loss': 0.25737126708786556}
2023-01-05 01:34:46,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:46,185 INFO:     Epoch: 34
2023-01-05 01:34:48,417 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4323243449131648, 'Total loss': 0.4323243449131648} | train loss {'Reaction outcome loss': 0.2515864564633955, 'Total loss': 0.2515864564633955}
2023-01-05 01:34:48,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:48,417 INFO:     Epoch: 35
2023-01-05 01:34:50,632 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4496536135673523, 'Total loss': 0.4496536135673523} | train loss {'Reaction outcome loss': 0.25236067298733955, 'Total loss': 0.25236067298733955}
2023-01-05 01:34:50,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:50,632 INFO:     Epoch: 36
2023-01-05 01:34:52,849 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4187363018592199, 'Total loss': 0.4187363018592199} | train loss {'Reaction outcome loss': 0.24338685454584766, 'Total loss': 0.24338685454584766}
2023-01-05 01:34:52,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:52,850 INFO:     Epoch: 37
2023-01-05 01:34:55,080 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46593652764956156, 'Total loss': 0.46593652764956156} | train loss {'Reaction outcome loss': 0.2444545714441093, 'Total loss': 0.2444545714441093}
2023-01-05 01:34:55,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:55,081 INFO:     Epoch: 38
2023-01-05 01:34:57,334 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4368894095222155, 'Total loss': 0.4368894095222155} | train loss {'Reaction outcome loss': 0.24684562260396584, 'Total loss': 0.24684562260396584}
2023-01-05 01:34:57,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:57,334 INFO:     Epoch: 39
2023-01-05 01:34:59,561 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46261335015296934, 'Total loss': 0.46261335015296934} | train loss {'Reaction outcome loss': 0.24178387473701782, 'Total loss': 0.24178387473701782}
2023-01-05 01:34:59,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:34:59,561 INFO:     Epoch: 40
2023-01-05 01:35:01,848 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.444989279905955, 'Total loss': 0.444989279905955} | train loss {'Reaction outcome loss': 0.24166089457635215, 'Total loss': 0.24166089457635215}
2023-01-05 01:35:01,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:01,849 INFO:     Epoch: 41
2023-01-05 01:35:04,154 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4357266515493393, 'Total loss': 0.4357266515493393} | train loss {'Reaction outcome loss': 0.23973814271469734, 'Total loss': 0.23973814271469734}
2023-01-05 01:35:04,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:04,154 INFO:     Epoch: 42
2023-01-05 01:35:06,445 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4238832028582692, 'Total loss': 0.4238832028582692} | train loss {'Reaction outcome loss': 0.23173427744431124, 'Total loss': 0.23173427744431124}
2023-01-05 01:35:06,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:06,446 INFO:     Epoch: 43
2023-01-05 01:35:08,501 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42892830868562065, 'Total loss': 0.42892830868562065} | train loss {'Reaction outcome loss': 0.23130431361631423, 'Total loss': 0.23130431361631423}
2023-01-05 01:35:08,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:08,501 INFO:     Epoch: 44
2023-01-05 01:35:10,747 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4609161784251531, 'Total loss': 0.4609161784251531} | train loss {'Reaction outcome loss': 0.2302096049936147, 'Total loss': 0.2302096049936147}
2023-01-05 01:35:10,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:10,748 INFO:     Epoch: 45
2023-01-05 01:35:12,980 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4312746415535609, 'Total loss': 0.4312746415535609} | train loss {'Reaction outcome loss': 0.23032287103495142, 'Total loss': 0.23032287103495142}
2023-01-05 01:35:12,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:12,980 INFO:     Epoch: 46
2023-01-05 01:35:15,153 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4407319962978363, 'Total loss': 0.4407319962978363} | train loss {'Reaction outcome loss': 0.22687060098109793, 'Total loss': 0.22687060098109793}
2023-01-05 01:35:15,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:15,154 INFO:     Epoch: 47
2023-01-05 01:35:17,385 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44871867696444195, 'Total loss': 0.44871867696444195} | train loss {'Reaction outcome loss': 0.2182811104280847, 'Total loss': 0.2182811104280847}
2023-01-05 01:35:17,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:17,386 INFO:     Epoch: 48
2023-01-05 01:35:19,617 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44093603094418843, 'Total loss': 0.44093603094418843} | train loss {'Reaction outcome loss': 0.21449108567891426, 'Total loss': 0.21449108567891426}
2023-01-05 01:35:19,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:19,617 INFO:     Epoch: 49
2023-01-05 01:35:21,842 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4393746887644132, 'Total loss': 0.4393746887644132} | train loss {'Reaction outcome loss': 0.21933035032175804, 'Total loss': 0.21933035032175804}
2023-01-05 01:35:21,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:21,842 INFO:     Epoch: 50
2023-01-05 01:35:24,073 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4551417499780655, 'Total loss': 0.4551417499780655} | train loss {'Reaction outcome loss': 0.21692586258459545, 'Total loss': 0.21692586258459545}
2023-01-05 01:35:24,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:24,073 INFO:     Epoch: 51
2023-01-05 01:35:26,322 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4352902303139369, 'Total loss': 0.4352902303139369} | train loss {'Reaction outcome loss': 0.20750406113566272, 'Total loss': 0.20750406113566272}
2023-01-05 01:35:26,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:26,322 INFO:     Epoch: 52
2023-01-05 01:35:28,512 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4614611387252808, 'Total loss': 0.4614611387252808} | train loss {'Reaction outcome loss': 0.2145215662304258, 'Total loss': 0.2145215662304258}
2023-01-05 01:35:28,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:28,512 INFO:     Epoch: 53
2023-01-05 01:35:30,776 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4419349133968353, 'Total loss': 0.4419349133968353} | train loss {'Reaction outcome loss': 0.20505930357540963, 'Total loss': 0.20505930357540963}
2023-01-05 01:35:30,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:30,777 INFO:     Epoch: 54
2023-01-05 01:35:33,067 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4578804612159729, 'Total loss': 0.4578804612159729} | train loss {'Reaction outcome loss': 0.21153196475664288, 'Total loss': 0.21153196475664288}
2023-01-05 01:35:33,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:33,067 INFO:     Epoch: 55
2023-01-05 01:35:35,339 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4528131718436877, 'Total loss': 0.4528131718436877} | train loss {'Reaction outcome loss': 0.206603842786601, 'Total loss': 0.206603842786601}
2023-01-05 01:35:35,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:35,340 INFO:     Epoch: 56
2023-01-05 01:35:37,602 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4534706046183904, 'Total loss': 0.4534706046183904} | train loss {'Reaction outcome loss': 0.19988699458735937, 'Total loss': 0.19988699458735937}
2023-01-05 01:35:37,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:37,602 INFO:     Epoch: 57
2023-01-05 01:35:39,852 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44598192572593687, 'Total loss': 0.44598192572593687} | train loss {'Reaction outcome loss': 0.20078023034886058, 'Total loss': 0.20078023034886058}
2023-01-05 01:35:39,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:39,853 INFO:     Epoch: 58
2023-01-05 01:35:42,123 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5143148303031921, 'Total loss': 0.5143148303031921} | train loss {'Reaction outcome loss': 0.20191352542125338, 'Total loss': 0.20191352542125338}
2023-01-05 01:35:42,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:42,124 INFO:     Epoch: 59
2023-01-05 01:35:44,376 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4633474151293437, 'Total loss': 0.4633474151293437} | train loss {'Reaction outcome loss': 0.20147235924799833, 'Total loss': 0.20147235924799833}
2023-01-05 01:35:44,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:44,377 INFO:     Epoch: 60
2023-01-05 01:35:46,638 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42426858047644295, 'Total loss': 0.42426858047644295} | train loss {'Reaction outcome loss': 0.1989800369012854, 'Total loss': 0.1989800369012854}
2023-01-05 01:35:46,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:46,638 INFO:     Epoch: 61
2023-01-05 01:35:48,903 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4600968904793262, 'Total loss': 0.4600968904793262} | train loss {'Reaction outcome loss': 0.19737448552252213, 'Total loss': 0.19737448552252213}
2023-01-05 01:35:48,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:48,903 INFO:     Epoch: 62
2023-01-05 01:35:51,174 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.490765447417895, 'Total loss': 0.490765447417895} | train loss {'Reaction outcome loss': 0.19447768174375044, 'Total loss': 0.19447768174375044}
2023-01-05 01:35:51,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:51,174 INFO:     Epoch: 63
2023-01-05 01:35:53,406 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46845053682724636, 'Total loss': 0.46845053682724636} | train loss {'Reaction outcome loss': 0.19287209556458276, 'Total loss': 0.19287209556458276}
2023-01-05 01:35:53,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:53,406 INFO:     Epoch: 64
2023-01-05 01:35:55,605 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4638646155595779, 'Total loss': 0.4638646155595779} | train loss {'Reaction outcome loss': 0.19181227767030182, 'Total loss': 0.19181227767030182}
2023-01-05 01:35:55,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:55,606 INFO:     Epoch: 65
2023-01-05 01:35:57,862 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4636314128835996, 'Total loss': 0.4636314128835996} | train loss {'Reaction outcome loss': 0.18925136695379743, 'Total loss': 0.18925136695379743}
2023-01-05 01:35:57,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:35:57,862 INFO:     Epoch: 66
2023-01-05 01:36:00,115 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45073850949605304, 'Total loss': 0.45073850949605304} | train loss {'Reaction outcome loss': 0.19327091850910633, 'Total loss': 0.19327091850910633}
2023-01-05 01:36:00,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:00,116 INFO:     Epoch: 67
2023-01-05 01:36:02,388 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44013431668281555, 'Total loss': 0.44013431668281555} | train loss {'Reaction outcome loss': 0.19027764199684802, 'Total loss': 0.19027764199684802}
2023-01-05 01:36:02,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:02,388 INFO:     Epoch: 68
2023-01-05 01:36:04,634 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46122563580671944, 'Total loss': 0.46122563580671944} | train loss {'Reaction outcome loss': 0.18931271389727414, 'Total loss': 0.18931271389727414}
2023-01-05 01:36:04,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:04,635 INFO:     Epoch: 69
2023-01-05 01:36:06,862 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45897227923075357, 'Total loss': 0.45897227923075357} | train loss {'Reaction outcome loss': 0.18782847946103623, 'Total loss': 0.18782847946103623}
2023-01-05 01:36:06,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:06,863 INFO:     Epoch: 70
2023-01-05 01:36:09,021 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47151603500048317, 'Total loss': 0.47151603500048317} | train loss {'Reaction outcome loss': 0.18739481010804107, 'Total loss': 0.18739481010804107}
2023-01-05 01:36:09,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:09,022 INFO:     Epoch: 71
2023-01-05 01:36:11,171 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46745239549006024, 'Total loss': 0.46745239549006024} | train loss {'Reaction outcome loss': 0.18606826864297676, 'Total loss': 0.18606826864297676}
2023-01-05 01:36:11,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:11,171 INFO:     Epoch: 72
2023-01-05 01:36:13,428 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46244285106658933, 'Total loss': 0.46244285106658933} | train loss {'Reaction outcome loss': 0.18643853103434516, 'Total loss': 0.18643853103434516}
2023-01-05 01:36:13,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:13,429 INFO:     Epoch: 73
2023-01-05 01:36:15,641 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46669612725575765, 'Total loss': 0.46669612725575765} | train loss {'Reaction outcome loss': 0.18399820095214967, 'Total loss': 0.18399820095214967}
2023-01-05 01:36:15,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:15,641 INFO:     Epoch: 74
2023-01-05 01:36:17,878 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.423471866051356, 'Total loss': 0.423471866051356} | train loss {'Reaction outcome loss': 0.18637499190831938, 'Total loss': 0.18637499190831938}
2023-01-05 01:36:17,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:17,878 INFO:     Epoch: 75
2023-01-05 01:36:20,126 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47244980136553444, 'Total loss': 0.47244980136553444} | train loss {'Reaction outcome loss': 0.18838938701715643, 'Total loss': 0.18838938701715643}
2023-01-05 01:36:20,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:20,126 INFO:     Epoch: 76
2023-01-05 01:36:22,316 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43902192016442615, 'Total loss': 0.43902192016442615} | train loss {'Reaction outcome loss': 0.18308582524810924, 'Total loss': 0.18308582524810924}
2023-01-05 01:36:22,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:22,317 INFO:     Epoch: 77
2023-01-05 01:36:24,494 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47847392161687213, 'Total loss': 0.47847392161687213} | train loss {'Reaction outcome loss': 0.18832542973003633, 'Total loss': 0.18832542973003633}
2023-01-05 01:36:24,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:24,494 INFO:     Epoch: 78
2023-01-05 01:36:26,663 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45016171733538307, 'Total loss': 0.45016171733538307} | train loss {'Reaction outcome loss': 0.1868100591216163, 'Total loss': 0.1868100591216163}
2023-01-05 01:36:26,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:26,664 INFO:     Epoch: 79
2023-01-05 01:36:28,925 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43675550520420076, 'Total loss': 0.43675550520420076} | train loss {'Reaction outcome loss': 0.18011266617205643, 'Total loss': 0.18011266617205643}
2023-01-05 01:36:28,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:28,926 INFO:     Epoch: 80
2023-01-05 01:36:31,170 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44574210047721863, 'Total loss': 0.44574210047721863} | train loss {'Reaction outcome loss': 0.17501634716872883, 'Total loss': 0.17501634716872883}
2023-01-05 01:36:31,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:31,170 INFO:     Epoch: 81
2023-01-05 01:36:33,444 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4753847708304723, 'Total loss': 0.4753847708304723} | train loss {'Reaction outcome loss': 0.1807613675178879, 'Total loss': 0.1807613675178879}
2023-01-05 01:36:33,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:33,444 INFO:     Epoch: 82
2023-01-05 01:36:35,707 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46611526012420657, 'Total loss': 0.46611526012420657} | train loss {'Reaction outcome loss': 0.17418396654176066, 'Total loss': 0.17418396654176066}
2023-01-05 01:36:35,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:35,707 INFO:     Epoch: 83
2023-01-05 01:36:37,922 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46007347106933594, 'Total loss': 0.46007347106933594} | train loss {'Reaction outcome loss': 0.17852378850912445, 'Total loss': 0.17852378850912445}
2023-01-05 01:36:37,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:37,922 INFO:     Epoch: 84
2023-01-05 01:36:40,161 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45255158344904584, 'Total loss': 0.45255158344904584} | train loss {'Reaction outcome loss': 0.17228719962261402, 'Total loss': 0.17228719962261402}
2023-01-05 01:36:40,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:40,161 INFO:     Epoch: 85
2023-01-05 01:36:42,370 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4844502588113149, 'Total loss': 0.4844502588113149} | train loss {'Reaction outcome loss': 0.17392586238818933, 'Total loss': 0.17392586238818933}
2023-01-05 01:36:42,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:42,370 INFO:     Epoch: 86
2023-01-05 01:36:44,577 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4699983755747477, 'Total loss': 0.4699983755747477} | train loss {'Reaction outcome loss': 0.1782788966556309, 'Total loss': 0.1782788966556309}
2023-01-05 01:36:44,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:44,578 INFO:     Epoch: 87
2023-01-05 01:36:46,843 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48006644944349924, 'Total loss': 0.48006644944349924} | train loss {'Reaction outcome loss': 0.17505845452989519, 'Total loss': 0.17505845452989519}
2023-01-05 01:36:46,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:46,843 INFO:     Epoch: 88
2023-01-05 01:36:49,106 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46658325095971426, 'Total loss': 0.46658325095971426} | train loss {'Reaction outcome loss': 0.17407861272838182, 'Total loss': 0.17407861272838182}
2023-01-05 01:36:49,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:49,106 INFO:     Epoch: 89
2023-01-05 01:36:51,279 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4371308167775472, 'Total loss': 0.4371308167775472} | train loss {'Reaction outcome loss': 0.1757457905716391, 'Total loss': 0.1757457905716391}
2023-01-05 01:36:51,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:51,280 INFO:     Epoch: 90
2023-01-05 01:36:53,524 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46098844266186156, 'Total loss': 0.46098844266186156} | train loss {'Reaction outcome loss': 0.17264971599249385, 'Total loss': 0.17264971599249385}
2023-01-05 01:36:53,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:53,525 INFO:     Epoch: 91
2023-01-05 01:36:55,798 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46823649207750956, 'Total loss': 0.46823649207750956} | train loss {'Reaction outcome loss': 0.17381232114174686, 'Total loss': 0.17381232114174686}
2023-01-05 01:36:55,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:55,798 INFO:     Epoch: 92
2023-01-05 01:36:58,074 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4372158666451772, 'Total loss': 0.4372158666451772} | train loss {'Reaction outcome loss': 0.1713500736866305, 'Total loss': 0.1713500736866305}
2023-01-05 01:36:58,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:36:58,074 INFO:     Epoch: 93
2023-01-05 01:37:00,215 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4525132397810618, 'Total loss': 0.4525132397810618} | train loss {'Reaction outcome loss': 0.16706964925788928, 'Total loss': 0.16706964925788928}
2023-01-05 01:37:00,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:00,215 INFO:     Epoch: 94
2023-01-05 01:37:02,399 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49362906416257224, 'Total loss': 0.49362906416257224} | train loss {'Reaction outcome loss': 0.17313324151547166, 'Total loss': 0.17313324151547166}
2023-01-05 01:37:02,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:02,399 INFO:     Epoch: 95
2023-01-05 01:37:04,623 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4747680902481079, 'Total loss': 0.4747680902481079} | train loss {'Reaction outcome loss': 0.16877577989024745, 'Total loss': 0.16877577989024745}
2023-01-05 01:37:04,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:04,624 INFO:     Epoch: 96
2023-01-05 01:37:06,891 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4842935919761658, 'Total loss': 0.4842935919761658} | train loss {'Reaction outcome loss': 0.17181733953580935, 'Total loss': 0.17181733953580935}
2023-01-05 01:37:06,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:06,891 INFO:     Epoch: 97
2023-01-05 01:37:09,141 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5092640141646068, 'Total loss': 0.5092640141646068} | train loss {'Reaction outcome loss': 0.16829571815332453, 'Total loss': 0.16829571815332453}
2023-01-05 01:37:09,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:09,141 INFO:     Epoch: 98
2023-01-05 01:37:11,404 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4715941071510315, 'Total loss': 0.4715941071510315} | train loss {'Reaction outcome loss': 0.17423166661048026, 'Total loss': 0.17423166661048026}
2023-01-05 01:37:11,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:11,404 INFO:     Epoch: 99
2023-01-05 01:37:13,646 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4849392334620158, 'Total loss': 0.4849392334620158} | train loss {'Reaction outcome loss': 0.17081928400127083, 'Total loss': 0.17081928400127083}
2023-01-05 01:37:13,647 INFO:     Best model found after epoch 25 of 100.
2023-01-05 01:37:13,647 INFO:   Done with stage: TRAINING
2023-01-05 01:37:13,648 INFO:   Starting stage: EVALUATION
2023-01-05 01:37:13,780 INFO:   Done with stage: EVALUATION
2023-01-05 01:37:13,780 INFO:   Leaving out SEQ value Fold_2
2023-01-05 01:37:13,793 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 01:37:13,793 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:37:14,442 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:37:14,442 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:37:14,510 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:37:14,510 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:37:14,510 INFO:     No hyperparam tuning for this model
2023-01-05 01:37:14,511 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:37:14,511 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:37:14,511 INFO:     None feature selector for col prot
2023-01-05 01:37:14,511 INFO:     None feature selector for col prot
2023-01-05 01:37:14,511 INFO:     None feature selector for col prot
2023-01-05 01:37:14,512 INFO:     None feature selector for col chem
2023-01-05 01:37:14,512 INFO:     None feature selector for col chem
2023-01-05 01:37:14,512 INFO:     None feature selector for col chem
2023-01-05 01:37:14,512 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:37:14,512 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:37:14,514 INFO:     Number of params in model 72931
2023-01-05 01:37:14,517 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:37:14,517 INFO:   Starting stage: TRAINING
2023-01-05 01:37:14,577 INFO:     Val loss before train {'Reaction outcome loss': 1.0579285780588785, 'Total loss': 1.0579285780588785}
2023-01-05 01:37:14,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:14,578 INFO:     Epoch: 0
2023-01-05 01:37:16,793 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8181209524472555, 'Total loss': 0.8181209524472555} | train loss {'Reaction outcome loss': 0.9375618601238335, 'Total loss': 0.9375618601238335}
2023-01-05 01:37:16,794 INFO:     Found new best model at epoch 0
2023-01-05 01:37:16,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:16,795 INFO:     Epoch: 1
2023-01-05 01:37:18,986 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5917351881663004, 'Total loss': 0.5917351881663004} | train loss {'Reaction outcome loss': 0.6149891429331713, 'Total loss': 0.6149891429331713}
2023-01-05 01:37:18,986 INFO:     Found new best model at epoch 1
2023-01-05 01:37:18,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:18,988 INFO:     Epoch: 2
2023-01-05 01:37:21,221 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5497782568136851, 'Total loss': 0.5497782568136851} | train loss {'Reaction outcome loss': 0.5203777449034945, 'Total loss': 0.5203777449034945}
2023-01-05 01:37:21,221 INFO:     Found new best model at epoch 2
2023-01-05 01:37:21,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:21,223 INFO:     Epoch: 3
2023-01-05 01:37:23,450 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5544335146745046, 'Total loss': 0.5544335146745046} | train loss {'Reaction outcome loss': 0.48488001364382194, 'Total loss': 0.48488001364382194}
2023-01-05 01:37:23,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:23,451 INFO:     Epoch: 4
2023-01-05 01:37:25,656 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49879129032293956, 'Total loss': 0.49879129032293956} | train loss {'Reaction outcome loss': 0.4602838370389554, 'Total loss': 0.4602838370389554}
2023-01-05 01:37:25,656 INFO:     Found new best model at epoch 4
2023-01-05 01:37:25,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:25,658 INFO:     Epoch: 5
2023-01-05 01:37:27,809 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.500080402692159, 'Total loss': 0.500080402692159} | train loss {'Reaction outcome loss': 0.43878134596587975, 'Total loss': 0.43878134596587975}
2023-01-05 01:37:27,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:27,809 INFO:     Epoch: 6
2023-01-05 01:37:30,016 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5093134820461274, 'Total loss': 0.5093134820461274} | train loss {'Reaction outcome loss': 0.4211995553621006, 'Total loss': 0.4211995553621006}
2023-01-05 01:37:30,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:30,016 INFO:     Epoch: 7
2023-01-05 01:37:32,250 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.521043653289477, 'Total loss': 0.521043653289477} | train loss {'Reaction outcome loss': 0.40812400188092346, 'Total loss': 0.40812400188092346}
2023-01-05 01:37:32,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:32,250 INFO:     Epoch: 8
2023-01-05 01:37:34,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49786033233006793, 'Total loss': 0.49786033233006793} | train loss {'Reaction outcome loss': 0.3973460232654771, 'Total loss': 0.3973460232654771}
2023-01-05 01:37:34,471 INFO:     Found new best model at epoch 8
2023-01-05 01:37:34,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:34,472 INFO:     Epoch: 9
2023-01-05 01:37:36,654 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4999484956264496, 'Total loss': 0.4999484956264496} | train loss {'Reaction outcome loss': 0.38754287932491127, 'Total loss': 0.38754287932491127}
2023-01-05 01:37:36,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:36,654 INFO:     Epoch: 10
2023-01-05 01:37:38,857 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5020456324021022, 'Total loss': 0.5020456324021022} | train loss {'Reaction outcome loss': 0.3788813934439704, 'Total loss': 0.3788813934439704}
2023-01-05 01:37:38,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:38,857 INFO:     Epoch: 11
2023-01-05 01:37:41,126 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5108484923839569, 'Total loss': 0.5108484923839569} | train loss {'Reaction outcome loss': 0.3714440228629025, 'Total loss': 0.3714440228629025}
2023-01-05 01:37:41,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:41,126 INFO:     Epoch: 12
2023-01-05 01:37:43,386 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47042825917402903, 'Total loss': 0.47042825917402903} | train loss {'Reaction outcome loss': 0.3606858932218709, 'Total loss': 0.3606858932218709}
2023-01-05 01:37:43,386 INFO:     Found new best model at epoch 12
2023-01-05 01:37:43,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:43,387 INFO:     Epoch: 13
2023-01-05 01:37:45,656 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4571732083956401, 'Total loss': 0.4571732083956401} | train loss {'Reaction outcome loss': 0.35193980073099174, 'Total loss': 0.35193980073099174}
2023-01-05 01:37:45,656 INFO:     Found new best model at epoch 13
2023-01-05 01:37:45,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:45,658 INFO:     Epoch: 14
2023-01-05 01:37:47,924 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47800152699152626, 'Total loss': 0.47800152699152626} | train loss {'Reaction outcome loss': 0.3389258653935277, 'Total loss': 0.3389258653935277}
2023-01-05 01:37:47,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:47,924 INFO:     Epoch: 15
2023-01-05 01:37:50,166 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4704199353853861, 'Total loss': 0.4704199353853861} | train loss {'Reaction outcome loss': 0.3328744509008341, 'Total loss': 0.3328744509008341}
2023-01-05 01:37:50,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:50,168 INFO:     Epoch: 16
2023-01-05 01:37:52,413 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48552169601122536, 'Total loss': 0.48552169601122536} | train loss {'Reaction outcome loss': 0.3314470972442802, 'Total loss': 0.3314470972442802}
2023-01-05 01:37:52,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:52,413 INFO:     Epoch: 17
2023-01-05 01:37:54,558 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47933136224746703, 'Total loss': 0.47933136224746703} | train loss {'Reaction outcome loss': 0.32209147065332083, 'Total loss': 0.32209147065332083}
2023-01-05 01:37:54,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:54,558 INFO:     Epoch: 18
2023-01-05 01:37:56,743 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4729857703049978, 'Total loss': 0.4729857703049978} | train loss {'Reaction outcome loss': 0.31543006094329523, 'Total loss': 0.31543006094329523}
2023-01-05 01:37:56,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:56,744 INFO:     Epoch: 19
2023-01-05 01:37:58,935 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45590430895487466, 'Total loss': 0.45590430895487466} | train loss {'Reaction outcome loss': 0.3151741384395531, 'Total loss': 0.3151741384395531}
2023-01-05 01:37:58,935 INFO:     Found new best model at epoch 19
2023-01-05 01:37:58,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:37:58,937 INFO:     Epoch: 20
2023-01-05 01:38:01,096 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4960422505935033, 'Total loss': 0.4960422505935033} | train loss {'Reaction outcome loss': 0.29961067425844434, 'Total loss': 0.29961067425844434}
2023-01-05 01:38:01,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:01,097 INFO:     Epoch: 21
2023-01-05 01:38:03,290 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5170842270056407, 'Total loss': 0.5170842270056407} | train loss {'Reaction outcome loss': 0.2996243194509775, 'Total loss': 0.2996243194509775}
2023-01-05 01:38:03,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:03,290 INFO:     Epoch: 22
2023-01-05 01:38:05,500 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4864587406317393, 'Total loss': 0.4864587406317393} | train loss {'Reaction outcome loss': 0.2895801928535704, 'Total loss': 0.2895801928535704}
2023-01-05 01:38:05,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:05,501 INFO:     Epoch: 23
2023-01-05 01:38:07,719 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.507846686244011, 'Total loss': 0.507846686244011} | train loss {'Reaction outcome loss': 0.2857137947674199, 'Total loss': 0.2857137947674199}
2023-01-05 01:38:07,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:07,719 INFO:     Epoch: 24
2023-01-05 01:38:09,967 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4933853189150492, 'Total loss': 0.4933853189150492} | train loss {'Reaction outcome loss': 0.28327565330452537, 'Total loss': 0.28327565330452537}
2023-01-05 01:38:09,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:09,968 INFO:     Epoch: 25
2023-01-05 01:38:12,210 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4939367746313413, 'Total loss': 0.4939367746313413} | train loss {'Reaction outcome loss': 0.27461342051652543, 'Total loss': 0.27461342051652543}
2023-01-05 01:38:12,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:12,211 INFO:     Epoch: 26
2023-01-05 01:38:14,442 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4986834535996119, 'Total loss': 0.4986834535996119} | train loss {'Reaction outcome loss': 0.2760308688342735, 'Total loss': 0.2760308688342735}
2023-01-05 01:38:14,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:14,442 INFO:     Epoch: 27
2023-01-05 01:38:16,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4968323270479838, 'Total loss': 0.4968323270479838} | train loss {'Reaction outcome loss': 0.27475127562089063, 'Total loss': 0.27475127562089063}
2023-01-05 01:38:16,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:16,663 INFO:     Epoch: 28
2023-01-05 01:38:18,902 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4861704756816228, 'Total loss': 0.4861704756816228} | train loss {'Reaction outcome loss': 0.262571853186403, 'Total loss': 0.262571853186403}
2023-01-05 01:38:18,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:18,902 INFO:     Epoch: 29
2023-01-05 01:38:21,104 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4997377226750056, 'Total loss': 0.4997377226750056} | train loss {'Reaction outcome loss': 0.26060092378571464, 'Total loss': 0.26060092378571464}
2023-01-05 01:38:21,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:21,104 INFO:     Epoch: 30
2023-01-05 01:38:23,267 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5327021837234497, 'Total loss': 0.5327021837234497} | train loss {'Reaction outcome loss': 0.2601600149271143, 'Total loss': 0.2601600149271143}
2023-01-05 01:38:23,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:23,268 INFO:     Epoch: 31
2023-01-05 01:38:25,459 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5223381102085114, 'Total loss': 0.5223381102085114} | train loss {'Reaction outcome loss': 0.2539554493904332, 'Total loss': 0.2539554493904332}
2023-01-05 01:38:25,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:25,460 INFO:     Epoch: 32
2023-01-05 01:38:27,583 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5091719696919124, 'Total loss': 0.5091719696919124} | train loss {'Reaction outcome loss': 0.2521341882455043, 'Total loss': 0.2521341882455043}
2023-01-05 01:38:27,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:27,583 INFO:     Epoch: 33
2023-01-05 01:38:29,834 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5218579083681106, 'Total loss': 0.5218579083681106} | train loss {'Reaction outcome loss': 0.24532873172572245, 'Total loss': 0.24532873172572245}
2023-01-05 01:38:29,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:29,834 INFO:     Epoch: 34
2023-01-05 01:38:32,075 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5320547845214605, 'Total loss': 0.5320547845214605} | train loss {'Reaction outcome loss': 0.2428318810795908, 'Total loss': 0.2428318810795908}
2023-01-05 01:38:32,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:32,076 INFO:     Epoch: 35
2023-01-05 01:38:34,336 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5339476446310679, 'Total loss': 0.5339476446310679} | train loss {'Reaction outcome loss': 0.24000347158683963, 'Total loss': 0.24000347158683963}
2023-01-05 01:38:34,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:34,336 INFO:     Epoch: 36
2023-01-05 01:38:36,565 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5134133845567703, 'Total loss': 0.5134133845567703} | train loss {'Reaction outcome loss': 0.24472189889777274, 'Total loss': 0.24472189889777274}
2023-01-05 01:38:36,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:36,566 INFO:     Epoch: 37
2023-01-05 01:38:38,459 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.507182780901591, 'Total loss': 0.507182780901591} | train loss {'Reaction outcome loss': 0.23472582207030648, 'Total loss': 0.23472582207030648}
2023-01-05 01:38:38,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:38,459 INFO:     Epoch: 38
2023-01-05 01:38:40,317 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4927785048882167, 'Total loss': 0.4927785048882167} | train loss {'Reaction outcome loss': 0.23258230590258108, 'Total loss': 0.23258230590258108}
2023-01-05 01:38:40,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:40,317 INFO:     Epoch: 39
2023-01-05 01:38:42,434 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5014369408289592, 'Total loss': 0.5014369408289592} | train loss {'Reaction outcome loss': 0.23570736879039378, 'Total loss': 0.23570736879039378}
2023-01-05 01:38:42,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:42,434 INFO:     Epoch: 40
2023-01-05 01:38:44,692 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5147712826728821, 'Total loss': 0.5147712826728821} | train loss {'Reaction outcome loss': 0.2285842867192877, 'Total loss': 0.2285842867192877}
2023-01-05 01:38:44,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:44,694 INFO:     Epoch: 41
2023-01-05 01:38:46,933 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5334372311830521, 'Total loss': 0.5334372311830521} | train loss {'Reaction outcome loss': 0.22837092356940547, 'Total loss': 0.22837092356940547}
2023-01-05 01:38:46,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:46,933 INFO:     Epoch: 42
2023-01-05 01:38:49,166 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5140002489089965, 'Total loss': 0.5140002489089965} | train loss {'Reaction outcome loss': 0.22257235546633874, 'Total loss': 0.22257235546633874}
2023-01-05 01:38:49,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:49,168 INFO:     Epoch: 43
2023-01-05 01:38:51,419 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5269971330960591, 'Total loss': 0.5269971330960591} | train loss {'Reaction outcome loss': 0.2229202852308095, 'Total loss': 0.2229202852308095}
2023-01-05 01:38:51,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:51,420 INFO:     Epoch: 44
2023-01-05 01:38:53,654 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5237399170796077, 'Total loss': 0.5237399170796077} | train loss {'Reaction outcome loss': 0.2184045353269839, 'Total loss': 0.2184045353269839}
2023-01-05 01:38:53,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:53,654 INFO:     Epoch: 45
2023-01-05 01:38:55,918 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5479293962319692, 'Total loss': 0.5479293962319692} | train loss {'Reaction outcome loss': 0.2145154632750776, 'Total loss': 0.2145154632750776}
2023-01-05 01:38:55,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:55,919 INFO:     Epoch: 46
2023-01-05 01:38:58,135 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5386927405993144, 'Total loss': 0.5386927405993144} | train loss {'Reaction outcome loss': 0.21584421080356334, 'Total loss': 0.21584421080356334}
2023-01-05 01:38:58,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:38:58,136 INFO:     Epoch: 47
2023-01-05 01:39:00,385 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5160177886486054, 'Total loss': 0.5160177886486054} | train loss {'Reaction outcome loss': 0.20928132173096958, 'Total loss': 0.20928132173096958}
2023-01-05 01:39:00,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:00,386 INFO:     Epoch: 48
2023-01-05 01:39:02,614 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5201895534992218, 'Total loss': 0.5201895534992218} | train loss {'Reaction outcome loss': 0.2131672175703468, 'Total loss': 0.2131672175703468}
2023-01-05 01:39:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:02,615 INFO:     Epoch: 49
2023-01-05 01:39:04,820 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5367765963077545, 'Total loss': 0.5367765963077545} | train loss {'Reaction outcome loss': 0.20954170683910558, 'Total loss': 0.20954170683910558}
2023-01-05 01:39:04,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:04,820 INFO:     Epoch: 50
2023-01-05 01:39:07,078 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5536983410517374, 'Total loss': 0.5536983410517374} | train loss {'Reaction outcome loss': 0.20715352644181842, 'Total loss': 0.20715352644181842}
2023-01-05 01:39:07,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:07,079 INFO:     Epoch: 51
2023-01-05 01:39:09,275 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5790335769454639, 'Total loss': 0.5790335769454639} | train loss {'Reaction outcome loss': 0.20745912470919636, 'Total loss': 0.20745912470919636}
2023-01-05 01:39:09,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:09,276 INFO:     Epoch: 52
2023-01-05 01:39:11,505 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5551806658506393, 'Total loss': 0.5551806658506393} | train loss {'Reaction outcome loss': 0.20601664495828387, 'Total loss': 0.20601664495828387}
2023-01-05 01:39:11,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:11,506 INFO:     Epoch: 53
2023-01-05 01:39:13,692 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5310916980107625, 'Total loss': 0.5310916980107625} | train loss {'Reaction outcome loss': 0.20210152707359458, 'Total loss': 0.20210152707359458}
2023-01-05 01:39:13,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:13,693 INFO:     Epoch: 54
2023-01-05 01:39:15,805 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5526828239361445, 'Total loss': 0.5526828239361445} | train loss {'Reaction outcome loss': 0.1992324677708767, 'Total loss': 0.1992324677708767}
2023-01-05 01:39:15,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:15,805 INFO:     Epoch: 55
2023-01-05 01:39:18,049 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5587455362081528, 'Total loss': 0.5587455362081528} | train loss {'Reaction outcome loss': 0.2039183487249163, 'Total loss': 0.2039183487249163}
2023-01-05 01:39:18,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:18,051 INFO:     Epoch: 56
2023-01-05 01:39:20,313 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5351833005746206, 'Total loss': 0.5351833005746206} | train loss {'Reaction outcome loss': 0.1989032943074629, 'Total loss': 0.1989032943074629}
2023-01-05 01:39:20,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:20,313 INFO:     Epoch: 57
2023-01-05 01:39:22,564 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5217630724112193, 'Total loss': 0.5217630724112193} | train loss {'Reaction outcome loss': 0.2038038130235541, 'Total loss': 0.2038038130235541}
2023-01-05 01:39:22,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:22,565 INFO:     Epoch: 58
2023-01-05 01:39:24,813 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5527640104293823, 'Total loss': 0.5527640104293823} | train loss {'Reaction outcome loss': 0.19274822166769495, 'Total loss': 0.19274822166769495}
2023-01-05 01:39:24,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:24,814 INFO:     Epoch: 59
2023-01-05 01:39:27,036 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5502016661067803, 'Total loss': 0.5502016661067803} | train loss {'Reaction outcome loss': 0.1944795617212852, 'Total loss': 0.1944795617212852}
2023-01-05 01:39:27,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:27,036 INFO:     Epoch: 60
2023-01-05 01:39:29,249 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5500938276449839, 'Total loss': 0.5500938276449839} | train loss {'Reaction outcome loss': 0.19370666236681489, 'Total loss': 0.19370666236681489}
2023-01-05 01:39:29,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:29,250 INFO:     Epoch: 61
2023-01-05 01:39:31,442 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5430402199427287, 'Total loss': 0.5430402199427287} | train loss {'Reaction outcome loss': 0.19463364129046817, 'Total loss': 0.19463364129046817}
2023-01-05 01:39:31,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:31,443 INFO:     Epoch: 62
2023-01-05 01:39:33,589 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5671771943569184, 'Total loss': 0.5671771943569184} | train loss {'Reaction outcome loss': 0.19862363515285292, 'Total loss': 0.19862363515285292}
2023-01-05 01:39:33,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:33,589 INFO:     Epoch: 63
2023-01-05 01:39:35,814 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5489964962005616, 'Total loss': 0.5489964962005616} | train loss {'Reaction outcome loss': 0.19169558010886223, 'Total loss': 0.19169558010886223}
2023-01-05 01:39:35,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:35,815 INFO:     Epoch: 64
2023-01-05 01:39:38,070 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5428327401479085, 'Total loss': 0.5428327401479085} | train loss {'Reaction outcome loss': 0.18761734551521558, 'Total loss': 0.18761734551521558}
2023-01-05 01:39:38,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:38,070 INFO:     Epoch: 65
2023-01-05 01:39:40,283 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5565814842780431, 'Total loss': 0.5565814842780431} | train loss {'Reaction outcome loss': 0.18456162401430665, 'Total loss': 0.18456162401430665}
2023-01-05 01:39:40,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:40,283 INFO:     Epoch: 66
2023-01-05 01:39:42,535 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5553548773129781, 'Total loss': 0.5553548773129781} | train loss {'Reaction outcome loss': 0.1860605530618202, 'Total loss': 0.1860605530618202}
2023-01-05 01:39:42,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:42,537 INFO:     Epoch: 67
2023-01-05 01:39:44,783 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5668198804060618, 'Total loss': 0.5668198804060618} | train loss {'Reaction outcome loss': 0.1884762952922956, 'Total loss': 0.1884762952922956}
2023-01-05 01:39:44,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:44,784 INFO:     Epoch: 68
2023-01-05 01:39:46,979 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5501810133457183, 'Total loss': 0.5501810133457183} | train loss {'Reaction outcome loss': 0.18646628389667189, 'Total loss': 0.18646628389667189}
2023-01-05 01:39:46,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:46,979 INFO:     Epoch: 69
2023-01-05 01:39:49,210 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5006883791026969, 'Total loss': 0.5006883791026969} | train loss {'Reaction outcome loss': 0.18662066323744073, 'Total loss': 0.18662066323744073}
2023-01-05 01:39:49,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:49,211 INFO:     Epoch: 70
2023-01-05 01:39:51,417 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5791653782129288, 'Total loss': 0.5791653782129288} | train loss {'Reaction outcome loss': 0.18397061916020435, 'Total loss': 0.18397061916020435}
2023-01-05 01:39:51,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:51,417 INFO:     Epoch: 71
2023-01-05 01:39:53,589 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5623120685418447, 'Total loss': 0.5623120685418447} | train loss {'Reaction outcome loss': 0.1791957895776373, 'Total loss': 0.1791957895776373}
2023-01-05 01:39:53,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:53,591 INFO:     Epoch: 72
2023-01-05 01:39:55,797 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5415637214978536, 'Total loss': 0.5415637214978536} | train loss {'Reaction outcome loss': 0.18645165749440046, 'Total loss': 0.18645165749440046}
2023-01-05 01:39:55,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:55,797 INFO:     Epoch: 73
2023-01-05 01:39:57,965 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5753462374210357, 'Total loss': 0.5753462374210357} | train loss {'Reaction outcome loss': 0.1805608461938471, 'Total loss': 0.1805608461938471}
2023-01-05 01:39:57,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:39:57,967 INFO:     Epoch: 74
2023-01-05 01:40:00,166 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5641800910234451, 'Total loss': 0.5641800910234451} | train loss {'Reaction outcome loss': 0.1840540095899363, 'Total loss': 0.1840540095899363}
2023-01-05 01:40:00,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:00,166 INFO:     Epoch: 75
2023-01-05 01:40:02,354 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5846838831901551, 'Total loss': 0.5846838831901551} | train loss {'Reaction outcome loss': 0.17997007848415184, 'Total loss': 0.17997007848415184}
2023-01-05 01:40:02,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:02,355 INFO:     Epoch: 76
2023-01-05 01:40:04,543 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5708944797515869, 'Total loss': 0.5708944797515869} | train loss {'Reaction outcome loss': 0.17894990044482217, 'Total loss': 0.17894990044482217}
2023-01-05 01:40:04,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:04,544 INFO:     Epoch: 77
2023-01-05 01:40:06,721 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6209883789221445, 'Total loss': 0.6209883789221445} | train loss {'Reaction outcome loss': 0.17696882377382053, 'Total loss': 0.17696882377382053}
2023-01-05 01:40:06,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:06,722 INFO:     Epoch: 78
2023-01-05 01:40:08,924 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5744490881760915, 'Total loss': 0.5744490881760915} | train loss {'Reaction outcome loss': 0.17466254121770625, 'Total loss': 0.17466254121770625}
2023-01-05 01:40:08,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:08,925 INFO:     Epoch: 79
2023-01-05 01:40:11,139 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5917096575101216, 'Total loss': 0.5917096575101216} | train loss {'Reaction outcome loss': 0.17595873693440914, 'Total loss': 0.17595873693440914}
2023-01-05 01:40:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:11,140 INFO:     Epoch: 80
2023-01-05 01:40:13,261 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5632837692896525, 'Total loss': 0.5632837692896525} | train loss {'Reaction outcome loss': 0.1801443481135554, 'Total loss': 0.1801443481135554}
2023-01-05 01:40:13,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:13,261 INFO:     Epoch: 81
2023-01-05 01:40:15,423 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5407132307688395, 'Total loss': 0.5407132307688395} | train loss {'Reaction outcome loss': 0.1722755244124558, 'Total loss': 0.1722755244124558}
2023-01-05 01:40:15,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:15,424 INFO:     Epoch: 82
2023-01-05 01:40:17,659 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5471888492504756, 'Total loss': 0.5471888492504756} | train loss {'Reaction outcome loss': 0.17280156300113206, 'Total loss': 0.17280156300113206}
2023-01-05 01:40:17,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:17,659 INFO:     Epoch: 83
2023-01-05 01:40:19,847 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5690457125504812, 'Total loss': 0.5690457125504812} | train loss {'Reaction outcome loss': 0.17111999539133066, 'Total loss': 0.17111999539133066}
2023-01-05 01:40:19,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:19,848 INFO:     Epoch: 84
2023-01-05 01:40:22,064 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5598355174064636, 'Total loss': 0.5598355174064636} | train loss {'Reaction outcome loss': 0.1729103526946553, 'Total loss': 0.1729103526946553}
2023-01-05 01:40:22,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:22,065 INFO:     Epoch: 85
2023-01-05 01:40:24,287 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5517618209123611, 'Total loss': 0.5517618209123611} | train loss {'Reaction outcome loss': 0.170667939415993, 'Total loss': 0.170667939415993}
2023-01-05 01:40:24,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:24,288 INFO:     Epoch: 86
2023-01-05 01:40:26,467 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5973403781652451, 'Total loss': 0.5973403781652451} | train loss {'Reaction outcome loss': 0.17398487521342307, 'Total loss': 0.17398487521342307}
2023-01-05 01:40:26,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:26,468 INFO:     Epoch: 87
2023-01-05 01:40:28,679 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5736234803994497, 'Total loss': 0.5736234803994497} | train loss {'Reaction outcome loss': 0.17365852320539482, 'Total loss': 0.17365852320539482}
2023-01-05 01:40:28,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:28,680 INFO:     Epoch: 88
2023-01-05 01:40:30,883 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6229615728060405, 'Total loss': 0.6229615728060405} | train loss {'Reaction outcome loss': 0.1694681753776285, 'Total loss': 0.1694681753776285}
2023-01-05 01:40:30,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:30,883 INFO:     Epoch: 89
2023-01-05 01:40:33,085 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5827082435290019, 'Total loss': 0.5827082435290019} | train loss {'Reaction outcome loss': 0.1708406787809162, 'Total loss': 0.1708406787809162}
2023-01-05 01:40:33,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:33,086 INFO:     Epoch: 90
2023-01-05 01:40:35,221 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5815949728091557, 'Total loss': 0.5815949728091557} | train loss {'Reaction outcome loss': 0.17298507726249787, 'Total loss': 0.17298507726249787}
2023-01-05 01:40:35,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:35,221 INFO:     Epoch: 91
2023-01-05 01:40:37,439 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5884572545687358, 'Total loss': 0.5884572545687358} | train loss {'Reaction outcome loss': 0.17020591299967233, 'Total loss': 0.17020591299967233}
2023-01-05 01:40:37,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:37,439 INFO:     Epoch: 92
2023-01-05 01:40:39,609 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5372391750415166, 'Total loss': 0.5372391750415166} | train loss {'Reaction outcome loss': 0.16833397131686137, 'Total loss': 0.16833397131686137}
2023-01-05 01:40:39,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:39,610 INFO:     Epoch: 93
2023-01-05 01:40:41,799 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5637458628043532, 'Total loss': 0.5637458628043532} | train loss {'Reaction outcome loss': 0.16450854688336997, 'Total loss': 0.16450854688336997}
2023-01-05 01:40:41,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:41,800 INFO:     Epoch: 94
2023-01-05 01:40:43,969 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5810622056325276, 'Total loss': 0.5810622056325276} | train loss {'Reaction outcome loss': 0.16269728313319576, 'Total loss': 0.16269728313319576}
2023-01-05 01:40:43,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:43,969 INFO:     Epoch: 95
2023-01-05 01:40:46,209 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6444321910540263, 'Total loss': 0.6444321910540263} | train loss {'Reaction outcome loss': 0.16862767986823624, 'Total loss': 0.16862767986823624}
2023-01-05 01:40:46,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:46,210 INFO:     Epoch: 96
2023-01-05 01:40:48,429 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5691943337519964, 'Total loss': 0.5691943337519964} | train loss {'Reaction outcome loss': 0.1706180331338156, 'Total loss': 0.1706180331338156}
2023-01-05 01:40:48,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:48,429 INFO:     Epoch: 97
2023-01-05 01:40:50,604 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5731792519489924, 'Total loss': 0.5731792519489924} | train loss {'Reaction outcome loss': 0.16505302742273706, 'Total loss': 0.16505302742273706}
2023-01-05 01:40:50,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:50,604 INFO:     Epoch: 98
2023-01-05 01:40:52,845 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6229470094045003, 'Total loss': 0.6229470094045003} | train loss {'Reaction outcome loss': 0.16816799506893035, 'Total loss': 0.16816799506893035}
2023-01-05 01:40:52,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:52,846 INFO:     Epoch: 99
2023-01-05 01:40:55,027 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6400692065556844, 'Total loss': 0.6400692065556844} | train loss {'Reaction outcome loss': 0.16285009008760637, 'Total loss': 0.16285009008760637}
2023-01-05 01:40:55,027 INFO:     Best model found after epoch 20 of 100.
2023-01-05 01:40:55,027 INFO:   Done with stage: TRAINING
2023-01-05 01:40:55,027 INFO:   Starting stage: EVALUATION
2023-01-05 01:40:55,175 INFO:   Done with stage: EVALUATION
2023-01-05 01:40:55,175 INFO:   Leaving out SEQ value Fold_3
2023-01-05 01:40:55,188 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 01:40:55,188 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:40:55,840 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:40:55,841 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:40:55,911 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:40:55,911 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:40:55,911 INFO:     No hyperparam tuning for this model
2023-01-05 01:40:55,911 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:40:55,911 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:40:55,912 INFO:     None feature selector for col prot
2023-01-05 01:40:55,912 INFO:     None feature selector for col prot
2023-01-05 01:40:55,912 INFO:     None feature selector for col prot
2023-01-05 01:40:55,913 INFO:     None feature selector for col chem
2023-01-05 01:40:55,913 INFO:     None feature selector for col chem
2023-01-05 01:40:55,913 INFO:     None feature selector for col chem
2023-01-05 01:40:55,913 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:40:55,913 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:40:55,914 INFO:     Number of params in model 72931
2023-01-05 01:40:55,917 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:40:55,918 INFO:   Starting stage: TRAINING
2023-01-05 01:40:55,978 INFO:     Val loss before train {'Reaction outcome loss': 1.0060970942179361, 'Total loss': 1.0060970942179361}
2023-01-05 01:40:55,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:55,978 INFO:     Epoch: 0
2023-01-05 01:40:58,213 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7683745503425599, 'Total loss': 0.7683745503425599} | train loss {'Reaction outcome loss': 0.9442179093178171, 'Total loss': 0.9442179093178171}
2023-01-05 01:40:58,214 INFO:     Found new best model at epoch 0
2023-01-05 01:40:58,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:40:58,215 INFO:     Epoch: 1
2023-01-05 01:41:00,437 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6104733526706696, 'Total loss': 0.6104733526706696} | train loss {'Reaction outcome loss': 0.6594438516963137, 'Total loss': 0.6594438516963137}
2023-01-05 01:41:00,437 INFO:     Found new best model at epoch 1
2023-01-05 01:41:00,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:00,438 INFO:     Epoch: 2
2023-01-05 01:41:02,676 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5342038174470266, 'Total loss': 0.5342038174470266} | train loss {'Reaction outcome loss': 0.5509810409624211, 'Total loss': 0.5509810409624211}
2023-01-05 01:41:02,676 INFO:     Found new best model at epoch 2
2023-01-05 01:41:02,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:02,678 INFO:     Epoch: 3
2023-01-05 01:41:04,937 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48732459942499795, 'Total loss': 0.48732459942499795} | train loss {'Reaction outcome loss': 0.5031587816502926, 'Total loss': 0.5031587816502926}
2023-01-05 01:41:04,938 INFO:     Found new best model at epoch 3
2023-01-05 01:41:04,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:04,939 INFO:     Epoch: 4
2023-01-05 01:41:07,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4685888409614563, 'Total loss': 0.4685888409614563} | train loss {'Reaction outcome loss': 0.4779047029514382, 'Total loss': 0.4779047029514382}
2023-01-05 01:41:07,111 INFO:     Found new best model at epoch 4
2023-01-05 01:41:07,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:07,112 INFO:     Epoch: 5
2023-01-05 01:41:09,355 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4713558832804362, 'Total loss': 0.4713558832804362} | train loss {'Reaction outcome loss': 0.45085865085142374, 'Total loss': 0.45085865085142374}
2023-01-05 01:41:09,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:09,357 INFO:     Epoch: 6
2023-01-05 01:41:11,630 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4503700395425161, 'Total loss': 0.4503700395425161} | train loss {'Reaction outcome loss': 0.43280037737240756, 'Total loss': 0.43280037737240756}
2023-01-05 01:41:11,630 INFO:     Found new best model at epoch 6
2023-01-05 01:41:11,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:11,632 INFO:     Epoch: 7
2023-01-05 01:41:13,888 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4408463875452677, 'Total loss': 0.4408463875452677} | train loss {'Reaction outcome loss': 0.4206351571220116, 'Total loss': 0.4206351571220116}
2023-01-05 01:41:13,888 INFO:     Found new best model at epoch 7
2023-01-05 01:41:13,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:13,889 INFO:     Epoch: 8
2023-01-05 01:41:16,061 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43821146885553997, 'Total loss': 0.43821146885553997} | train loss {'Reaction outcome loss': 0.3994545318784505, 'Total loss': 0.3994545318784505}
2023-01-05 01:41:16,062 INFO:     Found new best model at epoch 8
2023-01-05 01:41:16,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:16,064 INFO:     Epoch: 9
2023-01-05 01:41:18,295 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4423735757668813, 'Total loss': 0.4423735757668813} | train loss {'Reaction outcome loss': 0.38810285085635465, 'Total loss': 0.38810285085635465}
2023-01-05 01:41:18,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:18,295 INFO:     Epoch: 10
2023-01-05 01:41:20,504 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41655034124851226, 'Total loss': 0.41655034124851226} | train loss {'Reaction outcome loss': 0.3776170682760268, 'Total loss': 0.3776170682760268}
2023-01-05 01:41:20,505 INFO:     Found new best model at epoch 10
2023-01-05 01:41:20,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:20,506 INFO:     Epoch: 11
2023-01-05 01:41:22,751 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44446552395820615, 'Total loss': 0.44446552395820615} | train loss {'Reaction outcome loss': 0.3696123456487255, 'Total loss': 0.3696123456487255}
2023-01-05 01:41:22,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:22,752 INFO:     Epoch: 12
2023-01-05 01:41:24,993 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4487735331058502, 'Total loss': 0.4487735331058502} | train loss {'Reaction outcome loss': 0.35960165669556954, 'Total loss': 0.35960165669556954}
2023-01-05 01:41:24,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:24,994 INFO:     Epoch: 13
2023-01-05 01:41:27,206 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4614036699136098, 'Total loss': 0.4614036699136098} | train loss {'Reaction outcome loss': 0.35101879874828956, 'Total loss': 0.35101879874828956}
2023-01-05 01:41:27,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:27,206 INFO:     Epoch: 14
2023-01-05 01:41:29,451 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44312537312507627, 'Total loss': 0.44312537312507627} | train loss {'Reaction outcome loss': 0.3460894052183976, 'Total loss': 0.3460894052183976}
2023-01-05 01:41:29,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:29,452 INFO:     Epoch: 15
2023-01-05 01:41:31,691 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4184118300676346, 'Total loss': 0.4184118300676346} | train loss {'Reaction outcome loss': 0.33316756939909753, 'Total loss': 0.33316756939909753}
2023-01-05 01:41:31,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:31,691 INFO:     Epoch: 16
2023-01-05 01:41:33,946 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42678900957107546, 'Total loss': 0.42678900957107546} | train loss {'Reaction outcome loss': 0.33029300205572676, 'Total loss': 0.33029300205572676}
2023-01-05 01:41:33,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:33,948 INFO:     Epoch: 17
2023-01-05 01:41:36,190 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4443830609321594, 'Total loss': 0.4443830609321594} | train loss {'Reaction outcome loss': 0.31898007634347375, 'Total loss': 0.31898007634347375}
2023-01-05 01:41:36,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:36,191 INFO:     Epoch: 18
2023-01-05 01:41:38,461 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45336344639460247, 'Total loss': 0.45336344639460247} | train loss {'Reaction outcome loss': 0.3187249458129824, 'Total loss': 0.3187249458129824}
2023-01-05 01:41:38,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:38,461 INFO:     Epoch: 19
2023-01-05 01:41:40,720 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41849232117335, 'Total loss': 0.41849232117335} | train loss {'Reaction outcome loss': 0.30806414647041447, 'Total loss': 0.30806414647041447}
2023-01-05 01:41:40,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:40,721 INFO:     Epoch: 20
2023-01-05 01:41:42,967 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42299911280473074, 'Total loss': 0.42299911280473074} | train loss {'Reaction outcome loss': 0.30881685911793344, 'Total loss': 0.30881685911793344}
2023-01-05 01:41:42,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:42,967 INFO:     Epoch: 21
2023-01-05 01:41:45,230 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4066370626290639, 'Total loss': 0.4066370626290639} | train loss {'Reaction outcome loss': 0.29820505246846346, 'Total loss': 0.29820505246846346}
2023-01-05 01:41:45,231 INFO:     Found new best model at epoch 21
2023-01-05 01:41:45,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:45,233 INFO:     Epoch: 22
2023-01-05 01:41:47,426 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43969218333562216, 'Total loss': 0.43969218333562216} | train loss {'Reaction outcome loss': 0.29861131140513575, 'Total loss': 0.29861131140513575}
2023-01-05 01:41:47,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:47,426 INFO:     Epoch: 23
2023-01-05 01:41:49,700 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42926008204619087, 'Total loss': 0.42926008204619087} | train loss {'Reaction outcome loss': 0.29421040975916996, 'Total loss': 0.29421040975916996}
2023-01-05 01:41:49,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:49,700 INFO:     Epoch: 24
2023-01-05 01:41:51,967 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4506415883700053, 'Total loss': 0.4506415883700053} | train loss {'Reaction outcome loss': 0.28792078723709513, 'Total loss': 0.28792078723709513}
2023-01-05 01:41:51,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:51,968 INFO:     Epoch: 25
2023-01-05 01:41:54,218 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43037928541501363, 'Total loss': 0.43037928541501363} | train loss {'Reaction outcome loss': 0.2862754881817059, 'Total loss': 0.2862754881817059}
2023-01-05 01:41:54,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:54,219 INFO:     Epoch: 26
2023-01-05 01:41:56,472 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.452465949455897, 'Total loss': 0.452465949455897} | train loss {'Reaction outcome loss': 0.27019750518574764, 'Total loss': 0.27019750518574764}
2023-01-05 01:41:56,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:56,473 INFO:     Epoch: 27
2023-01-05 01:41:58,726 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44164365977048875, 'Total loss': 0.44164365977048875} | train loss {'Reaction outcome loss': 0.2766630630124442, 'Total loss': 0.2766630630124442}
2023-01-05 01:41:58,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:41:58,726 INFO:     Epoch: 28
2023-01-05 01:42:00,976 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4191534926493963, 'Total loss': 0.4191534926493963} | train loss {'Reaction outcome loss': 0.27194202123345795, 'Total loss': 0.27194202123345795}
2023-01-05 01:42:00,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:00,977 INFO:     Epoch: 29
2023-01-05 01:42:03,201 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45618128776550293, 'Total loss': 0.45618128776550293} | train loss {'Reaction outcome loss': 0.26840042136609554, 'Total loss': 0.26840042136609554}
2023-01-05 01:42:03,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:03,203 INFO:     Epoch: 30
2023-01-05 01:42:05,450 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40695757865905763, 'Total loss': 0.40695757865905763} | train loss {'Reaction outcome loss': 0.26801084688300414, 'Total loss': 0.26801084688300414}
2023-01-05 01:42:05,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:05,450 INFO:     Epoch: 31
2023-01-05 01:42:07,677 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41786629557609556, 'Total loss': 0.41786629557609556} | train loss {'Reaction outcome loss': 0.26423311316455805, 'Total loss': 0.26423311316455805}
2023-01-05 01:42:07,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:07,677 INFO:     Epoch: 32
2023-01-05 01:42:09,915 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45994527141253155, 'Total loss': 0.45994527141253155} | train loss {'Reaction outcome loss': 0.26037059669267304, 'Total loss': 0.26037059669267304}
2023-01-05 01:42:09,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:09,916 INFO:     Epoch: 33
2023-01-05 01:42:12,157 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4653103808561961, 'Total loss': 0.4653103808561961} | train loss {'Reaction outcome loss': 0.25753994776194333, 'Total loss': 0.25753994776194333}
2023-01-05 01:42:12,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:12,157 INFO:     Epoch: 34
2023-01-05 01:42:14,301 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45800642172495526, 'Total loss': 0.45800642172495526} | train loss {'Reaction outcome loss': 0.25235402585435524, 'Total loss': 0.25235402585435524}
2023-01-05 01:42:14,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:14,303 INFO:     Epoch: 35
2023-01-05 01:42:16,467 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42737902998924254, 'Total loss': 0.42737902998924254} | train loss {'Reaction outcome loss': 0.2552858843420544, 'Total loss': 0.2552858843420544}
2023-01-05 01:42:16,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:16,467 INFO:     Epoch: 36
2023-01-05 01:42:18,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.427082030971845, 'Total loss': 0.427082030971845} | train loss {'Reaction outcome loss': 0.25010453618682216, 'Total loss': 0.25010453618682216}
2023-01-05 01:42:18,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:18,598 INFO:     Epoch: 37
2023-01-05 01:42:20,827 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4343855837980906, 'Total loss': 0.4343855837980906} | train loss {'Reaction outcome loss': 0.2477380527645676, 'Total loss': 0.2477380527645676}
2023-01-05 01:42:20,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:20,828 INFO:     Epoch: 38
2023-01-05 01:42:23,084 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44219512343406675, 'Total loss': 0.44219512343406675} | train loss {'Reaction outcome loss': 0.2463010852463054, 'Total loss': 0.2463010852463054}
2023-01-05 01:42:23,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:23,084 INFO:     Epoch: 39
2023-01-05 01:42:25,256 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4419936329126358, 'Total loss': 0.4419936329126358} | train loss {'Reaction outcome loss': 0.23999563478150943, 'Total loss': 0.23999563478150943}
2023-01-05 01:42:25,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:25,256 INFO:     Epoch: 40
2023-01-05 01:42:27,453 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4244680205980937, 'Total loss': 0.4244680205980937} | train loss {'Reaction outcome loss': 0.23608881347969066, 'Total loss': 0.23608881347969066}
2023-01-05 01:42:27,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:27,454 INFO:     Epoch: 41
2023-01-05 01:42:29,676 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45232752958933514, 'Total loss': 0.45232752958933514} | train loss {'Reaction outcome loss': 0.2393008621790222, 'Total loss': 0.2393008621790222}
2023-01-05 01:42:29,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:29,676 INFO:     Epoch: 42
2023-01-05 01:42:31,852 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45708490113417305, 'Total loss': 0.45708490113417305} | train loss {'Reaction outcome loss': 0.23171016756771473, 'Total loss': 0.23171016756771473}
2023-01-05 01:42:31,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:31,854 INFO:     Epoch: 43
2023-01-05 01:42:34,036 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44423972964286806, 'Total loss': 0.44423972964286806} | train loss {'Reaction outcome loss': 0.2333467707826491, 'Total loss': 0.2333467707826491}
2023-01-05 01:42:34,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:34,037 INFO:     Epoch: 44
2023-01-05 01:42:36,286 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43244034772117934, 'Total loss': 0.43244034772117934} | train loss {'Reaction outcome loss': 0.23067821808376887, 'Total loss': 0.23067821808376887}
2023-01-05 01:42:36,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:36,287 INFO:     Epoch: 45
2023-01-05 01:42:38,455 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45151126980781553, 'Total loss': 0.45151126980781553} | train loss {'Reaction outcome loss': 0.22627900750206334, 'Total loss': 0.22627900750206334}
2023-01-05 01:42:38,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:38,456 INFO:     Epoch: 46
2023-01-05 01:42:40,646 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4818099627892176, 'Total loss': 0.4818099627892176} | train loss {'Reaction outcome loss': 0.2277316432582201, 'Total loss': 0.2277316432582201}
2023-01-05 01:42:40,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:40,646 INFO:     Epoch: 47
2023-01-05 01:42:42,861 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4366787632306417, 'Total loss': 0.4366787632306417} | train loss {'Reaction outcome loss': 0.22735125982087023, 'Total loss': 0.22735125982087023}
2023-01-05 01:42:42,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:42,863 INFO:     Epoch: 48
2023-01-05 01:42:45,018 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41854520042737325, 'Total loss': 0.41854520042737325} | train loss {'Reaction outcome loss': 0.2206480893625939, 'Total loss': 0.2206480893625939}
2023-01-05 01:42:45,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:45,018 INFO:     Epoch: 49
2023-01-05 01:42:47,184 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4468700021505356, 'Total loss': 0.4468700021505356} | train loss {'Reaction outcome loss': 0.21948603752075974, 'Total loss': 0.21948603752075974}
2023-01-05 01:42:47,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:47,184 INFO:     Epoch: 50
2023-01-05 01:42:49,411 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43413258294264473, 'Total loss': 0.43413258294264473} | train loss {'Reaction outcome loss': 0.22525578871858817, 'Total loss': 0.22525578871858817}
2023-01-05 01:42:49,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:49,412 INFO:     Epoch: 51
2023-01-05 01:42:51,604 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3991751595089833, 'Total loss': 0.3991751595089833} | train loss {'Reaction outcome loss': 0.2169282406119861, 'Total loss': 0.2169282406119861}
2023-01-05 01:42:51,604 INFO:     Found new best model at epoch 51
2023-01-05 01:42:51,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:51,605 INFO:     Epoch: 52
2023-01-05 01:42:53,829 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4431662857532501, 'Total loss': 0.4431662857532501} | train loss {'Reaction outcome loss': 0.21963281733371373, 'Total loss': 0.21963281733371373}
2023-01-05 01:42:53,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:53,829 INFO:     Epoch: 53
2023-01-05 01:42:56,035 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44950895408789315, 'Total loss': 0.44950895408789315} | train loss {'Reaction outcome loss': 0.21544543312808132, 'Total loss': 0.21544543312808132}
2023-01-05 01:42:56,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:56,036 INFO:     Epoch: 54
2023-01-05 01:42:58,233 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45896146098772683, 'Total loss': 0.45896146098772683} | train loss {'Reaction outcome loss': 0.2199837131201405, 'Total loss': 0.2199837131201405}
2023-01-05 01:42:58,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:42:58,233 INFO:     Epoch: 55
2023-01-05 01:43:00,481 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43912418087323507, 'Total loss': 0.43912418087323507} | train loss {'Reaction outcome loss': 0.22022954070002493, 'Total loss': 0.22022954070002493}
2023-01-05 01:43:00,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:00,482 INFO:     Epoch: 56
2023-01-05 01:43:02,650 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48038627902666725, 'Total loss': 0.48038627902666725} | train loss {'Reaction outcome loss': 0.2076432942276834, 'Total loss': 0.2076432942276834}
2023-01-05 01:43:02,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:02,650 INFO:     Epoch: 57
2023-01-05 01:43:04,797 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43585817217826844, 'Total loss': 0.43585817217826844} | train loss {'Reaction outcome loss': 0.21427994846862597, 'Total loss': 0.21427994846862597}
2023-01-05 01:43:04,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:04,797 INFO:     Epoch: 58
2023-01-05 01:43:07,014 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44549983491500217, 'Total loss': 0.44549983491500217} | train loss {'Reaction outcome loss': 0.2064985823579622, 'Total loss': 0.2064985823579622}
2023-01-05 01:43:07,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:07,015 INFO:     Epoch: 59
2023-01-05 01:43:09,213 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4796068032582601, 'Total loss': 0.4796068032582601} | train loss {'Reaction outcome loss': 0.20774086720452908, 'Total loss': 0.20774086720452908}
2023-01-05 01:43:09,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:09,214 INFO:     Epoch: 60
2023-01-05 01:43:11,394 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45781970222791035, 'Total loss': 0.45781970222791035} | train loss {'Reaction outcome loss': 0.21214227922886175, 'Total loss': 0.21214227922886175}
2023-01-05 01:43:11,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:11,394 INFO:     Epoch: 61
2023-01-05 01:43:13,620 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42556723157564796, 'Total loss': 0.42556723157564796} | train loss {'Reaction outcome loss': 0.20825172908243852, 'Total loss': 0.20825172908243852}
2023-01-05 01:43:13,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:13,622 INFO:     Epoch: 62
2023-01-05 01:43:15,839 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4670224517583847, 'Total loss': 0.4670224517583847} | train loss {'Reaction outcome loss': 0.21047230751124502, 'Total loss': 0.21047230751124502}
2023-01-05 01:43:15,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:15,839 INFO:     Epoch: 63
2023-01-05 01:43:18,046 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4410982092221578, 'Total loss': 0.4410982092221578} | train loss {'Reaction outcome loss': 0.20072387997740812, 'Total loss': 0.20072387997740812}
2023-01-05 01:43:18,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:18,046 INFO:     Epoch: 64
2023-01-05 01:43:20,280 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4361060912410418, 'Total loss': 0.4361060912410418} | train loss {'Reaction outcome loss': 0.19808876878466375, 'Total loss': 0.19808876878466375}
2023-01-05 01:43:20,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:20,282 INFO:     Epoch: 65
2023-01-05 01:43:22,341 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4634522596995036, 'Total loss': 0.4634522596995036} | train loss {'Reaction outcome loss': 0.20065101791499523, 'Total loss': 0.20065101791499523}
2023-01-05 01:43:22,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:22,341 INFO:     Epoch: 66
2023-01-05 01:43:24,541 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43778120875358584, 'Total loss': 0.43778120875358584} | train loss {'Reaction outcome loss': 0.2034661250433674, 'Total loss': 0.2034661250433674}
2023-01-05 01:43:24,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:24,543 INFO:     Epoch: 67
2023-01-05 01:43:26,786 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4282122373580933, 'Total loss': 0.4282122373580933} | train loss {'Reaction outcome loss': 0.20260509895160794, 'Total loss': 0.20260509895160794}
2023-01-05 01:43:26,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:26,787 INFO:     Epoch: 68
2023-01-05 01:43:28,994 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43703537484010063, 'Total loss': 0.43703537484010063} | train loss {'Reaction outcome loss': 0.19974626107889154, 'Total loss': 0.19974626107889154}
2023-01-05 01:43:28,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:28,994 INFO:     Epoch: 69
2023-01-05 01:43:31,215 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4630436877409617, 'Total loss': 0.4630436877409617} | train loss {'Reaction outcome loss': 0.2011242627852807, 'Total loss': 0.2011242627852807}
2023-01-05 01:43:31,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:31,216 INFO:     Epoch: 70
2023-01-05 01:43:33,442 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4409736843779683, 'Total loss': 0.4409736843779683} | train loss {'Reaction outcome loss': 0.19998533668227658, 'Total loss': 0.19998533668227658}
2023-01-05 01:43:33,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:33,442 INFO:     Epoch: 71
2023-01-05 01:43:35,674 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4351413995027542, 'Total loss': 0.4351413995027542} | train loss {'Reaction outcome loss': 0.19163134029937268, 'Total loss': 0.19163134029937268}
2023-01-05 01:43:35,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:35,675 INFO:     Epoch: 72
2023-01-05 01:43:37,865 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48492063383261363, 'Total loss': 0.48492063383261363} | train loss {'Reaction outcome loss': 0.19018641076846063, 'Total loss': 0.19018641076846063}
2023-01-05 01:43:37,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:37,865 INFO:     Epoch: 73
2023-01-05 01:43:40,092 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4447895780205727, 'Total loss': 0.4447895780205727} | train loss {'Reaction outcome loss': 0.19750870738423218, 'Total loss': 0.19750870738423218}
2023-01-05 01:43:40,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:40,093 INFO:     Epoch: 74
2023-01-05 01:43:42,281 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45120621621608736, 'Total loss': 0.45120621621608736} | train loss {'Reaction outcome loss': 0.1912530868953216, 'Total loss': 0.1912530868953216}
2023-01-05 01:43:42,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:42,282 INFO:     Epoch: 75
2023-01-05 01:43:44,464 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4428103148937225, 'Total loss': 0.4428103148937225} | train loss {'Reaction outcome loss': 0.19319430437537222, 'Total loss': 0.19319430437537222}
2023-01-05 01:43:44,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:44,464 INFO:     Epoch: 76
2023-01-05 01:43:46,708 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4680670162041982, 'Total loss': 0.4680670162041982} | train loss {'Reaction outcome loss': 0.19475564920431832, 'Total loss': 0.19475564920431832}
2023-01-05 01:43:46,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:46,709 INFO:     Epoch: 77
2023-01-05 01:43:48,938 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4785319964090983, 'Total loss': 0.4785319964090983} | train loss {'Reaction outcome loss': 0.19630224862047574, 'Total loss': 0.19630224862047574}
2023-01-05 01:43:48,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:48,939 INFO:     Epoch: 78
2023-01-05 01:43:51,195 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4737237721681595, 'Total loss': 0.4737237721681595} | train loss {'Reaction outcome loss': 0.19052456981114987, 'Total loss': 0.19052456981114987}
2023-01-05 01:43:51,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:51,195 INFO:     Epoch: 79
2023-01-05 01:43:53,498 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44650390396515527, 'Total loss': 0.44650390396515527} | train loss {'Reaction outcome loss': 0.19250875921498467, 'Total loss': 0.19250875921498467}
2023-01-05 01:43:53,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:53,499 INFO:     Epoch: 80
2023-01-05 01:43:55,632 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4656314233938853, 'Total loss': 0.4656314233938853} | train loss {'Reaction outcome loss': 0.1870548390650809, 'Total loss': 0.1870548390650809}
2023-01-05 01:43:55,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:55,633 INFO:     Epoch: 81
2023-01-05 01:43:57,882 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4492069164911906, 'Total loss': 0.4492069164911906} | train loss {'Reaction outcome loss': 0.18736970115684137, 'Total loss': 0.18736970115684137}
2023-01-05 01:43:57,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:43:57,883 INFO:     Epoch: 82
2023-01-05 01:44:00,100 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4671809772650401, 'Total loss': 0.4671809772650401} | train loss {'Reaction outcome loss': 0.1876033969549802, 'Total loss': 0.1876033969549802}
2023-01-05 01:44:00,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:00,102 INFO:     Epoch: 83
2023-01-05 01:44:02,291 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48544639789809785, 'Total loss': 0.48544639789809785} | train loss {'Reaction outcome loss': 0.19147462795835232, 'Total loss': 0.19147462795835232}
2023-01-05 01:44:02,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:02,291 INFO:     Epoch: 84
2023-01-05 01:44:04,494 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.445390011370182, 'Total loss': 0.445390011370182} | train loss {'Reaction outcome loss': 0.18520196664731706, 'Total loss': 0.18520196664731706}
2023-01-05 01:44:04,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:04,494 INFO:     Epoch: 85
2023-01-05 01:44:06,664 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4515836715698242, 'Total loss': 0.4515836715698242} | train loss {'Reaction outcome loss': 0.1822843121323925, 'Total loss': 0.1822843121323925}
2023-01-05 01:44:06,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:06,665 INFO:     Epoch: 86
2023-01-05 01:44:08,881 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4257164786259333, 'Total loss': 0.4257164786259333} | train loss {'Reaction outcome loss': 0.1909066325488643, 'Total loss': 0.1909066325488643}
2023-01-05 01:44:08,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:08,881 INFO:     Epoch: 87
2023-01-05 01:44:11,126 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4261100749174754, 'Total loss': 0.4261100749174754} | train loss {'Reaction outcome loss': 0.18218236208900157, 'Total loss': 0.18218236208900157}
2023-01-05 01:44:11,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:11,126 INFO:     Epoch: 88
2023-01-05 01:44:13,366 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44333105385303495, 'Total loss': 0.44333105385303495} | train loss {'Reaction outcome loss': 0.17885406882107857, 'Total loss': 0.17885406882107857}
2023-01-05 01:44:13,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:13,368 INFO:     Epoch: 89
2023-01-05 01:44:15,609 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42841508785883586, 'Total loss': 0.42841508785883586} | train loss {'Reaction outcome loss': 0.1807247930372909, 'Total loss': 0.1807247930372909}
2023-01-05 01:44:15,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:15,610 INFO:     Epoch: 90
2023-01-05 01:44:17,796 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4497991144657135, 'Total loss': 0.4497991144657135} | train loss {'Reaction outcome loss': 0.1798068326744965, 'Total loss': 0.1798068326744965}
2023-01-05 01:44:17,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:17,796 INFO:     Epoch: 91
2023-01-05 01:44:20,060 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42858794530232747, 'Total loss': 0.42858794530232747} | train loss {'Reaction outcome loss': 0.17500910055177815, 'Total loss': 0.17500910055177815}
2023-01-05 01:44:20,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:20,060 INFO:     Epoch: 92
2023-01-05 01:44:22,323 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46402464707692465, 'Total loss': 0.46402464707692465} | train loss {'Reaction outcome loss': 0.1756344102357045, 'Total loss': 0.1756344102357045}
2023-01-05 01:44:22,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:22,323 INFO:     Epoch: 93
2023-01-05 01:44:24,561 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42698553974429765, 'Total loss': 0.42698553974429765} | train loss {'Reaction outcome loss': 0.17515705687496946, 'Total loss': 0.17515705687496946}
2023-01-05 01:44:24,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:24,561 INFO:     Epoch: 94
2023-01-05 01:44:26,801 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4460614154736201, 'Total loss': 0.4460614154736201} | train loss {'Reaction outcome loss': 0.17730351869377178, 'Total loss': 0.17730351869377178}
2023-01-05 01:44:26,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:26,801 INFO:     Epoch: 95
2023-01-05 01:44:29,038 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4728704333305359, 'Total loss': 0.4728704333305359} | train loss {'Reaction outcome loss': 0.1731232358584602, 'Total loss': 0.1731232358584602}
2023-01-05 01:44:29,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:29,038 INFO:     Epoch: 96
2023-01-05 01:44:31,302 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4522951404253642, 'Total loss': 0.4522951404253642} | train loss {'Reaction outcome loss': 0.1718984477996935, 'Total loss': 0.1718984477996935}
2023-01-05 01:44:31,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:31,302 INFO:     Epoch: 97
2023-01-05 01:44:33,567 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45191768010457356, 'Total loss': 0.45191768010457356} | train loss {'Reaction outcome loss': 0.1772199448225272, 'Total loss': 0.1772199448225272}
2023-01-05 01:44:33,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:33,568 INFO:     Epoch: 98
2023-01-05 01:44:35,829 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45949150721232096, 'Total loss': 0.45949150721232096} | train loss {'Reaction outcome loss': 0.1763263918003951, 'Total loss': 0.1763263918003951}
2023-01-05 01:44:35,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:35,830 INFO:     Epoch: 99
2023-01-05 01:44:38,090 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41580463430533804, 'Total loss': 0.41580463430533804} | train loss {'Reaction outcome loss': 0.16912773750504873, 'Total loss': 0.16912773750504873}
2023-01-05 01:44:38,090 INFO:     Best model found after epoch 52 of 100.
2023-01-05 01:44:38,090 INFO:   Done with stage: TRAINING
2023-01-05 01:44:38,090 INFO:   Starting stage: EVALUATION
2023-01-05 01:44:38,231 INFO:   Done with stage: EVALUATION
2023-01-05 01:44:38,231 INFO:   Leaving out SEQ value Fold_4
2023-01-05 01:44:38,243 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 01:44:38,243 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:44:38,895 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:44:38,895 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:44:38,965 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:44:38,965 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:44:38,965 INFO:     No hyperparam tuning for this model
2023-01-05 01:44:38,965 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:44:38,965 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:44:38,966 INFO:     None feature selector for col prot
2023-01-05 01:44:38,966 INFO:     None feature selector for col prot
2023-01-05 01:44:38,966 INFO:     None feature selector for col prot
2023-01-05 01:44:38,966 INFO:     None feature selector for col chem
2023-01-05 01:44:38,966 INFO:     None feature selector for col chem
2023-01-05 01:44:38,967 INFO:     None feature selector for col chem
2023-01-05 01:44:38,967 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:44:38,967 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:44:38,968 INFO:     Number of params in model 72931
2023-01-05 01:44:38,971 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:44:38,971 INFO:   Starting stage: TRAINING
2023-01-05 01:44:39,032 INFO:     Val loss before train {'Reaction outcome loss': 1.0478549043337504, 'Total loss': 1.0478549043337504}
2023-01-05 01:44:39,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:39,032 INFO:     Epoch: 0
2023-01-05 01:44:41,257 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8473887205123901, 'Total loss': 0.8473887205123901} | train loss {'Reaction outcome loss': 0.9590577712093574, 'Total loss': 0.9590577712093574}
2023-01-05 01:44:41,257 INFO:     Found new best model at epoch 0
2023-01-05 01:44:41,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:41,259 INFO:     Epoch: 1
2023-01-05 01:44:43,503 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5522898972034455, 'Total loss': 0.5522898972034455} | train loss {'Reaction outcome loss': 0.6527080931262099, 'Total loss': 0.6527080931262099}
2023-01-05 01:44:43,504 INFO:     Found new best model at epoch 1
2023-01-05 01:44:43,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:43,506 INFO:     Epoch: 2
2023-01-05 01:44:45,767 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.475300340851148, 'Total loss': 0.475300340851148} | train loss {'Reaction outcome loss': 0.5331565507694377, 'Total loss': 0.5331565507694377}
2023-01-05 01:44:45,767 INFO:     Found new best model at epoch 2
2023-01-05 01:44:45,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:45,769 INFO:     Epoch: 3
2023-01-05 01:44:48,041 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4671708444754283, 'Total loss': 0.4671708444754283} | train loss {'Reaction outcome loss': 0.4927995405429839, 'Total loss': 0.4927995405429839}
2023-01-05 01:44:48,041 INFO:     Found new best model at epoch 3
2023-01-05 01:44:48,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:48,042 INFO:     Epoch: 4
2023-01-05 01:44:50,299 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4480406184991201, 'Total loss': 0.4480406184991201} | train loss {'Reaction outcome loss': 0.4648516895249486, 'Total loss': 0.4648516895249486}
2023-01-05 01:44:50,300 INFO:     Found new best model at epoch 4
2023-01-05 01:44:50,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:50,301 INFO:     Epoch: 5
2023-01-05 01:44:52,492 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41989005406697594, 'Total loss': 0.41989005406697594} | train loss {'Reaction outcome loss': 0.4407635046547406, 'Total loss': 0.4407635046547406}
2023-01-05 01:44:52,492 INFO:     Found new best model at epoch 5
2023-01-05 01:44:52,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:52,494 INFO:     Epoch: 6
2023-01-05 01:44:54,672 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45208947360515594, 'Total loss': 0.45208947360515594} | train loss {'Reaction outcome loss': 0.4246480541191556, 'Total loss': 0.4246480541191556}
2023-01-05 01:44:54,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:54,673 INFO:     Epoch: 7
2023-01-05 01:44:56,962 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4034455123047034, 'Total loss': 0.4034455123047034} | train loss {'Reaction outcome loss': 0.4122673351371634, 'Total loss': 0.4122673351371634}
2023-01-05 01:44:56,963 INFO:     Found new best model at epoch 7
2023-01-05 01:44:56,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:56,964 INFO:     Epoch: 8
2023-01-05 01:44:59,247 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4611929794152578, 'Total loss': 0.4611929794152578} | train loss {'Reaction outcome loss': 0.39295879960654007, 'Total loss': 0.39295879960654007}
2023-01-05 01:44:59,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:44:59,247 INFO:     Epoch: 9
2023-01-05 01:45:01,520 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4094309647878011, 'Total loss': 0.4094309647878011} | train loss {'Reaction outcome loss': 0.3841631189258634, 'Total loss': 0.3841631189258634}
2023-01-05 01:45:01,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:01,520 INFO:     Epoch: 10
2023-01-05 01:45:03,767 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39574781358242034, 'Total loss': 0.39574781358242034} | train loss {'Reaction outcome loss': 0.3748208015627376, 'Total loss': 0.3748208015627376}
2023-01-05 01:45:03,768 INFO:     Found new best model at epoch 10
2023-01-05 01:45:03,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:03,770 INFO:     Epoch: 11
2023-01-05 01:45:06,016 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4313919633626938, 'Total loss': 0.4313919633626938} | train loss {'Reaction outcome loss': 0.35898462035085843, 'Total loss': 0.35898462035085843}
2023-01-05 01:45:06,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:06,016 INFO:     Epoch: 12
2023-01-05 01:45:08,273 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41539128323396046, 'Total loss': 0.41539128323396046} | train loss {'Reaction outcome loss': 0.34979979178287846, 'Total loss': 0.34979979178287846}
2023-01-05 01:45:08,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:08,273 INFO:     Epoch: 13
2023-01-05 01:45:10,501 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42442037065823873, 'Total loss': 0.42442037065823873} | train loss {'Reaction outcome loss': 0.34162395048432687, 'Total loss': 0.34162395048432687}
2023-01-05 01:45:10,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:10,502 INFO:     Epoch: 14
2023-01-05 01:45:12,770 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.432954873641332, 'Total loss': 0.432954873641332} | train loss {'Reaction outcome loss': 0.3332726990152825, 'Total loss': 0.3332726990152825}
2023-01-05 01:45:12,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:12,771 INFO:     Epoch: 15
2023-01-05 01:45:15,001 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42223166724046074, 'Total loss': 0.42223166724046074} | train loss {'Reaction outcome loss': 0.3422901805868183, 'Total loss': 0.3422901805868183}
2023-01-05 01:45:15,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:15,001 INFO:     Epoch: 16
2023-01-05 01:45:17,273 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4176799754301707, 'Total loss': 0.4176799754301707} | train loss {'Reaction outcome loss': 0.34497673314467975, 'Total loss': 0.34497673314467975}
2023-01-05 01:45:17,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:17,273 INFO:     Epoch: 17
2023-01-05 01:45:19,545 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42784463440378506, 'Total loss': 0.42784463440378506} | train loss {'Reaction outcome loss': 0.3111907169594011, 'Total loss': 0.3111907169594011}
2023-01-05 01:45:19,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:19,546 INFO:     Epoch: 18
2023-01-05 01:45:21,732 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4604980170726776, 'Total loss': 0.4604980170726776} | train loss {'Reaction outcome loss': 0.30690044230794994, 'Total loss': 0.30690044230794994}
2023-01-05 01:45:21,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:21,732 INFO:     Epoch: 19
2023-01-05 01:45:23,973 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4389816254377365, 'Total loss': 0.4389816254377365} | train loss {'Reaction outcome loss': 0.30127057410477986, 'Total loss': 0.30127057410477986}
2023-01-05 01:45:23,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:23,973 INFO:     Epoch: 20
2023-01-05 01:45:26,218 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3967683546245098, 'Total loss': 0.3967683546245098} | train loss {'Reaction outcome loss': 0.29260720324743056, 'Total loss': 0.29260720324743056}
2023-01-05 01:45:26,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:26,219 INFO:     Epoch: 21
2023-01-05 01:45:28,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4289025644461314, 'Total loss': 0.4289025644461314} | train loss {'Reaction outcome loss': 0.2959447705922513, 'Total loss': 0.2959447705922513}
2023-01-05 01:45:28,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:28,485 INFO:     Epoch: 22
2023-01-05 01:45:30,762 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4307472596565882, 'Total loss': 0.4307472596565882} | train loss {'Reaction outcome loss': 0.287316146556396, 'Total loss': 0.287316146556396}
2023-01-05 01:45:30,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:30,763 INFO:     Epoch: 23
2023-01-05 01:45:33,028 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43033771018187206, 'Total loss': 0.43033771018187206} | train loss {'Reaction outcome loss': 0.28535579273180256, 'Total loss': 0.28535579273180256}
2023-01-05 01:45:33,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:33,028 INFO:     Epoch: 24
2023-01-05 01:45:35,279 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41144488056500755, 'Total loss': 0.41144488056500755} | train loss {'Reaction outcome loss': 0.2800747401492697, 'Total loss': 0.2800747401492697}
2023-01-05 01:45:35,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:35,279 INFO:     Epoch: 25
2023-01-05 01:45:37,519 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4231521666049957, 'Total loss': 0.4231521666049957} | train loss {'Reaction outcome loss': 0.2758713143951921, 'Total loss': 0.2758713143951921}
2023-01-05 01:45:37,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:37,519 INFO:     Epoch: 26
2023-01-05 01:45:39,715 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4065109997987747, 'Total loss': 0.4065109997987747} | train loss {'Reaction outcome loss': 0.27010688054766774, 'Total loss': 0.27010688054766774}
2023-01-05 01:45:39,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:39,716 INFO:     Epoch: 27
2023-01-05 01:45:41,987 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40334798594315846, 'Total loss': 0.40334798594315846} | train loss {'Reaction outcome loss': 0.26681095954584144, 'Total loss': 0.26681095954584144}
2023-01-05 01:45:41,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:41,988 INFO:     Epoch: 28
2023-01-05 01:45:44,254 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42673107584317527, 'Total loss': 0.42673107584317527} | train loss {'Reaction outcome loss': 0.26587525580375304, 'Total loss': 0.26587525580375304}
2023-01-05 01:45:44,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:44,255 INFO:     Epoch: 29
2023-01-05 01:45:46,537 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39797835275530813, 'Total loss': 0.39797835275530813} | train loss {'Reaction outcome loss': 0.2567585979274515, 'Total loss': 0.2567585979274515}
2023-01-05 01:45:46,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:46,538 INFO:     Epoch: 30
2023-01-05 01:45:48,744 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4039922634760539, 'Total loss': 0.4039922634760539} | train loss {'Reaction outcome loss': 0.2591036349615973, 'Total loss': 0.2591036349615973}
2023-01-05 01:45:48,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:48,744 INFO:     Epoch: 31
2023-01-05 01:45:50,973 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3944162135322889, 'Total loss': 0.3944162135322889} | train loss {'Reaction outcome loss': 0.2623512823519166, 'Total loss': 0.2623512823519166}
2023-01-05 01:45:50,973 INFO:     Found new best model at epoch 31
2023-01-05 01:45:50,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:50,974 INFO:     Epoch: 32
2023-01-05 01:45:53,181 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4467349241177241, 'Total loss': 0.4467349241177241} | train loss {'Reaction outcome loss': 0.2500136255103575, 'Total loss': 0.2500136255103575}
2023-01-05 01:45:53,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:53,182 INFO:     Epoch: 33
2023-01-05 01:45:55,368 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3960900331536929, 'Total loss': 0.3960900331536929} | train loss {'Reaction outcome loss': 0.24784914162212415, 'Total loss': 0.24784914162212415}
2023-01-05 01:45:55,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:55,370 INFO:     Epoch: 34
2023-01-05 01:45:57,591 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4304212794949611, 'Total loss': 0.4304212794949611} | train loss {'Reaction outcome loss': 0.2426974783192618, 'Total loss': 0.2426974783192618}
2023-01-05 01:45:57,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:57,591 INFO:     Epoch: 35
2023-01-05 01:45:59,823 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3739450563987096, 'Total loss': 0.3739450563987096} | train loss {'Reaction outcome loss': 0.2428619993772135, 'Total loss': 0.2428619993772135}
2023-01-05 01:45:59,823 INFO:     Found new best model at epoch 35
2023-01-05 01:45:59,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:45:59,825 INFO:     Epoch: 36
2023-01-05 01:46:02,108 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4001166095336278, 'Total loss': 0.4001166095336278} | train loss {'Reaction outcome loss': 0.23880648226949616, 'Total loss': 0.23880648226949616}
2023-01-05 01:46:02,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:02,109 INFO:     Epoch: 37
2023-01-05 01:46:04,387 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4379964624842008, 'Total loss': 0.4379964624842008} | train loss {'Reaction outcome loss': 0.23981586406159255, 'Total loss': 0.23981586406159255}
2023-01-05 01:46:04,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:04,388 INFO:     Epoch: 38
2023-01-05 01:46:06,606 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4160915975769361, 'Total loss': 0.4160915975769361} | train loss {'Reaction outcome loss': 0.23662195150351129, 'Total loss': 0.23662195150351129}
2023-01-05 01:46:06,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:06,606 INFO:     Epoch: 39
2023-01-05 01:46:08,875 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3906775037447611, 'Total loss': 0.3906775037447611} | train loss {'Reaction outcome loss': 0.2319568905779464, 'Total loss': 0.2319568905779464}
2023-01-05 01:46:08,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:08,875 INFO:     Epoch: 40
2023-01-05 01:46:11,114 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41019042432308195, 'Total loss': 0.41019042432308195} | train loss {'Reaction outcome loss': 0.23093932980445706, 'Total loss': 0.23093932980445706}
2023-01-05 01:46:11,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:11,114 INFO:     Epoch: 41
2023-01-05 01:46:13,352 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4497780362764994, 'Total loss': 0.4497780362764994} | train loss {'Reaction outcome loss': 0.2309164331042363, 'Total loss': 0.2309164331042363}
2023-01-05 01:46:13,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:13,352 INFO:     Epoch: 42
2023-01-05 01:46:15,579 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4385632614294688, 'Total loss': 0.4385632614294688} | train loss {'Reaction outcome loss': 0.229775943165726, 'Total loss': 0.229775943165726}
2023-01-05 01:46:15,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:15,580 INFO:     Epoch: 43
2023-01-05 01:46:17,790 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4181867520014445, 'Total loss': 0.4181867520014445} | train loss {'Reaction outcome loss': 0.265552866373859, 'Total loss': 0.265552866373859}
2023-01-05 01:46:17,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:17,790 INFO:     Epoch: 44
2023-01-05 01:46:19,992 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4399937132994334, 'Total loss': 0.4399937132994334} | train loss {'Reaction outcome loss': 0.22463948384087207, 'Total loss': 0.22463948384087207}
2023-01-05 01:46:19,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:19,993 INFO:     Epoch: 45
2023-01-05 01:46:22,252 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4280941973129908, 'Total loss': 0.4280941973129908} | train loss {'Reaction outcome loss': 0.22403960063905065, 'Total loss': 0.22403960063905065}
2023-01-05 01:46:22,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:22,252 INFO:     Epoch: 46
2023-01-05 01:46:24,489 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43206335107485455, 'Total loss': 0.43206335107485455} | train loss {'Reaction outcome loss': 0.25291313107489893, 'Total loss': 0.25291313107489893}
2023-01-05 01:46:24,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:24,489 INFO:     Epoch: 47
2023-01-05 01:46:26,751 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40564239223798115, 'Total loss': 0.40564239223798115} | train loss {'Reaction outcome loss': 0.220263941637814, 'Total loss': 0.220263941637814}
2023-01-05 01:46:26,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:26,752 INFO:     Epoch: 48
2023-01-05 01:46:28,925 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3953122819463412, 'Total loss': 0.3953122819463412} | train loss {'Reaction outcome loss': 0.21914999771473814, 'Total loss': 0.21914999771473814}
2023-01-05 01:46:28,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:28,925 INFO:     Epoch: 49
2023-01-05 01:46:31,151 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40204091866811115, 'Total loss': 0.40204091866811115} | train loss {'Reaction outcome loss': 0.21341030654814636, 'Total loss': 0.21341030654814636}
2023-01-05 01:46:31,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:31,153 INFO:     Epoch: 50
2023-01-05 01:46:33,424 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4241666962703069, 'Total loss': 0.4241666962703069} | train loss {'Reaction outcome loss': 0.21522113365574405, 'Total loss': 0.21522113365574405}
2023-01-05 01:46:33,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:33,424 INFO:     Epoch: 51
2023-01-05 01:46:35,683 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3847255085594952, 'Total loss': 0.3847255085594952} | train loss {'Reaction outcome loss': 0.20799784867794832, 'Total loss': 0.20799784867794832}
2023-01-05 01:46:35,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:35,683 INFO:     Epoch: 52
2023-01-05 01:46:37,835 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38609527548154193, 'Total loss': 0.38609527548154193} | train loss {'Reaction outcome loss': 0.2112136952801729, 'Total loss': 0.2112136952801729}
2023-01-05 01:46:37,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:37,836 INFO:     Epoch: 53
2023-01-05 01:46:40,103 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39760624766349795, 'Total loss': 0.39760624766349795} | train loss {'Reaction outcome loss': 0.21281073413505827, 'Total loss': 0.21281073413505827}
2023-01-05 01:46:40,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:40,103 INFO:     Epoch: 54
2023-01-05 01:46:42,377 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41586254636446635, 'Total loss': 0.41586254636446635} | train loss {'Reaction outcome loss': 0.21124998458274774, 'Total loss': 0.21124998458274774}
2023-01-05 01:46:42,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:42,378 INFO:     Epoch: 55
2023-01-05 01:46:44,648 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41837846239407855, 'Total loss': 0.41837846239407855} | train loss {'Reaction outcome loss': 0.20665269718881682, 'Total loss': 0.20665269718881682}
2023-01-05 01:46:44,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:44,648 INFO:     Epoch: 56
2023-01-05 01:46:46,922 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3692676638563474, 'Total loss': 0.3692676638563474} | train loss {'Reaction outcome loss': 0.2079457679655457, 'Total loss': 0.2079457679655457}
2023-01-05 01:46:46,923 INFO:     Found new best model at epoch 56
2023-01-05 01:46:46,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:46,924 INFO:     Epoch: 57
2023-01-05 01:46:49,125 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41683330237865446, 'Total loss': 0.41683330237865446} | train loss {'Reaction outcome loss': 0.22992757806028036, 'Total loss': 0.22992757806028036}
2023-01-05 01:46:49,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:49,126 INFO:     Epoch: 58
2023-01-05 01:46:51,389 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4081045061349869, 'Total loss': 0.4081045061349869} | train loss {'Reaction outcome loss': 0.20707351840911029, 'Total loss': 0.20707351840911029}
2023-01-05 01:46:51,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:51,390 INFO:     Epoch: 59
2023-01-05 01:46:53,648 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41096471846103666, 'Total loss': 0.41096471846103666} | train loss {'Reaction outcome loss': 0.2064624316484222, 'Total loss': 0.2064624316484222}
2023-01-05 01:46:53,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:53,649 INFO:     Epoch: 60
2023-01-05 01:46:55,801 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43579830328623453, 'Total loss': 0.43579830328623453} | train loss {'Reaction outcome loss': 0.206226468114582, 'Total loss': 0.206226468114582}
2023-01-05 01:46:55,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:55,801 INFO:     Epoch: 61
2023-01-05 01:46:58,064 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42331496079762776, 'Total loss': 0.42331496079762776} | train loss {'Reaction outcome loss': 0.19943644630506163, 'Total loss': 0.19943644630506163}
2023-01-05 01:46:58,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:46:58,064 INFO:     Epoch: 62
2023-01-05 01:47:00,242 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4184808333714803, 'Total loss': 0.4184808333714803} | train loss {'Reaction outcome loss': 0.20137561701583606, 'Total loss': 0.20137561701583606}
2023-01-05 01:47:00,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:00,242 INFO:     Epoch: 63
2023-01-05 01:47:02,389 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.395080903172493, 'Total loss': 0.395080903172493} | train loss {'Reaction outcome loss': 0.19804443653834902, 'Total loss': 0.19804443653834902}
2023-01-05 01:47:02,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:02,389 INFO:     Epoch: 64
2023-01-05 01:47:04,664 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42713005443414054, 'Total loss': 0.42713005443414054} | train loss {'Reaction outcome loss': 0.193757452497991, 'Total loss': 0.193757452497991}
2023-01-05 01:47:04,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:04,664 INFO:     Epoch: 65
2023-01-05 01:47:06,937 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3936315751324097, 'Total loss': 0.3936315751324097} | train loss {'Reaction outcome loss': 0.1980675800175801, 'Total loss': 0.1980675800175801}
2023-01-05 01:47:06,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:06,938 INFO:     Epoch: 66
2023-01-05 01:47:09,172 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3885681827863057, 'Total loss': 0.3885681827863057} | train loss {'Reaction outcome loss': 0.19483772569978813, 'Total loss': 0.19483772569978813}
2023-01-05 01:47:09,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:09,173 INFO:     Epoch: 67
2023-01-05 01:47:11,362 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3999830424785614, 'Total loss': 0.3999830424785614} | train loss {'Reaction outcome loss': 0.19734092303712014, 'Total loss': 0.19734092303712014}
2023-01-05 01:47:11,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:11,362 INFO:     Epoch: 68
2023-01-05 01:47:13,614 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43301884035269417, 'Total loss': 0.43301884035269417} | train loss {'Reaction outcome loss': 0.1962198601273037, 'Total loss': 0.1962198601273037}
2023-01-05 01:47:13,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:13,615 INFO:     Epoch: 69
2023-01-05 01:47:15,843 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.416084619363149, 'Total loss': 0.416084619363149} | train loss {'Reaction outcome loss': 0.1946745085963588, 'Total loss': 0.1946745085963588}
2023-01-05 01:47:15,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:15,843 INFO:     Epoch: 70
2023-01-05 01:47:17,996 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41494595011075336, 'Total loss': 0.41494595011075336} | train loss {'Reaction outcome loss': 0.18948953838991947, 'Total loss': 0.18948953838991947}
2023-01-05 01:47:17,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:17,996 INFO:     Epoch: 71
2023-01-05 01:47:20,251 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3903591165939967, 'Total loss': 0.3903591165939967} | train loss {'Reaction outcome loss': 0.1955141456835628, 'Total loss': 0.1955141456835628}
2023-01-05 01:47:20,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:20,251 INFO:     Epoch: 72
2023-01-05 01:47:22,495 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4098638564348221, 'Total loss': 0.4098638564348221} | train loss {'Reaction outcome loss': 0.19044252071678097, 'Total loss': 0.19044252071678097}
2023-01-05 01:47:22,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:22,496 INFO:     Epoch: 73
2023-01-05 01:47:24,720 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43080690801143645, 'Total loss': 0.43080690801143645} | train loss {'Reaction outcome loss': 0.1834125111480176, 'Total loss': 0.1834125111480176}
2023-01-05 01:47:24,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:24,720 INFO:     Epoch: 74
2023-01-05 01:47:26,986 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40394380589326223, 'Total loss': 0.40394380589326223} | train loss {'Reaction outcome loss': 0.1841345777644112, 'Total loss': 0.1841345777644112}
2023-01-05 01:47:26,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:26,987 INFO:     Epoch: 75
2023-01-05 01:47:29,047 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3942489412923654, 'Total loss': 0.3942489412923654} | train loss {'Reaction outcome loss': 0.18648545960372692, 'Total loss': 0.18648545960372692}
2023-01-05 01:47:29,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:29,048 INFO:     Epoch: 76
2023-01-05 01:47:31,215 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4107388436794281, 'Total loss': 0.4107388436794281} | train loss {'Reaction outcome loss': 0.184982613748023, 'Total loss': 0.184982613748023}
2023-01-05 01:47:31,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:31,216 INFO:     Epoch: 77
2023-01-05 01:47:33,465 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4158972680568695, 'Total loss': 0.4158972680568695} | train loss {'Reaction outcome loss': 0.1868908582179321, 'Total loss': 0.1868908582179321}
2023-01-05 01:47:33,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:33,466 INFO:     Epoch: 78
2023-01-05 01:47:35,645 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39341256270805997, 'Total loss': 0.39341256270805997} | train loss {'Reaction outcome loss': 0.18407071922580864, 'Total loss': 0.18407071922580864}
2023-01-05 01:47:35,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:35,645 INFO:     Epoch: 79
2023-01-05 01:47:37,891 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42875125209490456, 'Total loss': 0.42875125209490456} | train loss {'Reaction outcome loss': 0.18530783194802242, 'Total loss': 0.18530783194802242}
2023-01-05 01:47:37,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:37,892 INFO:     Epoch: 80
2023-01-05 01:47:40,149 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38957135391732056, 'Total loss': 0.38957135391732056} | train loss {'Reaction outcome loss': 0.18421226347445685, 'Total loss': 0.18421226347445685}
2023-01-05 01:47:40,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:40,149 INFO:     Epoch: 81
2023-01-05 01:47:42,360 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4084940075874329, 'Total loss': 0.4084940075874329} | train loss {'Reaction outcome loss': 0.18246915077569598, 'Total loss': 0.18246915077569598}
2023-01-05 01:47:42,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:42,361 INFO:     Epoch: 82
2023-01-05 01:47:44,623 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42554831355810163, 'Total loss': 0.42554831355810163} | train loss {'Reaction outcome loss': 0.18382439560229905, 'Total loss': 0.18382439560229905}
2023-01-05 01:47:44,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:44,623 INFO:     Epoch: 83
2023-01-05 01:47:46,848 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43168946703275046, 'Total loss': 0.43168946703275046} | train loss {'Reaction outcome loss': 0.1828557891297522, 'Total loss': 0.1828557891297522}
2023-01-05 01:47:46,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:46,848 INFO:     Epoch: 84
2023-01-05 01:47:49,055 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4139477749665578, 'Total loss': 0.4139477749665578} | train loss {'Reaction outcome loss': 0.17407039361938403, 'Total loss': 0.17407039361938403}
2023-01-05 01:47:49,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:49,056 INFO:     Epoch: 85
2023-01-05 01:47:51,322 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42177640795707705, 'Total loss': 0.42177640795707705} | train loss {'Reaction outcome loss': 0.17651571974262048, 'Total loss': 0.17651571974262048}
2023-01-05 01:47:51,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:51,322 INFO:     Epoch: 86
2023-01-05 01:47:53,586 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41343716382980344, 'Total loss': 0.41343716382980344} | train loss {'Reaction outcome loss': 0.17712904654257253, 'Total loss': 0.17712904654257253}
2023-01-05 01:47:53,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:53,586 INFO:     Epoch: 87
2023-01-05 01:47:55,831 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4353876809279124, 'Total loss': 0.4353876809279124} | train loss {'Reaction outcome loss': 0.17638025980483255, 'Total loss': 0.17638025980483255}
2023-01-05 01:47:55,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:55,831 INFO:     Epoch: 88
2023-01-05 01:47:58,054 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42342312534650167, 'Total loss': 0.42342312534650167} | train loss {'Reaction outcome loss': 0.17782555674236483, 'Total loss': 0.17782555674236483}
2023-01-05 01:47:58,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:47:58,054 INFO:     Epoch: 89
2023-01-05 01:48:00,328 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4327808236082395, 'Total loss': 0.4327808236082395} | train loss {'Reaction outcome loss': 0.17711241294265442, 'Total loss': 0.17711241294265442}
2023-01-05 01:48:00,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:00,328 INFO:     Epoch: 90
2023-01-05 01:48:02,602 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.427630627155304, 'Total loss': 0.427630627155304} | train loss {'Reaction outcome loss': 0.17122152655183592, 'Total loss': 0.17122152655183592}
2023-01-05 01:48:02,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:02,604 INFO:     Epoch: 91
2023-01-05 01:48:04,842 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3839348524808884, 'Total loss': 0.3839348524808884} | train loss {'Reaction outcome loss': 0.17296088475774488, 'Total loss': 0.17296088475774488}
2023-01-05 01:48:04,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:04,843 INFO:     Epoch: 92
2023-01-05 01:48:07,110 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38295158222317693, 'Total loss': 0.38295158222317693} | train loss {'Reaction outcome loss': 0.172563330584442, 'Total loss': 0.172563330584442}
2023-01-05 01:48:07,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:07,110 INFO:     Epoch: 93
2023-01-05 01:48:09,352 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4065387894709905, 'Total loss': 0.4065387894709905} | train loss {'Reaction outcome loss': 0.17344429969755543, 'Total loss': 0.17344429969755543}
2023-01-05 01:48:09,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:09,352 INFO:     Epoch: 94
2023-01-05 01:48:11,633 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37691536446412405, 'Total loss': 0.37691536446412405} | train loss {'Reaction outcome loss': 0.17284739742671515, 'Total loss': 0.17284739742671515}
2023-01-05 01:48:11,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:11,633 INFO:     Epoch: 95
2023-01-05 01:48:13,852 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43099979162216184, 'Total loss': 0.43099979162216184} | train loss {'Reaction outcome loss': 0.17366434043340606, 'Total loss': 0.17366434043340606}
2023-01-05 01:48:13,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:13,852 INFO:     Epoch: 96
2023-01-05 01:48:16,105 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42600681682427727, 'Total loss': 0.42600681682427727} | train loss {'Reaction outcome loss': 0.16831591076556768, 'Total loss': 0.16831591076556768}
2023-01-05 01:48:16,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:16,105 INFO:     Epoch: 97
2023-01-05 01:48:18,398 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40941184560457866, 'Total loss': 0.40941184560457866} | train loss {'Reaction outcome loss': 0.1697458552002702, 'Total loss': 0.1697458552002702}
2023-01-05 01:48:18,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:18,399 INFO:     Epoch: 98
2023-01-05 01:48:20,653 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43808353543281553, 'Total loss': 0.43808353543281553} | train loss {'Reaction outcome loss': 0.17077346710230695, 'Total loss': 0.17077346710230695}
2023-01-05 01:48:20,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:20,653 INFO:     Epoch: 99
2023-01-05 01:48:22,899 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4128859996795654, 'Total loss': 0.4128859996795654} | train loss {'Reaction outcome loss': 0.16630805471230406, 'Total loss': 0.16630805471230406}
2023-01-05 01:48:22,900 INFO:     Best model found after epoch 57 of 100.
2023-01-05 01:48:22,901 INFO:   Done with stage: TRAINING
2023-01-05 01:48:22,901 INFO:   Starting stage: EVALUATION
2023-01-05 01:48:23,035 INFO:   Done with stage: EVALUATION
2023-01-05 01:48:23,035 INFO:   Leaving out SEQ value Fold_5
2023-01-05 01:48:23,048 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 01:48:23,048 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:48:23,703 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:48:23,704 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:48:23,773 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:48:23,774 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:48:23,774 INFO:     No hyperparam tuning for this model
2023-01-05 01:48:23,774 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:48:23,774 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:48:23,775 INFO:     None feature selector for col prot
2023-01-05 01:48:23,775 INFO:     None feature selector for col prot
2023-01-05 01:48:23,775 INFO:     None feature selector for col prot
2023-01-05 01:48:23,775 INFO:     None feature selector for col chem
2023-01-05 01:48:23,775 INFO:     None feature selector for col chem
2023-01-05 01:48:23,775 INFO:     None feature selector for col chem
2023-01-05 01:48:23,776 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:48:23,776 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:48:23,777 INFO:     Number of params in model 72931
2023-01-05 01:48:23,780 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:48:23,780 INFO:   Starting stage: TRAINING
2023-01-05 01:48:23,840 INFO:     Val loss before train {'Reaction outcome loss': 0.8250689029693603, 'Total loss': 0.8250689029693603}
2023-01-05 01:48:23,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:23,840 INFO:     Epoch: 0
2023-01-05 01:48:26,079 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7016004780928294, 'Total loss': 0.7016004780928294} | train loss {'Reaction outcome loss': 0.9672786361043634, 'Total loss': 0.9672786361043634}
2023-01-05 01:48:26,079 INFO:     Found new best model at epoch 0
2023-01-05 01:48:26,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:26,081 INFO:     Epoch: 1
2023-01-05 01:48:28,273 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48364005287488304, 'Total loss': 0.48364005287488304} | train loss {'Reaction outcome loss': 0.6501556586487629, 'Total loss': 0.6501556586487629}
2023-01-05 01:48:28,274 INFO:     Found new best model at epoch 1
2023-01-05 01:48:28,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:28,276 INFO:     Epoch: 2
2023-01-05 01:48:30,530 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4471826454003652, 'Total loss': 0.4471826454003652} | train loss {'Reaction outcome loss': 0.5498325605254741, 'Total loss': 0.5498325605254741}
2023-01-05 01:48:30,530 INFO:     Found new best model at epoch 2
2023-01-05 01:48:30,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:30,531 INFO:     Epoch: 3
2023-01-05 01:48:32,786 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42371203800042473, 'Total loss': 0.42371203800042473} | train loss {'Reaction outcome loss': 0.5029628611428643, 'Total loss': 0.5029628611428643}
2023-01-05 01:48:32,786 INFO:     Found new best model at epoch 3
2023-01-05 01:48:32,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:32,787 INFO:     Epoch: 4
2023-01-05 01:48:35,031 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4020519485076269, 'Total loss': 0.4020519485076269} | train loss {'Reaction outcome loss': 0.46930687758896755, 'Total loss': 0.46930687758896755}
2023-01-05 01:48:35,032 INFO:     Found new best model at epoch 4
2023-01-05 01:48:35,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:35,033 INFO:     Epoch: 5
2023-01-05 01:48:37,283 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3870768591761589, 'Total loss': 0.3870768591761589} | train loss {'Reaction outcome loss': 0.4519781140536608, 'Total loss': 0.4519781140536608}
2023-01-05 01:48:37,284 INFO:     Found new best model at epoch 5
2023-01-05 01:48:37,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:37,285 INFO:     Epoch: 6
2023-01-05 01:48:39,552 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3865877022345861, 'Total loss': 0.3865877022345861} | train loss {'Reaction outcome loss': 0.4374111518532791, 'Total loss': 0.4374111518532791}
2023-01-05 01:48:39,553 INFO:     Found new best model at epoch 6
2023-01-05 01:48:39,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:39,554 INFO:     Epoch: 7
2023-01-05 01:48:41,819 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3731255600849787, 'Total loss': 0.3731255600849787} | train loss {'Reaction outcome loss': 0.4186172135416351, 'Total loss': 0.4186172135416351}
2023-01-05 01:48:41,820 INFO:     Found new best model at epoch 7
2023-01-05 01:48:41,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:41,821 INFO:     Epoch: 8
2023-01-05 01:48:44,053 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3832002525528272, 'Total loss': 0.3832002525528272} | train loss {'Reaction outcome loss': 0.4166610067179057, 'Total loss': 0.4166610067179057}
2023-01-05 01:48:44,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:44,053 INFO:     Epoch: 9
2023-01-05 01:48:46,318 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38315582896272343, 'Total loss': 0.38315582896272343} | train loss {'Reaction outcome loss': 0.4083551172745357, 'Total loss': 0.4083551172745357}
2023-01-05 01:48:46,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:46,319 INFO:     Epoch: 10
2023-01-05 01:48:48,558 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3831706792116165, 'Total loss': 0.3831706792116165} | train loss {'Reaction outcome loss': 0.3937639212672891, 'Total loss': 0.3937639212672891}
2023-01-05 01:48:48,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:48,558 INFO:     Epoch: 11
2023-01-05 01:48:50,822 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38016151686509453, 'Total loss': 0.38016151686509453} | train loss {'Reaction outcome loss': 0.38450640305500167, 'Total loss': 0.38450640305500167}
2023-01-05 01:48:50,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:50,823 INFO:     Epoch: 12
2023-01-05 01:48:53,079 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3711520403623581, 'Total loss': 0.3711520403623581} | train loss {'Reaction outcome loss': 0.37640744907653717, 'Total loss': 0.37640744907653717}
2023-01-05 01:48:53,080 INFO:     Found new best model at epoch 12
2023-01-05 01:48:53,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:53,081 INFO:     Epoch: 13
2023-01-05 01:48:55,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37000417411327363, 'Total loss': 0.37000417411327363} | train loss {'Reaction outcome loss': 0.3724122437436658, 'Total loss': 0.3724122437436658}
2023-01-05 01:48:55,295 INFO:     Found new best model at epoch 13
2023-01-05 01:48:55,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:55,296 INFO:     Epoch: 14
2023-01-05 01:48:57,517 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37078393598397574, 'Total loss': 0.37078393598397574} | train loss {'Reaction outcome loss': 0.36170757387088953, 'Total loss': 0.36170757387088953}
2023-01-05 01:48:57,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:57,518 INFO:     Epoch: 15
2023-01-05 01:48:59,735 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38142442603905996, 'Total loss': 0.38142442603905996} | train loss {'Reaction outcome loss': 0.35107238671409524, 'Total loss': 0.35107238671409524}
2023-01-05 01:48:59,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:48:59,735 INFO:     Epoch: 16
2023-01-05 01:49:01,943 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37178920606772103, 'Total loss': 0.37178920606772103} | train loss {'Reaction outcome loss': 0.34872612634182837, 'Total loss': 0.34872612634182837}
2023-01-05 01:49:01,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:01,943 INFO:     Epoch: 17
2023-01-05 01:49:04,179 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36776441683371863, 'Total loss': 0.36776441683371863} | train loss {'Reaction outcome loss': 0.33702959445732167, 'Total loss': 0.33702959445732167}
2023-01-05 01:49:04,180 INFO:     Found new best model at epoch 17
2023-01-05 01:49:04,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:04,181 INFO:     Epoch: 18
2023-01-05 01:49:06,396 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40014330446720126, 'Total loss': 0.40014330446720126} | train loss {'Reaction outcome loss': 0.33153035127245134, 'Total loss': 0.33153035127245134}
2023-01-05 01:49:06,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:06,396 INFO:     Epoch: 19
2023-01-05 01:49:08,637 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36383714427550634, 'Total loss': 0.36383714427550634} | train loss {'Reaction outcome loss': 0.3253769482812081, 'Total loss': 0.3253769482812081}
2023-01-05 01:49:08,638 INFO:     Found new best model at epoch 19
2023-01-05 01:49:08,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:08,639 INFO:     Epoch: 20
2023-01-05 01:49:10,896 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3687058210372925, 'Total loss': 0.3687058210372925} | train loss {'Reaction outcome loss': 0.32165509091172406, 'Total loss': 0.32165509091172406}
2023-01-05 01:49:10,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:10,896 INFO:     Epoch: 21
2023-01-05 01:49:13,180 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38831855952739713, 'Total loss': 0.38831855952739713} | train loss {'Reaction outcome loss': 0.3156637701370656, 'Total loss': 0.3156637701370656}
2023-01-05 01:49:13,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:13,181 INFO:     Epoch: 22
2023-01-05 01:49:15,457 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3590566724538803, 'Total loss': 0.3590566724538803} | train loss {'Reaction outcome loss': 0.3147082313195893, 'Total loss': 0.3147082313195893}
2023-01-05 01:49:15,458 INFO:     Found new best model at epoch 22
2023-01-05 01:49:15,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:15,459 INFO:     Epoch: 23
2023-01-05 01:49:17,715 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38741525312264763, 'Total loss': 0.38741525312264763} | train loss {'Reaction outcome loss': 0.30671098530427, 'Total loss': 0.30671098530427}
2023-01-05 01:49:17,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:17,715 INFO:     Epoch: 24
2023-01-05 01:49:19,965 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3852085957924525, 'Total loss': 0.3852085957924525} | train loss {'Reaction outcome loss': 0.29960411163013334, 'Total loss': 0.29960411163013334}
2023-01-05 01:49:19,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:19,966 INFO:     Epoch: 25
2023-01-05 01:49:22,239 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35646055738131205, 'Total loss': 0.35646055738131205} | train loss {'Reaction outcome loss': 0.2947198018189587, 'Total loss': 0.2947198018189587}
2023-01-05 01:49:22,240 INFO:     Found new best model at epoch 25
2023-01-05 01:49:22,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:22,241 INFO:     Epoch: 26
2023-01-05 01:49:24,493 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3734854181607564, 'Total loss': 0.3734854181607564} | train loss {'Reaction outcome loss': 0.29003395456215536, 'Total loss': 0.29003395456215536}
2023-01-05 01:49:24,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:24,493 INFO:     Epoch: 27
2023-01-05 01:49:26,718 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38332612017790474, 'Total loss': 0.38332612017790474} | train loss {'Reaction outcome loss': 0.28361228927431986, 'Total loss': 0.28361228927431986}
2023-01-05 01:49:26,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:26,718 INFO:     Epoch: 28
2023-01-05 01:49:28,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38162961999575296, 'Total loss': 0.38162961999575296} | train loss {'Reaction outcome loss': 0.281598075148431, 'Total loss': 0.281598075148431}
2023-01-05 01:49:28,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:28,959 INFO:     Epoch: 29
2023-01-05 01:49:31,197 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39045118987560273, 'Total loss': 0.39045118987560273} | train loss {'Reaction outcome loss': 0.28395904449994813, 'Total loss': 0.28395904449994813}
2023-01-05 01:49:31,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:31,198 INFO:     Epoch: 30
2023-01-05 01:49:33,434 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3674979275713364, 'Total loss': 0.3674979275713364} | train loss {'Reaction outcome loss': 0.2749809364280546, 'Total loss': 0.2749809364280546}
2023-01-05 01:49:33,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:33,434 INFO:     Epoch: 31
2023-01-05 01:49:35,645 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38501621782779694, 'Total loss': 0.38501621782779694} | train loss {'Reaction outcome loss': 0.26978156854825547, 'Total loss': 0.26978156854825547}
2023-01-05 01:49:35,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:35,646 INFO:     Epoch: 32
2023-01-05 01:49:37,897 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38232030520836513, 'Total loss': 0.38232030520836513} | train loss {'Reaction outcome loss': 0.2673592618414426, 'Total loss': 0.2673592618414426}
2023-01-05 01:49:37,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:37,898 INFO:     Epoch: 33
2023-01-05 01:49:40,115 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3672150323788325, 'Total loss': 0.3672150323788325} | train loss {'Reaction outcome loss': 0.26017815181951875, 'Total loss': 0.26017815181951875}
2023-01-05 01:49:40,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:40,115 INFO:     Epoch: 34
2023-01-05 01:49:42,356 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3816196699937185, 'Total loss': 0.3816196699937185} | train loss {'Reaction outcome loss': 0.26128862679865383, 'Total loss': 0.26128862679865383}
2023-01-05 01:49:42,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:42,356 INFO:     Epoch: 35
2023-01-05 01:49:44,607 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36665993332862856, 'Total loss': 0.36665993332862856} | train loss {'Reaction outcome loss': 0.25531549668376624, 'Total loss': 0.25531549668376624}
2023-01-05 01:49:44,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:44,607 INFO:     Epoch: 36
2023-01-05 01:49:46,888 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3517472813526789, 'Total loss': 0.3517472813526789} | train loss {'Reaction outcome loss': 0.2522594423339255, 'Total loss': 0.2522594423339255}
2023-01-05 01:49:46,888 INFO:     Found new best model at epoch 36
2023-01-05 01:49:46,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:46,890 INFO:     Epoch: 37
2023-01-05 01:49:49,166 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3682892541090647, 'Total loss': 0.3682892541090647} | train loss {'Reaction outcome loss': 0.243980429212593, 'Total loss': 0.243980429212593}
2023-01-05 01:49:49,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:49,166 INFO:     Epoch: 38
2023-01-05 01:49:51,436 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3664642165104548, 'Total loss': 0.3664642165104548} | train loss {'Reaction outcome loss': 0.2371345829043793, 'Total loss': 0.2371345829043793}
2023-01-05 01:49:51,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:51,437 INFO:     Epoch: 39
2023-01-05 01:49:53,673 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38130887001752856, 'Total loss': 0.38130887001752856} | train loss {'Reaction outcome loss': 0.2419551576181762, 'Total loss': 0.2419551576181762}
2023-01-05 01:49:53,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:53,674 INFO:     Epoch: 40
2023-01-05 01:49:55,937 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.355873641371727, 'Total loss': 0.355873641371727} | train loss {'Reaction outcome loss': 0.23164898929075214, 'Total loss': 0.23164898929075214}
2023-01-05 01:49:55,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:55,937 INFO:     Epoch: 41
2023-01-05 01:49:58,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3687870581944784, 'Total loss': 0.3687870581944784} | train loss {'Reaction outcome loss': 0.22689943271100738, 'Total loss': 0.22689943271100738}
2023-01-05 01:49:58,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:49:58,212 INFO:     Epoch: 42
2023-01-05 01:50:00,494 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36520615220069885, 'Total loss': 0.36520615220069885} | train loss {'Reaction outcome loss': 0.22889160685617785, 'Total loss': 0.22889160685617785}
2023-01-05 01:50:00,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:00,495 INFO:     Epoch: 43
2023-01-05 01:50:02,763 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39298244615395866, 'Total loss': 0.39298244615395866} | train loss {'Reaction outcome loss': 0.22227502016464942, 'Total loss': 0.22227502016464942}
2023-01-05 01:50:02,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:02,763 INFO:     Epoch: 44
2023-01-05 01:50:05,022 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3650004262725512, 'Total loss': 0.3650004262725512} | train loss {'Reaction outcome loss': 0.22508506534876646, 'Total loss': 0.22508506534876646}
2023-01-05 01:50:05,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:05,022 INFO:     Epoch: 45
2023-01-05 01:50:07,250 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3585180292526881, 'Total loss': 0.3585180292526881} | train loss {'Reaction outcome loss': 0.2195307476183783, 'Total loss': 0.2195307476183783}
2023-01-05 01:50:07,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:07,250 INFO:     Epoch: 46
2023-01-05 01:50:09,429 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3851085369785627, 'Total loss': 0.3851085369785627} | train loss {'Reaction outcome loss': 0.21791697330503904, 'Total loss': 0.21791697330503904}
2023-01-05 01:50:09,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:09,429 INFO:     Epoch: 47
2023-01-05 01:50:11,650 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37647767812013627, 'Total loss': 0.37647767812013627} | train loss {'Reaction outcome loss': 0.2185271198151882, 'Total loss': 0.2185271198151882}
2023-01-05 01:50:11,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:11,651 INFO:     Epoch: 48
2023-01-05 01:50:13,903 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36141722251971564, 'Total loss': 0.36141722251971564} | train loss {'Reaction outcome loss': 0.21597165186697825, 'Total loss': 0.21597165186697825}
2023-01-05 01:50:13,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:13,903 INFO:     Epoch: 49
2023-01-05 01:50:16,131 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3828369547923406, 'Total loss': 0.3828369547923406} | train loss {'Reaction outcome loss': 0.21206325541388257, 'Total loss': 0.21206325541388257}
2023-01-05 01:50:16,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:16,131 INFO:     Epoch: 50
2023-01-05 01:50:18,409 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3706258197625478, 'Total loss': 0.3706258197625478} | train loss {'Reaction outcome loss': 0.2128174747054596, 'Total loss': 0.2128174747054596}
2023-01-05 01:50:18,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:18,409 INFO:     Epoch: 51
2023-01-05 01:50:20,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.363252425690492, 'Total loss': 0.363252425690492} | train loss {'Reaction outcome loss': 0.21273311514017385, 'Total loss': 0.21273311514017385}
2023-01-05 01:50:20,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:20,694 INFO:     Epoch: 52
2023-01-05 01:50:22,977 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3794200400511424, 'Total loss': 0.3794200400511424} | train loss {'Reaction outcome loss': 0.2071129656548104, 'Total loss': 0.2071129656548104}
2023-01-05 01:50:22,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:22,978 INFO:     Epoch: 53
2023-01-05 01:50:25,260 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3844312352438768, 'Total loss': 0.3844312352438768} | train loss {'Reaction outcome loss': 0.2071235606325824, 'Total loss': 0.2071235606325824}
2023-01-05 01:50:25,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:25,261 INFO:     Epoch: 54
2023-01-05 01:50:27,545 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36774049429222944, 'Total loss': 0.36774049429222944} | train loss {'Reaction outcome loss': 0.20458567699935246, 'Total loss': 0.20458567699935246}
2023-01-05 01:50:27,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:27,546 INFO:     Epoch: 55
2023-01-05 01:50:29,815 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37956045965353646, 'Total loss': 0.37956045965353646} | train loss {'Reaction outcome loss': 0.2010880611426725, 'Total loss': 0.2010880611426725}
2023-01-05 01:50:29,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:29,816 INFO:     Epoch: 56
2023-01-05 01:50:32,094 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37755984961986544, 'Total loss': 0.37755984961986544} | train loss {'Reaction outcome loss': 0.1976690756742059, 'Total loss': 0.1976690756742059}
2023-01-05 01:50:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:32,094 INFO:     Epoch: 57
2023-01-05 01:50:34,319 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39724670102198917, 'Total loss': 0.39724670102198917} | train loss {'Reaction outcome loss': 0.1999969642595909, 'Total loss': 0.1999969642595909}
2023-01-05 01:50:34,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:34,320 INFO:     Epoch: 58
2023-01-05 01:50:36,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41735278914372126, 'Total loss': 0.41735278914372126} | train loss {'Reaction outcome loss': 0.1993781069347413, 'Total loss': 0.1993781069347413}
2023-01-05 01:50:36,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:36,568 INFO:     Epoch: 59
2023-01-05 01:50:38,815 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40513391718268393, 'Total loss': 0.40513391718268393} | train loss {'Reaction outcome loss': 0.2010566159336414, 'Total loss': 0.2010566159336414}
2023-01-05 01:50:38,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:38,816 INFO:     Epoch: 60
2023-01-05 01:50:41,072 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3735749242206415, 'Total loss': 0.3735749242206415} | train loss {'Reaction outcome loss': 0.19806230811583758, 'Total loss': 0.19806230811583758}
2023-01-05 01:50:41,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:41,073 INFO:     Epoch: 61
2023-01-05 01:50:43,214 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39024271120627724, 'Total loss': 0.39024271120627724} | train loss {'Reaction outcome loss': 0.19720865271326543, 'Total loss': 0.19720865271326543}
2023-01-05 01:50:43,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:43,215 INFO:     Epoch: 62
2023-01-05 01:50:45,496 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4029848878582319, 'Total loss': 0.4029848878582319} | train loss {'Reaction outcome loss': 0.19523860321511322, 'Total loss': 0.19523860321511322}
2023-01-05 01:50:45,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:45,496 INFO:     Epoch: 63
2023-01-05 01:50:47,785 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37167042096455893, 'Total loss': 0.37167042096455893} | train loss {'Reaction outcome loss': 0.19829563180569706, 'Total loss': 0.19829563180569706}
2023-01-05 01:50:47,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:47,786 INFO:     Epoch: 64
2023-01-05 01:50:50,058 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3830985759695371, 'Total loss': 0.3830985759695371} | train loss {'Reaction outcome loss': 0.19074915000489687, 'Total loss': 0.19074915000489687}
2023-01-05 01:50:50,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:50,059 INFO:     Epoch: 65
2023-01-05 01:50:52,350 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3969712138175964, 'Total loss': 0.3969712138175964} | train loss {'Reaction outcome loss': 0.18817812138966653, 'Total loss': 0.18817812138966653}
2023-01-05 01:50:52,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:52,350 INFO:     Epoch: 66
2023-01-05 01:50:54,624 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3649267295996348, 'Total loss': 0.3649267295996348} | train loss {'Reaction outcome loss': 0.1898934720403478, 'Total loss': 0.1898934720403478}
2023-01-05 01:50:54,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:54,624 INFO:     Epoch: 67
2023-01-05 01:50:56,898 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4155272831519445, 'Total loss': 0.4155272831519445} | train loss {'Reaction outcome loss': 0.18663328197290482, 'Total loss': 0.18663328197290482}
2023-01-05 01:50:56,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:56,898 INFO:     Epoch: 68
2023-01-05 01:50:59,177 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4054808517297109, 'Total loss': 0.4054808517297109} | train loss {'Reaction outcome loss': 0.18752909623866476, 'Total loss': 0.18752909623866476}
2023-01-05 01:50:59,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:50:59,178 INFO:     Epoch: 69
2023-01-05 01:51:01,465 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3881308843071262, 'Total loss': 0.3881308843071262} | train loss {'Reaction outcome loss': 0.18768314138602882, 'Total loss': 0.18768314138602882}
2023-01-05 01:51:01,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:01,465 INFO:     Epoch: 70
2023-01-05 01:51:03,641 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41271276970704396, 'Total loss': 0.41271276970704396} | train loss {'Reaction outcome loss': 0.1871563031486091, 'Total loss': 0.1871563031486091}
2023-01-05 01:51:03,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:03,642 INFO:     Epoch: 71
2023-01-05 01:51:05,877 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4015666355689367, 'Total loss': 0.4015666355689367} | train loss {'Reaction outcome loss': 0.18585286533715548, 'Total loss': 0.18585286533715548}
2023-01-05 01:51:05,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:05,877 INFO:     Epoch: 72
2023-01-05 01:51:08,095 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41921462764342626, 'Total loss': 0.41921462764342626} | train loss {'Reaction outcome loss': 0.1849861840670424, 'Total loss': 0.1849861840670424}
2023-01-05 01:51:08,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:08,095 INFO:     Epoch: 73
2023-01-05 01:51:10,359 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37509910265604657, 'Total loss': 0.37509910265604657} | train loss {'Reaction outcome loss': 0.1822586266108745, 'Total loss': 0.1822586266108745}
2023-01-05 01:51:10,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:10,360 INFO:     Epoch: 74
2023-01-05 01:51:12,629 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41220812425017356, 'Total loss': 0.41220812425017356} | train loss {'Reaction outcome loss': 0.18675205423849692, 'Total loss': 0.18675205423849692}
2023-01-05 01:51:12,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:12,629 INFO:     Epoch: 75
2023-01-05 01:51:14,886 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3912976865967115, 'Total loss': 0.3912976865967115} | train loss {'Reaction outcome loss': 0.1823911803340815, 'Total loss': 0.1823911803340815}
2023-01-05 01:51:14,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:14,886 INFO:     Epoch: 76
2023-01-05 01:51:17,107 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4185407628615697, 'Total loss': 0.4185407628615697} | train loss {'Reaction outcome loss': 0.18928889524097478, 'Total loss': 0.18928889524097478}
2023-01-05 01:51:17,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:17,107 INFO:     Epoch: 77
2023-01-05 01:51:19,297 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3949250380198161, 'Total loss': 0.3949250380198161} | train loss {'Reaction outcome loss': 0.18221174413506414, 'Total loss': 0.18221174413506414}
2023-01-05 01:51:19,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:19,297 INFO:     Epoch: 78
2023-01-05 01:51:21,561 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4354092627763748, 'Total loss': 0.4354092627763748} | train loss {'Reaction outcome loss': 0.1861159281119274, 'Total loss': 0.1861159281119274}
2023-01-05 01:51:21,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:21,561 INFO:     Epoch: 79
2023-01-05 01:51:23,815 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39774910708268485, 'Total loss': 0.39774910708268485} | train loss {'Reaction outcome loss': 0.18067848903130376, 'Total loss': 0.18067848903130376}
2023-01-05 01:51:23,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:23,816 INFO:     Epoch: 80
2023-01-05 01:51:25,987 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4051525816321373, 'Total loss': 0.4051525816321373} | train loss {'Reaction outcome loss': 0.18426049786824936, 'Total loss': 0.18426049786824936}
2023-01-05 01:51:25,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:25,987 INFO:     Epoch: 81
2023-01-05 01:51:28,233 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38434231157104176, 'Total loss': 0.38434231157104176} | train loss {'Reaction outcome loss': 0.18726792807492432, 'Total loss': 0.18726792807492432}
2023-01-05 01:51:28,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:28,233 INFO:     Epoch: 82
2023-01-05 01:51:30,143 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4075910250345866, 'Total loss': 0.4075910250345866} | train loss {'Reaction outcome loss': 0.18032267606322946, 'Total loss': 0.18032267606322946}
2023-01-05 01:51:30,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:30,143 INFO:     Epoch: 83
2023-01-05 01:51:31,989 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45044791599114736, 'Total loss': 0.45044791599114736} | train loss {'Reaction outcome loss': 0.17773598297633608, 'Total loss': 0.17773598297633608}
2023-01-05 01:51:31,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:31,989 INFO:     Epoch: 84
2023-01-05 01:51:34,036 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4251155515511831, 'Total loss': 0.4251155515511831} | train loss {'Reaction outcome loss': 0.1834634046443479, 'Total loss': 0.1834634046443479}
2023-01-05 01:51:34,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:34,036 INFO:     Epoch: 85
2023-01-05 01:51:36,090 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40108977307875954, 'Total loss': 0.40108977307875954} | train loss {'Reaction outcome loss': 0.17461688764433675, 'Total loss': 0.17461688764433675}
2023-01-05 01:51:36,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:36,090 INFO:     Epoch: 86
2023-01-05 01:51:38,356 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41883432467778525, 'Total loss': 0.41883432467778525} | train loss {'Reaction outcome loss': 0.17712633869701505, 'Total loss': 0.17712633869701505}
2023-01-05 01:51:38,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:38,357 INFO:     Epoch: 87
2023-01-05 01:51:40,587 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41234369575977325, 'Total loss': 0.41234369575977325} | train loss {'Reaction outcome loss': 0.1723952040980681, 'Total loss': 0.1723952040980681}
2023-01-05 01:51:40,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:40,588 INFO:     Epoch: 88
2023-01-05 01:51:42,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3894810805718104, 'Total loss': 0.3894810805718104} | train loss {'Reaction outcome loss': 0.17643955013872753, 'Total loss': 0.17643955013872753}
2023-01-05 01:51:42,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:42,794 INFO:     Epoch: 89
2023-01-05 01:51:45,042 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37523823281129204, 'Total loss': 0.37523823281129204} | train loss {'Reaction outcome loss': 0.17982718458950572, 'Total loss': 0.17982718458950572}
2023-01-05 01:51:45,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:45,043 INFO:     Epoch: 90
2023-01-05 01:51:47,312 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4194297879934311, 'Total loss': 0.4194297879934311} | train loss {'Reaction outcome loss': 0.17416892507170673, 'Total loss': 0.17416892507170673}
2023-01-05 01:51:47,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:47,313 INFO:     Epoch: 91
2023-01-05 01:51:49,576 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41879099210103354, 'Total loss': 0.41879099210103354} | train loss {'Reaction outcome loss': 0.1713746016557641, 'Total loss': 0.1713746016557641}
2023-01-05 01:51:49,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:49,576 INFO:     Epoch: 92
2023-01-05 01:51:51,859 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.396583221356074, 'Total loss': 0.396583221356074} | train loss {'Reaction outcome loss': 0.1761696978139318, 'Total loss': 0.1761696978139318}
2023-01-05 01:51:51,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:51,859 INFO:     Epoch: 93
2023-01-05 01:51:54,152 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3998551666736603, 'Total loss': 0.3998551666736603} | train loss {'Reaction outcome loss': 0.16855207444269493, 'Total loss': 0.16855207444269493}
2023-01-05 01:51:54,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:54,152 INFO:     Epoch: 94
2023-01-05 01:51:56,421 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3896221632758776, 'Total loss': 0.3896221632758776} | train loss {'Reaction outcome loss': 0.17628546769895492, 'Total loss': 0.17628546769895492}
2023-01-05 01:51:56,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:56,421 INFO:     Epoch: 95
2023-01-05 01:51:58,708 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4122728710373243, 'Total loss': 0.4122728710373243} | train loss {'Reaction outcome loss': 0.17267771913175764, 'Total loss': 0.17267771913175764}
2023-01-05 01:51:58,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:51:58,709 INFO:     Epoch: 96
2023-01-05 01:52:00,967 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.400964414079984, 'Total loss': 0.400964414079984} | train loss {'Reaction outcome loss': 0.16753466447499255, 'Total loss': 0.16753466447499255}
2023-01-05 01:52:00,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:00,967 INFO:     Epoch: 97
2023-01-05 01:52:03,266 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4121171057224274, 'Total loss': 0.4121171057224274} | train loss {'Reaction outcome loss': 0.16693129499076398, 'Total loss': 0.16693129499076398}
2023-01-05 01:52:03,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:03,266 INFO:     Epoch: 98
2023-01-05 01:52:05,557 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4096198489268621, 'Total loss': 0.4096198489268621} | train loss {'Reaction outcome loss': 0.16785858127049805, 'Total loss': 0.16785858127049805}
2023-01-05 01:52:05,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:05,558 INFO:     Epoch: 99
2023-01-05 01:52:07,842 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40932720800240835, 'Total loss': 0.40932720800240835} | train loss {'Reaction outcome loss': 0.1694073968042455, 'Total loss': 0.1694073968042455}
2023-01-05 01:52:07,842 INFO:     Best model found after epoch 37 of 100.
2023-01-05 01:52:07,842 INFO:   Done with stage: TRAINING
2023-01-05 01:52:07,842 INFO:   Starting stage: EVALUATION
2023-01-05 01:52:07,969 INFO:   Done with stage: EVALUATION
2023-01-05 01:52:07,969 INFO:   Leaving out SEQ value Fold_6
2023-01-05 01:52:07,982 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 01:52:07,982 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:52:08,631 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:52:08,631 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:52:08,701 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:52:08,701 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:52:08,701 INFO:     No hyperparam tuning for this model
2023-01-05 01:52:08,701 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:52:08,701 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:52:08,702 INFO:     None feature selector for col prot
2023-01-05 01:52:08,702 INFO:     None feature selector for col prot
2023-01-05 01:52:08,702 INFO:     None feature selector for col prot
2023-01-05 01:52:08,703 INFO:     None feature selector for col chem
2023-01-05 01:52:08,703 INFO:     None feature selector for col chem
2023-01-05 01:52:08,703 INFO:     None feature selector for col chem
2023-01-05 01:52:08,703 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:52:08,703 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:52:08,704 INFO:     Number of params in model 72931
2023-01-05 01:52:08,708 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:52:08,708 INFO:   Starting stage: TRAINING
2023-01-05 01:52:08,768 INFO:     Val loss before train {'Reaction outcome loss': 0.948404061794281, 'Total loss': 0.948404061794281}
2023-01-05 01:52:08,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:08,769 INFO:     Epoch: 0
2023-01-05 01:52:10,993 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6995748519897461, 'Total loss': 0.6995748519897461} | train loss {'Reaction outcome loss': 0.9372221797052092, 'Total loss': 0.9372221797052092}
2023-01-05 01:52:10,994 INFO:     Found new best model at epoch 0
2023-01-05 01:52:10,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:10,995 INFO:     Epoch: 1
2023-01-05 01:52:13,247 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5092437585194906, 'Total loss': 0.5092437585194906} | train loss {'Reaction outcome loss': 0.6301372148042178, 'Total loss': 0.6301372148042178}
2023-01-05 01:52:13,247 INFO:     Found new best model at epoch 1
2023-01-05 01:52:13,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:13,249 INFO:     Epoch: 2
2023-01-05 01:52:15,501 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4597645858923594, 'Total loss': 0.4597645858923594} | train loss {'Reaction outcome loss': 0.5287195491420962, 'Total loss': 0.5287195491420962}
2023-01-05 01:52:15,502 INFO:     Found new best model at epoch 2
2023-01-05 01:52:15,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:15,504 INFO:     Epoch: 3
2023-01-05 01:52:17,904 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42495325207710266, 'Total loss': 0.42495325207710266} | train loss {'Reaction outcome loss': 0.4920236886526546, 'Total loss': 0.4920236886526546}
2023-01-05 01:52:17,904 INFO:     Found new best model at epoch 3
2023-01-05 01:52:17,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:17,907 INFO:     Epoch: 4
2023-01-05 01:52:20,222 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.415646422902743, 'Total loss': 0.415646422902743} | train loss {'Reaction outcome loss': 0.46880935638272847, 'Total loss': 0.46880935638272847}
2023-01-05 01:52:20,222 INFO:     Found new best model at epoch 4
2023-01-05 01:52:20,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:20,223 INFO:     Epoch: 5
2023-01-05 01:52:22,429 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40475471367438637, 'Total loss': 0.40475471367438637} | train loss {'Reaction outcome loss': 0.4439428295314747, 'Total loss': 0.4439428295314747}
2023-01-05 01:52:22,430 INFO:     Found new best model at epoch 5
2023-01-05 01:52:22,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:22,431 INFO:     Epoch: 6
2023-01-05 01:52:24,652 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3897630075613658, 'Total loss': 0.3897630075613658} | train loss {'Reaction outcome loss': 0.4255382090698194, 'Total loss': 0.4255382090698194}
2023-01-05 01:52:24,652 INFO:     Found new best model at epoch 6
2023-01-05 01:52:24,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:24,654 INFO:     Epoch: 7
2023-01-05 01:52:26,912 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3573891873160998, 'Total loss': 0.3573891873160998} | train loss {'Reaction outcome loss': 0.4147714467814369, 'Total loss': 0.4147714467814369}
2023-01-05 01:52:26,912 INFO:     Found new best model at epoch 7
2023-01-05 01:52:26,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:26,915 INFO:     Epoch: 8
2023-01-05 01:52:29,158 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3813542226950328, 'Total loss': 0.3813542226950328} | train loss {'Reaction outcome loss': 0.3983624956033526, 'Total loss': 0.3983624956033526}
2023-01-05 01:52:29,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:29,158 INFO:     Epoch: 9
2023-01-05 01:52:31,275 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3580705384413401, 'Total loss': 0.3580705384413401} | train loss {'Reaction outcome loss': 0.3881795064267451, 'Total loss': 0.3881795064267451}
2023-01-05 01:52:31,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:31,275 INFO:     Epoch: 10
2023-01-05 01:52:33,516 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3581432888905207, 'Total loss': 0.3581432888905207} | train loss {'Reaction outcome loss': 0.3762456637392514, 'Total loss': 0.3762456637392514}
2023-01-05 01:52:33,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:33,516 INFO:     Epoch: 11
2023-01-05 01:52:35,622 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.345110222697258, 'Total loss': 0.345110222697258} | train loss {'Reaction outcome loss': 0.3686422838346802, 'Total loss': 0.3686422838346802}
2023-01-05 01:52:35,623 INFO:     Found new best model at epoch 11
2023-01-05 01:52:35,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:35,624 INFO:     Epoch: 12
2023-01-05 01:52:37,797 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35150523980458576, 'Total loss': 0.35150523980458576} | train loss {'Reaction outcome loss': 0.35752514257592005, 'Total loss': 0.35752514257592005}
2023-01-05 01:52:37,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:37,798 INFO:     Epoch: 13
2023-01-05 01:52:39,984 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3543544267614683, 'Total loss': 0.3543544267614683} | train loss {'Reaction outcome loss': 0.34908273620327024, 'Total loss': 0.34908273620327024}
2023-01-05 01:52:39,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:39,984 INFO:     Epoch: 14
2023-01-05 01:52:42,221 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3365389481186867, 'Total loss': 0.3365389481186867} | train loss {'Reaction outcome loss': 0.34166981625187137, 'Total loss': 0.34166981625187137}
2023-01-05 01:52:42,221 INFO:     Found new best model at epoch 14
2023-01-05 01:52:42,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:42,222 INFO:     Epoch: 15
2023-01-05 01:52:44,393 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3345187137524287, 'Total loss': 0.3345187137524287} | train loss {'Reaction outcome loss': 0.3303599724967549, 'Total loss': 0.3303599724967549}
2023-01-05 01:52:44,393 INFO:     Found new best model at epoch 15
2023-01-05 01:52:44,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:44,394 INFO:     Epoch: 16
2023-01-05 01:52:46,616 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3426912844181061, 'Total loss': 0.3426912844181061} | train loss {'Reaction outcome loss': 0.3217022912712754, 'Total loss': 0.3217022912712754}
2023-01-05 01:52:46,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:46,617 INFO:     Epoch: 17
2023-01-05 01:52:48,838 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.33442560732364657, 'Total loss': 0.33442560732364657} | train loss {'Reaction outcome loss': 0.3147946747604513, 'Total loss': 0.3147946747604513}
2023-01-05 01:52:48,838 INFO:     Found new best model at epoch 17
2023-01-05 01:52:48,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:48,839 INFO:     Epoch: 18
2023-01-05 01:52:51,061 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3611567864815394, 'Total loss': 0.3611567864815394} | train loss {'Reaction outcome loss': 0.30761348195102095, 'Total loss': 0.30761348195102095}
2023-01-05 01:52:51,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:51,062 INFO:     Epoch: 19
2023-01-05 01:52:53,281 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3267121051748594, 'Total loss': 0.3267121051748594} | train loss {'Reaction outcome loss': 0.3070456138710036, 'Total loss': 0.3070456138710036}
2023-01-05 01:52:53,281 INFO:     Found new best model at epoch 19
2023-01-05 01:52:53,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:53,283 INFO:     Epoch: 20
2023-01-05 01:52:55,407 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3475433866182963, 'Total loss': 0.3475433866182963} | train loss {'Reaction outcome loss': 0.2957826802493447, 'Total loss': 0.2957826802493447}
2023-01-05 01:52:55,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:55,407 INFO:     Epoch: 21
2023-01-05 01:52:57,596 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.34808848748604454, 'Total loss': 0.34808848748604454} | train loss {'Reaction outcome loss': 0.29488791521285135, 'Total loss': 0.29488791521285135}
2023-01-05 01:52:57,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:57,597 INFO:     Epoch: 22
2023-01-05 01:52:59,843 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35216000080108645, 'Total loss': 0.35216000080108645} | train loss {'Reaction outcome loss': 0.28914319356753876, 'Total loss': 0.28914319356753876}
2023-01-05 01:52:59,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:52:59,844 INFO:     Epoch: 23
2023-01-05 01:53:02,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.32999686946471535, 'Total loss': 0.32999686946471535} | train loss {'Reaction outcome loss': 0.28526430804092084, 'Total loss': 0.28526430804092084}
2023-01-05 01:53:02,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:02,016 INFO:     Epoch: 24
2023-01-05 01:53:04,259 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3366183231274287, 'Total loss': 0.3366183231274287} | train loss {'Reaction outcome loss': 0.27794687138584845, 'Total loss': 0.27794687138584845}
2023-01-05 01:53:04,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:04,259 INFO:     Epoch: 25
2023-01-05 01:53:06,491 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3208343952894211, 'Total loss': 0.3208343952894211} | train loss {'Reaction outcome loss': 0.2742353739067368, 'Total loss': 0.2742353739067368}
2023-01-05 01:53:06,491 INFO:     Found new best model at epoch 25
2023-01-05 01:53:06,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:06,492 INFO:     Epoch: 26
2023-01-05 01:53:08,694 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3543360511461894, 'Total loss': 0.3543360511461894} | train loss {'Reaction outcome loss': 0.2719815222913549, 'Total loss': 0.2719815222913549}
2023-01-05 01:53:08,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:08,695 INFO:     Epoch: 27
2023-01-05 01:53:10,825 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34476053168376286, 'Total loss': 0.34476053168376286} | train loss {'Reaction outcome loss': 0.26392286168207435, 'Total loss': 0.26392286168207435}
2023-01-05 01:53:10,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:10,826 INFO:     Epoch: 28
2023-01-05 01:53:12,988 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3293189167976379, 'Total loss': 0.3293189167976379} | train loss {'Reaction outcome loss': 0.26539184897798146, 'Total loss': 0.26539184897798146}
2023-01-05 01:53:12,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:12,988 INFO:     Epoch: 29
2023-01-05 01:53:15,231 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3246540514131387, 'Total loss': 0.3246540514131387} | train loss {'Reaction outcome loss': 0.2591387210549773, 'Total loss': 0.2591387210549773}
2023-01-05 01:53:15,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:15,231 INFO:     Epoch: 30
2023-01-05 01:53:17,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3696799397468567, 'Total loss': 0.3696799397468567} | train loss {'Reaction outcome loss': 0.25493937318152105, 'Total loss': 0.25493937318152105}
2023-01-05 01:53:17,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:17,364 INFO:     Epoch: 31
2023-01-05 01:53:19,585 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.333241161207358, 'Total loss': 0.333241161207358} | train loss {'Reaction outcome loss': 0.2550391851903966, 'Total loss': 0.2550391851903966}
2023-01-05 01:53:19,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:19,585 INFO:     Epoch: 32
2023-01-05 01:53:21,813 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.342594701051712, 'Total loss': 0.342594701051712} | train loss {'Reaction outcome loss': 0.24698503429654742, 'Total loss': 0.24698503429654742}
2023-01-05 01:53:21,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:21,813 INFO:     Epoch: 33
2023-01-05 01:53:24,016 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3324437042077382, 'Total loss': 0.3324437042077382} | train loss {'Reaction outcome loss': 0.24427064716897523, 'Total loss': 0.24427064716897523}
2023-01-05 01:53:24,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:24,017 INFO:     Epoch: 34
2023-01-05 01:53:26,214 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.34745001743237175, 'Total loss': 0.34745001743237175} | train loss {'Reaction outcome loss': 0.23867294606310827, 'Total loss': 0.23867294606310827}
2023-01-05 01:53:26,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:26,216 INFO:     Epoch: 35
2023-01-05 01:53:28,420 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3507685666282972, 'Total loss': 0.3507685666282972} | train loss {'Reaction outcome loss': 0.23419118510817524, 'Total loss': 0.23419118510817524}
2023-01-05 01:53:28,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:28,420 INFO:     Epoch: 36
2023-01-05 01:53:30,594 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3454148938258489, 'Total loss': 0.3454148938258489} | train loss {'Reaction outcome loss': 0.23578814527930786, 'Total loss': 0.23578814527930786}
2023-01-05 01:53:30,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:30,595 INFO:     Epoch: 37
2023-01-05 01:53:32,761 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36406340698401135, 'Total loss': 0.36406340698401135} | train loss {'Reaction outcome loss': 0.2323217119368976, 'Total loss': 0.2323217119368976}
2023-01-05 01:53:32,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:32,762 INFO:     Epoch: 38
2023-01-05 01:53:34,966 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.33502954666813217, 'Total loss': 0.33502954666813217} | train loss {'Reaction outcome loss': 0.2311170904210558, 'Total loss': 0.2311170904210558}
2023-01-05 01:53:34,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:34,966 INFO:     Epoch: 39
2023-01-05 01:53:37,201 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3443911145130793, 'Total loss': 0.3443911145130793} | train loss {'Reaction outcome loss': 0.22958307422316857, 'Total loss': 0.22958307422316857}
2023-01-05 01:53:37,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:37,201 INFO:     Epoch: 40
2023-01-05 01:53:39,401 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33605413138866425, 'Total loss': 0.33605413138866425} | train loss {'Reaction outcome loss': 0.22728512158794126, 'Total loss': 0.22728512158794126}
2023-01-05 01:53:39,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:39,401 INFO:     Epoch: 41
2023-01-05 01:53:41,636 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33915156275033953, 'Total loss': 0.33915156275033953} | train loss {'Reaction outcome loss': 0.21770830059859114, 'Total loss': 0.21770830059859114}
2023-01-05 01:53:41,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:41,637 INFO:     Epoch: 42
2023-01-05 01:53:43,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3299581915140152, 'Total loss': 0.3299581915140152} | train loss {'Reaction outcome loss': 0.22023331219615944, 'Total loss': 0.22023331219615944}
2023-01-05 01:53:43,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:43,769 INFO:     Epoch: 43
2023-01-05 01:53:45,974 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36555397311846416, 'Total loss': 0.36555397311846416} | train loss {'Reaction outcome loss': 0.2156619359433216, 'Total loss': 0.2156619359433216}
2023-01-05 01:53:45,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:45,975 INFO:     Epoch: 44
2023-01-05 01:53:48,216 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35448153018951417, 'Total loss': 0.35448153018951417} | train loss {'Reaction outcome loss': 0.21450589704633194, 'Total loss': 0.21450589704633194}
2023-01-05 01:53:48,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:48,216 INFO:     Epoch: 45
2023-01-05 01:53:50,371 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37613605956236523, 'Total loss': 0.37613605956236523} | train loss {'Reaction outcome loss': 0.21063769240625693, 'Total loss': 0.21063769240625693}
2023-01-05 01:53:50,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:50,371 INFO:     Epoch: 46
2023-01-05 01:53:52,560 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35478145877520245, 'Total loss': 0.35478145877520245} | train loss {'Reaction outcome loss': 0.21054450900932897, 'Total loss': 0.21054450900932897}
2023-01-05 01:53:52,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:52,560 INFO:     Epoch: 47
2023-01-05 01:53:54,770 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3494266927242279, 'Total loss': 0.3494266927242279} | train loss {'Reaction outcome loss': 0.20894693951020493, 'Total loss': 0.20894693951020493}
2023-01-05 01:53:54,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:54,770 INFO:     Epoch: 48
2023-01-05 01:53:56,974 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.357269815603892, 'Total loss': 0.357269815603892} | train loss {'Reaction outcome loss': 0.20647020069678335, 'Total loss': 0.20647020069678335}
2023-01-05 01:53:56,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:56,975 INFO:     Epoch: 49
2023-01-05 01:53:59,199 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35502838691075644, 'Total loss': 0.35502838691075644} | train loss {'Reaction outcome loss': 0.20581481178175576, 'Total loss': 0.20581481178175576}
2023-01-05 01:53:59,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:53:59,199 INFO:     Epoch: 50
2023-01-05 01:54:01,418 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3575775315364202, 'Total loss': 0.3575775315364202} | train loss {'Reaction outcome loss': 0.20628253030624702, 'Total loss': 0.20628253030624702}
2023-01-05 01:54:01,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:01,418 INFO:     Epoch: 51
2023-01-05 01:54:03,571 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3913236290216446, 'Total loss': 0.3913236290216446} | train loss {'Reaction outcome loss': 0.19921110304629933, 'Total loss': 0.19921110304629933}
2023-01-05 01:54:03,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:03,572 INFO:     Epoch: 52
2023-01-05 01:54:05,793 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3763666942715645, 'Total loss': 0.3763666942715645} | train loss {'Reaction outcome loss': 0.19874067921327412, 'Total loss': 0.19874067921327412}
2023-01-05 01:54:05,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:05,794 INFO:     Epoch: 53
2023-01-05 01:54:07,952 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3551105906565984, 'Total loss': 0.3551105906565984} | train loss {'Reaction outcome loss': 0.19427840424919107, 'Total loss': 0.19427840424919107}
2023-01-05 01:54:07,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:07,952 INFO:     Epoch: 54
2023-01-05 01:54:10,176 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3601587985952695, 'Total loss': 0.3601587985952695} | train loss {'Reaction outcome loss': 0.19669194796877185, 'Total loss': 0.19669194796877185}
2023-01-05 01:54:10,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:10,177 INFO:     Epoch: 55
2023-01-05 01:54:12,378 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36890303442875544, 'Total loss': 0.36890303442875544} | train loss {'Reaction outcome loss': 0.18983964096367303, 'Total loss': 0.18983964096367303}
2023-01-05 01:54:12,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:12,378 INFO:     Epoch: 56
2023-01-05 01:54:14,557 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3726611979305744, 'Total loss': 0.3726611979305744} | train loss {'Reaction outcome loss': 0.19510024983306706, 'Total loss': 0.19510024983306706}
2023-01-05 01:54:14,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:14,557 INFO:     Epoch: 57
2023-01-05 01:54:16,793 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3652533168904483, 'Total loss': 0.3652533168904483} | train loss {'Reaction outcome loss': 0.19417432278911345, 'Total loss': 0.19417432278911345}
2023-01-05 01:54:16,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:16,793 INFO:     Epoch: 58
2023-01-05 01:54:18,975 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35034198400874933, 'Total loss': 0.35034198400874933} | train loss {'Reaction outcome loss': 0.18635701400017107, 'Total loss': 0.18635701400017107}
2023-01-05 01:54:18,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:18,975 INFO:     Epoch: 59
2023-01-05 01:54:21,202 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36950015015900134, 'Total loss': 0.36950015015900134} | train loss {'Reaction outcome loss': 0.18781443789642113, 'Total loss': 0.18781443789642113}
2023-01-05 01:54:21,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:21,203 INFO:     Epoch: 60
2023-01-05 01:54:23,406 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37455463310082754, 'Total loss': 0.37455463310082754} | train loss {'Reaction outcome loss': 0.18840991209403876, 'Total loss': 0.18840991209403876}
2023-01-05 01:54:23,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:23,407 INFO:     Epoch: 61
2023-01-05 01:54:25,637 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3791460702816645, 'Total loss': 0.3791460702816645} | train loss {'Reaction outcome loss': 0.18656055540199915, 'Total loss': 0.18656055540199915}
2023-01-05 01:54:25,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:25,637 INFO:     Epoch: 62
2023-01-05 01:54:27,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3466508562366168, 'Total loss': 0.3466508562366168} | train loss {'Reaction outcome loss': 0.18331466629985638, 'Total loss': 0.18331466629985638}
2023-01-05 01:54:27,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:27,857 INFO:     Epoch: 63
2023-01-05 01:54:30,011 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3702945079654455, 'Total loss': 0.3702945079654455} | train loss {'Reaction outcome loss': 0.17916329543915216, 'Total loss': 0.17916329543915216}
2023-01-05 01:54:30,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:30,011 INFO:     Epoch: 64
2023-01-05 01:54:32,244 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40016961420575775, 'Total loss': 0.40016961420575775} | train loss {'Reaction outcome loss': 0.17762147212217488, 'Total loss': 0.17762147212217488}
2023-01-05 01:54:32,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:32,244 INFO:     Epoch: 65
2023-01-05 01:54:34,469 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.406092461446921, 'Total loss': 0.406092461446921} | train loss {'Reaction outcome loss': 0.18254957347768394, 'Total loss': 0.18254957347768394}
2023-01-05 01:54:34,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:34,470 INFO:     Epoch: 66
2023-01-05 01:54:36,701 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3988930304845174, 'Total loss': 0.3988930304845174} | train loss {'Reaction outcome loss': 0.1794960673721711, 'Total loss': 0.1794960673721711}
2023-01-05 01:54:36,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:36,701 INFO:     Epoch: 67
2023-01-05 01:54:38,934 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39415209740400314, 'Total loss': 0.39415209740400314} | train loss {'Reaction outcome loss': 0.17893431279604344, 'Total loss': 0.17893431279604344}
2023-01-05 01:54:38,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:38,935 INFO:     Epoch: 68
2023-01-05 01:54:41,130 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3750105818112691, 'Total loss': 0.3750105818112691} | train loss {'Reaction outcome loss': 0.1764741548146699, 'Total loss': 0.1764741548146699}
2023-01-05 01:54:41,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:41,131 INFO:     Epoch: 69
2023-01-05 01:54:43,298 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35517043073972066, 'Total loss': 0.35517043073972066} | train loss {'Reaction outcome loss': 0.17845323412121702, 'Total loss': 0.17845323412121702}
2023-01-05 01:54:43,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:43,299 INFO:     Epoch: 70
2023-01-05 01:54:45,523 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37081462691227596, 'Total loss': 0.37081462691227596} | train loss {'Reaction outcome loss': 0.17540544831962154, 'Total loss': 0.17540544831962154}
2023-01-05 01:54:45,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:45,523 INFO:     Epoch: 71
2023-01-05 01:54:47,760 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37738569180170695, 'Total loss': 0.37738569180170695} | train loss {'Reaction outcome loss': 0.17154098537335866, 'Total loss': 0.17154098537335866}
2023-01-05 01:54:47,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:47,760 INFO:     Epoch: 72
2023-01-05 01:54:49,995 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3896487434705099, 'Total loss': 0.3896487434705099} | train loss {'Reaction outcome loss': 0.17207119025861042, 'Total loss': 0.17207119025861042}
2023-01-05 01:54:49,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:49,995 INFO:     Epoch: 73
2023-01-05 01:54:52,217 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3903507046867162, 'Total loss': 0.3903507046867162} | train loss {'Reaction outcome loss': 0.17197140546202877, 'Total loss': 0.17197140546202877}
2023-01-05 01:54:52,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:52,217 INFO:     Epoch: 74
2023-01-05 01:54:54,417 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3967964082956314, 'Total loss': 0.3967964082956314} | train loss {'Reaction outcome loss': 0.17274658805622725, 'Total loss': 0.17274658805622725}
2023-01-05 01:54:54,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:54,418 INFO:     Epoch: 75
2023-01-05 01:54:56,626 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4270720114310583, 'Total loss': 0.4270720114310583} | train loss {'Reaction outcome loss': 0.16946820305306873, 'Total loss': 0.16946820305306873}
2023-01-05 01:54:56,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:56,626 INFO:     Epoch: 76
2023-01-05 01:54:58,834 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38471488654613495, 'Total loss': 0.38471488654613495} | train loss {'Reaction outcome loss': 0.16673222489410292, 'Total loss': 0.16673222489410292}
2023-01-05 01:54:58,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:54:58,834 INFO:     Epoch: 77
2023-01-05 01:55:01,060 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3898565669854482, 'Total loss': 0.3898565669854482} | train loss {'Reaction outcome loss': 0.16572703331042707, 'Total loss': 0.16572703331042707}
2023-01-05 01:55:01,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:01,060 INFO:     Epoch: 78
2023-01-05 01:55:03,233 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3892527202765147, 'Total loss': 0.3892527202765147} | train loss {'Reaction outcome loss': 0.16593141492964347, 'Total loss': 0.16593141492964347}
2023-01-05 01:55:03,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:03,233 INFO:     Epoch: 79
2023-01-05 01:55:05,400 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3892183855175972, 'Total loss': 0.3892183855175972} | train loss {'Reaction outcome loss': 0.1638121702164466, 'Total loss': 0.1638121702164466}
2023-01-05 01:55:05,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:05,400 INFO:     Epoch: 80
2023-01-05 01:55:07,602 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3689388185739517, 'Total loss': 0.3689388185739517} | train loss {'Reaction outcome loss': 0.16813882522414147, 'Total loss': 0.16813882522414147}
2023-01-05 01:55:07,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:07,603 INFO:     Epoch: 81
2023-01-05 01:55:09,832 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40281685392061867, 'Total loss': 0.40281685392061867} | train loss {'Reaction outcome loss': 0.16977277153552287, 'Total loss': 0.16977277153552287}
2023-01-05 01:55:09,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:09,833 INFO:     Epoch: 82
2023-01-05 01:55:12,065 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36003180854022504, 'Total loss': 0.36003180854022504} | train loss {'Reaction outcome loss': 0.16827974249574826, 'Total loss': 0.16827974249574826}
2023-01-05 01:55:12,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:12,065 INFO:     Epoch: 83
2023-01-05 01:55:14,269 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3830049569408099, 'Total loss': 0.3830049569408099} | train loss {'Reaction outcome loss': 0.16831274435304813, 'Total loss': 0.16831274435304813}
2023-01-05 01:55:14,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:14,269 INFO:     Epoch: 84
2023-01-05 01:55:16,453 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3996955533822378, 'Total loss': 0.3996955533822378} | train loss {'Reaction outcome loss': 0.16292406508637877, 'Total loss': 0.16292406508637877}
2023-01-05 01:55:16,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:16,454 INFO:     Epoch: 85
2023-01-05 01:55:18,711 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39275814096132916, 'Total loss': 0.39275814096132916} | train loss {'Reaction outcome loss': 0.1585082984172542, 'Total loss': 0.1585082984172542}
2023-01-05 01:55:18,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:18,712 INFO:     Epoch: 86
2023-01-05 01:55:20,903 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38249003489812217, 'Total loss': 0.38249003489812217} | train loss {'Reaction outcome loss': 0.16759852167681186, 'Total loss': 0.16759852167681186}
2023-01-05 01:55:20,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:20,903 INFO:     Epoch: 87
2023-01-05 01:55:23,114 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3876720810929934, 'Total loss': 0.3876720810929934} | train loss {'Reaction outcome loss': 0.1625954692377743, 'Total loss': 0.1625954692377743}
2023-01-05 01:55:23,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:23,114 INFO:     Epoch: 88
2023-01-05 01:55:25,336 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37065756469964983, 'Total loss': 0.37065756469964983} | train loss {'Reaction outcome loss': 0.1606532113225519, 'Total loss': 0.1606532113225519}
2023-01-05 01:55:25,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:25,336 INFO:     Epoch: 89
2023-01-05 01:55:27,562 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4009962424635887, 'Total loss': 0.4009962424635887} | train loss {'Reaction outcome loss': 0.16602703568824723, 'Total loss': 0.16602703568824723}
2023-01-05 01:55:27,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:27,563 INFO:     Epoch: 90
2023-01-05 01:55:29,774 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41828930576642354, 'Total loss': 0.41828930576642354} | train loss {'Reaction outcome loss': 0.161919950565364, 'Total loss': 0.161919950565364}
2023-01-05 01:55:29,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:29,775 INFO:     Epoch: 91
2023-01-05 01:55:31,993 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39015985329945885, 'Total loss': 0.39015985329945885} | train loss {'Reaction outcome loss': 0.15544565142315886, 'Total loss': 0.15544565142315886}
2023-01-05 01:55:31,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:31,993 INFO:     Epoch: 92
2023-01-05 01:55:34,193 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39096342275540036, 'Total loss': 0.39096342275540036} | train loss {'Reaction outcome loss': 0.15831502903436384, 'Total loss': 0.15831502903436384}
2023-01-05 01:55:34,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:34,194 INFO:     Epoch: 93
2023-01-05 01:55:36,422 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37341639200846355, 'Total loss': 0.37341639200846355} | train loss {'Reaction outcome loss': 0.15763832754829396, 'Total loss': 0.15763832754829396}
2023-01-05 01:55:36,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:36,422 INFO:     Epoch: 94
2023-01-05 01:55:38,662 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37491861879825594, 'Total loss': 0.37491861879825594} | train loss {'Reaction outcome loss': 0.1605148909606692, 'Total loss': 0.1605148909606692}
2023-01-05 01:55:38,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:38,662 INFO:     Epoch: 95
2023-01-05 01:55:40,652 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4012729783852895, 'Total loss': 0.4012729783852895} | train loss {'Reaction outcome loss': 0.15689712375687964, 'Total loss': 0.15689712375687964}
2023-01-05 01:55:40,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:40,653 INFO:     Epoch: 96
2023-01-05 01:55:42,870 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.414307227730751, 'Total loss': 0.414307227730751} | train loss {'Reaction outcome loss': 0.15666274672686836, 'Total loss': 0.15666274672686836}
2023-01-05 01:55:42,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:42,870 INFO:     Epoch: 97
2023-01-05 01:55:45,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4024017537633578, 'Total loss': 0.4024017537633578} | train loss {'Reaction outcome loss': 0.15180055787243005, 'Total loss': 0.15180055787243005}
2023-01-05 01:55:45,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:45,087 INFO:     Epoch: 98
2023-01-05 01:55:47,260 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43872064277529715, 'Total loss': 0.43872064277529715} | train loss {'Reaction outcome loss': 0.1568809769270996, 'Total loss': 0.1568809769270996}
2023-01-05 01:55:47,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:47,261 INFO:     Epoch: 99
2023-01-05 01:55:49,472 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40558440120269856, 'Total loss': 0.40558440120269856} | train loss {'Reaction outcome loss': 0.15652754189732082, 'Total loss': 0.15652754189732082}
2023-01-05 01:55:49,472 INFO:     Best model found after epoch 26 of 100.
2023-01-05 01:55:49,472 INFO:   Done with stage: TRAINING
2023-01-05 01:55:49,472 INFO:   Starting stage: EVALUATION
2023-01-05 01:55:49,611 INFO:   Done with stage: EVALUATION
2023-01-05 01:55:49,611 INFO:   Leaving out SEQ value Fold_7
2023-01-05 01:55:49,624 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 01:55:49,624 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:55:50,261 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:55:50,261 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:55:50,330 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:55:50,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:55:50,330 INFO:     No hyperparam tuning for this model
2023-01-05 01:55:50,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:55:50,330 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:55:50,331 INFO:     None feature selector for col prot
2023-01-05 01:55:50,331 INFO:     None feature selector for col prot
2023-01-05 01:55:50,331 INFO:     None feature selector for col prot
2023-01-05 01:55:50,332 INFO:     None feature selector for col chem
2023-01-05 01:55:50,332 INFO:     None feature selector for col chem
2023-01-05 01:55:50,332 INFO:     None feature selector for col chem
2023-01-05 01:55:50,332 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:55:50,332 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:55:50,334 INFO:     Number of params in model 72931
2023-01-05 01:55:50,337 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:55:50,337 INFO:   Starting stage: TRAINING
2023-01-05 01:55:50,397 INFO:     Val loss before train {'Reaction outcome loss': 1.090540870030721, 'Total loss': 1.090540870030721}
2023-01-05 01:55:50,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:50,397 INFO:     Epoch: 0
2023-01-05 01:55:52,541 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8564798394838969, 'Total loss': 0.8564798394838969} | train loss {'Reaction outcome loss': 0.9584458429012855, 'Total loss': 0.9584458429012855}
2023-01-05 01:55:52,541 INFO:     Found new best model at epoch 0
2023-01-05 01:55:52,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:52,542 INFO:     Epoch: 1
2023-01-05 01:55:54,779 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5733623464902242, 'Total loss': 0.5733623464902242} | train loss {'Reaction outcome loss': 0.6648508154780325, 'Total loss': 0.6648508154780325}
2023-01-05 01:55:54,779 INFO:     Found new best model at epoch 1
2023-01-05 01:55:54,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:54,781 INFO:     Epoch: 2
2023-01-05 01:55:57,005 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.521860541899999, 'Total loss': 0.521860541899999} | train loss {'Reaction outcome loss': 0.5465153035347479, 'Total loss': 0.5465153035347479}
2023-01-05 01:55:57,005 INFO:     Found new best model at epoch 2
2023-01-05 01:55:57,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:57,006 INFO:     Epoch: 3
2023-01-05 01:55:59,237 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4927697797616323, 'Total loss': 0.4927697797616323} | train loss {'Reaction outcome loss': 0.5070797347456869, 'Total loss': 0.5070797347456869}
2023-01-05 01:55:59,237 INFO:     Found new best model at epoch 3
2023-01-05 01:55:59,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:55:59,238 INFO:     Epoch: 4
2023-01-05 01:56:01,462 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47516987919807435, 'Total loss': 0.47516987919807435} | train loss {'Reaction outcome loss': 0.47856417972676074, 'Total loss': 0.47856417972676074}
2023-01-05 01:56:01,463 INFO:     Found new best model at epoch 4
2023-01-05 01:56:01,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:01,464 INFO:     Epoch: 5
2023-01-05 01:56:03,664 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4861684759457906, 'Total loss': 0.4861684759457906} | train loss {'Reaction outcome loss': 0.4611324897974077, 'Total loss': 0.4611324897974077}
2023-01-05 01:56:03,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:03,664 INFO:     Epoch: 6
2023-01-05 01:56:05,891 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4727246820926666, 'Total loss': 0.4727246820926666} | train loss {'Reaction outcome loss': 0.4483837100276112, 'Total loss': 0.4483837100276112}
2023-01-05 01:56:05,891 INFO:     Found new best model at epoch 6
2023-01-05 01:56:05,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:05,892 INFO:     Epoch: 7
2023-01-05 01:56:08,097 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46370394428571066, 'Total loss': 0.46370394428571066} | train loss {'Reaction outcome loss': 0.43571943602096425, 'Total loss': 0.43571943602096425}
2023-01-05 01:56:08,097 INFO:     Found new best model at epoch 7
2023-01-05 01:56:08,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:08,099 INFO:     Epoch: 8
2023-01-05 01:56:10,337 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45117827455202736, 'Total loss': 0.45117827455202736} | train loss {'Reaction outcome loss': 0.4220024956403858, 'Total loss': 0.4220024956403858}
2023-01-05 01:56:10,338 INFO:     Found new best model at epoch 8
2023-01-05 01:56:10,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:10,339 INFO:     Epoch: 9
2023-01-05 01:56:12,567 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4505913863579432, 'Total loss': 0.4505913863579432} | train loss {'Reaction outcome loss': 0.412077438711685, 'Total loss': 0.412077438711685}
2023-01-05 01:56:12,567 INFO:     Found new best model at epoch 9
2023-01-05 01:56:12,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:12,569 INFO:     Epoch: 10
2023-01-05 01:56:14,750 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46274925072987877, 'Total loss': 0.46274925072987877} | train loss {'Reaction outcome loss': 0.4003529418667738, 'Total loss': 0.4003529418667738}
2023-01-05 01:56:14,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:14,751 INFO:     Epoch: 11
2023-01-05 01:56:16,994 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44321659704049426, 'Total loss': 0.44321659704049426} | train loss {'Reaction outcome loss': 0.3887634648785104, 'Total loss': 0.3887634648785104}
2023-01-05 01:56:16,995 INFO:     Found new best model at epoch 11
2023-01-05 01:56:16,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:16,996 INFO:     Epoch: 12
2023-01-05 01:56:19,230 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4619319707155228, 'Total loss': 0.4619319707155228} | train loss {'Reaction outcome loss': 0.3830824736505747, 'Total loss': 0.3830824736505747}
2023-01-05 01:56:19,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:19,231 INFO:     Epoch: 13
2023-01-05 01:56:21,449 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4775115966796875, 'Total loss': 0.4775115966796875} | train loss {'Reaction outcome loss': 0.37095408081790826, 'Total loss': 0.37095408081790826}
2023-01-05 01:56:21,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:21,449 INFO:     Epoch: 14
2023-01-05 01:56:23,653 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4283789878090223, 'Total loss': 0.4283789878090223} | train loss {'Reaction outcome loss': 0.35975322983887076, 'Total loss': 0.35975322983887076}
2023-01-05 01:56:23,653 INFO:     Found new best model at epoch 14
2023-01-05 01:56:23,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:23,655 INFO:     Epoch: 15
2023-01-05 01:56:25,872 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4400298123558362, 'Total loss': 0.4400298123558362} | train loss {'Reaction outcome loss': 0.35878693574808374, 'Total loss': 0.35878693574808374}
2023-01-05 01:56:25,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:25,873 INFO:     Epoch: 16
2023-01-05 01:56:28,098 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4594716469446818, 'Total loss': 0.4594716469446818} | train loss {'Reaction outcome loss': 0.35089680571516935, 'Total loss': 0.35089680571516935}
2023-01-05 01:56:28,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:28,098 INFO:     Epoch: 17
2023-01-05 01:56:30,342 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45707246859868367, 'Total loss': 0.45707246859868367} | train loss {'Reaction outcome loss': 0.34018535947386364, 'Total loss': 0.34018535947386364}
2023-01-05 01:56:30,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:30,343 INFO:     Epoch: 18
2023-01-05 01:56:32,552 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46247802873452504, 'Total loss': 0.46247802873452504} | train loss {'Reaction outcome loss': 0.3323826570961162, 'Total loss': 0.3323826570961162}
2023-01-05 01:56:32,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:32,552 INFO:     Epoch: 19
2023-01-05 01:56:34,790 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45067978302637735, 'Total loss': 0.45067978302637735} | train loss {'Reaction outcome loss': 0.32816056603987287, 'Total loss': 0.32816056603987287}
2023-01-05 01:56:34,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:34,790 INFO:     Epoch: 20
2023-01-05 01:56:36,980 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4249788482983907, 'Total loss': 0.4249788482983907} | train loss {'Reaction outcome loss': 0.3193527283486876, 'Total loss': 0.3193527283486876}
2023-01-05 01:56:36,980 INFO:     Found new best model at epoch 20
2023-01-05 01:56:36,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:36,981 INFO:     Epoch: 21
2023-01-05 01:56:39,186 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.453519074122111, 'Total loss': 0.453519074122111} | train loss {'Reaction outcome loss': 0.30949566109500226, 'Total loss': 0.30949566109500226}
2023-01-05 01:56:39,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:39,186 INFO:     Epoch: 22
2023-01-05 01:56:41,424 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4287365665038427, 'Total loss': 0.4287365665038427} | train loss {'Reaction outcome loss': 0.31113430056856933, 'Total loss': 0.31113430056856933}
2023-01-05 01:56:41,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:41,424 INFO:     Epoch: 23
2023-01-05 01:56:43,640 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4335569898287455, 'Total loss': 0.4335569898287455} | train loss {'Reaction outcome loss': 0.30298121296630726, 'Total loss': 0.30298121296630726}
2023-01-05 01:56:43,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:43,640 INFO:     Epoch: 24
2023-01-05 01:56:45,855 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42583214739958447, 'Total loss': 0.42583214739958447} | train loss {'Reaction outcome loss': 0.299645044929246, 'Total loss': 0.299645044929246}
2023-01-05 01:56:45,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:45,856 INFO:     Epoch: 25
2023-01-05 01:56:48,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4190115362405777, 'Total loss': 0.4190115362405777} | train loss {'Reaction outcome loss': 0.29605128151113097, 'Total loss': 0.29605128151113097}
2023-01-05 01:56:48,083 INFO:     Found new best model at epoch 25
2023-01-05 01:56:48,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:48,085 INFO:     Epoch: 26
2023-01-05 01:56:50,268 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4540335259089867, 'Total loss': 0.4540335259089867} | train loss {'Reaction outcome loss': 0.2875446774962827, 'Total loss': 0.2875446774962827}
2023-01-05 01:56:50,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:50,269 INFO:     Epoch: 27
2023-01-05 01:56:52,511 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4301019052664439, 'Total loss': 0.4301019052664439} | train loss {'Reaction outcome loss': 0.28708527364978825, 'Total loss': 0.28708527364978825}
2023-01-05 01:56:52,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:52,512 INFO:     Epoch: 28
2023-01-05 01:56:54,712 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41235726450880367, 'Total loss': 0.41235726450880367} | train loss {'Reaction outcome loss': 0.28020682187247886, 'Total loss': 0.28020682187247886}
2023-01-05 01:56:54,712 INFO:     Found new best model at epoch 28
2023-01-05 01:56:54,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:54,713 INFO:     Epoch: 29
2023-01-05 01:56:56,948 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43120598594347637, 'Total loss': 0.43120598594347637} | train loss {'Reaction outcome loss': 0.27426250295264876, 'Total loss': 0.27426250295264876}
2023-01-05 01:56:56,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:56,949 INFO:     Epoch: 30
2023-01-05 01:56:59,214 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42637815649310745, 'Total loss': 0.42637815649310745} | train loss {'Reaction outcome loss': 0.270751348176604, 'Total loss': 0.270751348176604}
2023-01-05 01:56:59,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:56:59,214 INFO:     Epoch: 31
2023-01-05 01:57:01,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4533369948466619, 'Total loss': 0.4533369948466619} | train loss {'Reaction outcome loss': 0.26158126594539544, 'Total loss': 0.26158126594539544}
2023-01-05 01:57:01,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:01,414 INFO:     Epoch: 32
2023-01-05 01:57:03,646 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4599280635515849, 'Total loss': 0.4599280635515849} | train loss {'Reaction outcome loss': 0.2641527329428788, 'Total loss': 0.2641527329428788}
2023-01-05 01:57:03,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:03,646 INFO:     Epoch: 33
2023-01-05 01:57:05,895 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.467353101571401, 'Total loss': 0.467353101571401} | train loss {'Reaction outcome loss': 0.2576851739962823, 'Total loss': 0.2576851739962823}
2023-01-05 01:57:05,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:05,896 INFO:     Epoch: 34
2023-01-05 01:57:08,145 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43656630367040633, 'Total loss': 0.43656630367040633} | train loss {'Reaction outcome loss': 0.25318942711192327, 'Total loss': 0.25318942711192327}
2023-01-05 01:57:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:08,146 INFO:     Epoch: 35
2023-01-05 01:57:10,386 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44853782455126445, 'Total loss': 0.44853782455126445} | train loss {'Reaction outcome loss': 0.2500349919984702, 'Total loss': 0.2500349919984702}
2023-01-05 01:57:10,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:10,386 INFO:     Epoch: 36
2023-01-05 01:57:12,567 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45444996654987335, 'Total loss': 0.45444996654987335} | train loss {'Reaction outcome loss': 0.2508335782310171, 'Total loss': 0.2508335782310171}
2023-01-05 01:57:12,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:12,568 INFO:     Epoch: 37
2023-01-05 01:57:14,749 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4720497305194537, 'Total loss': 0.4720497305194537} | train loss {'Reaction outcome loss': 0.24256799004999172, 'Total loss': 0.24256799004999172}
2023-01-05 01:57:14,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:14,750 INFO:     Epoch: 38
2023-01-05 01:57:16,956 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4589596311251322, 'Total loss': 0.4589596311251322} | train loss {'Reaction outcome loss': 0.244193930913062, 'Total loss': 0.244193930913062}
2023-01-05 01:57:16,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:16,956 INFO:     Epoch: 39
2023-01-05 01:57:19,174 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4208866715431213, 'Total loss': 0.4208866715431213} | train loss {'Reaction outcome loss': 0.23883811178460826, 'Total loss': 0.23883811178460826}
2023-01-05 01:57:19,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:19,175 INFO:     Epoch: 40
2023-01-05 01:57:21,427 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4105095158020655, 'Total loss': 0.4105095158020655} | train loss {'Reaction outcome loss': 0.23816470855534294, 'Total loss': 0.23816470855534294}
2023-01-05 01:57:21,428 INFO:     Found new best model at epoch 40
2023-01-05 01:57:21,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:21,430 INFO:     Epoch: 41
2023-01-05 01:57:23,666 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43553265929222107, 'Total loss': 0.43553265929222107} | train loss {'Reaction outcome loss': 0.22924620856660127, 'Total loss': 0.22924620856660127}
2023-01-05 01:57:23,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:23,666 INFO:     Epoch: 42
2023-01-05 01:57:25,881 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4374453360835711, 'Total loss': 0.4374453360835711} | train loss {'Reaction outcome loss': 0.22449154915954292, 'Total loss': 0.22449154915954292}
2023-01-05 01:57:25,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:25,881 INFO:     Epoch: 43
2023-01-05 01:57:28,125 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4444919044772784, 'Total loss': 0.4444919044772784} | train loss {'Reaction outcome loss': 0.22892133485063584, 'Total loss': 0.22892133485063584}
2023-01-05 01:57:28,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:28,126 INFO:     Epoch: 44
2023-01-05 01:57:30,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47025712529818214, 'Total loss': 0.47025712529818214} | train loss {'Reaction outcome loss': 0.22811548261610914, 'Total loss': 0.22811548261610914}
2023-01-05 01:57:30,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:30,373 INFO:     Epoch: 45
2023-01-05 01:57:32,619 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46823942263921103, 'Total loss': 0.46823942263921103} | train loss {'Reaction outcome loss': 0.22775318814835843, 'Total loss': 0.22775318814835843}
2023-01-05 01:57:32,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:32,620 INFO:     Epoch: 46
2023-01-05 01:57:34,872 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47190264860788983, 'Total loss': 0.47190264860788983} | train loss {'Reaction outcome loss': 0.21688336931359375, 'Total loss': 0.21688336931359375}
2023-01-05 01:57:34,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:34,872 INFO:     Epoch: 47
2023-01-05 01:57:37,088 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44652933776378634, 'Total loss': 0.44652933776378634} | train loss {'Reaction outcome loss': 0.21717799218357914, 'Total loss': 0.21717799218357914}
2023-01-05 01:57:37,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:37,089 INFO:     Epoch: 48
2023-01-05 01:57:39,346 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4533118923505147, 'Total loss': 0.4533118923505147} | train loss {'Reaction outcome loss': 0.2166868060093074, 'Total loss': 0.2166868060093074}
2023-01-05 01:57:39,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:39,346 INFO:     Epoch: 49
2023-01-05 01:57:41,583 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46173671012123424, 'Total loss': 0.46173671012123424} | train loss {'Reaction outcome loss': 0.2154213919909331, 'Total loss': 0.2154213919909331}
2023-01-05 01:57:41,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:41,584 INFO:     Epoch: 50
2023-01-05 01:57:43,791 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4589078257481257, 'Total loss': 0.4589078257481257} | train loss {'Reaction outcome loss': 0.21428757495362394, 'Total loss': 0.21428757495362394}
2023-01-05 01:57:43,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:43,792 INFO:     Epoch: 51
2023-01-05 01:57:45,938 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44664286673069, 'Total loss': 0.44664286673069} | train loss {'Reaction outcome loss': 0.21686836272940366, 'Total loss': 0.21686836272940366}
2023-01-05 01:57:45,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:45,938 INFO:     Epoch: 52
2023-01-05 01:57:48,142 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42688455382982887, 'Total loss': 0.42688455382982887} | train loss {'Reaction outcome loss': 0.20927513512463247, 'Total loss': 0.20927513512463247}
2023-01-05 01:57:48,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:48,143 INFO:     Epoch: 53
2023-01-05 01:57:50,395 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4592853546142578, 'Total loss': 0.4592853546142578} | train loss {'Reaction outcome loss': 0.20911114880590814, 'Total loss': 0.20911114880590814}
2023-01-05 01:57:50,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:50,395 INFO:     Epoch: 54
2023-01-05 01:57:52,653 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4961235170563062, 'Total loss': 0.4961235170563062} | train loss {'Reaction outcome loss': 0.20575162177619927, 'Total loss': 0.20575162177619927}
2023-01-05 01:57:52,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:52,653 INFO:     Epoch: 55
2023-01-05 01:57:54,898 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4574368963638941, 'Total loss': 0.4574368963638941} | train loss {'Reaction outcome loss': 0.20104864838594286, 'Total loss': 0.20104864838594286}
2023-01-05 01:57:54,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:54,898 INFO:     Epoch: 56
2023-01-05 01:57:57,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4851138323545456, 'Total loss': 0.4851138323545456} | train loss {'Reaction outcome loss': 0.20145658441363787, 'Total loss': 0.20145658441363787}
2023-01-05 01:57:57,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:57,156 INFO:     Epoch: 57
2023-01-05 01:57:59,269 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4554831584294637, 'Total loss': 0.4554831584294637} | train loss {'Reaction outcome loss': 0.20147513722266702, 'Total loss': 0.20147513722266702}
2023-01-05 01:57:59,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:57:59,270 INFO:     Epoch: 58
2023-01-05 01:58:01,116 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45746424198150637, 'Total loss': 0.45746424198150637} | train loss {'Reaction outcome loss': 0.19956916633204821, 'Total loss': 0.19956916633204821}
2023-01-05 01:58:01,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:01,116 INFO:     Epoch: 59
2023-01-05 01:58:03,018 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4635201394557953, 'Total loss': 0.4635201394557953} | train loss {'Reaction outcome loss': 0.1951527379004516, 'Total loss': 0.1951527379004516}
2023-01-05 01:58:03,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:03,018 INFO:     Epoch: 60
2023-01-05 01:58:05,176 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45395643760760623, 'Total loss': 0.45395643760760623} | train loss {'Reaction outcome loss': 0.19670841340859332, 'Total loss': 0.19670841340859332}
2023-01-05 01:58:05,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:05,177 INFO:     Epoch: 61
2023-01-05 01:58:07,322 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4715735788146655, 'Total loss': 0.4715735788146655} | train loss {'Reaction outcome loss': 0.19310945675395647, 'Total loss': 0.19310945675395647}
2023-01-05 01:58:07,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:07,322 INFO:     Epoch: 62
2023-01-05 01:58:09,458 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4547447661558787, 'Total loss': 0.4547447661558787} | train loss {'Reaction outcome loss': 0.1902643471419213, 'Total loss': 0.1902643471419213}
2023-01-05 01:58:09,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:09,458 INFO:     Epoch: 63
2023-01-05 01:58:11,690 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4602952281634013, 'Total loss': 0.4602952281634013} | train loss {'Reaction outcome loss': 0.19067281978476766, 'Total loss': 0.19067281978476766}
2023-01-05 01:58:11,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:11,690 INFO:     Epoch: 64
2023-01-05 01:58:13,922 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47383452554543815, 'Total loss': 0.47383452554543815} | train loss {'Reaction outcome loss': 0.1925913306245458, 'Total loss': 0.1925913306245458}
2023-01-05 01:58:13,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:13,922 INFO:     Epoch: 65
2023-01-05 01:58:16,144 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4735346734523773, 'Total loss': 0.4735346734523773} | train loss {'Reaction outcome loss': 0.1877443603423499, 'Total loss': 0.1877443603423499}
2023-01-05 01:58:16,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:16,144 INFO:     Epoch: 66
2023-01-05 01:58:18,347 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4777684619029363, 'Total loss': 0.4777684619029363} | train loss {'Reaction outcome loss': 0.19205079851740034, 'Total loss': 0.19205079851740034}
2023-01-05 01:58:18,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:18,348 INFO:     Epoch: 67
2023-01-05 01:58:20,618 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4701931009689967, 'Total loss': 0.4701931009689967} | train loss {'Reaction outcome loss': 0.18633917093881996, 'Total loss': 0.18633917093881996}
2023-01-05 01:58:20,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:20,618 INFO:     Epoch: 68
2023-01-05 01:58:22,845 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4377275198698044, 'Total loss': 0.4377275198698044} | train loss {'Reaction outcome loss': 0.18842123010209388, 'Total loss': 0.18842123010209388}
2023-01-05 01:58:22,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:22,845 INFO:     Epoch: 69
2023-01-05 01:58:25,109 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43938221236069996, 'Total loss': 0.43938221236069996} | train loss {'Reaction outcome loss': 0.18443923257291317, 'Total loss': 0.18443923257291317}
2023-01-05 01:58:25,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:25,109 INFO:     Epoch: 70
2023-01-05 01:58:27,328 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4886386533578237, 'Total loss': 0.4886386533578237} | train loss {'Reaction outcome loss': 0.18166380238304608, 'Total loss': 0.18166380238304608}
2023-01-05 01:58:27,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:27,328 INFO:     Epoch: 71
2023-01-05 01:58:29,533 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.457458217193683, 'Total loss': 0.457458217193683} | train loss {'Reaction outcome loss': 0.18261146915050047, 'Total loss': 0.18261146915050047}
2023-01-05 01:58:29,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:29,533 INFO:     Epoch: 72
2023-01-05 01:58:31,802 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42564787666002907, 'Total loss': 0.42564787666002907} | train loss {'Reaction outcome loss': 0.18345449954087772, 'Total loss': 0.18345449954087772}
2023-01-05 01:58:31,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:31,803 INFO:     Epoch: 73
2023-01-05 01:58:33,939 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4339226443320513, 'Total loss': 0.4339226443320513} | train loss {'Reaction outcome loss': 0.18199603758194913, 'Total loss': 0.18199603758194913}
2023-01-05 01:58:33,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:33,940 INFO:     Epoch: 74
2023-01-05 01:58:36,180 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4630461434523265, 'Total loss': 0.4630461434523265} | train loss {'Reaction outcome loss': 0.17664830312200816, 'Total loss': 0.17664830312200816}
2023-01-05 01:58:36,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:36,181 INFO:     Epoch: 75
2023-01-05 01:58:38,405 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44765254060427345, 'Total loss': 0.44765254060427345} | train loss {'Reaction outcome loss': 0.18098467957214825, 'Total loss': 0.18098467957214825}
2023-01-05 01:58:38,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:38,405 INFO:     Epoch: 76
2023-01-05 01:58:40,654 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46495237251122795, 'Total loss': 0.46495237251122795} | train loss {'Reaction outcome loss': 0.18249305571687754, 'Total loss': 0.18249305571687754}
2023-01-05 01:58:40,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:40,655 INFO:     Epoch: 77
2023-01-05 01:58:42,910 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4853103150924047, 'Total loss': 0.4853103150924047} | train loss {'Reaction outcome loss': 0.17958527608998937, 'Total loss': 0.17958527608998937}
2023-01-05 01:58:42,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:42,910 INFO:     Epoch: 78
2023-01-05 01:58:45,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4901600072781245, 'Total loss': 0.4901600072781245} | train loss {'Reaction outcome loss': 0.17896937285583928, 'Total loss': 0.17896937285583928}
2023-01-05 01:58:45,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:45,089 INFO:     Epoch: 79
2023-01-05 01:58:47,317 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.466798992951711, 'Total loss': 0.466798992951711} | train loss {'Reaction outcome loss': 0.17558132898212023, 'Total loss': 0.17558132898212023}
2023-01-05 01:58:47,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:47,318 INFO:     Epoch: 80
2023-01-05 01:58:49,556 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44891108870506286, 'Total loss': 0.44891108870506286} | train loss {'Reaction outcome loss': 0.174635975123689, 'Total loss': 0.174635975123689}
2023-01-05 01:58:49,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:49,556 INFO:     Epoch: 81
2023-01-05 01:58:51,759 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4388570139805476, 'Total loss': 0.4388570139805476} | train loss {'Reaction outcome loss': 0.1790200065631066, 'Total loss': 0.1790200065631066}
2023-01-05 01:58:51,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:51,759 INFO:     Epoch: 82
2023-01-05 01:58:54,004 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44207722345987954, 'Total loss': 0.44207722345987954} | train loss {'Reaction outcome loss': 0.1751468190685404, 'Total loss': 0.1751468190685404}
2023-01-05 01:58:54,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:54,005 INFO:     Epoch: 83
2023-01-05 01:58:56,257 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4395637740691503, 'Total loss': 0.4395637740691503} | train loss {'Reaction outcome loss': 0.17362166991810837, 'Total loss': 0.17362166991810837}
2023-01-05 01:58:56,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:56,257 INFO:     Epoch: 84
2023-01-05 01:58:58,489 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4802323748668035, 'Total loss': 0.4802323748668035} | train loss {'Reaction outcome loss': 0.17411951959153543, 'Total loss': 0.17411951959153543}
2023-01-05 01:58:58,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:58:58,489 INFO:     Epoch: 85
2023-01-05 01:59:00,736 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4387959857781728, 'Total loss': 0.4387959857781728} | train loss {'Reaction outcome loss': 0.1720877528941789, 'Total loss': 0.1720877528941789}
2023-01-05 01:59:00,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:00,737 INFO:     Epoch: 86
2023-01-05 01:59:02,975 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45928919812043506, 'Total loss': 0.45928919812043506} | train loss {'Reaction outcome loss': 0.16952617983265786, 'Total loss': 0.16952617983265786}
2023-01-05 01:59:02,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:02,975 INFO:     Epoch: 87
2023-01-05 01:59:05,151 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4097319253953174, 'Total loss': 0.4097319253953174} | train loss {'Reaction outcome loss': 0.17080295795955472, 'Total loss': 0.17080295795955472}
2023-01-05 01:59:05,151 INFO:     Found new best model at epoch 87
2023-01-05 01:59:05,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:05,153 INFO:     Epoch: 88
2023-01-05 01:59:07,379 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44575470487276714, 'Total loss': 0.44575470487276714} | train loss {'Reaction outcome loss': 0.16969974950146283, 'Total loss': 0.16969974950146283}
2023-01-05 01:59:07,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:07,379 INFO:     Epoch: 89
2023-01-05 01:59:09,596 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4387083252271016, 'Total loss': 0.4387083252271016} | train loss {'Reaction outcome loss': 0.17271016696875874, 'Total loss': 0.17271016696875874}
2023-01-05 01:59:09,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:09,597 INFO:     Epoch: 90
2023-01-05 01:59:11,857 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47482443874080976, 'Total loss': 0.47482443874080976} | train loss {'Reaction outcome loss': 0.16904761761861997, 'Total loss': 0.16904761761861997}
2023-01-05 01:59:11,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:11,857 INFO:     Epoch: 91
2023-01-05 01:59:14,005 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4603675703207652, 'Total loss': 0.4603675703207652} | train loss {'Reaction outcome loss': 0.1637870491122025, 'Total loss': 0.1637870491122025}
2023-01-05 01:59:14,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:14,006 INFO:     Epoch: 92
2023-01-05 01:59:16,203 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47853634556134544, 'Total loss': 0.47853634556134544} | train loss {'Reaction outcome loss': 0.1660491479526743, 'Total loss': 0.1660491479526743}
2023-01-05 01:59:16,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:16,204 INFO:     Epoch: 93
2023-01-05 01:59:18,401 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44203821818033856, 'Total loss': 0.44203821818033856} | train loss {'Reaction outcome loss': 0.16614185313330487, 'Total loss': 0.16614185313330487}
2023-01-05 01:59:18,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:18,401 INFO:     Epoch: 94
2023-01-05 01:59:20,513 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4626393601298332, 'Total loss': 0.4626393601298332} | train loss {'Reaction outcome loss': 0.16748867001058193, 'Total loss': 0.16748867001058193}
2023-01-05 01:59:20,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:20,513 INFO:     Epoch: 95
2023-01-05 01:59:22,732 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44997551540533703, 'Total loss': 0.44997551540533703} | train loss {'Reaction outcome loss': 0.16634689917937465, 'Total loss': 0.16634689917937465}
2023-01-05 01:59:22,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:22,732 INFO:     Epoch: 96
2023-01-05 01:59:24,912 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.474552587668101, 'Total loss': 0.474552587668101} | train loss {'Reaction outcome loss': 0.16666902364809474, 'Total loss': 0.16666902364809474}
2023-01-05 01:59:24,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:24,912 INFO:     Epoch: 97
2023-01-05 01:59:27,148 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46106209854284924, 'Total loss': 0.46106209854284924} | train loss {'Reaction outcome loss': 0.16788098769751889, 'Total loss': 0.16788098769751889}
2023-01-05 01:59:27,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:27,148 INFO:     Epoch: 98
2023-01-05 01:59:29,408 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4746618231137594, 'Total loss': 0.4746618231137594} | train loss {'Reaction outcome loss': 0.1647600647526025, 'Total loss': 0.1647600647526025}
2023-01-05 01:59:29,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:29,409 INFO:     Epoch: 99
2023-01-05 01:59:31,673 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44023687541484835, 'Total loss': 0.44023687541484835} | train loss {'Reaction outcome loss': 0.16292421054944778, 'Total loss': 0.16292421054944778}
2023-01-05 01:59:31,673 INFO:     Best model found after epoch 88 of 100.
2023-01-05 01:59:31,673 INFO:   Done with stage: TRAINING
2023-01-05 01:59:31,673 INFO:   Starting stage: EVALUATION
2023-01-05 01:59:31,814 INFO:   Done with stage: EVALUATION
2023-01-05 01:59:31,814 INFO:   Leaving out SEQ value Fold_8
2023-01-05 01:59:31,827 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 01:59:31,827 INFO:   Starting stage: FEATURE SCALING
2023-01-05 01:59:32,473 INFO:   Done with stage: FEATURE SCALING
2023-01-05 01:59:32,473 INFO:   Starting stage: SCALING TARGETS
2023-01-05 01:59:32,545 INFO:   Done with stage: SCALING TARGETS
2023-01-05 01:59:32,545 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:59:32,545 INFO:     No hyperparam tuning for this model
2023-01-05 01:59:32,545 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 01:59:32,545 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 01:59:32,546 INFO:     None feature selector for col prot
2023-01-05 01:59:32,546 INFO:     None feature selector for col prot
2023-01-05 01:59:32,546 INFO:     None feature selector for col prot
2023-01-05 01:59:32,546 INFO:     None feature selector for col chem
2023-01-05 01:59:32,547 INFO:     None feature selector for col chem
2023-01-05 01:59:32,547 INFO:     None feature selector for col chem
2023-01-05 01:59:32,547 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 01:59:32,547 INFO:   Starting stage: BUILD MODEL
2023-01-05 01:59:32,548 INFO:     Number of params in model 72931
2023-01-05 01:59:32,551 INFO:   Done with stage: BUILD MODEL
2023-01-05 01:59:32,551 INFO:   Starting stage: TRAINING
2023-01-05 01:59:32,612 INFO:     Val loss before train {'Reaction outcome loss': 0.8688728849093119, 'Total loss': 0.8688728849093119}
2023-01-05 01:59:32,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:32,612 INFO:     Epoch: 0
2023-01-05 01:59:34,896 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.613838654756546, 'Total loss': 0.613838654756546} | train loss {'Reaction outcome loss': 0.9183933140999143, 'Total loss': 0.9183933140999143}
2023-01-05 01:59:34,896 INFO:     Found new best model at epoch 0
2023-01-05 01:59:34,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:34,898 INFO:     Epoch: 1
2023-01-05 01:59:37,120 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4895012597242991, 'Total loss': 0.4895012597242991} | train loss {'Reaction outcome loss': 0.6241216387882129, 'Total loss': 0.6241216387882129}
2023-01-05 01:59:37,120 INFO:     Found new best model at epoch 1
2023-01-05 01:59:37,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:37,122 INFO:     Epoch: 2
2023-01-05 01:59:39,334 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46722841064135234, 'Total loss': 0.46722841064135234} | train loss {'Reaction outcome loss': 0.543734023502157, 'Total loss': 0.543734023502157}
2023-01-05 01:59:39,334 INFO:     Found new best model at epoch 2
2023-01-05 01:59:39,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:39,335 INFO:     Epoch: 3
2023-01-05 01:59:41,527 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4353652050097783, 'Total loss': 0.4353652050097783} | train loss {'Reaction outcome loss': 0.4992336763694398, 'Total loss': 0.4992336763694398}
2023-01-05 01:59:41,527 INFO:     Found new best model at epoch 3
2023-01-05 01:59:41,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:41,529 INFO:     Epoch: 4
2023-01-05 01:59:43,781 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4336647133032481, 'Total loss': 0.4336647133032481} | train loss {'Reaction outcome loss': 0.46500125508553714, 'Total loss': 0.46500125508553714}
2023-01-05 01:59:43,782 INFO:     Found new best model at epoch 4
2023-01-05 01:59:43,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:43,783 INFO:     Epoch: 5
2023-01-05 01:59:45,872 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4124930153290431, 'Total loss': 0.4124930153290431} | train loss {'Reaction outcome loss': 0.4440817701687451, 'Total loss': 0.4440817701687451}
2023-01-05 01:59:45,873 INFO:     Found new best model at epoch 5
2023-01-05 01:59:45,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:45,874 INFO:     Epoch: 6
2023-01-05 01:59:48,062 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.419368784626325, 'Total loss': 0.419368784626325} | train loss {'Reaction outcome loss': 0.4198024049132309, 'Total loss': 0.4198024049132309}
2023-01-05 01:59:48,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:48,062 INFO:     Epoch: 7
2023-01-05 01:59:50,323 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40791130463282266, 'Total loss': 0.40791130463282266} | train loss {'Reaction outcome loss': 0.3991796505849284, 'Total loss': 0.3991796505849284}
2023-01-05 01:59:50,323 INFO:     Found new best model at epoch 7
2023-01-05 01:59:50,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:50,325 INFO:     Epoch: 8
2023-01-05 01:59:52,530 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3845895210901896, 'Total loss': 0.3845895210901896} | train loss {'Reaction outcome loss': 0.38924290247880167, 'Total loss': 0.38924290247880167}
2023-01-05 01:59:52,530 INFO:     Found new best model at epoch 8
2023-01-05 01:59:52,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:52,532 INFO:     Epoch: 9
2023-01-05 01:59:54,688 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37614503105481467, 'Total loss': 0.37614503105481467} | train loss {'Reaction outcome loss': 0.3749131499134031, 'Total loss': 0.3749131499134031}
2023-01-05 01:59:54,688 INFO:     Found new best model at epoch 9
2023-01-05 01:59:54,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:54,689 INFO:     Epoch: 10
2023-01-05 01:59:56,933 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40413060834010445, 'Total loss': 0.40413060834010445} | train loss {'Reaction outcome loss': 0.36389232752340367, 'Total loss': 0.36389232752340367}
2023-01-05 01:59:56,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:56,934 INFO:     Epoch: 11
2023-01-05 01:59:59,200 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3859155962864558, 'Total loss': 0.3859155962864558} | train loss {'Reaction outcome loss': 0.3555974404223344, 'Total loss': 0.3555974404223344}
2023-01-05 01:59:59,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 01:59:59,200 INFO:     Epoch: 12
2023-01-05 02:00:01,471 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3843200405438741, 'Total loss': 0.3843200405438741} | train loss {'Reaction outcome loss': 0.3455242377433536, 'Total loss': 0.3455242377433536}
2023-01-05 02:00:01,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:01,472 INFO:     Epoch: 13
2023-01-05 02:00:03,750 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3888621638218562, 'Total loss': 0.3888621638218562} | train loss {'Reaction outcome loss': 0.335415793562624, 'Total loss': 0.335415793562624}
2023-01-05 02:00:03,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:03,750 INFO:     Epoch: 14
2023-01-05 02:00:06,014 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3637304772933324, 'Total loss': 0.3637304772933324} | train loss {'Reaction outcome loss': 0.32559002946645343, 'Total loss': 0.32559002946645343}
2023-01-05 02:00:06,014 INFO:     Found new best model at epoch 14
2023-01-05 02:00:06,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:06,016 INFO:     Epoch: 15
2023-01-05 02:00:08,217 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3741805851459503, 'Total loss': 0.3741805851459503} | train loss {'Reaction outcome loss': 0.32169897555766985, 'Total loss': 0.32169897555766985}
2023-01-05 02:00:08,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:08,217 INFO:     Epoch: 16
2023-01-05 02:00:10,456 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3661465128262838, 'Total loss': 0.3661465128262838} | train loss {'Reaction outcome loss': 0.3126644856071214, 'Total loss': 0.3126644856071214}
2023-01-05 02:00:10,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:10,457 INFO:     Epoch: 17
2023-01-05 02:00:12,714 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3639034847418467, 'Total loss': 0.3639034847418467} | train loss {'Reaction outcome loss': 0.3027165639432759, 'Total loss': 0.3027165639432759}
2023-01-05 02:00:12,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:12,715 INFO:     Epoch: 18
2023-01-05 02:00:14,938 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3700720191001892, 'Total loss': 0.3700720191001892} | train loss {'Reaction outcome loss': 0.299057933478364, 'Total loss': 0.299057933478364}
2023-01-05 02:00:14,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:14,938 INFO:     Epoch: 19
2023-01-05 02:00:17,168 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3530852446953456, 'Total loss': 0.3530852446953456} | train loss {'Reaction outcome loss': 0.2960894608782732, 'Total loss': 0.2960894608782732}
2023-01-05 02:00:17,168 INFO:     Found new best model at epoch 19
2023-01-05 02:00:17,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:17,169 INFO:     Epoch: 20
2023-01-05 02:00:19,410 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3778573135534922, 'Total loss': 0.3778573135534922} | train loss {'Reaction outcome loss': 0.2898798187125461, 'Total loss': 0.2898798187125461}
2023-01-05 02:00:19,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:19,410 INFO:     Epoch: 21
2023-01-05 02:00:21,611 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35998408993085224, 'Total loss': 0.35998408993085224} | train loss {'Reaction outcome loss': 0.2848006884032854, 'Total loss': 0.2848006884032854}
2023-01-05 02:00:21,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:21,612 INFO:     Epoch: 22
2023-01-05 02:00:23,797 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3490039845307668, 'Total loss': 0.3490039845307668} | train loss {'Reaction outcome loss': 0.27803807529462804, 'Total loss': 0.27803807529462804}
2023-01-05 02:00:23,798 INFO:     Found new best model at epoch 22
2023-01-05 02:00:23,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:23,799 INFO:     Epoch: 23
2023-01-05 02:00:26,044 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3689780051509539, 'Total loss': 0.3689780051509539} | train loss {'Reaction outcome loss': 0.2733379097567999, 'Total loss': 0.2733379097567999}
2023-01-05 02:00:26,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:26,045 INFO:     Epoch: 24
2023-01-05 02:00:28,294 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3527108500401179, 'Total loss': 0.3527108500401179} | train loss {'Reaction outcome loss': 0.2689190842480221, 'Total loss': 0.2689190842480221}
2023-01-05 02:00:28,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:28,295 INFO:     Epoch: 25
2023-01-05 02:00:30,548 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3798272252082825, 'Total loss': 0.3798272252082825} | train loss {'Reaction outcome loss': 0.2628044525719507, 'Total loss': 0.2628044525719507}
2023-01-05 02:00:30,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:30,549 INFO:     Epoch: 26
2023-01-05 02:00:32,729 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38210418621699016, 'Total loss': 0.38210418621699016} | train loss {'Reaction outcome loss': 0.25726829898217524, 'Total loss': 0.25726829898217524}
2023-01-05 02:00:32,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:32,729 INFO:     Epoch: 27
2023-01-05 02:00:34,985 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3620397887192667, 'Total loss': 0.3620397887192667} | train loss {'Reaction outcome loss': 0.2531003809470132, 'Total loss': 0.2531003809470132}
2023-01-05 02:00:34,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:34,986 INFO:     Epoch: 28
2023-01-05 02:00:37,242 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38002547025680544, 'Total loss': 0.38002547025680544} | train loss {'Reaction outcome loss': 0.2503696062033895, 'Total loss': 0.2503696062033895}
2023-01-05 02:00:37,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:37,242 INFO:     Epoch: 29
2023-01-05 02:00:39,514 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35528040130933125, 'Total loss': 0.35528040130933125} | train loss {'Reaction outcome loss': 0.24720390240530676, 'Total loss': 0.24720390240530676}
2023-01-05 02:00:39,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:39,514 INFO:     Epoch: 30
2023-01-05 02:00:41,775 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3546850989262263, 'Total loss': 0.3546850989262263} | train loss {'Reaction outcome loss': 0.24491385404114688, 'Total loss': 0.24491385404114688}
2023-01-05 02:00:41,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:41,775 INFO:     Epoch: 31
2023-01-05 02:00:44,042 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3622922107577324, 'Total loss': 0.3622922107577324} | train loss {'Reaction outcome loss': 0.24053575336220354, 'Total loss': 0.24053575336220354}
2023-01-05 02:00:44,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:44,042 INFO:     Epoch: 32
2023-01-05 02:00:46,303 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3853373716274897, 'Total loss': 0.3853373716274897} | train loss {'Reaction outcome loss': 0.23630668869786745, 'Total loss': 0.23630668869786745}
2023-01-05 02:00:46,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:46,303 INFO:     Epoch: 33
2023-01-05 02:00:48,579 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3709818532069524, 'Total loss': 0.3709818532069524} | train loss {'Reaction outcome loss': 0.23863096631364056, 'Total loss': 0.23863096631364056}
2023-01-05 02:00:48,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:48,580 INFO:     Epoch: 34
2023-01-05 02:00:50,849 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.397101902961731, 'Total loss': 0.397101902961731} | train loss {'Reaction outcome loss': 0.22888710802347007, 'Total loss': 0.22888710802347007}
2023-01-05 02:00:50,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:50,850 INFO:     Epoch: 35
2023-01-05 02:00:53,105 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3729609429836273, 'Total loss': 0.3729609429836273} | train loss {'Reaction outcome loss': 0.22906407308916055, 'Total loss': 0.22906407308916055}
2023-01-05 02:00:53,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:53,106 INFO:     Epoch: 36
2023-01-05 02:00:55,342 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.356259856124719, 'Total loss': 0.356259856124719} | train loss {'Reaction outcome loss': 0.2262468201710106, 'Total loss': 0.2262468201710106}
2023-01-05 02:00:55,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:55,342 INFO:     Epoch: 37
2023-01-05 02:00:57,594 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3593079368273417, 'Total loss': 0.3593079368273417} | train loss {'Reaction outcome loss': 0.2235201652084447, 'Total loss': 0.2235201652084447}
2023-01-05 02:00:57,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:57,595 INFO:     Epoch: 38
2023-01-05 02:00:59,840 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3824504420161247, 'Total loss': 0.3824504420161247} | train loss {'Reaction outcome loss': 0.22210244580578825, 'Total loss': 0.22210244580578825}
2023-01-05 02:00:59,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:00:59,840 INFO:     Epoch: 39
2023-01-05 02:01:02,102 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3603917156656583, 'Total loss': 0.3603917156656583} | train loss {'Reaction outcome loss': 0.21787777458341112, 'Total loss': 0.21787777458341112}
2023-01-05 02:01:02,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:02,102 INFO:     Epoch: 40
2023-01-05 02:01:04,248 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38200716276963553, 'Total loss': 0.38200716276963553} | train loss {'Reaction outcome loss': 0.21811917915583895, 'Total loss': 0.21811917915583895}
2023-01-05 02:01:04,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:04,249 INFO:     Epoch: 41
2023-01-05 02:01:06,403 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41096264583369096, 'Total loss': 0.41096264583369096} | train loss {'Reaction outcome loss': 0.21413954877923327, 'Total loss': 0.21413954877923327}
2023-01-05 02:01:06,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:06,403 INFO:     Epoch: 42
2023-01-05 02:01:08,552 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4140857229630152, 'Total loss': 0.4140857229630152} | train loss {'Reaction outcome loss': 0.21063227575971655, 'Total loss': 0.21063227575971655}
2023-01-05 02:01:08,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:08,553 INFO:     Epoch: 43
2023-01-05 02:01:10,759 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41511012613773346, 'Total loss': 0.41511012613773346} | train loss {'Reaction outcome loss': 0.20338135562998508, 'Total loss': 0.20338135562998508}
2023-01-05 02:01:10,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:10,760 INFO:     Epoch: 44
2023-01-05 02:01:12,904 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39688374747832617, 'Total loss': 0.39688374747832617} | train loss {'Reaction outcome loss': 0.20704937099213527, 'Total loss': 0.20704937099213527}
2023-01-05 02:01:12,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:12,904 INFO:     Epoch: 45
2023-01-05 02:01:15,121 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40873066782951356, 'Total loss': 0.40873066782951356} | train loss {'Reaction outcome loss': 0.19975028670853548, 'Total loss': 0.19975028670853548}
2023-01-05 02:01:15,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:15,121 INFO:     Epoch: 46
2023-01-05 02:01:17,327 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37999736418326696, 'Total loss': 0.37999736418326696} | train loss {'Reaction outcome loss': 0.20433089879613758, 'Total loss': 0.20433089879613758}
2023-01-05 02:01:17,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:17,328 INFO:     Epoch: 47
2023-01-05 02:01:19,566 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4006219665209452, 'Total loss': 0.4006219665209452} | train loss {'Reaction outcome loss': 0.20507647021125586, 'Total loss': 0.20507647021125586}
2023-01-05 02:01:19,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:19,567 INFO:     Epoch: 48
2023-01-05 02:01:21,788 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40500906109809875, 'Total loss': 0.40500906109809875} | train loss {'Reaction outcome loss': 0.20009442655847068, 'Total loss': 0.20009442655847068}
2023-01-05 02:01:21,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:21,789 INFO:     Epoch: 49
2023-01-05 02:01:24,021 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40757381319999697, 'Total loss': 0.40757381319999697} | train loss {'Reaction outcome loss': 0.19868170885564188, 'Total loss': 0.19868170885564188}
2023-01-05 02:01:24,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:24,021 INFO:     Epoch: 50
2023-01-05 02:01:26,242 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4116299659013748, 'Total loss': 0.4116299659013748} | train loss {'Reaction outcome loss': 0.19653189928011988, 'Total loss': 0.19653189928011988}
2023-01-05 02:01:26,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:26,242 INFO:     Epoch: 51
2023-01-05 02:01:28,376 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4026425451040268, 'Total loss': 0.4026425451040268} | train loss {'Reaction outcome loss': 0.19441356917083372, 'Total loss': 0.19441356917083372}
2023-01-05 02:01:28,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:28,377 INFO:     Epoch: 52
2023-01-05 02:01:30,560 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39239130057394506, 'Total loss': 0.39239130057394506} | train loss {'Reaction outcome loss': 0.19524564448784404, 'Total loss': 0.19524564448784404}
2023-01-05 02:01:30,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:30,561 INFO:     Epoch: 53
2023-01-05 02:01:32,802 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3908552239338557, 'Total loss': 0.3908552239338557} | train loss {'Reaction outcome loss': 0.19143549375747085, 'Total loss': 0.19143549375747085}
2023-01-05 02:01:32,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:32,804 INFO:     Epoch: 54
2023-01-05 02:01:35,049 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4353561153014501, 'Total loss': 0.4353561153014501} | train loss {'Reaction outcome loss': 0.19492919995224217, 'Total loss': 0.19492919995224217}
2023-01-05 02:01:35,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:35,050 INFO:     Epoch: 55
2023-01-05 02:01:37,274 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37157502124706904, 'Total loss': 0.37157502124706904} | train loss {'Reaction outcome loss': 0.19171280682671962, 'Total loss': 0.19171280682671962}
2023-01-05 02:01:37,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:37,274 INFO:     Epoch: 56
2023-01-05 02:01:39,515 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39127898315588633, 'Total loss': 0.39127898315588633} | train loss {'Reaction outcome loss': 0.18699384180808756, 'Total loss': 0.18699384180808756}
2023-01-05 02:01:39,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:39,516 INFO:     Epoch: 57
2023-01-05 02:01:41,755 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38853020817041395, 'Total loss': 0.38853020817041395} | train loss {'Reaction outcome loss': 0.1929658099652574, 'Total loss': 0.1929658099652574}
2023-01-05 02:01:41,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:41,756 INFO:     Epoch: 58
2023-01-05 02:01:44,034 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3984636336565018, 'Total loss': 0.3984636336565018} | train loss {'Reaction outcome loss': 0.1844496360226847, 'Total loss': 0.1844496360226847}
2023-01-05 02:01:44,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:44,035 INFO:     Epoch: 59
2023-01-05 02:01:46,289 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3864425515135129, 'Total loss': 0.3864425515135129} | train loss {'Reaction outcome loss': 0.1834110303005264, 'Total loss': 0.1834110303005264}
2023-01-05 02:01:46,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:46,289 INFO:     Epoch: 60
2023-01-05 02:01:48,543 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41011416614055635, 'Total loss': 0.41011416614055635} | train loss {'Reaction outcome loss': 0.1874421259896016, 'Total loss': 0.1874421259896016}
2023-01-05 02:01:48,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:48,543 INFO:     Epoch: 61
2023-01-05 02:01:50,695 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37800449381272, 'Total loss': 0.37800449381272} | train loss {'Reaction outcome loss': 0.18121547449635686, 'Total loss': 0.18121547449635686}
2023-01-05 02:01:50,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:50,695 INFO:     Epoch: 62
2023-01-05 02:01:52,910 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3892895927031835, 'Total loss': 0.3892895927031835} | train loss {'Reaction outcome loss': 0.18207470344426616, 'Total loss': 0.18207470344426616}
2023-01-05 02:01:52,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:52,911 INFO:     Epoch: 63
2023-01-05 02:01:55,125 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38482926140228907, 'Total loss': 0.38482926140228907} | train loss {'Reaction outcome loss': 0.1808378238597421, 'Total loss': 0.1808378238597421}
2023-01-05 02:01:55,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:55,125 INFO:     Epoch: 64
2023-01-05 02:01:57,362 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41293568859497704, 'Total loss': 0.41293568859497704} | train loss {'Reaction outcome loss': 0.18738274049645942, 'Total loss': 0.18738274049645942}
2023-01-05 02:01:57,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:57,362 INFO:     Epoch: 65
2023-01-05 02:01:59,550 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40321643054485323, 'Total loss': 0.40321643054485323} | train loss {'Reaction outcome loss': 0.17857383433830276, 'Total loss': 0.17857383433830276}
2023-01-05 02:01:59,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:01:59,550 INFO:     Epoch: 66
2023-01-05 02:02:01,809 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3794268384575844, 'Total loss': 0.3794268384575844} | train loss {'Reaction outcome loss': 0.17830498317686927, 'Total loss': 0.17830498317686927}
2023-01-05 02:02:01,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:01,809 INFO:     Epoch: 67
2023-01-05 02:02:04,070 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.401235335568587, 'Total loss': 0.401235335568587} | train loss {'Reaction outcome loss': 0.17331705953663598, 'Total loss': 0.17331705953663598}
2023-01-05 02:02:04,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:04,070 INFO:     Epoch: 68
2023-01-05 02:02:06,288 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39417589058478675, 'Total loss': 0.39417589058478675} | train loss {'Reaction outcome loss': 0.17590363660746586, 'Total loss': 0.17590363660746586}
2023-01-05 02:02:06,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:06,288 INFO:     Epoch: 69
2023-01-05 02:02:08,543 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4160744647185008, 'Total loss': 0.4160744647185008} | train loss {'Reaction outcome loss': 0.1768052939977833, 'Total loss': 0.1768052939977833}
2023-01-05 02:02:08,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:08,544 INFO:     Epoch: 70
2023-01-05 02:02:10,806 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.391139821211497, 'Total loss': 0.391139821211497} | train loss {'Reaction outcome loss': 0.17567893185918404, 'Total loss': 0.17567893185918404}
2023-01-05 02:02:10,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:10,806 INFO:     Epoch: 71
2023-01-05 02:02:13,072 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4167598883310954, 'Total loss': 0.4167598883310954} | train loss {'Reaction outcome loss': 0.17406183995293042, 'Total loss': 0.17406183995293042}
2023-01-05 02:02:13,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:13,072 INFO:     Epoch: 72
2023-01-05 02:02:15,266 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3869315927227338, 'Total loss': 0.3869315927227338} | train loss {'Reaction outcome loss': 0.1712286312348253, 'Total loss': 0.1712286312348253}
2023-01-05 02:02:15,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:15,267 INFO:     Epoch: 73
2023-01-05 02:02:17,498 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41822028855482735, 'Total loss': 0.41822028855482735} | train loss {'Reaction outcome loss': 0.17565646647922828, 'Total loss': 0.17565646647922828}
2023-01-05 02:02:17,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:17,498 INFO:     Epoch: 74
2023-01-05 02:02:19,731 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40054314732551577, 'Total loss': 0.40054314732551577} | train loss {'Reaction outcome loss': 0.17218085839194566, 'Total loss': 0.17218085839194566}
2023-01-05 02:02:19,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:19,732 INFO:     Epoch: 75
2023-01-05 02:02:21,991 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42850273847579956, 'Total loss': 0.42850273847579956} | train loss {'Reaction outcome loss': 0.16978736544054823, 'Total loss': 0.16978736544054823}
2023-01-05 02:02:21,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:21,991 INFO:     Epoch: 76
2023-01-05 02:02:24,240 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3894427562753359, 'Total loss': 0.3894427562753359} | train loss {'Reaction outcome loss': 0.1710505940067155, 'Total loss': 0.1710505940067155}
2023-01-05 02:02:24,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:24,240 INFO:     Epoch: 77
2023-01-05 02:02:26,501 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39865126584966976, 'Total loss': 0.39865126584966976} | train loss {'Reaction outcome loss': 0.1712872998852834, 'Total loss': 0.1712872998852834}
2023-01-05 02:02:26,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:26,502 INFO:     Epoch: 78
2023-01-05 02:02:28,725 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39564361597100894, 'Total loss': 0.39564361597100894} | train loss {'Reaction outcome loss': 0.17080592509654993, 'Total loss': 0.17080592509654993}
2023-01-05 02:02:28,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:28,726 INFO:     Epoch: 79
2023-01-05 02:02:30,966 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41006648788849515, 'Total loss': 0.41006648788849515} | train loss {'Reaction outcome loss': 0.1687468185866191, 'Total loss': 0.1687468185866191}
2023-01-05 02:02:30,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:30,967 INFO:     Epoch: 80
2023-01-05 02:02:33,211 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40952523549397785, 'Total loss': 0.40952523549397785} | train loss {'Reaction outcome loss': 0.1713098782696341, 'Total loss': 0.1713098782696341}
2023-01-05 02:02:33,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:33,211 INFO:     Epoch: 81
2023-01-05 02:02:35,475 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39323252340157827, 'Total loss': 0.39323252340157827} | train loss {'Reaction outcome loss': 0.16653934115752417, 'Total loss': 0.16653934115752417}
2023-01-05 02:02:35,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:35,475 INFO:     Epoch: 82
2023-01-05 02:02:37,733 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42162076433499657, 'Total loss': 0.42162076433499657} | train loss {'Reaction outcome loss': 0.16494304296268075, 'Total loss': 0.16494304296268075}
2023-01-05 02:02:37,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:37,733 INFO:     Epoch: 83
2023-01-05 02:02:40,002 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40088251829147337, 'Total loss': 0.40088251829147337} | train loss {'Reaction outcome loss': 0.1622265858579064, 'Total loss': 0.1622265858579064}
2023-01-05 02:02:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:40,003 INFO:     Epoch: 84
2023-01-05 02:02:42,237 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44772241115570066, 'Total loss': 0.44772241115570066} | train loss {'Reaction outcome loss': 0.16448088183945267, 'Total loss': 0.16448088183945267}
2023-01-05 02:02:42,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:42,238 INFO:     Epoch: 85
2023-01-05 02:02:44,501 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40884257256984713, 'Total loss': 0.40884257256984713} | train loss {'Reaction outcome loss': 0.1661244226562444, 'Total loss': 0.1661244226562444}
2023-01-05 02:02:44,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:44,503 INFO:     Epoch: 86
2023-01-05 02:02:46,773 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4112621462593476, 'Total loss': 0.4112621462593476} | train loss {'Reaction outcome loss': 0.16094210347839857, 'Total loss': 0.16094210347839857}
2023-01-05 02:02:46,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:46,774 INFO:     Epoch: 87
2023-01-05 02:02:49,044 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4213568985462189, 'Total loss': 0.4213568985462189} | train loss {'Reaction outcome loss': 0.1676594602576178, 'Total loss': 0.1676594602576178}
2023-01-05 02:02:49,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:49,044 INFO:     Epoch: 88
2023-01-05 02:02:51,267 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3909710275630156, 'Total loss': 0.3909710275630156} | train loss {'Reaction outcome loss': 0.16027174726387466, 'Total loss': 0.16027174726387466}
2023-01-05 02:02:51,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:51,268 INFO:     Epoch: 89
2023-01-05 02:02:53,472 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45502865438659984, 'Total loss': 0.45502865438659984} | train loss {'Reaction outcome loss': 0.16161736921114772, 'Total loss': 0.16161736921114772}
2023-01-05 02:02:53,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:53,472 INFO:     Epoch: 90
2023-01-05 02:02:55,737 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43249888221422833, 'Total loss': 0.43249888221422833} | train loss {'Reaction outcome loss': 0.16109282494815141, 'Total loss': 0.16109282494815141}
2023-01-05 02:02:55,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:55,737 INFO:     Epoch: 91
2023-01-05 02:02:57,920 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4452241112788518, 'Total loss': 0.4452241112788518} | train loss {'Reaction outcome loss': 0.16427734752592466, 'Total loss': 0.16427734752592466}
2023-01-05 02:02:57,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:02:57,920 INFO:     Epoch: 92
2023-01-05 02:03:00,205 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41820854792992274, 'Total loss': 0.41820854792992274} | train loss {'Reaction outcome loss': 0.16092280968384892, 'Total loss': 0.16092280968384892}
2023-01-05 02:03:00,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:00,206 INFO:     Epoch: 93
2023-01-05 02:03:02,452 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4003287797172864, 'Total loss': 0.4003287797172864} | train loss {'Reaction outcome loss': 0.1601159747316761, 'Total loss': 0.1601159747316761}
2023-01-05 02:03:02,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:02,452 INFO:     Epoch: 94
2023-01-05 02:03:04,644 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41754100161294144, 'Total loss': 0.41754100161294144} | train loss {'Reaction outcome loss': 0.161715175406772, 'Total loss': 0.161715175406772}
2023-01-05 02:03:04,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:04,645 INFO:     Epoch: 95
2023-01-05 02:03:06,807 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4511006606121858, 'Total loss': 0.4511006606121858} | train loss {'Reaction outcome loss': 0.16251189763311444, 'Total loss': 0.16251189763311444}
2023-01-05 02:03:06,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:06,807 INFO:     Epoch: 96
2023-01-05 02:03:09,089 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4495123232404391, 'Total loss': 0.4495123232404391} | train loss {'Reaction outcome loss': 0.15985275294450163, 'Total loss': 0.15985275294450163}
2023-01-05 02:03:09,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:09,089 INFO:     Epoch: 97
2023-01-05 02:03:11,382 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42183696031570433, 'Total loss': 0.42183696031570433} | train loss {'Reaction outcome loss': 0.15512662830624716, 'Total loss': 0.15512662830624716}
2023-01-05 02:03:11,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:11,382 INFO:     Epoch: 98
2023-01-05 02:03:13,662 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4548783535758654, 'Total loss': 0.4548783535758654} | train loss {'Reaction outcome loss': 0.15911427484354548, 'Total loss': 0.15911427484354548}
2023-01-05 02:03:13,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:13,662 INFO:     Epoch: 99
2023-01-05 02:03:15,897 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4687793493270874, 'Total loss': 0.4687793493270874} | train loss {'Reaction outcome loss': 0.15762690129599094, 'Total loss': 0.15762690129599094}
2023-01-05 02:03:15,897 INFO:     Best model found after epoch 23 of 100.
2023-01-05 02:03:15,897 INFO:   Done with stage: TRAINING
2023-01-05 02:03:15,897 INFO:   Starting stage: EVALUATION
2023-01-05 02:03:16,044 INFO:   Done with stage: EVALUATION
2023-01-05 02:03:16,044 INFO:   Leaving out SEQ value Fold_9
2023-01-05 02:03:16,059 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:03:16,059 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:03:16,764 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:03:16,764 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:03:16,844 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:03:16,844 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:03:16,844 INFO:     No hyperparam tuning for this model
2023-01-05 02:03:16,844 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:03:16,844 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:03:16,845 INFO:     None feature selector for col prot
2023-01-05 02:03:16,845 INFO:     None feature selector for col prot
2023-01-05 02:03:16,845 INFO:     None feature selector for col prot
2023-01-05 02:03:16,846 INFO:     None feature selector for col chem
2023-01-05 02:03:16,847 INFO:     None feature selector for col chem
2023-01-05 02:03:16,847 INFO:     None feature selector for col chem
2023-01-05 02:03:16,847 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:03:16,847 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:03:16,848 INFO:     Number of params in model 72931
2023-01-05 02:03:16,852 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:03:16,852 INFO:   Starting stage: TRAINING
2023-01-05 02:03:16,915 INFO:     Val loss before train {'Reaction outcome loss': 0.9949678977330526, 'Total loss': 0.9949678977330526}
2023-01-05 02:03:16,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:16,915 INFO:     Epoch: 0
2023-01-05 02:03:19,206 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7776900827884674, 'Total loss': 0.7776900827884674} | train loss {'Reaction outcome loss': 0.9506912465295653, 'Total loss': 0.9506912465295653}
2023-01-05 02:03:19,206 INFO:     Found new best model at epoch 0
2023-01-05 02:03:19,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:19,207 INFO:     Epoch: 1
2023-01-05 02:03:21,512 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.587521864970525, 'Total loss': 0.587521864970525} | train loss {'Reaction outcome loss': 0.6519896550117618, 'Total loss': 0.6519896550117618}
2023-01-05 02:03:21,513 INFO:     Found new best model at epoch 1
2023-01-05 02:03:21,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:21,515 INFO:     Epoch: 2
2023-01-05 02:03:23,826 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5596861183643341, 'Total loss': 0.5596861183643341} | train loss {'Reaction outcome loss': 0.5385116012427058, 'Total loss': 0.5385116012427058}
2023-01-05 02:03:23,826 INFO:     Found new best model at epoch 2
2023-01-05 02:03:23,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:23,829 INFO:     Epoch: 3
2023-01-05 02:03:26,149 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5497477928797404, 'Total loss': 0.5497477928797404} | train loss {'Reaction outcome loss': 0.4965948098658645, 'Total loss': 0.4965948098658645}
2023-01-05 02:03:26,149 INFO:     Found new best model at epoch 3
2023-01-05 02:03:26,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:26,150 INFO:     Epoch: 4
2023-01-05 02:03:28,405 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4836537778377533, 'Total loss': 0.4836537778377533} | train loss {'Reaction outcome loss': 0.46551059368644315, 'Total loss': 0.46551059368644315}
2023-01-05 02:03:28,406 INFO:     Found new best model at epoch 4
2023-01-05 02:03:28,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:28,408 INFO:     Epoch: 5
2023-01-05 02:03:30,659 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4744876742362976, 'Total loss': 0.4744876742362976} | train loss {'Reaction outcome loss': 0.44496767570937634, 'Total loss': 0.44496767570937634}
2023-01-05 02:03:30,659 INFO:     Found new best model at epoch 5
2023-01-05 02:03:30,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:30,661 INFO:     Epoch: 6
2023-01-05 02:03:32,921 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46360990206400554, 'Total loss': 0.46360990206400554} | train loss {'Reaction outcome loss': 0.41928843683461203, 'Total loss': 0.41928843683461203}
2023-01-05 02:03:32,921 INFO:     Found new best model at epoch 6
2023-01-05 02:03:32,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:32,923 INFO:     Epoch: 7
2023-01-05 02:03:35,190 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4617165009180705, 'Total loss': 0.4617165009180705} | train loss {'Reaction outcome loss': 0.4029800729744517, 'Total loss': 0.4029800729744517}
2023-01-05 02:03:35,190 INFO:     Found new best model at epoch 7
2023-01-05 02:03:35,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:35,191 INFO:     Epoch: 8
2023-01-05 02:03:37,441 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4507378081480662, 'Total loss': 0.4507378081480662} | train loss {'Reaction outcome loss': 0.3936144658466325, 'Total loss': 0.3936144658466325}
2023-01-05 02:03:37,442 INFO:     Found new best model at epoch 8
2023-01-05 02:03:37,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:37,443 INFO:     Epoch: 9
2023-01-05 02:03:39,649 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45074647466341655, 'Total loss': 0.45074647466341655} | train loss {'Reaction outcome loss': 0.3783290841936195, 'Total loss': 0.3783290841936195}
2023-01-05 02:03:39,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:39,649 INFO:     Epoch: 10
2023-01-05 02:03:41,876 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42862361868222554, 'Total loss': 0.42862361868222554} | train loss {'Reaction outcome loss': 0.37176949698070105, 'Total loss': 0.37176949698070105}
2023-01-05 02:03:41,877 INFO:     Found new best model at epoch 10
2023-01-05 02:03:41,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:41,879 INFO:     Epoch: 11
2023-01-05 02:03:44,064 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.454219917456309, 'Total loss': 0.454219917456309} | train loss {'Reaction outcome loss': 0.3603990213931912, 'Total loss': 0.3603990213931912}
2023-01-05 02:03:44,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:44,064 INFO:     Epoch: 12
2023-01-05 02:03:46,293 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4165345638990402, 'Total loss': 0.4165345638990402} | train loss {'Reaction outcome loss': 0.34869334960261184, 'Total loss': 0.34869334960261184}
2023-01-05 02:03:46,293 INFO:     Found new best model at epoch 12
2023-01-05 02:03:46,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:46,294 INFO:     Epoch: 13
2023-01-05 02:03:48,538 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4342603117227554, 'Total loss': 0.4342603117227554} | train loss {'Reaction outcome loss': 0.3362490584271668, 'Total loss': 0.3362490584271668}
2023-01-05 02:03:48,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:48,538 INFO:     Epoch: 14
2023-01-05 02:03:50,735 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43425992925961815, 'Total loss': 0.43425992925961815} | train loss {'Reaction outcome loss': 0.3269912391071663, 'Total loss': 0.3269912391071663}
2023-01-05 02:03:50,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:50,736 INFO:     Epoch: 15
2023-01-05 02:03:52,786 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4398363431294759, 'Total loss': 0.4398363431294759} | train loss {'Reaction outcome loss': 0.3189268067044063, 'Total loss': 0.3189268067044063}
2023-01-05 02:03:52,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:52,787 INFO:     Epoch: 16
2023-01-05 02:03:54,990 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4509881019592285, 'Total loss': 0.4509881019592285} | train loss {'Reaction outcome loss': 0.31466420935670825, 'Total loss': 0.31466420935670825}
2023-01-05 02:03:54,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:54,990 INFO:     Epoch: 17
2023-01-05 02:03:57,206 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4200165013472239, 'Total loss': 0.4200165013472239} | train loss {'Reaction outcome loss': 0.30745459456730934, 'Total loss': 0.30745459456730934}
2023-01-05 02:03:57,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:57,207 INFO:     Epoch: 18
2023-01-05 02:03:59,415 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4468433648347855, 'Total loss': 0.4468433648347855} | train loss {'Reaction outcome loss': 0.3020448716642865, 'Total loss': 0.3020448716642865}
2023-01-05 02:03:59,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:03:59,416 INFO:     Epoch: 19
2023-01-05 02:04:01,617 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4477898140748342, 'Total loss': 0.4477898140748342} | train loss {'Reaction outcome loss': 0.2992190535105493, 'Total loss': 0.2992190535105493}
2023-01-05 02:04:01,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:01,617 INFO:     Epoch: 20
2023-01-05 02:04:03,796 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42571530242760974, 'Total loss': 0.42571530242760974} | train loss {'Reaction outcome loss': 0.29139637986510775, 'Total loss': 0.29139637986510775}
2023-01-05 02:04:03,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:03,796 INFO:     Epoch: 21
2023-01-05 02:04:06,039 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4282914698123932, 'Total loss': 0.4282914698123932} | train loss {'Reaction outcome loss': 0.286791284521022, 'Total loss': 0.286791284521022}
2023-01-05 02:04:06,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:06,040 INFO:     Epoch: 22
2023-01-05 02:04:08,293 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4462783714135488, 'Total loss': 0.4462783714135488} | train loss {'Reaction outcome loss': 0.2809723803610371, 'Total loss': 0.2809723803610371}
2023-01-05 02:04:08,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:08,294 INFO:     Epoch: 23
2023-01-05 02:04:10,554 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4385824084281921, 'Total loss': 0.4385824084281921} | train loss {'Reaction outcome loss': 0.2821507609116226, 'Total loss': 0.2821507609116226}
2023-01-05 02:04:10,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:10,555 INFO:     Epoch: 24
2023-01-05 02:04:12,810 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4357656384507815, 'Total loss': 0.4357656384507815} | train loss {'Reaction outcome loss': 0.275343155733099, 'Total loss': 0.275343155733099}
2023-01-05 02:04:12,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:12,810 INFO:     Epoch: 25
2023-01-05 02:04:14,966 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4457540680964788, 'Total loss': 0.4457540680964788} | train loss {'Reaction outcome loss': 0.26902376449782484, 'Total loss': 0.26902376449782484}
2023-01-05 02:04:14,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:14,966 INFO:     Epoch: 26
2023-01-05 02:04:17,206 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49150930245717367, 'Total loss': 0.49150930245717367} | train loss {'Reaction outcome loss': 0.2617465700872623, 'Total loss': 0.2617465700872623}
2023-01-05 02:04:17,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:17,206 INFO:     Epoch: 27
2023-01-05 02:04:19,427 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4444824556509654, 'Total loss': 0.4444824556509654} | train loss {'Reaction outcome loss': 0.2608223520015387, 'Total loss': 0.2608223520015387}
2023-01-05 02:04:19,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:19,427 INFO:     Epoch: 28
2023-01-05 02:04:21,655 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45509432554244994, 'Total loss': 0.45509432554244994} | train loss {'Reaction outcome loss': 0.25866187754746556, 'Total loss': 0.25866187754746556}
2023-01-05 02:04:21,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:21,655 INFO:     Epoch: 29
2023-01-05 02:04:23,908 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4406333456436793, 'Total loss': 0.4406333456436793} | train loss {'Reaction outcome loss': 0.25726188755981677, 'Total loss': 0.25726188755981677}
2023-01-05 02:04:23,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:23,908 INFO:     Epoch: 30
2023-01-05 02:04:26,106 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43103983004887897, 'Total loss': 0.43103983004887897} | train loss {'Reaction outcome loss': 0.248794177057643, 'Total loss': 0.248794177057643}
2023-01-05 02:04:26,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:26,106 INFO:     Epoch: 31
2023-01-05 02:04:28,312 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4053986395398776, 'Total loss': 0.4053986395398776} | train loss {'Reaction outcome loss': 0.2474884953295445, 'Total loss': 0.2474884953295445}
2023-01-05 02:04:28,313 INFO:     Found new best model at epoch 31
2023-01-05 02:04:28,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:28,315 INFO:     Epoch: 32
2023-01-05 02:04:30,556 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44688351452350616, 'Total loss': 0.44688351452350616} | train loss {'Reaction outcome loss': 0.24153738434895547, 'Total loss': 0.24153738434895547}
2023-01-05 02:04:30,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:30,556 INFO:     Epoch: 33
2023-01-05 02:04:32,799 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4477368106444677, 'Total loss': 0.4477368106444677} | train loss {'Reaction outcome loss': 0.2442940357311146, 'Total loss': 0.2442940357311146}
2023-01-05 02:04:32,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:32,799 INFO:     Epoch: 34
2023-01-05 02:04:35,037 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4732243816057841, 'Total loss': 0.4732243816057841} | train loss {'Reaction outcome loss': 0.243942486278604, 'Total loss': 0.243942486278604}
2023-01-05 02:04:35,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:35,038 INFO:     Epoch: 35
2023-01-05 02:04:37,227 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43925100068251294, 'Total loss': 0.43925100068251294} | train loss {'Reaction outcome loss': 0.2353491388315702, 'Total loss': 0.2353491388315702}
2023-01-05 02:04:37,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:37,228 INFO:     Epoch: 36
2023-01-05 02:04:39,460 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44879029045502344, 'Total loss': 0.44879029045502344} | train loss {'Reaction outcome loss': 0.2373523801891473, 'Total loss': 0.2373523801891473}
2023-01-05 02:04:39,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:39,461 INFO:     Epoch: 37
2023-01-05 02:04:41,714 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4278015504280726, 'Total loss': 0.4278015504280726} | train loss {'Reaction outcome loss': 0.22645670703755025, 'Total loss': 0.22645670703755025}
2023-01-05 02:04:41,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:41,714 INFO:     Epoch: 38
2023-01-05 02:04:43,960 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42789116203784944, 'Total loss': 0.42789116203784944} | train loss {'Reaction outcome loss': 0.22350380836856842, 'Total loss': 0.22350380836856842}
2023-01-05 02:04:43,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:43,960 INFO:     Epoch: 39
2023-01-05 02:04:46,214 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44653188387552895, 'Total loss': 0.44653188387552895} | train loss {'Reaction outcome loss': 0.2270689901120852, 'Total loss': 0.2270689901120852}
2023-01-05 02:04:46,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:46,214 INFO:     Epoch: 40
2023-01-05 02:04:48,377 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.462012392282486, 'Total loss': 0.462012392282486} | train loss {'Reaction outcome loss': 0.22969663756335304, 'Total loss': 0.22969663756335304}
2023-01-05 02:04:48,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:48,378 INFO:     Epoch: 41
2023-01-05 02:04:50,620 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.457706107199192, 'Total loss': 0.457706107199192} | train loss {'Reaction outcome loss': 0.2215108915748768, 'Total loss': 0.2215108915748768}
2023-01-05 02:04:50,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:50,620 INFO:     Epoch: 42
2023-01-05 02:04:52,891 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4499718224008878, 'Total loss': 0.4499718224008878} | train loss {'Reaction outcome loss': 0.2261107760875819, 'Total loss': 0.2261107760875819}
2023-01-05 02:04:52,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:52,891 INFO:     Epoch: 43
2023-01-05 02:04:55,103 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45992239465316137, 'Total loss': 0.45992239465316137} | train loss {'Reaction outcome loss': 0.22115525403773806, 'Total loss': 0.22115525403773806}
2023-01-05 02:04:55,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:55,103 INFO:     Epoch: 44
2023-01-05 02:04:57,334 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4603968620300293, 'Total loss': 0.4603968620300293} | train loss {'Reaction outcome loss': 0.21572375459338192, 'Total loss': 0.21572375459338192}
2023-01-05 02:04:57,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:57,336 INFO:     Epoch: 45
2023-01-05 02:04:59,580 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4460796847939491, 'Total loss': 0.4460796847939491} | train loss {'Reaction outcome loss': 0.21936850841870925, 'Total loss': 0.21936850841870925}
2023-01-05 02:04:59,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:04:59,580 INFO:     Epoch: 46
2023-01-05 02:05:01,829 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5071454286575318, 'Total loss': 0.5071454286575318} | train loss {'Reaction outcome loss': 0.21757486075788302, 'Total loss': 0.21757486075788302}
2023-01-05 02:05:01,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:01,830 INFO:     Epoch: 47
2023-01-05 02:05:04,058 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43220213303963345, 'Total loss': 0.43220213303963345} | train loss {'Reaction outcome loss': 0.21258446059604413, 'Total loss': 0.21258446059604413}
2023-01-05 02:05:04,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:04,059 INFO:     Epoch: 48
2023-01-05 02:05:06,312 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4605567624171575, 'Total loss': 0.4605567624171575} | train loss {'Reaction outcome loss': 0.20939493047100674, 'Total loss': 0.20939493047100674}
2023-01-05 02:05:06,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:06,312 INFO:     Epoch: 49
2023-01-05 02:05:08,531 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4543373703956604, 'Total loss': 0.4543373703956604} | train loss {'Reaction outcome loss': 0.2140194099994689, 'Total loss': 0.2140194099994689}
2023-01-05 02:05:08,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:08,532 INFO:     Epoch: 50
2023-01-05 02:05:10,783 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44729284395774205, 'Total loss': 0.44729284395774205} | train loss {'Reaction outcome loss': 0.21020576677346317, 'Total loss': 0.21020576677346317}
2023-01-05 02:05:10,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:10,783 INFO:     Epoch: 51
2023-01-05 02:05:13,000 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4523856431245804, 'Total loss': 0.4523856431245804} | train loss {'Reaction outcome loss': 0.20997739800789061, 'Total loss': 0.20997739800789061}
2023-01-05 02:05:13,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:13,001 INFO:     Epoch: 52
2023-01-05 02:05:15,223 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43761434853076936, 'Total loss': 0.43761434853076936} | train loss {'Reaction outcome loss': 0.20263082038502406, 'Total loss': 0.20263082038502406}
2023-01-05 02:05:15,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:15,223 INFO:     Epoch: 53
2023-01-05 02:05:17,432 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45077487466235955, 'Total loss': 0.45077487466235955} | train loss {'Reaction outcome loss': 0.20132066430116113, 'Total loss': 0.20132066430116113}
2023-01-05 02:05:17,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:17,433 INFO:     Epoch: 54
2023-01-05 02:05:19,685 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4727495531241099, 'Total loss': 0.4727495531241099} | train loss {'Reaction outcome loss': 0.2097288479715803, 'Total loss': 0.2097288479715803}
2023-01-05 02:05:19,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:19,685 INFO:     Epoch: 55
2023-01-05 02:05:21,901 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4471069544553757, 'Total loss': 0.4471069544553757} | train loss {'Reaction outcome loss': 0.2045825306618464, 'Total loss': 0.2045825306618464}
2023-01-05 02:05:21,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:21,901 INFO:     Epoch: 56
2023-01-05 02:05:24,127 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4602373749017715, 'Total loss': 0.4602373749017715} | train loss {'Reaction outcome loss': 0.19537388138901307, 'Total loss': 0.19537388138901307}
2023-01-05 02:05:24,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:24,127 INFO:     Epoch: 57
2023-01-05 02:05:26,362 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46590316394964854, 'Total loss': 0.46590316394964854} | train loss {'Reaction outcome loss': 0.20029187503943804, 'Total loss': 0.20029187503943804}
2023-01-05 02:05:26,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:26,363 INFO:     Epoch: 58
2023-01-05 02:05:28,542 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4616621345281601, 'Total loss': 0.4616621345281601} | train loss {'Reaction outcome loss': 0.19481161376801284, 'Total loss': 0.19481161376801284}
2023-01-05 02:05:28,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:28,542 INFO:     Epoch: 59
2023-01-05 02:05:30,797 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47122909426689147, 'Total loss': 0.47122909426689147} | train loss {'Reaction outcome loss': 0.19365672339909595, 'Total loss': 0.19365672339909595}
2023-01-05 02:05:30,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:30,797 INFO:     Epoch: 60
2023-01-05 02:05:33,074 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4562269906202952, 'Total loss': 0.4562269906202952} | train loss {'Reaction outcome loss': 0.19537781967176465, 'Total loss': 0.19537781967176465}
2023-01-05 02:05:33,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:33,075 INFO:     Epoch: 61
2023-01-05 02:05:35,347 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46272053718566897, 'Total loss': 0.46272053718566897} | train loss {'Reaction outcome loss': 0.1966653867101256, 'Total loss': 0.1966653867101256}
2023-01-05 02:05:35,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:35,347 INFO:     Epoch: 62
2023-01-05 02:05:37,596 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42938884695370994, 'Total loss': 0.42938884695370994} | train loss {'Reaction outcome loss': 0.19267636961745518, 'Total loss': 0.19267636961745518}
2023-01-05 02:05:37,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:37,596 INFO:     Epoch: 63
2023-01-05 02:05:39,881 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4689314916729927, 'Total loss': 0.4689314916729927} | train loss {'Reaction outcome loss': 0.19016464492883942, 'Total loss': 0.19016464492883942}
2023-01-05 02:05:39,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:39,882 INFO:     Epoch: 64
2023-01-05 02:05:42,149 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45150126665830614, 'Total loss': 0.45150126665830614} | train loss {'Reaction outcome loss': 0.1975025583507262, 'Total loss': 0.1975025583507262}
2023-01-05 02:05:42,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:42,149 INFO:     Epoch: 65
2023-01-05 02:05:44,408 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4568336586157481, 'Total loss': 0.4568336586157481} | train loss {'Reaction outcome loss': 0.19342271546853612, 'Total loss': 0.19342271546853612}
2023-01-05 02:05:44,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:44,409 INFO:     Epoch: 66
2023-01-05 02:05:46,588 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4654914091030757, 'Total loss': 0.4654914091030757} | train loss {'Reaction outcome loss': 0.18679502177099785, 'Total loss': 0.18679502177099785}
2023-01-05 02:05:46,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:46,589 INFO:     Epoch: 67
2023-01-05 02:05:48,777 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4607693319519361, 'Total loss': 0.4607693319519361} | train loss {'Reaction outcome loss': 0.186392182249739, 'Total loss': 0.186392182249739}
2023-01-05 02:05:48,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:48,777 INFO:     Epoch: 68
2023-01-05 02:05:50,986 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45913720528284707, 'Total loss': 0.45913720528284707} | train loss {'Reaction outcome loss': 0.18996665912959046, 'Total loss': 0.18996665912959046}
2023-01-05 02:05:50,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:50,987 INFO:     Epoch: 69
2023-01-05 02:05:53,168 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44015017251173655, 'Total loss': 0.44015017251173655} | train loss {'Reaction outcome loss': 0.18663657945240883, 'Total loss': 0.18663657945240883}
2023-01-05 02:05:53,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:53,169 INFO:     Epoch: 70
2023-01-05 02:05:55,382 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46098442549506824, 'Total loss': 0.46098442549506824} | train loss {'Reaction outcome loss': 0.1860896204904157, 'Total loss': 0.1860896204904157}
2023-01-05 02:05:55,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:55,382 INFO:     Epoch: 71
2023-01-05 02:05:57,586 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44753772715727486, 'Total loss': 0.44753772715727486} | train loss {'Reaction outcome loss': 0.18272629360512008, 'Total loss': 0.18272629360512008}
2023-01-05 02:05:57,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:57,587 INFO:     Epoch: 72
2023-01-05 02:05:59,767 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42420998265345894, 'Total loss': 0.42420998265345894} | train loss {'Reaction outcome loss': 0.18585982001012694, 'Total loss': 0.18585982001012694}
2023-01-05 02:05:59,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:05:59,767 INFO:     Epoch: 73
2023-01-05 02:06:01,964 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4706637392441432, 'Total loss': 0.4706637392441432} | train loss {'Reaction outcome loss': 0.18408170323750941, 'Total loss': 0.18408170323750941}
2023-01-05 02:06:01,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:01,964 INFO:     Epoch: 74
2023-01-05 02:06:04,173 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4559118241071701, 'Total loss': 0.4559118241071701} | train loss {'Reaction outcome loss': 0.18079542338739346, 'Total loss': 0.18079542338739346}
2023-01-05 02:06:04,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:04,174 INFO:     Epoch: 75
2023-01-05 02:06:06,357 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45530335505803426, 'Total loss': 0.45530335505803426} | train loss {'Reaction outcome loss': 0.18323475983245366, 'Total loss': 0.18323475983245366}
2023-01-05 02:06:06,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:06,357 INFO:     Epoch: 76
2023-01-05 02:06:08,605 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45604851047197975, 'Total loss': 0.45604851047197975} | train loss {'Reaction outcome loss': 0.18121532063904036, 'Total loss': 0.18121532063904036}
2023-01-05 02:06:08,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:08,606 INFO:     Epoch: 77
2023-01-05 02:06:10,872 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46899711390336357, 'Total loss': 0.46899711390336357} | train loss {'Reaction outcome loss': 0.18259207060370242, 'Total loss': 0.18259207060370242}
2023-01-05 02:06:10,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:10,872 INFO:     Epoch: 78
2023-01-05 02:06:13,118 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4706142028172811, 'Total loss': 0.4706142028172811} | train loss {'Reaction outcome loss': 0.17680594157835428, 'Total loss': 0.17680594157835428}
2023-01-05 02:06:13,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:13,119 INFO:     Epoch: 79
2023-01-05 02:06:15,361 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4500546485185623, 'Total loss': 0.4500546485185623} | train loss {'Reaction outcome loss': 0.18307864188597314, 'Total loss': 0.18307864188597314}
2023-01-05 02:06:15,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:15,362 INFO:     Epoch: 80
2023-01-05 02:06:17,598 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4741102079550425, 'Total loss': 0.4741102079550425} | train loss {'Reaction outcome loss': 0.17917972391838358, 'Total loss': 0.17917972391838358}
2023-01-05 02:06:17,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:17,598 INFO:     Epoch: 81
2023-01-05 02:06:19,736 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45850525895754496, 'Total loss': 0.45850525895754496} | train loss {'Reaction outcome loss': 0.180350769487937, 'Total loss': 0.180350769487937}
2023-01-05 02:06:19,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:19,736 INFO:     Epoch: 82
2023-01-05 02:06:21,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4660580774148305, 'Total loss': 0.4660580774148305} | train loss {'Reaction outcome loss': 0.1764289236416782, 'Total loss': 0.1764289236416782}
2023-01-05 02:06:21,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:21,978 INFO:     Epoch: 83
2023-01-05 02:06:24,163 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47764405806859334, 'Total loss': 0.47764405806859334} | train loss {'Reaction outcome loss': 0.17444761734741338, 'Total loss': 0.17444761734741338}
2023-01-05 02:06:24,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:24,163 INFO:     Epoch: 84
2023-01-05 02:06:26,336 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.452744064728419, 'Total loss': 0.452744064728419} | train loss {'Reaction outcome loss': 0.17283987676738388, 'Total loss': 0.17283987676738388}
2023-01-05 02:06:26,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:26,336 INFO:     Epoch: 85
2023-01-05 02:06:28,489 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4796246538559596, 'Total loss': 0.4796246538559596} | train loss {'Reaction outcome loss': 0.17195899153712893, 'Total loss': 0.17195899153712893}
2023-01-05 02:06:28,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:28,490 INFO:     Epoch: 86
2023-01-05 02:06:30,742 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4837663650512695, 'Total loss': 0.4837663650512695} | train loss {'Reaction outcome loss': 0.17551806703359432, 'Total loss': 0.17551806703359432}
2023-01-05 02:06:30,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:30,743 INFO:     Epoch: 87
2023-01-05 02:06:32,870 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4721726734812061, 'Total loss': 0.4721726734812061} | train loss {'Reaction outcome loss': 0.17358027392298148, 'Total loss': 0.17358027392298148}
2023-01-05 02:06:32,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:32,870 INFO:     Epoch: 88
2023-01-05 02:06:35,091 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4852247218290965, 'Total loss': 0.4852247218290965} | train loss {'Reaction outcome loss': 0.17624835902994948, 'Total loss': 0.17624835902994948}
2023-01-05 02:06:35,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:35,091 INFO:     Epoch: 89
2023-01-05 02:06:37,280 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4627347975969315, 'Total loss': 0.4627347975969315} | train loss {'Reaction outcome loss': 0.17460629018363508, 'Total loss': 0.17460629018363508}
2023-01-05 02:06:37,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:37,280 INFO:     Epoch: 90
2023-01-05 02:06:39,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49446684022744497, 'Total loss': 0.49446684022744497} | train loss {'Reaction outcome loss': 0.1771766720033747, 'Total loss': 0.1771766720033747}
2023-01-05 02:06:39,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:39,408 INFO:     Epoch: 91
2023-01-05 02:06:41,617 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4544572774320841, 'Total loss': 0.4544572774320841} | train loss {'Reaction outcome loss': 0.17090420011281424, 'Total loss': 0.17090420011281424}
2023-01-05 02:06:41,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:41,617 INFO:     Epoch: 92
2023-01-05 02:06:43,753 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44119263216853144, 'Total loss': 0.44119263216853144} | train loss {'Reaction outcome loss': 0.17068097697924414, 'Total loss': 0.17068097697924414}
2023-01-05 02:06:43,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:43,753 INFO:     Epoch: 93
2023-01-05 02:06:45,931 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4594841589530309, 'Total loss': 0.4594841589530309} | train loss {'Reaction outcome loss': 0.16874076275963906, 'Total loss': 0.16874076275963906}
2023-01-05 02:06:45,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:45,932 INFO:     Epoch: 94
2023-01-05 02:06:48,142 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45948848525683084, 'Total loss': 0.45948848525683084} | train loss {'Reaction outcome loss': 0.16814634761854624, 'Total loss': 0.16814634761854624}
2023-01-05 02:06:48,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:48,142 INFO:     Epoch: 95
2023-01-05 02:06:50,354 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4965469340483348, 'Total loss': 0.4965469340483348} | train loss {'Reaction outcome loss': 0.16960767753945705, 'Total loss': 0.16960767753945705}
2023-01-05 02:06:50,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:50,354 INFO:     Epoch: 96
2023-01-05 02:06:52,529 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5324811061223348, 'Total loss': 0.5324811061223348} | train loss {'Reaction outcome loss': 0.16611556207462058, 'Total loss': 0.16611556207462058}
2023-01-05 02:06:52,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:52,530 INFO:     Epoch: 97
2023-01-05 02:06:54,740 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48245191673437754, 'Total loss': 0.48245191673437754} | train loss {'Reaction outcome loss': 0.17063681435614933, 'Total loss': 0.17063681435614933}
2023-01-05 02:06:54,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:54,741 INFO:     Epoch: 98
2023-01-05 02:06:56,948 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4711326628923416, 'Total loss': 0.4711326628923416} | train loss {'Reaction outcome loss': 0.1627428416777946, 'Total loss': 0.1627428416777946}
2023-01-05 02:06:56,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:06:56,948 INFO:     Epoch: 99
2023-01-05 02:06:59,188 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4828673839569092, 'Total loss': 0.4828673839569092} | train loss {'Reaction outcome loss': 0.16720833033527227, 'Total loss': 0.16720833033527227}
2023-01-05 02:06:59,189 INFO:     Best model found after epoch 32 of 100.
2023-01-05 02:06:59,189 INFO:   Done with stage: TRAINING
2023-01-05 02:06:59,189 INFO:   Starting stage: EVALUATION
2023-01-05 02:06:59,329 INFO:   Done with stage: EVALUATION
2023-01-05 02:06:59,337 INFO:   Leaving out SEQ value Fold_0
2023-01-05 02:06:59,350 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 02:06:59,350 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:06:59,990 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:06:59,990 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:07:00,058 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:07:00,058 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:07:00,059 INFO:     No hyperparam tuning for this model
2023-01-05 02:07:00,059 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:07:00,059 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:07:00,059 INFO:     None feature selector for col prot
2023-01-05 02:07:00,059 INFO:     None feature selector for col prot
2023-01-05 02:07:00,060 INFO:     None feature selector for col prot
2023-01-05 02:07:00,060 INFO:     None feature selector for col chem
2023-01-05 02:07:00,060 INFO:     None feature selector for col chem
2023-01-05 02:07:00,060 INFO:     None feature selector for col chem
2023-01-05 02:07:00,060 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:07:00,060 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:07:00,062 INFO:     Number of params in model 72931
2023-01-05 02:07:00,065 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:07:00,065 INFO:   Starting stage: TRAINING
2023-01-05 02:07:00,126 INFO:     Val loss before train {'Reaction outcome loss': 1.0367039640744526, 'Total loss': 1.0367039640744526}
2023-01-05 02:07:00,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:00,126 INFO:     Epoch: 0
2023-01-05 02:07:02,351 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7877770801385243, 'Total loss': 0.7877770801385243} | train loss {'Reaction outcome loss': 0.9250627024160637, 'Total loss': 0.9250627024160637}
2023-01-05 02:07:02,351 INFO:     Found new best model at epoch 0
2023-01-05 02:07:02,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:02,352 INFO:     Epoch: 1
2023-01-05 02:07:04,547 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.650874278942744, 'Total loss': 0.650874278942744} | train loss {'Reaction outcome loss': 0.6308667005855085, 'Total loss': 0.6308667005855085}
2023-01-05 02:07:04,548 INFO:     Found new best model at epoch 1
2023-01-05 02:07:04,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:04,549 INFO:     Epoch: 2
2023-01-05 02:07:06,772 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.59883833527565, 'Total loss': 0.59883833527565} | train loss {'Reaction outcome loss': 0.5405132872608555, 'Total loss': 0.5405132872608555}
2023-01-05 02:07:06,772 INFO:     Found new best model at epoch 2
2023-01-05 02:07:06,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:06,774 INFO:     Epoch: 3
2023-01-05 02:07:08,991 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5490266780058543, 'Total loss': 0.5490266780058543} | train loss {'Reaction outcome loss': 0.5002759884729053, 'Total loss': 0.5002759884729053}
2023-01-05 02:07:08,991 INFO:     Found new best model at epoch 3
2023-01-05 02:07:08,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:08,993 INFO:     Epoch: 4
2023-01-05 02:07:11,208 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5250190993150076, 'Total loss': 0.5250190993150076} | train loss {'Reaction outcome loss': 0.4687465054866595, 'Total loss': 0.4687465054866595}
2023-01-05 02:07:11,209 INFO:     Found new best model at epoch 4
2023-01-05 02:07:11,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:11,210 INFO:     Epoch: 5
2023-01-05 02:07:13,444 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5502876102924347, 'Total loss': 0.5502876102924347} | train loss {'Reaction outcome loss': 0.4501257292626105, 'Total loss': 0.4501257292626105}
2023-01-05 02:07:13,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:13,444 INFO:     Epoch: 6
2023-01-05 02:07:15,694 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5084066947301229, 'Total loss': 0.5084066947301229} | train loss {'Reaction outcome loss': 0.4351607648717178, 'Total loss': 0.4351607648717178}
2023-01-05 02:07:15,695 INFO:     Found new best model at epoch 6
2023-01-05 02:07:15,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:15,696 INFO:     Epoch: 7
2023-01-05 02:07:17,921 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.511212154229482, 'Total loss': 0.511212154229482} | train loss {'Reaction outcome loss': 0.4174677497083014, 'Total loss': 0.4174677497083014}
2023-01-05 02:07:17,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:17,921 INFO:     Epoch: 8
2023-01-05 02:07:20,153 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5035719811916352, 'Total loss': 0.5035719811916352} | train loss {'Reaction outcome loss': 0.4060216677876619, 'Total loss': 0.4060216677876619}
2023-01-05 02:07:20,153 INFO:     Found new best model at epoch 8
2023-01-05 02:07:20,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:20,154 INFO:     Epoch: 9
2023-01-05 02:07:22,374 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48654304643472035, 'Total loss': 0.48654304643472035} | train loss {'Reaction outcome loss': 0.3964844196761921, 'Total loss': 0.3964844196761921}
2023-01-05 02:07:22,374 INFO:     Found new best model at epoch 9
2023-01-05 02:07:22,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:22,376 INFO:     Epoch: 10
2023-01-05 02:07:24,558 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4679649531841278, 'Total loss': 0.4679649531841278} | train loss {'Reaction outcome loss': 0.3823557424294206, 'Total loss': 0.3823557424294206}
2023-01-05 02:07:24,558 INFO:     Found new best model at epoch 10
2023-01-05 02:07:24,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:24,560 INFO:     Epoch: 11
2023-01-05 02:07:26,791 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47208005686601, 'Total loss': 0.47208005686601} | train loss {'Reaction outcome loss': 0.3660435522650624, 'Total loss': 0.3660435522650624}
2023-01-05 02:07:26,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:26,791 INFO:     Epoch: 12
2023-01-05 02:07:29,006 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4547547042369843, 'Total loss': 0.4547547042369843} | train loss {'Reaction outcome loss': 0.3590082069074278, 'Total loss': 0.3590082069074278}
2023-01-05 02:07:29,007 INFO:     Found new best model at epoch 12
2023-01-05 02:07:29,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:29,008 INFO:     Epoch: 13
2023-01-05 02:07:31,234 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5044919709364574, 'Total loss': 0.5044919709364574} | train loss {'Reaction outcome loss': 0.34866025347958557, 'Total loss': 0.34866025347958557}
2023-01-05 02:07:31,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:31,234 INFO:     Epoch: 14
2023-01-05 02:07:33,448 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4714418202638626, 'Total loss': 0.4714418202638626} | train loss {'Reaction outcome loss': 0.34360202538333967, 'Total loss': 0.34360202538333967}
2023-01-05 02:07:33,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:33,449 INFO:     Epoch: 15
2023-01-05 02:07:35,671 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4647128979365031, 'Total loss': 0.4647128979365031} | train loss {'Reaction outcome loss': 0.33092497821365086, 'Total loss': 0.33092497821365086}
2023-01-05 02:07:35,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:35,672 INFO:     Epoch: 16
2023-01-05 02:07:37,908 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45908093452453613, 'Total loss': 0.45908093452453613} | train loss {'Reaction outcome loss': 0.32482509911333246, 'Total loss': 0.32482509911333246}
2023-01-05 02:07:37,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:37,908 INFO:     Epoch: 17
2023-01-05 02:07:40,089 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4714177389939626, 'Total loss': 0.4714177389939626} | train loss {'Reaction outcome loss': 0.3201709270695627, 'Total loss': 0.3201709270695627}
2023-01-05 02:07:40,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:40,089 INFO:     Epoch: 18
2023-01-05 02:07:42,324 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48277584513028465, 'Total loss': 0.48277584513028465} | train loss {'Reaction outcome loss': 0.31018891923074976, 'Total loss': 0.31018891923074976}
2023-01-05 02:07:42,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:42,324 INFO:     Epoch: 19
2023-01-05 02:07:44,535 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4609963854153951, 'Total loss': 0.4609963854153951} | train loss {'Reaction outcome loss': 0.30725245150454317, 'Total loss': 0.30725245150454317}
2023-01-05 02:07:44,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:44,535 INFO:     Epoch: 20
2023-01-05 02:07:46,726 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4781915545463562, 'Total loss': 0.4781915545463562} | train loss {'Reaction outcome loss': 0.30263355914708023, 'Total loss': 0.30263355914708023}
2023-01-05 02:07:46,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:46,726 INFO:     Epoch: 21
2023-01-05 02:07:48,949 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44931789139906564, 'Total loss': 0.44931789139906564} | train loss {'Reaction outcome loss': 0.29635077193652315, 'Total loss': 0.29635077193652315}
2023-01-05 02:07:48,949 INFO:     Found new best model at epoch 21
2023-01-05 02:07:48,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:48,950 INFO:     Epoch: 22
2023-01-05 02:07:51,181 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44080719351768494, 'Total loss': 0.44080719351768494} | train loss {'Reaction outcome loss': 0.28952392624629725, 'Total loss': 0.28952392624629725}
2023-01-05 02:07:51,182 INFO:     Found new best model at epoch 22
2023-01-05 02:07:51,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:51,183 INFO:     Epoch: 23
2023-01-05 02:07:53,369 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4424264381329219, 'Total loss': 0.4424264381329219} | train loss {'Reaction outcome loss': 0.287667444924186, 'Total loss': 0.287667444924186}
2023-01-05 02:07:53,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:53,370 INFO:     Epoch: 24
2023-01-05 02:07:55,539 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49198441207408905, 'Total loss': 0.49198441207408905} | train loss {'Reaction outcome loss': 0.28083710190959466, 'Total loss': 0.28083710190959466}
2023-01-05 02:07:55,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:55,540 INFO:     Epoch: 25
2023-01-05 02:07:57,761 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4514381349086761, 'Total loss': 0.4514381349086761} | train loss {'Reaction outcome loss': 0.27638001453418, 'Total loss': 0.27638001453418}
2023-01-05 02:07:57,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:57,762 INFO:     Epoch: 26
2023-01-05 02:07:59,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46701477964719135, 'Total loss': 0.46701477964719135} | train loss {'Reaction outcome loss': 0.27288497679426776, 'Total loss': 0.27288497679426776}
2023-01-05 02:07:59,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:07:59,745 INFO:     Epoch: 27
2023-01-05 02:08:01,970 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4902825822432836, 'Total loss': 0.4902825822432836} | train loss {'Reaction outcome loss': 0.26944792393472167, 'Total loss': 0.26944792393472167}
2023-01-05 02:08:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:01,970 INFO:     Epoch: 28
2023-01-05 02:08:04,190 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4375703603029251, 'Total loss': 0.4375703603029251} | train loss {'Reaction outcome loss': 0.2627149175975349, 'Total loss': 0.2627149175975349}
2023-01-05 02:08:04,190 INFO:     Found new best model at epoch 28
2023-01-05 02:08:04,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:04,191 INFO:     Epoch: 29
2023-01-05 02:08:06,417 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4996374527613322, 'Total loss': 0.4996374527613322} | train loss {'Reaction outcome loss': 0.25893986962339927, 'Total loss': 0.25893986962339927}
2023-01-05 02:08:06,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:06,417 INFO:     Epoch: 30
2023-01-05 02:08:08,660 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46100086470444995, 'Total loss': 0.46100086470444995} | train loss {'Reaction outcome loss': 0.25552326068964415, 'Total loss': 0.25552326068964415}
2023-01-05 02:08:08,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:08,661 INFO:     Epoch: 31
2023-01-05 02:08:10,872 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4758678416411082, 'Total loss': 0.4758678416411082} | train loss {'Reaction outcome loss': 0.250485938717867, 'Total loss': 0.250485938717867}
2023-01-05 02:08:10,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:10,873 INFO:     Epoch: 32
2023-01-05 02:08:13,069 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43682109415531156, 'Total loss': 0.43682109415531156} | train loss {'Reaction outcome loss': 0.2482385033223055, 'Total loss': 0.2482385033223055}
2023-01-05 02:08:13,069 INFO:     Found new best model at epoch 32
2023-01-05 02:08:13,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:13,071 INFO:     Epoch: 33
2023-01-05 02:08:15,310 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44236728399991987, 'Total loss': 0.44236728399991987} | train loss {'Reaction outcome loss': 0.2475095032765479, 'Total loss': 0.2475095032765479}
2023-01-05 02:08:15,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:15,310 INFO:     Epoch: 34
2023-01-05 02:08:17,521 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46572895447413126, 'Total loss': 0.46572895447413126} | train loss {'Reaction outcome loss': 0.24025071227424966, 'Total loss': 0.24025071227424966}
2023-01-05 02:08:17,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:17,522 INFO:     Epoch: 35
2023-01-05 02:08:19,760 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4497548242410024, 'Total loss': 0.4497548242410024} | train loss {'Reaction outcome loss': 0.24620383145499142, 'Total loss': 0.24620383145499142}
2023-01-05 02:08:19,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:19,760 INFO:     Epoch: 36
2023-01-05 02:08:21,974 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4487070699532827, 'Total loss': 0.4487070699532827} | train loss {'Reaction outcome loss': 0.2408875598957687, 'Total loss': 0.2408875598957687}
2023-01-05 02:08:21,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:21,974 INFO:     Epoch: 37
2023-01-05 02:08:24,237 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4412643015384674, 'Total loss': 0.4412643015384674} | train loss {'Reaction outcome loss': 0.24210649929367578, 'Total loss': 0.24210649929367578}
2023-01-05 02:08:24,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:24,237 INFO:     Epoch: 38
2023-01-05 02:08:26,505 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5035131692886352, 'Total loss': 0.5035131692886352} | train loss {'Reaction outcome loss': 0.23239897346915506, 'Total loss': 0.23239897346915506}
2023-01-05 02:08:26,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:26,505 INFO:     Epoch: 39
2023-01-05 02:08:28,728 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4827914590636889, 'Total loss': 0.4827914590636889} | train loss {'Reaction outcome loss': 0.22848455730020564, 'Total loss': 0.22848455730020564}
2023-01-05 02:08:28,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:28,729 INFO:     Epoch: 40
2023-01-05 02:08:30,989 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4372263332207998, 'Total loss': 0.4372263332207998} | train loss {'Reaction outcome loss': 0.22955532207054805, 'Total loss': 0.22955532207054805}
2023-01-05 02:08:30,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:30,989 INFO:     Epoch: 41
2023-01-05 02:08:33,217 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49040234088897705, 'Total loss': 0.49040234088897705} | train loss {'Reaction outcome loss': 0.2258566334986916, 'Total loss': 0.2258566334986916}
2023-01-05 02:08:33,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:33,217 INFO:     Epoch: 42
2023-01-05 02:08:35,468 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4463799734910329, 'Total loss': 0.4463799734910329} | train loss {'Reaction outcome loss': 0.2201474936160467, 'Total loss': 0.2201474936160467}
2023-01-05 02:08:35,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:35,469 INFO:     Epoch: 43
2023-01-05 02:08:37,635 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4716840441028277, 'Total loss': 0.4716840441028277} | train loss {'Reaction outcome loss': 0.21853783986814349, 'Total loss': 0.21853783986814349}
2023-01-05 02:08:37,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:37,636 INFO:     Epoch: 44
2023-01-05 02:08:39,861 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48019709388415016, 'Total loss': 0.48019709388415016} | train loss {'Reaction outcome loss': 0.21895433228885952, 'Total loss': 0.21895433228885952}
2023-01-05 02:08:39,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:39,861 INFO:     Epoch: 45
2023-01-05 02:08:42,099 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4542327016592026, 'Total loss': 0.4542327016592026} | train loss {'Reaction outcome loss': 0.217599454987453, 'Total loss': 0.217599454987453}
2023-01-05 02:08:42,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:42,099 INFO:     Epoch: 46
2023-01-05 02:08:44,290 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4659949541091919, 'Total loss': 0.4659949541091919} | train loss {'Reaction outcome loss': 0.21519961326140843, 'Total loss': 0.21519961326140843}
2023-01-05 02:08:44,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:44,291 INFO:     Epoch: 47
2023-01-05 02:08:46,516 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.472969114780426, 'Total loss': 0.472969114780426} | train loss {'Reaction outcome loss': 0.20937502836286612, 'Total loss': 0.20937502836286612}
2023-01-05 02:08:46,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:46,516 INFO:     Epoch: 48
2023-01-05 02:08:48,668 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48230143785476687, 'Total loss': 0.48230143785476687} | train loss {'Reaction outcome loss': 0.20696345938799474, 'Total loss': 0.20696345938799474}
2023-01-05 02:08:48,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:48,668 INFO:     Epoch: 49
2023-01-05 02:08:50,909 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49519176681836446, 'Total loss': 0.49519176681836446} | train loss {'Reaction outcome loss': 0.2043068058372581, 'Total loss': 0.2043068058372581}
2023-01-05 02:08:50,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:50,909 INFO:     Epoch: 50
2023-01-05 02:08:53,109 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4755698134501775, 'Total loss': 0.4755698134501775} | train loss {'Reaction outcome loss': 0.2036362942001158, 'Total loss': 0.2036362942001158}
2023-01-05 02:08:53,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:53,109 INFO:     Epoch: 51
2023-01-05 02:08:55,333 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49443749388058983, 'Total loss': 0.49443749388058983} | train loss {'Reaction outcome loss': 0.20352097085571333, 'Total loss': 0.20352097085571333}
2023-01-05 02:08:55,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:55,334 INFO:     Epoch: 52
2023-01-05 02:08:57,546 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4806460519631704, 'Total loss': 0.4806460519631704} | train loss {'Reaction outcome loss': 0.19992173399482838, 'Total loss': 0.19992173399482838}
2023-01-05 02:08:57,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:57,547 INFO:     Epoch: 53
2023-01-05 02:08:59,779 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4717863986889521, 'Total loss': 0.4717863986889521} | train loss {'Reaction outcome loss': 0.20120491741750485, 'Total loss': 0.20120491741750485}
2023-01-05 02:08:59,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:08:59,781 INFO:     Epoch: 54
2023-01-05 02:09:02,010 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47360208034515383, 'Total loss': 0.47360208034515383} | train loss {'Reaction outcome loss': 0.1995757703700072, 'Total loss': 0.1995757703700072}
2023-01-05 02:09:02,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:02,011 INFO:     Epoch: 55
2023-01-05 02:09:04,223 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48444139361381533, 'Total loss': 0.48444139361381533} | train loss {'Reaction outcome loss': 0.19520387305168524, 'Total loss': 0.19520387305168524}
2023-01-05 02:09:04,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:04,223 INFO:     Epoch: 56
2023-01-05 02:09:06,435 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5352911402781805, 'Total loss': 0.5352911402781805} | train loss {'Reaction outcome loss': 0.19181812405518014, 'Total loss': 0.19181812405518014}
2023-01-05 02:09:06,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:06,436 INFO:     Epoch: 57
2023-01-05 02:09:08,623 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47516198952992755, 'Total loss': 0.47516198952992755} | train loss {'Reaction outcome loss': 0.1942261031729889, 'Total loss': 0.1942261031729889}
2023-01-05 02:09:08,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:08,624 INFO:     Epoch: 58
2023-01-05 02:09:10,806 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47090002298355105, 'Total loss': 0.47090002298355105} | train loss {'Reaction outcome loss': 0.1897264881803221, 'Total loss': 0.1897264881803221}
2023-01-05 02:09:10,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:10,806 INFO:     Epoch: 59
2023-01-05 02:09:12,918 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45418364045520626, 'Total loss': 0.45418364045520626} | train loss {'Reaction outcome loss': 0.1881462798552799, 'Total loss': 0.1881462798552799}
2023-01-05 02:09:12,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:12,919 INFO:     Epoch: 60
2023-01-05 02:09:15,142 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.475240495800972, 'Total loss': 0.475240495800972} | train loss {'Reaction outcome loss': 0.19368171018135527, 'Total loss': 0.19368171018135527}
2023-01-05 02:09:15,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:15,143 INFO:     Epoch: 61
2023-01-05 02:09:17,384 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5276124755541484, 'Total loss': 0.5276124755541484} | train loss {'Reaction outcome loss': 0.19099831729172131, 'Total loss': 0.19099831729172131}
2023-01-05 02:09:17,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:17,385 INFO:     Epoch: 62
2023-01-05 02:09:19,616 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5077339073022207, 'Total loss': 0.5077339073022207} | train loss {'Reaction outcome loss': 0.18959038172449386, 'Total loss': 0.18959038172449386}
2023-01-05 02:09:19,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:19,617 INFO:     Epoch: 63
2023-01-05 02:09:21,839 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4892499844233195, 'Total loss': 0.4892499844233195} | train loss {'Reaction outcome loss': 0.18372708387440922, 'Total loss': 0.18372708387440922}
2023-01-05 02:09:21,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:21,839 INFO:     Epoch: 64
2023-01-05 02:09:24,073 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5215553055206935, 'Total loss': 0.5215553055206935} | train loss {'Reaction outcome loss': 0.1826973415522294, 'Total loss': 0.1826973415522294}
2023-01-05 02:09:24,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:24,073 INFO:     Epoch: 65
2023-01-05 02:09:26,293 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46928878178199135, 'Total loss': 0.46928878178199135} | train loss {'Reaction outcome loss': 0.19117876996999203, 'Total loss': 0.19117876996999203}
2023-01-05 02:09:26,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:26,294 INFO:     Epoch: 66
2023-01-05 02:09:28,534 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4646743049224218, 'Total loss': 0.4646743049224218} | train loss {'Reaction outcome loss': 0.18456983750842976, 'Total loss': 0.18456983750842976}
2023-01-05 02:09:28,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:28,534 INFO:     Epoch: 67
2023-01-05 02:09:30,764 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5154016504685084, 'Total loss': 0.5154016504685084} | train loss {'Reaction outcome loss': 0.17533553957652587, 'Total loss': 0.17533553957652587}
2023-01-05 02:09:30,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:30,764 INFO:     Epoch: 68
2023-01-05 02:09:32,997 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5298267165819804, 'Total loss': 0.5298267165819804} | train loss {'Reaction outcome loss': 0.18193274150831085, 'Total loss': 0.18193274150831085}
2023-01-05 02:09:32,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:32,997 INFO:     Epoch: 69
2023-01-05 02:09:35,249 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5013874292373657, 'Total loss': 0.5013874292373657} | train loss {'Reaction outcome loss': 0.18138041246627823, 'Total loss': 0.18138041246627823}
2023-01-05 02:09:35,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:35,250 INFO:     Epoch: 70
2023-01-05 02:09:37,504 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4932790110508601, 'Total loss': 0.4932790110508601} | train loss {'Reaction outcome loss': 0.17832723230758046, 'Total loss': 0.17832723230758046}
2023-01-05 02:09:37,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:37,504 INFO:     Epoch: 71
2023-01-05 02:09:39,753 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47522953351338704, 'Total loss': 0.47522953351338704} | train loss {'Reaction outcome loss': 0.18066767168712322, 'Total loss': 0.18066767168712322}
2023-01-05 02:09:39,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:39,754 INFO:     Epoch: 72
2023-01-05 02:09:41,992 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4638175815343857, 'Total loss': 0.4638175815343857} | train loss {'Reaction outcome loss': 0.1743178879193989, 'Total loss': 0.1743178879193989}
2023-01-05 02:09:41,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:41,993 INFO:     Epoch: 73
2023-01-05 02:09:44,234 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46124825278917947, 'Total loss': 0.46124825278917947} | train loss {'Reaction outcome loss': 0.17793401342308346, 'Total loss': 0.17793401342308346}
2023-01-05 02:09:44,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:44,234 INFO:     Epoch: 74
2023-01-05 02:09:46,494 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4738789349794388, 'Total loss': 0.4738789349794388} | train loss {'Reaction outcome loss': 0.17657138772936531, 'Total loss': 0.17657138772936531}
2023-01-05 02:09:46,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:46,494 INFO:     Epoch: 75
2023-01-05 02:09:48,760 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4961574594179789, 'Total loss': 0.4961574594179789} | train loss {'Reaction outcome loss': 0.17470815338726556, 'Total loss': 0.17470815338726556}
2023-01-05 02:09:48,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:48,761 INFO:     Epoch: 76
2023-01-05 02:09:51,009 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4869328558444977, 'Total loss': 0.4869328558444977} | train loss {'Reaction outcome loss': 0.17546794974269012, 'Total loss': 0.17546794974269012}
2023-01-05 02:09:51,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:51,009 INFO:     Epoch: 77
2023-01-05 02:09:53,248 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46568871339162193, 'Total loss': 0.46568871339162193} | train loss {'Reaction outcome loss': 0.16961988155310462, 'Total loss': 0.16961988155310462}
2023-01-05 02:09:53,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:53,248 INFO:     Epoch: 78
2023-01-05 02:09:55,478 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49465266466140745, 'Total loss': 0.49465266466140745} | train loss {'Reaction outcome loss': 0.17708251289443383, 'Total loss': 0.17708251289443383}
2023-01-05 02:09:55,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:55,479 INFO:     Epoch: 79
2023-01-05 02:09:57,719 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5052135596672694, 'Total loss': 0.5052135596672694} | train loss {'Reaction outcome loss': 0.17102968241446292, 'Total loss': 0.17102968241446292}
2023-01-05 02:09:57,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:57,719 INFO:     Epoch: 80
2023-01-05 02:09:59,959 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4913785845041275, 'Total loss': 0.4913785845041275} | train loss {'Reaction outcome loss': 0.17115425500479756, 'Total loss': 0.17115425500479756}
2023-01-05 02:09:59,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:09:59,959 INFO:     Epoch: 81
2023-01-05 02:10:02,162 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5005443533261617, 'Total loss': 0.5005443533261617} | train loss {'Reaction outcome loss': 0.16877478185611275, 'Total loss': 0.16877478185611275}
2023-01-05 02:10:02,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:02,162 INFO:     Epoch: 82
2023-01-05 02:10:04,339 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5143066962560018, 'Total loss': 0.5143066962560018} | train loss {'Reaction outcome loss': 0.16737628758683692, 'Total loss': 0.16737628758683692}
2023-01-05 02:10:04,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:04,341 INFO:     Epoch: 83
2023-01-05 02:10:06,561 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47978431880474093, 'Total loss': 0.47978431880474093} | train loss {'Reaction outcome loss': 0.17032183897971506, 'Total loss': 0.17032183897971506}
2023-01-05 02:10:06,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:06,561 INFO:     Epoch: 84
2023-01-05 02:10:08,755 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48986174662907916, 'Total loss': 0.48986174662907916} | train loss {'Reaction outcome loss': 0.16487339381537922, 'Total loss': 0.16487339381537922}
2023-01-05 02:10:08,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:08,755 INFO:     Epoch: 85
2023-01-05 02:10:10,921 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4667755825755497, 'Total loss': 0.4667755825755497} | train loss {'Reaction outcome loss': 0.16814677067947037, 'Total loss': 0.16814677067947037}
2023-01-05 02:10:10,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:10,921 INFO:     Epoch: 86
2023-01-05 02:10:13,115 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45883717040220895, 'Total loss': 0.45883717040220895} | train loss {'Reaction outcome loss': 0.16552953030095324, 'Total loss': 0.16552953030095324}
2023-01-05 02:10:13,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:13,115 INFO:     Epoch: 87
2023-01-05 02:10:15,232 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5036616901556651, 'Total loss': 0.5036616901556651} | train loss {'Reaction outcome loss': 0.16348067585774612, 'Total loss': 0.16348067585774612}
2023-01-05 02:10:15,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:15,232 INFO:     Epoch: 88
2023-01-05 02:10:17,404 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47858584218968947, 'Total loss': 0.47858584218968947} | train loss {'Reaction outcome loss': 0.16351346927268545, 'Total loss': 0.16351346927268545}
2023-01-05 02:10:17,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:17,405 INFO:     Epoch: 89
2023-01-05 02:10:19,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5307825764020284, 'Total loss': 0.5307825764020284} | train loss {'Reaction outcome loss': 0.16720455150109725, 'Total loss': 0.16720455150109725}
2023-01-05 02:10:19,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:19,514 INFO:     Epoch: 90
2023-01-05 02:10:21,740 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47645092237119874, 'Total loss': 0.47645092237119874} | train loss {'Reaction outcome loss': 0.16230724041773203, 'Total loss': 0.16230724041773203}
2023-01-05 02:10:21,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:21,741 INFO:     Epoch: 91
2023-01-05 02:10:23,977 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48886929303407667, 'Total loss': 0.48886929303407667} | train loss {'Reaction outcome loss': 0.16819037687742994, 'Total loss': 0.16819037687742994}
2023-01-05 02:10:23,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:23,978 INFO:     Epoch: 92
2023-01-05 02:10:26,244 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5102122982343038, 'Total loss': 0.5102122982343038} | train loss {'Reaction outcome loss': 0.1678906057299466, 'Total loss': 0.1678906057299466}
2023-01-05 02:10:26,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:26,245 INFO:     Epoch: 93
2023-01-05 02:10:28,503 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4976504733165105, 'Total loss': 0.4976504733165105} | train loss {'Reaction outcome loss': 0.15747321301034137, 'Total loss': 0.15747321301034137}
2023-01-05 02:10:28,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:28,503 INFO:     Epoch: 94
2023-01-05 02:10:30,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49143270154794055, 'Total loss': 0.49143270154794055} | train loss {'Reaction outcome loss': 0.1598318262778789, 'Total loss': 0.1598318262778789}
2023-01-05 02:10:30,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:30,677 INFO:     Epoch: 95
2023-01-05 02:10:32,873 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.510933921734492, 'Total loss': 0.510933921734492} | train loss {'Reaction outcome loss': 0.16022812392334063, 'Total loss': 0.16022812392334063}
2023-01-05 02:10:32,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:32,874 INFO:     Epoch: 96
2023-01-05 02:10:35,101 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49663025041421255, 'Total loss': 0.49663025041421255} | train loss {'Reaction outcome loss': 0.15986735699357185, 'Total loss': 0.15986735699357185}
2023-01-05 02:10:35,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:35,101 INFO:     Epoch: 97
2023-01-05 02:10:37,318 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.501489594578743, 'Total loss': 0.501489594578743} | train loss {'Reaction outcome loss': 0.16369497265637725, 'Total loss': 0.16369497265637725}
2023-01-05 02:10:37,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:37,318 INFO:     Epoch: 98
2023-01-05 02:10:39,476 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47313045859336855, 'Total loss': 0.47313045859336855} | train loss {'Reaction outcome loss': 0.169914135320501, 'Total loss': 0.169914135320501}
2023-01-05 02:10:39,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:39,476 INFO:     Epoch: 99
2023-01-05 02:10:41,635 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5054482460021973, 'Total loss': 0.5054482460021973} | train loss {'Reaction outcome loss': 0.16066681141896863, 'Total loss': 0.16066681141896863}
2023-01-05 02:10:41,636 INFO:     Best model found after epoch 33 of 100.
2023-01-05 02:10:41,636 INFO:   Done with stage: TRAINING
2023-01-05 02:10:41,636 INFO:   Starting stage: EVALUATION
2023-01-05 02:10:41,784 INFO:   Done with stage: EVALUATION
2023-01-05 02:10:41,784 INFO:   Leaving out SEQ value Fold_1
2023-01-05 02:10:41,797 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:10:41,797 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:10:42,437 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:10:42,437 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:10:42,507 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:10:42,507 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:10:42,507 INFO:     No hyperparam tuning for this model
2023-01-05 02:10:42,507 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:10:42,507 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:10:42,508 INFO:     None feature selector for col prot
2023-01-05 02:10:42,508 INFO:     None feature selector for col prot
2023-01-05 02:10:42,508 INFO:     None feature selector for col prot
2023-01-05 02:10:42,509 INFO:     None feature selector for col chem
2023-01-05 02:10:42,509 INFO:     None feature selector for col chem
2023-01-05 02:10:42,509 INFO:     None feature selector for col chem
2023-01-05 02:10:42,509 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:10:42,509 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:10:42,510 INFO:     Number of params in model 72931
2023-01-05 02:10:42,513 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:10:42,513 INFO:   Starting stage: TRAINING
2023-01-05 02:10:42,572 INFO:     Val loss before train {'Reaction outcome loss': 1.0376219471295676, 'Total loss': 1.0376219471295676}
2023-01-05 02:10:42,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:42,572 INFO:     Epoch: 0
2023-01-05 02:10:44,740 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8023746808369955, 'Total loss': 0.8023746808369955} | train loss {'Reaction outcome loss': 0.9363822584604695, 'Total loss': 0.9363822584604695}
2023-01-05 02:10:44,740 INFO:     Found new best model at epoch 0
2023-01-05 02:10:44,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:44,742 INFO:     Epoch: 1
2023-01-05 02:10:46,878 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6077865382035573, 'Total loss': 0.6077865382035573} | train loss {'Reaction outcome loss': 0.6250421928010718, 'Total loss': 0.6250421928010718}
2023-01-05 02:10:46,878 INFO:     Found new best model at epoch 1
2023-01-05 02:10:46,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:46,879 INFO:     Epoch: 2
2023-01-05 02:10:49,105 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5567425747712453, 'Total loss': 0.5567425747712453} | train loss {'Reaction outcome loss': 0.5371447031515358, 'Total loss': 0.5371447031515358}
2023-01-05 02:10:49,106 INFO:     Found new best model at epoch 2
2023-01-05 02:10:49,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:49,107 INFO:     Epoch: 3
2023-01-05 02:10:51,298 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5506423354148865, 'Total loss': 0.5506423354148865} | train loss {'Reaction outcome loss': 0.5016112021938728, 'Total loss': 0.5016112021938728}
2023-01-05 02:10:51,298 INFO:     Found new best model at epoch 3
2023-01-05 02:10:51,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:51,299 INFO:     Epoch: 4
2023-01-05 02:10:53,510 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5218581636746724, 'Total loss': 0.5218581636746724} | train loss {'Reaction outcome loss': 0.46965714984566626, 'Total loss': 0.46965714984566626}
2023-01-05 02:10:53,510 INFO:     Found new best model at epoch 4
2023-01-05 02:10:53,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:53,512 INFO:     Epoch: 5
2023-01-05 02:10:55,659 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5294481962919235, 'Total loss': 0.5294481962919235} | train loss {'Reaction outcome loss': 0.4416589547139015, 'Total loss': 0.4416589547139015}
2023-01-05 02:10:55,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:55,660 INFO:     Epoch: 6
2023-01-05 02:10:57,811 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5192961434523264, 'Total loss': 0.5192961434523264} | train loss {'Reaction outcome loss': 0.4242987119640312, 'Total loss': 0.4242987119640312}
2023-01-05 02:10:57,811 INFO:     Found new best model at epoch 6
2023-01-05 02:10:57,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:10:57,812 INFO:     Epoch: 7
2023-01-05 02:11:00,018 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4999493350585302, 'Total loss': 0.4999493350585302} | train loss {'Reaction outcome loss': 0.4081665156477124, 'Total loss': 0.4081665156477124}
2023-01-05 02:11:00,018 INFO:     Found new best model at epoch 7
2023-01-05 02:11:00,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:00,020 INFO:     Epoch: 8
2023-01-05 02:11:02,170 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47640743255615237, 'Total loss': 0.47640743255615237} | train loss {'Reaction outcome loss': 0.39335961745929543, 'Total loss': 0.39335961745929543}
2023-01-05 02:11:02,170 INFO:     Found new best model at epoch 8
2023-01-05 02:11:02,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:02,172 INFO:     Epoch: 9
2023-01-05 02:11:04,322 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.488800964752833, 'Total loss': 0.488800964752833} | train loss {'Reaction outcome loss': 0.37930549569699884, 'Total loss': 0.37930549569699884}
2023-01-05 02:11:04,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:04,323 INFO:     Epoch: 10
2023-01-05 02:11:06,423 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49834500352541605, 'Total loss': 0.49834500352541605} | train loss {'Reaction outcome loss': 0.36895350883476924, 'Total loss': 0.36895350883476924}
2023-01-05 02:11:06,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:06,424 INFO:     Epoch: 11
2023-01-05 02:11:08,252 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49461156924565636, 'Total loss': 0.49461156924565636} | train loss {'Reaction outcome loss': 0.35687338607045854, 'Total loss': 0.35687338607045854}
2023-01-05 02:11:08,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:08,252 INFO:     Epoch: 12
2023-01-05 02:11:10,048 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47580836415290834, 'Total loss': 0.47580836415290834} | train loss {'Reaction outcome loss': 0.33984391936474906, 'Total loss': 0.33984391936474906}
2023-01-05 02:11:10,048 INFO:     Found new best model at epoch 12
2023-01-05 02:11:10,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:10,050 INFO:     Epoch: 13
2023-01-05 02:11:12,254 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48970854381720225, 'Total loss': 0.48970854381720225} | train loss {'Reaction outcome loss': 0.3343614069405046, 'Total loss': 0.3343614069405046}
2023-01-05 02:11:12,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:12,255 INFO:     Epoch: 14
2023-01-05 02:11:14,473 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4645873268445333, 'Total loss': 0.4645873268445333} | train loss {'Reaction outcome loss': 0.3295100599010713, 'Total loss': 0.3295100599010713}
2023-01-05 02:11:14,473 INFO:     Found new best model at epoch 14
2023-01-05 02:11:14,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:14,475 INFO:     Epoch: 15
2023-01-05 02:11:16,721 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4651147266228994, 'Total loss': 0.4651147266228994} | train loss {'Reaction outcome loss': 0.3196073185013485, 'Total loss': 0.3196073185013485}
2023-01-05 02:11:16,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:16,721 INFO:     Epoch: 16
2023-01-05 02:11:18,958 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46899789770444233, 'Total loss': 0.46899789770444233} | train loss {'Reaction outcome loss': 0.31122740261583, 'Total loss': 0.31122740261583}
2023-01-05 02:11:18,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:18,959 INFO:     Epoch: 17
2023-01-05 02:11:21,142 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48971559951702753, 'Total loss': 0.48971559951702753} | train loss {'Reaction outcome loss': 0.3072276166402293, 'Total loss': 0.3072276166402293}
2023-01-05 02:11:21,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:21,142 INFO:     Epoch: 18
2023-01-05 02:11:23,342 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47343509594599403, 'Total loss': 0.47343509594599403} | train loss {'Reaction outcome loss': 0.2978786899279939, 'Total loss': 0.2978786899279939}
2023-01-05 02:11:23,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:23,343 INFO:     Epoch: 19
2023-01-05 02:11:25,551 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4712707360585531, 'Total loss': 0.4712707360585531} | train loss {'Reaction outcome loss': 0.2873734983948678, 'Total loss': 0.2873734983948678}
2023-01-05 02:11:25,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:25,551 INFO:     Epoch: 20
2023-01-05 02:11:27,777 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5011677205562591, 'Total loss': 0.5011677205562591} | train loss {'Reaction outcome loss': 0.28582679477595063, 'Total loss': 0.28582679477595063}
2023-01-05 02:11:27,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:27,777 INFO:     Epoch: 21
2023-01-05 02:11:30,012 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4593749155600866, 'Total loss': 0.4593749155600866} | train loss {'Reaction outcome loss': 0.2851955380263555, 'Total loss': 0.2851955380263555}
2023-01-05 02:11:30,012 INFO:     Found new best model at epoch 21
2023-01-05 02:11:30,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:30,013 INFO:     Epoch: 22
2023-01-05 02:11:32,213 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49216424226760863, 'Total loss': 0.49216424226760863} | train loss {'Reaction outcome loss': 0.27138531407218996, 'Total loss': 0.27138531407218996}
2023-01-05 02:11:32,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:32,214 INFO:     Epoch: 23
2023-01-05 02:11:34,394 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45069439510504405, 'Total loss': 0.45069439510504405} | train loss {'Reaction outcome loss': 0.2722307905677135, 'Total loss': 0.2722307905677135}
2023-01-05 02:11:34,394 INFO:     Found new best model at epoch 23
2023-01-05 02:11:34,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:34,395 INFO:     Epoch: 24
2023-01-05 02:11:36,621 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4777619441350301, 'Total loss': 0.4777619441350301} | train loss {'Reaction outcome loss': 0.2637117758502055, 'Total loss': 0.2637117758502055}
2023-01-05 02:11:36,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:36,621 INFO:     Epoch: 25
2023-01-05 02:11:38,788 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46156609853108727, 'Total loss': 0.46156609853108727} | train loss {'Reaction outcome loss': 0.26060529288421147, 'Total loss': 0.26060529288421147}
2023-01-05 02:11:38,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:38,788 INFO:     Epoch: 26
2023-01-05 02:11:41,032 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5012197464704513, 'Total loss': 0.5012197464704513} | train loss {'Reaction outcome loss': 0.26041433892219606, 'Total loss': 0.26041433892219606}
2023-01-05 02:11:41,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:41,032 INFO:     Epoch: 27
2023-01-05 02:11:43,260 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48317419067025186, 'Total loss': 0.48317419067025186} | train loss {'Reaction outcome loss': 0.25488358799259375, 'Total loss': 0.25488358799259375}
2023-01-05 02:11:43,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:43,262 INFO:     Epoch: 28
2023-01-05 02:11:45,497 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4822265366713206, 'Total loss': 0.4822265366713206} | train loss {'Reaction outcome loss': 0.2541420565319866, 'Total loss': 0.2541420565319866}
2023-01-05 02:11:45,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:45,497 INFO:     Epoch: 29
2023-01-05 02:11:47,664 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46547312537829083, 'Total loss': 0.46547312537829083} | train loss {'Reaction outcome loss': 0.25159952937061114, 'Total loss': 0.25159952937061114}
2023-01-05 02:11:47,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:47,665 INFO:     Epoch: 30
2023-01-05 02:11:49,905 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47133761445681255, 'Total loss': 0.47133761445681255} | train loss {'Reaction outcome loss': 0.24981778807747756, 'Total loss': 0.24981778807747756}
2023-01-05 02:11:49,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:49,906 INFO:     Epoch: 31
2023-01-05 02:11:52,155 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5032536307970683, 'Total loss': 0.5032536307970683} | train loss {'Reaction outcome loss': 0.24534442650330981, 'Total loss': 0.24534442650330981}
2023-01-05 02:11:52,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:52,155 INFO:     Epoch: 32
2023-01-05 02:11:54,400 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5108703752358754, 'Total loss': 0.5108703752358754} | train loss {'Reaction outcome loss': 0.2364126061612781, 'Total loss': 0.2364126061612781}
2023-01-05 02:11:54,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:54,400 INFO:     Epoch: 33
2023-01-05 02:11:56,620 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4768636663754781, 'Total loss': 0.4768636663754781} | train loss {'Reaction outcome loss': 0.23373377782013946, 'Total loss': 0.23373377782013946}
2023-01-05 02:11:56,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:56,620 INFO:     Epoch: 34
2023-01-05 02:11:58,857 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5178775211175283, 'Total loss': 0.5178775211175283} | train loss {'Reaction outcome loss': 0.2398538673024652, 'Total loss': 0.2398538673024652}
2023-01-05 02:11:58,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:11:58,857 INFO:     Epoch: 35
2023-01-05 02:12:01,088 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5258621017138163, 'Total loss': 0.5258621017138163} | train loss {'Reaction outcome loss': 0.2310073558499452, 'Total loss': 0.2310073558499452}
2023-01-05 02:12:01,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:01,089 INFO:     Epoch: 36
2023-01-05 02:12:03,314 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49403486450513207, 'Total loss': 0.49403486450513207} | train loss {'Reaction outcome loss': 0.23044382198203872, 'Total loss': 0.23044382198203872}
2023-01-05 02:12:03,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:03,315 INFO:     Epoch: 37
2023-01-05 02:12:05,362 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4926030079523722, 'Total loss': 0.4926030079523722} | train loss {'Reaction outcome loss': 0.2259215907547215, 'Total loss': 0.2259215907547215}
2023-01-05 02:12:05,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:05,362 INFO:     Epoch: 38
2023-01-05 02:12:07,589 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5181506931781769, 'Total loss': 0.5181506931781769} | train loss {'Reaction outcome loss': 0.21864057186800634, 'Total loss': 0.21864057186800634}
2023-01-05 02:12:07,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:07,589 INFO:     Epoch: 39
2023-01-05 02:12:09,803 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5087329924106598, 'Total loss': 0.5087329924106598} | train loss {'Reaction outcome loss': 0.22289959420144123, 'Total loss': 0.22289959420144123}
2023-01-05 02:12:09,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:09,803 INFO:     Epoch: 40
2023-01-05 02:12:12,052 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4963525702555974, 'Total loss': 0.4963525702555974} | train loss {'Reaction outcome loss': 0.2149958208910305, 'Total loss': 0.2149958208910305}
2023-01-05 02:12:12,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:12,052 INFO:     Epoch: 41
2023-01-05 02:12:14,170 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5155952900648118, 'Total loss': 0.5155952900648118} | train loss {'Reaction outcome loss': 0.21613160637717177, 'Total loss': 0.21613160637717177}
2023-01-05 02:12:14,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:14,172 INFO:     Epoch: 42
2023-01-05 02:12:16,391 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4952697217464447, 'Total loss': 0.4952697217464447} | train loss {'Reaction outcome loss': 0.21858468978754142, 'Total loss': 0.21858468978754142}
2023-01-05 02:12:16,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:16,391 INFO:     Epoch: 43
2023-01-05 02:12:18,618 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5296896090110143, 'Total loss': 0.5296896090110143} | train loss {'Reaction outcome loss': 0.2105652501969768, 'Total loss': 0.2105652501969768}
2023-01-05 02:12:18,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:18,618 INFO:     Epoch: 44
2023-01-05 02:12:20,831 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49874412814776103, 'Total loss': 0.49874412814776103} | train loss {'Reaction outcome loss': 0.21139536253482538, 'Total loss': 0.21139536253482538}
2023-01-05 02:12:20,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:20,832 INFO:     Epoch: 45
2023-01-05 02:12:23,091 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5140920778115591, 'Total loss': 0.5140920778115591} | train loss {'Reaction outcome loss': 0.2072300172757602, 'Total loss': 0.2072300172757602}
2023-01-05 02:12:23,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:23,092 INFO:     Epoch: 46
2023-01-05 02:12:25,306 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5210719168186188, 'Total loss': 0.5210719168186188} | train loss {'Reaction outcome loss': 0.20879026968032122, 'Total loss': 0.20879026968032122}
2023-01-05 02:12:25,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:25,306 INFO:     Epoch: 47
2023-01-05 02:12:27,523 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5047519683837891, 'Total loss': 0.5047519683837891} | train loss {'Reaction outcome loss': 0.20409105723234314, 'Total loss': 0.20409105723234314}
2023-01-05 02:12:27,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:27,523 INFO:     Epoch: 48
2023-01-05 02:12:29,798 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5326824466387431, 'Total loss': 0.5326824466387431} | train loss {'Reaction outcome loss': 0.20281720896299085, 'Total loss': 0.20281720896299085}
2023-01-05 02:12:29,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:29,798 INFO:     Epoch: 49
2023-01-05 02:12:31,990 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5046871344248454, 'Total loss': 0.5046871344248454} | train loss {'Reaction outcome loss': 0.20293119013391053, 'Total loss': 0.20293119013391053}
2023-01-05 02:12:31,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:31,990 INFO:     Epoch: 50
2023-01-05 02:12:34,231 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5112698252002398, 'Total loss': 0.5112698252002398} | train loss {'Reaction outcome loss': 0.19715068177286074, 'Total loss': 0.19715068177286074}
2023-01-05 02:12:34,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:34,232 INFO:     Epoch: 51
2023-01-05 02:12:36,496 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5330780386924744, 'Total loss': 0.5330780386924744} | train loss {'Reaction outcome loss': 0.19769277380792982, 'Total loss': 0.19769277380792982}
2023-01-05 02:12:36,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:36,496 INFO:     Epoch: 52
2023-01-05 02:12:38,752 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5346536695957184, 'Total loss': 0.5346536695957184} | train loss {'Reaction outcome loss': 0.19966721842167423, 'Total loss': 0.19966721842167423}
2023-01-05 02:12:38,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:38,753 INFO:     Epoch: 53
2023-01-05 02:12:41,024 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5075593411922454, 'Total loss': 0.5075593411922454} | train loss {'Reaction outcome loss': 0.1946496272520808, 'Total loss': 0.1946496272520808}
2023-01-05 02:12:41,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:41,025 INFO:     Epoch: 54
2023-01-05 02:12:43,266 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5275915056467056, 'Total loss': 0.5275915056467056} | train loss {'Reaction outcome loss': 0.19230004126736283, 'Total loss': 0.19230004126736283}
2023-01-05 02:12:43,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:43,268 INFO:     Epoch: 55
2023-01-05 02:12:45,493 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5023326362172763, 'Total loss': 0.5023326362172763} | train loss {'Reaction outcome loss': 0.19129470908796808, 'Total loss': 0.19129470908796808}
2023-01-05 02:12:45,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:45,494 INFO:     Epoch: 56
2023-01-05 02:12:47,739 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5752658764521281, 'Total loss': 0.5752658764521281} | train loss {'Reaction outcome loss': 0.19263200358195354, 'Total loss': 0.19263200358195354}
2023-01-05 02:12:47,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:47,740 INFO:     Epoch: 57
2023-01-05 02:12:50,012 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5579483230908712, 'Total loss': 0.5579483230908712} | train loss {'Reaction outcome loss': 0.19450851483270526, 'Total loss': 0.19450851483270526}
2023-01-05 02:12:50,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:50,012 INFO:     Epoch: 58
2023-01-05 02:12:52,200 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5332160125176112, 'Total loss': 0.5332160125176112} | train loss {'Reaction outcome loss': 0.1870368719950699, 'Total loss': 0.1870368719950699}
2023-01-05 02:12:52,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:52,201 INFO:     Epoch: 59
2023-01-05 02:12:54,350 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5391241629918416, 'Total loss': 0.5391241629918416} | train loss {'Reaction outcome loss': 0.19307110319593854, 'Total loss': 0.19307110319593854}
2023-01-05 02:12:54,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:54,350 INFO:     Epoch: 60
2023-01-05 02:12:56,529 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5251978079477946, 'Total loss': 0.5251978079477946} | train loss {'Reaction outcome loss': 0.1868679731859941, 'Total loss': 0.1868679731859941}
2023-01-05 02:12:56,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:56,530 INFO:     Epoch: 61
2023-01-05 02:12:58,765 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5695738534132639, 'Total loss': 0.5695738534132639} | train loss {'Reaction outcome loss': 0.1865592165306265, 'Total loss': 0.1865592165306265}
2023-01-05 02:12:58,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:12:58,765 INFO:     Epoch: 62
2023-01-05 02:13:00,931 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5291393240292867, 'Total loss': 0.5291393240292867} | train loss {'Reaction outcome loss': 0.18444859786095083, 'Total loss': 0.18444859786095083}
2023-01-05 02:13:00,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:00,932 INFO:     Epoch: 63
2023-01-05 02:13:03,168 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5532180728390813, 'Total loss': 0.5532180728390813} | train loss {'Reaction outcome loss': 0.18434669627862418, 'Total loss': 0.18434669627862418}
2023-01-05 02:13:03,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:03,169 INFO:     Epoch: 64
2023-01-05 02:13:05,399 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5938778132200241, 'Total loss': 0.5938778132200241} | train loss {'Reaction outcome loss': 0.1824371936037647, 'Total loss': 0.1824371936037647}
2023-01-05 02:13:05,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:05,399 INFO:     Epoch: 65
2023-01-05 02:13:07,554 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5534497688213984, 'Total loss': 0.5534497688213984} | train loss {'Reaction outcome loss': 0.18785731808493172, 'Total loss': 0.18785731808493172}
2023-01-05 02:13:07,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:07,554 INFO:     Epoch: 66
2023-01-05 02:13:09,748 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5623298486073812, 'Total loss': 0.5623298486073812} | train loss {'Reaction outcome loss': 0.184335989772213, 'Total loss': 0.184335989772213}
2023-01-05 02:13:09,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:09,749 INFO:     Epoch: 67
2023-01-05 02:13:11,941 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5260564764340718, 'Total loss': 0.5260564764340718} | train loss {'Reaction outcome loss': 0.17914362537103576, 'Total loss': 0.17914362537103576}
2023-01-05 02:13:11,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:11,942 INFO:     Epoch: 68
2023-01-05 02:13:14,123 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5059551864862442, 'Total loss': 0.5059551864862442} | train loss {'Reaction outcome loss': 0.17771215434526058, 'Total loss': 0.17771215434526058}
2023-01-05 02:13:14,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:14,123 INFO:     Epoch: 69
2023-01-05 02:13:16,354 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5315870344638824, 'Total loss': 0.5315870344638824} | train loss {'Reaction outcome loss': 0.17407785015126323, 'Total loss': 0.17407785015126323}
2023-01-05 02:13:16,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:16,354 INFO:     Epoch: 70
2023-01-05 02:13:18,590 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5378429638842742, 'Total loss': 0.5378429638842742} | train loss {'Reaction outcome loss': 0.17967191498971333, 'Total loss': 0.17967191498971333}
2023-01-05 02:13:18,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:18,590 INFO:     Epoch: 71
2023-01-05 02:13:20,830 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5422128421564897, 'Total loss': 0.5422128421564897} | train loss {'Reaction outcome loss': 0.178642357988487, 'Total loss': 0.178642357988487}
2023-01-05 02:13:20,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:20,832 INFO:     Epoch: 72
2023-01-05 02:13:23,080 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6162250757217407, 'Total loss': 0.6162250757217407} | train loss {'Reaction outcome loss': 0.1796015664649597, 'Total loss': 0.1796015664649597}
2023-01-05 02:13:23,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:23,080 INFO:     Epoch: 73
2023-01-05 02:13:25,333 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5678776880105336, 'Total loss': 0.5678776880105336} | train loss {'Reaction outcome loss': 0.1775544879849266, 'Total loss': 0.1775544879849266}
2023-01-05 02:13:25,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:25,333 INFO:     Epoch: 74
2023-01-05 02:13:27,607 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5125094572703044, 'Total loss': 0.5125094572703044} | train loss {'Reaction outcome loss': 0.17375555772837387, 'Total loss': 0.17375555772837387}
2023-01-05 02:13:27,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:27,608 INFO:     Epoch: 75
2023-01-05 02:13:29,825 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5220947543780009, 'Total loss': 0.5220947543780009} | train loss {'Reaction outcome loss': 0.17699829590282518, 'Total loss': 0.17699829590282518}
2023-01-05 02:13:29,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:29,826 INFO:     Epoch: 76
2023-01-05 02:13:32,054 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.557944252093633, 'Total loss': 0.557944252093633} | train loss {'Reaction outcome loss': 0.17423413589046113, 'Total loss': 0.17423413589046113}
2023-01-05 02:13:32,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:32,054 INFO:     Epoch: 77
2023-01-05 02:13:34,310 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5134982744852702, 'Total loss': 0.5134982744852702} | train loss {'Reaction outcome loss': 0.1722678202289381, 'Total loss': 0.1722678202289381}
2023-01-05 02:13:34,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:34,310 INFO:     Epoch: 78
2023-01-05 02:13:36,511 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5482427276670933, 'Total loss': 0.5482427276670933} | train loss {'Reaction outcome loss': 0.17105739347867832, 'Total loss': 0.17105739347867832}
2023-01-05 02:13:36,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:36,512 INFO:     Epoch: 79
2023-01-05 02:13:38,719 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5739765266577402, 'Total loss': 0.5739765266577402} | train loss {'Reaction outcome loss': 0.16770207207398422, 'Total loss': 0.16770207207398422}
2023-01-05 02:13:38,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:38,719 INFO:     Epoch: 80
2023-01-05 02:13:40,848 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5279727051655452, 'Total loss': 0.5279727051655452} | train loss {'Reaction outcome loss': 0.1683851336298959, 'Total loss': 0.1683851336298959}
2023-01-05 02:13:40,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:40,849 INFO:     Epoch: 81
2023-01-05 02:13:43,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5267512917518615, 'Total loss': 0.5267512917518615} | train loss {'Reaction outcome loss': 0.17233947011723733, 'Total loss': 0.17233947011723733}
2023-01-05 02:13:43,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:43,139 INFO:     Epoch: 82
2023-01-05 02:13:45,298 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5564559668302536, 'Total loss': 0.5564559668302536} | train loss {'Reaction outcome loss': 0.17043458953003543, 'Total loss': 0.17043458953003543}
2023-01-05 02:13:45,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:45,298 INFO:     Epoch: 83
2023-01-05 02:13:47,525 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5420574923356374, 'Total loss': 0.5420574923356374} | train loss {'Reaction outcome loss': 0.1682423731519494, 'Total loss': 0.1682423731519494}
2023-01-05 02:13:47,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:47,525 INFO:     Epoch: 84
2023-01-05 02:13:49,764 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4959050749739011, 'Total loss': 0.4959050749739011} | train loss {'Reaction outcome loss': 0.16743904218268002, 'Total loss': 0.16743904218268002}
2023-01-05 02:13:49,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:49,765 INFO:     Epoch: 85
2023-01-05 02:13:51,977 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5539974113305409, 'Total loss': 0.5539974113305409} | train loss {'Reaction outcome loss': 0.1673292590842249, 'Total loss': 0.1673292590842249}
2023-01-05 02:13:51,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:51,978 INFO:     Epoch: 86
2023-01-05 02:13:54,165 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.558772216240565, 'Total loss': 0.558772216240565} | train loss {'Reaction outcome loss': 0.16360655508554764, 'Total loss': 0.16360655508554764}
2023-01-05 02:13:54,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:54,165 INFO:     Epoch: 87
2023-01-05 02:13:56,391 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5363554656505585, 'Total loss': 0.5363554656505585} | train loss {'Reaction outcome loss': 0.16460468580208745, 'Total loss': 0.16460468580208745}
2023-01-05 02:13:56,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:56,392 INFO:     Epoch: 88
2023-01-05 02:13:58,618 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.541760782400767, 'Total loss': 0.541760782400767} | train loss {'Reaction outcome loss': 0.16052609551731958, 'Total loss': 0.16052609551731958}
2023-01-05 02:13:58,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:13:58,619 INFO:     Epoch: 89
2023-01-05 02:14:00,780 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5438276171684265, 'Total loss': 0.5438276171684265} | train loss {'Reaction outcome loss': 0.16460198738075194, 'Total loss': 0.16460198738075194}
2023-01-05 02:14:00,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:00,780 INFO:     Epoch: 90
2023-01-05 02:14:03,026 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5132515996694564, 'Total loss': 0.5132515996694564} | train loss {'Reaction outcome loss': 0.16324649928273618, 'Total loss': 0.16324649928273618}
2023-01-05 02:14:03,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:03,026 INFO:     Epoch: 91
2023-01-05 02:14:05,261 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.524918865164121, 'Total loss': 0.524918865164121} | train loss {'Reaction outcome loss': 0.16601301163407792, 'Total loss': 0.16601301163407792}
2023-01-05 02:14:05,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:05,261 INFO:     Epoch: 92
2023-01-05 02:14:07,417 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5586366812388103, 'Total loss': 0.5586366812388103} | train loss {'Reaction outcome loss': 0.16238592585963435, 'Total loss': 0.16238592585963435}
2023-01-05 02:14:07,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:07,417 INFO:     Epoch: 93
2023-01-05 02:14:09,667 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5300805069506168, 'Total loss': 0.5300805069506168} | train loss {'Reaction outcome loss': 0.15971712174444683, 'Total loss': 0.15971712174444683}
2023-01-05 02:14:09,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:09,668 INFO:     Epoch: 94
2023-01-05 02:14:11,892 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5255133430240676, 'Total loss': 0.5255133430240676} | train loss {'Reaction outcome loss': 0.1642227817605501, 'Total loss': 0.1642227817605501}
2023-01-05 02:14:11,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:11,892 INFO:     Epoch: 95
2023-01-05 02:14:14,129 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5390793626507123, 'Total loss': 0.5390793626507123} | train loss {'Reaction outcome loss': 0.158500085807453, 'Total loss': 0.158500085807453}
2023-01-05 02:14:14,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:14,129 INFO:     Epoch: 96
2023-01-05 02:14:16,360 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5229179451862971, 'Total loss': 0.5229179451862971} | train loss {'Reaction outcome loss': 0.16225314346978265, 'Total loss': 0.16225314346978265}
2023-01-05 02:14:16,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:16,360 INFO:     Epoch: 97
2023-01-05 02:14:18,595 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5294342120488484, 'Total loss': 0.5294342120488484} | train loss {'Reaction outcome loss': 0.16411505561716255, 'Total loss': 0.16411505561716255}
2023-01-05 02:14:18,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:18,596 INFO:     Epoch: 98
2023-01-05 02:14:20,838 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5587351282437643, 'Total loss': 0.5587351282437643} | train loss {'Reaction outcome loss': 0.160265678855978, 'Total loss': 0.160265678855978}
2023-01-05 02:14:20,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:20,839 INFO:     Epoch: 99
2023-01-05 02:14:23,076 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5394710158308347, 'Total loss': 0.5394710158308347} | train loss {'Reaction outcome loss': 0.1569004607128564, 'Total loss': 0.1569004607128564}
2023-01-05 02:14:23,076 INFO:     Best model found after epoch 24 of 100.
2023-01-05 02:14:23,076 INFO:   Done with stage: TRAINING
2023-01-05 02:14:23,076 INFO:   Starting stage: EVALUATION
2023-01-05 02:14:23,217 INFO:   Done with stage: EVALUATION
2023-01-05 02:14:23,217 INFO:   Leaving out SEQ value Fold_2
2023-01-05 02:14:23,230 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 02:14:23,230 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:14:23,873 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:14:23,873 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:14:23,942 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:14:23,942 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:14:23,942 INFO:     No hyperparam tuning for this model
2023-01-05 02:14:23,942 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:14:23,943 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:14:23,943 INFO:     None feature selector for col prot
2023-01-05 02:14:23,943 INFO:     None feature selector for col prot
2023-01-05 02:14:23,943 INFO:     None feature selector for col prot
2023-01-05 02:14:23,944 INFO:     None feature selector for col chem
2023-01-05 02:14:23,944 INFO:     None feature selector for col chem
2023-01-05 02:14:23,944 INFO:     None feature selector for col chem
2023-01-05 02:14:23,944 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:14:23,944 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:14:23,946 INFO:     Number of params in model 72931
2023-01-05 02:14:23,949 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:14:23,949 INFO:   Starting stage: TRAINING
2023-01-05 02:14:24,009 INFO:     Val loss before train {'Reaction outcome loss': 0.9981608629226685, 'Total loss': 0.9981608629226685}
2023-01-05 02:14:24,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:24,009 INFO:     Epoch: 0
2023-01-05 02:14:26,189 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7870763738950094, 'Total loss': 0.7870763738950094} | train loss {'Reaction outcome loss': 0.9330189065400497, 'Total loss': 0.9330189065400497}
2023-01-05 02:14:26,190 INFO:     Found new best model at epoch 0
2023-01-05 02:14:26,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:26,191 INFO:     Epoch: 1
2023-01-05 02:14:28,326 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5379927198092143, 'Total loss': 0.5379927198092143} | train loss {'Reaction outcome loss': 0.6526220629448856, 'Total loss': 0.6526220629448856}
2023-01-05 02:14:28,327 INFO:     Found new best model at epoch 1
2023-01-05 02:14:28,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:28,328 INFO:     Epoch: 2
2023-01-05 02:14:30,539 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5205354948838552, 'Total loss': 0.5205354948838552} | train loss {'Reaction outcome loss': 0.5321107541685139, 'Total loss': 0.5321107541685139}
2023-01-05 02:14:30,539 INFO:     Found new best model at epoch 2
2023-01-05 02:14:30,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:30,540 INFO:     Epoch: 3
2023-01-05 02:14:32,658 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4989393264055252, 'Total loss': 0.4989393264055252} | train loss {'Reaction outcome loss': 0.4922392890676037, 'Total loss': 0.4922392890676037}
2023-01-05 02:14:32,658 INFO:     Found new best model at epoch 3
2023-01-05 02:14:32,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:32,660 INFO:     Epoch: 4
2023-01-05 02:14:34,840 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.513215692838033, 'Total loss': 0.513215692838033} | train loss {'Reaction outcome loss': 0.4609788758304966, 'Total loss': 0.4609788758304966}
2023-01-05 02:14:34,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:34,841 INFO:     Epoch: 5
2023-01-05 02:14:36,979 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49331128001213076, 'Total loss': 0.49331128001213076} | train loss {'Reaction outcome loss': 0.43449174648239497, 'Total loss': 0.43449174648239497}
2023-01-05 02:14:36,979 INFO:     Found new best model at epoch 5
2023-01-05 02:14:36,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:36,981 INFO:     Epoch: 6
2023-01-05 02:14:39,193 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4826001703739166, 'Total loss': 0.4826001703739166} | train loss {'Reaction outcome loss': 0.41612558416176193, 'Total loss': 0.41612558416176193}
2023-01-05 02:14:39,194 INFO:     Found new best model at epoch 6
2023-01-05 02:14:39,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:39,195 INFO:     Epoch: 7
2023-01-05 02:14:41,298 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4801612436771393, 'Total loss': 0.4801612436771393} | train loss {'Reaction outcome loss': 0.40022003912663723, 'Total loss': 0.40022003912663723}
2023-01-05 02:14:41,298 INFO:     Found new best model at epoch 7
2023-01-05 02:14:41,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:41,299 INFO:     Epoch: 8
2023-01-05 02:14:43,504 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47302384972572326, 'Total loss': 0.47302384972572326} | train loss {'Reaction outcome loss': 0.3816641637707477, 'Total loss': 0.3816641637707477}
2023-01-05 02:14:43,504 INFO:     Found new best model at epoch 8
2023-01-05 02:14:43,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:43,506 INFO:     Epoch: 9
2023-01-05 02:14:45,669 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4619287590185801, 'Total loss': 0.4619287590185801} | train loss {'Reaction outcome loss': 0.36826055770528404, 'Total loss': 0.36826055770528404}
2023-01-05 02:14:45,669 INFO:     Found new best model at epoch 9
2023-01-05 02:14:45,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:45,671 INFO:     Epoch: 10
2023-01-05 02:14:47,859 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4579534967740377, 'Total loss': 0.4579534967740377} | train loss {'Reaction outcome loss': 0.36129814814844413, 'Total loss': 0.36129814814844413}
2023-01-05 02:14:47,859 INFO:     Found new best model at epoch 10
2023-01-05 02:14:47,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:47,861 INFO:     Epoch: 11
2023-01-05 02:14:50,074 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47821381986141204, 'Total loss': 0.47821381986141204} | train loss {'Reaction outcome loss': 0.35171566045273356, 'Total loss': 0.35171566045273356}
2023-01-05 02:14:50,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:50,074 INFO:     Epoch: 12
2023-01-05 02:14:52,264 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44745227272311844, 'Total loss': 0.44745227272311844} | train loss {'Reaction outcome loss': 0.3340769873270185, 'Total loss': 0.3340769873270185}
2023-01-05 02:14:52,265 INFO:     Found new best model at epoch 12
2023-01-05 02:14:52,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:52,266 INFO:     Epoch: 13
2023-01-05 02:14:54,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4273410032192866, 'Total loss': 0.4273410032192866} | train loss {'Reaction outcome loss': 0.325173105539638, 'Total loss': 0.325173105539638}
2023-01-05 02:14:54,458 INFO:     Found new best model at epoch 13
2023-01-05 02:14:54,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:54,459 INFO:     Epoch: 14
2023-01-05 02:14:56,675 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45366034905115765, 'Total loss': 0.45366034905115765} | train loss {'Reaction outcome loss': 0.32441711862445316, 'Total loss': 0.32441711862445316}
2023-01-05 02:14:56,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:56,675 INFO:     Epoch: 15
2023-01-05 02:14:58,902 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45356832146644593, 'Total loss': 0.45356832146644593} | train loss {'Reaction outcome loss': 0.30922483448143845, 'Total loss': 0.30922483448143845}
2023-01-05 02:14:58,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:14:58,902 INFO:     Epoch: 16
2023-01-05 02:15:01,085 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4610045115152995, 'Total loss': 0.4610045115152995} | train loss {'Reaction outcome loss': 0.3033944249098554, 'Total loss': 0.3033944249098554}
2023-01-05 02:15:01,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:01,086 INFO:     Epoch: 17
2023-01-05 02:15:03,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4693428099155426, 'Total loss': 0.4693428099155426} | train loss {'Reaction outcome loss': 0.29608671307809403, 'Total loss': 0.29608671307809403}
2023-01-05 02:15:03,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:03,223 INFO:     Epoch: 18
2023-01-05 02:15:05,430 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4593293567498525, 'Total loss': 0.4593293567498525} | train loss {'Reaction outcome loss': 0.2912474211011996, 'Total loss': 0.2912474211011996}
2023-01-05 02:15:05,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:05,431 INFO:     Epoch: 19
2023-01-05 02:15:07,653 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46783289810021716, 'Total loss': 0.46783289810021716} | train loss {'Reaction outcome loss': 0.28712807025337395, 'Total loss': 0.28712807025337395}
2023-01-05 02:15:07,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:07,653 INFO:     Epoch: 20
2023-01-05 02:15:09,871 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42973869244257606, 'Total loss': 0.42973869244257606} | train loss {'Reaction outcome loss': 0.2823826883247484, 'Total loss': 0.2823826883247484}
2023-01-05 02:15:09,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:09,871 INFO:     Epoch: 21
2023-01-05 02:15:12,018 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4396247133612633, 'Total loss': 0.4396247133612633} | train loss {'Reaction outcome loss': 0.27698985558180583, 'Total loss': 0.27698985558180583}
2023-01-05 02:15:12,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:12,019 INFO:     Epoch: 22
2023-01-05 02:15:14,217 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4735808908939362, 'Total loss': 0.4735808908939362} | train loss {'Reaction outcome loss': 0.26662660626892426, 'Total loss': 0.26662660626892426}
2023-01-05 02:15:14,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:14,218 INFO:     Epoch: 23
2023-01-05 02:15:16,341 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4644233097632726, 'Total loss': 0.4644233097632726} | train loss {'Reaction outcome loss': 0.26711494403280617, 'Total loss': 0.26711494403280617}
2023-01-05 02:15:16,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:16,341 INFO:     Epoch: 24
2023-01-05 02:15:18,461 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46396515766779584, 'Total loss': 0.46396515766779584} | train loss {'Reaction outcome loss': 0.25986819034749337, 'Total loss': 0.25986819034749337}
2023-01-05 02:15:18,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:18,461 INFO:     Epoch: 25
2023-01-05 02:15:20,684 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4510059873263041, 'Total loss': 0.4510059873263041} | train loss {'Reaction outcome loss': 0.2572253288516959, 'Total loss': 0.2572253288516959}
2023-01-05 02:15:20,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:20,684 INFO:     Epoch: 26
2023-01-05 02:15:22,889 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4552818487087886, 'Total loss': 0.4552818487087886} | train loss {'Reaction outcome loss': 0.25228071235284044, 'Total loss': 0.25228071235284044}
2023-01-05 02:15:22,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:22,890 INFO:     Epoch: 27
2023-01-05 02:15:25,075 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.483204115430514, 'Total loss': 0.483204115430514} | train loss {'Reaction outcome loss': 0.24768963921474013, 'Total loss': 0.24768963921474013}
2023-01-05 02:15:25,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:25,076 INFO:     Epoch: 28
2023-01-05 02:15:27,199 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46254031658172606, 'Total loss': 0.46254031658172606} | train loss {'Reaction outcome loss': 0.246509066301879, 'Total loss': 0.246509066301879}
2023-01-05 02:15:27,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:27,199 INFO:     Epoch: 29
2023-01-05 02:15:29,341 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.464966881275177, 'Total loss': 0.464966881275177} | train loss {'Reaction outcome loss': 0.24214637009324608, 'Total loss': 0.24214637009324608}
2023-01-05 02:15:29,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:29,342 INFO:     Epoch: 30
2023-01-05 02:15:31,590 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48712435166041057, 'Total loss': 0.48712435166041057} | train loss {'Reaction outcome loss': 0.23917835352485214, 'Total loss': 0.23917835352485214}
2023-01-05 02:15:31,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:31,590 INFO:     Epoch: 31
2023-01-05 02:15:33,820 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46239677915970484, 'Total loss': 0.46239677915970484} | train loss {'Reaction outcome loss': 0.23764670611574099, 'Total loss': 0.23764670611574099}
2023-01-05 02:15:33,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:33,821 INFO:     Epoch: 32
2023-01-05 02:15:36,055 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4513729691505432, 'Total loss': 0.4513729691505432} | train loss {'Reaction outcome loss': 0.2331574641154472, 'Total loss': 0.2331574641154472}
2023-01-05 02:15:36,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:36,055 INFO:     Epoch: 33
2023-01-05 02:15:38,229 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49102073212464653, 'Total loss': 0.49102073212464653} | train loss {'Reaction outcome loss': 0.22938160901810742, 'Total loss': 0.22938160901810742}
2023-01-05 02:15:38,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:38,230 INFO:     Epoch: 34
2023-01-05 02:15:40,471 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4747244656085968, 'Total loss': 0.4747244656085968} | train loss {'Reaction outcome loss': 0.2235908916445224, 'Total loss': 0.2235908916445224}
2023-01-05 02:15:40,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:40,471 INFO:     Epoch: 35
2023-01-05 02:15:42,710 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49069704711437223, 'Total loss': 0.49069704711437223} | train loss {'Reaction outcome loss': 0.2259920463580024, 'Total loss': 0.2259920463580024}
2023-01-05 02:15:42,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:42,711 INFO:     Epoch: 36
2023-01-05 02:15:44,922 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4334547867377599, 'Total loss': 0.4334547867377599} | train loss {'Reaction outcome loss': 0.22115691515084887, 'Total loss': 0.22115691515084887}
2023-01-05 02:15:44,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:44,923 INFO:     Epoch: 37
2023-01-05 02:15:47,218 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46017068475484846, 'Total loss': 0.46017068475484846} | train loss {'Reaction outcome loss': 0.22140698421801075, 'Total loss': 0.22140698421801075}
2023-01-05 02:15:47,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:47,219 INFO:     Epoch: 38
2023-01-05 02:15:49,493 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4538101931413015, 'Total loss': 0.4538101931413015} | train loss {'Reaction outcome loss': 0.21959180957995927, 'Total loss': 0.21959180957995927}
2023-01-05 02:15:49,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:49,494 INFO:     Epoch: 39
2023-01-05 02:15:51,711 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5008899013201396, 'Total loss': 0.5008899013201396} | train loss {'Reaction outcome loss': 0.2156505224025457, 'Total loss': 0.2156505224025457}
2023-01-05 02:15:51,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:51,711 INFO:     Epoch: 40
2023-01-05 02:15:53,915 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48504989047845204, 'Total loss': 0.48504989047845204} | train loss {'Reaction outcome loss': 0.2158723455127124, 'Total loss': 0.2158723455127124}
2023-01-05 02:15:53,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:53,915 INFO:     Epoch: 41
2023-01-05 02:15:56,152 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47199784517288207, 'Total loss': 0.47199784517288207} | train loss {'Reaction outcome loss': 0.21576190888608768, 'Total loss': 0.21576190888608768}
2023-01-05 02:15:56,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:56,152 INFO:     Epoch: 42
2023-01-05 02:15:58,337 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4632948686679204, 'Total loss': 0.4632948686679204} | train loss {'Reaction outcome loss': 0.211931936333686, 'Total loss': 0.211931936333686}
2023-01-05 02:15:58,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:15:58,338 INFO:     Epoch: 43
2023-01-05 02:16:00,540 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46276148557662966, 'Total loss': 0.46276148557662966} | train loss {'Reaction outcome loss': 0.21008570447236627, 'Total loss': 0.21008570447236627}
2023-01-05 02:16:00,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:00,541 INFO:     Epoch: 44
2023-01-05 02:16:02,689 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4431436995665232, 'Total loss': 0.4431436995665232} | train loss {'Reaction outcome loss': 0.2086651486620962, 'Total loss': 0.2086651486620962}
2023-01-05 02:16:02,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:02,690 INFO:     Epoch: 45
2023-01-05 02:16:04,904 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48713279565175377, 'Total loss': 0.48713279565175377} | train loss {'Reaction outcome loss': 0.2040017719547718, 'Total loss': 0.2040017719547718}
2023-01-05 02:16:04,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:04,904 INFO:     Epoch: 46
2023-01-05 02:16:07,078 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47973187764485675, 'Total loss': 0.47973187764485675} | train loss {'Reaction outcome loss': 0.20354962276615501, 'Total loss': 0.20354962276615501}
2023-01-05 02:16:07,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:07,079 INFO:     Epoch: 47
2023-01-05 02:16:09,333 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44279276008407276, 'Total loss': 0.44279276008407276} | train loss {'Reaction outcome loss': 0.20042229790390628, 'Total loss': 0.20042229790390628}
2023-01-05 02:16:09,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:09,334 INFO:     Epoch: 48
2023-01-05 02:16:11,382 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4750900864601135, 'Total loss': 0.4750900864601135} | train loss {'Reaction outcome loss': 0.20729511876286932, 'Total loss': 0.20729511876286932}
2023-01-05 02:16:11,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:11,382 INFO:     Epoch: 49
2023-01-05 02:16:13,612 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4420071803033352, 'Total loss': 0.4420071803033352} | train loss {'Reaction outcome loss': 0.2058591307328516, 'Total loss': 0.2058591307328516}
2023-01-05 02:16:13,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:13,613 INFO:     Epoch: 50
2023-01-05 02:16:15,799 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45324724217255913, 'Total loss': 0.45324724217255913} | train loss {'Reaction outcome loss': 0.1952397992438722, 'Total loss': 0.1952397992438722}
2023-01-05 02:16:15,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:15,799 INFO:     Epoch: 51
2023-01-05 02:16:17,969 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46753986875216164, 'Total loss': 0.46753986875216164} | train loss {'Reaction outcome loss': 0.1937030450928779, 'Total loss': 0.1937030450928779}
2023-01-05 02:16:17,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:17,969 INFO:     Epoch: 52
2023-01-05 02:16:20,149 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4575088640054067, 'Total loss': 0.4575088640054067} | train loss {'Reaction outcome loss': 0.19356365793729166, 'Total loss': 0.19356365793729166}
2023-01-05 02:16:20,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:20,150 INFO:     Epoch: 53
2023-01-05 02:16:22,295 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48029120365778605, 'Total loss': 0.48029120365778605} | train loss {'Reaction outcome loss': 0.18961607587725032, 'Total loss': 0.18961607587725032}
2023-01-05 02:16:22,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:22,295 INFO:     Epoch: 54
2023-01-05 02:16:24,512 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5050158366560936, 'Total loss': 0.5050158366560936} | train loss {'Reaction outcome loss': 0.1912423207905594, 'Total loss': 0.1912423207905594}
2023-01-05 02:16:24,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:24,512 INFO:     Epoch: 55
2023-01-05 02:16:26,742 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44406429131825764, 'Total loss': 0.44406429131825764} | train loss {'Reaction outcome loss': 0.19357368786693055, 'Total loss': 0.19357368786693055}
2023-01-05 02:16:26,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:26,742 INFO:     Epoch: 56
2023-01-05 02:16:28,887 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4557456980148951, 'Total loss': 0.4557456980148951} | train loss {'Reaction outcome loss': 0.18452936028993447, 'Total loss': 0.18452936028993447}
2023-01-05 02:16:28,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:28,887 INFO:     Epoch: 57
2023-01-05 02:16:31,095 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4542095204194387, 'Total loss': 0.4542095204194387} | train loss {'Reaction outcome loss': 0.18599945142687785, 'Total loss': 0.18599945142687785}
2023-01-05 02:16:31,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:31,095 INFO:     Epoch: 58
2023-01-05 02:16:33,332 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4586948183675607, 'Total loss': 0.4586948183675607} | train loss {'Reaction outcome loss': 0.19072504402496493, 'Total loss': 0.19072504402496493}
2023-01-05 02:16:33,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:33,333 INFO:     Epoch: 59
2023-01-05 02:16:35,453 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4714347114165624, 'Total loss': 0.4714347114165624} | train loss {'Reaction outcome loss': 0.1886101086221417, 'Total loss': 0.1886101086221417}
2023-01-05 02:16:35,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:35,454 INFO:     Epoch: 60
2023-01-05 02:16:37,695 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48682021498680117, 'Total loss': 0.48682021498680117} | train loss {'Reaction outcome loss': 0.18902876838741503, 'Total loss': 0.18902876838741503}
2023-01-05 02:16:37,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:37,695 INFO:     Epoch: 61
2023-01-05 02:16:39,900 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4691483269135157, 'Total loss': 0.4691483269135157} | train loss {'Reaction outcome loss': 0.1841635273380594, 'Total loss': 0.1841635273380594}
2023-01-05 02:16:39,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:39,900 INFO:     Epoch: 62
2023-01-05 02:16:42,130 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44807296295960747, 'Total loss': 0.44807296295960747} | train loss {'Reaction outcome loss': 0.18421346189338209, 'Total loss': 0.18421346189338209}
2023-01-05 02:16:42,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:42,130 INFO:     Epoch: 63
2023-01-05 02:16:44,345 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4846966395775477, 'Total loss': 0.4846966395775477} | train loss {'Reaction outcome loss': 0.18493635934392066, 'Total loss': 0.18493635934392066}
2023-01-05 02:16:44,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:44,345 INFO:     Epoch: 64
2023-01-05 02:16:46,560 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4662293205658595, 'Total loss': 0.4662293205658595} | train loss {'Reaction outcome loss': 0.18104994505807592, 'Total loss': 0.18104994505807592}
2023-01-05 02:16:46,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:46,561 INFO:     Epoch: 65
2023-01-05 02:16:48,778 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4909276500344276, 'Total loss': 0.4909276500344276} | train loss {'Reaction outcome loss': 0.177529963734645, 'Total loss': 0.177529963734645}
2023-01-05 02:16:48,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:48,779 INFO:     Epoch: 66
2023-01-05 02:16:50,999 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5124773780504862, 'Total loss': 0.5124773780504862} | train loss {'Reaction outcome loss': 0.18078108786199337, 'Total loss': 0.18078108786199337}
2023-01-05 02:16:50,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:50,999 INFO:     Epoch: 67
2023-01-05 02:16:53,135 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5038359691699346, 'Total loss': 0.5038359691699346} | train loss {'Reaction outcome loss': 0.17871294231853369, 'Total loss': 0.17871294231853369}
2023-01-05 02:16:53,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:53,135 INFO:     Epoch: 68
2023-01-05 02:16:55,369 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5147357036670049, 'Total loss': 0.5147357036670049} | train loss {'Reaction outcome loss': 0.17760174102644563, 'Total loss': 0.17760174102644563}
2023-01-05 02:16:55,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:55,370 INFO:     Epoch: 69
2023-01-05 02:16:57,599 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47757651706536614, 'Total loss': 0.47757651706536614} | train loss {'Reaction outcome loss': 0.17525858308986894, 'Total loss': 0.17525858308986894}
2023-01-05 02:16:57,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:57,599 INFO:     Epoch: 70
2023-01-05 02:16:59,799 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48978399684031804, 'Total loss': 0.48978399684031804} | train loss {'Reaction outcome loss': 0.17859384450198393, 'Total loss': 0.17859384450198393}
2023-01-05 02:16:59,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:16:59,799 INFO:     Epoch: 71
2023-01-05 02:17:01,964 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47644442319869995, 'Total loss': 0.47644442319869995} | train loss {'Reaction outcome loss': 0.17668861024859514, 'Total loss': 0.17668861024859514}
2023-01-05 02:17:01,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:01,964 INFO:     Epoch: 72
2023-01-05 02:17:04,099 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49753565192222593, 'Total loss': 0.49753565192222593} | train loss {'Reaction outcome loss': 0.17747037462811685, 'Total loss': 0.17747037462811685}
2023-01-05 02:17:04,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:04,099 INFO:     Epoch: 73
2023-01-05 02:17:06,297 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5218117972215016, 'Total loss': 0.5218117972215016} | train loss {'Reaction outcome loss': 0.17451600615112556, 'Total loss': 0.17451600615112556}
2023-01-05 02:17:06,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:06,298 INFO:     Epoch: 74
2023-01-05 02:17:08,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46851034263769786, 'Total loss': 0.46851034263769786} | train loss {'Reaction outcome loss': 0.1730068891000893, 'Total loss': 0.1730068891000893}
2023-01-05 02:17:08,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:08,535 INFO:     Epoch: 75
2023-01-05 02:17:10,758 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4796339477101962, 'Total loss': 0.4796339477101962} | train loss {'Reaction outcome loss': 0.17203082508260842, 'Total loss': 0.17203082508260842}
2023-01-05 02:17:10,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:10,759 INFO:     Epoch: 76
2023-01-05 02:17:13,002 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4747123056401809, 'Total loss': 0.4747123056401809} | train loss {'Reaction outcome loss': 0.1721774570101483, 'Total loss': 0.1721774570101483}
2023-01-05 02:17:13,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:13,003 INFO:     Epoch: 77
2023-01-05 02:17:15,158 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48280895948410035, 'Total loss': 0.48280895948410035} | train loss {'Reaction outcome loss': 0.1678609566681169, 'Total loss': 0.1678609566681169}
2023-01-05 02:17:15,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:15,158 INFO:     Epoch: 78
2023-01-05 02:17:17,249 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4861027836799622, 'Total loss': 0.4861027836799622} | train loss {'Reaction outcome loss': 0.17517291987485392, 'Total loss': 0.17517291987485392}
2023-01-05 02:17:17,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:17,249 INFO:     Epoch: 79
2023-01-05 02:17:19,370 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4928298036257426, 'Total loss': 0.4928298036257426} | train loss {'Reaction outcome loss': 0.17219284681889874, 'Total loss': 0.17219284681889874}
2023-01-05 02:17:19,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:19,370 INFO:     Epoch: 80
2023-01-05 02:17:21,502 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4786230057477951, 'Total loss': 0.4786230057477951} | train loss {'Reaction outcome loss': 0.17378370215154285, 'Total loss': 0.17378370215154285}
2023-01-05 02:17:21,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:21,503 INFO:     Epoch: 81
2023-01-05 02:17:23,399 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47849142948786416, 'Total loss': 0.47849142948786416} | train loss {'Reaction outcome loss': 0.17207508062391164, 'Total loss': 0.17207508062391164}
2023-01-05 02:17:23,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:23,399 INFO:     Epoch: 82
2023-01-05 02:17:25,200 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48306918491919837, 'Total loss': 0.48306918491919837} | train loss {'Reaction outcome loss': 0.17465419826718667, 'Total loss': 0.17465419826718667}
2023-01-05 02:17:25,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:25,201 INFO:     Epoch: 83
2023-01-05 02:17:27,198 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4511440829684337, 'Total loss': 0.4511440829684337} | train loss {'Reaction outcome loss': 0.16507448407739483, 'Total loss': 0.16507448407739483}
2023-01-05 02:17:27,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:27,198 INFO:     Epoch: 84
2023-01-05 02:17:29,433 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4931732123096784, 'Total loss': 0.4931732123096784} | train loss {'Reaction outcome loss': 0.1649064782310973, 'Total loss': 0.1649064782310973}
2023-01-05 02:17:29,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:29,433 INFO:     Epoch: 85
2023-01-05 02:17:31,645 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4706331968307495, 'Total loss': 0.4706331968307495} | train loss {'Reaction outcome loss': 0.16191149230290805, 'Total loss': 0.16191149230290805}
2023-01-05 02:17:31,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:31,646 INFO:     Epoch: 86
2023-01-05 02:17:33,758 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4971280445655187, 'Total loss': 0.4971280445655187} | train loss {'Reaction outcome loss': 0.16866924544120884, 'Total loss': 0.16866924544120884}
2023-01-05 02:17:33,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:33,758 INFO:     Epoch: 87
2023-01-05 02:17:35,980 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4752808113892873, 'Total loss': 0.4752808113892873} | train loss {'Reaction outcome loss': 0.16340265189887676, 'Total loss': 0.16340265189887676}
2023-01-05 02:17:35,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:35,980 INFO:     Epoch: 88
2023-01-05 02:17:38,158 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5294425378243128, 'Total loss': 0.5294425378243128} | train loss {'Reaction outcome loss': 0.1670229894214825, 'Total loss': 0.1670229894214825}
2023-01-05 02:17:38,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:38,158 INFO:     Epoch: 89
2023-01-05 02:17:40,288 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49637393951416015, 'Total loss': 0.49637393951416015} | train loss {'Reaction outcome loss': 0.16448104577036676, 'Total loss': 0.16448104577036676}
2023-01-05 02:17:40,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:40,289 INFO:     Epoch: 90
2023-01-05 02:17:42,430 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48493667840957644, 'Total loss': 0.48493667840957644} | train loss {'Reaction outcome loss': 0.16082115090305443, 'Total loss': 0.16082115090305443}
2023-01-05 02:17:42,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:42,430 INFO:     Epoch: 91
2023-01-05 02:17:44,620 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4909434750676155, 'Total loss': 0.4909434750676155} | train loss {'Reaction outcome loss': 0.16253399897721552, 'Total loss': 0.16253399897721552}
2023-01-05 02:17:44,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:44,621 INFO:     Epoch: 92
2023-01-05 02:17:46,783 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48322751025358834, 'Total loss': 0.48322751025358834} | train loss {'Reaction outcome loss': 0.15783505018070448, 'Total loss': 0.15783505018070448}
2023-01-05 02:17:46,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:46,783 INFO:     Epoch: 93
2023-01-05 02:17:49,035 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4600109060605367, 'Total loss': 0.4600109060605367} | train loss {'Reaction outcome loss': 0.16781378076872328, 'Total loss': 0.16781378076872328}
2023-01-05 02:17:49,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:49,035 INFO:     Epoch: 94
2023-01-05 02:17:51,245 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4858725686868032, 'Total loss': 0.4858725686868032} | train loss {'Reaction outcome loss': 0.1613953693534483, 'Total loss': 0.1613953693534483}
2023-01-05 02:17:51,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:51,245 INFO:     Epoch: 95
2023-01-05 02:17:53,527 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5063527668515841, 'Total loss': 0.5063527668515841} | train loss {'Reaction outcome loss': 0.15742192754092124, 'Total loss': 0.15742192754092124}
2023-01-05 02:17:53,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:53,527 INFO:     Epoch: 96
2023-01-05 02:17:55,769 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4592837264140447, 'Total loss': 0.4592837264140447} | train loss {'Reaction outcome loss': 0.1668379708711781, 'Total loss': 0.1668379708711781}
2023-01-05 02:17:55,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:55,770 INFO:     Epoch: 97
2023-01-05 02:17:57,905 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5302530417839686, 'Total loss': 0.5302530417839686} | train loss {'Reaction outcome loss': 0.15800790168727055, 'Total loss': 0.15800790168727055}
2023-01-05 02:17:57,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:17:57,905 INFO:     Epoch: 98
2023-01-05 02:18:00,156 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4868297924598058, 'Total loss': 0.4868297924598058} | train loss {'Reaction outcome loss': 0.16007504432765773, 'Total loss': 0.16007504432765773}
2023-01-05 02:18:00,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:00,156 INFO:     Epoch: 99
2023-01-05 02:18:02,345 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4670989066362381, 'Total loss': 0.4670989066362381} | train loss {'Reaction outcome loss': 0.15831534055167393, 'Total loss': 0.15831534055167393}
2023-01-05 02:18:02,346 INFO:     Best model found after epoch 14 of 100.
2023-01-05 02:18:02,346 INFO:   Done with stage: TRAINING
2023-01-05 02:18:02,346 INFO:   Starting stage: EVALUATION
2023-01-05 02:18:02,492 INFO:   Done with stage: EVALUATION
2023-01-05 02:18:02,492 INFO:   Leaving out SEQ value Fold_3
2023-01-05 02:18:02,505 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:18:02,505 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:18:03,147 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:18:03,147 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:18:03,215 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:18:03,216 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:18:03,216 INFO:     No hyperparam tuning for this model
2023-01-05 02:18:03,216 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:18:03,216 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:18:03,217 INFO:     None feature selector for col prot
2023-01-05 02:18:03,217 INFO:     None feature selector for col prot
2023-01-05 02:18:03,217 INFO:     None feature selector for col prot
2023-01-05 02:18:03,217 INFO:     None feature selector for col chem
2023-01-05 02:18:03,217 INFO:     None feature selector for col chem
2023-01-05 02:18:03,218 INFO:     None feature selector for col chem
2023-01-05 02:18:03,218 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:18:03,218 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:18:03,219 INFO:     Number of params in model 72931
2023-01-05 02:18:03,222 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:18:03,222 INFO:   Starting stage: TRAINING
2023-01-05 02:18:03,283 INFO:     Val loss before train {'Reaction outcome loss': 1.0624122142791748, 'Total loss': 1.0624122142791748}
2023-01-05 02:18:03,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:03,284 INFO:     Epoch: 0
2023-01-05 02:18:05,521 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8308171351750692, 'Total loss': 0.8308171351750692} | train loss {'Reaction outcome loss': 0.9587845923039164, 'Total loss': 0.9587845923039164}
2023-01-05 02:18:05,522 INFO:     Found new best model at epoch 0
2023-01-05 02:18:05,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:05,523 INFO:     Epoch: 1
2023-01-05 02:18:07,776 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5792948782444001, 'Total loss': 0.5792948782444001} | train loss {'Reaction outcome loss': 0.6554577379439869, 'Total loss': 0.6554577379439869}
2023-01-05 02:18:07,776 INFO:     Found new best model at epoch 1
2023-01-05 02:18:07,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:07,777 INFO:     Epoch: 2
2023-01-05 02:18:10,028 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5513532241185506, 'Total loss': 0.5513532241185506} | train loss {'Reaction outcome loss': 0.5495364586040922, 'Total loss': 0.5495364586040922}
2023-01-05 02:18:10,028 INFO:     Found new best model at epoch 2
2023-01-05 02:18:10,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:10,029 INFO:     Epoch: 3
2023-01-05 02:18:12,273 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5197726567586263, 'Total loss': 0.5197726567586263} | train loss {'Reaction outcome loss': 0.5122352080949901, 'Total loss': 0.5122352080949901}
2023-01-05 02:18:12,273 INFO:     Found new best model at epoch 3
2023-01-05 02:18:12,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:12,274 INFO:     Epoch: 4
2023-01-05 02:18:14,516 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4952218612035116, 'Total loss': 0.4952218612035116} | train loss {'Reaction outcome loss': 0.4821133109992438, 'Total loss': 0.4821133109992438}
2023-01-05 02:18:14,516 INFO:     Found new best model at epoch 4
2023-01-05 02:18:14,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:14,518 INFO:     Epoch: 5
2023-01-05 02:18:16,746 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4584512154261271, 'Total loss': 0.4584512154261271} | train loss {'Reaction outcome loss': 0.45662013076952773, 'Total loss': 0.45662013076952773}
2023-01-05 02:18:16,746 INFO:     Found new best model at epoch 5
2023-01-05 02:18:16,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:16,748 INFO:     Epoch: 6
2023-01-05 02:18:18,934 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4577230751514435, 'Total loss': 0.4577230751514435} | train loss {'Reaction outcome loss': 0.43593244298096123, 'Total loss': 0.43593244298096123}
2023-01-05 02:18:18,934 INFO:     Found new best model at epoch 6
2023-01-05 02:18:18,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:18,936 INFO:     Epoch: 7
2023-01-05 02:18:21,118 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4577289789915085, 'Total loss': 0.4577289789915085} | train loss {'Reaction outcome loss': 0.4222676986488548, 'Total loss': 0.4222676986488548}
2023-01-05 02:18:21,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:21,118 INFO:     Epoch: 8
2023-01-05 02:18:23,367 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4643470178047816, 'Total loss': 0.4643470178047816} | train loss {'Reaction outcome loss': 0.4098580366503583, 'Total loss': 0.4098580366503583}
2023-01-05 02:18:23,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:23,367 INFO:     Epoch: 9
2023-01-05 02:18:25,565 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44896013538042706, 'Total loss': 0.44896013538042706} | train loss {'Reaction outcome loss': 0.3993732176557945, 'Total loss': 0.3993732176557945}
2023-01-05 02:18:25,565 INFO:     Found new best model at epoch 9
2023-01-05 02:18:25,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:25,566 INFO:     Epoch: 10
2023-01-05 02:18:27,764 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4476501305898031, 'Total loss': 0.4476501305898031} | train loss {'Reaction outcome loss': 0.3848431862510034, 'Total loss': 0.3848431862510034}
2023-01-05 02:18:27,764 INFO:     Found new best model at epoch 10
2023-01-05 02:18:27,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:27,765 INFO:     Epoch: 11
2023-01-05 02:18:29,979 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4582757572333018, 'Total loss': 0.4582757572333018} | train loss {'Reaction outcome loss': 0.3749456004015286, 'Total loss': 0.3749456004015286}
2023-01-05 02:18:29,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:29,979 INFO:     Epoch: 12
2023-01-05 02:18:32,142 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42103443245093025, 'Total loss': 0.42103443245093025} | train loss {'Reaction outcome loss': 0.3692909848679156, 'Total loss': 0.3692909848679156}
2023-01-05 02:18:32,143 INFO:     Found new best model at epoch 12
2023-01-05 02:18:32,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:32,145 INFO:     Epoch: 13
2023-01-05 02:18:34,368 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43687721093495685, 'Total loss': 0.43687721093495685} | train loss {'Reaction outcome loss': 0.36056800363381414, 'Total loss': 0.36056800363381414}
2023-01-05 02:18:34,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:34,368 INFO:     Epoch: 14
2023-01-05 02:18:36,540 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41458297868569693, 'Total loss': 0.41458297868569693} | train loss {'Reaction outcome loss': 0.3507417069788832, 'Total loss': 0.3507417069788832}
2023-01-05 02:18:36,540 INFO:     Found new best model at epoch 14
2023-01-05 02:18:36,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:36,541 INFO:     Epoch: 15
2023-01-05 02:18:38,704 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41808328131834666, 'Total loss': 0.41808328131834666} | train loss {'Reaction outcome loss': 0.3421214483678341, 'Total loss': 0.3421214483678341}
2023-01-05 02:18:38,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:38,705 INFO:     Epoch: 16
2023-01-05 02:18:40,875 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4333995819091797, 'Total loss': 0.4333995819091797} | train loss {'Reaction outcome loss': 0.3322739135066088, 'Total loss': 0.3322739135066088}
2023-01-05 02:18:40,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:40,875 INFO:     Epoch: 17
2023-01-05 02:18:43,097 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4400778273741404, 'Total loss': 0.4400778273741404} | train loss {'Reaction outcome loss': 0.32761655024585934, 'Total loss': 0.32761655024585934}
2023-01-05 02:18:43,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:43,097 INFO:     Epoch: 18
2023-01-05 02:18:45,274 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4439689596494039, 'Total loss': 0.4439689596494039} | train loss {'Reaction outcome loss': 0.3260131433578956, 'Total loss': 0.3260131433578956}
2023-01-05 02:18:45,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:45,274 INFO:     Epoch: 19
2023-01-05 02:18:47,492 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42541785538196564, 'Total loss': 0.42541785538196564} | train loss {'Reaction outcome loss': 0.31407220876456177, 'Total loss': 0.31407220876456177}
2023-01-05 02:18:47,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:47,492 INFO:     Epoch: 20
2023-01-05 02:18:49,740 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44157108863194783, 'Total loss': 0.44157108863194783} | train loss {'Reaction outcome loss': 0.3070345611114354, 'Total loss': 0.3070345611114354}
2023-01-05 02:18:49,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:49,740 INFO:     Epoch: 21
2023-01-05 02:18:51,877 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4223785857359568, 'Total loss': 0.4223785857359568} | train loss {'Reaction outcome loss': 0.3048841592033196, 'Total loss': 0.3048841592033196}
2023-01-05 02:18:51,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:51,878 INFO:     Epoch: 22
2023-01-05 02:18:54,047 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44155672887961067, 'Total loss': 0.44155672887961067} | train loss {'Reaction outcome loss': 0.295953348360575, 'Total loss': 0.295953348360575}
2023-01-05 02:18:54,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:54,048 INFO:     Epoch: 23
2023-01-05 02:18:56,290 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4444288750489553, 'Total loss': 0.4444288750489553} | train loss {'Reaction outcome loss': 0.2914712050263464, 'Total loss': 0.2914712050263464}
2023-01-05 02:18:56,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:56,290 INFO:     Epoch: 24
2023-01-05 02:18:58,471 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41770058013498784, 'Total loss': 0.41770058013498784} | train loss {'Reaction outcome loss': 0.2874632618478397, 'Total loss': 0.2874632618478397}
2023-01-05 02:18:58,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:18:58,472 INFO:     Epoch: 25
2023-01-05 02:19:00,665 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4393003940582275, 'Total loss': 0.4393003940582275} | train loss {'Reaction outcome loss': 0.27946579507993957, 'Total loss': 0.27946579507993957}
2023-01-05 02:19:00,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:00,665 INFO:     Epoch: 26
2023-01-05 02:19:02,908 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46700779994328817, 'Total loss': 0.46700779994328817} | train loss {'Reaction outcome loss': 0.27517972414103087, 'Total loss': 0.27517972414103087}
2023-01-05 02:19:02,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:02,908 INFO:     Epoch: 27
2023-01-05 02:19:05,113 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4442235499620438, 'Total loss': 0.4442235499620438} | train loss {'Reaction outcome loss': 0.26856836502569437, 'Total loss': 0.26856836502569437}
2023-01-05 02:19:05,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:05,113 INFO:     Epoch: 28
2023-01-05 02:19:07,317 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4431177238623301, 'Total loss': 0.4431177238623301} | train loss {'Reaction outcome loss': 0.2602544634528186, 'Total loss': 0.2602544634528186}
2023-01-05 02:19:07,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:07,318 INFO:     Epoch: 29
2023-01-05 02:19:09,540 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4538725475470225, 'Total loss': 0.4538725475470225} | train loss {'Reaction outcome loss': 0.2584059426873705, 'Total loss': 0.2584059426873705}
2023-01-05 02:19:09,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:09,540 INFO:     Epoch: 30
2023-01-05 02:19:11,738 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48888797760009767, 'Total loss': 0.48888797760009767} | train loss {'Reaction outcome loss': 0.2530951331621104, 'Total loss': 0.2530951331621104}
2023-01-05 02:19:11,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:11,738 INFO:     Epoch: 31
2023-01-05 02:19:13,957 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49745189150174457, 'Total loss': 0.49745189150174457} | train loss {'Reaction outcome loss': 0.24873446954590997, 'Total loss': 0.24873446954590997}
2023-01-05 02:19:13,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:13,958 INFO:     Epoch: 32
2023-01-05 02:19:16,125 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4859899292389552, 'Total loss': 0.4859899292389552} | train loss {'Reaction outcome loss': 0.247001877353683, 'Total loss': 0.247001877353683}
2023-01-05 02:19:16,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:16,126 INFO:     Epoch: 33
2023-01-05 02:19:18,319 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47572903434435526, 'Total loss': 0.47572903434435526} | train loss {'Reaction outcome loss': 0.2427241009163813, 'Total loss': 0.2427241009163813}
2023-01-05 02:19:18,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:18,319 INFO:     Epoch: 34
2023-01-05 02:19:20,531 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.461659607787927, 'Total loss': 0.461659607787927} | train loss {'Reaction outcome loss': 0.24793495315324215, 'Total loss': 0.24793495315324215}
2023-01-05 02:19:20,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:20,532 INFO:     Epoch: 35
2023-01-05 02:19:22,717 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.511640735467275, 'Total loss': 0.511640735467275} | train loss {'Reaction outcome loss': 0.23589814595714972, 'Total loss': 0.23589814595714972}
2023-01-05 02:19:22,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:22,718 INFO:     Epoch: 36
2023-01-05 02:19:24,924 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4715717971324921, 'Total loss': 0.4715717971324921} | train loss {'Reaction outcome loss': 0.2365819369952609, 'Total loss': 0.2365819369952609}
2023-01-05 02:19:24,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:24,925 INFO:     Epoch: 37
2023-01-05 02:19:27,111 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5013690183560053, 'Total loss': 0.5013690183560053} | train loss {'Reaction outcome loss': 0.22942082086292498, 'Total loss': 0.22942082086292498}
2023-01-05 02:19:27,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:27,112 INFO:     Epoch: 38
2023-01-05 02:19:29,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48631100555260975, 'Total loss': 0.48631100555260975} | train loss {'Reaction outcome loss': 0.22739851372792338, 'Total loss': 0.22739851372792338}
2023-01-05 02:19:29,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:29,324 INFO:     Epoch: 39
2023-01-05 02:19:31,535 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4915805379549662, 'Total loss': 0.4915805379549662} | train loss {'Reaction outcome loss': 0.22660282690988948, 'Total loss': 0.22660282690988948}
2023-01-05 02:19:31,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:31,536 INFO:     Epoch: 40
2023-01-05 02:19:33,749 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4902324676513672, 'Total loss': 0.4902324676513672} | train loss {'Reaction outcome loss': 0.22326467245354922, 'Total loss': 0.22326467245354922}
2023-01-05 02:19:33,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:33,749 INFO:     Epoch: 41
2023-01-05 02:19:35,914 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4645859658718109, 'Total loss': 0.4645859658718109} | train loss {'Reaction outcome loss': 0.2210100808615939, 'Total loss': 0.2210100808615939}
2023-01-05 02:19:35,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:35,914 INFO:     Epoch: 42
2023-01-05 02:19:38,157 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47636786609267195, 'Total loss': 0.47636786609267195} | train loss {'Reaction outcome loss': 0.21954890193730375, 'Total loss': 0.21954890193730375}
2023-01-05 02:19:38,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:38,158 INFO:     Epoch: 43
2023-01-05 02:19:40,347 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.503578903277715, 'Total loss': 0.503578903277715} | train loss {'Reaction outcome loss': 0.213370357810037, 'Total loss': 0.213370357810037}
2023-01-05 02:19:40,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:40,348 INFO:     Epoch: 44
2023-01-05 02:19:42,576 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.522154477238655, 'Total loss': 0.522154477238655} | train loss {'Reaction outcome loss': 0.21445162499826537, 'Total loss': 0.21445162499826537}
2023-01-05 02:19:42,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:42,576 INFO:     Epoch: 45
2023-01-05 02:19:44,844 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48776907175779344, 'Total loss': 0.48776907175779344} | train loss {'Reaction outcome loss': 0.2168743849976709, 'Total loss': 0.2168743849976709}
2023-01-05 02:19:44,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:44,845 INFO:     Epoch: 46
2023-01-05 02:19:47,054 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5115296165148417, 'Total loss': 0.5115296165148417} | train loss {'Reaction outcome loss': 0.20400029605417683, 'Total loss': 0.20400029605417683}
2023-01-05 02:19:47,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:47,055 INFO:     Epoch: 47
2023-01-05 02:19:49,316 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5123370096087456, 'Total loss': 0.5123370096087456} | train loss {'Reaction outcome loss': 0.20814020115283938, 'Total loss': 0.20814020115283938}
2023-01-05 02:19:49,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:49,316 INFO:     Epoch: 48
2023-01-05 02:19:51,574 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5170597399274508, 'Total loss': 0.5170597399274508} | train loss {'Reaction outcome loss': 0.2079150988278489, 'Total loss': 0.2079150988278489}
2023-01-05 02:19:51,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:51,575 INFO:     Epoch: 49
2023-01-05 02:19:53,815 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5099033643802007, 'Total loss': 0.5099033643802007} | train loss {'Reaction outcome loss': 0.20382615573785817, 'Total loss': 0.20382615573785817}
2023-01-05 02:19:53,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:53,816 INFO:     Epoch: 50
2023-01-05 02:19:56,047 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49350698093573253, 'Total loss': 0.49350698093573253} | train loss {'Reaction outcome loss': 0.20247437268577134, 'Total loss': 0.20247437268577134}
2023-01-05 02:19:56,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:56,047 INFO:     Epoch: 51
2023-01-05 02:19:58,276 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5028893033663432, 'Total loss': 0.5028893033663432} | train loss {'Reaction outcome loss': 0.20238985854411756, 'Total loss': 0.20238985854411756}
2023-01-05 02:19:58,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:19:58,277 INFO:     Epoch: 52
2023-01-05 02:20:00,536 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5107265988985698, 'Total loss': 0.5107265988985698} | train loss {'Reaction outcome loss': 0.20209830014347813, 'Total loss': 0.20209830014347813}
2023-01-05 02:20:00,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:00,537 INFO:     Epoch: 53
2023-01-05 02:20:02,783 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5108048439025878, 'Total loss': 0.5108048439025878} | train loss {'Reaction outcome loss': 0.20185861100585464, 'Total loss': 0.20185861100585464}
2023-01-05 02:20:02,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:02,783 INFO:     Epoch: 54
2023-01-05 02:20:05,039 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4907949388027191, 'Total loss': 0.4907949388027191} | train loss {'Reaction outcome loss': 0.19327307648848008, 'Total loss': 0.19327307648848008}
2023-01-05 02:20:05,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:05,040 INFO:     Epoch: 55
2023-01-05 02:20:07,342 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5440950910250346, 'Total loss': 0.5440950910250346} | train loss {'Reaction outcome loss': 0.1963459187353805, 'Total loss': 0.1963459187353805}
2023-01-05 02:20:07,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:07,343 INFO:     Epoch: 56
2023-01-05 02:20:09,580 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5354633579651514, 'Total loss': 0.5354633579651514} | train loss {'Reaction outcome loss': 0.19608839485032933, 'Total loss': 0.19608839485032933}
2023-01-05 02:20:09,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:09,580 INFO:     Epoch: 57
2023-01-05 02:20:11,771 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48420580476522446, 'Total loss': 0.48420580476522446} | train loss {'Reaction outcome loss': 0.1951891190804079, 'Total loss': 0.1951891190804079}
2023-01-05 02:20:11,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:11,772 INFO:     Epoch: 58
2023-01-05 02:20:13,997 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5222356418768564, 'Total loss': 0.5222356418768564} | train loss {'Reaction outcome loss': 0.19361562070260027, 'Total loss': 0.19361562070260027}
2023-01-05 02:20:13,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:13,999 INFO:     Epoch: 59
2023-01-05 02:20:16,112 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48985904157161714, 'Total loss': 0.48985904157161714} | train loss {'Reaction outcome loss': 0.19560914994455383, 'Total loss': 0.19560914994455383}
2023-01-05 02:20:16,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:16,112 INFO:     Epoch: 60
2023-01-05 02:20:18,290 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4924482638637225, 'Total loss': 0.4924482638637225} | train loss {'Reaction outcome loss': 0.1867725291071854, 'Total loss': 0.1867725291071854}
2023-01-05 02:20:18,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:18,290 INFO:     Epoch: 61
2023-01-05 02:20:20,446 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5314876238505045, 'Total loss': 0.5314876238505045} | train loss {'Reaction outcome loss': 0.1905636594878904, 'Total loss': 0.1905636594878904}
2023-01-05 02:20:20,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:20,447 INFO:     Epoch: 62
2023-01-05 02:20:22,656 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5051350851853689, 'Total loss': 0.5051350851853689} | train loss {'Reaction outcome loss': 0.19177950778636185, 'Total loss': 0.19177950778636185}
2023-01-05 02:20:22,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:22,656 INFO:     Epoch: 63
2023-01-05 02:20:24,834 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48153454760710396, 'Total loss': 0.48153454760710396} | train loss {'Reaction outcome loss': 0.18725219133724696, 'Total loss': 0.18725219133724696}
2023-01-05 02:20:24,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:24,834 INFO:     Epoch: 64
2023-01-05 02:20:27,084 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49287820756435397, 'Total loss': 0.49287820756435397} | train loss {'Reaction outcome loss': 0.1852579787339553, 'Total loss': 0.1852579787339553}
2023-01-05 02:20:27,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:27,084 INFO:     Epoch: 65
2023-01-05 02:20:29,324 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5169948279857636, 'Total loss': 0.5169948279857636} | train loss {'Reaction outcome loss': 0.18769678247439928, 'Total loss': 0.18769678247439928}
2023-01-05 02:20:29,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:29,325 INFO:     Epoch: 66
2023-01-05 02:20:31,526 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4759281019369761, 'Total loss': 0.4759281019369761} | train loss {'Reaction outcome loss': 0.19047804291353282, 'Total loss': 0.19047804291353282}
2023-01-05 02:20:31,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:31,527 INFO:     Epoch: 67
2023-01-05 02:20:33,744 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.533727706472079, 'Total loss': 0.533727706472079} | train loss {'Reaction outcome loss': 0.1811562264813994, 'Total loss': 0.1811562264813994}
2023-01-05 02:20:33,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:33,745 INFO:     Epoch: 68
2023-01-05 02:20:35,994 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.53213116923968, 'Total loss': 0.53213116923968} | train loss {'Reaction outcome loss': 0.18156917119759006, 'Total loss': 0.18156917119759006}
2023-01-05 02:20:35,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:35,994 INFO:     Epoch: 69
2023-01-05 02:20:38,252 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49421599904696145, 'Total loss': 0.49421599904696145} | train loss {'Reaction outcome loss': 0.1819026833994953, 'Total loss': 0.1819026833994953}
2023-01-05 02:20:38,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:38,252 INFO:     Epoch: 70
2023-01-05 02:20:40,481 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5028863211472829, 'Total loss': 0.5028863211472829} | train loss {'Reaction outcome loss': 0.17505211496800457, 'Total loss': 0.17505211496800457}
2023-01-05 02:20:40,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:40,482 INFO:     Epoch: 71
2023-01-05 02:20:42,731 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49807490905125934, 'Total loss': 0.49807490905125934} | train loss {'Reaction outcome loss': 0.18455175904261398, 'Total loss': 0.18455175904261398}
2023-01-05 02:20:42,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:42,731 INFO:     Epoch: 72
2023-01-05 02:20:44,961 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5073555370171865, 'Total loss': 0.5073555370171865} | train loss {'Reaction outcome loss': 0.18001561164584037, 'Total loss': 0.18001561164584037}
2023-01-05 02:20:44,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:44,961 INFO:     Epoch: 73
2023-01-05 02:20:47,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4959935446580251, 'Total loss': 0.4959935446580251} | train loss {'Reaction outcome loss': 0.1780241068595354, 'Total loss': 0.1780241068595354}
2023-01-05 02:20:47,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:47,228 INFO:     Epoch: 74
2023-01-05 02:20:49,493 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47954289987683296, 'Total loss': 0.47954289987683296} | train loss {'Reaction outcome loss': 0.1760881999847445, 'Total loss': 0.1760881999847445}
2023-01-05 02:20:49,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:49,495 INFO:     Epoch: 75
2023-01-05 02:20:51,707 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4810891717672348, 'Total loss': 0.4810891717672348} | train loss {'Reaction outcome loss': 0.17945752973008874, 'Total loss': 0.17945752973008874}
2023-01-05 02:20:51,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:51,708 INFO:     Epoch: 76
2023-01-05 02:20:53,951 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4910014321406682, 'Total loss': 0.4910014321406682} | train loss {'Reaction outcome loss': 0.17653627230031213, 'Total loss': 0.17653627230031213}
2023-01-05 02:20:53,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:53,952 INFO:     Epoch: 77
2023-01-05 02:20:56,132 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48080046971638996, 'Total loss': 0.48080046971638996} | train loss {'Reaction outcome loss': 0.17167883025427913, 'Total loss': 0.17167883025427913}
2023-01-05 02:20:56,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:56,133 INFO:     Epoch: 78
2023-01-05 02:20:58,280 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5239599466323852, 'Total loss': 0.5239599466323852} | train loss {'Reaction outcome loss': 0.17024048961304727, 'Total loss': 0.17024048961304727}
2023-01-05 02:20:58,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:20:58,281 INFO:     Epoch: 79
2023-01-05 02:21:00,479 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4888470602532228, 'Total loss': 0.4888470602532228} | train loss {'Reaction outcome loss': 0.1679697390203874, 'Total loss': 0.1679697390203874}
2023-01-05 02:21:00,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:00,479 INFO:     Epoch: 80
2023-01-05 02:21:02,656 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.50113525390625, 'Total loss': 0.50113525390625} | train loss {'Reaction outcome loss': 0.17165356805806395, 'Total loss': 0.17165356805806395}
2023-01-05 02:21:02,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:02,657 INFO:     Epoch: 81
2023-01-05 02:21:04,902 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5290378471215565, 'Total loss': 0.5290378471215565} | train loss {'Reaction outcome loss': 0.17556589950780202, 'Total loss': 0.17556589950780202}
2023-01-05 02:21:04,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:04,902 INFO:     Epoch: 82
2023-01-05 02:21:07,145 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5241873274246852, 'Total loss': 0.5241873274246852} | train loss {'Reaction outcome loss': 0.16937202602424353, 'Total loss': 0.16937202602424353}
2023-01-05 02:21:07,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:07,145 INFO:     Epoch: 83
2023-01-05 02:21:09,376 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49817702968915306, 'Total loss': 0.49817702968915306} | train loss {'Reaction outcome loss': 0.17736209492219518, 'Total loss': 0.17736209492219518}
2023-01-05 02:21:09,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:09,377 INFO:     Epoch: 84
2023-01-05 02:21:11,611 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5108464459578196, 'Total loss': 0.5108464459578196} | train loss {'Reaction outcome loss': 0.1669087333988779, 'Total loss': 0.1669087333988779}
2023-01-05 02:21:11,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:11,611 INFO:     Epoch: 85
2023-01-05 02:21:13,865 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48908353348573047, 'Total loss': 0.48908353348573047} | train loss {'Reaction outcome loss': 0.16854397156683687, 'Total loss': 0.16854397156683687}
2023-01-05 02:21:13,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:13,865 INFO:     Epoch: 86
2023-01-05 02:21:16,121 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4850208818912506, 'Total loss': 0.4850208818912506} | train loss {'Reaction outcome loss': 0.17156534593375602, 'Total loss': 0.17156534593375602}
2023-01-05 02:21:16,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:16,121 INFO:     Epoch: 87
2023-01-05 02:21:18,314 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4942286702726657, 'Total loss': 0.4942286702726657} | train loss {'Reaction outcome loss': 0.16507401750728923, 'Total loss': 0.16507401750728923}
2023-01-05 02:21:18,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:18,315 INFO:     Epoch: 88
2023-01-05 02:21:20,533 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49132687548796333, 'Total loss': 0.49132687548796333} | train loss {'Reaction outcome loss': 0.1703174550971696, 'Total loss': 0.1703174550971696}
2023-01-05 02:21:20,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:20,534 INFO:     Epoch: 89
2023-01-05 02:21:22,778 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4849143842856089, 'Total loss': 0.4849143842856089} | train loss {'Reaction outcome loss': 0.16758187084601525, 'Total loss': 0.16758187084601525}
2023-01-05 02:21:22,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:22,778 INFO:     Epoch: 90
2023-01-05 02:21:25,026 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4863565367956956, 'Total loss': 0.4863565367956956} | train loss {'Reaction outcome loss': 0.16665713270500737, 'Total loss': 0.16665713270500737}
2023-01-05 02:21:25,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:25,026 INFO:     Epoch: 91
2023-01-05 02:21:27,282 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5061175346374511, 'Total loss': 0.5061175346374511} | train loss {'Reaction outcome loss': 0.16629759535655705, 'Total loss': 0.16629759535655705}
2023-01-05 02:21:27,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:27,283 INFO:     Epoch: 92
2023-01-05 02:21:29,526 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4964571634928385, 'Total loss': 0.4964571634928385} | train loss {'Reaction outcome loss': 0.1647446355867424, 'Total loss': 0.1647446355867424}
2023-01-05 02:21:29,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:29,526 INFO:     Epoch: 93
2023-01-05 02:21:31,738 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4937341302633286, 'Total loss': 0.4937341302633286} | train loss {'Reaction outcome loss': 0.1717414383752693, 'Total loss': 0.1717414383752693}
2023-01-05 02:21:31,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:31,739 INFO:     Epoch: 94
2023-01-05 02:21:33,965 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5338857312997182, 'Total loss': 0.5338857312997182} | train loss {'Reaction outcome loss': 0.16528911711682095, 'Total loss': 0.16528911711682095}
2023-01-05 02:21:33,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:33,966 INFO:     Epoch: 95
2023-01-05 02:21:36,200 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5181159635384878, 'Total loss': 0.5181159635384878} | train loss {'Reaction outcome loss': 0.16368940942342916, 'Total loss': 0.16368940942342916}
2023-01-05 02:21:36,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:36,200 INFO:     Epoch: 96
2023-01-05 02:21:38,460 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5211659746865431, 'Total loss': 0.5211659746865431} | train loss {'Reaction outcome loss': 0.16378196758170524, 'Total loss': 0.16378196758170524}
2023-01-05 02:21:38,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:38,461 INFO:     Epoch: 97
2023-01-05 02:21:40,717 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5368942429622015, 'Total loss': 0.5368942429622015} | train loss {'Reaction outcome loss': 0.16521922473109116, 'Total loss': 0.16521922473109116}
2023-01-05 02:21:40,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:40,718 INFO:     Epoch: 98
2023-01-05 02:21:42,960 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5304387827714284, 'Total loss': 0.5304387827714284} | train loss {'Reaction outcome loss': 0.16755220564218223, 'Total loss': 0.16755220564218223}
2023-01-05 02:21:42,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:42,960 INFO:     Epoch: 99
2023-01-05 02:21:45,202 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4843958895653486, 'Total loss': 0.4843958895653486} | train loss {'Reaction outcome loss': 0.16271089204845365, 'Total loss': 0.16271089204845365}
2023-01-05 02:21:45,203 INFO:     Best model found after epoch 15 of 100.
2023-01-05 02:21:45,203 INFO:   Done with stage: TRAINING
2023-01-05 02:21:45,203 INFO:   Starting stage: EVALUATION
2023-01-05 02:21:45,345 INFO:   Done with stage: EVALUATION
2023-01-05 02:21:45,345 INFO:   Leaving out SEQ value Fold_4
2023-01-05 02:21:45,358 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 02:21:45,358 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:21:46,019 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:21:46,020 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:21:46,089 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:21:46,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:21:46,089 INFO:     No hyperparam tuning for this model
2023-01-05 02:21:46,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:21:46,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:21:46,090 INFO:     None feature selector for col prot
2023-01-05 02:21:46,090 INFO:     None feature selector for col prot
2023-01-05 02:21:46,090 INFO:     None feature selector for col prot
2023-01-05 02:21:46,091 INFO:     None feature selector for col chem
2023-01-05 02:21:46,091 INFO:     None feature selector for col chem
2023-01-05 02:21:46,091 INFO:     None feature selector for col chem
2023-01-05 02:21:46,091 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:21:46,091 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:21:46,093 INFO:     Number of params in model 72931
2023-01-05 02:21:46,096 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:21:46,096 INFO:   Starting stage: TRAINING
2023-01-05 02:21:46,156 INFO:     Val loss before train {'Reaction outcome loss': 0.9627712865670522, 'Total loss': 0.9627712865670522}
2023-01-05 02:21:46,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:46,156 INFO:     Epoch: 0
2023-01-05 02:21:48,380 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8048446913560231, 'Total loss': 0.8048446913560231} | train loss {'Reaction outcome loss': 0.9597826822512392, 'Total loss': 0.9597826822512392}
2023-01-05 02:21:48,380 INFO:     Found new best model at epoch 0
2023-01-05 02:21:48,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:48,381 INFO:     Epoch: 1
2023-01-05 02:21:50,635 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5616357982158661, 'Total loss': 0.5616357982158661} | train loss {'Reaction outcome loss': 0.6852901188413734, 'Total loss': 0.6852901188413734}
2023-01-05 02:21:50,635 INFO:     Found new best model at epoch 1
2023-01-05 02:21:50,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:50,637 INFO:     Epoch: 2
2023-01-05 02:21:52,844 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.50611545642217, 'Total loss': 0.50611545642217} | train loss {'Reaction outcome loss': 0.5516254302600155, 'Total loss': 0.5516254302600155}
2023-01-05 02:21:52,844 INFO:     Found new best model at epoch 2
2023-01-05 02:21:52,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:52,846 INFO:     Epoch: 3
2023-01-05 02:21:55,043 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4682854413986206, 'Total loss': 0.4682854413986206} | train loss {'Reaction outcome loss': 0.5274688649544681, 'Total loss': 0.5274688649544681}
2023-01-05 02:21:55,043 INFO:     Found new best model at epoch 3
2023-01-05 02:21:55,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:55,045 INFO:     Epoch: 4
2023-01-05 02:21:57,309 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4392565757036209, 'Total loss': 0.4392565757036209} | train loss {'Reaction outcome loss': 0.4724530310174315, 'Total loss': 0.4724530310174315}
2023-01-05 02:21:57,310 INFO:     Found new best model at epoch 4
2023-01-05 02:21:57,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:57,311 INFO:     Epoch: 5
2023-01-05 02:21:59,531 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46633936862150827, 'Total loss': 0.46633936862150827} | train loss {'Reaction outcome loss': 0.44671762324414094, 'Total loss': 0.44671762324414094}
2023-01-05 02:21:59,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:21:59,531 INFO:     Epoch: 6
2023-01-05 02:22:01,682 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42945600549379986, 'Total loss': 0.42945600549379986} | train loss {'Reaction outcome loss': 0.4316760563847113, 'Total loss': 0.4316760563847113}
2023-01-05 02:22:01,682 INFO:     Found new best model at epoch 6
2023-01-05 02:22:01,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:01,683 INFO:     Epoch: 7
2023-01-05 02:22:03,866 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41254332959651946, 'Total loss': 0.41254332959651946} | train loss {'Reaction outcome loss': 0.4168455083517061, 'Total loss': 0.4168455083517061}
2023-01-05 02:22:03,866 INFO:     Found new best model at epoch 7
2023-01-05 02:22:03,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:03,868 INFO:     Epoch: 8
2023-01-05 02:22:06,011 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42220258216063183, 'Total loss': 0.42220258216063183} | train loss {'Reaction outcome loss': 0.40638436161089636, 'Total loss': 0.40638436161089636}
2023-01-05 02:22:06,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:06,012 INFO:     Epoch: 9
2023-01-05 02:22:08,246 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42628657519817353, 'Total loss': 0.42628657519817353} | train loss {'Reaction outcome loss': 0.3933029304110054, 'Total loss': 0.3933029304110054}
2023-01-05 02:22:08,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:08,247 INFO:     Epoch: 10
2023-01-05 02:22:10,467 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.393080598115921, 'Total loss': 0.393080598115921} | train loss {'Reaction outcome loss': 0.3790839068436374, 'Total loss': 0.3790839068436374}
2023-01-05 02:22:10,467 INFO:     Found new best model at epoch 10
2023-01-05 02:22:10,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:10,468 INFO:     Epoch: 11
2023-01-05 02:22:12,685 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41192514399687447, 'Total loss': 0.41192514399687447} | train loss {'Reaction outcome loss': 0.3704498247840303, 'Total loss': 0.3704498247840303}
2023-01-05 02:22:12,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:12,685 INFO:     Epoch: 12
2023-01-05 02:22:14,869 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4299777259429296, 'Total loss': 0.4299777259429296} | train loss {'Reaction outcome loss': 0.36199275985616597, 'Total loss': 0.36199275985616597}
2023-01-05 02:22:14,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:14,870 INFO:     Epoch: 13
2023-01-05 02:22:17,114 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4085692077875137, 'Total loss': 0.4085692077875137} | train loss {'Reaction outcome loss': 0.3597021935426671, 'Total loss': 0.3597021935426671}
2023-01-05 02:22:17,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:17,115 INFO:     Epoch: 14
2023-01-05 02:22:19,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40696602165699003, 'Total loss': 0.40696602165699003} | train loss {'Reaction outcome loss': 0.3529963215013318, 'Total loss': 0.3529963215013318}
2023-01-05 02:22:19,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:19,361 INFO:     Epoch: 15
2023-01-05 02:22:21,629 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3979793071746826, 'Total loss': 0.3979793071746826} | train loss {'Reaction outcome loss': 0.3367897187076185, 'Total loss': 0.3367897187076185}
2023-01-05 02:22:21,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:21,629 INFO:     Epoch: 16
2023-01-05 02:22:23,868 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3958239863316218, 'Total loss': 0.3958239863316218} | train loss {'Reaction outcome loss': 0.33154428683253395, 'Total loss': 0.33154428683253395}
2023-01-05 02:22:23,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:23,868 INFO:     Epoch: 17
2023-01-05 02:22:26,131 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42113808492819466, 'Total loss': 0.42113808492819466} | train loss {'Reaction outcome loss': 0.3220948505660762, 'Total loss': 0.3220948505660762}
2023-01-05 02:22:26,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:26,131 INFO:     Epoch: 18
2023-01-05 02:22:28,362 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3845021938284238, 'Total loss': 0.3845021938284238} | train loss {'Reaction outcome loss': 0.31339211150686647, 'Total loss': 0.31339211150686647}
2023-01-05 02:22:28,363 INFO:     Found new best model at epoch 18
2023-01-05 02:22:28,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:28,365 INFO:     Epoch: 19
2023-01-05 02:22:30,607 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39473218222459155, 'Total loss': 0.39473218222459155} | train loss {'Reaction outcome loss': 0.309635190266198, 'Total loss': 0.309635190266198}
2023-01-05 02:22:30,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:30,607 INFO:     Epoch: 20
2023-01-05 02:22:32,802 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41453903118769325, 'Total loss': 0.41453903118769325} | train loss {'Reaction outcome loss': 0.29871364542961365, 'Total loss': 0.29871364542961365}
2023-01-05 02:22:32,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:32,802 INFO:     Epoch: 21
2023-01-05 02:22:34,987 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4138125201066335, 'Total loss': 0.4138125201066335} | train loss {'Reaction outcome loss': 0.2942194572867489, 'Total loss': 0.2942194572867489}
2023-01-05 02:22:34,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:34,988 INFO:     Epoch: 22
2023-01-05 02:22:37,131 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.384627166390419, 'Total loss': 0.384627166390419} | train loss {'Reaction outcome loss': 0.2899902632799121, 'Total loss': 0.2899902632799121}
2023-01-05 02:22:37,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:37,131 INFO:     Epoch: 23
2023-01-05 02:22:39,366 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3907358109951019, 'Total loss': 0.3907358109951019} | train loss {'Reaction outcome loss': 0.28146108652126184, 'Total loss': 0.28146108652126184}
2023-01-05 02:22:39,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:39,367 INFO:     Epoch: 24
2023-01-05 02:22:41,628 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4208289682865143, 'Total loss': 0.4208289682865143} | train loss {'Reaction outcome loss': 0.27999370504835824, 'Total loss': 0.27999370504835824}
2023-01-05 02:22:41,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:41,629 INFO:     Epoch: 25
2023-01-05 02:22:43,872 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.388101809596022, 'Total loss': 0.388101809596022} | train loss {'Reaction outcome loss': 0.2730006247225717, 'Total loss': 0.2730006247225717}
2023-01-05 02:22:43,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:43,872 INFO:     Epoch: 26
2023-01-05 02:22:46,141 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39897175629933673, 'Total loss': 0.39897175629933673} | train loss {'Reaction outcome loss': 0.2715331934184929, 'Total loss': 0.2715331934184929}
2023-01-05 02:22:46,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:46,141 INFO:     Epoch: 27
2023-01-05 02:22:48,428 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4061130573352178, 'Total loss': 0.4061130573352178} | train loss {'Reaction outcome loss': 0.2639978245057611, 'Total loss': 0.2639978245057611}
2023-01-05 02:22:48,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:48,429 INFO:     Epoch: 28
2023-01-05 02:22:50,682 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42051179309686026, 'Total loss': 0.42051179309686026} | train loss {'Reaction outcome loss': 0.25943488811743376, 'Total loss': 0.25943488811743376}
2023-01-05 02:22:50,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:50,683 INFO:     Epoch: 29
2023-01-05 02:22:52,917 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4256216337283452, 'Total loss': 0.4256216337283452} | train loss {'Reaction outcome loss': 0.2578898045066508, 'Total loss': 0.2578898045066508}
2023-01-05 02:22:52,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:52,918 INFO:     Epoch: 30
2023-01-05 02:22:55,168 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3934378494819005, 'Total loss': 0.3934378494819005} | train loss {'Reaction outcome loss': 0.2521897149744673, 'Total loss': 0.2521897149744673}
2023-01-05 02:22:55,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:55,168 INFO:     Epoch: 31
2023-01-05 02:22:57,382 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4072002708911896, 'Total loss': 0.4072002708911896} | train loss {'Reaction outcome loss': 0.26643909082370065, 'Total loss': 0.26643909082370065}
2023-01-05 02:22:57,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:57,384 INFO:     Epoch: 32
2023-01-05 02:22:59,594 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4129803578058879, 'Total loss': 0.4129803578058879} | train loss {'Reaction outcome loss': 0.24103907188080062, 'Total loss': 0.24103907188080062}
2023-01-05 02:22:59,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:22:59,594 INFO:     Epoch: 33
2023-01-05 02:23:01,773 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38100043336550393, 'Total loss': 0.38100043336550393} | train loss {'Reaction outcome loss': 0.23785518533955124, 'Total loss': 0.23785518533955124}
2023-01-05 02:23:01,773 INFO:     Found new best model at epoch 33
2023-01-05 02:23:01,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:01,775 INFO:     Epoch: 34
2023-01-05 02:23:03,977 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.397670516371727, 'Total loss': 0.397670516371727} | train loss {'Reaction outcome loss': 0.23248364881399777, 'Total loss': 0.23248364881399777}
2023-01-05 02:23:03,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:03,978 INFO:     Epoch: 35
2023-01-05 02:23:06,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4271995743115743, 'Total loss': 0.4271995743115743} | train loss {'Reaction outcome loss': 0.23137300531379879, 'Total loss': 0.23137300531379879}
2023-01-05 02:23:06,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:06,214 INFO:     Epoch: 36
2023-01-05 02:23:08,498 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4077532480160395, 'Total loss': 0.4077532480160395} | train loss {'Reaction outcome loss': 0.2504005411680302, 'Total loss': 0.2504005411680302}
2023-01-05 02:23:08,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:08,498 INFO:     Epoch: 37
2023-01-05 02:23:10,765 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4236711810032527, 'Total loss': 0.4236711810032527} | train loss {'Reaction outcome loss': 0.2437208955753717, 'Total loss': 0.2437208955753717}
2023-01-05 02:23:10,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:10,765 INFO:     Epoch: 38
2023-01-05 02:23:13,048 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45100294748942055, 'Total loss': 0.45100294748942055} | train loss {'Reaction outcome loss': 0.2257285592082105, 'Total loss': 0.2257285592082105}
2023-01-05 02:23:13,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:13,048 INFO:     Epoch: 39
2023-01-05 02:23:15,310 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41732267489035924, 'Total loss': 0.41732267489035924} | train loss {'Reaction outcome loss': 0.22350955526411964, 'Total loss': 0.22350955526411964}
2023-01-05 02:23:15,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:15,310 INFO:     Epoch: 40
2023-01-05 02:23:17,561 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42947395940621697, 'Total loss': 0.42947395940621697} | train loss {'Reaction outcome loss': 0.2186569647348496, 'Total loss': 0.2186569647348496}
2023-01-05 02:23:17,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:17,562 INFO:     Epoch: 41
2023-01-05 02:23:19,851 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4402044415473938, 'Total loss': 0.4402044415473938} | train loss {'Reaction outcome loss': 0.20913590609089242, 'Total loss': 0.20913590609089242}
2023-01-05 02:23:19,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:19,852 INFO:     Epoch: 42
2023-01-05 02:23:22,136 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43966531654198965, 'Total loss': 0.43966531654198965} | train loss {'Reaction outcome loss': 0.20504032936709785, 'Total loss': 0.20504032936709785}
2023-01-05 02:23:22,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:22,136 INFO:     Epoch: 43
2023-01-05 02:23:24,420 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.415636719763279, 'Total loss': 0.415636719763279} | train loss {'Reaction outcome loss': 0.20268060119174744, 'Total loss': 0.20268060119174744}
2023-01-05 02:23:24,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:24,420 INFO:     Epoch: 44
2023-01-05 02:23:26,690 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4392076770464579, 'Total loss': 0.4392076770464579} | train loss {'Reaction outcome loss': 0.20139752568565714, 'Total loss': 0.20139752568565714}
2023-01-05 02:23:26,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:26,690 INFO:     Epoch: 45
2023-01-05 02:23:28,957 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4363459567228953, 'Total loss': 0.4363459567228953} | train loss {'Reaction outcome loss': 0.2027999768727476, 'Total loss': 0.2027999768727476}
2023-01-05 02:23:28,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:28,957 INFO:     Epoch: 46
2023-01-05 02:23:31,235 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4489611893892288, 'Total loss': 0.4489611893892288} | train loss {'Reaction outcome loss': 0.19772477550398343, 'Total loss': 0.19772477550398343}
2023-01-05 02:23:31,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:31,236 INFO:     Epoch: 47
2023-01-05 02:23:33,526 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4249889274438222, 'Total loss': 0.4249889274438222} | train loss {'Reaction outcome loss': 0.19758955295791553, 'Total loss': 0.19758955295791553}
2023-01-05 02:23:33,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:33,527 INFO:     Epoch: 48
2023-01-05 02:23:35,814 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.442423053085804, 'Total loss': 0.442423053085804} | train loss {'Reaction outcome loss': 0.19826245555768895, 'Total loss': 0.19826245555768895}
2023-01-05 02:23:35,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:35,814 INFO:     Epoch: 49
2023-01-05 02:23:38,077 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43563293615976967, 'Total loss': 0.43563293615976967} | train loss {'Reaction outcome loss': 0.19595772328371505, 'Total loss': 0.19595772328371505}
2023-01-05 02:23:38,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:38,077 INFO:     Epoch: 50
2023-01-05 02:23:40,352 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43123070200284325, 'Total loss': 0.43123070200284325} | train loss {'Reaction outcome loss': 0.19353009805764895, 'Total loss': 0.19353009805764895}
2023-01-05 02:23:40,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:40,352 INFO:     Epoch: 51
2023-01-05 02:23:42,605 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42412564853827156, 'Total loss': 0.42412564853827156} | train loss {'Reaction outcome loss': 0.18948993453523144, 'Total loss': 0.18948993453523144}
2023-01-05 02:23:42,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:42,605 INFO:     Epoch: 52
2023-01-05 02:23:44,821 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4198659310738246, 'Total loss': 0.4198659310738246} | train loss {'Reaction outcome loss': 0.18919847895512762, 'Total loss': 0.18919847895512762}
2023-01-05 02:23:44,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:44,821 INFO:     Epoch: 53
2023-01-05 02:23:47,027 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.468666269381841, 'Total loss': 0.468666269381841} | train loss {'Reaction outcome loss': 0.19042164753224916, 'Total loss': 0.19042164753224916}
2023-01-05 02:23:47,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:47,027 INFO:     Epoch: 54
2023-01-05 02:23:49,278 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4492275749643644, 'Total loss': 0.4492275749643644} | train loss {'Reaction outcome loss': 0.1851662444136362, 'Total loss': 0.1851662444136362}
2023-01-05 02:23:49,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:49,278 INFO:     Epoch: 55
2023-01-05 02:23:51,539 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4657945146163305, 'Total loss': 0.4657945146163305} | train loss {'Reaction outcome loss': 0.18483587569325988, 'Total loss': 0.18483587569325988}
2023-01-05 02:23:51,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:51,539 INFO:     Epoch: 56
2023-01-05 02:23:53,778 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4273197324325641, 'Total loss': 0.4273197324325641} | train loss {'Reaction outcome loss': 0.1843706210984501, 'Total loss': 0.1843706210984501}
2023-01-05 02:23:53,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:53,779 INFO:     Epoch: 57
2023-01-05 02:23:56,025 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44829020897547406, 'Total loss': 0.44829020897547406} | train loss {'Reaction outcome loss': 0.186893972105927, 'Total loss': 0.186893972105927}
2023-01-05 02:23:56,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:56,026 INFO:     Epoch: 58
2023-01-05 02:23:58,337 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45787563025951383, 'Total loss': 0.45787563025951383} | train loss {'Reaction outcome loss': 0.18060897107985194, 'Total loss': 0.18060897107985194}
2023-01-05 02:23:58,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:23:58,337 INFO:     Epoch: 59
2023-01-05 02:24:00,651 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4487978825966517, 'Total loss': 0.4487978825966517} | train loss {'Reaction outcome loss': 0.17933488009562032, 'Total loss': 0.17933488009562032}
2023-01-05 02:24:00,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:00,651 INFO:     Epoch: 60
2023-01-05 02:24:02,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4725240816672643, 'Total loss': 0.4725240816672643} | train loss {'Reaction outcome loss': 0.18335081117781912, 'Total loss': 0.18335081117781912}
2023-01-05 02:24:02,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:02,958 INFO:     Epoch: 61
2023-01-05 02:24:05,236 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4694294641415278, 'Total loss': 0.4694294641415278} | train loss {'Reaction outcome loss': 0.177352020257377, 'Total loss': 0.177352020257377}
2023-01-05 02:24:05,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:05,236 INFO:     Epoch: 62
2023-01-05 02:24:07,507 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4846294492483139, 'Total loss': 0.4846294492483139} | train loss {'Reaction outcome loss': 0.18014777265489101, 'Total loss': 0.18014777265489101}
2023-01-05 02:24:07,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:07,507 INFO:     Epoch: 63
2023-01-05 02:24:09,763 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46423976719379423, 'Total loss': 0.46423976719379423} | train loss {'Reaction outcome loss': 0.19894973366889104, 'Total loss': 0.19894973366889104}
2023-01-05 02:24:09,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:09,764 INFO:     Epoch: 64
2023-01-05 02:24:12,019 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44753069678942364, 'Total loss': 0.44753069678942364} | train loss {'Reaction outcome loss': 0.17791195256142892, 'Total loss': 0.17791195256142892}
2023-01-05 02:24:12,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:12,019 INFO:     Epoch: 65
2023-01-05 02:24:14,317 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43697843203941983, 'Total loss': 0.43697843203941983} | train loss {'Reaction outcome loss': 0.17599759042512733, 'Total loss': 0.17599759042512733}
2023-01-05 02:24:14,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:14,317 INFO:     Epoch: 66
2023-01-05 02:24:16,562 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4695674081643422, 'Total loss': 0.4695674081643422} | train loss {'Reaction outcome loss': 0.17188055931628565, 'Total loss': 0.17188055931628565}
2023-01-05 02:24:16,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:16,563 INFO:     Epoch: 67
2023-01-05 02:24:18,829 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4560819000005722, 'Total loss': 0.4560819000005722} | train loss {'Reaction outcome loss': 0.1738393631057461, 'Total loss': 0.1738393631057461}
2023-01-05 02:24:18,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:18,830 INFO:     Epoch: 68
2023-01-05 02:24:21,051 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5002208322286605, 'Total loss': 0.5002208322286605} | train loss {'Reaction outcome loss': 0.16769191771005432, 'Total loss': 0.16769191771005432}
2023-01-05 02:24:21,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:21,051 INFO:     Epoch: 69
2023-01-05 02:24:23,232 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4502405971288681, 'Total loss': 0.4502405971288681} | train loss {'Reaction outcome loss': 0.1705869112275136, 'Total loss': 0.1705869112275136}
2023-01-05 02:24:23,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:23,233 INFO:     Epoch: 70
2023-01-05 02:24:25,351 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4792070607344309, 'Total loss': 0.4792070607344309} | train loss {'Reaction outcome loss': 0.1694305036706256, 'Total loss': 0.1694305036706256}
2023-01-05 02:24:25,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:25,351 INFO:     Epoch: 71
2023-01-05 02:24:27,585 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4441527562836806, 'Total loss': 0.4441527562836806} | train loss {'Reaction outcome loss': 0.17442184880348868, 'Total loss': 0.17442184880348868}
2023-01-05 02:24:27,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:27,585 INFO:     Epoch: 72
2023-01-05 02:24:29,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.455128442744414, 'Total loss': 0.455128442744414} | train loss {'Reaction outcome loss': 0.17290671997487653, 'Total loss': 0.17290671997487653}
2023-01-05 02:24:29,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:29,826 INFO:     Epoch: 73
2023-01-05 02:24:32,068 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49180627465248106, 'Total loss': 0.49180627465248106} | train loss {'Reaction outcome loss': 0.16878874187181203, 'Total loss': 0.16878874187181203}
2023-01-05 02:24:32,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:32,069 INFO:     Epoch: 74
2023-01-05 02:24:34,292 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4896202921867371, 'Total loss': 0.4896202921867371} | train loss {'Reaction outcome loss': 0.16647857965234952, 'Total loss': 0.16647857965234952}
2023-01-05 02:24:34,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:34,292 INFO:     Epoch: 75
2023-01-05 02:24:36,535 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4314795484145482, 'Total loss': 0.4314795484145482} | train loss {'Reaction outcome loss': 0.16558216849496576, 'Total loss': 0.16558216849496576}
2023-01-05 02:24:36,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:36,536 INFO:     Epoch: 76
2023-01-05 02:24:38,796 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45929408172766367, 'Total loss': 0.45929408172766367} | train loss {'Reaction outcome loss': 0.1651196119745019, 'Total loss': 0.1651196119745019}
2023-01-05 02:24:38,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:38,796 INFO:     Epoch: 77
2023-01-05 02:24:41,038 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4509315058588982, 'Total loss': 0.4509315058588982} | train loss {'Reaction outcome loss': 0.1637394438713681, 'Total loss': 0.1637394438713681}
2023-01-05 02:24:41,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:41,039 INFO:     Epoch: 78
2023-01-05 02:24:43,275 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43919296463330587, 'Total loss': 0.43919296463330587} | train loss {'Reaction outcome loss': 0.1691312510064418, 'Total loss': 0.1691312510064418}
2023-01-05 02:24:43,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:43,276 INFO:     Epoch: 79
2023-01-05 02:24:45,499 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45182638068993886, 'Total loss': 0.45182638068993886} | train loss {'Reaction outcome loss': 0.16384097934106662, 'Total loss': 0.16384097934106662}
2023-01-05 02:24:45,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:45,500 INFO:     Epoch: 80
2023-01-05 02:24:47,725 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4819285124540329, 'Total loss': 0.4819285124540329} | train loss {'Reaction outcome loss': 0.18946865859412565, 'Total loss': 0.18946865859412565}
2023-01-05 02:24:47,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:47,725 INFO:     Epoch: 81
2023-01-05 02:24:49,978 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46178714036941526, 'Total loss': 0.46178714036941526} | train loss {'Reaction outcome loss': 0.1792457487596118, 'Total loss': 0.1792457487596118}
2023-01-05 02:24:49,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:49,978 INFO:     Epoch: 82
2023-01-05 02:24:52,213 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4685261259476344, 'Total loss': 0.4685261259476344} | train loss {'Reaction outcome loss': 0.17366429293446034, 'Total loss': 0.17366429293446034}
2023-01-05 02:24:52,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:52,214 INFO:     Epoch: 83
2023-01-05 02:24:54,471 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44561774333318077, 'Total loss': 0.44561774333318077} | train loss {'Reaction outcome loss': 0.16698235189002278, 'Total loss': 0.16698235189002278}
2023-01-05 02:24:54,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:54,471 INFO:     Epoch: 84
2023-01-05 02:24:56,716 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48363932768503826, 'Total loss': 0.48363932768503826} | train loss {'Reaction outcome loss': 0.16416954824534766, 'Total loss': 0.16416954824534766}
2023-01-05 02:24:56,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:56,716 INFO:     Epoch: 85
2023-01-05 02:24:58,899 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5025790127615134, 'Total loss': 0.5025790127615134} | train loss {'Reaction outcome loss': 0.16685399212440025, 'Total loss': 0.16685399212440025}
2023-01-05 02:24:58,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:24:58,899 INFO:     Epoch: 86
2023-01-05 02:25:01,158 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4816490282615026, 'Total loss': 0.4816490282615026} | train loss {'Reaction outcome loss': 0.1618375632037962, 'Total loss': 0.1618375632037962}
2023-01-05 02:25:01,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:01,158 INFO:     Epoch: 87
2023-01-05 02:25:03,401 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4581203709046046, 'Total loss': 0.4581203709046046} | train loss {'Reaction outcome loss': 0.16159559130372383, 'Total loss': 0.16159559130372383}
2023-01-05 02:25:03,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:03,402 INFO:     Epoch: 88
2023-01-05 02:25:05,660 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4792103379964828, 'Total loss': 0.4792103379964828} | train loss {'Reaction outcome loss': 0.16144850213785886, 'Total loss': 0.16144850213785886}
2023-01-05 02:25:05,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:05,661 INFO:     Epoch: 89
2023-01-05 02:25:07,932 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4922622859477997, 'Total loss': 0.4922622859477997} | train loss {'Reaction outcome loss': 0.1585376914303777, 'Total loss': 0.1585376914303777}
2023-01-05 02:25:07,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:07,932 INFO:     Epoch: 90
2023-01-05 02:25:10,184 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48515851298968, 'Total loss': 0.48515851298968} | train loss {'Reaction outcome loss': 0.15823993728216906, 'Total loss': 0.15823993728216906}
2023-01-05 02:25:10,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:10,184 INFO:     Epoch: 91
2023-01-05 02:25:12,443 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44863455997159085, 'Total loss': 0.44863455997159085} | train loss {'Reaction outcome loss': 0.16007424693628086, 'Total loss': 0.16007424693628086}
2023-01-05 02:25:12,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:12,443 INFO:     Epoch: 92
2023-01-05 02:25:14,679 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49232862194379173, 'Total loss': 0.49232862194379173} | train loss {'Reaction outcome loss': 0.1579993172394018, 'Total loss': 0.1579993172394018}
2023-01-05 02:25:14,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:14,679 INFO:     Epoch: 93
2023-01-05 02:25:16,906 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4580213248729706, 'Total loss': 0.4580213248729706} | train loss {'Reaction outcome loss': 0.15828092819572412, 'Total loss': 0.15828092819572412}
2023-01-05 02:25:16,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:16,906 INFO:     Epoch: 94
2023-01-05 02:25:19,103 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5012596180041631, 'Total loss': 0.5012596180041631} | train loss {'Reaction outcome loss': 0.1579629044500652, 'Total loss': 0.1579629044500652}
2023-01-05 02:25:19,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:19,103 INFO:     Epoch: 95
2023-01-05 02:25:21,342 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44155706465244293, 'Total loss': 0.44155706465244293} | train loss {'Reaction outcome loss': 0.15889359352933383, 'Total loss': 0.15889359352933383}
2023-01-05 02:25:21,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:21,344 INFO:     Epoch: 96
2023-01-05 02:25:23,605 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4531098961830139, 'Total loss': 0.4531098961830139} | train loss {'Reaction outcome loss': 0.16034560465587952, 'Total loss': 0.16034560465587952}
2023-01-05 02:25:23,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:23,606 INFO:     Epoch: 97
2023-01-05 02:25:25,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4957172671953837, 'Total loss': 0.4957172671953837} | train loss {'Reaction outcome loss': 0.16392569915700259, 'Total loss': 0.16392569915700259}
2023-01-05 02:25:25,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:25,843 INFO:     Epoch: 98
2023-01-05 02:25:28,075 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46500658815105755, 'Total loss': 0.46500658815105755} | train loss {'Reaction outcome loss': 0.15336166623055233, 'Total loss': 0.15336166623055233}
2023-01-05 02:25:28,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:28,076 INFO:     Epoch: 99
2023-01-05 02:25:30,336 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5063890506823857, 'Total loss': 0.5063890506823857} | train loss {'Reaction outcome loss': 0.1826095630387789, 'Total loss': 0.1826095630387789}
2023-01-05 02:25:30,336 INFO:     Best model found after epoch 34 of 100.
2023-01-05 02:25:30,336 INFO:   Done with stage: TRAINING
2023-01-05 02:25:30,336 INFO:   Starting stage: EVALUATION
2023-01-05 02:25:30,471 INFO:   Done with stage: EVALUATION
2023-01-05 02:25:30,471 INFO:   Leaving out SEQ value Fold_5
2023-01-05 02:25:30,484 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 02:25:30,484 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:25:31,128 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:25:31,128 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:25:31,197 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:25:31,197 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:25:31,197 INFO:     No hyperparam tuning for this model
2023-01-05 02:25:31,197 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:25:31,197 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:25:31,198 INFO:     None feature selector for col prot
2023-01-05 02:25:31,198 INFO:     None feature selector for col prot
2023-01-05 02:25:31,198 INFO:     None feature selector for col prot
2023-01-05 02:25:31,199 INFO:     None feature selector for col chem
2023-01-05 02:25:31,199 INFO:     None feature selector for col chem
2023-01-05 02:25:31,199 INFO:     None feature selector for col chem
2023-01-05 02:25:31,199 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:25:31,199 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:25:31,201 INFO:     Number of params in model 72931
2023-01-05 02:25:31,204 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:25:31,204 INFO:   Starting stage: TRAINING
2023-01-05 02:25:31,264 INFO:     Val loss before train {'Reaction outcome loss': 1.023643136024475, 'Total loss': 1.023643136024475}
2023-01-05 02:25:31,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:31,264 INFO:     Epoch: 0
2023-01-05 02:25:33,507 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6612980365753174, 'Total loss': 0.6612980365753174} | train loss {'Reaction outcome loss': 0.8791995538209659, 'Total loss': 0.8791995538209659}
2023-01-05 02:25:33,507 INFO:     Found new best model at epoch 0
2023-01-05 02:25:33,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:33,508 INFO:     Epoch: 1
2023-01-05 02:25:35,767 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5954718073209126, 'Total loss': 0.5954718073209126} | train loss {'Reaction outcome loss': 0.5807379926217423, 'Total loss': 0.5807379926217423}
2023-01-05 02:25:35,767 INFO:     Found new best model at epoch 1
2023-01-05 02:25:35,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:35,768 INFO:     Epoch: 2
2023-01-05 02:25:38,006 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5336011012395223, 'Total loss': 0.5336011012395223} | train loss {'Reaction outcome loss': 0.5120127943438896, 'Total loss': 0.5120127943438896}
2023-01-05 02:25:38,006 INFO:     Found new best model at epoch 2
2023-01-05 02:25:38,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:38,007 INFO:     Epoch: 3
2023-01-05 02:25:40,247 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5122267127037048, 'Total loss': 0.5122267127037048} | train loss {'Reaction outcome loss': 0.4669200184061597, 'Total loss': 0.4669200184061597}
2023-01-05 02:25:40,248 INFO:     Found new best model at epoch 3
2023-01-05 02:25:40,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:40,249 INFO:     Epoch: 4
2023-01-05 02:25:42,512 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49816283186276755, 'Total loss': 0.49816283186276755} | train loss {'Reaction outcome loss': 0.436587896440988, 'Total loss': 0.436587896440988}
2023-01-05 02:25:42,512 INFO:     Found new best model at epoch 4
2023-01-05 02:25:42,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:42,513 INFO:     Epoch: 5
2023-01-05 02:25:44,734 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4702421317497889, 'Total loss': 0.4702421317497889} | train loss {'Reaction outcome loss': 0.41281494018124026, 'Total loss': 0.41281494018124026}
2023-01-05 02:25:44,734 INFO:     Found new best model at epoch 5
2023-01-05 02:25:44,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:44,735 INFO:     Epoch: 6
2023-01-05 02:25:46,994 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5044505536556244, 'Total loss': 0.5044505536556244} | train loss {'Reaction outcome loss': 0.42167274486543477, 'Total loss': 0.42167274486543477}
2023-01-05 02:25:46,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:46,995 INFO:     Epoch: 7
2023-01-05 02:25:49,188 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48554213841756183, 'Total loss': 0.48554213841756183} | train loss {'Reaction outcome loss': 0.37981207099189795, 'Total loss': 0.37981207099189795}
2023-01-05 02:25:49,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:49,189 INFO:     Epoch: 8
2023-01-05 02:25:51,412 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4666882316271464, 'Total loss': 0.4666882316271464} | train loss {'Reaction outcome loss': 0.3724491383013167, 'Total loss': 0.3724491383013167}
2023-01-05 02:25:51,412 INFO:     Found new best model at epoch 8
2023-01-05 02:25:51,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:51,414 INFO:     Epoch: 9
2023-01-05 02:25:53,583 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48571375807126366, 'Total loss': 0.48571375807126366} | train loss {'Reaction outcome loss': 0.35973937804068346, 'Total loss': 0.35973937804068346}
2023-01-05 02:25:53,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:53,583 INFO:     Epoch: 10
2023-01-05 02:25:55,807 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48519326448440553, 'Total loss': 0.48519326448440553} | train loss {'Reaction outcome loss': 0.34849113921054464, 'Total loss': 0.34849113921054464}
2023-01-05 02:25:55,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:55,807 INFO:     Epoch: 11
2023-01-05 02:25:58,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5072805523872376, 'Total loss': 0.5072805523872376} | train loss {'Reaction outcome loss': 0.3342813198265714, 'Total loss': 0.3342813198265714}
2023-01-05 02:25:58,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:25:58,056 INFO:     Epoch: 12
2023-01-05 02:26:00,276 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4784076114495595, 'Total loss': 0.4784076114495595} | train loss {'Reaction outcome loss': 0.3272379188008768, 'Total loss': 0.3272379188008768}
2023-01-05 02:26:00,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:00,276 INFO:     Epoch: 13
2023-01-05 02:26:02,487 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5016973455746968, 'Total loss': 0.5016973455746968} | train loss {'Reaction outcome loss': 0.31820953778578376, 'Total loss': 0.31820953778578376}
2023-01-05 02:26:02,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:02,488 INFO:     Epoch: 14
2023-01-05 02:26:04,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4688268154859543, 'Total loss': 0.4688268154859543} | train loss {'Reaction outcome loss': 0.30975756374475855, 'Total loss': 0.30975756374475855}
2023-01-05 02:26:04,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:04,673 INFO:     Epoch: 15
2023-01-05 02:26:06,835 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4881888866424561, 'Total loss': 0.4881888866424561} | train loss {'Reaction outcome loss': 0.30735788102923095, 'Total loss': 0.30735788102923095}
2023-01-05 02:26:06,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:06,836 INFO:     Epoch: 16
2023-01-05 02:26:09,039 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46530858079592385, 'Total loss': 0.46530858079592385} | train loss {'Reaction outcome loss': 0.3100659972549403, 'Total loss': 0.3100659972549403}
2023-01-05 02:26:09,039 INFO:     Found new best model at epoch 16
2023-01-05 02:26:09,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:09,040 INFO:     Epoch: 17
2023-01-05 02:26:11,273 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4892865518728892, 'Total loss': 0.4892865518728892} | train loss {'Reaction outcome loss': 0.3029935020899427, 'Total loss': 0.3029935020899427}
2023-01-05 02:26:11,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:11,273 INFO:     Epoch: 18
2023-01-05 02:26:13,525 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.457467790444692, 'Total loss': 0.457467790444692} | train loss {'Reaction outcome loss': 0.2949337095938919, 'Total loss': 0.2949337095938919}
2023-01-05 02:26:13,525 INFO:     Found new best model at epoch 18
2023-01-05 02:26:13,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:13,527 INFO:     Epoch: 19
2023-01-05 02:26:15,781 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46593716939290364, 'Total loss': 0.46593716939290364} | train loss {'Reaction outcome loss': 0.28210844365252263, 'Total loss': 0.28210844365252263}
2023-01-05 02:26:15,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:15,781 INFO:     Epoch: 20
2023-01-05 02:26:18,034 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4728221277395884, 'Total loss': 0.4728221277395884} | train loss {'Reaction outcome loss': 0.275887306227072, 'Total loss': 0.275887306227072}
2023-01-05 02:26:18,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:18,035 INFO:     Epoch: 21
2023-01-05 02:26:20,288 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.50568854312102, 'Total loss': 0.50568854312102} | train loss {'Reaction outcome loss': 0.2706752533069474, 'Total loss': 0.2706752533069474}
2023-01-05 02:26:20,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:20,288 INFO:     Epoch: 22
2023-01-05 02:26:22,552 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46100911299387615, 'Total loss': 0.46100911299387615} | train loss {'Reaction outcome loss': 0.26966362334517896, 'Total loss': 0.26966362334517896}
2023-01-05 02:26:22,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:22,553 INFO:     Epoch: 23
2023-01-05 02:26:24,807 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4468748579422633, 'Total loss': 0.4468748579422633} | train loss {'Reaction outcome loss': 0.2642092676548561, 'Total loss': 0.2642092676548561}
2023-01-05 02:26:24,807 INFO:     Found new best model at epoch 23
2023-01-05 02:26:24,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:24,809 INFO:     Epoch: 24
2023-01-05 02:26:27,057 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45728840231895446, 'Total loss': 0.45728840231895446} | train loss {'Reaction outcome loss': 0.26092604291287885, 'Total loss': 0.26092604291287885}
2023-01-05 02:26:27,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:27,057 INFO:     Epoch: 25
2023-01-05 02:26:29,295 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46165876984596255, 'Total loss': 0.46165876984596255} | train loss {'Reaction outcome loss': 0.258622645046157, 'Total loss': 0.258622645046157}
2023-01-05 02:26:29,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:29,296 INFO:     Epoch: 26
2023-01-05 02:26:31,516 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4624744395414988, 'Total loss': 0.4624744395414988} | train loss {'Reaction outcome loss': 0.2522425576723923, 'Total loss': 0.2522425576723923}
2023-01-05 02:26:31,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:31,517 INFO:     Epoch: 27
2023-01-05 02:26:33,685 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45508961081504823, 'Total loss': 0.45508961081504823} | train loss {'Reaction outcome loss': 0.2519889171732981, 'Total loss': 0.2519889171732981}
2023-01-05 02:26:33,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:33,685 INFO:     Epoch: 28
2023-01-05 02:26:35,906 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47108535369237264, 'Total loss': 0.47108535369237264} | train loss {'Reaction outcome loss': 0.24731337138665907, 'Total loss': 0.24731337138665907}
2023-01-05 02:26:35,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:35,907 INFO:     Epoch: 29
2023-01-05 02:26:38,253 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4859687884648641, 'Total loss': 0.4859687884648641} | train loss {'Reaction outcome loss': 0.2413893570762833, 'Total loss': 0.2413893570762833}
2023-01-05 02:26:38,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:38,253 INFO:     Epoch: 30
2023-01-05 02:26:40,445 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45540907283624016, 'Total loss': 0.45540907283624016} | train loss {'Reaction outcome loss': 0.24291067343353684, 'Total loss': 0.24291067343353684}
2023-01-05 02:26:40,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:40,445 INFO:     Epoch: 31
2023-01-05 02:26:42,598 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4667328844467799, 'Total loss': 0.4667328844467799} | train loss {'Reaction outcome loss': 0.2371037182603976, 'Total loss': 0.2371037182603976}
2023-01-05 02:26:42,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:42,599 INFO:     Epoch: 32
2023-01-05 02:26:44,773 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48482436736424767, 'Total loss': 0.48482436736424767} | train loss {'Reaction outcome loss': 0.2604845302462902, 'Total loss': 0.2604845302462902}
2023-01-05 02:26:44,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:44,774 INFO:     Epoch: 33
2023-01-05 02:26:46,988 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48105507095654804, 'Total loss': 0.48105507095654804} | train loss {'Reaction outcome loss': 0.23378574109190833, 'Total loss': 0.23378574109190833}
2023-01-05 02:26:46,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:46,989 INFO:     Epoch: 34
2023-01-05 02:26:49,195 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5077400793631871, 'Total loss': 0.5077400793631871} | train loss {'Reaction outcome loss': 0.2311567648226246, 'Total loss': 0.2311567648226246}
2023-01-05 02:26:49,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:49,196 INFO:     Epoch: 35
2023-01-05 02:26:51,416 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46548726558685305, 'Total loss': 0.46548726558685305} | train loss {'Reaction outcome loss': 0.2301478687778412, 'Total loss': 0.2301478687778412}
2023-01-05 02:26:51,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:51,416 INFO:     Epoch: 36
2023-01-05 02:26:53,624 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5064974268277486, 'Total loss': 0.5064974268277486} | train loss {'Reaction outcome loss': 0.2268085996048331, 'Total loss': 0.2268085996048331}
2023-01-05 02:26:53,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:53,624 INFO:     Epoch: 37
2023-01-05 02:26:55,820 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.464659841855367, 'Total loss': 0.464659841855367} | train loss {'Reaction outcome loss': 0.22414948847101954, 'Total loss': 0.22414948847101954}
2023-01-05 02:26:55,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:55,820 INFO:     Epoch: 38
2023-01-05 02:26:57,968 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.51620305677255, 'Total loss': 0.51620305677255} | train loss {'Reaction outcome loss': 0.24777208569635084, 'Total loss': 0.24777208569635084}
2023-01-05 02:26:57,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:26:57,970 INFO:     Epoch: 39
2023-01-05 02:27:00,195 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4641451676686605, 'Total loss': 0.4641451676686605} | train loss {'Reaction outcome loss': 0.21991404234870351, 'Total loss': 0.21991404234870351}
2023-01-05 02:27:00,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:00,195 INFO:     Epoch: 40
2023-01-05 02:27:02,386 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4959177434444427, 'Total loss': 0.4959177434444427} | train loss {'Reaction outcome loss': 0.22098092448014423, 'Total loss': 0.22098092448014423}
2023-01-05 02:27:02,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:02,387 INFO:     Epoch: 41
2023-01-05 02:27:04,565 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47511065502961475, 'Total loss': 0.47511065502961475} | train loss {'Reaction outcome loss': 0.2170341650624692, 'Total loss': 0.2170341650624692}
2023-01-05 02:27:04,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:04,566 INFO:     Epoch: 42
2023-01-05 02:27:06,766 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4785377343495687, 'Total loss': 0.4785377343495687} | train loss {'Reaction outcome loss': 0.2148089085720763, 'Total loss': 0.2148089085720763}
2023-01-05 02:27:06,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:06,766 INFO:     Epoch: 43
2023-01-05 02:27:08,927 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48565464119116464, 'Total loss': 0.48565464119116464} | train loss {'Reaction outcome loss': 0.21476424003924258, 'Total loss': 0.21476424003924258}
2023-01-05 02:27:08,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:08,927 INFO:     Epoch: 44
2023-01-05 02:27:11,102 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5124200085798899, 'Total loss': 0.5124200085798899} | train loss {'Reaction outcome loss': 0.2092865413962526, 'Total loss': 0.2092865413962526}
2023-01-05 02:27:11,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:11,102 INFO:     Epoch: 45
2023-01-05 02:27:13,317 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49735603531201683, 'Total loss': 0.49735603531201683} | train loss {'Reaction outcome loss': 0.20794702297501752, 'Total loss': 0.20794702297501752}
2023-01-05 02:27:13,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:13,317 INFO:     Epoch: 46
2023-01-05 02:27:15,488 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5043241361776988, 'Total loss': 0.5043241361776988} | train loss {'Reaction outcome loss': 0.20837986734493272, 'Total loss': 0.20837986734493272}
2023-01-05 02:27:15,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:15,488 INFO:     Epoch: 47
2023-01-05 02:27:17,707 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5199105113744735, 'Total loss': 0.5199105113744735} | train loss {'Reaction outcome loss': 0.21047174421328632, 'Total loss': 0.21047174421328632}
2023-01-05 02:27:17,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:17,708 INFO:     Epoch: 48
2023-01-05 02:27:19,968 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.510501875480016, 'Total loss': 0.510501875480016} | train loss {'Reaction outcome loss': 0.20983347151364348, 'Total loss': 0.20983347151364348}
2023-01-05 02:27:19,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:19,969 INFO:     Epoch: 49
2023-01-05 02:27:22,148 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4941261490186056, 'Total loss': 0.4941261490186056} | train loss {'Reaction outcome loss': 0.20576048624301937, 'Total loss': 0.20576048624301937}
2023-01-05 02:27:22,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:22,149 INFO:     Epoch: 50
2023-01-05 02:27:24,398 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5201381127039592, 'Total loss': 0.5201381127039592} | train loss {'Reaction outcome loss': 0.2040281821737417, 'Total loss': 0.2040281821737417}
2023-01-05 02:27:24,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:24,398 INFO:     Epoch: 51
2023-01-05 02:27:26,661 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5226747274398804, 'Total loss': 0.5226747274398804} | train loss {'Reaction outcome loss': 0.20077274422215272, 'Total loss': 0.20077274422215272}
2023-01-05 02:27:26,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:26,661 INFO:     Epoch: 52
2023-01-05 02:27:28,874 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4981856187184652, 'Total loss': 0.4981856187184652} | train loss {'Reaction outcome loss': 0.2054433533044505, 'Total loss': 0.2054433533044505}
2023-01-05 02:27:28,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:28,874 INFO:     Epoch: 53
2023-01-05 02:27:31,104 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4539700627326965, 'Total loss': 0.4539700627326965} | train loss {'Reaction outcome loss': 0.23295375624118184, 'Total loss': 0.23295375624118184}
2023-01-05 02:27:31,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:31,104 INFO:     Epoch: 54
2023-01-05 02:27:33,355 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4890550434589386, 'Total loss': 0.4890550434589386} | train loss {'Reaction outcome loss': 0.19425316549081734, 'Total loss': 0.19425316549081734}
2023-01-05 02:27:33,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:33,355 INFO:     Epoch: 55
2023-01-05 02:27:35,594 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48328549340367316, 'Total loss': 0.48328549340367316} | train loss {'Reaction outcome loss': 0.19068632440375027, 'Total loss': 0.19068632440375027}
2023-01-05 02:27:35,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:35,596 INFO:     Epoch: 56
2023-01-05 02:27:37,851 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5162847638130188, 'Total loss': 0.5162847638130188} | train loss {'Reaction outcome loss': 0.18827025458143698, 'Total loss': 0.18827025458143698}
2023-01-05 02:27:37,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:37,852 INFO:     Epoch: 57
2023-01-05 02:27:40,086 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4987924019495646, 'Total loss': 0.4987924019495646} | train loss {'Reaction outcome loss': 0.19350437166795545, 'Total loss': 0.19350437166795545}
2023-01-05 02:27:40,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:40,086 INFO:     Epoch: 58
2023-01-05 02:27:42,251 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5193481494983038, 'Total loss': 0.5193481494983038} | train loss {'Reaction outcome loss': 0.1906469098791696, 'Total loss': 0.1906469098791696}
2023-01-05 02:27:42,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:42,252 INFO:     Epoch: 59
2023-01-05 02:27:44,473 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5150887022415797, 'Total loss': 0.5150887022415797} | train loss {'Reaction outcome loss': 0.19062562191881455, 'Total loss': 0.19062562191881455}
2023-01-05 02:27:44,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:44,473 INFO:     Epoch: 60
2023-01-05 02:27:46,694 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4920234322547913, 'Total loss': 0.4920234322547913} | train loss {'Reaction outcome loss': 0.18730489984201099, 'Total loss': 0.18730489984201099}
2023-01-05 02:27:46,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:46,694 INFO:     Epoch: 61
2023-01-05 02:27:48,880 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5025967399279276, 'Total loss': 0.5025967399279276} | train loss {'Reaction outcome loss': 0.1867169933277604, 'Total loss': 0.1867169933277604}
2023-01-05 02:27:48,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:48,881 INFO:     Epoch: 62
2023-01-05 02:27:51,093 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5340538740158081, 'Total loss': 0.5340538740158081} | train loss {'Reaction outcome loss': 0.18988532309784836, 'Total loss': 0.18988532309784836}
2023-01-05 02:27:51,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:51,093 INFO:     Epoch: 63
2023-01-05 02:27:53,339 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47718126475811007, 'Total loss': 0.47718126475811007} | train loss {'Reaction outcome loss': 0.1822840388091551, 'Total loss': 0.1822840388091551}
2023-01-05 02:27:53,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:53,340 INFO:     Epoch: 64
2023-01-05 02:27:55,543 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5450865844885509, 'Total loss': 0.5450865844885509} | train loss {'Reaction outcome loss': 0.18779016270612678, 'Total loss': 0.18779016270612678}
2023-01-05 02:27:55,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:55,544 INFO:     Epoch: 65
2023-01-05 02:27:57,781 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47073785265286766, 'Total loss': 0.47073785265286766} | train loss {'Reaction outcome loss': 0.18963561054746, 'Total loss': 0.18963561054746}
2023-01-05 02:27:57,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:27:57,781 INFO:     Epoch: 66
2023-01-05 02:28:00,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5569556256135305, 'Total loss': 0.5569556256135305} | train loss {'Reaction outcome loss': 0.18468005548482694, 'Total loss': 0.18468005548482694}
2023-01-05 02:28:00,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:00,011 INFO:     Epoch: 67
2023-01-05 02:28:02,229 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.503276913954566, 'Total loss': 0.503276913954566} | train loss {'Reaction outcome loss': 0.18477959888717294, 'Total loss': 0.18477959888717294}
2023-01-05 02:28:02,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:02,230 INFO:     Epoch: 68
2023-01-05 02:28:04,456 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5167857825756073, 'Total loss': 0.5167857825756073} | train loss {'Reaction outcome loss': 0.17894399457944257, 'Total loss': 0.17894399457944257}
2023-01-05 02:28:04,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:04,457 INFO:     Epoch: 69
2023-01-05 02:28:06,719 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5113204787795742, 'Total loss': 0.5113204787795742} | train loss {'Reaction outcome loss': 0.17681086135490803, 'Total loss': 0.17681086135490803}
2023-01-05 02:28:06,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:06,719 INFO:     Epoch: 70
2023-01-05 02:28:08,970 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.54284854332606, 'Total loss': 0.54284854332606} | train loss {'Reaction outcome loss': 0.17727029877562966, 'Total loss': 0.17727029877562966}
2023-01-05 02:28:08,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:08,970 INFO:     Epoch: 71
2023-01-05 02:28:11,152 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5296547611554464, 'Total loss': 0.5296547611554464} | train loss {'Reaction outcome loss': 0.17960570996080566, 'Total loss': 0.17960570996080566}
2023-01-05 02:28:11,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:11,153 INFO:     Epoch: 72
2023-01-05 02:28:13,409 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5433568278948466, 'Total loss': 0.5433568278948466} | train loss {'Reaction outcome loss': 0.1803618735343596, 'Total loss': 0.1803618735343596}
2023-01-05 02:28:13,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:13,409 INFO:     Epoch: 73
2023-01-05 02:28:15,627 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5298288186391195, 'Total loss': 0.5298288186391195} | train loss {'Reaction outcome loss': 0.17549846348339232, 'Total loss': 0.17549846348339232}
2023-01-05 02:28:15,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:15,627 INFO:     Epoch: 74
2023-01-05 02:28:17,870 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5583779195944468, 'Total loss': 0.5583779195944468} | train loss {'Reaction outcome loss': 0.17575277765517702, 'Total loss': 0.17575277765517702}
2023-01-05 02:28:17,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:17,870 INFO:     Epoch: 75
2023-01-05 02:28:20,110 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5073760618766149, 'Total loss': 0.5073760618766149} | train loss {'Reaction outcome loss': 0.176402327191444, 'Total loss': 0.176402327191444}
2023-01-05 02:28:20,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:20,110 INFO:     Epoch: 76
2023-01-05 02:28:22,302 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.524690791964531, 'Total loss': 0.524690791964531} | train loss {'Reaction outcome loss': 0.17623999905249482, 'Total loss': 0.17623999905249482}
2023-01-05 02:28:22,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:22,303 INFO:     Epoch: 77
2023-01-05 02:28:24,548 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5327780365943908, 'Total loss': 0.5327780365943908} | train loss {'Reaction outcome loss': 0.17540029573180052, 'Total loss': 0.17540029573180052}
2023-01-05 02:28:24,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:24,549 INFO:     Epoch: 78
2023-01-05 02:28:26,782 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.555215471982956, 'Total loss': 0.555215471982956} | train loss {'Reaction outcome loss': 0.17359832585100157, 'Total loss': 0.17359832585100157}
2023-01-05 02:28:26,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:26,782 INFO:     Epoch: 79
2023-01-05 02:28:28,923 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5344090769688289, 'Total loss': 0.5344090769688289} | train loss {'Reaction outcome loss': 0.1752980304350469, 'Total loss': 0.1752980304350469}
2023-01-05 02:28:28,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:28,923 INFO:     Epoch: 80
2023-01-05 02:28:30,959 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5464183201392492, 'Total loss': 0.5464183201392492} | train loss {'Reaction outcome loss': 0.17338897409870802, 'Total loss': 0.17338897409870802}
2023-01-05 02:28:30,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:30,959 INFO:     Epoch: 81
2023-01-05 02:28:33,168 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5550282001495361, 'Total loss': 0.5550282001495361} | train loss {'Reaction outcome loss': 0.17091480136994083, 'Total loss': 0.17091480136994083}
2023-01-05 02:28:33,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:33,169 INFO:     Epoch: 82
2023-01-05 02:28:35,349 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5616071204344432, 'Total loss': 0.5616071204344432} | train loss {'Reaction outcome loss': 0.17416044426626404, 'Total loss': 0.17416044426626404}
2023-01-05 02:28:35,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:35,349 INFO:     Epoch: 83
2023-01-05 02:28:37,556 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5121316174666087, 'Total loss': 0.5121316174666087} | train loss {'Reaction outcome loss': 0.1762319946825248, 'Total loss': 0.1762319946825248}
2023-01-05 02:28:37,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:37,556 INFO:     Epoch: 84
2023-01-05 02:28:39,794 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5301526725292206, 'Total loss': 0.5301526725292206} | train loss {'Reaction outcome loss': 0.1730372533227479, 'Total loss': 0.1730372533227479}
2023-01-05 02:28:39,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:39,795 INFO:     Epoch: 85
2023-01-05 02:28:42,041 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5781116704146068, 'Total loss': 0.5781116704146068} | train loss {'Reaction outcome loss': 0.17342627190310336, 'Total loss': 0.17342627190310336}
2023-01-05 02:28:42,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:42,043 INFO:     Epoch: 86
2023-01-05 02:28:44,247 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5416072964668274, 'Total loss': 0.5416072964668274} | train loss {'Reaction outcome loss': 0.16837097083012137, 'Total loss': 0.16837097083012137}
2023-01-05 02:28:44,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:44,247 INFO:     Epoch: 87
2023-01-05 02:28:46,403 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5542604277531306, 'Total loss': 0.5542604277531306} | train loss {'Reaction outcome loss': 0.16697070329404518, 'Total loss': 0.16697070329404518}
2023-01-05 02:28:46,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:46,404 INFO:     Epoch: 88
2023-01-05 02:28:48,594 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5634620447953542, 'Total loss': 0.5634620447953542} | train loss {'Reaction outcome loss': 0.16776076699202153, 'Total loss': 0.16776076699202153}
2023-01-05 02:28:48,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:48,595 INFO:     Epoch: 89
2023-01-05 02:28:50,722 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5262267505129178, 'Total loss': 0.5262267505129178} | train loss {'Reaction outcome loss': 0.1922258012738261, 'Total loss': 0.1922258012738261}
2023-01-05 02:28:50,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:50,722 INFO:     Epoch: 90
2023-01-05 02:28:52,896 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5369911978642146, 'Total loss': 0.5369911978642146} | train loss {'Reaction outcome loss': 0.16739452345359165, 'Total loss': 0.16739452345359165}
2023-01-05 02:28:52,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:52,896 INFO:     Epoch: 91
2023-01-05 02:28:55,127 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5215576051811998, 'Total loss': 0.5215576051811998} | train loss {'Reaction outcome loss': 0.16260389473957373, 'Total loss': 0.16260389473957373}
2023-01-05 02:28:55,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:55,127 INFO:     Epoch: 92
2023-01-05 02:28:57,355 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.557308804988861, 'Total loss': 0.557308804988861} | train loss {'Reaction outcome loss': 0.1628267484754189, 'Total loss': 0.1628267484754189}
2023-01-05 02:28:57,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:57,356 INFO:     Epoch: 93
2023-01-05 02:28:59,555 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5177703673640887, 'Total loss': 0.5177703673640887} | train loss {'Reaction outcome loss': 0.16187164330166642, 'Total loss': 0.16187164330166642}
2023-01-05 02:28:59,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:28:59,555 INFO:     Epoch: 94
2023-01-05 02:29:01,788 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5491170982519785, 'Total loss': 0.5491170982519785} | train loss {'Reaction outcome loss': 0.1717862002517812, 'Total loss': 0.1717862002517812}
2023-01-05 02:29:01,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:01,789 INFO:     Epoch: 95
2023-01-05 02:29:04,032 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5061891734600067, 'Total loss': 0.5061891734600067} | train loss {'Reaction outcome loss': 0.21458931177725046, 'Total loss': 0.21458931177725046}
2023-01-05 02:29:04,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:04,032 INFO:     Epoch: 96
2023-01-05 02:29:06,276 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5221257746219635, 'Total loss': 0.5221257746219635} | train loss {'Reaction outcome loss': 0.1678015377475421, 'Total loss': 0.1678015377475421}
2023-01-05 02:29:06,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:06,277 INFO:     Epoch: 97
2023-01-05 02:29:08,504 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5235834807157517, 'Total loss': 0.5235834807157517} | train loss {'Reaction outcome loss': 0.16462852734653954, 'Total loss': 0.16462852734653954}
2023-01-05 02:29:08,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:08,504 INFO:     Epoch: 98
2023-01-05 02:29:10,719 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5460860550403595, 'Total loss': 0.5460860550403595} | train loss {'Reaction outcome loss': 0.1613006202817854, 'Total loss': 0.1613006202817854}
2023-01-05 02:29:10,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:10,719 INFO:     Epoch: 99
2023-01-05 02:29:12,910 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.547010083993276, 'Total loss': 0.547010083993276} | train loss {'Reaction outcome loss': 0.16156634074413095, 'Total loss': 0.16156634074413095}
2023-01-05 02:29:12,911 INFO:     Best model found after epoch 24 of 100.
2023-01-05 02:29:12,911 INFO:   Done with stage: TRAINING
2023-01-05 02:29:12,911 INFO:   Starting stage: EVALUATION
2023-01-05 02:29:13,044 INFO:   Done with stage: EVALUATION
2023-01-05 02:29:13,044 INFO:   Leaving out SEQ value Fold_6
2023-01-05 02:29:13,057 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 02:29:13,057 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:29:13,710 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:29:13,710 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:29:13,779 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:29:13,779 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:29:13,779 INFO:     No hyperparam tuning for this model
2023-01-05 02:29:13,779 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:29:13,779 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:29:13,780 INFO:     None feature selector for col prot
2023-01-05 02:29:13,780 INFO:     None feature selector for col prot
2023-01-05 02:29:13,780 INFO:     None feature selector for col prot
2023-01-05 02:29:13,781 INFO:     None feature selector for col chem
2023-01-05 02:29:13,781 INFO:     None feature selector for col chem
2023-01-05 02:29:13,781 INFO:     None feature selector for col chem
2023-01-05 02:29:13,781 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:29:13,781 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:29:13,782 INFO:     Number of params in model 72931
2023-01-05 02:29:13,785 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:29:13,786 INFO:   Starting stage: TRAINING
2023-01-05 02:29:13,847 INFO:     Val loss before train {'Reaction outcome loss': 0.9621935963630677, 'Total loss': 0.9621935963630677}
2023-01-05 02:29:13,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:13,847 INFO:     Epoch: 0
2023-01-05 02:29:16,051 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7580797334512075, 'Total loss': 0.7580797334512075} | train loss {'Reaction outcome loss': 0.9272967346738822, 'Total loss': 0.9272967346738822}
2023-01-05 02:29:16,052 INFO:     Found new best model at epoch 0
2023-01-05 02:29:16,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:16,053 INFO:     Epoch: 1
2023-01-05 02:29:18,217 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5543372392654419, 'Total loss': 0.5543372392654419} | train loss {'Reaction outcome loss': 0.625289487333074, 'Total loss': 0.625289487333074}
2023-01-05 02:29:18,217 INFO:     Found new best model at epoch 1
2023-01-05 02:29:18,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:18,218 INFO:     Epoch: 2
2023-01-05 02:29:20,464 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5321334302425385, 'Total loss': 0.5321334302425385} | train loss {'Reaction outcome loss': 0.5349126531328966, 'Total loss': 0.5349126531328966}
2023-01-05 02:29:20,465 INFO:     Found new best model at epoch 2
2023-01-05 02:29:20,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:20,467 INFO:     Epoch: 3
2023-01-05 02:29:22,713 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49960231880346934, 'Total loss': 0.49960231880346934} | train loss {'Reaction outcome loss': 0.4980129801839698, 'Total loss': 0.4980129801839698}
2023-01-05 02:29:22,713 INFO:     Found new best model at epoch 3
2023-01-05 02:29:22,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:22,715 INFO:     Epoch: 4
2023-01-05 02:29:24,960 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49595734775066375, 'Total loss': 0.49595734775066375} | train loss {'Reaction outcome loss': 0.467978064925662, 'Total loss': 0.467978064925662}
2023-01-05 02:29:24,960 INFO:     Found new best model at epoch 4
2023-01-05 02:29:24,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:24,961 INFO:     Epoch: 5
2023-01-05 02:29:27,195 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48626278042793275, 'Total loss': 0.48626278042793275} | train loss {'Reaction outcome loss': 0.4457586761900234, 'Total loss': 0.4457586761900234}
2023-01-05 02:29:27,195 INFO:     Found new best model at epoch 5
2023-01-05 02:29:27,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:27,197 INFO:     Epoch: 6
2023-01-05 02:29:29,423 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.485554709037145, 'Total loss': 0.485554709037145} | train loss {'Reaction outcome loss': 0.42554673444923513, 'Total loss': 0.42554673444923513}
2023-01-05 02:29:29,423 INFO:     Found new best model at epoch 6
2023-01-05 02:29:29,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:29,424 INFO:     Epoch: 7
2023-01-05 02:29:31,630 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47364017367362976, 'Total loss': 0.47364017367362976} | train loss {'Reaction outcome loss': 0.4144753867000449, 'Total loss': 0.4144753867000449}
2023-01-05 02:29:31,630 INFO:     Found new best model at epoch 7
2023-01-05 02:29:31,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:31,632 INFO:     Epoch: 8
2023-01-05 02:29:33,843 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46628813644250233, 'Total loss': 0.46628813644250233} | train loss {'Reaction outcome loss': 0.39734893015145395, 'Total loss': 0.39734893015145395}
2023-01-05 02:29:33,844 INFO:     Found new best model at epoch 8
2023-01-05 02:29:33,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:33,845 INFO:     Epoch: 9
2023-01-05 02:29:36,039 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4652422328790029, 'Total loss': 0.4652422328790029} | train loss {'Reaction outcome loss': 0.3878312578646715, 'Total loss': 0.3878312578646715}
2023-01-05 02:29:36,039 INFO:     Found new best model at epoch 9
2023-01-05 02:29:36,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:36,041 INFO:     Epoch: 10
2023-01-05 02:29:38,227 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4515120804309845, 'Total loss': 0.4515120804309845} | train loss {'Reaction outcome loss': 0.3718526336811617, 'Total loss': 0.3718526336811617}
2023-01-05 02:29:38,227 INFO:     Found new best model at epoch 10
2023-01-05 02:29:38,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:38,228 INFO:     Epoch: 11
2023-01-05 02:29:40,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4413401931524277, 'Total loss': 0.4413401931524277} | train loss {'Reaction outcome loss': 0.3648327904810544, 'Total loss': 0.3648327904810544}
2023-01-05 02:29:40,477 INFO:     Found new best model at epoch 11
2023-01-05 02:29:40,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:40,478 INFO:     Epoch: 12
2023-01-05 02:29:42,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43718572159608204, 'Total loss': 0.43718572159608204} | train loss {'Reaction outcome loss': 0.35765569183693036, 'Total loss': 0.35765569183693036}
2023-01-05 02:29:42,732 INFO:     Found new best model at epoch 12
2023-01-05 02:29:42,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:42,734 INFO:     Epoch: 13
2023-01-05 02:29:44,975 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46265982190767924, 'Total loss': 0.46265982190767924} | train loss {'Reaction outcome loss': 0.3470024629512849, 'Total loss': 0.3470024629512849}
2023-01-05 02:29:44,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:44,975 INFO:     Epoch: 14
2023-01-05 02:29:47,204 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47992831518252693, 'Total loss': 0.47992831518252693} | train loss {'Reaction outcome loss': 0.3389526930661193, 'Total loss': 0.3389526930661193}
2023-01-05 02:29:47,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:47,204 INFO:     Epoch: 15
2023-01-05 02:29:49,414 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4498387982447942, 'Total loss': 0.4498387982447942} | train loss {'Reaction outcome loss': 0.3361258009979871, 'Total loss': 0.3361258009979871}
2023-01-05 02:29:49,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:49,415 INFO:     Epoch: 16
2023-01-05 02:29:51,670 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4707449813683828, 'Total loss': 0.4707449813683828} | train loss {'Reaction outcome loss': 0.3251600918504628, 'Total loss': 0.3251600918504628}
2023-01-05 02:29:51,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:51,670 INFO:     Epoch: 17
2023-01-05 02:29:53,909 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4560037632783254, 'Total loss': 0.4560037632783254} | train loss {'Reaction outcome loss': 0.3183528401952788, 'Total loss': 0.3183528401952788}
2023-01-05 02:29:53,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:53,909 INFO:     Epoch: 18
2023-01-05 02:29:56,155 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4644736270109812, 'Total loss': 0.4644736270109812} | train loss {'Reaction outcome loss': 0.3113656365026851, 'Total loss': 0.3113656365026851}
2023-01-05 02:29:56,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:56,155 INFO:     Epoch: 19
2023-01-05 02:29:58,350 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46479735175768533, 'Total loss': 0.46479735175768533} | train loss {'Reaction outcome loss': 0.3022920886854833, 'Total loss': 0.3022920886854833}
2023-01-05 02:29:58,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:29:58,350 INFO:     Epoch: 20
2023-01-05 02:30:00,620 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4397930214802424, 'Total loss': 0.4397930214802424} | train loss {'Reaction outcome loss': 0.29610364040904524, 'Total loss': 0.29610364040904524}
2023-01-05 02:30:00,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:00,620 INFO:     Epoch: 21
2023-01-05 02:30:02,859 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45486029783884685, 'Total loss': 0.45486029783884685} | train loss {'Reaction outcome loss': 0.28977017081762907, 'Total loss': 0.28977017081762907}
2023-01-05 02:30:02,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:02,860 INFO:     Epoch: 22
2023-01-05 02:30:05,075 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44763096471627556, 'Total loss': 0.44763096471627556} | train loss {'Reaction outcome loss': 0.2834752243859458, 'Total loss': 0.2834752243859458}
2023-01-05 02:30:05,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:05,075 INFO:     Epoch: 23
2023-01-05 02:30:07,313 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44591134091218315, 'Total loss': 0.44591134091218315} | train loss {'Reaction outcome loss': 0.27832848312407193, 'Total loss': 0.27832848312407193}
2023-01-05 02:30:07,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:07,313 INFO:     Epoch: 24
2023-01-05 02:30:09,568 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4263859301805496, 'Total loss': 0.4263859301805496} | train loss {'Reaction outcome loss': 0.2728444994477696, 'Total loss': 0.2728444994477696}
2023-01-05 02:30:09,568 INFO:     Found new best model at epoch 24
2023-01-05 02:30:09,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:09,570 INFO:     Epoch: 25
2023-01-05 02:30:11,788 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.442792110145092, 'Total loss': 0.442792110145092} | train loss {'Reaction outcome loss': 0.26818533438940395, 'Total loss': 0.26818533438940395}
2023-01-05 02:30:11,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:11,788 INFO:     Epoch: 26
2023-01-05 02:30:13,994 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4471472988526026, 'Total loss': 0.4471472988526026} | train loss {'Reaction outcome loss': 0.2671299629343761, 'Total loss': 0.2671299629343761}
2023-01-05 02:30:13,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:13,994 INFO:     Epoch: 27
2023-01-05 02:30:16,205 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44051747818787895, 'Total loss': 0.44051747818787895} | train loss {'Reaction outcome loss': 0.2624779075841396, 'Total loss': 0.2624779075841396}
2023-01-05 02:30:16,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:16,205 INFO:     Epoch: 28
2023-01-05 02:30:18,456 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4369089643160502, 'Total loss': 0.4369089643160502} | train loss {'Reaction outcome loss': 0.25422847517076813, 'Total loss': 0.25422847517076813}
2023-01-05 02:30:18,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:18,458 INFO:     Epoch: 29
2023-01-05 02:30:20,682 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4520537356535594, 'Total loss': 0.4520537356535594} | train loss {'Reaction outcome loss': 0.2548450679259395, 'Total loss': 0.2548450679259395}
2023-01-05 02:30:20,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:20,682 INFO:     Epoch: 30
2023-01-05 02:30:22,935 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4799817552169164, 'Total loss': 0.4799817552169164} | train loss {'Reaction outcome loss': 0.25030297441710636, 'Total loss': 0.25030297441710636}
2023-01-05 02:30:22,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:22,935 INFO:     Epoch: 31
2023-01-05 02:30:25,174 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43861357470353446, 'Total loss': 0.43861357470353446} | train loss {'Reaction outcome loss': 0.24667914595710458, 'Total loss': 0.24667914595710458}
2023-01-05 02:30:25,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:25,175 INFO:     Epoch: 32
2023-01-05 02:30:27,430 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44555246233940127, 'Total loss': 0.44555246233940127} | train loss {'Reaction outcome loss': 0.2397580719166284, 'Total loss': 0.2397580719166284}
2023-01-05 02:30:27,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:27,430 INFO:     Epoch: 33
2023-01-05 02:30:29,690 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4672769476970037, 'Total loss': 0.4672769476970037} | train loss {'Reaction outcome loss': 0.23941050065069422, 'Total loss': 0.23941050065069422}
2023-01-05 02:30:29,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:29,691 INFO:     Epoch: 34
2023-01-05 02:30:31,940 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4651415377855301, 'Total loss': 0.4651415377855301} | train loss {'Reaction outcome loss': 0.2384503938002169, 'Total loss': 0.2384503938002169}
2023-01-05 02:30:31,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:31,940 INFO:     Epoch: 35
2023-01-05 02:30:34,173 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46174531877040864, 'Total loss': 0.46174531877040864} | train loss {'Reaction outcome loss': 0.23149992912900147, 'Total loss': 0.23149992912900147}
2023-01-05 02:30:34,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:34,174 INFO:     Epoch: 36
2023-01-05 02:30:36,392 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4684634129206339, 'Total loss': 0.4684634129206339} | train loss {'Reaction outcome loss': 0.23276091444672553, 'Total loss': 0.23276091444672553}
2023-01-05 02:30:36,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:36,392 INFO:     Epoch: 37
2023-01-05 02:30:38,627 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4670304596424103, 'Total loss': 0.4670304596424103} | train loss {'Reaction outcome loss': 0.22816816145816435, 'Total loss': 0.22816816145816435}
2023-01-05 02:30:38,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:38,628 INFO:     Epoch: 38
2023-01-05 02:30:40,885 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4330623676379522, 'Total loss': 0.4330623676379522} | train loss {'Reaction outcome loss': 0.22850795757926542, 'Total loss': 0.22850795757926542}
2023-01-05 02:30:40,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:40,885 INFO:     Epoch: 39
2023-01-05 02:30:43,034 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44302447537581124, 'Total loss': 0.44302447537581124} | train loss {'Reaction outcome loss': 0.22711725079114903, 'Total loss': 0.22711725079114903}
2023-01-05 02:30:43,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:43,034 INFO:     Epoch: 40
2023-01-05 02:30:44,851 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46021660765012107, 'Total loss': 0.46021660765012107} | train loss {'Reaction outcome loss': 0.22315675269691307, 'Total loss': 0.22315675269691307}
2023-01-05 02:30:44,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:44,852 INFO:     Epoch: 41
2023-01-05 02:30:46,762 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45939271797736486, 'Total loss': 0.45939271797736486} | train loss {'Reaction outcome loss': 0.22307755710684865, 'Total loss': 0.22307755710684865}
2023-01-05 02:30:46,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:46,763 INFO:     Epoch: 42
2023-01-05 02:30:48,992 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4734463353951772, 'Total loss': 0.4734463353951772} | train loss {'Reaction outcome loss': 0.21612250993182944, 'Total loss': 0.21612250993182944}
2023-01-05 02:30:48,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:48,992 INFO:     Epoch: 43
2023-01-05 02:30:51,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48408220956722897, 'Total loss': 0.48408220956722897} | train loss {'Reaction outcome loss': 0.21158256731416344, 'Total loss': 0.21158256731416344}
2023-01-05 02:30:51,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:51,235 INFO:     Epoch: 44
2023-01-05 02:30:53,438 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48739200135072075, 'Total loss': 0.48739200135072075} | train loss {'Reaction outcome loss': 0.2117331250157167, 'Total loss': 0.2117331250157167}
2023-01-05 02:30:53,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:53,439 INFO:     Epoch: 45
2023-01-05 02:30:55,684 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45895177125930786, 'Total loss': 0.45895177125930786} | train loss {'Reaction outcome loss': 0.21045898714704633, 'Total loss': 0.21045898714704633}
2023-01-05 02:30:55,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:55,684 INFO:     Epoch: 46
2023-01-05 02:30:58,001 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4837622145811717, 'Total loss': 0.4837622145811717} | train loss {'Reaction outcome loss': 0.2119233961442371, 'Total loss': 0.2119233961442371}
2023-01-05 02:30:58,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:30:58,001 INFO:     Epoch: 47
2023-01-05 02:31:00,258 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45763357579708097, 'Total loss': 0.45763357579708097} | train loss {'Reaction outcome loss': 0.20912974572569024, 'Total loss': 0.20912974572569024}
2023-01-05 02:31:00,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:00,259 INFO:     Epoch: 48
2023-01-05 02:31:02,541 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4886538793643316, 'Total loss': 0.4886538793643316} | train loss {'Reaction outcome loss': 0.20649434968876226, 'Total loss': 0.20649434968876226}
2023-01-05 02:31:02,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:02,541 INFO:     Epoch: 49
2023-01-05 02:31:04,832 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49626506368319195, 'Total loss': 0.49626506368319195} | train loss {'Reaction outcome loss': 0.20572513585997618, 'Total loss': 0.20572513585997618}
2023-01-05 02:31:04,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:04,833 INFO:     Epoch: 50
2023-01-05 02:31:07,097 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47729508951306343, 'Total loss': 0.47729508951306343} | train loss {'Reaction outcome loss': 0.20213856388703796, 'Total loss': 0.20213856388703796}
2023-01-05 02:31:07,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:07,098 INFO:     Epoch: 51
2023-01-05 02:31:09,374 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46558619985977806, 'Total loss': 0.46558619985977806} | train loss {'Reaction outcome loss': 0.20294894834153274, 'Total loss': 0.20294894834153274}
2023-01-05 02:31:09,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:09,374 INFO:     Epoch: 52
2023-01-05 02:31:11,619 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45981210470199585, 'Total loss': 0.45981210470199585} | train loss {'Reaction outcome loss': 0.2005534866515426, 'Total loss': 0.2005534866515426}
2023-01-05 02:31:11,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:11,619 INFO:     Epoch: 53
2023-01-05 02:31:13,831 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4260889559984207, 'Total loss': 0.4260889559984207} | train loss {'Reaction outcome loss': 0.20202016007383808, 'Total loss': 0.20202016007383808}
2023-01-05 02:31:13,832 INFO:     Found new best model at epoch 53
2023-01-05 02:31:13,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:13,834 INFO:     Epoch: 54
2023-01-05 02:31:16,093 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.488789489865303, 'Total loss': 0.488789489865303} | train loss {'Reaction outcome loss': 0.19834221103346306, 'Total loss': 0.19834221103346306}
2023-01-05 02:31:16,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:16,094 INFO:     Epoch: 55
2023-01-05 02:31:18,312 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4989331712325414, 'Total loss': 0.4989331712325414} | train loss {'Reaction outcome loss': 0.1961514958809214, 'Total loss': 0.1961514958809214}
2023-01-05 02:31:18,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:18,312 INFO:     Epoch: 56
2023-01-05 02:31:20,581 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4840027074019114, 'Total loss': 0.4840027074019114} | train loss {'Reaction outcome loss': 0.1945642812332199, 'Total loss': 0.1945642812332199}
2023-01-05 02:31:20,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:20,581 INFO:     Epoch: 57
2023-01-05 02:31:22,774 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5006591141223907, 'Total loss': 0.5006591141223907} | train loss {'Reaction outcome loss': 0.19462451345828574, 'Total loss': 0.19462451345828574}
2023-01-05 02:31:22,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:22,774 INFO:     Epoch: 58
2023-01-05 02:31:25,070 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49946732024351753, 'Total loss': 0.49946732024351753} | train loss {'Reaction outcome loss': 0.19453602482225169, 'Total loss': 0.19453602482225169}
2023-01-05 02:31:25,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:25,070 INFO:     Epoch: 59
2023-01-05 02:31:27,343 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5041094223658243, 'Total loss': 0.5041094223658243} | train loss {'Reaction outcome loss': 0.19451132530366685, 'Total loss': 0.19451132530366685}
2023-01-05 02:31:27,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:27,343 INFO:     Epoch: 60
2023-01-05 02:31:29,607 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.516162767012914, 'Total loss': 0.516162767012914} | train loss {'Reaction outcome loss': 0.19058315372531595, 'Total loss': 0.19058315372531595}
2023-01-05 02:31:29,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:29,608 INFO:     Epoch: 61
2023-01-05 02:31:31,900 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46921152075131733, 'Total loss': 0.46921152075131733} | train loss {'Reaction outcome loss': 0.18988065193793888, 'Total loss': 0.18988065193793888}
2023-01-05 02:31:31,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:31,901 INFO:     Epoch: 62
2023-01-05 02:31:34,159 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48745649456977846, 'Total loss': 0.48745649456977846} | train loss {'Reaction outcome loss': 0.19269712802883412, 'Total loss': 0.19269712802883412}
2023-01-05 02:31:34,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:34,160 INFO:     Epoch: 63
2023-01-05 02:31:36,427 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4865116059780121, 'Total loss': 0.4865116059780121} | train loss {'Reaction outcome loss': 0.18683522273971287, 'Total loss': 0.18683522273971287}
2023-01-05 02:31:36,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:36,428 INFO:     Epoch: 64
2023-01-05 02:31:38,569 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4640659213066101, 'Total loss': 0.4640659213066101} | train loss {'Reaction outcome loss': 0.18918918487649505, 'Total loss': 0.18918918487649505}
2023-01-05 02:31:38,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:38,569 INFO:     Epoch: 65
2023-01-05 02:31:40,786 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4815333798527718, 'Total loss': 0.4815333798527718} | train loss {'Reaction outcome loss': 0.18119338471845922, 'Total loss': 0.18119338471845922}
2023-01-05 02:31:40,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:40,787 INFO:     Epoch: 66
2023-01-05 02:31:42,941 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46875967681407926, 'Total loss': 0.46875967681407926} | train loss {'Reaction outcome loss': 0.18363026700012844, 'Total loss': 0.18363026700012844}
2023-01-05 02:31:42,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:42,941 INFO:     Epoch: 67
2023-01-05 02:31:45,194 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4884389171997706, 'Total loss': 0.4884389171997706} | train loss {'Reaction outcome loss': 0.18321645842017842, 'Total loss': 0.18321645842017842}
2023-01-05 02:31:45,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:45,194 INFO:     Epoch: 68
2023-01-05 02:31:47,431 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48667679031689964, 'Total loss': 0.48667679031689964} | train loss {'Reaction outcome loss': 0.19026416709263294, 'Total loss': 0.19026416709263294}
2023-01-05 02:31:47,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:47,431 INFO:     Epoch: 69
2023-01-05 02:31:49,692 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49843854109446206, 'Total loss': 0.49843854109446206} | train loss {'Reaction outcome loss': 0.18754314342076597, 'Total loss': 0.18754314342076597}
2023-01-05 02:31:49,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:49,693 INFO:     Epoch: 70
2023-01-05 02:31:51,901 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47757756809393564, 'Total loss': 0.47757756809393564} | train loss {'Reaction outcome loss': 0.17880379796256765, 'Total loss': 0.17880379796256765}
2023-01-05 02:31:51,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:51,901 INFO:     Epoch: 71
2023-01-05 02:31:54,099 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45803056756655375, 'Total loss': 0.45803056756655375} | train loss {'Reaction outcome loss': 0.1804650001940637, 'Total loss': 0.1804650001940637}
2023-01-05 02:31:54,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:54,099 INFO:     Epoch: 72
2023-01-05 02:31:56,369 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5021376450856526, 'Total loss': 0.5021376450856526} | train loss {'Reaction outcome loss': 0.17804824367891794, 'Total loss': 0.17804824367891794}
2023-01-05 02:31:56,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:56,369 INFO:     Epoch: 73
2023-01-05 02:31:58,615 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.474318864941597, 'Total loss': 0.474318864941597} | train loss {'Reaction outcome loss': 0.18151501968960254, 'Total loss': 0.18151501968960254}
2023-01-05 02:31:58,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:31:58,615 INFO:     Epoch: 74
2023-01-05 02:32:00,881 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49491881330808, 'Total loss': 0.49491881330808} | train loss {'Reaction outcome loss': 0.18203544127166488, 'Total loss': 0.18203544127166488}
2023-01-05 02:32:00,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:00,882 INFO:     Epoch: 75
2023-01-05 02:32:03,164 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43529341121514636, 'Total loss': 0.43529341121514636} | train loss {'Reaction outcome loss': 0.1796664981749783, 'Total loss': 0.1796664981749783}
2023-01-05 02:32:03,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:03,164 INFO:     Epoch: 76
2023-01-05 02:32:05,400 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4787608742713928, 'Total loss': 0.4787608742713928} | train loss {'Reaction outcome loss': 0.17511741016463575, 'Total loss': 0.17511741016463575}
2023-01-05 02:32:05,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:05,401 INFO:     Epoch: 77
2023-01-05 02:32:07,669 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4716857249538104, 'Total loss': 0.4716857249538104} | train loss {'Reaction outcome loss': 0.17590460321102763, 'Total loss': 0.17590460321102763}
2023-01-05 02:32:07,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:07,669 INFO:     Epoch: 78
2023-01-05 02:32:09,858 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48278990586598713, 'Total loss': 0.48278990586598713} | train loss {'Reaction outcome loss': 0.17507095998388442, 'Total loss': 0.17507095998388442}
2023-01-05 02:32:09,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:09,858 INFO:     Epoch: 79
2023-01-05 02:32:12,127 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4957765728235245, 'Total loss': 0.4957765728235245} | train loss {'Reaction outcome loss': 0.1765738422662988, 'Total loss': 0.1765738422662988}
2023-01-05 02:32:12,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:12,128 INFO:     Epoch: 80
2023-01-05 02:32:14,322 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5066257630785306, 'Total loss': 0.5066257630785306} | train loss {'Reaction outcome loss': 0.17383615255846713, 'Total loss': 0.17383615255846713}
2023-01-05 02:32:14,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:14,323 INFO:     Epoch: 81
2023-01-05 02:32:16,499 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.497207631667455, 'Total loss': 0.497207631667455} | train loss {'Reaction outcome loss': 0.17392585824986764, 'Total loss': 0.17392585824986764}
2023-01-05 02:32:16,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:16,499 INFO:     Epoch: 82
2023-01-05 02:32:18,705 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5061153570810953, 'Total loss': 0.5061153570810953} | train loss {'Reaction outcome loss': 0.16680961673144615, 'Total loss': 0.16680961673144615}
2023-01-05 02:32:18,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:18,705 INFO:     Epoch: 83
2023-01-05 02:32:20,944 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5124353031317394, 'Total loss': 0.5124353031317394} | train loss {'Reaction outcome loss': 0.167716066045384, 'Total loss': 0.167716066045384}
2023-01-05 02:32:20,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:20,944 INFO:     Epoch: 84
2023-01-05 02:32:23,205 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4736905311544736, 'Total loss': 0.4736905311544736} | train loss {'Reaction outcome loss': 0.17410533950203486, 'Total loss': 0.17410533950203486}
2023-01-05 02:32:23,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:23,206 INFO:     Epoch: 85
2023-01-05 02:32:25,475 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4593833719690641, 'Total loss': 0.4593833719690641} | train loss {'Reaction outcome loss': 0.17001293913800847, 'Total loss': 0.17001293913800847}
2023-01-05 02:32:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:25,475 INFO:     Epoch: 86
2023-01-05 02:32:27,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4825056334336599, 'Total loss': 0.4825056334336599} | train loss {'Reaction outcome loss': 0.17755860160020875, 'Total loss': 0.17755860160020875}
2023-01-05 02:32:27,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:27,727 INFO:     Epoch: 87
2023-01-05 02:32:29,935 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4846055577198664, 'Total loss': 0.4846055577198664} | train loss {'Reaction outcome loss': 0.16667224635245675, 'Total loss': 0.16667224635245675}
2023-01-05 02:32:29,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:29,935 INFO:     Epoch: 88
2023-01-05 02:32:32,155 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4770193755626678, 'Total loss': 0.4770193755626678} | train loss {'Reaction outcome loss': 0.1669987183978734, 'Total loss': 0.1669987183978734}
2023-01-05 02:32:32,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:32,155 INFO:     Epoch: 89
2023-01-05 02:32:34,350 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5003026723861694, 'Total loss': 0.5003026723861694} | train loss {'Reaction outcome loss': 0.17223697144618857, 'Total loss': 0.17223697144618857}
2023-01-05 02:32:34,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:34,350 INFO:     Epoch: 90
2023-01-05 02:32:36,506 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4759235550959905, 'Total loss': 0.4759235550959905} | train loss {'Reaction outcome loss': 0.165924639135115, 'Total loss': 0.165924639135115}
2023-01-05 02:32:36,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:36,506 INFO:     Epoch: 91
2023-01-05 02:32:38,726 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47518034974733986, 'Total loss': 0.47518034974733986} | train loss {'Reaction outcome loss': 0.16745724039327098, 'Total loss': 0.16745724039327098}
2023-01-05 02:32:38,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:38,726 INFO:     Epoch: 92
2023-01-05 02:32:40,982 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46073662166794144, 'Total loss': 0.46073662166794144} | train loss {'Reaction outcome loss': 0.16617006255945843, 'Total loss': 0.16617006255945843}
2023-01-05 02:32:40,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:40,983 INFO:     Epoch: 93
2023-01-05 02:32:43,249 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.473275625705719, 'Total loss': 0.473275625705719} | train loss {'Reaction outcome loss': 0.1669190498842229, 'Total loss': 0.1669190498842229}
2023-01-05 02:32:43,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:43,249 INFO:     Epoch: 94
2023-01-05 02:32:45,477 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46655471821626027, 'Total loss': 0.46655471821626027} | train loss {'Reaction outcome loss': 0.1634495933019028, 'Total loss': 0.1634495933019028}
2023-01-05 02:32:45,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:45,477 INFO:     Epoch: 95
2023-01-05 02:32:47,640 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.494711834192276, 'Total loss': 0.494711834192276} | train loss {'Reaction outcome loss': 0.16617734486317862, 'Total loss': 0.16617734486317862}
2023-01-05 02:32:47,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:47,641 INFO:     Epoch: 96
2023-01-05 02:32:49,877 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4718974769115448, 'Total loss': 0.4718974769115448} | train loss {'Reaction outcome loss': 0.16971497999719387, 'Total loss': 0.16971497999719387}
2023-01-05 02:32:49,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:49,878 INFO:     Epoch: 97
2023-01-05 02:32:52,074 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4947282552719116, 'Total loss': 0.4947282552719116} | train loss {'Reaction outcome loss': 0.16650870796931833, 'Total loss': 0.16650870796931833}
2023-01-05 02:32:52,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:52,074 INFO:     Epoch: 98
2023-01-05 02:32:54,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45956733226776125, 'Total loss': 0.45956733226776125} | train loss {'Reaction outcome loss': 0.1642128394291289, 'Total loss': 0.1642128394291289}
2023-01-05 02:32:54,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:54,338 INFO:     Epoch: 99
2023-01-05 02:32:56,542 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48281567096710204, 'Total loss': 0.48281567096710204} | train loss {'Reaction outcome loss': 0.16111196505598427, 'Total loss': 0.16111196505598427}
2023-01-05 02:32:56,542 INFO:     Best model found after epoch 54 of 100.
2023-01-05 02:32:56,542 INFO:   Done with stage: TRAINING
2023-01-05 02:32:56,542 INFO:   Starting stage: EVALUATION
2023-01-05 02:32:56,669 INFO:   Done with stage: EVALUATION
2023-01-05 02:32:56,669 INFO:   Leaving out SEQ value Fold_7
2023-01-05 02:32:56,681 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 02:32:56,681 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:32:57,328 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:32:57,328 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:32:57,397 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:32:57,397 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:32:57,397 INFO:     No hyperparam tuning for this model
2023-01-05 02:32:57,397 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:32:57,397 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:32:57,398 INFO:     None feature selector for col prot
2023-01-05 02:32:57,398 INFO:     None feature selector for col prot
2023-01-05 02:32:57,398 INFO:     None feature selector for col prot
2023-01-05 02:32:57,399 INFO:     None feature selector for col chem
2023-01-05 02:32:57,399 INFO:     None feature selector for col chem
2023-01-05 02:32:57,399 INFO:     None feature selector for col chem
2023-01-05 02:32:57,399 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:32:57,399 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:32:57,401 INFO:     Number of params in model 72931
2023-01-05 02:32:57,404 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:32:57,404 INFO:   Starting stage: TRAINING
2023-01-05 02:32:57,465 INFO:     Val loss before train {'Reaction outcome loss': 1.0140123208363852, 'Total loss': 1.0140123208363852}
2023-01-05 02:32:57,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:57,465 INFO:     Epoch: 0
2023-01-05 02:32:59,693 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8060552755991618, 'Total loss': 0.8060552755991618} | train loss {'Reaction outcome loss': 0.9400196862995409, 'Total loss': 0.9400196862995409}
2023-01-05 02:32:59,694 INFO:     Found new best model at epoch 0
2023-01-05 02:32:59,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:32:59,695 INFO:     Epoch: 1
2023-01-05 02:33:01,935 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6086576104164123, 'Total loss': 0.6086576104164123} | train loss {'Reaction outcome loss': 0.6171439809704515, 'Total loss': 0.6171439809704515}
2023-01-05 02:33:01,935 INFO:     Found new best model at epoch 1
2023-01-05 02:33:01,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:01,937 INFO:     Epoch: 2
2023-01-05 02:33:04,179 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.56907919049263, 'Total loss': 0.56907919049263} | train loss {'Reaction outcome loss': 0.5235967494090111, 'Total loss': 0.5235967494090111}
2023-01-05 02:33:04,179 INFO:     Found new best model at epoch 2
2023-01-05 02:33:04,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:04,181 INFO:     Epoch: 3
2023-01-05 02:33:06,432 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5499520023663839, 'Total loss': 0.5499520023663839} | train loss {'Reaction outcome loss': 0.4802526709512683, 'Total loss': 0.4802526709512683}
2023-01-05 02:33:06,432 INFO:     Found new best model at epoch 3
2023-01-05 02:33:06,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:06,433 INFO:     Epoch: 4
2023-01-05 02:33:08,661 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5587889532248179, 'Total loss': 0.5587889532248179} | train loss {'Reaction outcome loss': 0.45498513024206194, 'Total loss': 0.45498513024206194}
2023-01-05 02:33:08,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:08,662 INFO:     Epoch: 5
2023-01-05 02:33:10,897 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5635312020778656, 'Total loss': 0.5635312020778656} | train loss {'Reaction outcome loss': 0.4316783167072152, 'Total loss': 0.4316783167072152}
2023-01-05 02:33:10,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:10,897 INFO:     Epoch: 6
2023-01-05 02:33:13,159 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5367176870505015, 'Total loss': 0.5367176870505015} | train loss {'Reaction outcome loss': 0.41655066757318343, 'Total loss': 0.41655066757318343}
2023-01-05 02:33:13,159 INFO:     Found new best model at epoch 6
2023-01-05 02:33:13,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:13,161 INFO:     Epoch: 7
2023-01-05 02:33:15,418 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5130293567975363, 'Total loss': 0.5130293567975363} | train loss {'Reaction outcome loss': 0.4033498241152574, 'Total loss': 0.4033498241152574}
2023-01-05 02:33:15,418 INFO:     Found new best model at epoch 7
2023-01-05 02:33:15,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:15,420 INFO:     Epoch: 8
2023-01-05 02:33:17,655 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4986277629931768, 'Total loss': 0.4986277629931768} | train loss {'Reaction outcome loss': 0.39159920425675404, 'Total loss': 0.39159920425675404}
2023-01-05 02:33:17,656 INFO:     Found new best model at epoch 8
2023-01-05 02:33:17,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:17,657 INFO:     Epoch: 9
2023-01-05 02:33:19,902 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5230049630006154, 'Total loss': 0.5230049630006154} | train loss {'Reaction outcome loss': 0.3824968532480918, 'Total loss': 0.3824968532480918}
2023-01-05 02:33:19,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:19,903 INFO:     Epoch: 10
2023-01-05 02:33:22,160 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5146142899990082, 'Total loss': 0.5146142899990082} | train loss {'Reaction outcome loss': 0.3710701215729817, 'Total loss': 0.3710701215729817}
2023-01-05 02:33:22,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:22,160 INFO:     Epoch: 11
2023-01-05 02:33:24,396 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5173765818277994, 'Total loss': 0.5173765818277994} | train loss {'Reaction outcome loss': 0.3646224745909014, 'Total loss': 0.3646224745909014}
2023-01-05 02:33:24,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:24,397 INFO:     Epoch: 12
2023-01-05 02:33:26,653 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5007591068744659, 'Total loss': 0.5007591068744659} | train loss {'Reaction outcome loss': 0.34794333318941, 'Total loss': 0.34794333318941}
2023-01-05 02:33:26,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:26,653 INFO:     Epoch: 13
2023-01-05 02:33:28,917 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5269867777824402, 'Total loss': 0.5269867777824402} | train loss {'Reaction outcome loss': 0.34353356036468535, 'Total loss': 0.34353356036468535}
2023-01-05 02:33:28,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:28,917 INFO:     Epoch: 14
2023-01-05 02:33:31,145 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48749474485715233, 'Total loss': 0.48749474485715233} | train loss {'Reaction outcome loss': 0.3332127666753122, 'Total loss': 0.3332127666753122}
2023-01-05 02:33:31,145 INFO:     Found new best model at epoch 14
2023-01-05 02:33:31,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:31,147 INFO:     Epoch: 15
2023-01-05 02:33:33,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.50294808447361, 'Total loss': 0.50294808447361} | train loss {'Reaction outcome loss': 0.324134120589882, 'Total loss': 0.324134120589882}
2023-01-05 02:33:33,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:33,402 INFO:     Epoch: 16
2023-01-05 02:33:35,661 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.506521267692248, 'Total loss': 0.506521267692248} | train loss {'Reaction outcome loss': 0.32037893666579836, 'Total loss': 0.32037893666579836}
2023-01-05 02:33:35,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:35,662 INFO:     Epoch: 17
2023-01-05 02:33:37,871 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48894455035527545, 'Total loss': 0.48894455035527545} | train loss {'Reaction outcome loss': 0.3151154750924463, 'Total loss': 0.3151154750924463}
2023-01-05 02:33:37,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:37,872 INFO:     Epoch: 18
2023-01-05 02:33:40,118 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49168847997983295, 'Total loss': 0.49168847997983295} | train loss {'Reaction outcome loss': 0.3064173562620306, 'Total loss': 0.3064173562620306}
2023-01-05 02:33:40,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:40,118 INFO:     Epoch: 19
2023-01-05 02:33:42,337 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5096117397149403, 'Total loss': 0.5096117397149403} | train loss {'Reaction outcome loss': 0.29747766678621623, 'Total loss': 0.29747766678621623}
2023-01-05 02:33:42,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:42,337 INFO:     Epoch: 20
2023-01-05 02:33:44,554 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49975591401259106, 'Total loss': 0.49975591401259106} | train loss {'Reaction outcome loss': 0.29253285282731917, 'Total loss': 0.29253285282731917}
2023-01-05 02:33:44,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:44,555 INFO:     Epoch: 21
2023-01-05 02:33:46,707 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5379473020633062, 'Total loss': 0.5379473020633062} | train loss {'Reaction outcome loss': 0.28633473818913263, 'Total loss': 0.28633473818913263}
2023-01-05 02:33:46,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:46,707 INFO:     Epoch: 22
2023-01-05 02:33:48,955 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5222229073445003, 'Total loss': 0.5222229073445003} | train loss {'Reaction outcome loss': 0.28284862133193533, 'Total loss': 0.28284862133193533}
2023-01-05 02:33:48,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:48,955 INFO:     Epoch: 23
2023-01-05 02:33:51,220 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5220822731653849, 'Total loss': 0.5220822731653849} | train loss {'Reaction outcome loss': 0.2749928129225001, 'Total loss': 0.2749928129225001}
2023-01-05 02:33:51,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:51,220 INFO:     Epoch: 24
2023-01-05 02:33:53,440 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5184548238913218, 'Total loss': 0.5184548238913218} | train loss {'Reaction outcome loss': 0.2780604178913018, 'Total loss': 0.2780604178913018}
2023-01-05 02:33:53,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:53,441 INFO:     Epoch: 25
2023-01-05 02:33:55,641 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.492257692416509, 'Total loss': 0.492257692416509} | train loss {'Reaction outcome loss': 0.2706302424778469, 'Total loss': 0.2706302424778469}
2023-01-05 02:33:55,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:55,641 INFO:     Epoch: 26
2023-01-05 02:33:57,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5126144131024678, 'Total loss': 0.5126144131024678} | train loss {'Reaction outcome loss': 0.2690927738236391, 'Total loss': 0.2690927738236391}
2023-01-05 02:33:57,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:33:57,798 INFO:     Epoch: 27
2023-01-05 02:34:00,022 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5236060361067454, 'Total loss': 0.5236060361067454} | train loss {'Reaction outcome loss': 0.2589254572395814, 'Total loss': 0.2589254572395814}
2023-01-05 02:34:00,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:00,023 INFO:     Epoch: 28
2023-01-05 02:34:02,287 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.529898515343666, 'Total loss': 0.529898515343666} | train loss {'Reaction outcome loss': 0.2589212782304425, 'Total loss': 0.2589212782304425}
2023-01-05 02:34:02,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:02,287 INFO:     Epoch: 29
2023-01-05 02:34:04,568 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5243524352709452, 'Total loss': 0.5243524352709452} | train loss {'Reaction outcome loss': 0.25629534735092185, 'Total loss': 0.25629534735092185}
2023-01-05 02:34:04,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:04,569 INFO:     Epoch: 30
2023-01-05 02:34:06,852 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.534885992606481, 'Total loss': 0.534885992606481} | train loss {'Reaction outcome loss': 0.24840114654347784, 'Total loss': 0.24840114654347784}
2023-01-05 02:34:06,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:06,853 INFO:     Epoch: 31
2023-01-05 02:34:09,123 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5223034958044688, 'Total loss': 0.5223034958044688} | train loss {'Reaction outcome loss': 0.24179501272065546, 'Total loss': 0.24179501272065546}
2023-01-05 02:34:09,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:09,123 INFO:     Epoch: 32
2023-01-05 02:34:11,431 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5114317973454793, 'Total loss': 0.5114317973454793} | train loss {'Reaction outcome loss': 0.2448934328066528, 'Total loss': 0.2448934328066528}
2023-01-05 02:34:11,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:11,431 INFO:     Epoch: 33
2023-01-05 02:34:13,682 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5256723384062449, 'Total loss': 0.5256723384062449} | train loss {'Reaction outcome loss': 0.23840654149167373, 'Total loss': 0.23840654149167373}
2023-01-05 02:34:13,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:13,682 INFO:     Epoch: 34
2023-01-05 02:34:15,964 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5478286027908326, 'Total loss': 0.5478286027908326} | train loss {'Reaction outcome loss': 0.24044765942202148, 'Total loss': 0.24044765942202148}
2023-01-05 02:34:15,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:15,964 INFO:     Epoch: 35
2023-01-05 02:34:18,236 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5271606524785359, 'Total loss': 0.5271606524785359} | train loss {'Reaction outcome loss': 0.2387945299114131, 'Total loss': 0.2387945299114131}
2023-01-05 02:34:18,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:18,237 INFO:     Epoch: 36
2023-01-05 02:34:20,500 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5539884646733602, 'Total loss': 0.5539884646733602} | train loss {'Reaction outcome loss': 0.22677568859329938, 'Total loss': 0.22677568859329938}
2023-01-05 02:34:20,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:20,500 INFO:     Epoch: 37
2023-01-05 02:34:22,727 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5403292248646419, 'Total loss': 0.5403292248646419} | train loss {'Reaction outcome loss': 0.2322556508153623, 'Total loss': 0.2322556508153623}
2023-01-05 02:34:22,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:22,728 INFO:     Epoch: 38
2023-01-05 02:34:24,990 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.505045426885287, 'Total loss': 0.505045426885287} | train loss {'Reaction outcome loss': 0.229599516455501, 'Total loss': 0.229599516455501}
2023-01-05 02:34:24,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:24,990 INFO:     Epoch: 39
2023-01-05 02:34:27,267 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5106116871039073, 'Total loss': 0.5106116871039073} | train loss {'Reaction outcome loss': 0.22294573699349424, 'Total loss': 0.22294573699349424}
2023-01-05 02:34:27,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:27,267 INFO:     Epoch: 40
2023-01-05 02:34:29,546 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5133359481890997, 'Total loss': 0.5133359481890997} | train loss {'Reaction outcome loss': 0.2270332926393416, 'Total loss': 0.2270332926393416}
2023-01-05 02:34:29,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:29,547 INFO:     Epoch: 41
2023-01-05 02:34:31,800 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5094040016333262, 'Total loss': 0.5094040016333262} | train loss {'Reaction outcome loss': 0.22015575714920402, 'Total loss': 0.22015575714920402}
2023-01-05 02:34:31,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:31,801 INFO:     Epoch: 42
2023-01-05 02:34:34,075 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5137272477149963, 'Total loss': 0.5137272477149963} | train loss {'Reaction outcome loss': 0.2167505600392173, 'Total loss': 0.2167505600392173}
2023-01-05 02:34:34,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:34,075 INFO:     Epoch: 43
2023-01-05 02:34:36,333 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5234870324532191, 'Total loss': 0.5234870324532191} | train loss {'Reaction outcome loss': 0.2104682995120756, 'Total loss': 0.2104682995120756}
2023-01-05 02:34:36,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:36,334 INFO:     Epoch: 44
2023-01-05 02:34:38,629 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5188222507635752, 'Total loss': 0.5188222507635752} | train loss {'Reaction outcome loss': 0.21134793037373828, 'Total loss': 0.21134793037373828}
2023-01-05 02:34:38,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:38,629 INFO:     Epoch: 45
2023-01-05 02:34:40,821 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5471002717812856, 'Total loss': 0.5471002717812856} | train loss {'Reaction outcome loss': 0.21020570948605663, 'Total loss': 0.21020570948605663}
2023-01-05 02:34:40,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:40,821 INFO:     Epoch: 46
2023-01-05 02:34:43,046 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5060951004425684, 'Total loss': 0.5060951004425684} | train loss {'Reaction outcome loss': 0.2126411125366492, 'Total loss': 0.2126411125366492}
2023-01-05 02:34:43,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:43,046 INFO:     Epoch: 47
2023-01-05 02:34:45,317 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5491081337134044, 'Total loss': 0.5491081337134044} | train loss {'Reaction outcome loss': 0.20047077774288743, 'Total loss': 0.20047077774288743}
2023-01-05 02:34:45,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:45,317 INFO:     Epoch: 48
2023-01-05 02:34:47,519 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5028895487387975, 'Total loss': 0.5028895487387975} | train loss {'Reaction outcome loss': 0.20412393804599233, 'Total loss': 0.20412393804599233}
2023-01-05 02:34:47,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:47,519 INFO:     Epoch: 49
2023-01-05 02:34:49,718 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5238652015725772, 'Total loss': 0.5238652015725772} | train loss {'Reaction outcome loss': 0.2027228973261232, 'Total loss': 0.2027228973261232}
2023-01-05 02:34:49,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:49,719 INFO:     Epoch: 50
2023-01-05 02:34:51,986 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5173134624958038, 'Total loss': 0.5173134624958038} | train loss {'Reaction outcome loss': 0.20272760136247972, 'Total loss': 0.20272760136247972}
2023-01-05 02:34:51,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:51,986 INFO:     Epoch: 51
2023-01-05 02:34:54,148 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5336458176374436, 'Total loss': 0.5336458176374436} | train loss {'Reaction outcome loss': 0.2048502836035168, 'Total loss': 0.2048502836035168}
2023-01-05 02:34:54,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:54,149 INFO:     Epoch: 52
2023-01-05 02:34:56,414 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5234654953082403, 'Total loss': 0.5234654953082403} | train loss {'Reaction outcome loss': 0.19756725766033686, 'Total loss': 0.19756725766033686}
2023-01-05 02:34:56,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:56,414 INFO:     Epoch: 53
2023-01-05 02:34:58,651 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5411633809407552, 'Total loss': 0.5411633809407552} | train loss {'Reaction outcome loss': 0.19568111613688702, 'Total loss': 0.19568111613688702}
2023-01-05 02:34:58,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:34:58,652 INFO:     Epoch: 54
2023-01-05 02:35:00,849 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5307346030448874, 'Total loss': 0.5307346030448874} | train loss {'Reaction outcome loss': 0.1960026930130023, 'Total loss': 0.1960026930130023}
2023-01-05 02:35:00,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:00,850 INFO:     Epoch: 55
2023-01-05 02:35:03,119 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.579886582493782, 'Total loss': 0.579886582493782} | train loss {'Reaction outcome loss': 0.19740069908550553, 'Total loss': 0.19740069908550553}
2023-01-05 02:35:03,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:03,119 INFO:     Epoch: 56
2023-01-05 02:35:05,359 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5253116976469755, 'Total loss': 0.5253116976469755} | train loss {'Reaction outcome loss': 0.19166411802219732, 'Total loss': 0.19166411802219732}
2023-01-05 02:35:05,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:05,360 INFO:     Epoch: 57
2023-01-05 02:35:07,517 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5323625266551971, 'Total loss': 0.5323625266551971} | train loss {'Reaction outcome loss': 0.19513531322406086, 'Total loss': 0.19513531322406086}
2023-01-05 02:35:07,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:07,517 INFO:     Epoch: 58
2023-01-05 02:35:09,786 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5776907414197922, 'Total loss': 0.5776907414197922} | train loss {'Reaction outcome loss': 0.1892499672585177, 'Total loss': 0.1892499672585177}
2023-01-05 02:35:09,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:09,786 INFO:     Epoch: 59
2023-01-05 02:35:12,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5305892358223597, 'Total loss': 0.5305892358223597} | train loss {'Reaction outcome loss': 0.18777303235262416, 'Total loss': 0.18777303235262416}
2023-01-05 02:35:12,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:12,052 INFO:     Epoch: 60
2023-01-05 02:35:14,315 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5546796192725499, 'Total loss': 0.5546796192725499} | train loss {'Reaction outcome loss': 0.18061892586904796, 'Total loss': 0.18061892586904796}
2023-01-05 02:35:14,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:14,315 INFO:     Epoch: 61
2023-01-05 02:35:16,581 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.539796781539917, 'Total loss': 0.539796781539917} | train loss {'Reaction outcome loss': 0.18535158236843907, 'Total loss': 0.18535158236843907}
2023-01-05 02:35:16,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:16,581 INFO:     Epoch: 62
2023-01-05 02:35:18,788 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.54781926771005, 'Total loss': 0.54781926771005} | train loss {'Reaction outcome loss': 0.18568132411930643, 'Total loss': 0.18568132411930643}
2023-01-05 02:35:18,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:18,789 INFO:     Epoch: 63
2023-01-05 02:35:21,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.573893200357755, 'Total loss': 0.573893200357755} | train loss {'Reaction outcome loss': 0.17953478850992496, 'Total loss': 0.17953478850992496}
2023-01-05 02:35:21,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:21,068 INFO:     Epoch: 64
2023-01-05 02:35:23,308 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5169123818476995, 'Total loss': 0.5169123818476995} | train loss {'Reaction outcome loss': 0.18431791637953546, 'Total loss': 0.18431791637953546}
2023-01-05 02:35:23,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:23,308 INFO:     Epoch: 65
2023-01-05 02:35:25,501 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5187119603157043, 'Total loss': 0.5187119603157043} | train loss {'Reaction outcome loss': 0.1853952938774836, 'Total loss': 0.1853952938774836}
2023-01-05 02:35:25,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:25,502 INFO:     Epoch: 66
2023-01-05 02:35:27,767 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5162400941054026, 'Total loss': 0.5162400941054026} | train loss {'Reaction outcome loss': 0.17947479511614525, 'Total loss': 0.17947479511614525}
2023-01-05 02:35:27,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:27,767 INFO:     Epoch: 67
2023-01-05 02:35:29,972 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5092922416826089, 'Total loss': 0.5092922416826089} | train loss {'Reaction outcome loss': 0.1772180504606035, 'Total loss': 0.1772180504606035}
2023-01-05 02:35:29,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:29,972 INFO:     Epoch: 68
2023-01-05 02:35:32,205 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5341935237248738, 'Total loss': 0.5341935237248738} | train loss {'Reaction outcome loss': 0.17710724365073743, 'Total loss': 0.17710724365073743}
2023-01-05 02:35:32,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:32,205 INFO:     Epoch: 69
2023-01-05 02:35:34,451 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5365745385487874, 'Total loss': 0.5365745385487874} | train loss {'Reaction outcome loss': 0.17535473531051557, 'Total loss': 0.17535473531051557}
2023-01-05 02:35:34,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:34,452 INFO:     Epoch: 70
2023-01-05 02:35:36,723 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5166979551315307, 'Total loss': 0.5166979551315307} | train loss {'Reaction outcome loss': 0.17664386953196962, 'Total loss': 0.17664386953196962}
2023-01-05 02:35:36,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:36,723 INFO:     Epoch: 71
2023-01-05 02:35:39,007 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4946630626916885, 'Total loss': 0.4946630626916885} | train loss {'Reaction outcome loss': 0.17686660742615803, 'Total loss': 0.17686660742615803}
2023-01-05 02:35:39,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:39,007 INFO:     Epoch: 72
2023-01-05 02:35:41,256 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5023862759272257, 'Total loss': 0.5023862759272257} | train loss {'Reaction outcome loss': 0.17504101157329627, 'Total loss': 0.17504101157329627}
2023-01-05 02:35:41,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:41,257 INFO:     Epoch: 73
2023-01-05 02:35:43,510 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.506810012459755, 'Total loss': 0.506810012459755} | train loss {'Reaction outcome loss': 0.17199244577982312, 'Total loss': 0.17199244577982312}
2023-01-05 02:35:43,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:43,511 INFO:     Epoch: 74
2023-01-05 02:35:45,680 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5673891584078471, 'Total loss': 0.5673891584078471} | train loss {'Reaction outcome loss': 0.17439042961238363, 'Total loss': 0.17439042961238363}
2023-01-05 02:35:45,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:45,680 INFO:     Epoch: 75
2023-01-05 02:35:47,944 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5220502247412999, 'Total loss': 0.5220502247412999} | train loss {'Reaction outcome loss': 0.17241163563911235, 'Total loss': 0.17241163563911235}
2023-01-05 02:35:47,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:47,945 INFO:     Epoch: 76
2023-01-05 02:35:50,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.525985062122345, 'Total loss': 0.525985062122345} | train loss {'Reaction outcome loss': 0.17105265071998865, 'Total loss': 0.17105265071998865}
2023-01-05 02:35:50,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:50,179 INFO:     Epoch: 77
2023-01-05 02:35:52,373 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5316398243109385, 'Total loss': 0.5316398243109385} | train loss {'Reaction outcome loss': 0.16861320097026306, 'Total loss': 0.16861320097026306}
2023-01-05 02:35:52,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:52,373 INFO:     Epoch: 78
2023-01-05 02:35:54,583 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5266642947991689, 'Total loss': 0.5266642947991689} | train loss {'Reaction outcome loss': 0.17099646840661442, 'Total loss': 0.17099646840661442}
2023-01-05 02:35:54,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:54,584 INFO:     Epoch: 79
2023-01-05 02:35:56,752 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5159453570842742, 'Total loss': 0.5159453570842742} | train loss {'Reaction outcome loss': 0.16893647761094227, 'Total loss': 0.16893647761094227}
2023-01-05 02:35:56,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:56,752 INFO:     Epoch: 80
2023-01-05 02:35:59,010 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5065617024898529, 'Total loss': 0.5065617024898529} | train loss {'Reaction outcome loss': 0.1712173458763704, 'Total loss': 0.1712173458763704}
2023-01-05 02:35:59,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:35:59,010 INFO:     Epoch: 81
2023-01-05 02:36:01,274 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5490776817003886, 'Total loss': 0.5490776817003886} | train loss {'Reaction outcome loss': 0.1663272191773737, 'Total loss': 0.1663272191773737}
2023-01-05 02:36:01,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:01,274 INFO:     Epoch: 82
2023-01-05 02:36:03,526 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5269945551951726, 'Total loss': 0.5269945551951726} | train loss {'Reaction outcome loss': 0.1712339703373557, 'Total loss': 0.1712339703373557}
2023-01-05 02:36:03,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:03,526 INFO:     Epoch: 83
2023-01-05 02:36:05,783 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5328803837299347, 'Total loss': 0.5328803837299347} | train loss {'Reaction outcome loss': 0.16965077816095162, 'Total loss': 0.16965077816095162}
2023-01-05 02:36:05,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:05,783 INFO:     Epoch: 84
2023-01-05 02:36:07,962 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5379476229349772, 'Total loss': 0.5379476229349772} | train loss {'Reaction outcome loss': 0.16256457206201386, 'Total loss': 0.16256457206201386}
2023-01-05 02:36:07,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:07,962 INFO:     Epoch: 85
2023-01-05 02:36:10,169 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5535130302111307, 'Total loss': 0.5535130302111307} | train loss {'Reaction outcome loss': 0.17044370535202996, 'Total loss': 0.17044370535202996}
2023-01-05 02:36:10,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:10,169 INFO:     Epoch: 86
2023-01-05 02:36:12,415 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5513156175613403, 'Total loss': 0.5513156175613403} | train loss {'Reaction outcome loss': 0.16455106624143218, 'Total loss': 0.16455106624143218}
2023-01-05 02:36:12,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:12,415 INFO:     Epoch: 87
2023-01-05 02:36:14,659 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5593974669774373, 'Total loss': 0.5593974669774373} | train loss {'Reaction outcome loss': 0.16668524535285437, 'Total loss': 0.16668524535285437}
2023-01-05 02:36:14,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:14,659 INFO:     Epoch: 88
2023-01-05 02:36:16,894 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.513135802745819, 'Total loss': 0.513135802745819} | train loss {'Reaction outcome loss': 0.1664098888914696, 'Total loss': 0.1664098888914696}
2023-01-05 02:36:16,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:16,895 INFO:     Epoch: 89
2023-01-05 02:36:19,138 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5370190540949503, 'Total loss': 0.5370190540949503} | train loss {'Reaction outcome loss': 0.16673757655996602, 'Total loss': 0.16673757655996602}
2023-01-05 02:36:19,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:19,138 INFO:     Epoch: 90
2023-01-05 02:36:21,340 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5196037391821543, 'Total loss': 0.5196037391821543} | train loss {'Reaction outcome loss': 0.16443799192250608, 'Total loss': 0.16443799192250608}
2023-01-05 02:36:21,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:21,340 INFO:     Epoch: 91
2023-01-05 02:36:23,597 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5410165424148242, 'Total loss': 0.5410165424148242} | train loss {'Reaction outcome loss': 0.15935389645438008, 'Total loss': 0.15935389645438008}
2023-01-05 02:36:23,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:23,597 INFO:     Epoch: 92
2023-01-05 02:36:25,846 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5563206575190027, 'Total loss': 0.5563206575190027} | train loss {'Reaction outcome loss': 0.16544380512707177, 'Total loss': 0.16544380512707177}
2023-01-05 02:36:25,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:25,846 INFO:     Epoch: 93
2023-01-05 02:36:28,068 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5319429347912471, 'Total loss': 0.5319429347912471} | train loss {'Reaction outcome loss': 0.1617208129645658, 'Total loss': 0.1617208129645658}
2023-01-05 02:36:28,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:28,068 INFO:     Epoch: 94
2023-01-05 02:36:30,313 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5271621172626814, 'Total loss': 0.5271621172626814} | train loss {'Reaction outcome loss': 0.16176335090630106, 'Total loss': 0.16176335090630106}
2023-01-05 02:36:30,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:30,313 INFO:     Epoch: 95
2023-01-05 02:36:32,527 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5321646591027578, 'Total loss': 0.5321646591027578} | train loss {'Reaction outcome loss': 0.16126687368394854, 'Total loss': 0.16126687368394854}
2023-01-05 02:36:32,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:32,527 INFO:     Epoch: 96
2023-01-05 02:36:34,761 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5350060224533081, 'Total loss': 0.5350060224533081} | train loss {'Reaction outcome loss': 0.1608786729117351, 'Total loss': 0.1608786729117351}
2023-01-05 02:36:34,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:34,761 INFO:     Epoch: 97
2023-01-05 02:36:36,957 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5311071892579396, 'Total loss': 0.5311071892579396} | train loss {'Reaction outcome loss': 0.16175370550687534, 'Total loss': 0.16175370550687534}
2023-01-05 02:36:36,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:36,958 INFO:     Epoch: 98
2023-01-05 02:36:39,158 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5407253473997116, 'Total loss': 0.5407253473997116} | train loss {'Reaction outcome loss': 0.15920468141570257, 'Total loss': 0.15920468141570257}
2023-01-05 02:36:39,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:39,158 INFO:     Epoch: 99
2023-01-05 02:36:41,201 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5402541582783064, 'Total loss': 0.5402541582783064} | train loss {'Reaction outcome loss': 0.15969768658932634, 'Total loss': 0.15969768658932634}
2023-01-05 02:36:41,201 INFO:     Best model found after epoch 15 of 100.
2023-01-05 02:36:41,201 INFO:   Done with stage: TRAINING
2023-01-05 02:36:41,201 INFO:   Starting stage: EVALUATION
2023-01-05 02:36:41,327 INFO:   Done with stage: EVALUATION
2023-01-05 02:36:41,327 INFO:   Leaving out SEQ value Fold_8
2023-01-05 02:36:41,340 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 02:36:41,340 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:36:41,978 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:36:41,979 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:36:42,047 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:36:42,047 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:36:42,047 INFO:     No hyperparam tuning for this model
2023-01-05 02:36:42,047 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:36:42,047 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:36:42,048 INFO:     None feature selector for col prot
2023-01-05 02:36:42,048 INFO:     None feature selector for col prot
2023-01-05 02:36:42,048 INFO:     None feature selector for col prot
2023-01-05 02:36:42,048 INFO:     None feature selector for col chem
2023-01-05 02:36:42,048 INFO:     None feature selector for col chem
2023-01-05 02:36:42,049 INFO:     None feature selector for col chem
2023-01-05 02:36:42,049 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:36:42,049 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:36:42,050 INFO:     Number of params in model 72931
2023-01-05 02:36:42,053 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:36:42,053 INFO:   Starting stage: TRAINING
2023-01-05 02:36:42,111 INFO:     Val loss before train {'Reaction outcome loss': 0.9412920872370402, 'Total loss': 0.9412920872370402}
2023-01-05 02:36:42,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:42,111 INFO:     Epoch: 0
2023-01-05 02:36:44,008 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6868065416812896, 'Total loss': 0.6868065416812896} | train loss {'Reaction outcome loss': 0.9381831741289972, 'Total loss': 0.9381831741289972}
2023-01-05 02:36:44,008 INFO:     Found new best model at epoch 0
2023-01-05 02:36:44,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:44,010 INFO:     Epoch: 1
2023-01-05 02:36:45,871 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5664956152439118, 'Total loss': 0.5664956152439118} | train loss {'Reaction outcome loss': 0.606158150662584, 'Total loss': 0.606158150662584}
2023-01-05 02:36:45,871 INFO:     Found new best model at epoch 1
2023-01-05 02:36:45,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:45,873 INFO:     Epoch: 2
2023-01-05 02:36:47,959 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5205488661924998, 'Total loss': 0.5205488661924998} | train loss {'Reaction outcome loss': 0.5262650356826369, 'Total loss': 0.5262650356826369}
2023-01-05 02:36:47,959 INFO:     Found new best model at epoch 2
2023-01-05 02:36:47,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:47,960 INFO:     Epoch: 3
2023-01-05 02:36:50,192 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48303340673446654, 'Total loss': 0.48303340673446654} | train loss {'Reaction outcome loss': 0.48505209822086653, 'Total loss': 0.48505209822086653}
2023-01-05 02:36:50,192 INFO:     Found new best model at epoch 3
2023-01-05 02:36:50,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:50,194 INFO:     Epoch: 4
2023-01-05 02:36:52,368 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4689160684744517, 'Total loss': 0.4689160684744517} | train loss {'Reaction outcome loss': 0.4559999470353557, 'Total loss': 0.4559999470353557}
2023-01-05 02:36:52,369 INFO:     Found new best model at epoch 4
2023-01-05 02:36:52,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:52,371 INFO:     Epoch: 5
2023-01-05 02:36:54,599 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45542178948720297, 'Total loss': 0.45542178948720297} | train loss {'Reaction outcome loss': 0.4275152979398462, 'Total loss': 0.4275152979398462}
2023-01-05 02:36:54,600 INFO:     Found new best model at epoch 5
2023-01-05 02:36:54,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:54,601 INFO:     Epoch: 6
2023-01-05 02:36:56,764 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44632354378700256, 'Total loss': 0.44632354378700256} | train loss {'Reaction outcome loss': 0.4170136406802529, 'Total loss': 0.4170136406802529}
2023-01-05 02:36:56,764 INFO:     Found new best model at epoch 6
2023-01-05 02:36:56,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:56,765 INFO:     Epoch: 7
2023-01-05 02:36:58,962 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4346608559290568, 'Total loss': 0.4346608559290568} | train loss {'Reaction outcome loss': 0.4058253707007811, 'Total loss': 0.4058253707007811}
2023-01-05 02:36:58,962 INFO:     Found new best model at epoch 7
2023-01-05 02:36:58,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:36:58,964 INFO:     Epoch: 8
2023-01-05 02:37:01,153 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4199443678061167, 'Total loss': 0.4199443678061167} | train loss {'Reaction outcome loss': 0.3936417468887374, 'Total loss': 0.3936417468887374}
2023-01-05 02:37:01,153 INFO:     Found new best model at epoch 8
2023-01-05 02:37:01,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:01,155 INFO:     Epoch: 9
2023-01-05 02:37:03,409 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42794386148452757, 'Total loss': 0.42794386148452757} | train loss {'Reaction outcome loss': 0.38158015403829326, 'Total loss': 0.38158015403829326}
2023-01-05 02:37:03,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:03,410 INFO:     Epoch: 10
2023-01-05 02:37:05,665 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42885963916778563, 'Total loss': 0.42885963916778563} | train loss {'Reaction outcome loss': 0.37113574152603906, 'Total loss': 0.37113574152603906}
2023-01-05 02:37:05,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:05,665 INFO:     Epoch: 11
2023-01-05 02:37:07,910 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42555492321650185, 'Total loss': 0.42555492321650185} | train loss {'Reaction outcome loss': 0.3635574600756814, 'Total loss': 0.3635574600756814}
2023-01-05 02:37:07,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:07,910 INFO:     Epoch: 12
2023-01-05 02:37:10,112 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41423772821823757, 'Total loss': 0.41423772821823757} | train loss {'Reaction outcome loss': 0.3530356697603684, 'Total loss': 0.3530356697603684}
2023-01-05 02:37:10,112 INFO:     Found new best model at epoch 12
2023-01-05 02:37:10,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:10,113 INFO:     Epoch: 13
2023-01-05 02:37:12,373 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41526007652282715, 'Total loss': 0.41526007652282715} | train loss {'Reaction outcome loss': 0.3442944133593718, 'Total loss': 0.3442944133593718}
2023-01-05 02:37:12,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:12,373 INFO:     Epoch: 14
2023-01-05 02:37:14,586 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38950822949409486, 'Total loss': 0.38950822949409486} | train loss {'Reaction outcome loss': 0.3362934986929601, 'Total loss': 0.3362934986929601}
2023-01-05 02:37:14,587 INFO:     Found new best model at epoch 14
2023-01-05 02:37:14,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:14,588 INFO:     Epoch: 15
2023-01-05 02:37:16,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3820114344358444, 'Total loss': 0.3820114344358444} | train loss {'Reaction outcome loss': 0.3291787411008931, 'Total loss': 0.3291787411008931}
2023-01-05 02:37:16,746 INFO:     Found new best model at epoch 15
2023-01-05 02:37:16,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:16,747 INFO:     Epoch: 16
2023-01-05 02:37:18,944 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3934493879477183, 'Total loss': 0.3934493879477183} | train loss {'Reaction outcome loss': 0.3230378967760272, 'Total loss': 0.3230378967760272}
2023-01-05 02:37:18,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:18,945 INFO:     Epoch: 17
2023-01-05 02:37:21,095 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40289194087187447, 'Total loss': 0.40289194087187447} | train loss {'Reaction outcome loss': 0.3136387585463937, 'Total loss': 0.3136387585463937}
2023-01-05 02:37:21,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:21,095 INFO:     Epoch: 18
2023-01-05 02:37:23,325 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3794029116630554, 'Total loss': 0.3794029116630554} | train loss {'Reaction outcome loss': 0.3109474405780811, 'Total loss': 0.3109474405780811}
2023-01-05 02:37:23,325 INFO:     Found new best model at epoch 18
2023-01-05 02:37:23,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:23,327 INFO:     Epoch: 19
2023-01-05 02:37:25,567 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4014430950085322, 'Total loss': 0.4014430950085322} | train loss {'Reaction outcome loss': 0.3066797360562676, 'Total loss': 0.3066797360562676}
2023-01-05 02:37:25,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:25,567 INFO:     Epoch: 20
2023-01-05 02:37:27,783 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3963015655676524, 'Total loss': 0.3963015655676524} | train loss {'Reaction outcome loss': 0.3005237528778586, 'Total loss': 0.3005237528778586}
2023-01-05 02:37:27,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:27,784 INFO:     Epoch: 21
2023-01-05 02:37:30,007 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.359114371240139, 'Total loss': 0.359114371240139} | train loss {'Reaction outcome loss': 0.29556857104604856, 'Total loss': 0.29556857104604856}
2023-01-05 02:37:30,007 INFO:     Found new best model at epoch 21
2023-01-05 02:37:30,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:30,008 INFO:     Epoch: 22
2023-01-05 02:37:32,222 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39938172698020935, 'Total loss': 0.39938172698020935} | train loss {'Reaction outcome loss': 0.29140230747013746, 'Total loss': 0.29140230747013746}
2023-01-05 02:37:32,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:32,222 INFO:     Epoch: 23
2023-01-05 02:37:34,428 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38535527189572655, 'Total loss': 0.38535527189572655} | train loss {'Reaction outcome loss': 0.28607090220312564, 'Total loss': 0.28607090220312564}
2023-01-05 02:37:34,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:34,429 INFO:     Epoch: 24
2023-01-05 02:37:36,673 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37198860943317413, 'Total loss': 0.37198860943317413} | train loss {'Reaction outcome loss': 0.28388425481878893, 'Total loss': 0.28388425481878893}
2023-01-05 02:37:36,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:36,673 INFO:     Epoch: 25
2023-01-05 02:37:38,925 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36556307375431063, 'Total loss': 0.36556307375431063} | train loss {'Reaction outcome loss': 0.27753071500398624, 'Total loss': 0.27753071500398624}
2023-01-05 02:37:38,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:38,926 INFO:     Epoch: 26
2023-01-05 02:37:41,153 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38965755303700766, 'Total loss': 0.38965755303700766} | train loss {'Reaction outcome loss': 0.2721631390442702, 'Total loss': 0.2721631390442702}
2023-01-05 02:37:41,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:41,153 INFO:     Epoch: 27
2023-01-05 02:37:43,361 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40091957449913024, 'Total loss': 0.40091957449913024} | train loss {'Reaction outcome loss': 0.2697156881207486, 'Total loss': 0.2697156881207486}
2023-01-05 02:37:43,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:43,361 INFO:     Epoch: 28
2023-01-05 02:37:45,555 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.347462597489357, 'Total loss': 0.347462597489357} | train loss {'Reaction outcome loss': 0.2678608852791657, 'Total loss': 0.2678608852791657}
2023-01-05 02:37:45,555 INFO:     Found new best model at epoch 28
2023-01-05 02:37:45,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:45,556 INFO:     Epoch: 29
2023-01-05 02:37:47,801 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3664928595225016, 'Total loss': 0.3664928595225016} | train loss {'Reaction outcome loss': 0.26463900946268964, 'Total loss': 0.26463900946268964}
2023-01-05 02:37:47,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:47,802 INFO:     Epoch: 30
2023-01-05 02:37:50,023 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3712914442022642, 'Total loss': 0.3712914442022642} | train loss {'Reaction outcome loss': 0.2563154373438995, 'Total loss': 0.2563154373438995}
2023-01-05 02:37:50,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:50,023 INFO:     Epoch: 31
2023-01-05 02:37:52,216 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37475612908601763, 'Total loss': 0.37475612908601763} | train loss {'Reaction outcome loss': 0.25854104560285485, 'Total loss': 0.25854104560285485}
2023-01-05 02:37:52,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:52,216 INFO:     Epoch: 32
2023-01-05 02:37:54,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3679874966541926, 'Total loss': 0.3679874966541926} | train loss {'Reaction outcome loss': 0.2512664775690232, 'Total loss': 0.2512664775690232}
2023-01-05 02:37:54,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:54,475 INFO:     Epoch: 33
2023-01-05 02:37:56,710 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3727405269940694, 'Total loss': 0.3727405269940694} | train loss {'Reaction outcome loss': 0.2545060787605465, 'Total loss': 0.2545060787605465}
2023-01-05 02:37:56,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:56,711 INFO:     Epoch: 34
2023-01-05 02:37:58,966 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3928221772114436, 'Total loss': 0.3928221772114436} | train loss {'Reaction outcome loss': 0.24805874833400068, 'Total loss': 0.24805874833400068}
2023-01-05 02:37:58,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:37:58,966 INFO:     Epoch: 35
2023-01-05 02:38:01,183 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34673729836940764, 'Total loss': 0.34673729836940764} | train loss {'Reaction outcome loss': 0.24571845568178577, 'Total loss': 0.24571845568178577}
2023-01-05 02:38:01,183 INFO:     Found new best model at epoch 35
2023-01-05 02:38:01,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:01,184 INFO:     Epoch: 36
2023-01-05 02:38:03,445 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3598381645977497, 'Total loss': 0.3598381645977497} | train loss {'Reaction outcome loss': 0.24102768292549714, 'Total loss': 0.24102768292549714}
2023-01-05 02:38:03,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:03,445 INFO:     Epoch: 37
2023-01-05 02:38:05,710 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3762441471219063, 'Total loss': 0.3762441471219063} | train loss {'Reaction outcome loss': 0.23937357974235332, 'Total loss': 0.23937357974235332}
2023-01-05 02:38:05,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:05,711 INFO:     Epoch: 38
2023-01-05 02:38:07,963 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3624220003684362, 'Total loss': 0.3624220003684362} | train loss {'Reaction outcome loss': 0.23982698563822555, 'Total loss': 0.23982698563822555}
2023-01-05 02:38:07,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:07,963 INFO:     Epoch: 39
2023-01-05 02:38:10,207 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36928582936525345, 'Total loss': 0.36928582936525345} | train loss {'Reaction outcome loss': 0.24133592963030406, 'Total loss': 0.24133592963030406}
2023-01-05 02:38:10,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:10,208 INFO:     Epoch: 40
2023-01-05 02:38:12,371 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34767188876867294, 'Total loss': 0.34767188876867294} | train loss {'Reaction outcome loss': 0.23677855714590756, 'Total loss': 0.23677855714590756}
2023-01-05 02:38:12,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:12,372 INFO:     Epoch: 41
2023-01-05 02:38:14,594 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3463352590799332, 'Total loss': 0.3463352590799332} | train loss {'Reaction outcome loss': 0.23392681321566286, 'Total loss': 0.23392681321566286}
2023-01-05 02:38:14,594 INFO:     Found new best model at epoch 41
2023-01-05 02:38:14,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:14,596 INFO:     Epoch: 42
2023-01-05 02:38:16,744 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3502501611908277, 'Total loss': 0.3502501611908277} | train loss {'Reaction outcome loss': 0.23054213955030115, 'Total loss': 0.23054213955030115}
2023-01-05 02:38:16,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:16,744 INFO:     Epoch: 43
2023-01-05 02:38:18,953 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36653851767381035, 'Total loss': 0.36653851767381035} | train loss {'Reaction outcome loss': 0.22983397938149716, 'Total loss': 0.22983397938149716}
2023-01-05 02:38:18,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:18,954 INFO:     Epoch: 44
2023-01-05 02:38:21,161 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34876347382863365, 'Total loss': 0.34876347382863365} | train loss {'Reaction outcome loss': 0.22215935002864484, 'Total loss': 0.22215935002864484}
2023-01-05 02:38:21,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:21,161 INFO:     Epoch: 45
2023-01-05 02:38:23,378 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36616486807664234, 'Total loss': 0.36616486807664234} | train loss {'Reaction outcome loss': 0.22825830825184226, 'Total loss': 0.22825830825184226}
2023-01-05 02:38:23,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:23,378 INFO:     Epoch: 46
2023-01-05 02:38:25,599 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35746812721093496, 'Total loss': 0.35746812721093496} | train loss {'Reaction outcome loss': 0.22649574940620723, 'Total loss': 0.22649574940620723}
2023-01-05 02:38:25,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:25,600 INFO:     Epoch: 47
2023-01-05 02:38:27,811 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34796372602383296, 'Total loss': 0.34796372602383296} | train loss {'Reaction outcome loss': 0.22412274896237824, 'Total loss': 0.22412274896237824}
2023-01-05 02:38:27,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:27,811 INFO:     Epoch: 48
2023-01-05 02:38:30,058 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36872947017351787, 'Total loss': 0.36872947017351787} | train loss {'Reaction outcome loss': 0.2207590971572412, 'Total loss': 0.2207590971572412}
2023-01-05 02:38:30,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:30,059 INFO:     Epoch: 49
2023-01-05 02:38:32,244 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37049430832266805, 'Total loss': 0.37049430832266805} | train loss {'Reaction outcome loss': 0.22035604112845467, 'Total loss': 0.22035604112845467}
2023-01-05 02:38:32,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:32,244 INFO:     Epoch: 50
2023-01-05 02:38:34,455 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3502301593621572, 'Total loss': 0.3502301593621572} | train loss {'Reaction outcome loss': 0.21849017956089026, 'Total loss': 0.21849017956089026}
2023-01-05 02:38:34,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:34,456 INFO:     Epoch: 51
2023-01-05 02:38:36,692 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3824700087308884, 'Total loss': 0.3824700087308884} | train loss {'Reaction outcome loss': 0.21810861574048815, 'Total loss': 0.21810861574048815}
2023-01-05 02:38:36,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:36,693 INFO:     Epoch: 52
2023-01-05 02:38:38,934 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36258921325206755, 'Total loss': 0.36258921325206755} | train loss {'Reaction outcome loss': 0.2171166350574162, 'Total loss': 0.2171166350574162}
2023-01-05 02:38:38,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:38,934 INFO:     Epoch: 53
2023-01-05 02:38:41,129 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3767736166715622, 'Total loss': 0.3767736166715622} | train loss {'Reaction outcome loss': 0.21192426750577636, 'Total loss': 0.21192426750577636}
2023-01-05 02:38:41,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:41,130 INFO:     Epoch: 54
2023-01-05 02:38:43,356 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36870989501476287, 'Total loss': 0.36870989501476287} | train loss {'Reaction outcome loss': 0.21426235226786525, 'Total loss': 0.21426235226786525}
2023-01-05 02:38:43,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:43,356 INFO:     Epoch: 55
2023-01-05 02:38:45,582 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3764949823419253, 'Total loss': 0.3764949823419253} | train loss {'Reaction outcome loss': 0.20871045745384714, 'Total loss': 0.20871045745384714}
2023-01-05 02:38:45,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:45,582 INFO:     Epoch: 56
2023-01-05 02:38:47,797 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37807652552922566, 'Total loss': 0.37807652552922566} | train loss {'Reaction outcome loss': 0.20729585559971442, 'Total loss': 0.20729585559971442}
2023-01-05 02:38:47,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:47,797 INFO:     Epoch: 57
2023-01-05 02:38:49,976 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3748461827635765, 'Total loss': 0.3748461827635765} | train loss {'Reaction outcome loss': 0.20728986749983652, 'Total loss': 0.20728986749983652}
2023-01-05 02:38:49,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:49,976 INFO:     Epoch: 58
2023-01-05 02:38:52,225 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3587842027346293, 'Total loss': 0.3587842027346293} | train loss {'Reaction outcome loss': 0.2076294387115791, 'Total loss': 0.2076294387115791}
2023-01-05 02:38:52,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:52,225 INFO:     Epoch: 59
2023-01-05 02:38:54,476 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3813571085532506, 'Total loss': 0.3813571085532506} | train loss {'Reaction outcome loss': 0.2070666671485139, 'Total loss': 0.2070666671485139}
2023-01-05 02:38:54,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:54,477 INFO:     Epoch: 60
2023-01-05 02:38:56,770 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35789973139762876, 'Total loss': 0.35789973139762876} | train loss {'Reaction outcome loss': 0.20415191751457618, 'Total loss': 0.20415191751457618}
2023-01-05 02:38:56,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:56,770 INFO:     Epoch: 61
2023-01-05 02:38:59,031 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3996482412020365, 'Total loss': 0.3996482412020365} | train loss {'Reaction outcome loss': 0.2010065891144508, 'Total loss': 0.2010065891144508}
2023-01-05 02:38:59,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:38:59,031 INFO:     Epoch: 62
2023-01-05 02:39:01,294 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38144215643405915, 'Total loss': 0.38144215643405915} | train loss {'Reaction outcome loss': 0.20175087228013935, 'Total loss': 0.20175087228013935}
2023-01-05 02:39:01,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:01,294 INFO:     Epoch: 63
2023-01-05 02:39:03,521 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37244243423144024, 'Total loss': 0.37244243423144024} | train loss {'Reaction outcome loss': 0.20228408506671336, 'Total loss': 0.20228408506671336}
2023-01-05 02:39:03,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:03,522 INFO:     Epoch: 64
2023-01-05 02:39:05,772 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3808643102645874, 'Total loss': 0.3808643102645874} | train loss {'Reaction outcome loss': 0.20078269738219812, 'Total loss': 0.20078269738219812}
2023-01-05 02:39:05,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:05,773 INFO:     Epoch: 65
2023-01-05 02:39:07,970 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3848275641600291, 'Total loss': 0.3848275641600291} | train loss {'Reaction outcome loss': 0.19732991313151613, 'Total loss': 0.19732991313151613}
2023-01-05 02:39:07,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:07,970 INFO:     Epoch: 66
2023-01-05 02:39:10,204 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3902347763379415, 'Total loss': 0.3902347763379415} | train loss {'Reaction outcome loss': 0.19922936028575639, 'Total loss': 0.19922936028575639}
2023-01-05 02:39:10,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:10,205 INFO:     Epoch: 67
2023-01-05 02:39:12,442 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3826659639676412, 'Total loss': 0.3826659639676412} | train loss {'Reaction outcome loss': 0.19960928243326043, 'Total loss': 0.19960928243326043}
2023-01-05 02:39:12,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:12,442 INFO:     Epoch: 68
2023-01-05 02:39:14,691 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36209747528967756, 'Total loss': 0.36209747528967756} | train loss {'Reaction outcome loss': 0.19692670953685304, 'Total loss': 0.19692670953685304}
2023-01-05 02:39:14,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:14,692 INFO:     Epoch: 69
2023-01-05 02:39:16,943 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38095629910628, 'Total loss': 0.38095629910628} | train loss {'Reaction outcome loss': 0.19624236550867988, 'Total loss': 0.19624236550867988}
2023-01-05 02:39:16,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:16,944 INFO:     Epoch: 70
2023-01-05 02:39:19,210 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40675179064273836, 'Total loss': 0.40675179064273836} | train loss {'Reaction outcome loss': 0.19650978883493034, 'Total loss': 0.19650978883493034}
2023-01-05 02:39:19,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:19,210 INFO:     Epoch: 71
2023-01-05 02:39:21,558 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3960983335971832, 'Total loss': 0.3960983335971832} | train loss {'Reaction outcome loss': 0.1931984328466471, 'Total loss': 0.1931984328466471}
2023-01-05 02:39:21,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:21,558 INFO:     Epoch: 72
2023-01-05 02:39:23,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4054089883963267, 'Total loss': 0.4054089883963267} | train loss {'Reaction outcome loss': 0.19397969919488856, 'Total loss': 0.19397969919488856}
2023-01-05 02:39:23,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:23,775 INFO:     Epoch: 73
2023-01-05 02:39:25,944 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37267918984095255, 'Total loss': 0.37267918984095255} | train loss {'Reaction outcome loss': 0.1927371611684184, 'Total loss': 0.1927371611684184}
2023-01-05 02:39:25,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:25,944 INFO:     Epoch: 74
2023-01-05 02:39:28,182 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3742633402347565, 'Total loss': 0.3742633402347565} | train loss {'Reaction outcome loss': 0.19295192157197408, 'Total loss': 0.19295192157197408}
2023-01-05 02:39:28,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:28,182 INFO:     Epoch: 75
2023-01-05 02:39:30,416 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38693177203337353, 'Total loss': 0.38693177203337353} | train loss {'Reaction outcome loss': 0.18707130571981953, 'Total loss': 0.18707130571981953}
2023-01-05 02:39:30,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:30,417 INFO:     Epoch: 76
2023-01-05 02:39:32,663 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3936764890948931, 'Total loss': 0.3936764890948931} | train loss {'Reaction outcome loss': 0.18893565031084558, 'Total loss': 0.18893565031084558}
2023-01-05 02:39:32,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:32,663 INFO:     Epoch: 77
2023-01-05 02:39:34,889 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39324897329012554, 'Total loss': 0.39324897329012554} | train loss {'Reaction outcome loss': 0.19020047313819508, 'Total loss': 0.19020047313819508}
2023-01-05 02:39:34,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:34,889 INFO:     Epoch: 78
2023-01-05 02:39:37,144 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3936891178290049, 'Total loss': 0.3936891178290049} | train loss {'Reaction outcome loss': 0.18796433548237926, 'Total loss': 0.18796433548237926}
2023-01-05 02:39:37,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:37,144 INFO:     Epoch: 79
2023-01-05 02:39:39,349 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3693887621164322, 'Total loss': 0.3693887621164322} | train loss {'Reaction outcome loss': 0.18655146285723423, 'Total loss': 0.18655146285723423}
2023-01-05 02:39:39,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:39,350 INFO:     Epoch: 80
2023-01-05 02:39:41,576 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37457563827435175, 'Total loss': 0.37457563827435175} | train loss {'Reaction outcome loss': 0.1847108382805644, 'Total loss': 0.1847108382805644}
2023-01-05 02:39:41,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:41,576 INFO:     Epoch: 81
2023-01-05 02:39:43,840 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3925168971220652, 'Total loss': 0.3925168971220652} | train loss {'Reaction outcome loss': 0.17965722837761072, 'Total loss': 0.17965722837761072}
2023-01-05 02:39:43,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:43,840 INFO:     Epoch: 82
2023-01-05 02:39:46,074 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3901896794637044, 'Total loss': 0.3901896794637044} | train loss {'Reaction outcome loss': 0.18602913794265757, 'Total loss': 0.18602913794265757}
2023-01-05 02:39:46,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:46,075 INFO:     Epoch: 83
2023-01-05 02:39:48,315 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3862178176641464, 'Total loss': 0.3862178176641464} | train loss {'Reaction outcome loss': 0.18355798248927838, 'Total loss': 0.18355798248927838}
2023-01-05 02:39:48,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:48,315 INFO:     Epoch: 84
2023-01-05 02:39:50,481 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38970698515574137, 'Total loss': 0.38970698515574137} | train loss {'Reaction outcome loss': 0.17823083219135227, 'Total loss': 0.17823083219135227}
2023-01-05 02:39:50,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:50,481 INFO:     Epoch: 85
2023-01-05 02:39:52,685 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3823894823590914, 'Total loss': 0.3823894823590914} | train loss {'Reaction outcome loss': 0.18437027285003274, 'Total loss': 0.18437027285003274}
2023-01-05 02:39:52,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:52,686 INFO:     Epoch: 86
2023-01-05 02:39:54,941 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38564806481202446, 'Total loss': 0.38564806481202446} | train loss {'Reaction outcome loss': 0.18283242234012065, 'Total loss': 0.18283242234012065}
2023-01-05 02:39:54,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:54,941 INFO:     Epoch: 87
2023-01-05 02:39:57,165 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38980696101983386, 'Total loss': 0.38980696101983386} | train loss {'Reaction outcome loss': 0.17941144928470631, 'Total loss': 0.17941144928470631}
2023-01-05 02:39:57,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:57,166 INFO:     Epoch: 88
2023-01-05 02:39:59,419 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38734417061010995, 'Total loss': 0.38734417061010995} | train loss {'Reaction outcome loss': 0.18297781040454922, 'Total loss': 0.18297781040454922}
2023-01-05 02:39:59,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:39:59,419 INFO:     Epoch: 89
2023-01-05 02:40:01,644 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3543787717819214, 'Total loss': 0.3543787717819214} | train loss {'Reaction outcome loss': 0.1824119186351607, 'Total loss': 0.1824119186351607}
2023-01-05 02:40:01,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:01,644 INFO:     Epoch: 90
2023-01-05 02:40:03,879 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3761642356713613, 'Total loss': 0.3761642356713613} | train loss {'Reaction outcome loss': 0.17535139623330065, 'Total loss': 0.17535139623330065}
2023-01-05 02:40:03,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:03,879 INFO:     Epoch: 91
2023-01-05 02:40:06,057 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36838583946228026, 'Total loss': 0.36838583946228026} | train loss {'Reaction outcome loss': 0.17837272946880828, 'Total loss': 0.17837272946880828}
2023-01-05 02:40:06,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:06,058 INFO:     Epoch: 92
2023-01-05 02:40:08,271 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3991959929466248, 'Total loss': 0.3991959929466248} | train loss {'Reaction outcome loss': 0.1748238021427167, 'Total loss': 0.1748238021427167}
2023-01-05 02:40:08,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:08,271 INFO:     Epoch: 93
2023-01-05 02:40:10,484 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39968597094217934, 'Total loss': 0.39968597094217934} | train loss {'Reaction outcome loss': 0.17656281362170023, 'Total loss': 0.17656281362170023}
2023-01-05 02:40:10,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:10,484 INFO:     Epoch: 94
2023-01-05 02:40:12,705 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.374640512218078, 'Total loss': 0.374640512218078} | train loss {'Reaction outcome loss': 0.18124594497040505, 'Total loss': 0.18124594497040505}
2023-01-05 02:40:12,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:12,705 INFO:     Epoch: 95
2023-01-05 02:40:14,931 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41489267150561016, 'Total loss': 0.41489267150561016} | train loss {'Reaction outcome loss': 0.1767077210547557, 'Total loss': 0.1767077210547557}
2023-01-05 02:40:14,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:14,932 INFO:     Epoch: 96
2023-01-05 02:40:17,143 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3821903556585312, 'Total loss': 0.3821903556585312} | train loss {'Reaction outcome loss': 0.17423031093814959, 'Total loss': 0.17423031093814959}
2023-01-05 02:40:17,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:17,143 INFO:     Epoch: 97
2023-01-05 02:40:19,376 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4007882552842299, 'Total loss': 0.4007882552842299} | train loss {'Reaction outcome loss': 0.17532908574035827, 'Total loss': 0.17532908574035827}
2023-01-05 02:40:19,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:19,376 INFO:     Epoch: 98
2023-01-05 02:40:21,568 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4018585761388143, 'Total loss': 0.4018585761388143} | train loss {'Reaction outcome loss': 0.1740857601965969, 'Total loss': 0.1740857601965969}
2023-01-05 02:40:21,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:21,568 INFO:     Epoch: 99
2023-01-05 02:40:23,817 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4305136422316233, 'Total loss': 0.4305136422316233} | train loss {'Reaction outcome loss': 0.17270273869413386, 'Total loss': 0.17270273869413386}
2023-01-05 02:40:23,818 INFO:     Best model found after epoch 42 of 100.
2023-01-05 02:40:23,818 INFO:   Done with stage: TRAINING
2023-01-05 02:40:23,818 INFO:   Starting stage: EVALUATION
2023-01-05 02:40:23,944 INFO:   Done with stage: EVALUATION
2023-01-05 02:40:23,944 INFO:   Leaving out SEQ value Fold_9
2023-01-05 02:40:23,957 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:40:23,957 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:40:24,606 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:40:24,606 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:40:24,674 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:40:24,674 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:40:24,674 INFO:     No hyperparam tuning for this model
2023-01-05 02:40:24,674 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:40:24,674 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:40:24,675 INFO:     None feature selector for col prot
2023-01-05 02:40:24,675 INFO:     None feature selector for col prot
2023-01-05 02:40:24,675 INFO:     None feature selector for col prot
2023-01-05 02:40:24,676 INFO:     None feature selector for col chem
2023-01-05 02:40:24,676 INFO:     None feature selector for col chem
2023-01-05 02:40:24,676 INFO:     None feature selector for col chem
2023-01-05 02:40:24,676 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:40:24,676 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:40:24,678 INFO:     Number of params in model 72931
2023-01-05 02:40:24,681 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:40:24,681 INFO:   Starting stage: TRAINING
2023-01-05 02:40:24,742 INFO:     Val loss before train {'Reaction outcome loss': 0.9856097102165222, 'Total loss': 0.9856097102165222}
2023-01-05 02:40:24,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:24,743 INFO:     Epoch: 0
2023-01-05 02:40:26,938 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5998104989528656, 'Total loss': 0.5998104989528656} | train loss {'Reaction outcome loss': 0.9079912599638431, 'Total loss': 0.9079912599638431}
2023-01-05 02:40:26,938 INFO:     Found new best model at epoch 0
2023-01-05 02:40:26,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:26,940 INFO:     Epoch: 1
2023-01-05 02:40:29,164 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4950769166151682, 'Total loss': 0.4950769166151682} | train loss {'Reaction outcome loss': 0.5872318477091127, 'Total loss': 0.5872318477091127}
2023-01-05 02:40:29,164 INFO:     Found new best model at epoch 1
2023-01-05 02:40:29,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:29,165 INFO:     Epoch: 2
2023-01-05 02:40:31,355 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4574506938457489, 'Total loss': 0.4574506938457489} | train loss {'Reaction outcome loss': 0.5129160341555185, 'Total loss': 0.5129160341555185}
2023-01-05 02:40:31,356 INFO:     Found new best model at epoch 2
2023-01-05 02:40:31,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:31,358 INFO:     Epoch: 3
2023-01-05 02:40:33,547 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.431898162762324, 'Total loss': 0.431898162762324} | train loss {'Reaction outcome loss': 0.4762130934935417, 'Total loss': 0.4762130934935417}
2023-01-05 02:40:33,548 INFO:     Found new best model at epoch 3
2023-01-05 02:40:33,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:33,549 INFO:     Epoch: 4
2023-01-05 02:40:35,763 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4220008114973704, 'Total loss': 0.4220008114973704} | train loss {'Reaction outcome loss': 0.4468189003149958, 'Total loss': 0.4468189003149958}
2023-01-05 02:40:35,763 INFO:     Found new best model at epoch 4
2023-01-05 02:40:35,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:35,765 INFO:     Epoch: 5
2023-01-05 02:40:37,986 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4229108661413193, 'Total loss': 0.4229108661413193} | train loss {'Reaction outcome loss': 0.42990099296082546, 'Total loss': 0.42990099296082546}
2023-01-05 02:40:37,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:37,986 INFO:     Epoch: 6
2023-01-05 02:40:40,157 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41793363988399507, 'Total loss': 0.41793363988399507} | train loss {'Reaction outcome loss': 0.40724565700566684, 'Total loss': 0.40724565700566684}
2023-01-05 02:40:40,157 INFO:     Found new best model at epoch 6
2023-01-05 02:40:40,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:40,158 INFO:     Epoch: 7
2023-01-05 02:40:42,388 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.410440593957901, 'Total loss': 0.410440593957901} | train loss {'Reaction outcome loss': 0.3917765182300206, 'Total loss': 0.3917765182300206}
2023-01-05 02:40:42,388 INFO:     Found new best model at epoch 7
2023-01-05 02:40:42,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:42,389 INFO:     Epoch: 8
2023-01-05 02:40:44,541 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.397150519490242, 'Total loss': 0.397150519490242} | train loss {'Reaction outcome loss': 0.3850794793480504, 'Total loss': 0.3850794793480504}
2023-01-05 02:40:44,542 INFO:     Found new best model at epoch 8
2023-01-05 02:40:44,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:44,543 INFO:     Epoch: 9
2023-01-05 02:40:46,577 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4224005659421285, 'Total loss': 0.4224005659421285} | train loss {'Reaction outcome loss': 0.36498986684927975, 'Total loss': 0.36498986684927975}
2023-01-05 02:40:46,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:46,577 INFO:     Epoch: 10
2023-01-05 02:40:48,786 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42188848555088043, 'Total loss': 0.42188848555088043} | train loss {'Reaction outcome loss': 0.35987916354932925, 'Total loss': 0.35987916354932925}
2023-01-05 02:40:48,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:48,787 INFO:     Epoch: 11
2023-01-05 02:40:51,000 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40654920736948646, 'Total loss': 0.40654920736948646} | train loss {'Reaction outcome loss': 0.34775274159916997, 'Total loss': 0.34775274159916997}
2023-01-05 02:40:51,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:51,001 INFO:     Epoch: 12
2023-01-05 02:40:53,267 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42178914944330853, 'Total loss': 0.42178914944330853} | train loss {'Reaction outcome loss': 0.3402668475071444, 'Total loss': 0.3402668475071444}
2023-01-05 02:40:53,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:53,269 INFO:     Epoch: 13
2023-01-05 02:40:55,434 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4246922423442205, 'Total loss': 0.4246922423442205} | train loss {'Reaction outcome loss': 0.33417999866778836, 'Total loss': 0.33417999866778836}
2023-01-05 02:40:55,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:55,435 INFO:     Epoch: 14
2023-01-05 02:40:57,647 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4252979795138041, 'Total loss': 0.4252979795138041} | train loss {'Reaction outcome loss': 0.3183540661622138, 'Total loss': 0.3183540661622138}
2023-01-05 02:40:57,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:57,647 INFO:     Epoch: 15
2023-01-05 02:40:59,867 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39978959957758586, 'Total loss': 0.39978959957758586} | train loss {'Reaction outcome loss': 0.3172214624274821, 'Total loss': 0.3172214624274821}
2023-01-05 02:40:59,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:40:59,868 INFO:     Epoch: 16
2023-01-05 02:41:02,084 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42989240288734437, 'Total loss': 0.42989240288734437} | train loss {'Reaction outcome loss': 0.3054199253283713, 'Total loss': 0.3054199253283713}
2023-01-05 02:41:02,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:02,084 INFO:     Epoch: 17
2023-01-05 02:41:04,322 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41210300425688423, 'Total loss': 0.41210300425688423} | train loss {'Reaction outcome loss': 0.3021710031550296, 'Total loss': 0.3021710031550296}
2023-01-05 02:41:04,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:04,322 INFO:     Epoch: 18
2023-01-05 02:41:06,554 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41697612206141155, 'Total loss': 0.41697612206141155} | train loss {'Reaction outcome loss': 0.29348260172418433, 'Total loss': 0.29348260172418433}
2023-01-05 02:41:06,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:06,554 INFO:     Epoch: 19
2023-01-05 02:41:08,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4395787795384725, 'Total loss': 0.4395787795384725} | train loss {'Reaction outcome loss': 0.28716403808798235, 'Total loss': 0.28716403808798235}
2023-01-05 02:41:08,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:08,752 INFO:     Epoch: 20
2023-01-05 02:41:10,915 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39991930723190305, 'Total loss': 0.39991930723190305} | train loss {'Reaction outcome loss': 0.28493003121638383, 'Total loss': 0.28493003121638383}
2023-01-05 02:41:10,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:10,915 INFO:     Epoch: 21
2023-01-05 02:41:13,028 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43027079502741494, 'Total loss': 0.43027079502741494} | train loss {'Reaction outcome loss': 0.2782311054748775, 'Total loss': 0.2782311054748775}
2023-01-05 02:41:13,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:13,029 INFO:     Epoch: 22
2023-01-05 02:41:15,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4395855079094569, 'Total loss': 0.4395855079094569} | train loss {'Reaction outcome loss': 0.2757774913533978, 'Total loss': 0.2757774913533978}
2023-01-05 02:41:15,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:15,216 INFO:     Epoch: 23
2023-01-05 02:41:17,372 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4237561086813609, 'Total loss': 0.4237561086813609} | train loss {'Reaction outcome loss': 0.27107305518847746, 'Total loss': 0.27107305518847746}
2023-01-05 02:41:17,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:17,372 INFO:     Epoch: 24
2023-01-05 02:41:19,585 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4430217246214549, 'Total loss': 0.4430217246214549} | train loss {'Reaction outcome loss': 0.26751617938416067, 'Total loss': 0.26751617938416067}
2023-01-05 02:41:19,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:19,585 INFO:     Epoch: 25
2023-01-05 02:41:21,813 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4191654523213704, 'Total loss': 0.4191654523213704} | train loss {'Reaction outcome loss': 0.2612281668876862, 'Total loss': 0.2612281668876862}
2023-01-05 02:41:21,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:21,813 INFO:     Epoch: 26
2023-01-05 02:41:24,040 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43415977160135905, 'Total loss': 0.43415977160135905} | train loss {'Reaction outcome loss': 0.2544627117169817, 'Total loss': 0.2544627117169817}
2023-01-05 02:41:24,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:24,041 INFO:     Epoch: 27
2023-01-05 02:41:26,257 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39753284951051077, 'Total loss': 0.39753284951051077} | train loss {'Reaction outcome loss': 0.2524581585677653, 'Total loss': 0.2524581585677653}
2023-01-05 02:41:26,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:26,258 INFO:     Epoch: 28
2023-01-05 02:41:28,434 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40184823671976727, 'Total loss': 0.40184823671976727} | train loss {'Reaction outcome loss': 0.25020696353303257, 'Total loss': 0.25020696353303257}
2023-01-05 02:41:28,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:28,435 INFO:     Epoch: 29
2023-01-05 02:41:30,636 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42521925767262775, 'Total loss': 0.42521925767262775} | train loss {'Reaction outcome loss': 0.24434435729236498, 'Total loss': 0.24434435729236498}
2023-01-05 02:41:30,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:30,637 INFO:     Epoch: 30
2023-01-05 02:41:32,863 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3974736993511518, 'Total loss': 0.3974736993511518} | train loss {'Reaction outcome loss': 0.24239608672631047, 'Total loss': 0.24239608672631047}
2023-01-05 02:41:32,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:32,863 INFO:     Epoch: 31
2023-01-05 02:41:35,032 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39828385015328727, 'Total loss': 0.39828385015328727} | train loss {'Reaction outcome loss': 0.23610337310042367, 'Total loss': 0.23610337310042367}
2023-01-05 02:41:35,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:35,033 INFO:     Epoch: 32
2023-01-05 02:41:37,229 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.404685378074646, 'Total loss': 0.404685378074646} | train loss {'Reaction outcome loss': 0.23845085608399044, 'Total loss': 0.23845085608399044}
2023-01-05 02:41:37,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:37,229 INFO:     Epoch: 33
2023-01-05 02:41:39,461 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3922334688405196, 'Total loss': 0.3922334688405196} | train loss {'Reaction outcome loss': 0.23124554224421073, 'Total loss': 0.23124554224421073}
2023-01-05 02:41:39,461 INFO:     Found new best model at epoch 33
2023-01-05 02:41:39,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:39,462 INFO:     Epoch: 34
2023-01-05 02:41:41,708 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37299987276395163, 'Total loss': 0.37299987276395163} | train loss {'Reaction outcome loss': 0.23030931751386527, 'Total loss': 0.23030931751386527}
2023-01-05 02:41:41,708 INFO:     Found new best model at epoch 34
2023-01-05 02:41:41,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:41,710 INFO:     Epoch: 35
2023-01-05 02:41:43,942 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41532709101835885, 'Total loss': 0.41532709101835885} | train loss {'Reaction outcome loss': 0.2229657098786892, 'Total loss': 0.2229657098786892}
2023-01-05 02:41:43,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:43,942 INFO:     Epoch: 36
2023-01-05 02:41:46,182 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3864284730205933, 'Total loss': 0.3864284730205933} | train loss {'Reaction outcome loss': 0.21999675489581413, 'Total loss': 0.21999675489581413}
2023-01-05 02:41:46,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:46,182 INFO:     Epoch: 37
2023-01-05 02:41:48,391 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3905681808789571, 'Total loss': 0.3905681808789571} | train loss {'Reaction outcome loss': 0.21889781332608774, 'Total loss': 0.21889781332608774}
2023-01-05 02:41:48,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:48,392 INFO:     Epoch: 38
2023-01-05 02:41:50,564 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4228702813386917, 'Total loss': 0.4228702813386917} | train loss {'Reaction outcome loss': 0.216961472206851, 'Total loss': 0.216961472206851}
2023-01-05 02:41:50,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:50,565 INFO:     Epoch: 39
2023-01-05 02:41:52,796 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40155318280061086, 'Total loss': 0.40155318280061086} | train loss {'Reaction outcome loss': 0.2162587743959505, 'Total loss': 0.2162587743959505}
2023-01-05 02:41:52,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:52,796 INFO:     Epoch: 40
2023-01-05 02:41:54,944 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4195564518372218, 'Total loss': 0.4195564518372218} | train loss {'Reaction outcome loss': 0.21428770943116532, 'Total loss': 0.21428770943116532}
2023-01-05 02:41:54,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:54,944 INFO:     Epoch: 41
2023-01-05 02:41:57,127 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4058898756901423, 'Total loss': 0.4058898756901423} | train loss {'Reaction outcome loss': 0.21001058024605804, 'Total loss': 0.21001058024605804}
2023-01-05 02:41:57,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:57,127 INFO:     Epoch: 42
2023-01-05 02:41:59,354 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4398282696803411, 'Total loss': 0.4398282696803411} | train loss {'Reaction outcome loss': 0.20684481765327117, 'Total loss': 0.20684481765327117}
2023-01-05 02:41:59,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:41:59,354 INFO:     Epoch: 43
2023-01-05 02:42:01,534 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41587261060873665, 'Total loss': 0.41587261060873665} | train loss {'Reaction outcome loss': 0.20298920210491675, 'Total loss': 0.20298920210491675}
2023-01-05 02:42:01,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:01,534 INFO:     Epoch: 44
2023-01-05 02:42:03,748 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43726399342219036, 'Total loss': 0.43726399342219036} | train loss {'Reaction outcome loss': 0.20101984870708445, 'Total loss': 0.20101984870708445}
2023-01-05 02:42:03,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:03,748 INFO:     Epoch: 45
2023-01-05 02:42:05,912 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43988706668217975, 'Total loss': 0.43988706668217975} | train loss {'Reaction outcome loss': 0.20251941680568306, 'Total loss': 0.20251941680568306}
2023-01-05 02:42:05,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:05,913 INFO:     Epoch: 46
2023-01-05 02:42:08,145 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44556738833586373, 'Total loss': 0.44556738833586373} | train loss {'Reaction outcome loss': 0.20071876039524583, 'Total loss': 0.20071876039524583}
2023-01-05 02:42:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:08,145 INFO:     Epoch: 47
2023-01-05 02:42:10,301 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44645087271928785, 'Total loss': 0.44645087271928785} | train loss {'Reaction outcome loss': 0.20067227257578804, 'Total loss': 0.20067227257578804}
2023-01-05 02:42:10,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:10,301 INFO:     Epoch: 48
2023-01-05 02:42:12,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4214129694892714, 'Total loss': 0.4214129694892714} | train loss {'Reaction outcome loss': 0.1965352493086762, 'Total loss': 0.1965352493086762}
2023-01-05 02:42:12,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:12,531 INFO:     Epoch: 49
2023-01-05 02:42:14,740 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44657916923364005, 'Total loss': 0.44657916923364005} | train loss {'Reaction outcome loss': 0.19602051369818677, 'Total loss': 0.19602051369818677}
2023-01-05 02:42:14,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:14,741 INFO:     Epoch: 50
2023-01-05 02:42:16,954 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4481860359509786, 'Total loss': 0.4481860359509786} | train loss {'Reaction outcome loss': 0.19472881282142696, 'Total loss': 0.19472881282142696}
2023-01-05 02:42:16,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:16,954 INFO:     Epoch: 51
2023-01-05 02:42:19,157 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4298270622889201, 'Total loss': 0.4298270622889201} | train loss {'Reaction outcome loss': 0.19389539093363786, 'Total loss': 0.19389539093363786}
2023-01-05 02:42:19,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:19,157 INFO:     Epoch: 52
2023-01-05 02:42:21,460 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43755940965687234, 'Total loss': 0.43755940965687234} | train loss {'Reaction outcome loss': 0.19287281882452922, 'Total loss': 0.19287281882452922}
2023-01-05 02:42:21,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:21,460 INFO:     Epoch: 53
2023-01-05 02:42:23,667 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38970278774698575, 'Total loss': 0.38970278774698575} | train loss {'Reaction outcome loss': 0.18713269054033135, 'Total loss': 0.18713269054033135}
2023-01-05 02:42:23,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:23,667 INFO:     Epoch: 54
2023-01-05 02:42:25,842 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44951444466908774, 'Total loss': 0.44951444466908774} | train loss {'Reaction outcome loss': 0.18938143379360872, 'Total loss': 0.18938143379360872}
2023-01-05 02:42:25,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:25,843 INFO:     Epoch: 55
2023-01-05 02:42:28,053 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41037354469299314, 'Total loss': 0.41037354469299314} | train loss {'Reaction outcome loss': 0.18933427242399023, 'Total loss': 0.18933427242399023}
2023-01-05 02:42:28,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:28,054 INFO:     Epoch: 56
2023-01-05 02:42:30,261 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4263308654228846, 'Total loss': 0.4263308654228846} | train loss {'Reaction outcome loss': 0.19500412489457505, 'Total loss': 0.19500412489457505}
2023-01-05 02:42:30,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:30,261 INFO:     Epoch: 57
2023-01-05 02:42:32,384 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46416030476490655, 'Total loss': 0.46416030476490655} | train loss {'Reaction outcome loss': 0.18261071917920435, 'Total loss': 0.18261071917920435}
2023-01-05 02:42:32,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:32,384 INFO:     Epoch: 58
2023-01-05 02:42:34,537 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4101163292924563, 'Total loss': 0.4101163292924563} | train loss {'Reaction outcome loss': 0.18127756186822144, 'Total loss': 0.18127756186822144}
2023-01-05 02:42:34,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:34,537 INFO:     Epoch: 59
2023-01-05 02:42:36,761 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4358130246400833, 'Total loss': 0.4358130246400833} | train loss {'Reaction outcome loss': 0.18323141900333065, 'Total loss': 0.18323141900333065}
2023-01-05 02:42:36,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:36,762 INFO:     Epoch: 60
2023-01-05 02:42:38,951 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40947839319705964, 'Total loss': 0.40947839319705964} | train loss {'Reaction outcome loss': 0.18247899443699714, 'Total loss': 0.18247899443699714}
2023-01-05 02:42:38,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:38,951 INFO:     Epoch: 61
2023-01-05 02:42:41,160 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4350453456242879, 'Total loss': 0.4350453456242879} | train loss {'Reaction outcome loss': 0.17827572219794358, 'Total loss': 0.17827572219794358}
2023-01-05 02:42:41,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:41,160 INFO:     Epoch: 62
2023-01-05 02:42:43,386 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4049530915915966, 'Total loss': 0.4049530915915966} | train loss {'Reaction outcome loss': 0.1844190723368096, 'Total loss': 0.1844190723368096}
2023-01-05 02:42:43,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:43,387 INFO:     Epoch: 63
2023-01-05 02:42:45,614 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3877621461947759, 'Total loss': 0.3877621461947759} | train loss {'Reaction outcome loss': 0.17286351045430468, 'Total loss': 0.17286351045430468}
2023-01-05 02:42:45,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:45,614 INFO:     Epoch: 64
2023-01-05 02:42:47,830 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41788542568683623, 'Total loss': 0.41788542568683623} | train loss {'Reaction outcome loss': 0.1821550907954628, 'Total loss': 0.1821550907954628}
2023-01-05 02:42:47,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:47,830 INFO:     Epoch: 65
2023-01-05 02:42:49,961 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40633460866908233, 'Total loss': 0.40633460866908233} | train loss {'Reaction outcome loss': 0.1765226835612697, 'Total loss': 0.1765226835612697}
2023-01-05 02:42:49,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:49,961 INFO:     Epoch: 66
2023-01-05 02:42:52,172 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4182609885931015, 'Total loss': 0.4182609885931015} | train loss {'Reaction outcome loss': 0.17524144587440105, 'Total loss': 0.17524144587440105}
2023-01-05 02:42:52,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:52,172 INFO:     Epoch: 67
2023-01-05 02:42:54,384 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41772342324256895, 'Total loss': 0.41772342324256895} | train loss {'Reaction outcome loss': 0.1723617890214099, 'Total loss': 0.1723617890214099}
2023-01-05 02:42:54,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:54,384 INFO:     Epoch: 68
2023-01-05 02:42:56,611 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4609441104034583, 'Total loss': 0.4609441104034583} | train loss {'Reaction outcome loss': 0.174886814262514, 'Total loss': 0.174886814262514}
2023-01-05 02:42:56,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:56,612 INFO:     Epoch: 69
2023-01-05 02:42:58,836 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4363573621958494, 'Total loss': 0.4363573621958494} | train loss {'Reaction outcome loss': 0.17673791360184823, 'Total loss': 0.17673791360184823}
2023-01-05 02:42:58,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:42:58,836 INFO:     Epoch: 70
2023-01-05 02:43:01,064 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46008141537507374, 'Total loss': 0.46008141537507374} | train loss {'Reaction outcome loss': 0.16881939955735512, 'Total loss': 0.16881939955735512}
2023-01-05 02:43:01,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:01,065 INFO:     Epoch: 71
2023-01-05 02:43:03,292 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4289363364378611, 'Total loss': 0.4289363364378611} | train loss {'Reaction outcome loss': 0.17214212951549485, 'Total loss': 0.17214212951549485}
2023-01-05 02:43:03,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:03,293 INFO:     Epoch: 72
2023-01-05 02:43:05,498 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44118342250585557, 'Total loss': 0.44118342250585557} | train loss {'Reaction outcome loss': 0.16983152057696813, 'Total loss': 0.16983152057696813}
2023-01-05 02:43:05,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:05,498 INFO:     Epoch: 73
2023-01-05 02:43:07,653 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.459897385040919, 'Total loss': 0.459897385040919} | train loss {'Reaction outcome loss': 0.17312504004782242, 'Total loss': 0.17312504004782242}
2023-01-05 02:43:07,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:07,655 INFO:     Epoch: 74
2023-01-05 02:43:09,850 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.423282195130984, 'Total loss': 0.423282195130984} | train loss {'Reaction outcome loss': 0.17137159347996442, 'Total loss': 0.17137159347996442}
2023-01-05 02:43:09,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:09,850 INFO:     Epoch: 75
2023-01-05 02:43:12,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.428874948186179, 'Total loss': 0.428874948186179} | train loss {'Reaction outcome loss': 0.16859145165101563, 'Total loss': 0.16859145165101563}
2023-01-05 02:43:12,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:12,083 INFO:     Epoch: 76
2023-01-05 02:43:14,307 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44952307393153507, 'Total loss': 0.44952307393153507} | train loss {'Reaction outcome loss': 0.1721706319002122, 'Total loss': 0.1721706319002122}
2023-01-05 02:43:14,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:14,308 INFO:     Epoch: 77
2023-01-05 02:43:16,531 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4357118884722392, 'Total loss': 0.4357118884722392} | train loss {'Reaction outcome loss': 0.16684983869892184, 'Total loss': 0.16684983869892184}
2023-01-05 02:43:16,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:16,532 INFO:     Epoch: 78
2023-01-05 02:43:18,787 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4714462916056315, 'Total loss': 0.4714462916056315} | train loss {'Reaction outcome loss': 0.16513517868779873, 'Total loss': 0.16513517868779873}
2023-01-05 02:43:18,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:18,787 INFO:     Epoch: 79
2023-01-05 02:43:20,991 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4476702600717545, 'Total loss': 0.4476702600717545} | train loss {'Reaction outcome loss': 0.16176492074864787, 'Total loss': 0.16176492074864787}
2023-01-05 02:43:20,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:20,992 INFO:     Epoch: 80
2023-01-05 02:43:23,217 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4217780848344167, 'Total loss': 0.4217780848344167} | train loss {'Reaction outcome loss': 0.16400005437355544, 'Total loss': 0.16400005437355544}
2023-01-05 02:43:23,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:23,217 INFO:     Epoch: 81
2023-01-05 02:43:25,442 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4294082423051198, 'Total loss': 0.4294082423051198} | train loss {'Reaction outcome loss': 0.16342679802736226, 'Total loss': 0.16342679802736226}
2023-01-05 02:43:25,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:25,442 INFO:     Epoch: 82
2023-01-05 02:43:27,662 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4472425768772761, 'Total loss': 0.4472425768772761} | train loss {'Reaction outcome loss': 0.16739618124943362, 'Total loss': 0.16739618124943362}
2023-01-05 02:43:27,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:27,663 INFO:     Epoch: 83
2023-01-05 02:43:29,873 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4464837451775869, 'Total loss': 0.4464837451775869} | train loss {'Reaction outcome loss': 0.16363114987357255, 'Total loss': 0.16363114987357255}
2023-01-05 02:43:29,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:29,873 INFO:     Epoch: 84
2023-01-05 02:43:32,096 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41646909415721894, 'Total loss': 0.41646909415721894} | train loss {'Reaction outcome loss': 0.16124861752002562, 'Total loss': 0.16124861752002562}
2023-01-05 02:43:32,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:32,097 INFO:     Epoch: 85
2023-01-05 02:43:34,319 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4809102137883504, 'Total loss': 0.4809102137883504} | train loss {'Reaction outcome loss': 0.16207756956080724, 'Total loss': 0.16207756956080724}
2023-01-05 02:43:34,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:34,319 INFO:     Epoch: 86
2023-01-05 02:43:36,545 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4455845137437185, 'Total loss': 0.4455845137437185} | train loss {'Reaction outcome loss': 0.16234219555205998, 'Total loss': 0.16234219555205998}
2023-01-05 02:43:36,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:36,546 INFO:     Epoch: 87
2023-01-05 02:43:38,685 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4061698317527771, 'Total loss': 0.4061698317527771} | train loss {'Reaction outcome loss': 0.16072870969745148, 'Total loss': 0.16072870969745148}
2023-01-05 02:43:38,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:38,685 INFO:     Epoch: 88
2023-01-05 02:43:40,873 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45834402094284693, 'Total loss': 0.45834402094284693} | train loss {'Reaction outcome loss': 0.16250481149079754, 'Total loss': 0.16250481149079754}
2023-01-05 02:43:40,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:40,874 INFO:     Epoch: 89
2023-01-05 02:43:43,101 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42830934723218284, 'Total loss': 0.42830934723218284} | train loss {'Reaction outcome loss': 0.16114268021617276, 'Total loss': 0.16114268021617276}
2023-01-05 02:43:43,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:43,102 INFO:     Epoch: 90
2023-01-05 02:43:45,308 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4411541481812795, 'Total loss': 0.4411541481812795} | train loss {'Reaction outcome loss': 0.16088301096499022, 'Total loss': 0.16088301096499022}
2023-01-05 02:43:45,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:45,308 INFO:     Epoch: 91
2023-01-05 02:43:47,522 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46895420650641123, 'Total loss': 0.46895420650641123} | train loss {'Reaction outcome loss': 0.1638594357828766, 'Total loss': 0.1638594357828766}
2023-01-05 02:43:47,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:47,522 INFO:     Epoch: 92
2023-01-05 02:43:49,716 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44276967843373616, 'Total loss': 0.44276967843373616} | train loss {'Reaction outcome loss': 0.16271297147592706, 'Total loss': 0.16271297147592706}
2023-01-05 02:43:49,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:49,717 INFO:     Epoch: 93
2023-01-05 02:43:51,914 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3956225310762723, 'Total loss': 0.3956225310762723} | train loss {'Reaction outcome loss': 0.1574550666523431, 'Total loss': 0.1574550666523431}
2023-01-05 02:43:51,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:51,915 INFO:     Epoch: 94
2023-01-05 02:43:54,139 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4130496010184288, 'Total loss': 0.4130496010184288} | train loss {'Reaction outcome loss': 0.15605168419135532, 'Total loss': 0.15605168419135532}
2023-01-05 02:43:54,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:54,139 INFO:     Epoch: 95
2023-01-05 02:43:56,350 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47388772169748944, 'Total loss': 0.47388772169748944} | train loss {'Reaction outcome loss': 0.15624602328659626, 'Total loss': 0.15624602328659626}
2023-01-05 02:43:56,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:56,350 INFO:     Epoch: 96
2023-01-05 02:43:58,563 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40403899972637497, 'Total loss': 0.40403899972637497} | train loss {'Reaction outcome loss': 0.16380628925768564, 'Total loss': 0.16380628925768564}
2023-01-05 02:43:58,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:43:58,563 INFO:     Epoch: 97
2023-01-05 02:44:00,785 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47362335920333865, 'Total loss': 0.47362335920333865} | train loss {'Reaction outcome loss': 0.15939530999957155, 'Total loss': 0.15939530999957155}
2023-01-05 02:44:00,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:00,785 INFO:     Epoch: 98
2023-01-05 02:44:02,994 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46898515671491625, 'Total loss': 0.46898515671491625} | train loss {'Reaction outcome loss': 0.1556685439032251, 'Total loss': 0.1556685439032251}
2023-01-05 02:44:02,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:02,995 INFO:     Epoch: 99
2023-01-05 02:44:05,225 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4678351471821467, 'Total loss': 0.4678351471821467} | train loss {'Reaction outcome loss': 0.16014111643813442, 'Total loss': 0.16014111643813442}
2023-01-05 02:44:05,225 INFO:     Best model found after epoch 35 of 100.
2023-01-05 02:44:05,225 INFO:   Done with stage: TRAINING
2023-01-05 02:44:05,225 INFO:   Starting stage: EVALUATION
2023-01-05 02:44:05,365 INFO:   Done with stage: EVALUATION
2023-01-05 02:44:05,374 INFO:   Leaving out SEQ value Fold_0
2023-01-05 02:44:05,386 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:44:05,386 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:44:06,018 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:44:06,018 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:44:06,086 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:44:06,086 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:44:06,086 INFO:     No hyperparam tuning for this model
2023-01-05 02:44:06,086 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:44:06,086 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:44:06,087 INFO:     None feature selector for col prot
2023-01-05 02:44:06,087 INFO:     None feature selector for col prot
2023-01-05 02:44:06,087 INFO:     None feature selector for col prot
2023-01-05 02:44:06,088 INFO:     None feature selector for col chem
2023-01-05 02:44:06,088 INFO:     None feature selector for col chem
2023-01-05 02:44:06,088 INFO:     None feature selector for col chem
2023-01-05 02:44:06,088 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:44:06,088 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:44:06,089 INFO:     Number of params in model 72931
2023-01-05 02:44:06,093 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:44:06,093 INFO:   Starting stage: TRAINING
2023-01-05 02:44:06,153 INFO:     Val loss before train {'Reaction outcome loss': 1.1164992133776346, 'Total loss': 1.1164992133776346}
2023-01-05 02:44:06,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:06,154 INFO:     Epoch: 0
2023-01-05 02:44:08,345 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7859544237454732, 'Total loss': 0.7859544237454732} | train loss {'Reaction outcome loss': 0.9120927462830161, 'Total loss': 0.9120927462830161}
2023-01-05 02:44:08,345 INFO:     Found new best model at epoch 0
2023-01-05 02:44:08,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:08,347 INFO:     Epoch: 1
2023-01-05 02:44:10,564 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6232056180636089, 'Total loss': 0.6232056180636089} | train loss {'Reaction outcome loss': 0.6126726649320908, 'Total loss': 0.6126726649320908}
2023-01-05 02:44:10,564 INFO:     Found new best model at epoch 1
2023-01-05 02:44:10,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:10,566 INFO:     Epoch: 2
2023-01-05 02:44:12,769 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.57878231604894, 'Total loss': 0.57878231604894} | train loss {'Reaction outcome loss': 0.5253516854378428, 'Total loss': 0.5253516854378428}
2023-01-05 02:44:12,770 INFO:     Found new best model at epoch 2
2023-01-05 02:44:12,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:12,772 INFO:     Epoch: 3
2023-01-05 02:44:14,970 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5511543035507203, 'Total loss': 0.5511543035507203} | train loss {'Reaction outcome loss': 0.48510145140390326, 'Total loss': 0.48510145140390326}
2023-01-05 02:44:14,970 INFO:     Found new best model at epoch 3
2023-01-05 02:44:14,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:14,971 INFO:     Epoch: 4
2023-01-05 02:44:17,142 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5461563726266225, 'Total loss': 0.5461563726266225} | train loss {'Reaction outcome loss': 0.46089231027086286, 'Total loss': 0.46089231027086286}
2023-01-05 02:44:17,143 INFO:     Found new best model at epoch 4
2023-01-05 02:44:17,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:17,144 INFO:     Epoch: 5
2023-01-05 02:44:19,301 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5426379640897115, 'Total loss': 0.5426379640897115} | train loss {'Reaction outcome loss': 0.43470530424022324, 'Total loss': 0.43470530424022324}
2023-01-05 02:44:19,301 INFO:     Found new best model at epoch 5
2023-01-05 02:44:19,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:19,303 INFO:     Epoch: 6
2023-01-05 02:44:21,446 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5318502366542817, 'Total loss': 0.5318502366542817} | train loss {'Reaction outcome loss': 0.4145341278427709, 'Total loss': 0.4145341278427709}
2023-01-05 02:44:21,446 INFO:     Found new best model at epoch 6
2023-01-05 02:44:21,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:21,447 INFO:     Epoch: 7
2023-01-05 02:44:23,644 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.535906445980072, 'Total loss': 0.535906445980072} | train loss {'Reaction outcome loss': 0.40148265083340834, 'Total loss': 0.40148265083340834}
2023-01-05 02:44:23,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:23,645 INFO:     Epoch: 8
2023-01-05 02:44:25,861 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5828915516535441, 'Total loss': 0.5828915516535441} | train loss {'Reaction outcome loss': 0.3882414415805009, 'Total loss': 0.3882414415805009}
2023-01-05 02:44:25,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:25,861 INFO:     Epoch: 9
2023-01-05 02:44:28,080 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5352219939231873, 'Total loss': 0.5352219939231873} | train loss {'Reaction outcome loss': 0.3804063978910881, 'Total loss': 0.3804063978910881}
2023-01-05 02:44:28,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:28,080 INFO:     Epoch: 10
2023-01-05 02:44:30,269 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5314949373404185, 'Total loss': 0.5314949373404185} | train loss {'Reaction outcome loss': 0.36926960001570464, 'Total loss': 0.36926960001570464}
2023-01-05 02:44:30,269 INFO:     Found new best model at epoch 10
2023-01-05 02:44:30,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:30,270 INFO:     Epoch: 11
2023-01-05 02:44:32,483 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5521313707033794, 'Total loss': 0.5521313707033794} | train loss {'Reaction outcome loss': 0.3562988531469864, 'Total loss': 0.3562988531469864}
2023-01-05 02:44:32,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:32,484 INFO:     Epoch: 12
2023-01-05 02:44:34,709 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5291325057546298, 'Total loss': 0.5291325057546298} | train loss {'Reaction outcome loss': 0.3522850361237996, 'Total loss': 0.3522850361237996}
2023-01-05 02:44:34,709 INFO:     Found new best model at epoch 12
2023-01-05 02:44:34,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:34,710 INFO:     Epoch: 13
2023-01-05 02:44:36,926 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5173208753267924, 'Total loss': 0.5173208753267924} | train loss {'Reaction outcome loss': 0.3422459087395755, 'Total loss': 0.3422459087395755}
2023-01-05 02:44:36,926 INFO:     Found new best model at epoch 13
2023-01-05 02:44:36,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:36,928 INFO:     Epoch: 14
2023-01-05 02:44:39,142 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5273744483788808, 'Total loss': 0.5273744483788808} | train loss {'Reaction outcome loss': 0.333783049469501, 'Total loss': 0.333783049469501}
2023-01-05 02:44:39,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:39,142 INFO:     Epoch: 15
2023-01-05 02:44:41,380 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5042688777049382, 'Total loss': 0.5042688777049382} | train loss {'Reaction outcome loss': 0.323565334027266, 'Total loss': 0.323565334027266}
2023-01-05 02:44:41,380 INFO:     Found new best model at epoch 15
2023-01-05 02:44:41,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:41,382 INFO:     Epoch: 16
2023-01-05 02:44:43,602 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5418077309926351, 'Total loss': 0.5418077309926351} | train loss {'Reaction outcome loss': 0.316497717623728, 'Total loss': 0.316497717623728}
2023-01-05 02:44:43,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:43,602 INFO:     Epoch: 17
2023-01-05 02:44:45,832 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5130207757155101, 'Total loss': 0.5130207757155101} | train loss {'Reaction outcome loss': 0.31027878047286594, 'Total loss': 0.31027878047286594}
2023-01-05 02:44:45,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:45,832 INFO:     Epoch: 18
2023-01-05 02:44:48,057 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.561166650056839, 'Total loss': 0.561166650056839} | train loss {'Reaction outcome loss': 0.30246822822866215, 'Total loss': 0.30246822822866215}
2023-01-05 02:44:48,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:48,059 INFO:     Epoch: 19
2023-01-05 02:44:50,050 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5108675599098206, 'Total loss': 0.5108675599098206} | train loss {'Reaction outcome loss': 0.2992884126648198, 'Total loss': 0.2992884126648198}
2023-01-05 02:44:50,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:50,051 INFO:     Epoch: 20
2023-01-05 02:44:52,275 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5446890493233999, 'Total loss': 0.5446890493233999} | train loss {'Reaction outcome loss': 0.29498172514684445, 'Total loss': 0.29498172514684445}
2023-01-05 02:44:52,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:52,276 INFO:     Epoch: 21
2023-01-05 02:44:54,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5197487607598305, 'Total loss': 0.5197487607598305} | train loss {'Reaction outcome loss': 0.28854347919759743, 'Total loss': 0.28854347919759743}
2023-01-05 02:44:54,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:54,481 INFO:     Epoch: 22
2023-01-05 02:44:56,700 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5576717088619868, 'Total loss': 0.5576717088619868} | train loss {'Reaction outcome loss': 0.28785969777862086, 'Total loss': 0.28785969777862086}
2023-01-05 02:44:56,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:56,700 INFO:     Epoch: 23
2023-01-05 02:44:58,930 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5211920708417892, 'Total loss': 0.5211920708417892} | train loss {'Reaction outcome loss': 0.27375795660934743, 'Total loss': 0.27375795660934743}
2023-01-05 02:44:58,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:44:58,930 INFO:     Epoch: 24
2023-01-05 02:45:01,127 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5423617800076802, 'Total loss': 0.5423617800076802} | train loss {'Reaction outcome loss': 0.27265164620467347, 'Total loss': 0.27265164620467347}
2023-01-05 02:45:01,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:01,128 INFO:     Epoch: 25
2023-01-05 02:45:03,345 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5186467533310254, 'Total loss': 0.5186467533310254} | train loss {'Reaction outcome loss': 0.2693001255936866, 'Total loss': 0.2693001255936866}
2023-01-05 02:45:03,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:03,345 INFO:     Epoch: 26
2023-01-05 02:45:05,553 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5328079064687093, 'Total loss': 0.5328079064687093} | train loss {'Reaction outcome loss': 0.26594392359800584, 'Total loss': 0.26594392359800584}
2023-01-05 02:45:05,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:05,553 INFO:     Epoch: 27
2023-01-05 02:45:07,789 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5256293872992198, 'Total loss': 0.5256293872992198} | train loss {'Reaction outcome loss': 0.25825973091660626, 'Total loss': 0.25825973091660626}
2023-01-05 02:45:07,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:07,790 INFO:     Epoch: 28
2023-01-05 02:45:09,951 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5137708564599355, 'Total loss': 0.5137708564599355} | train loss {'Reaction outcome loss': 0.2532191975314143, 'Total loss': 0.2532191975314143}
2023-01-05 02:45:09,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:09,951 INFO:     Epoch: 29
2023-01-05 02:45:12,160 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5185912668704986, 'Total loss': 0.5185912668704986} | train loss {'Reaction outcome loss': 0.2510914570740322, 'Total loss': 0.2510914570740322}
2023-01-05 02:45:12,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:12,160 INFO:     Epoch: 30
2023-01-05 02:45:14,366 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5063681046168009, 'Total loss': 0.5063681046168009} | train loss {'Reaction outcome loss': 0.24772702964417037, 'Total loss': 0.24772702964417037}
2023-01-05 02:45:14,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:14,366 INFO:     Epoch: 31
2023-01-05 02:45:16,586 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5354520658651988, 'Total loss': 0.5354520658651988} | train loss {'Reaction outcome loss': 0.2404429968514473, 'Total loss': 0.2404429968514473}
2023-01-05 02:45:16,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:16,586 INFO:     Epoch: 32
2023-01-05 02:45:18,738 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5270147621631622, 'Total loss': 0.5270147621631622} | train loss {'Reaction outcome loss': 0.23778712076481676, 'Total loss': 0.23778712076481676}
2023-01-05 02:45:18,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:18,738 INFO:     Epoch: 33
2023-01-05 02:45:20,884 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5179134715348482, 'Total loss': 0.5179134715348482} | train loss {'Reaction outcome loss': 0.23476848276128082, 'Total loss': 0.23476848276128082}
2023-01-05 02:45:20,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:20,884 INFO:     Epoch: 34
2023-01-05 02:45:23,082 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5320949097474416, 'Total loss': 0.5320949097474416} | train loss {'Reaction outcome loss': 0.2362087907296789, 'Total loss': 0.2362087907296789}
2023-01-05 02:45:23,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:23,082 INFO:     Epoch: 35
2023-01-05 02:45:25,255 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5079752991596858, 'Total loss': 0.5079752991596858} | train loss {'Reaction outcome loss': 0.23161535341646114, 'Total loss': 0.23161535341646114}
2023-01-05 02:45:25,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:25,257 INFO:     Epoch: 36
2023-01-05 02:45:27,439 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5263843794663747, 'Total loss': 0.5263843794663747} | train loss {'Reaction outcome loss': 0.22500421132647644, 'Total loss': 0.22500421132647644}
2023-01-05 02:45:27,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:27,439 INFO:     Epoch: 37
2023-01-05 02:45:29,605 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.542435085773468, 'Total loss': 0.542435085773468} | train loss {'Reaction outcome loss': 0.22031151417670022, 'Total loss': 0.22031151417670022}
2023-01-05 02:45:29,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:29,605 INFO:     Epoch: 38
2023-01-05 02:45:31,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5278151571750641, 'Total loss': 0.5278151571750641} | train loss {'Reaction outcome loss': 0.21717711069016127, 'Total loss': 0.21717711069016127}
2023-01-05 02:45:31,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:31,807 INFO:     Epoch: 39
2023-01-05 02:45:34,040 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5718945105870564, 'Total loss': 0.5718945105870564} | train loss {'Reaction outcome loss': 0.21983744403904806, 'Total loss': 0.21983744403904806}
2023-01-05 02:45:34,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:34,041 INFO:     Epoch: 40
2023-01-05 02:45:36,205 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5540636027852694, 'Total loss': 0.5540636027852694} | train loss {'Reaction outcome loss': 0.21219649825272333, 'Total loss': 0.21219649825272333}
2023-01-05 02:45:36,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:36,205 INFO:     Epoch: 41
2023-01-05 02:45:38,430 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5244855801264445, 'Total loss': 0.5244855801264445} | train loss {'Reaction outcome loss': 0.21154680293746783, 'Total loss': 0.21154680293746783}
2023-01-05 02:45:38,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:38,430 INFO:     Epoch: 42
2023-01-05 02:45:40,613 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5608981649080912, 'Total loss': 0.5608981649080912} | train loss {'Reaction outcome loss': 0.2064720869648957, 'Total loss': 0.2064720869648957}
2023-01-05 02:45:40,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:40,613 INFO:     Epoch: 43
2023-01-05 02:45:42,771 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5973992546399435, 'Total loss': 0.5973992546399435} | train loss {'Reaction outcome loss': 0.20840136489973668, 'Total loss': 0.20840136489973668}
2023-01-05 02:45:42,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:42,772 INFO:     Epoch: 44
2023-01-05 02:45:44,963 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5602149407068888, 'Total loss': 0.5602149407068888} | train loss {'Reaction outcome loss': 0.20612657686056446, 'Total loss': 0.20612657686056446}
2023-01-05 02:45:44,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:44,964 INFO:     Epoch: 45
2023-01-05 02:45:47,107 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5611546238263448, 'Total loss': 0.5611546238263448} | train loss {'Reaction outcome loss': 0.19977866601960284, 'Total loss': 0.19977866601960284}
2023-01-05 02:45:47,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:47,108 INFO:     Epoch: 46
2023-01-05 02:45:49,304 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5116254786650339, 'Total loss': 0.5116254786650339} | train loss {'Reaction outcome loss': 0.19683653744019186, 'Total loss': 0.19683653744019186}
2023-01-05 02:45:49,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:49,304 INFO:     Epoch: 47
2023-01-05 02:45:51,501 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5613720864057541, 'Total loss': 0.5613720864057541} | train loss {'Reaction outcome loss': 0.2012758047224777, 'Total loss': 0.2012758047224777}
2023-01-05 02:45:51,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:51,501 INFO:     Epoch: 48
2023-01-05 02:45:53,738 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5540598869323731, 'Total loss': 0.5540598869323731} | train loss {'Reaction outcome loss': 0.1992867695623125, 'Total loss': 0.1992867695623125}
2023-01-05 02:45:53,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:53,738 INFO:     Epoch: 49
2023-01-05 02:45:55,968 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5657132824261983, 'Total loss': 0.5657132824261983} | train loss {'Reaction outcome loss': 0.19274502019839782, 'Total loss': 0.19274502019839782}
2023-01-05 02:45:55,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:55,969 INFO:     Epoch: 50
2023-01-05 02:45:58,195 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5449929515520732, 'Total loss': 0.5449929515520732} | train loss {'Reaction outcome loss': 0.19663089111678467, 'Total loss': 0.19663089111678467}
2023-01-05 02:45:58,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:45:58,195 INFO:     Epoch: 51
2023-01-05 02:46:00,397 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5550667226314545, 'Total loss': 0.5550667226314545} | train loss {'Reaction outcome loss': 0.1909632528112372, 'Total loss': 0.1909632528112372}
2023-01-05 02:46:00,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:00,397 INFO:     Epoch: 52
2023-01-05 02:46:02,615 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5387179851531982, 'Total loss': 0.5387179851531982} | train loss {'Reaction outcome loss': 0.19080875974393238, 'Total loss': 0.19080875974393238}
2023-01-05 02:46:02,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:02,616 INFO:     Epoch: 53
2023-01-05 02:46:04,830 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.564474955201149, 'Total loss': 0.564474955201149} | train loss {'Reaction outcome loss': 0.18867068558618644, 'Total loss': 0.18867068558618644}
2023-01-05 02:46:04,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:04,830 INFO:     Epoch: 54
2023-01-05 02:46:07,059 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.543043689057231, 'Total loss': 0.543043689057231} | train loss {'Reaction outcome loss': 0.1826299696270186, 'Total loss': 0.1826299696270186}
2023-01-05 02:46:07,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:07,060 INFO:     Epoch: 55
2023-01-05 02:46:09,279 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5712809026241302, 'Total loss': 0.5712809026241302} | train loss {'Reaction outcome loss': 0.18495044484394638, 'Total loss': 0.18495044484394638}
2023-01-05 02:46:09,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:09,279 INFO:     Epoch: 56
2023-01-05 02:46:11,486 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5903208017349243, 'Total loss': 0.5903208017349243} | train loss {'Reaction outcome loss': 0.18326043381430482, 'Total loss': 0.18326043381430482}
2023-01-05 02:46:11,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:11,486 INFO:     Epoch: 57
2023-01-05 02:46:13,702 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5633521497249603, 'Total loss': 0.5633521497249603} | train loss {'Reaction outcome loss': 0.1844247322849059, 'Total loss': 0.1844247322849059}
2023-01-05 02:46:13,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:13,702 INFO:     Epoch: 58
2023-01-05 02:46:15,859 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5718711237112681, 'Total loss': 0.5718711237112681} | train loss {'Reaction outcome loss': 0.18560686668408286, 'Total loss': 0.18560686668408286}
2023-01-05 02:46:15,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:15,860 INFO:     Epoch: 59
2023-01-05 02:46:18,024 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5485182543595631, 'Total loss': 0.5485182543595631} | train loss {'Reaction outcome loss': 0.1826756790579453, 'Total loss': 0.1826756790579453}
2023-01-05 02:46:18,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:18,024 INFO:     Epoch: 60
2023-01-05 02:46:20,236 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5571811974048615, 'Total loss': 0.5571811974048615} | train loss {'Reaction outcome loss': 0.18154424707656794, 'Total loss': 0.18154424707656794}
2023-01-05 02:46:20,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:20,236 INFO:     Epoch: 61
2023-01-05 02:46:22,467 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.6109585652748744, 'Total loss': 0.6109585652748744} | train loss {'Reaction outcome loss': 0.1798008477458064, 'Total loss': 0.1798008477458064}
2023-01-05 02:46:22,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:22,467 INFO:     Epoch: 62
2023-01-05 02:46:24,660 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5783070504665375, 'Total loss': 0.5783070504665375} | train loss {'Reaction outcome loss': 0.17740166938462615, 'Total loss': 0.17740166938462615}
2023-01-05 02:46:24,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:24,660 INFO:     Epoch: 63
2023-01-05 02:46:26,834 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5592225164175033, 'Total loss': 0.5592225164175033} | train loss {'Reaction outcome loss': 0.17928337141953027, 'Total loss': 0.17928337141953027}
2023-01-05 02:46:26,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:26,835 INFO:     Epoch: 64
2023-01-05 02:46:29,038 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.601932022968928, 'Total loss': 0.601932022968928} | train loss {'Reaction outcome loss': 0.17502979103333052, 'Total loss': 0.17502979103333052}
2023-01-05 02:46:29,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:29,039 INFO:     Epoch: 65
2023-01-05 02:46:31,241 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.6036646962165833, 'Total loss': 0.6036646962165833} | train loss {'Reaction outcome loss': 0.17442668305818726, 'Total loss': 0.17442668305818726}
2023-01-05 02:46:31,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:31,242 INFO:     Epoch: 66
2023-01-05 02:46:33,459 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5638241032759349, 'Total loss': 0.5638241032759349} | train loss {'Reaction outcome loss': 0.17411567093838468, 'Total loss': 0.17411567093838468}
2023-01-05 02:46:33,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:33,459 INFO:     Epoch: 67
2023-01-05 02:46:35,658 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.573058162132899, 'Total loss': 0.573058162132899} | train loss {'Reaction outcome loss': 0.17274140839866042, 'Total loss': 0.17274140839866042}
2023-01-05 02:46:35,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:35,658 INFO:     Epoch: 68
2023-01-05 02:46:37,846 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5779338518778483, 'Total loss': 0.5779338518778483} | train loss {'Reaction outcome loss': 0.17070338330877416, 'Total loss': 0.17070338330877416}
2023-01-05 02:46:37,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:37,847 INFO:     Epoch: 69
2023-01-05 02:46:40,019 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6254651387532552, 'Total loss': 0.6254651387532552} | train loss {'Reaction outcome loss': 0.17102712501914505, 'Total loss': 0.17102712501914505}
2023-01-05 02:46:40,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:40,019 INFO:     Epoch: 70
2023-01-05 02:46:42,248 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6045936976869901, 'Total loss': 0.6045936976869901} | train loss {'Reaction outcome loss': 0.17457642084850936, 'Total loss': 0.17457642084850936}
2023-01-05 02:46:42,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:42,248 INFO:     Epoch: 71
2023-01-05 02:46:44,447 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5766976137955984, 'Total loss': 0.5766976137955984} | train loss {'Reaction outcome loss': 0.17034380220855674, 'Total loss': 0.17034380220855674}
2023-01-05 02:46:44,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:44,447 INFO:     Epoch: 72
2023-01-05 02:46:46,624 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5826230049133301, 'Total loss': 0.5826230049133301} | train loss {'Reaction outcome loss': 0.1663499783051547, 'Total loss': 0.1663499783051547}
2023-01-05 02:46:46,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:46,624 INFO:     Epoch: 73
2023-01-05 02:46:48,818 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5862205743789672, 'Total loss': 0.5862205743789672} | train loss {'Reaction outcome loss': 0.16608515972047228, 'Total loss': 0.16608515972047228}
2023-01-05 02:46:48,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:48,819 INFO:     Epoch: 74
2023-01-05 02:46:50,986 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5702616227169831, 'Total loss': 0.5702616227169831} | train loss {'Reaction outcome loss': 0.1714334423504226, 'Total loss': 0.1714334423504226}
2023-01-05 02:46:50,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:50,987 INFO:     Epoch: 75
2023-01-05 02:46:53,170 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5564898480971654, 'Total loss': 0.5564898480971654} | train loss {'Reaction outcome loss': 0.16719564691909936, 'Total loss': 0.16719564691909936}
2023-01-05 02:46:53,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:53,170 INFO:     Epoch: 76
2023-01-05 02:46:55,358 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5731654942035675, 'Total loss': 0.5731654942035675} | train loss {'Reaction outcome loss': 0.17028160187259425, 'Total loss': 0.17028160187259425}
2023-01-05 02:46:55,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:55,359 INFO:     Epoch: 77
2023-01-05 02:46:57,532 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.586008882522583, 'Total loss': 0.586008882522583} | train loss {'Reaction outcome loss': 0.16962324858160457, 'Total loss': 0.16962324858160457}
2023-01-05 02:46:57,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:57,532 INFO:     Epoch: 78
2023-01-05 02:46:59,739 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5950994461774826, 'Total loss': 0.5950994461774826} | train loss {'Reaction outcome loss': 0.16812351790943394, 'Total loss': 0.16812351790943394}
2023-01-05 02:46:59,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:46:59,740 INFO:     Epoch: 79
2023-01-05 02:47:01,984 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5732904593149821, 'Total loss': 0.5732904593149821} | train loss {'Reaction outcome loss': 0.16997711135441587, 'Total loss': 0.16997711135441587}
2023-01-05 02:47:01,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:01,984 INFO:     Epoch: 80
2023-01-05 02:47:04,241 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5770286758740742, 'Total loss': 0.5770286758740742} | train loss {'Reaction outcome loss': 0.16516386780439177, 'Total loss': 0.16516386780439177}
2023-01-05 02:47:04,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:04,241 INFO:     Epoch: 81
2023-01-05 02:47:06,499 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5706960062185923, 'Total loss': 0.5706960062185923} | train loss {'Reaction outcome loss': 0.16116836383925193, 'Total loss': 0.16116836383925193}
2023-01-05 02:47:06,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:06,501 INFO:     Epoch: 82
2023-01-05 02:47:08,740 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5693154493967693, 'Total loss': 0.5693154493967693} | train loss {'Reaction outcome loss': 0.16136537978415424, 'Total loss': 0.16136537978415424}
2023-01-05 02:47:08,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:08,740 INFO:     Epoch: 83
2023-01-05 02:47:10,958 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5887200673421223, 'Total loss': 0.5887200673421223} | train loss {'Reaction outcome loss': 0.16151005108534855, 'Total loss': 0.16151005108534855}
2023-01-05 02:47:10,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:10,958 INFO:     Epoch: 84
2023-01-05 02:47:13,197 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5654725770155589, 'Total loss': 0.5654725770155589} | train loss {'Reaction outcome loss': 0.1633236469024534, 'Total loss': 0.1633236469024534}
2023-01-05 02:47:13,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:13,198 INFO:     Epoch: 85
2023-01-05 02:47:15,439 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.617555969953537, 'Total loss': 0.617555969953537} | train loss {'Reaction outcome loss': 0.16385643971560482, 'Total loss': 0.16385643971560482}
2023-01-05 02:47:15,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:15,440 INFO:     Epoch: 86
2023-01-05 02:47:17,606 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5859580223138133, 'Total loss': 0.5859580223138133} | train loss {'Reaction outcome loss': 0.16152955232150717, 'Total loss': 0.16152955232150717}
2023-01-05 02:47:17,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:17,607 INFO:     Epoch: 87
2023-01-05 02:47:19,866 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5727551122506459, 'Total loss': 0.5727551122506459} | train loss {'Reaction outcome loss': 0.16177649366971866, 'Total loss': 0.16177649366971866}
2023-01-05 02:47:19,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:19,866 INFO:     Epoch: 88
2023-01-05 02:47:22,083 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5581027746200562, 'Total loss': 0.5581027746200562} | train loss {'Reaction outcome loss': 0.15933128166943789, 'Total loss': 0.15933128166943789}
2023-01-05 02:47:22,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:22,083 INFO:     Epoch: 89
2023-01-05 02:47:24,310 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5565280536810557, 'Total loss': 0.5565280536810557} | train loss {'Reaction outcome loss': 0.15657271874769435, 'Total loss': 0.15657271874769435}
2023-01-05 02:47:24,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:24,311 INFO:     Epoch: 90
2023-01-05 02:47:26,573 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6084220548470815, 'Total loss': 0.6084220548470815} | train loss {'Reaction outcome loss': 0.16097938732318853, 'Total loss': 0.16097938732318853}
2023-01-05 02:47:26,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:26,574 INFO:     Epoch: 91
2023-01-05 02:47:28,800 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.583788933356603, 'Total loss': 0.583788933356603} | train loss {'Reaction outcome loss': 0.15765846749584117, 'Total loss': 0.15765846749584117}
2023-01-05 02:47:28,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:28,800 INFO:     Epoch: 92
2023-01-05 02:47:31,022 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6009246230125427, 'Total loss': 0.6009246230125427} | train loss {'Reaction outcome loss': 0.1575745409940893, 'Total loss': 0.1575745409940893}
2023-01-05 02:47:31,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:31,022 INFO:     Epoch: 93
2023-01-05 02:47:33,266 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5843081593513488, 'Total loss': 0.5843081593513488} | train loss {'Reaction outcome loss': 0.15463334676914978, 'Total loss': 0.15463334676914978}
2023-01-05 02:47:33,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:33,267 INFO:     Epoch: 94
2023-01-05 02:47:35,458 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6219882766405741, 'Total loss': 0.6219882766405741} | train loss {'Reaction outcome loss': 0.15883406867905364, 'Total loss': 0.15883406867905364}
2023-01-05 02:47:35,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:35,458 INFO:     Epoch: 95
2023-01-05 02:47:37,679 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6135113656520843, 'Total loss': 0.6135113656520843} | train loss {'Reaction outcome loss': 0.15447389601940548, 'Total loss': 0.15447389601940548}
2023-01-05 02:47:37,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:37,679 INFO:     Epoch: 96
2023-01-05 02:47:39,894 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6000072379906972, 'Total loss': 0.6000072379906972} | train loss {'Reaction outcome loss': 0.153752462377595, 'Total loss': 0.153752462377595}
2023-01-05 02:47:39,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:39,895 INFO:     Epoch: 97
2023-01-05 02:47:42,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5990653256575267, 'Total loss': 0.5990653256575267} | train loss {'Reaction outcome loss': 0.15528986068870737, 'Total loss': 0.15528986068870737}
2023-01-05 02:47:42,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:42,088 INFO:     Epoch: 98
2023-01-05 02:47:44,311 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5912785003582637, 'Total loss': 0.5912785003582637} | train loss {'Reaction outcome loss': 0.1537546862586381, 'Total loss': 0.1537546862586381}
2023-01-05 02:47:44,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:44,311 INFO:     Epoch: 99
2023-01-05 02:47:46,552 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5686020026604335, 'Total loss': 0.5686020026604335} | train loss {'Reaction outcome loss': 0.15048839603414774, 'Total loss': 0.15048839603414774}
2023-01-05 02:47:46,553 INFO:     Best model found after epoch 16 of 100.
2023-01-05 02:47:46,553 INFO:   Done with stage: TRAINING
2023-01-05 02:47:46,553 INFO:   Starting stage: EVALUATION
2023-01-05 02:47:46,693 INFO:   Done with stage: EVALUATION
2023-01-05 02:47:46,693 INFO:   Leaving out SEQ value Fold_1
2023-01-05 02:47:46,706 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 02:47:46,706 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:47:47,350 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:47:47,350 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:47:47,437 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:47:47,437 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:47:47,437 INFO:     No hyperparam tuning for this model
2023-01-05 02:47:47,437 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:47:47,437 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:47:47,438 INFO:     None feature selector for col prot
2023-01-05 02:47:47,438 INFO:     None feature selector for col prot
2023-01-05 02:47:47,438 INFO:     None feature selector for col prot
2023-01-05 02:47:47,439 INFO:     None feature selector for col chem
2023-01-05 02:47:47,439 INFO:     None feature selector for col chem
2023-01-05 02:47:47,439 INFO:     None feature selector for col chem
2023-01-05 02:47:47,439 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:47:47,439 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:47:47,442 INFO:     Number of params in model 72931
2023-01-05 02:47:47,447 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:47:47,447 INFO:   Starting stage: TRAINING
2023-01-05 02:47:47,512 INFO:     Val loss before train {'Reaction outcome loss': 1.0605833252271017, 'Total loss': 1.0605833252271017}
2023-01-05 02:47:47,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:47,512 INFO:     Epoch: 0
2023-01-05 02:47:49,772 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7575857778390248, 'Total loss': 0.7575857778390248} | train loss {'Reaction outcome loss': 0.9347141570904278, 'Total loss': 0.9347141570904278}
2023-01-05 02:47:49,773 INFO:     Found new best model at epoch 0
2023-01-05 02:47:49,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:49,774 INFO:     Epoch: 1
2023-01-05 02:47:52,024 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5328209340572357, 'Total loss': 0.5328209340572357} | train loss {'Reaction outcome loss': 0.6273060342848665, 'Total loss': 0.6273060342848665}
2023-01-05 02:47:52,024 INFO:     Found new best model at epoch 1
2023-01-05 02:47:52,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:52,026 INFO:     Epoch: 2
2023-01-05 02:47:54,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48255166014035544, 'Total loss': 0.48255166014035544} | train loss {'Reaction outcome loss': 0.5467353893200988, 'Total loss': 0.5467353893200988}
2023-01-05 02:47:54,298 INFO:     Found new best model at epoch 2
2023-01-05 02:47:54,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:54,299 INFO:     Epoch: 3
2023-01-05 02:47:56,582 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4840423127015432, 'Total loss': 0.4840423127015432} | train loss {'Reaction outcome loss': 0.48669731001491134, 'Total loss': 0.48669731001491134}
2023-01-05 02:47:56,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:56,582 INFO:     Epoch: 4
2023-01-05 02:47:58,822 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4611801673968633, 'Total loss': 0.4611801673968633} | train loss {'Reaction outcome loss': 0.4597322545621706, 'Total loss': 0.4597322545621706}
2023-01-05 02:47:58,822 INFO:     Found new best model at epoch 4
2023-01-05 02:47:58,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:47:58,824 INFO:     Epoch: 5
2023-01-05 02:48:00,979 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45743123094240823, 'Total loss': 0.45743123094240823} | train loss {'Reaction outcome loss': 0.43561337024405383, 'Total loss': 0.43561337024405383}
2023-01-05 02:48:00,980 INFO:     Found new best model at epoch 5
2023-01-05 02:48:00,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:00,981 INFO:     Epoch: 6
2023-01-05 02:48:03,202 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4301910936832428, 'Total loss': 0.4301910936832428} | train loss {'Reaction outcome loss': 0.4164801670691383, 'Total loss': 0.4164801670691383}
2023-01-05 02:48:03,202 INFO:     Found new best model at epoch 6
2023-01-05 02:48:03,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:03,204 INFO:     Epoch: 7
2023-01-05 02:48:05,394 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43544664680957795, 'Total loss': 0.43544664680957795} | train loss {'Reaction outcome loss': 0.40262057374406984, 'Total loss': 0.40262057374406984}
2023-01-05 02:48:05,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:05,394 INFO:     Epoch: 8
2023-01-05 02:48:07,595 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43276029229164126, 'Total loss': 0.43276029229164126} | train loss {'Reaction outcome loss': 0.39135159341537434, 'Total loss': 0.39135159341537434}
2023-01-05 02:48:07,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:07,595 INFO:     Epoch: 9
2023-01-05 02:48:09,778 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41592028240362805, 'Total loss': 0.41592028240362805} | train loss {'Reaction outcome loss': 0.37822136305866466, 'Total loss': 0.37822136305866466}
2023-01-05 02:48:09,778 INFO:     Found new best model at epoch 9
2023-01-05 02:48:09,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:09,780 INFO:     Epoch: 10
2023-01-05 02:48:12,007 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4055193265279134, 'Total loss': 0.4055193265279134} | train loss {'Reaction outcome loss': 0.3765239771725475, 'Total loss': 0.3765239771725475}
2023-01-05 02:48:12,007 INFO:     Found new best model at epoch 10
2023-01-05 02:48:12,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:12,008 INFO:     Epoch: 11
2023-01-05 02:48:14,259 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4050470143556595, 'Total loss': 0.4050470143556595} | train loss {'Reaction outcome loss': 0.3590603678392759, 'Total loss': 0.3590603678392759}
2023-01-05 02:48:14,259 INFO:     Found new best model at epoch 11
2023-01-05 02:48:14,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:14,260 INFO:     Epoch: 12
2023-01-05 02:48:16,505 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4122549543778102, 'Total loss': 0.4122549543778102} | train loss {'Reaction outcome loss': 0.3427601856478364, 'Total loss': 0.3427601856478364}
2023-01-05 02:48:16,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:16,505 INFO:     Epoch: 13
2023-01-05 02:48:18,741 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4074102073907852, 'Total loss': 0.4074102073907852} | train loss {'Reaction outcome loss': 0.33455502722442715, 'Total loss': 0.33455502722442715}
2023-01-05 02:48:18,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:18,742 INFO:     Epoch: 14
2023-01-05 02:48:20,975 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4157716671625773, 'Total loss': 0.4157716671625773} | train loss {'Reaction outcome loss': 0.32808043022869504, 'Total loss': 0.32808043022869504}
2023-01-05 02:48:20,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:20,975 INFO:     Epoch: 15
2023-01-05 02:48:23,203 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4136474241813024, 'Total loss': 0.4136474241813024} | train loss {'Reaction outcome loss': 0.32151752742736234, 'Total loss': 0.32151752742736234}
2023-01-05 02:48:23,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:23,203 INFO:     Epoch: 16
2023-01-05 02:48:25,440 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43141152411699296, 'Total loss': 0.43141152411699296} | train loss {'Reaction outcome loss': 0.32163952745369, 'Total loss': 0.32163952745369}
2023-01-05 02:48:25,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:25,441 INFO:     Epoch: 17
2023-01-05 02:48:27,689 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4187332381804784, 'Total loss': 0.4187332381804784} | train loss {'Reaction outcome loss': 0.31100537871563994, 'Total loss': 0.31100537871563994}
2023-01-05 02:48:27,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:27,690 INFO:     Epoch: 18
2023-01-05 02:48:29,918 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4171612044175466, 'Total loss': 0.4171612044175466} | train loss {'Reaction outcome loss': 0.30647620286006294, 'Total loss': 0.30647620286006294}
2023-01-05 02:48:29,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:29,918 INFO:     Epoch: 19
2023-01-05 02:48:32,130 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40931704541047415, 'Total loss': 0.40931704541047415} | train loss {'Reaction outcome loss': 0.29789854043190356, 'Total loss': 0.29789854043190356}
2023-01-05 02:48:32,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:32,130 INFO:     Epoch: 20
2023-01-05 02:48:34,364 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4133171955744425, 'Total loss': 0.4133171955744425} | train loss {'Reaction outcome loss': 0.29331132795596204, 'Total loss': 0.29331132795596204}
2023-01-05 02:48:34,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:34,364 INFO:     Epoch: 21
2023-01-05 02:48:36,606 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4291678706804911, 'Total loss': 0.4291678706804911} | train loss {'Reaction outcome loss': 0.285905198679994, 'Total loss': 0.285905198679994}
2023-01-05 02:48:36,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:36,606 INFO:     Epoch: 22
2023-01-05 02:48:38,850 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40445475429296496, 'Total loss': 0.40445475429296496} | train loss {'Reaction outcome loss': 0.2906120176998809, 'Total loss': 0.2906120176998809}
2023-01-05 02:48:38,851 INFO:     Found new best model at epoch 22
2023-01-05 02:48:38,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:38,853 INFO:     Epoch: 23
2023-01-05 02:48:41,077 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42731225887934365, 'Total loss': 0.42731225887934365} | train loss {'Reaction outcome loss': 0.2741508507034809, 'Total loss': 0.2741508507034809}
2023-01-05 02:48:41,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:41,077 INFO:     Epoch: 24
2023-01-05 02:48:43,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4206154445807139, 'Total loss': 0.4206154445807139} | train loss {'Reaction outcome loss': 0.27162990217471233, 'Total loss': 0.27162990217471233}
2023-01-05 02:48:43,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:43,333 INFO:     Epoch: 25
2023-01-05 02:48:45,568 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4170926729838053, 'Total loss': 0.4170926729838053} | train loss {'Reaction outcome loss': 0.26845275955038495, 'Total loss': 0.26845275955038495}
2023-01-05 02:48:45,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:45,569 INFO:     Epoch: 26
2023-01-05 02:48:47,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4509523103634516, 'Total loss': 0.4509523103634516} | train loss {'Reaction outcome loss': 0.26101346537167125, 'Total loss': 0.26101346537167125}
2023-01-05 02:48:47,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:47,798 INFO:     Epoch: 27
2023-01-05 02:48:50,012 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4469454417626063, 'Total loss': 0.4469454417626063} | train loss {'Reaction outcome loss': 0.2609750247236503, 'Total loss': 0.2609750247236503}
2023-01-05 02:48:50,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:50,012 INFO:     Epoch: 28
2023-01-05 02:48:52,224 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42114168802897134, 'Total loss': 0.42114168802897134} | train loss {'Reaction outcome loss': 0.2574499388076905, 'Total loss': 0.2574499388076905}
2023-01-05 02:48:52,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:52,224 INFO:     Epoch: 29
2023-01-05 02:48:54,483 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4262012590964635, 'Total loss': 0.4262012590964635} | train loss {'Reaction outcome loss': 0.268258647758531, 'Total loss': 0.268258647758531}
2023-01-05 02:48:54,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:54,485 INFO:     Epoch: 30
2023-01-05 02:48:56,542 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4308503637711207, 'Total loss': 0.4308503637711207} | train loss {'Reaction outcome loss': 0.2603575977010895, 'Total loss': 0.2603575977010895}
2023-01-05 02:48:56,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:56,542 INFO:     Epoch: 31
2023-01-05 02:48:58,665 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42408441652854284, 'Total loss': 0.42408441652854284} | train loss {'Reaction outcome loss': 0.25505265266216104, 'Total loss': 0.25505265266216104}
2023-01-05 02:48:58,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:48:58,665 INFO:     Epoch: 32
2023-01-05 02:49:00,889 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4337311794360479, 'Total loss': 0.4337311794360479} | train loss {'Reaction outcome loss': 0.2479738118008886, 'Total loss': 0.2479738118008886}
2023-01-05 02:49:00,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:00,890 INFO:     Epoch: 33
2023-01-05 02:49:03,121 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42831544280052186, 'Total loss': 0.42831544280052186} | train loss {'Reaction outcome loss': 0.24634298665757565, 'Total loss': 0.24634298665757565}
2023-01-05 02:49:03,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:03,121 INFO:     Epoch: 34
2023-01-05 02:49:05,298 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42837484379609425, 'Total loss': 0.42837484379609425} | train loss {'Reaction outcome loss': 0.24263344259604747, 'Total loss': 0.24263344259604747}
2023-01-05 02:49:05,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:05,299 INFO:     Epoch: 35
2023-01-05 02:49:07,475 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4253237466017405, 'Total loss': 0.4253237466017405} | train loss {'Reaction outcome loss': 0.24144196584550798, 'Total loss': 0.24144196584550798}
2023-01-05 02:49:07,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:07,475 INFO:     Epoch: 36
2023-01-05 02:49:09,678 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4299694831172625, 'Total loss': 0.4299694831172625} | train loss {'Reaction outcome loss': 0.25616977214340825, 'Total loss': 0.25616977214340825}
2023-01-05 02:49:09,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:09,678 INFO:     Epoch: 37
2023-01-05 02:49:11,889 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47072484691937766, 'Total loss': 0.47072484691937766} | train loss {'Reaction outcome loss': 0.23901987487308518, 'Total loss': 0.23901987487308518}
2023-01-05 02:49:11,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:11,890 INFO:     Epoch: 38
2023-01-05 02:49:14,115 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42268216212590537, 'Total loss': 0.42268216212590537} | train loss {'Reaction outcome loss': 0.2294091981349756, 'Total loss': 0.2294091981349756}
2023-01-05 02:49:14,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:14,116 INFO:     Epoch: 39
2023-01-05 02:49:16,346 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4294168367981911, 'Total loss': 0.4294168367981911} | train loss {'Reaction outcome loss': 0.23479910141218896, 'Total loss': 0.23479910141218896}
2023-01-05 02:49:16,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:16,346 INFO:     Epoch: 40
2023-01-05 02:49:18,599 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4375380610426267, 'Total loss': 0.4375380610426267} | train loss {'Reaction outcome loss': 0.23055260929791932, 'Total loss': 0.23055260929791932}
2023-01-05 02:49:18,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:18,599 INFO:     Epoch: 41
2023-01-05 02:49:20,810 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43872322837511696, 'Total loss': 0.43872322837511696} | train loss {'Reaction outcome loss': 0.22904438087784185, 'Total loss': 0.22904438087784185}
2023-01-05 02:49:20,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:20,810 INFO:     Epoch: 42
2023-01-05 02:49:23,065 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4273545036713282, 'Total loss': 0.4273545036713282} | train loss {'Reaction outcome loss': 0.2253950571074434, 'Total loss': 0.2253950571074434}
2023-01-05 02:49:23,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:23,065 INFO:     Epoch: 43
2023-01-05 02:49:25,285 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44532562990983326, 'Total loss': 0.44532562990983326} | train loss {'Reaction outcome loss': 0.25268964968837687, 'Total loss': 0.25268964968837687}
2023-01-05 02:49:25,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:25,285 INFO:     Epoch: 44
2023-01-05 02:49:27,501 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4431488464275996, 'Total loss': 0.4431488464275996} | train loss {'Reaction outcome loss': 0.24540259871982795, 'Total loss': 0.24540259871982795}
2023-01-05 02:49:27,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:27,501 INFO:     Epoch: 45
2023-01-05 02:49:29,691 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43953211506207784, 'Total loss': 0.43953211506207784} | train loss {'Reaction outcome loss': 0.23098162195474023, 'Total loss': 0.23098162195474023}
2023-01-05 02:49:29,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:29,693 INFO:     Epoch: 46
2023-01-05 02:49:31,876 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4600713223218918, 'Total loss': 0.4600713223218918} | train loss {'Reaction outcome loss': 0.2228851449225777, 'Total loss': 0.2228851449225777}
2023-01-05 02:49:31,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:31,876 INFO:     Epoch: 47
2023-01-05 02:49:34,113 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44489015539487203, 'Total loss': 0.44489015539487203} | train loss {'Reaction outcome loss': 0.2196758541673341, 'Total loss': 0.2196758541673341}
2023-01-05 02:49:34,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:34,113 INFO:     Epoch: 48
2023-01-05 02:49:36,363 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4535629908243815, 'Total loss': 0.4535629908243815} | train loss {'Reaction outcome loss': 0.21154384771564408, 'Total loss': 0.21154384771564408}
2023-01-05 02:49:36,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:36,364 INFO:     Epoch: 49
2023-01-05 02:49:38,575 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4707428018252055, 'Total loss': 0.4707428018252055} | train loss {'Reaction outcome loss': 0.22157475198754042, 'Total loss': 0.22157475198754042}
2023-01-05 02:49:38,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:38,575 INFO:     Epoch: 50
2023-01-05 02:49:40,768 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4446973790725072, 'Total loss': 0.4446973790725072} | train loss {'Reaction outcome loss': 0.2182677960684658, 'Total loss': 0.2182677960684658}
2023-01-05 02:49:40,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:40,769 INFO:     Epoch: 51
2023-01-05 02:49:43,005 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4293968771894773, 'Total loss': 0.4293968771894773} | train loss {'Reaction outcome loss': 0.236871097702533, 'Total loss': 0.236871097702533}
2023-01-05 02:49:43,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:43,006 INFO:     Epoch: 52
2023-01-05 02:49:45,187 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.450134731332461, 'Total loss': 0.450134731332461} | train loss {'Reaction outcome loss': 0.21561749191040808, 'Total loss': 0.21561749191040808}
2023-01-05 02:49:45,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:45,187 INFO:     Epoch: 53
2023-01-05 02:49:47,446 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45894657373428344, 'Total loss': 0.45894657373428344} | train loss {'Reaction outcome loss': 0.2093907319670678, 'Total loss': 0.2093907319670678}
2023-01-05 02:49:47,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:47,446 INFO:     Epoch: 54
2023-01-05 02:49:49,641 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45315657258033754, 'Total loss': 0.45315657258033754} | train loss {'Reaction outcome loss': 0.20984471724132428, 'Total loss': 0.20984471724132428}
2023-01-05 02:49:49,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:49,642 INFO:     Epoch: 55
2023-01-05 02:49:51,893 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4699226980408033, 'Total loss': 0.4699226980408033} | train loss {'Reaction outcome loss': 0.20473448248019954, 'Total loss': 0.20473448248019954}
2023-01-05 02:49:51,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:51,893 INFO:     Epoch: 56
2023-01-05 02:49:54,054 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4394398719072342, 'Total loss': 0.4394398719072342} | train loss {'Reaction outcome loss': 0.20955824557492725, 'Total loss': 0.20955824557492725}
2023-01-05 02:49:54,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:54,054 INFO:     Epoch: 57
2023-01-05 02:49:56,212 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43729890485604606, 'Total loss': 0.43729890485604606} | train loss {'Reaction outcome loss': 0.20670765504726898, 'Total loss': 0.20670765504726898}
2023-01-05 02:49:56,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:56,212 INFO:     Epoch: 58
2023-01-05 02:49:58,424 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4587142417828242, 'Total loss': 0.4587142417828242} | train loss {'Reaction outcome loss': 0.20810535548978648, 'Total loss': 0.20810535548978648}
2023-01-05 02:49:58,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:49:58,424 INFO:     Epoch: 59
2023-01-05 02:50:00,599 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4731304109096527, 'Total loss': 0.4731304109096527} | train loss {'Reaction outcome loss': 0.20436707353624312, 'Total loss': 0.20436707353624312}
2023-01-05 02:50:00,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:00,599 INFO:     Epoch: 60
2023-01-05 02:50:02,813 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4360142042239507, 'Total loss': 0.4360142042239507} | train loss {'Reaction outcome loss': 0.20490505145235674, 'Total loss': 0.20490505145235674}
2023-01-05 02:50:02,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:02,813 INFO:     Epoch: 61
2023-01-05 02:50:05,081 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42015952269236245, 'Total loss': 0.42015952269236245} | train loss {'Reaction outcome loss': 0.20213829488763452, 'Total loss': 0.20213829488763452}
2023-01-05 02:50:05,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:05,081 INFO:     Epoch: 62
2023-01-05 02:50:07,307 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4349635084470113, 'Total loss': 0.4349635084470113} | train loss {'Reaction outcome loss': 0.20102809770268967, 'Total loss': 0.20102809770268967}
2023-01-05 02:50:07,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:07,309 INFO:     Epoch: 63
2023-01-05 02:50:09,546 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4320751403768857, 'Total loss': 0.4320751403768857} | train loss {'Reaction outcome loss': 0.20264397703863654, 'Total loss': 0.20264397703863654}
2023-01-05 02:50:09,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:09,547 INFO:     Epoch: 64
2023-01-05 02:50:11,809 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46907155911127724, 'Total loss': 0.46907155911127724} | train loss {'Reaction outcome loss': 0.20122593716023138, 'Total loss': 0.20122593716023138}
2023-01-05 02:50:11,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:11,809 INFO:     Epoch: 65
2023-01-05 02:50:14,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4539161205291748, 'Total loss': 0.4539161205291748} | train loss {'Reaction outcome loss': 0.19950602747269222, 'Total loss': 0.19950602747269222}
2023-01-05 02:50:14,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:14,071 INFO:     Epoch: 66
2023-01-05 02:50:16,350 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4495071053504944, 'Total loss': 0.4495071053504944} | train loss {'Reaction outcome loss': 0.19747315099390317, 'Total loss': 0.19747315099390317}
2023-01-05 02:50:16,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:16,350 INFO:     Epoch: 67
2023-01-05 02:50:18,514 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44691906347870825, 'Total loss': 0.44691906347870825} | train loss {'Reaction outcome loss': 0.19769912335618425, 'Total loss': 0.19769912335618425}
2023-01-05 02:50:18,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:18,514 INFO:     Epoch: 68
2023-01-05 02:50:20,360 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45598942240079243, 'Total loss': 0.45598942240079243} | train loss {'Reaction outcome loss': 0.19291342005295598, 'Total loss': 0.19291342005295598}
2023-01-05 02:50:20,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:20,361 INFO:     Epoch: 69
2023-01-05 02:50:22,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4500318651398023, 'Total loss': 0.4500318651398023} | train loss {'Reaction outcome loss': 0.19255737410444915, 'Total loss': 0.19255737410444915}
2023-01-05 02:50:22,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:22,199 INFO:     Epoch: 70
2023-01-05 02:50:24,486 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43948309620221454, 'Total loss': 0.43948309620221454} | train loss {'Reaction outcome loss': 0.189432708961987, 'Total loss': 0.189432708961987}
2023-01-05 02:50:24,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:24,486 INFO:     Epoch: 71
2023-01-05 02:50:26,806 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4490121672550837, 'Total loss': 0.4490121672550837} | train loss {'Reaction outcome loss': 0.19618199938111872, 'Total loss': 0.19618199938111872}
2023-01-05 02:50:26,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:26,807 INFO:     Epoch: 72
2023-01-05 02:50:29,045 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4646051446596781, 'Total loss': 0.4646051446596781} | train loss {'Reaction outcome loss': 0.19450135992336573, 'Total loss': 0.19450135992336573}
2023-01-05 02:50:29,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:29,045 INFO:     Epoch: 73
2023-01-05 02:50:31,286 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44519544442494713, 'Total loss': 0.44519544442494713} | train loss {'Reaction outcome loss': 0.19108193262439707, 'Total loss': 0.19108193262439707}
2023-01-05 02:50:31,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:31,287 INFO:     Epoch: 74
2023-01-05 02:50:33,433 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4427088369925817, 'Total loss': 0.4427088369925817} | train loss {'Reaction outcome loss': 0.18526358676709884, 'Total loss': 0.18526358676709884}
2023-01-05 02:50:33,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:33,433 INFO:     Epoch: 75
2023-01-05 02:50:35,680 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43126773126423357, 'Total loss': 0.43126773126423357} | train loss {'Reaction outcome loss': 0.18907930902829664, 'Total loss': 0.18907930902829664}
2023-01-05 02:50:35,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:35,680 INFO:     Epoch: 76
2023-01-05 02:50:37,944 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4465151290098826, 'Total loss': 0.4465151290098826} | train loss {'Reaction outcome loss': 0.1881962229503636, 'Total loss': 0.1881962229503636}
2023-01-05 02:50:37,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:37,945 INFO:     Epoch: 77
2023-01-05 02:50:40,192 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4172424376010895, 'Total loss': 0.4172424376010895} | train loss {'Reaction outcome loss': 0.1906657549738209, 'Total loss': 0.1906657549738209}
2023-01-05 02:50:40,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:40,193 INFO:     Epoch: 78
2023-01-05 02:50:42,440 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4569586296876272, 'Total loss': 0.4569586296876272} | train loss {'Reaction outcome loss': 0.18804827898059992, 'Total loss': 0.18804827898059992}
2023-01-05 02:50:42,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:42,440 INFO:     Epoch: 79
2023-01-05 02:50:44,659 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45926096638043723, 'Total loss': 0.45926096638043723} | train loss {'Reaction outcome loss': 0.18927552662623476, 'Total loss': 0.18927552662623476}
2023-01-05 02:50:44,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:44,660 INFO:     Epoch: 80
2023-01-05 02:50:46,898 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44274573822816216, 'Total loss': 0.44274573822816216} | train loss {'Reaction outcome loss': 0.18693379551658165, 'Total loss': 0.18693379551658165}
2023-01-05 02:50:46,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:46,898 INFO:     Epoch: 81
2023-01-05 02:50:49,152 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.447091227521499, 'Total loss': 0.447091227521499} | train loss {'Reaction outcome loss': 0.20263730571689625, 'Total loss': 0.20263730571689625}
2023-01-05 02:50:49,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:49,152 INFO:     Epoch: 82
2023-01-05 02:50:51,412 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4757619241873423, 'Total loss': 0.4757619241873423} | train loss {'Reaction outcome loss': 0.17939458366658917, 'Total loss': 0.17939458366658917}
2023-01-05 02:50:51,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:51,413 INFO:     Epoch: 83
2023-01-05 02:50:53,659 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5043554415305456, 'Total loss': 0.5043554415305456} | train loss {'Reaction outcome loss': 0.17441731710425593, 'Total loss': 0.17441731710425593}
2023-01-05 02:50:53,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:53,659 INFO:     Epoch: 84
2023-01-05 02:50:55,910 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4864874482154846, 'Total loss': 0.4864874482154846} | train loss {'Reaction outcome loss': 0.17961473951004006, 'Total loss': 0.17961473951004006}
2023-01-05 02:50:55,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:55,911 INFO:     Epoch: 85
2023-01-05 02:50:58,152 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4768625269333521, 'Total loss': 0.4768625269333521} | train loss {'Reaction outcome loss': 0.17761425029628142, 'Total loss': 0.17761425029628142}
2023-01-05 02:50:58,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:50:58,153 INFO:     Epoch: 86
2023-01-05 02:51:00,427 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45787650098403293, 'Total loss': 0.45787650098403293} | train loss {'Reaction outcome loss': 0.17918878489180698, 'Total loss': 0.17918878489180698}
2023-01-05 02:51:00,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:00,427 INFO:     Epoch: 87
2023-01-05 02:51:02,672 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43936492800712584, 'Total loss': 0.43936492800712584} | train loss {'Reaction outcome loss': 0.1840356038923399, 'Total loss': 0.1840356038923399}
2023-01-05 02:51:02,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:02,672 INFO:     Epoch: 88
2023-01-05 02:51:04,900 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44293817480405173, 'Total loss': 0.44293817480405173} | train loss {'Reaction outcome loss': 0.18542599828198444, 'Total loss': 0.18542599828198444}
2023-01-05 02:51:04,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:04,901 INFO:     Epoch: 89
2023-01-05 02:51:07,152 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44531173606713614, 'Total loss': 0.44531173606713614} | train loss {'Reaction outcome loss': 0.18147951397628093, 'Total loss': 0.18147951397628093}
2023-01-05 02:51:07,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:07,153 INFO:     Epoch: 90
2023-01-05 02:51:09,391 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46003986299037936, 'Total loss': 0.46003986299037936} | train loss {'Reaction outcome loss': 0.181163817689884, 'Total loss': 0.181163817689884}
2023-01-05 02:51:09,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:09,392 INFO:     Epoch: 91
2023-01-05 02:51:11,639 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4443407227595647, 'Total loss': 0.4443407227595647} | train loss {'Reaction outcome loss': 0.18202215536376057, 'Total loss': 0.18202215536376057}
2023-01-05 02:51:11,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:11,639 INFO:     Epoch: 92
2023-01-05 02:51:13,894 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4566705048084259, 'Total loss': 0.4566705048084259} | train loss {'Reaction outcome loss': 0.1970384315869339, 'Total loss': 0.1970384315869339}
2023-01-05 02:51:13,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:13,894 INFO:     Epoch: 93
2023-01-05 02:51:16,134 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44924237529436745, 'Total loss': 0.44924237529436745} | train loss {'Reaction outcome loss': 0.17743743169863802, 'Total loss': 0.17743743169863802}
2023-01-05 02:51:16,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:16,134 INFO:     Epoch: 94
2023-01-05 02:51:18,379 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4476017226775487, 'Total loss': 0.4476017226775487} | train loss {'Reaction outcome loss': 0.17469037587769612, 'Total loss': 0.17469037587769612}
2023-01-05 02:51:18,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:18,379 INFO:     Epoch: 95
2023-01-05 02:51:20,635 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4815931163728237, 'Total loss': 0.4815931163728237} | train loss {'Reaction outcome loss': 0.17369878490158505, 'Total loss': 0.17369878490158505}
2023-01-05 02:51:20,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:20,635 INFO:     Epoch: 96
2023-01-05 02:51:22,864 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43791119158267977, 'Total loss': 0.43791119158267977} | train loss {'Reaction outcome loss': 0.17318176211425662, 'Total loss': 0.17318176211425662}
2023-01-05 02:51:22,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:22,864 INFO:     Epoch: 97
2023-01-05 02:51:25,129 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44615620573361714, 'Total loss': 0.44615620573361714} | train loss {'Reaction outcome loss': 0.16968069915521047, 'Total loss': 0.16968069915521047}
2023-01-05 02:51:25,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:25,130 INFO:     Epoch: 98
2023-01-05 02:51:27,365 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45336765150229136, 'Total loss': 0.45336765150229136} | train loss {'Reaction outcome loss': 0.17515362321731356, 'Total loss': 0.17515362321731356}
2023-01-05 02:51:27,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:27,365 INFO:     Epoch: 99
2023-01-05 02:51:29,605 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4610431004315615, 'Total loss': 0.4610431004315615} | train loss {'Reaction outcome loss': 0.17323407628894041, 'Total loss': 0.17323407628894041}
2023-01-05 02:51:29,605 INFO:     Best model found after epoch 23 of 100.
2023-01-05 02:51:29,606 INFO:   Done with stage: TRAINING
2023-01-05 02:51:29,606 INFO:   Starting stage: EVALUATION
2023-01-05 02:51:29,740 INFO:   Done with stage: EVALUATION
2023-01-05 02:51:29,741 INFO:   Leaving out SEQ value Fold_2
2023-01-05 02:51:29,753 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 02:51:29,753 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:51:30,394 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:51:30,394 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:51:30,463 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:51:30,463 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:51:30,463 INFO:     No hyperparam tuning for this model
2023-01-05 02:51:30,463 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:51:30,463 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:51:30,464 INFO:     None feature selector for col prot
2023-01-05 02:51:30,464 INFO:     None feature selector for col prot
2023-01-05 02:51:30,464 INFO:     None feature selector for col prot
2023-01-05 02:51:30,464 INFO:     None feature selector for col chem
2023-01-05 02:51:30,465 INFO:     None feature selector for col chem
2023-01-05 02:51:30,465 INFO:     None feature selector for col chem
2023-01-05 02:51:30,465 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:51:30,465 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:51:30,466 INFO:     Number of params in model 72931
2023-01-05 02:51:30,469 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:51:30,469 INFO:   Starting stage: TRAINING
2023-01-05 02:51:30,531 INFO:     Val loss before train {'Reaction outcome loss': 1.0018239577611288, 'Total loss': 1.0018239577611288}
2023-01-05 02:51:30,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:30,531 INFO:     Epoch: 0
2023-01-05 02:51:32,742 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7764280200004577, 'Total loss': 0.7764280200004577} | train loss {'Reaction outcome loss': 0.9447938856417245, 'Total loss': 0.9447938856417245}
2023-01-05 02:51:32,742 INFO:     Found new best model at epoch 0
2023-01-05 02:51:32,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:32,744 INFO:     Epoch: 1
2023-01-05 02:51:34,973 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48462943037350975, 'Total loss': 0.48462943037350975} | train loss {'Reaction outcome loss': 0.641283913304771, 'Total loss': 0.641283913304771}
2023-01-05 02:51:34,973 INFO:     Found new best model at epoch 1
2023-01-05 02:51:34,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:34,974 INFO:     Epoch: 2
2023-01-05 02:51:37,209 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46207011938095094, 'Total loss': 0.46207011938095094} | train loss {'Reaction outcome loss': 0.5284728513908212, 'Total loss': 0.5284728513908212}
2023-01-05 02:51:37,209 INFO:     Found new best model at epoch 2
2023-01-05 02:51:37,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:37,211 INFO:     Epoch: 3
2023-01-05 02:51:39,411 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4593695958455404, 'Total loss': 0.4593695958455404} | train loss {'Reaction outcome loss': 0.48722126111932046, 'Total loss': 0.48722126111932046}
2023-01-05 02:51:39,411 INFO:     Found new best model at epoch 3
2023-01-05 02:51:39,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:39,412 INFO:     Epoch: 4
2023-01-05 02:51:41,660 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4037664900223414, 'Total loss': 0.4037664900223414} | train loss {'Reaction outcome loss': 0.46070008787469274, 'Total loss': 0.46070008787469274}
2023-01-05 02:51:41,660 INFO:     Found new best model at epoch 4
2023-01-05 02:51:41,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:41,661 INFO:     Epoch: 5
2023-01-05 02:51:43,898 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41794357101122537, 'Total loss': 0.41794357101122537} | train loss {'Reaction outcome loss': 0.43916772904187223, 'Total loss': 0.43916772904187223}
2023-01-05 02:51:43,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:43,899 INFO:     Epoch: 6
2023-01-05 02:51:46,091 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37694179465373356, 'Total loss': 0.37694179465373356} | train loss {'Reaction outcome loss': 0.41983077169334804, 'Total loss': 0.41983077169334804}
2023-01-05 02:51:46,092 INFO:     Found new best model at epoch 6
2023-01-05 02:51:46,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:46,093 INFO:     Epoch: 7
2023-01-05 02:51:48,314 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.35130131741364795, 'Total loss': 0.35130131741364795} | train loss {'Reaction outcome loss': 0.4067615874818642, 'Total loss': 0.4067615874818642}
2023-01-05 02:51:48,314 INFO:     Found new best model at epoch 7
2023-01-05 02:51:48,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:48,315 INFO:     Epoch: 8
2023-01-05 02:51:50,539 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37336220939954123, 'Total loss': 0.37336220939954123} | train loss {'Reaction outcome loss': 0.3914813374570251, 'Total loss': 0.3914813374570251}
2023-01-05 02:51:50,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:50,539 INFO:     Epoch: 9
2023-01-05 02:51:52,774 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3413059095541636, 'Total loss': 0.3413059095541636} | train loss {'Reaction outcome loss': 0.37947609786787173, 'Total loss': 0.37947609786787173}
2023-01-05 02:51:52,774 INFO:     Found new best model at epoch 9
2023-01-05 02:51:52,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:52,775 INFO:     Epoch: 10
2023-01-05 02:51:54,926 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35402721067269644, 'Total loss': 0.35402721067269644} | train loss {'Reaction outcome loss': 0.3711253995089418, 'Total loss': 0.3711253995089418}
2023-01-05 02:51:54,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:54,926 INFO:     Epoch: 11
2023-01-05 02:51:57,140 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34095365504423775, 'Total loss': 0.34095365504423775} | train loss {'Reaction outcome loss': 0.36105128052732804, 'Total loss': 0.36105128052732804}
2023-01-05 02:51:57,140 INFO:     Found new best model at epoch 11
2023-01-05 02:51:57,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:57,142 INFO:     Epoch: 12
2023-01-05 02:51:59,309 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3705815037091573, 'Total loss': 0.3705815037091573} | train loss {'Reaction outcome loss': 0.3505618972771794, 'Total loss': 0.3505618972771794}
2023-01-05 02:51:59,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:51:59,309 INFO:     Epoch: 13
2023-01-05 02:52:01,526 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.33515217701594036, 'Total loss': 0.33515217701594036} | train loss {'Reaction outcome loss': 0.34292268256799585, 'Total loss': 0.34292268256799585}
2023-01-05 02:52:01,526 INFO:     Found new best model at epoch 13
2023-01-05 02:52:01,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:01,527 INFO:     Epoch: 14
2023-01-05 02:52:03,766 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.31410339872042337, 'Total loss': 0.31410339872042337} | train loss {'Reaction outcome loss': 0.33588990539203595, 'Total loss': 0.33588990539203595}
2023-01-05 02:52:03,767 INFO:     Found new best model at epoch 14
2023-01-05 02:52:03,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:03,768 INFO:     Epoch: 15
2023-01-05 02:52:05,995 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.32761316895484927, 'Total loss': 0.32761316895484927} | train loss {'Reaction outcome loss': 0.32753864504451297, 'Total loss': 0.32753864504451297}
2023-01-05 02:52:05,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:05,995 INFO:     Epoch: 16
2023-01-05 02:52:08,225 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3201250026623408, 'Total loss': 0.3201250026623408} | train loss {'Reaction outcome loss': 0.3225087347528795, 'Total loss': 0.3225087347528795}
2023-01-05 02:52:08,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:08,225 INFO:     Epoch: 17
2023-01-05 02:52:10,434 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3242607593536377, 'Total loss': 0.3242607593536377} | train loss {'Reaction outcome loss': 0.31507358232336324, 'Total loss': 0.31507358232336324}
2023-01-05 02:52:10,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:10,434 INFO:     Epoch: 18
2023-01-05 02:52:12,624 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3191930795709292, 'Total loss': 0.3191930795709292} | train loss {'Reaction outcome loss': 0.3091537465416167, 'Total loss': 0.3091537465416167}
2023-01-05 02:52:12,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:12,625 INFO:     Epoch: 19
2023-01-05 02:52:14,869 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.322809757788976, 'Total loss': 0.322809757788976} | train loss {'Reaction outcome loss': 0.30038711537409873, 'Total loss': 0.30038711537409873}
2023-01-05 02:52:14,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:14,869 INFO:     Epoch: 20
2023-01-05 02:52:17,080 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.32922490934530896, 'Total loss': 0.32922490934530896} | train loss {'Reaction outcome loss': 0.2935612734379995, 'Total loss': 0.2935612734379995}
2023-01-05 02:52:17,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:17,080 INFO:     Epoch: 21
2023-01-05 02:52:19,292 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.33129690488179525, 'Total loss': 0.33129690488179525} | train loss {'Reaction outcome loss': 0.2929026934379426, 'Total loss': 0.2929026934379426}
2023-01-05 02:52:19,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:19,293 INFO:     Epoch: 22
2023-01-05 02:52:21,490 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.31921436339616777, 'Total loss': 0.31921436339616777} | train loss {'Reaction outcome loss': 0.2794241494750672, 'Total loss': 0.2794241494750672}
2023-01-05 02:52:21,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:21,490 INFO:     Epoch: 23
2023-01-05 02:52:23,690 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.31897979428370793, 'Total loss': 0.31897979428370793} | train loss {'Reaction outcome loss': 0.2792462830492941, 'Total loss': 0.2792462830492941}
2023-01-05 02:52:23,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:23,690 INFO:     Epoch: 24
2023-01-05 02:52:25,901 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.32287362962961197, 'Total loss': 0.32287362962961197} | train loss {'Reaction outcome loss': 0.2796662986060999, 'Total loss': 0.2796662986060999}
2023-01-05 02:52:25,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:25,902 INFO:     Epoch: 25
2023-01-05 02:52:28,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.31816152334213255, 'Total loss': 0.31816152334213255} | train loss {'Reaction outcome loss': 0.27122105784496686, 'Total loss': 0.27122105784496686}
2023-01-05 02:52:28,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:28,139 INFO:     Epoch: 26
2023-01-05 02:52:30,386 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.32694556588927903, 'Total loss': 0.32694556588927903} | train loss {'Reaction outcome loss': 0.26905523085572425, 'Total loss': 0.26905523085572425}
2023-01-05 02:52:30,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:30,386 INFO:     Epoch: 27
2023-01-05 02:52:32,601 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3181688199440638, 'Total loss': 0.3181688199440638} | train loss {'Reaction outcome loss': 0.26535786186637234, 'Total loss': 0.26535786186637234}
2023-01-05 02:52:32,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:32,601 INFO:     Epoch: 28
2023-01-05 02:52:34,846 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3418477753798167, 'Total loss': 0.3418477753798167} | train loss {'Reaction outcome loss': 0.2600339870138543, 'Total loss': 0.2600339870138543}
2023-01-05 02:52:34,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:34,847 INFO:     Epoch: 29
2023-01-05 02:52:36,987 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.29986854592959084, 'Total loss': 0.29986854592959084} | train loss {'Reaction outcome loss': 0.2581209253084703, 'Total loss': 0.2581209253084703}
2023-01-05 02:52:36,987 INFO:     Found new best model at epoch 29
2023-01-05 02:52:36,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:36,988 INFO:     Epoch: 30
2023-01-05 02:52:39,230 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.31208509405454, 'Total loss': 0.31208509405454} | train loss {'Reaction outcome loss': 0.2567220630131009, 'Total loss': 0.2567220630131009}
2023-01-05 02:52:39,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:39,231 INFO:     Epoch: 31
2023-01-05 02:52:41,451 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.32483655512332915, 'Total loss': 0.32483655512332915} | train loss {'Reaction outcome loss': 0.24988025782398715, 'Total loss': 0.24988025782398715}
2023-01-05 02:52:41,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:41,451 INFO:     Epoch: 32
2023-01-05 02:52:43,665 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34400531053543093, 'Total loss': 0.34400531053543093} | train loss {'Reaction outcome loss': 0.2500671728439357, 'Total loss': 0.2500671728439357}
2023-01-05 02:52:43,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:43,665 INFO:     Epoch: 33
2023-01-05 02:52:45,880 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3116251208509008, 'Total loss': 0.3116251208509008} | train loss {'Reaction outcome loss': 0.23958228158009967, 'Total loss': 0.23958228158009967}
2023-01-05 02:52:45,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:45,880 INFO:     Epoch: 34
2023-01-05 02:52:48,041 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.32325440148512524, 'Total loss': 0.32325440148512524} | train loss {'Reaction outcome loss': 0.2387173757310549, 'Total loss': 0.2387173757310549}
2023-01-05 02:52:48,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:48,041 INFO:     Epoch: 35
2023-01-05 02:52:50,274 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3245146448413531, 'Total loss': 0.3245146448413531} | train loss {'Reaction outcome loss': 0.23959268311405704, 'Total loss': 0.23959268311405704}
2023-01-05 02:52:50,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:50,275 INFO:     Epoch: 36
2023-01-05 02:52:52,476 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.31139348944028217, 'Total loss': 0.31139348944028217} | train loss {'Reaction outcome loss': 0.2368383638044126, 'Total loss': 0.2368383638044126}
2023-01-05 02:52:52,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:52,476 INFO:     Epoch: 37
2023-01-05 02:52:54,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.32571380188067756, 'Total loss': 0.32571380188067756} | train loss {'Reaction outcome loss': 0.23302415529959394, 'Total loss': 0.23302415529959394}
2023-01-05 02:52:54,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:54,633 INFO:     Epoch: 38
2023-01-05 02:52:56,853 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3140064919988314, 'Total loss': 0.3140064919988314} | train loss {'Reaction outcome loss': 0.23276866627789108, 'Total loss': 0.23276866627789108}
2023-01-05 02:52:56,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:56,854 INFO:     Epoch: 39
2023-01-05 02:52:58,997 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3078478189650923, 'Total loss': 0.3078478189650923} | train loss {'Reaction outcome loss': 0.22735370581045095, 'Total loss': 0.22735370581045095}
2023-01-05 02:52:58,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:52:58,997 INFO:     Epoch: 40
2023-01-05 02:53:01,186 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33337036247054735, 'Total loss': 0.33337036247054735} | train loss {'Reaction outcome loss': 0.22795091539512585, 'Total loss': 0.22795091539512585}
2023-01-05 02:53:01,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:01,187 INFO:     Epoch: 41
2023-01-05 02:53:03,195 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3480861862500509, 'Total loss': 0.3480861862500509} | train loss {'Reaction outcome loss': 0.22575066383438605, 'Total loss': 0.22575066383438605}
2023-01-05 02:53:03,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:03,195 INFO:     Epoch: 42
2023-01-05 02:53:05,438 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3220808391769727, 'Total loss': 0.3220808391769727} | train loss {'Reaction outcome loss': 0.2205966115711651, 'Total loss': 0.2205966115711651}
2023-01-05 02:53:05,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:05,438 INFO:     Epoch: 43
2023-01-05 02:53:07,618 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.32740435550610225, 'Total loss': 0.32740435550610225} | train loss {'Reaction outcome loss': 0.21736578281669722, 'Total loss': 0.21736578281669722}
2023-01-05 02:53:07,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:07,618 INFO:     Epoch: 44
2023-01-05 02:53:09,834 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3797518620888392, 'Total loss': 0.3797518620888392} | train loss {'Reaction outcome loss': 0.21637459431033934, 'Total loss': 0.21637459431033934}
2023-01-05 02:53:09,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:09,834 INFO:     Epoch: 45
2023-01-05 02:53:12,036 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.32901593546072644, 'Total loss': 0.32901593546072644} | train loss {'Reaction outcome loss': 0.22088448783845036, 'Total loss': 0.22088448783845036}
2023-01-05 02:53:12,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:12,037 INFO:     Epoch: 46
2023-01-05 02:53:14,182 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35611705978711444, 'Total loss': 0.35611705978711444} | train loss {'Reaction outcome loss': 0.20995422297694388, 'Total loss': 0.20995422297694388}
2023-01-05 02:53:14,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:14,183 INFO:     Epoch: 47
2023-01-05 02:53:16,358 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36211755077044167, 'Total loss': 0.36211755077044167} | train loss {'Reaction outcome loss': 0.21295711273041956, 'Total loss': 0.21295711273041956}
2023-01-05 02:53:16,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:16,359 INFO:     Epoch: 48
2023-01-05 02:53:18,562 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.33676288661857445, 'Total loss': 0.33676288661857445} | train loss {'Reaction outcome loss': 0.2093742683726995, 'Total loss': 0.2093742683726995}
2023-01-05 02:53:18,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:18,563 INFO:     Epoch: 49
2023-01-05 02:53:20,690 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.366598046819369, 'Total loss': 0.366598046819369} | train loss {'Reaction outcome loss': 0.20849959772542445, 'Total loss': 0.20849959772542445}
2023-01-05 02:53:20,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:20,690 INFO:     Epoch: 50
2023-01-05 02:53:22,835 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3628176604708036, 'Total loss': 0.3628176604708036} | train loss {'Reaction outcome loss': 0.20644477968627628, 'Total loss': 0.20644477968627628}
2023-01-05 02:53:22,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:22,836 INFO:     Epoch: 51
2023-01-05 02:53:25,071 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37039992411931355, 'Total loss': 0.37039992411931355} | train loss {'Reaction outcome loss': 0.2034350908939203, 'Total loss': 0.2034350908939203}
2023-01-05 02:53:25,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:25,071 INFO:     Epoch: 52
2023-01-05 02:53:27,306 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3458619634310404, 'Total loss': 0.3458619634310404} | train loss {'Reaction outcome loss': 0.20275212061611841, 'Total loss': 0.20275212061611841}
2023-01-05 02:53:27,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:27,307 INFO:     Epoch: 53
2023-01-05 02:53:29,461 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36742803851763406, 'Total loss': 0.36742803851763406} | train loss {'Reaction outcome loss': 0.20418203308206243, 'Total loss': 0.20418203308206243}
2023-01-05 02:53:29,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:29,462 INFO:     Epoch: 54
2023-01-05 02:53:31,645 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34766966899236046, 'Total loss': 0.34766966899236046} | train loss {'Reaction outcome loss': 0.19947986799312661, 'Total loss': 0.19947986799312661}
2023-01-05 02:53:31,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:31,646 INFO:     Epoch: 55
2023-01-05 02:53:33,861 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36888888478279114, 'Total loss': 0.36888888478279114} | train loss {'Reaction outcome loss': 0.2007848620380744, 'Total loss': 0.2007848620380744}
2023-01-05 02:53:33,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:33,861 INFO:     Epoch: 56
2023-01-05 02:53:36,078 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32414095252752306, 'Total loss': 0.32414095252752306} | train loss {'Reaction outcome loss': 0.19502002314195363, 'Total loss': 0.19502002314195363}
2023-01-05 02:53:36,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:36,078 INFO:     Epoch: 57
2023-01-05 02:53:38,322 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3376128596564134, 'Total loss': 0.3376128596564134} | train loss {'Reaction outcome loss': 0.196076677498632, 'Total loss': 0.196076677498632}
2023-01-05 02:53:38,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:38,323 INFO:     Epoch: 58
2023-01-05 02:53:40,481 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.354452512661616, 'Total loss': 0.354452512661616} | train loss {'Reaction outcome loss': 0.1935487652544177, 'Total loss': 0.1935487652544177}
2023-01-05 02:53:40,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:40,482 INFO:     Epoch: 59
2023-01-05 02:53:42,669 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37530945539474486, 'Total loss': 0.37530945539474486} | train loss {'Reaction outcome loss': 0.19260470682829892, 'Total loss': 0.19260470682829892}
2023-01-05 02:53:42,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:42,669 INFO:     Epoch: 60
2023-01-05 02:53:44,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3625705604751905, 'Total loss': 0.3625705604751905} | train loss {'Reaction outcome loss': 0.1902232202021473, 'Total loss': 0.1902232202021473}
2023-01-05 02:53:44,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:44,892 INFO:     Epoch: 61
2023-01-05 02:53:47,132 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35704873700936635, 'Total loss': 0.35704873700936635} | train loss {'Reaction outcome loss': 0.19234037425464195, 'Total loss': 0.19234037425464195}
2023-01-05 02:53:47,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:47,132 INFO:     Epoch: 62
2023-01-05 02:53:49,327 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.356538321574529, 'Total loss': 0.356538321574529} | train loss {'Reaction outcome loss': 0.18951544015715918, 'Total loss': 0.18951544015715918}
2023-01-05 02:53:49,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:49,327 INFO:     Epoch: 63
2023-01-05 02:53:51,545 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34018767774105074, 'Total loss': 0.34018767774105074} | train loss {'Reaction outcome loss': 0.18750259554503065, 'Total loss': 0.18750259554503065}
2023-01-05 02:53:51,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:51,546 INFO:     Epoch: 64
2023-01-05 02:53:53,692 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36312135110298793, 'Total loss': 0.36312135110298793} | train loss {'Reaction outcome loss': 0.18668552284829154, 'Total loss': 0.18668552284829154}
2023-01-05 02:53:53,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:53,692 INFO:     Epoch: 65
2023-01-05 02:53:55,924 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3441735953092575, 'Total loss': 0.3441735953092575} | train loss {'Reaction outcome loss': 0.1888330141354325, 'Total loss': 0.1888330141354325}
2023-01-05 02:53:55,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:55,924 INFO:     Epoch: 66
2023-01-05 02:53:58,155 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.332515988064309, 'Total loss': 0.332515988064309} | train loss {'Reaction outcome loss': 0.1850814145520656, 'Total loss': 0.1850814145520656}
2023-01-05 02:53:58,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:53:58,156 INFO:     Epoch: 67
2023-01-05 02:54:00,359 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3546893815199534, 'Total loss': 0.3546893815199534} | train loss {'Reaction outcome loss': 0.18398802216932938, 'Total loss': 0.18398802216932938}
2023-01-05 02:54:00,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:00,359 INFO:     Epoch: 68
2023-01-05 02:54:02,477 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36255788058042526, 'Total loss': 0.36255788058042526} | train loss {'Reaction outcome loss': 0.18249249137958418, 'Total loss': 0.18249249137958418}
2023-01-05 02:54:02,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:02,478 INFO:     Epoch: 69
2023-01-05 02:54:04,671 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3609675606091817, 'Total loss': 0.3609675606091817} | train loss {'Reaction outcome loss': 0.18552484574394612, 'Total loss': 0.18552484574394612}
2023-01-05 02:54:04,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:04,671 INFO:     Epoch: 70
2023-01-05 02:54:06,826 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3523395098745823, 'Total loss': 0.3523395098745823} | train loss {'Reaction outcome loss': 0.17943425656357495, 'Total loss': 0.17943425656357495}
2023-01-05 02:54:06,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:06,826 INFO:     Epoch: 71
2023-01-05 02:54:08,993 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35828839034462967, 'Total loss': 0.35828839034462967} | train loss {'Reaction outcome loss': 0.1811920790049336, 'Total loss': 0.1811920790049336}
2023-01-05 02:54:08,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:08,994 INFO:     Epoch: 72
2023-01-05 02:54:11,188 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.33794677356878916, 'Total loss': 0.33794677356878916} | train loss {'Reaction outcome loss': 0.17686446753235358, 'Total loss': 0.17686446753235358}
2023-01-05 02:54:11,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:11,188 INFO:     Epoch: 73
2023-01-05 02:54:13,362 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35068164666493734, 'Total loss': 0.35068164666493734} | train loss {'Reaction outcome loss': 0.17861868248722196, 'Total loss': 0.17861868248722196}
2023-01-05 02:54:13,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:13,363 INFO:     Epoch: 74
2023-01-05 02:54:15,611 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3867417146762212, 'Total loss': 0.3867417146762212} | train loss {'Reaction outcome loss': 0.17433565831403283, 'Total loss': 0.17433565831403283}
2023-01-05 02:54:15,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:15,611 INFO:     Epoch: 75
2023-01-05 02:54:17,833 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3933279206355413, 'Total loss': 0.3933279206355413} | train loss {'Reaction outcome loss': 0.17883587855315447, 'Total loss': 0.17883587855315447}
2023-01-05 02:54:17,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:17,833 INFO:     Epoch: 76
2023-01-05 02:54:20,030 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3755692015091578, 'Total loss': 0.3755692015091578} | train loss {'Reaction outcome loss': 0.17422469691407397, 'Total loss': 0.17422469691407397}
2023-01-05 02:54:20,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:20,031 INFO:     Epoch: 77
2023-01-05 02:54:22,271 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39458997348944347, 'Total loss': 0.39458997348944347} | train loss {'Reaction outcome loss': 0.17308959323083506, 'Total loss': 0.17308959323083506}
2023-01-05 02:54:22,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:22,272 INFO:     Epoch: 78
2023-01-05 02:54:24,498 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3842141608397166, 'Total loss': 0.3842141608397166} | train loss {'Reaction outcome loss': 0.17335104752658276, 'Total loss': 0.17335104752658276}
2023-01-05 02:54:24,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:24,498 INFO:     Epoch: 79
2023-01-05 02:54:26,722 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37856718301773074, 'Total loss': 0.37856718301773074} | train loss {'Reaction outcome loss': 0.17345123359063355, 'Total loss': 0.17345123359063355}
2023-01-05 02:54:26,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:26,722 INFO:     Epoch: 80
2023-01-05 02:54:28,899 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3916349003712336, 'Total loss': 0.3916349003712336} | train loss {'Reaction outcome loss': 0.17303529550341795, 'Total loss': 0.17303529550341795}
2023-01-05 02:54:28,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:28,899 INFO:     Epoch: 81
2023-01-05 02:54:31,050 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37315462430318197, 'Total loss': 0.37315462430318197} | train loss {'Reaction outcome loss': 0.16900181695886882, 'Total loss': 0.16900181695886882}
2023-01-05 02:54:31,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:31,051 INFO:     Epoch: 82
2023-01-05 02:54:33,248 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3709933489561081, 'Total loss': 0.3709933489561081} | train loss {'Reaction outcome loss': 0.17071115436120787, 'Total loss': 0.17071115436120787}
2023-01-05 02:54:33,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:33,249 INFO:     Epoch: 83
2023-01-05 02:54:35,484 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35991976658503216, 'Total loss': 0.35991976658503216} | train loss {'Reaction outcome loss': 0.1733102788995734, 'Total loss': 0.1733102788995734}
2023-01-05 02:54:35,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:35,484 INFO:     Epoch: 84
2023-01-05 02:54:37,681 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35444331876933577, 'Total loss': 0.35444331876933577} | train loss {'Reaction outcome loss': 0.16657353499836294, 'Total loss': 0.16657353499836294}
2023-01-05 02:54:37,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:37,681 INFO:     Epoch: 85
2023-01-05 02:54:39,907 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3791728183627129, 'Total loss': 0.3791728183627129} | train loss {'Reaction outcome loss': 0.16996493009360927, 'Total loss': 0.16996493009360927}
2023-01-05 02:54:39,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:39,908 INFO:     Epoch: 86
2023-01-05 02:54:42,123 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3680624604225159, 'Total loss': 0.3680624604225159} | train loss {'Reaction outcome loss': 0.17048273441198208, 'Total loss': 0.17048273441198208}
2023-01-05 02:54:42,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:42,124 INFO:     Epoch: 87
2023-01-05 02:54:44,366 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3650970607995987, 'Total loss': 0.3650970607995987} | train loss {'Reaction outcome loss': 0.17257470146406198, 'Total loss': 0.17257470146406198}
2023-01-05 02:54:44,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:44,366 INFO:     Epoch: 88
2023-01-05 02:54:46,573 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37336328824361165, 'Total loss': 0.37336328824361165} | train loss {'Reaction outcome loss': 0.16530935858872575, 'Total loss': 0.16530935858872575}
2023-01-05 02:54:46,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:46,573 INFO:     Epoch: 89
2023-01-05 02:54:48,821 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3570479174455007, 'Total loss': 0.3570479174455007} | train loss {'Reaction outcome loss': 0.16538265548360936, 'Total loss': 0.16538265548360936}
2023-01-05 02:54:48,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:48,821 INFO:     Epoch: 90
2023-01-05 02:54:51,038 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3915370166301727, 'Total loss': 0.3915370166301727} | train loss {'Reaction outcome loss': 0.16630069662334165, 'Total loss': 0.16630069662334165}
2023-01-05 02:54:51,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:51,039 INFO:     Epoch: 91
2023-01-05 02:54:53,223 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39479299684365593, 'Total loss': 0.39479299684365593} | train loss {'Reaction outcome loss': 0.16953640526677244, 'Total loss': 0.16953640526677244}
2023-01-05 02:54:53,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:53,224 INFO:     Epoch: 92
2023-01-05 02:54:55,418 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39367607347667216, 'Total loss': 0.39367607347667216} | train loss {'Reaction outcome loss': 0.17174060613487976, 'Total loss': 0.17174060613487976}
2023-01-05 02:54:55,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:55,418 INFO:     Epoch: 93
2023-01-05 02:54:57,655 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.362101303289334, 'Total loss': 0.362101303289334} | train loss {'Reaction outcome loss': 0.16489424691093665, 'Total loss': 0.16489424691093665}
2023-01-05 02:54:57,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:57,655 INFO:     Epoch: 94
2023-01-05 02:54:59,823 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38316593170166013, 'Total loss': 0.38316593170166013} | train loss {'Reaction outcome loss': 0.16274740168549473, 'Total loss': 0.16274740168549473}
2023-01-05 02:54:59,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:54:59,823 INFO:     Epoch: 95
2023-01-05 02:55:02,045 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3726442495981852, 'Total loss': 0.3726442495981852} | train loss {'Reaction outcome loss': 0.1594519893788345, 'Total loss': 0.1594519893788345}
2023-01-05 02:55:02,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:02,045 INFO:     Epoch: 96
2023-01-05 02:55:04,173 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4026953650638461, 'Total loss': 0.4026953650638461} | train loss {'Reaction outcome loss': 0.16158668407286605, 'Total loss': 0.16158668407286605}
2023-01-05 02:55:04,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:04,174 INFO:     Epoch: 97
2023-01-05 02:55:06,389 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3902915274103483, 'Total loss': 0.3902915274103483} | train loss {'Reaction outcome loss': 0.16734556398646783, 'Total loss': 0.16734556398646783}
2023-01-05 02:55:06,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:06,390 INFO:     Epoch: 98
2023-01-05 02:55:08,591 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39492123027642567, 'Total loss': 0.39492123027642567} | train loss {'Reaction outcome loss': 0.16498268885286457, 'Total loss': 0.16498268885286457}
2023-01-05 02:55:08,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:08,591 INFO:     Epoch: 99
2023-01-05 02:55:10,789 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36744755584125716, 'Total loss': 0.36744755584125716} | train loss {'Reaction outcome loss': 0.16373596029240556, 'Total loss': 0.16373596029240556}
2023-01-05 02:55:10,790 INFO:     Best model found after epoch 30 of 100.
2023-01-05 02:55:10,790 INFO:   Done with stage: TRAINING
2023-01-05 02:55:10,790 INFO:   Starting stage: EVALUATION
2023-01-05 02:55:10,931 INFO:   Done with stage: EVALUATION
2023-01-05 02:55:10,931 INFO:   Leaving out SEQ value Fold_3
2023-01-05 02:55:10,944 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 02:55:10,944 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:55:11,584 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:55:11,584 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:55:11,653 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:55:11,653 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:55:11,653 INFO:     No hyperparam tuning for this model
2023-01-05 02:55:11,653 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:55:11,653 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:55:11,654 INFO:     None feature selector for col prot
2023-01-05 02:55:11,654 INFO:     None feature selector for col prot
2023-01-05 02:55:11,654 INFO:     None feature selector for col prot
2023-01-05 02:55:11,654 INFO:     None feature selector for col chem
2023-01-05 02:55:11,654 INFO:     None feature selector for col chem
2023-01-05 02:55:11,655 INFO:     None feature selector for col chem
2023-01-05 02:55:11,655 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:55:11,655 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:55:11,656 INFO:     Number of params in model 72931
2023-01-05 02:55:11,659 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:55:11,659 INFO:   Starting stage: TRAINING
2023-01-05 02:55:11,718 INFO:     Val loss before train {'Reaction outcome loss': 1.009452215830485, 'Total loss': 1.009452215830485}
2023-01-05 02:55:11,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:11,719 INFO:     Epoch: 0
2023-01-05 02:55:13,864 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8698093930880229, 'Total loss': 0.8698093930880229} | train loss {'Reaction outcome loss': 0.9558273812571725, 'Total loss': 0.9558273812571725}
2023-01-05 02:55:13,864 INFO:     Found new best model at epoch 0
2023-01-05 02:55:13,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:13,865 INFO:     Epoch: 1
2023-01-05 02:55:16,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6056455910205841, 'Total loss': 0.6056455910205841} | train loss {'Reaction outcome loss': 0.7164656079950786, 'Total loss': 0.7164656079950786}
2023-01-05 02:55:16,058 INFO:     Found new best model at epoch 1
2023-01-05 02:55:16,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:16,060 INFO:     Epoch: 2
2023-01-05 02:55:18,249 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.523655253648758, 'Total loss': 0.523655253648758} | train loss {'Reaction outcome loss': 0.5541683932691267, 'Total loss': 0.5541683932691267}
2023-01-05 02:55:18,249 INFO:     Found new best model at epoch 2
2023-01-05 02:55:18,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:18,251 INFO:     Epoch: 3
2023-01-05 02:55:20,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5296744803587595, 'Total loss': 0.5296744803587595} | train loss {'Reaction outcome loss': 0.5129235899382896, 'Total loss': 0.5129235899382896}
2023-01-05 02:55:20,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:20,445 INFO:     Epoch: 4
2023-01-05 02:55:22,623 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4794106344381968, 'Total loss': 0.4794106344381968} | train loss {'Reaction outcome loss': 0.47693386100805724, 'Total loss': 0.47693386100805724}
2023-01-05 02:55:22,623 INFO:     Found new best model at epoch 4
2023-01-05 02:55:22,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:22,625 INFO:     Epoch: 5
2023-01-05 02:55:24,829 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4641405334075292, 'Total loss': 0.4641405334075292} | train loss {'Reaction outcome loss': 0.45138384595567926, 'Total loss': 0.45138384595567926}
2023-01-05 02:55:24,830 INFO:     Found new best model at epoch 5
2023-01-05 02:55:24,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:24,831 INFO:     Epoch: 6
2023-01-05 02:55:27,035 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4591372231642405, 'Total loss': 0.4591372231642405} | train loss {'Reaction outcome loss': 0.4295076292294722, 'Total loss': 0.4295076292294722}
2023-01-05 02:55:27,035 INFO:     Found new best model at epoch 6
2023-01-05 02:55:27,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:27,037 INFO:     Epoch: 7
2023-01-05 02:55:29,236 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.469592613975207, 'Total loss': 0.469592613975207} | train loss {'Reaction outcome loss': 0.41250107560183974, 'Total loss': 0.41250107560183974}
2023-01-05 02:55:29,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:29,237 INFO:     Epoch: 8
2023-01-05 02:55:31,357 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45049527287483215, 'Total loss': 0.45049527287483215} | train loss {'Reaction outcome loss': 0.39976058245360196, 'Total loss': 0.39976058245360196}
2023-01-05 02:55:31,357 INFO:     Found new best model at epoch 8
2023-01-05 02:55:31,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:31,359 INFO:     Epoch: 9
2023-01-05 02:55:33,581 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4426361898581187, 'Total loss': 0.4426361898581187} | train loss {'Reaction outcome loss': 0.38743233596121435, 'Total loss': 0.38743233596121435}
2023-01-05 02:55:33,582 INFO:     Found new best model at epoch 9
2023-01-05 02:55:33,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:33,583 INFO:     Epoch: 10
2023-01-05 02:55:35,721 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4524497320254644, 'Total loss': 0.4524497320254644} | train loss {'Reaction outcome loss': 0.3753139679132527, 'Total loss': 0.3753139679132527}
2023-01-05 02:55:35,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:35,722 INFO:     Epoch: 11
2023-01-05 02:55:37,936 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4666313906510671, 'Total loss': 0.4666313906510671} | train loss {'Reaction outcome loss': 0.36285963335207533, 'Total loss': 0.36285963335207533}
2023-01-05 02:55:37,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:37,937 INFO:     Epoch: 12
2023-01-05 02:55:40,064 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4342975835005442, 'Total loss': 0.4342975835005442} | train loss {'Reaction outcome loss': 0.3509057304334073, 'Total loss': 0.3509057304334073}
2023-01-05 02:55:40,065 INFO:     Found new best model at epoch 12
2023-01-05 02:55:40,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:40,066 INFO:     Epoch: 13
2023-01-05 02:55:42,151 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.418867660065492, 'Total loss': 0.418867660065492} | train loss {'Reaction outcome loss': 0.3413150150315229, 'Total loss': 0.3413150150315229}
2023-01-05 02:55:42,151 INFO:     Found new best model at epoch 13
2023-01-05 02:55:42,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:42,152 INFO:     Epoch: 14
2023-01-05 02:55:44,325 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41840917666753136, 'Total loss': 0.41840917666753136} | train loss {'Reaction outcome loss': 0.3316420509851787, 'Total loss': 0.3316420509851787}
2023-01-05 02:55:44,326 INFO:     Found new best model at epoch 14
2023-01-05 02:55:44,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:44,327 INFO:     Epoch: 15
2023-01-05 02:55:46,545 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43931061327457427, 'Total loss': 0.43931061327457427} | train loss {'Reaction outcome loss': 0.3242117014505488, 'Total loss': 0.3242117014505488}
2023-01-05 02:55:46,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:46,545 INFO:     Epoch: 16
2023-01-05 02:55:48,747 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40828331957260766, 'Total loss': 0.40828331957260766} | train loss {'Reaction outcome loss': 0.31692238867064537, 'Total loss': 0.31692238867064537}
2023-01-05 02:55:48,747 INFO:     Found new best model at epoch 16
2023-01-05 02:55:48,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:48,748 INFO:     Epoch: 17
2023-01-05 02:55:50,980 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4173976500829061, 'Total loss': 0.4173976500829061} | train loss {'Reaction outcome loss': 0.31032511622699543, 'Total loss': 0.31032511622699543}
2023-01-05 02:55:50,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:50,981 INFO:     Epoch: 18
2023-01-05 02:55:53,181 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42433505058288573, 'Total loss': 0.42433505058288573} | train loss {'Reaction outcome loss': 0.3047221430437469, 'Total loss': 0.3047221430437469}
2023-01-05 02:55:53,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:53,182 INFO:     Epoch: 19
2023-01-05 02:55:55,409 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41325306594371797, 'Total loss': 0.41325306594371797} | train loss {'Reaction outcome loss': 0.300657036512981, 'Total loss': 0.300657036512981}
2023-01-05 02:55:55,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:55,409 INFO:     Epoch: 20
2023-01-05 02:55:57,616 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43621644874413806, 'Total loss': 0.43621644874413806} | train loss {'Reaction outcome loss': 0.29175813117443206, 'Total loss': 0.29175813117443206}
2023-01-05 02:55:57,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:57,616 INFO:     Epoch: 21
2023-01-05 02:55:59,798 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40100148916244505, 'Total loss': 0.40100148916244505} | train loss {'Reaction outcome loss': 0.2824379529653888, 'Total loss': 0.2824379529653888}
2023-01-05 02:55:59,798 INFO:     Found new best model at epoch 21
2023-01-05 02:55:59,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:55:59,800 INFO:     Epoch: 22
2023-01-05 02:56:01,993 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40408103317022326, 'Total loss': 0.40408103317022326} | train loss {'Reaction outcome loss': 0.2860499816117706, 'Total loss': 0.2860499816117706}
2023-01-05 02:56:01,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:01,993 INFO:     Epoch: 23
2023-01-05 02:56:04,114 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4354012062773108, 'Total loss': 0.4354012062773108} | train loss {'Reaction outcome loss': 0.27946740552619265, 'Total loss': 0.27946740552619265}
2023-01-05 02:56:04,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:04,114 INFO:     Epoch: 24
2023-01-05 02:56:05,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4463668202360471, 'Total loss': 0.4463668202360471} | train loss {'Reaction outcome loss': 0.27048014424359185, 'Total loss': 0.27048014424359185}
2023-01-05 02:56:05,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:05,970 INFO:     Epoch: 25
2023-01-05 02:56:07,826 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44823610385258994, 'Total loss': 0.44823610385258994} | train loss {'Reaction outcome loss': 0.26955150294325725, 'Total loss': 0.26955150294325725}
2023-01-05 02:56:07,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:07,827 INFO:     Epoch: 26
2023-01-05 02:56:09,958 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44139822920163474, 'Total loss': 0.44139822920163474} | train loss {'Reaction outcome loss': 0.2625426220001428, 'Total loss': 0.2625426220001428}
2023-01-05 02:56:09,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:09,959 INFO:     Epoch: 27
2023-01-05 02:56:12,114 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42532210424542427, 'Total loss': 0.42532210424542427} | train loss {'Reaction outcome loss': 0.26188574290592154, 'Total loss': 0.26188574290592154}
2023-01-05 02:56:12,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:12,114 INFO:     Epoch: 28
2023-01-05 02:56:14,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4349249809980392, 'Total loss': 0.4349249809980392} | train loss {'Reaction outcome loss': 0.2567786646481508, 'Total loss': 0.2567786646481508}
2023-01-05 02:56:14,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:14,325 INFO:     Epoch: 29
2023-01-05 02:56:16,517 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46896718939145404, 'Total loss': 0.46896718939145404} | train loss {'Reaction outcome loss': 0.24983169603751693, 'Total loss': 0.24983169603751693}
2023-01-05 02:56:16,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:16,518 INFO:     Epoch: 30
2023-01-05 02:56:18,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4484720855951309, 'Total loss': 0.4484720855951309} | train loss {'Reaction outcome loss': 0.2501495369460993, 'Total loss': 0.2501495369460993}
2023-01-05 02:56:18,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:18,746 INFO:     Epoch: 31
2023-01-05 02:56:20,985 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46431416471799214, 'Total loss': 0.46431416471799214} | train loss {'Reaction outcome loss': 0.23747112702291745, 'Total loss': 0.23747112702291745}
2023-01-05 02:56:20,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:20,985 INFO:     Epoch: 32
2023-01-05 02:56:23,210 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43401522437731427, 'Total loss': 0.43401522437731427} | train loss {'Reaction outcome loss': 0.2418907936798893, 'Total loss': 0.2418907936798893}
2023-01-05 02:56:23,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:23,211 INFO:     Epoch: 33
2023-01-05 02:56:25,343 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4336322863896688, 'Total loss': 0.4336322863896688} | train loss {'Reaction outcome loss': 0.2408579049202112, 'Total loss': 0.2408579049202112}
2023-01-05 02:56:25,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:25,344 INFO:     Epoch: 34
2023-01-05 02:56:27,549 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4411082784334818, 'Total loss': 0.4411082784334818} | train loss {'Reaction outcome loss': 0.2359351238078905, 'Total loss': 0.2359351238078905}
2023-01-05 02:56:27,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:27,549 INFO:     Epoch: 35
2023-01-05 02:56:29,780 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4294226408004761, 'Total loss': 0.4294226408004761} | train loss {'Reaction outcome loss': 0.23187498438543888, 'Total loss': 0.23187498438543888}
2023-01-05 02:56:29,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:29,781 INFO:     Epoch: 36
2023-01-05 02:56:31,976 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4493063857158025, 'Total loss': 0.4493063857158025} | train loss {'Reaction outcome loss': 0.22702456028251858, 'Total loss': 0.22702456028251858}
2023-01-05 02:56:31,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:31,977 INFO:     Epoch: 37
2023-01-05 02:56:34,200 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44095342258612313, 'Total loss': 0.44095342258612313} | train loss {'Reaction outcome loss': 0.22422989109196725, 'Total loss': 0.22422989109196725}
2023-01-05 02:56:34,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:34,201 INFO:     Epoch: 38
2023-01-05 02:56:36,379 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49553960462411245, 'Total loss': 0.49553960462411245} | train loss {'Reaction outcome loss': 0.22127956926358708, 'Total loss': 0.22127956926358708}
2023-01-05 02:56:36,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:36,379 INFO:     Epoch: 39
2023-01-05 02:56:38,574 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4711008469263713, 'Total loss': 0.4711008469263713} | train loss {'Reaction outcome loss': 0.22384343238636142, 'Total loss': 0.22384343238636142}
2023-01-05 02:56:38,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:38,574 INFO:     Epoch: 40
2023-01-05 02:56:40,690 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4371423234542211, 'Total loss': 0.4371423234542211} | train loss {'Reaction outcome loss': 0.2159945535040273, 'Total loss': 0.2159945535040273}
2023-01-05 02:56:40,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:40,691 INFO:     Epoch: 41
2023-01-05 02:56:42,918 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44392698009808856, 'Total loss': 0.44392698009808856} | train loss {'Reaction outcome loss': 0.21466656643283236, 'Total loss': 0.21466656643283236}
2023-01-05 02:56:42,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:42,918 INFO:     Epoch: 42
2023-01-05 02:56:45,138 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45541806022326153, 'Total loss': 0.45541806022326153} | train loss {'Reaction outcome loss': 0.21374481010861396, 'Total loss': 0.21374481010861396}
2023-01-05 02:56:45,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:45,138 INFO:     Epoch: 43
2023-01-05 02:56:47,373 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4693059742450714, 'Total loss': 0.4693059742450714} | train loss {'Reaction outcome loss': 0.2110433363229473, 'Total loss': 0.2110433363229473}
2023-01-05 02:56:47,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:47,374 INFO:     Epoch: 44
2023-01-05 02:56:49,581 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45487305223941804, 'Total loss': 0.45487305223941804} | train loss {'Reaction outcome loss': 0.2116734652435441, 'Total loss': 0.2116734652435441}
2023-01-05 02:56:49,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:49,581 INFO:     Epoch: 45
2023-01-05 02:56:51,796 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4476023475329081, 'Total loss': 0.4476023475329081} | train loss {'Reaction outcome loss': 0.21255675932535759, 'Total loss': 0.21255675932535759}
2023-01-05 02:56:51,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:51,797 INFO:     Epoch: 46
2023-01-05 02:56:53,963 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4220444773634275, 'Total loss': 0.4220444773634275} | train loss {'Reaction outcome loss': 0.20935621443494554, 'Total loss': 0.20935621443494554}
2023-01-05 02:56:53,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:53,964 INFO:     Epoch: 47
2023-01-05 02:56:56,166 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43798920838162303, 'Total loss': 0.43798920838162303} | train loss {'Reaction outcome loss': 0.2062541424730049, 'Total loss': 0.2062541424730049}
2023-01-05 02:56:56,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:56,166 INFO:     Epoch: 48
2023-01-05 02:56:58,337 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4358078350623449, 'Total loss': 0.4358078350623449} | train loss {'Reaction outcome loss': 0.20236167877284816, 'Total loss': 0.20236167877284816}
2023-01-05 02:56:58,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:56:58,338 INFO:     Epoch: 49
2023-01-05 02:57:00,558 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4213501493136088, 'Total loss': 0.4213501493136088} | train loss {'Reaction outcome loss': 0.2012831351341127, 'Total loss': 0.2012831351341127}
2023-01-05 02:57:00,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:00,559 INFO:     Epoch: 50
2023-01-05 02:57:02,776 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42480104764302573, 'Total loss': 0.42480104764302573} | train loss {'Reaction outcome loss': 0.20072449897091849, 'Total loss': 0.20072449897091849}
2023-01-05 02:57:02,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:02,777 INFO:     Epoch: 51
2023-01-05 02:57:04,968 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44678122997283937, 'Total loss': 0.44678122997283937} | train loss {'Reaction outcome loss': 0.20042467446172194, 'Total loss': 0.20042467446172194}
2023-01-05 02:57:04,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:04,968 INFO:     Epoch: 52
2023-01-05 02:57:07,034 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4266828835010529, 'Total loss': 0.4266828835010529} | train loss {'Reaction outcome loss': 0.20001593894826677, 'Total loss': 0.20001593894826677}
2023-01-05 02:57:07,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:07,034 INFO:     Epoch: 53
2023-01-05 02:57:09,228 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43158167774478595, 'Total loss': 0.43158167774478595} | train loss {'Reaction outcome loss': 0.19644977969472252, 'Total loss': 0.19644977969472252}
2023-01-05 02:57:09,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:09,229 INFO:     Epoch: 54
2023-01-05 02:57:11,435 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40696522692839304, 'Total loss': 0.40696522692839304} | train loss {'Reaction outcome loss': 0.19505424146291428, 'Total loss': 0.19505424146291428}
2023-01-05 02:57:11,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:11,435 INFO:     Epoch: 55
2023-01-05 02:57:13,656 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42902773519357046, 'Total loss': 0.42902773519357046} | train loss {'Reaction outcome loss': 0.18865191315611204, 'Total loss': 0.18865191315611204}
2023-01-05 02:57:13,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:13,657 INFO:     Epoch: 56
2023-01-05 02:57:15,868 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4425224552551905, 'Total loss': 0.4425224552551905} | train loss {'Reaction outcome loss': 0.19591892440718062, 'Total loss': 0.19591892440718062}
2023-01-05 02:57:15,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:15,869 INFO:     Epoch: 57
2023-01-05 02:57:18,024 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4360855648914973, 'Total loss': 0.4360855648914973} | train loss {'Reaction outcome loss': 0.19340012319413297, 'Total loss': 0.19340012319413297}
2023-01-05 02:57:18,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:18,024 INFO:     Epoch: 58
2023-01-05 02:57:20,227 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4018742995957533, 'Total loss': 0.4018742995957533} | train loss {'Reaction outcome loss': 0.18964698958473328, 'Total loss': 0.18964698958473328}
2023-01-05 02:57:20,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:20,227 INFO:     Epoch: 59
2023-01-05 02:57:22,428 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40435734192530315, 'Total loss': 0.40435734192530315} | train loss {'Reaction outcome loss': 0.18686971605342606, 'Total loss': 0.18686971605342606}
2023-01-05 02:57:22,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:22,428 INFO:     Epoch: 60
2023-01-05 02:57:24,641 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3854339124634862, 'Total loss': 0.3854339124634862} | train loss {'Reaction outcome loss': 0.18609986786266633, 'Total loss': 0.18609986786266633}
2023-01-05 02:57:24,641 INFO:     Found new best model at epoch 60
2023-01-05 02:57:24,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:24,642 INFO:     Epoch: 61
2023-01-05 02:57:26,842 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4050844406088193, 'Total loss': 0.4050844406088193} | train loss {'Reaction outcome loss': 0.18044131485260886, 'Total loss': 0.18044131485260886}
2023-01-05 02:57:26,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:26,843 INFO:     Epoch: 62
2023-01-05 02:57:29,063 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3986110478639603, 'Total loss': 0.3986110478639603} | train loss {'Reaction outcome loss': 0.1861453971402522, 'Total loss': 0.1861453971402522}
2023-01-05 02:57:29,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:29,063 INFO:     Epoch: 63
2023-01-05 02:57:31,265 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4111619144678116, 'Total loss': 0.4111619144678116} | train loss {'Reaction outcome loss': 0.18303928890985338, 'Total loss': 0.18303928890985338}
2023-01-05 02:57:31,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:31,265 INFO:     Epoch: 64
2023-01-05 02:57:33,493 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40508121252059937, 'Total loss': 0.40508121252059937} | train loss {'Reaction outcome loss': 0.18218153677607848, 'Total loss': 0.18218153677607848}
2023-01-05 02:57:33,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:33,493 INFO:     Epoch: 65
2023-01-05 02:57:35,705 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39434503217538197, 'Total loss': 0.39434503217538197} | train loss {'Reaction outcome loss': 0.1776197409315287, 'Total loss': 0.1776197409315287}
2023-01-05 02:57:35,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:35,705 INFO:     Epoch: 66
2023-01-05 02:57:37,928 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41762941765288514, 'Total loss': 0.41762941765288514} | train loss {'Reaction outcome loss': 0.17702196460838118, 'Total loss': 0.17702196460838118}
2023-01-05 02:57:37,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:37,928 INFO:     Epoch: 67
2023-01-05 02:57:40,158 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4029713024695714, 'Total loss': 0.4029713024695714} | train loss {'Reaction outcome loss': 0.17592730031318063, 'Total loss': 0.17592730031318063}
2023-01-05 02:57:40,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:40,159 INFO:     Epoch: 68
2023-01-05 02:57:42,363 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4286891902486483, 'Total loss': 0.4286891902486483} | train loss {'Reaction outcome loss': 0.17762909907738478, 'Total loss': 0.17762909907738478}
2023-01-05 02:57:42,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:42,364 INFO:     Epoch: 69
2023-01-05 02:57:44,595 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4055660794178645, 'Total loss': 0.4055660794178645} | train loss {'Reaction outcome loss': 0.17359520072943016, 'Total loss': 0.17359520072943016}
2023-01-05 02:57:44,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:44,595 INFO:     Epoch: 70
2023-01-05 02:57:46,815 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4404358963171641, 'Total loss': 0.4404358963171641} | train loss {'Reaction outcome loss': 0.17728451771436485, 'Total loss': 0.17728451771436485}
2023-01-05 02:57:46,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:46,815 INFO:     Epoch: 71
2023-01-05 02:57:49,042 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38423026412104566, 'Total loss': 0.38423026412104566} | train loss {'Reaction outcome loss': 0.17330404629951324, 'Total loss': 0.17330404629951324}
2023-01-05 02:57:49,042 INFO:     Found new best model at epoch 71
2023-01-05 02:57:49,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:49,043 INFO:     Epoch: 72
2023-01-05 02:57:51,232 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4246065114935239, 'Total loss': 0.4246065114935239} | train loss {'Reaction outcome loss': 0.1689757165932284, 'Total loss': 0.1689757165932284}
2023-01-05 02:57:51,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:51,232 INFO:     Epoch: 73
2023-01-05 02:57:53,443 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3698227564493815, 'Total loss': 0.3698227564493815} | train loss {'Reaction outcome loss': 0.17977767443069473, 'Total loss': 0.17977767443069473}
2023-01-05 02:57:53,444 INFO:     Found new best model at epoch 73
2023-01-05 02:57:53,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:53,445 INFO:     Epoch: 74
2023-01-05 02:57:55,683 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3936266221726934, 'Total loss': 0.3936266221726934} | train loss {'Reaction outcome loss': 0.17223937394636454, 'Total loss': 0.17223937394636454}
2023-01-05 02:57:55,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:55,683 INFO:     Epoch: 75
2023-01-05 02:57:57,922 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42251009742418927, 'Total loss': 0.42251009742418927} | train loss {'Reaction outcome loss': 0.1711167975946333, 'Total loss': 0.1711167975946333}
2023-01-05 02:57:57,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:57:57,922 INFO:     Epoch: 76
2023-01-05 02:58:00,149 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4445969108802577, 'Total loss': 0.4445969108802577} | train loss {'Reaction outcome loss': 0.17019704280373377, 'Total loss': 0.17019704280373377}
2023-01-05 02:58:00,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:00,150 INFO:     Epoch: 77
2023-01-05 02:58:02,388 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3902378271023432, 'Total loss': 0.3902378271023432} | train loss {'Reaction outcome loss': 0.167645546547973, 'Total loss': 0.167645546547973}
2023-01-05 02:58:02,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:02,388 INFO:     Epoch: 78
2023-01-05 02:58:04,612 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44919311106204984, 'Total loss': 0.44919311106204984} | train loss {'Reaction outcome loss': 0.16498266277415166, 'Total loss': 0.16498266277415166}
2023-01-05 02:58:04,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:04,613 INFO:     Epoch: 79
2023-01-05 02:58:06,851 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43715563664833706, 'Total loss': 0.43715563664833706} | train loss {'Reaction outcome loss': 0.17126391881619726, 'Total loss': 0.17126391881619726}
2023-01-05 02:58:06,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:06,852 INFO:     Epoch: 80
2023-01-05 02:58:09,088 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4058203833022465, 'Total loss': 0.4058203833022465} | train loss {'Reaction outcome loss': 0.16917134192345779, 'Total loss': 0.16917134192345779}
2023-01-05 02:58:09,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:09,088 INFO:     Epoch: 81
2023-01-05 02:58:11,325 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41997714936733244, 'Total loss': 0.41997714936733244} | train loss {'Reaction outcome loss': 0.17068844546406997, 'Total loss': 0.17068844546406997}
2023-01-05 02:58:11,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:11,325 INFO:     Epoch: 82
2023-01-05 02:58:13,572 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40917515257994336, 'Total loss': 0.40917515257994336} | train loss {'Reaction outcome loss': 0.16989157888049009, 'Total loss': 0.16989157888049009}
2023-01-05 02:58:13,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:13,572 INFO:     Epoch: 83
2023-01-05 02:58:15,759 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40300382673740387, 'Total loss': 0.40300382673740387} | train loss {'Reaction outcome loss': 0.16857731184963096, 'Total loss': 0.16857731184963096}
2023-01-05 02:58:15,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:15,759 INFO:     Epoch: 84
2023-01-05 02:58:18,034 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4168541083733241, 'Total loss': 0.4168541083733241} | train loss {'Reaction outcome loss': 0.16346123765458118, 'Total loss': 0.16346123765458118}
2023-01-05 02:58:18,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:18,034 INFO:     Epoch: 85
2023-01-05 02:58:20,304 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4198090041677157, 'Total loss': 0.4198090041677157} | train loss {'Reaction outcome loss': 0.16934751805545756, 'Total loss': 0.16934751805545756}
2023-01-05 02:58:20,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:20,305 INFO:     Epoch: 86
2023-01-05 02:58:22,493 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39346995105346044, 'Total loss': 0.39346995105346044} | train loss {'Reaction outcome loss': 0.16367293087229978, 'Total loss': 0.16367293087229978}
2023-01-05 02:58:22,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:22,495 INFO:     Epoch: 87
2023-01-05 02:58:24,701 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4083128609190074, 'Total loss': 0.4083128609190074} | train loss {'Reaction outcome loss': 0.1634329806163825, 'Total loss': 0.1634329806163825}
2023-01-05 02:58:24,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:24,701 INFO:     Epoch: 88
2023-01-05 02:58:26,892 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37044524202744167, 'Total loss': 0.37044524202744167} | train loss {'Reaction outcome loss': 0.1585141600522421, 'Total loss': 0.1585141600522421}
2023-01-05 02:58:26,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:26,892 INFO:     Epoch: 89
2023-01-05 02:58:29,088 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38210179631908736, 'Total loss': 0.38210179631908736} | train loss {'Reaction outcome loss': 0.166354373399332, 'Total loss': 0.166354373399332}
2023-01-05 02:58:29,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:29,089 INFO:     Epoch: 90
2023-01-05 02:58:31,242 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4608318328857422, 'Total loss': 0.4608318328857422} | train loss {'Reaction outcome loss': 0.16246699184373758, 'Total loss': 0.16246699184373758}
2023-01-05 02:58:31,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:31,242 INFO:     Epoch: 91
2023-01-05 02:58:33,458 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4398457556962967, 'Total loss': 0.4398457556962967} | train loss {'Reaction outcome loss': 0.15664904673443936, 'Total loss': 0.15664904673443936}
2023-01-05 02:58:33,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:33,459 INFO:     Epoch: 92
2023-01-05 02:58:35,677 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4673243155082067, 'Total loss': 0.4673243155082067} | train loss {'Reaction outcome loss': 0.15754710345088943, 'Total loss': 0.15754710345088943}
2023-01-05 02:58:35,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:35,677 INFO:     Epoch: 93
2023-01-05 02:58:37,899 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.405708110332489, 'Total loss': 0.405708110332489} | train loss {'Reaction outcome loss': 0.15307513177360751, 'Total loss': 0.15307513177360751}
2023-01-05 02:58:37,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:37,900 INFO:     Epoch: 94
2023-01-05 02:58:40,114 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37984942449256776, 'Total loss': 0.37984942449256776} | train loss {'Reaction outcome loss': 0.15763215340960485, 'Total loss': 0.15763215340960485}
2023-01-05 02:58:40,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:40,114 INFO:     Epoch: 95
2023-01-05 02:58:42,337 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3698511521021525, 'Total loss': 0.3698511521021525} | train loss {'Reaction outcome loss': 0.16265536124575816, 'Total loss': 0.16265536124575816}
2023-01-05 02:58:42,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:42,338 INFO:     Epoch: 96
2023-01-05 02:58:44,522 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3878008748094241, 'Total loss': 0.3878008748094241} | train loss {'Reaction outcome loss': 0.1598345560905261, 'Total loss': 0.1598345560905261}
2023-01-05 02:58:44,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:44,522 INFO:     Epoch: 97
2023-01-05 02:58:46,723 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4147254263361295, 'Total loss': 0.4147254263361295} | train loss {'Reaction outcome loss': 0.15850783088977957, 'Total loss': 0.15850783088977957}
2023-01-05 02:58:46,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:46,723 INFO:     Epoch: 98
2023-01-05 02:58:48,950 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3826087774243206, 'Total loss': 0.3826087774243206} | train loss {'Reaction outcome loss': 0.1626947901788212, 'Total loss': 0.1626947901788212}
2023-01-05 02:58:48,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:48,951 INFO:     Epoch: 99
2023-01-05 02:58:51,151 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3562577991435925, 'Total loss': 0.3562577991435925} | train loss {'Reaction outcome loss': 0.1573170817017064, 'Total loss': 0.1573170817017064}
2023-01-05 02:58:51,151 INFO:     Found new best model at epoch 99
2023-01-05 02:58:51,153 INFO:     Best model found after epoch 100 of 100.
2023-01-05 02:58:51,153 INFO:   Done with stage: TRAINING
2023-01-05 02:58:51,153 INFO:   Starting stage: EVALUATION
2023-01-05 02:58:51,298 INFO:   Done with stage: EVALUATION
2023-01-05 02:58:51,298 INFO:   Leaving out SEQ value Fold_4
2023-01-05 02:58:51,311 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 02:58:51,311 INFO:   Starting stage: FEATURE SCALING
2023-01-05 02:58:51,948 INFO:   Done with stage: FEATURE SCALING
2023-01-05 02:58:51,948 INFO:   Starting stage: SCALING TARGETS
2023-01-05 02:58:52,017 INFO:   Done with stage: SCALING TARGETS
2023-01-05 02:58:52,017 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:58:52,017 INFO:     No hyperparam tuning for this model
2023-01-05 02:58:52,017 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 02:58:52,017 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 02:58:52,018 INFO:     None feature selector for col prot
2023-01-05 02:58:52,018 INFO:     None feature selector for col prot
2023-01-05 02:58:52,018 INFO:     None feature selector for col prot
2023-01-05 02:58:52,018 INFO:     None feature selector for col chem
2023-01-05 02:58:52,018 INFO:     None feature selector for col chem
2023-01-05 02:58:52,019 INFO:     None feature selector for col chem
2023-01-05 02:58:52,019 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 02:58:52,019 INFO:   Starting stage: BUILD MODEL
2023-01-05 02:58:52,020 INFO:     Number of params in model 72931
2023-01-05 02:58:52,023 INFO:   Done with stage: BUILD MODEL
2023-01-05 02:58:52,023 INFO:   Starting stage: TRAINING
2023-01-05 02:58:52,084 INFO:     Val loss before train {'Reaction outcome loss': 1.050298774242401, 'Total loss': 1.050298774242401}
2023-01-05 02:58:52,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:52,084 INFO:     Epoch: 0
2023-01-05 02:58:54,322 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7746165295441946, 'Total loss': 0.7746165295441946} | train loss {'Reaction outcome loss': 0.9435003584493762, 'Total loss': 0.9435003584493762}
2023-01-05 02:58:54,322 INFO:     Found new best model at epoch 0
2023-01-05 02:58:54,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:54,324 INFO:     Epoch: 1
2023-01-05 02:58:56,566 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5333098292350769, 'Total loss': 0.5333098292350769} | train loss {'Reaction outcome loss': 0.617130692994249, 'Total loss': 0.617130692994249}
2023-01-05 02:58:56,566 INFO:     Found new best model at epoch 1
2023-01-05 02:58:56,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:56,567 INFO:     Epoch: 2
2023-01-05 02:58:58,803 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49770723978678383, 'Total loss': 0.49770723978678383} | train loss {'Reaction outcome loss': 0.5379258398830459, 'Total loss': 0.5379258398830459}
2023-01-05 02:58:58,805 INFO:     Found new best model at epoch 2
2023-01-05 02:58:58,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:58:58,806 INFO:     Epoch: 3
2023-01-05 02:59:01,062 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4857411781946818, 'Total loss': 0.4857411781946818} | train loss {'Reaction outcome loss': 0.5034239148262186, 'Total loss': 0.5034239148262186}
2023-01-05 02:59:01,062 INFO:     Found new best model at epoch 3
2023-01-05 02:59:01,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:01,063 INFO:     Epoch: 4
2023-01-05 02:59:03,276 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4534588545560837, 'Total loss': 0.4534588545560837} | train loss {'Reaction outcome loss': 0.47751939653054526, 'Total loss': 0.47751939653054526}
2023-01-05 02:59:03,276 INFO:     Found new best model at epoch 4
2023-01-05 02:59:03,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:03,277 INFO:     Epoch: 5
2023-01-05 02:59:05,529 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4483265221118927, 'Total loss': 0.4483265221118927} | train loss {'Reaction outcome loss': 0.4582014697396358, 'Total loss': 0.4582014697396358}
2023-01-05 02:59:05,530 INFO:     Found new best model at epoch 5
2023-01-05 02:59:05,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:05,531 INFO:     Epoch: 6
2023-01-05 02:59:07,764 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4467592626810074, 'Total loss': 0.4467592626810074} | train loss {'Reaction outcome loss': 0.4401019432487479, 'Total loss': 0.4401019432487479}
2023-01-05 02:59:07,764 INFO:     Found new best model at epoch 6
2023-01-05 02:59:07,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:07,766 INFO:     Epoch: 7
2023-01-05 02:59:10,012 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4375201423962911, 'Total loss': 0.4375201423962911} | train loss {'Reaction outcome loss': 0.4301789545440271, 'Total loss': 0.4301789545440271}
2023-01-05 02:59:10,012 INFO:     Found new best model at epoch 7
2023-01-05 02:59:10,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:10,013 INFO:     Epoch: 8
2023-01-05 02:59:12,261 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4163321117560069, 'Total loss': 0.4163321117560069} | train loss {'Reaction outcome loss': 0.4188685104498923, 'Total loss': 0.4188685104498923}
2023-01-05 02:59:12,261 INFO:     Found new best model at epoch 8
2023-01-05 02:59:12,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:12,262 INFO:     Epoch: 9
2023-01-05 02:59:14,457 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42506674031416575, 'Total loss': 0.42506674031416575} | train loss {'Reaction outcome loss': 0.40459000240451237, 'Total loss': 0.40459000240451237}
2023-01-05 02:59:14,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:14,457 INFO:     Epoch: 10
2023-01-05 02:59:16,690 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4252570331096649, 'Total loss': 0.4252570331096649} | train loss {'Reaction outcome loss': 0.4099179550573446, 'Total loss': 0.4099179550573446}
2023-01-05 02:59:16,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:16,691 INFO:     Epoch: 11
2023-01-05 02:59:18,936 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4088724235693614, 'Total loss': 0.4088724235693614} | train loss {'Reaction outcome loss': 0.39750965976850566, 'Total loss': 0.39750965976850566}
2023-01-05 02:59:18,937 INFO:     Found new best model at epoch 11
2023-01-05 02:59:18,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:18,939 INFO:     Epoch: 12
2023-01-05 02:59:21,172 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4092868611216545, 'Total loss': 0.4092868611216545} | train loss {'Reaction outcome loss': 0.40590424536039, 'Total loss': 0.40590424536039}
2023-01-05 02:59:21,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:21,173 INFO:     Epoch: 13
2023-01-05 02:59:23,386 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40760457664728167, 'Total loss': 0.40760457664728167} | train loss {'Reaction outcome loss': 0.37494806174283335, 'Total loss': 0.37494806174283335}
2023-01-05 02:59:23,386 INFO:     Found new best model at epoch 13
2023-01-05 02:59:23,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:23,387 INFO:     Epoch: 14
2023-01-05 02:59:25,624 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4099016765753428, 'Total loss': 0.4099016765753428} | train loss {'Reaction outcome loss': 0.3623342494589135, 'Total loss': 0.3623342494589135}
2023-01-05 02:59:25,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:25,624 INFO:     Epoch: 15
2023-01-05 02:59:27,869 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3975851505994797, 'Total loss': 0.3975851505994797} | train loss {'Reaction outcome loss': 0.353001085481188, 'Total loss': 0.353001085481188}
2023-01-05 02:59:27,869 INFO:     Found new best model at epoch 15
2023-01-05 02:59:27,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:27,871 INFO:     Epoch: 16
2023-01-05 02:59:30,115 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38410457968711853, 'Total loss': 0.38410457968711853} | train loss {'Reaction outcome loss': 0.3492810052405769, 'Total loss': 0.3492810052405769}
2023-01-05 02:59:30,115 INFO:     Found new best model at epoch 16
2023-01-05 02:59:30,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:30,116 INFO:     Epoch: 17
2023-01-05 02:59:32,362 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38986708720525104, 'Total loss': 0.38986708720525104} | train loss {'Reaction outcome loss': 0.36340820994498074, 'Total loss': 0.36340820994498074}
2023-01-05 02:59:32,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:32,362 INFO:     Epoch: 18
2023-01-05 02:59:34,595 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39725434631109235, 'Total loss': 0.39725434631109235} | train loss {'Reaction outcome loss': 0.33437740433272783, 'Total loss': 0.33437740433272783}
2023-01-05 02:59:34,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:34,597 INFO:     Epoch: 19
2023-01-05 02:59:36,806 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39537802239259084, 'Total loss': 0.39537802239259084} | train loss {'Reaction outcome loss': 0.3278177176143272, 'Total loss': 0.3278177176143272}
2023-01-05 02:59:36,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:36,807 INFO:     Epoch: 20
2023-01-05 02:59:39,053 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3789195368687312, 'Total loss': 0.3789195368687312} | train loss {'Reaction outcome loss': 0.3187822896373067, 'Total loss': 0.3187822896373067}
2023-01-05 02:59:39,053 INFO:     Found new best model at epoch 20
2023-01-05 02:59:39,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:39,054 INFO:     Epoch: 21
2023-01-05 02:59:41,279 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37618268430233004, 'Total loss': 0.37618268430233004} | train loss {'Reaction outcome loss': 0.3073757438097095, 'Total loss': 0.3073757438097095}
2023-01-05 02:59:41,280 INFO:     Found new best model at epoch 21
2023-01-05 02:59:41,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:41,281 INFO:     Epoch: 22
2023-01-05 02:59:43,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38864640692869823, 'Total loss': 0.38864640692869823} | train loss {'Reaction outcome loss': 0.30484060946767294, 'Total loss': 0.30484060946767294}
2023-01-05 02:59:43,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:43,496 INFO:     Epoch: 23
2023-01-05 02:59:45,703 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37104903186360993, 'Total loss': 0.37104903186360993} | train loss {'Reaction outcome loss': 0.3001810086256676, 'Total loss': 0.3001810086256676}
2023-01-05 02:59:45,703 INFO:     Found new best model at epoch 23
2023-01-05 02:59:45,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:45,704 INFO:     Epoch: 24
2023-01-05 02:59:47,928 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3920506169398626, 'Total loss': 0.3920506169398626} | train loss {'Reaction outcome loss': 0.29054820287850375, 'Total loss': 0.29054820287850375}
2023-01-05 02:59:47,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:47,928 INFO:     Epoch: 25
2023-01-05 02:59:50,142 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3825010279814402, 'Total loss': 0.3825010279814402} | train loss {'Reaction outcome loss': 0.2869318104619025, 'Total loss': 0.2869318104619025}
2023-01-05 02:59:50,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:50,142 INFO:     Epoch: 26
2023-01-05 02:59:52,394 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3739646231134733, 'Total loss': 0.3739646231134733} | train loss {'Reaction outcome loss': 0.28460511932338495, 'Total loss': 0.28460511932338495}
2023-01-05 02:59:52,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:52,394 INFO:     Epoch: 27
2023-01-05 02:59:54,664 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38679064214229586, 'Total loss': 0.38679064214229586} | train loss {'Reaction outcome loss': 0.28126656400981237, 'Total loss': 0.28126656400981237}
2023-01-05 02:59:54,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:54,665 INFO:     Epoch: 28
2023-01-05 02:59:56,906 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36858670512835184, 'Total loss': 0.36858670512835184} | train loss {'Reaction outcome loss': 0.2688387596196886, 'Total loss': 0.2688387596196886}
2023-01-05 02:59:56,906 INFO:     Found new best model at epoch 28
2023-01-05 02:59:56,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:56,907 INFO:     Epoch: 29
2023-01-05 02:59:59,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3922051390012105, 'Total loss': 0.3922051390012105} | train loss {'Reaction outcome loss': 0.2699277855647159, 'Total loss': 0.2699277855647159}
2023-01-05 02:59:59,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 02:59:59,132 INFO:     Epoch: 30
2023-01-05 03:00:01,347 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3750825854639212, 'Total loss': 0.3750825854639212} | train loss {'Reaction outcome loss': 0.26898329013931577, 'Total loss': 0.26898329013931577}
2023-01-05 03:00:01,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:01,347 INFO:     Epoch: 31
2023-01-05 03:00:03,572 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39046323398749033, 'Total loss': 0.39046323398749033} | train loss {'Reaction outcome loss': 0.2616184946247444, 'Total loss': 0.2616184946247444}
2023-01-05 03:00:03,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:03,573 INFO:     Epoch: 32
2023-01-05 03:00:05,821 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3885329777995745, 'Total loss': 0.3885329777995745} | train loss {'Reaction outcome loss': 0.26162762057873, 'Total loss': 0.26162762057873}
2023-01-05 03:00:05,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:05,822 INFO:     Epoch: 33
2023-01-05 03:00:08,056 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38078427612781524, 'Total loss': 0.38078427612781524} | train loss {'Reaction outcome loss': 0.26924830851604004, 'Total loss': 0.26924830851604004}
2023-01-05 03:00:08,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:08,056 INFO:     Epoch: 34
2023-01-05 03:00:10,310 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35586823529253403, 'Total loss': 0.35586823529253403} | train loss {'Reaction outcome loss': 0.27967322629242053, 'Total loss': 0.27967322629242053}
2023-01-05 03:00:10,311 INFO:     Found new best model at epoch 34
2023-01-05 03:00:10,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:10,313 INFO:     Epoch: 35
2023-01-05 03:00:12,488 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3851947098970413, 'Total loss': 0.3851947098970413} | train loss {'Reaction outcome loss': 0.2492075544339942, 'Total loss': 0.2492075544339942}
2023-01-05 03:00:12,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:12,488 INFO:     Epoch: 36
2023-01-05 03:00:14,638 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3566821879552056, 'Total loss': 0.3566821879552056} | train loss {'Reaction outcome loss': 0.24755931571501383, 'Total loss': 0.24755931571501383}
2023-01-05 03:00:14,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:14,638 INFO:     Epoch: 37
2023-01-05 03:00:16,800 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36078670918941497, 'Total loss': 0.36078670918941497} | train loss {'Reaction outcome loss': 0.24115900692961895, 'Total loss': 0.24115900692961895}
2023-01-05 03:00:16,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:16,801 INFO:     Epoch: 38
2023-01-05 03:00:19,035 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36518613000710803, 'Total loss': 0.36518613000710803} | train loss {'Reaction outcome loss': 0.24082463710953522, 'Total loss': 0.24082463710953522}
2023-01-05 03:00:19,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:19,035 INFO:     Epoch: 39
2023-01-05 03:00:21,261 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38143647511800133, 'Total loss': 0.38143647511800133} | train loss {'Reaction outcome loss': 0.24430602464312012, 'Total loss': 0.24430602464312012}
2023-01-05 03:00:21,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:21,261 INFO:     Epoch: 40
2023-01-05 03:00:23,490 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39979631106058755, 'Total loss': 0.39979631106058755} | train loss {'Reaction outcome loss': 0.23718471603765004, 'Total loss': 0.23718471603765004}
2023-01-05 03:00:23,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:23,490 INFO:     Epoch: 41
2023-01-05 03:00:25,714 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3644937733809153, 'Total loss': 0.3644937733809153} | train loss {'Reaction outcome loss': 0.23574270692388646, 'Total loss': 0.23574270692388646}
2023-01-05 03:00:25,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:25,714 INFO:     Epoch: 42
2023-01-05 03:00:27,963 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.368073237935702, 'Total loss': 0.368073237935702} | train loss {'Reaction outcome loss': 0.2325397632303593, 'Total loss': 0.2325397632303593}
2023-01-05 03:00:27,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:27,963 INFO:     Epoch: 43
2023-01-05 03:00:30,117 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35140974124272667, 'Total loss': 0.35140974124272667} | train loss {'Reaction outcome loss': 0.2333885605878912, 'Total loss': 0.2333885605878912}
2023-01-05 03:00:30,118 INFO:     Found new best model at epoch 43
2023-01-05 03:00:30,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:30,119 INFO:     Epoch: 44
2023-01-05 03:00:32,344 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38376962145169574, 'Total loss': 0.38376962145169574} | train loss {'Reaction outcome loss': 0.23032029721413722, 'Total loss': 0.23032029721413722}
2023-01-05 03:00:32,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:32,344 INFO:     Epoch: 45
2023-01-05 03:00:34,581 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3933946092923482, 'Total loss': 0.3933946092923482} | train loss {'Reaction outcome loss': 0.23126067239913475, 'Total loss': 0.23126067239913475}
2023-01-05 03:00:34,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:34,581 INFO:     Epoch: 46
2023-01-05 03:00:36,841 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37347524364789325, 'Total loss': 0.37347524364789325} | train loss {'Reaction outcome loss': 0.22238329621293393, 'Total loss': 0.22238329621293393}
2023-01-05 03:00:36,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:36,841 INFO:     Epoch: 47
2023-01-05 03:00:39,094 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3871944010257721, 'Total loss': 0.3871944010257721} | train loss {'Reaction outcome loss': 0.22560332669620065, 'Total loss': 0.22560332669620065}
2023-01-05 03:00:39,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:39,094 INFO:     Epoch: 48
2023-01-05 03:00:41,345 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37532945970694226, 'Total loss': 0.37532945970694226} | train loss {'Reaction outcome loss': 0.25505526813060936, 'Total loss': 0.25505526813060936}
2023-01-05 03:00:41,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:41,345 INFO:     Epoch: 49
2023-01-05 03:00:43,564 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3850858042637507, 'Total loss': 0.3850858042637507} | train loss {'Reaction outcome loss': 0.22186191447004946, 'Total loss': 0.22186191447004946}
2023-01-05 03:00:43,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:43,565 INFO:     Epoch: 50
2023-01-05 03:00:45,772 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3786535789569219, 'Total loss': 0.3786535789569219} | train loss {'Reaction outcome loss': 0.21510633041079796, 'Total loss': 0.21510633041079796}
2023-01-05 03:00:45,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:45,774 INFO:     Epoch: 51
2023-01-05 03:00:48,009 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38222114543120067, 'Total loss': 0.38222114543120067} | train loss {'Reaction outcome loss': 0.2130581729731563, 'Total loss': 0.2130581729731563}
2023-01-05 03:00:48,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:48,010 INFO:     Epoch: 52
2023-01-05 03:00:50,258 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3805869420369466, 'Total loss': 0.3805869420369466} | train loss {'Reaction outcome loss': 0.21870166057234872, 'Total loss': 0.21870166057234872}
2023-01-05 03:00:50,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:50,259 INFO:     Epoch: 53
2023-01-05 03:00:52,467 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3822451348726948, 'Total loss': 0.3822451348726948} | train loss {'Reaction outcome loss': 0.2182141347143772, 'Total loss': 0.2182141347143772}
2023-01-05 03:00:52,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:52,468 INFO:     Epoch: 54
2023-01-05 03:00:54,709 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36980651517709096, 'Total loss': 0.36980651517709096} | train loss {'Reaction outcome loss': 0.21123689820803743, 'Total loss': 0.21123689820803743}
2023-01-05 03:00:54,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:54,710 INFO:     Epoch: 55
2023-01-05 03:00:56,958 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4057119031747182, 'Total loss': 0.4057119031747182} | train loss {'Reaction outcome loss': 0.20482924302010308, 'Total loss': 0.20482924302010308}
2023-01-05 03:00:56,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:56,958 INFO:     Epoch: 56
2023-01-05 03:00:59,195 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3822047024965286, 'Total loss': 0.3822047024965286} | train loss {'Reaction outcome loss': 0.2121615577455394, 'Total loss': 0.2121615577455394}
2023-01-05 03:00:59,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:00:59,195 INFO:     Epoch: 57
2023-01-05 03:01:01,438 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4004285251100858, 'Total loss': 0.4004285251100858} | train loss {'Reaction outcome loss': 0.20759481737015606, 'Total loss': 0.20759481737015606}
2023-01-05 03:01:01,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:01,439 INFO:     Epoch: 58
2023-01-05 03:01:03,696 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3792595108350118, 'Total loss': 0.3792595108350118} | train loss {'Reaction outcome loss': 0.2049952874593251, 'Total loss': 0.2049952874593251}
2023-01-05 03:01:03,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:03,697 INFO:     Epoch: 59
2023-01-05 03:01:05,958 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42297276059786476, 'Total loss': 0.42297276059786476} | train loss {'Reaction outcome loss': 0.20115495732655594, 'Total loss': 0.20115495732655594}
2023-01-05 03:01:05,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:05,959 INFO:     Epoch: 60
2023-01-05 03:01:08,194 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39423098663489026, 'Total loss': 0.39423098663489026} | train loss {'Reaction outcome loss': 0.19793849998993962, 'Total loss': 0.19793849998993962}
2023-01-05 03:01:08,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:08,194 INFO:     Epoch: 61
2023-01-05 03:01:10,452 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.397042960425218, 'Total loss': 0.397042960425218} | train loss {'Reaction outcome loss': 0.197613485282341, 'Total loss': 0.197613485282341}
2023-01-05 03:01:10,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:10,452 INFO:     Epoch: 62
2023-01-05 03:01:12,541 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4130906769850602, 'Total loss': 0.4130906769850602} | train loss {'Reaction outcome loss': 0.19882186851973002, 'Total loss': 0.19882186851973002}
2023-01-05 03:01:12,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:12,542 INFO:     Epoch: 63
2023-01-05 03:01:14,773 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3856624944756428, 'Total loss': 0.3856624944756428} | train loss {'Reaction outcome loss': 0.19273195030046222, 'Total loss': 0.19273195030046222}
2023-01-05 03:01:14,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:14,774 INFO:     Epoch: 64
2023-01-05 03:01:17,030 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4120962460835775, 'Total loss': 0.4120962460835775} | train loss {'Reaction outcome loss': 0.19457268548886414, 'Total loss': 0.19457268548886414}
2023-01-05 03:01:17,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:17,030 INFO:     Epoch: 65
2023-01-05 03:01:19,259 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4255586887399356, 'Total loss': 0.4255586887399356} | train loss {'Reaction outcome loss': 0.1951494435256725, 'Total loss': 0.1951494435256725}
2023-01-05 03:01:19,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:19,259 INFO:     Epoch: 66
2023-01-05 03:01:21,513 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41908453901608783, 'Total loss': 0.41908453901608783} | train loss {'Reaction outcome loss': 0.19620919577689652, 'Total loss': 0.19620919577689652}
2023-01-05 03:01:21,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:21,514 INFO:     Epoch: 67
2023-01-05 03:01:23,779 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38988049030303956, 'Total loss': 0.38988049030303956} | train loss {'Reaction outcome loss': 0.1935192380514691, 'Total loss': 0.1935192380514691}
2023-01-05 03:01:23,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:23,779 INFO:     Epoch: 68
2023-01-05 03:01:26,033 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4011114607254664, 'Total loss': 0.4011114607254664} | train loss {'Reaction outcome loss': 0.1897665990176577, 'Total loss': 0.1897665990176577}
2023-01-05 03:01:26,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:26,033 INFO:     Epoch: 69
2023-01-05 03:01:28,296 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3832060764233271, 'Total loss': 0.3832060764233271} | train loss {'Reaction outcome loss': 0.18650311664543182, 'Total loss': 0.18650311664543182}
2023-01-05 03:01:28,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:28,297 INFO:     Epoch: 70
2023-01-05 03:01:30,539 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3774322251478831, 'Total loss': 0.3774322251478831} | train loss {'Reaction outcome loss': 0.1919497510239455, 'Total loss': 0.1919497510239455}
2023-01-05 03:01:30,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:30,540 INFO:     Epoch: 71
2023-01-05 03:01:32,767 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3918963676939408, 'Total loss': 0.3918963676939408} | train loss {'Reaction outcome loss': 0.1886758912840615, 'Total loss': 0.1886758912840615}
2023-01-05 03:01:32,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:32,768 INFO:     Epoch: 72
2023-01-05 03:01:35,025 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39649144833286604, 'Total loss': 0.39649144833286604} | train loss {'Reaction outcome loss': 0.19008770355435115, 'Total loss': 0.19008770355435115}
2023-01-05 03:01:35,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:35,025 INFO:     Epoch: 73
2023-01-05 03:01:37,294 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3805692865823706, 'Total loss': 0.3805692865823706} | train loss {'Reaction outcome loss': 0.18569789656085314, 'Total loss': 0.18569789656085314}
2023-01-05 03:01:37,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:37,294 INFO:     Epoch: 74
2023-01-05 03:01:39,561 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40951479226350784, 'Total loss': 0.40951479226350784} | train loss {'Reaction outcome loss': 0.18374935673225834, 'Total loss': 0.18374935673225834}
2023-01-05 03:01:39,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:39,561 INFO:     Epoch: 75
2023-01-05 03:01:41,795 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3899749909217159, 'Total loss': 0.3899749909217159} | train loss {'Reaction outcome loss': 0.18631373488081052, 'Total loss': 0.18631373488081052}
2023-01-05 03:01:41,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:41,796 INFO:     Epoch: 76
2023-01-05 03:01:44,026 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3790639651318391, 'Total loss': 0.3790639651318391} | train loss {'Reaction outcome loss': 0.18385592346637655, 'Total loss': 0.18385592346637655}
2023-01-05 03:01:44,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:44,027 INFO:     Epoch: 77
2023-01-05 03:01:46,291 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.394767955566446, 'Total loss': 0.394767955566446} | train loss {'Reaction outcome loss': 0.1880270473218685, 'Total loss': 0.1880270473218685}
2023-01-05 03:01:46,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:46,291 INFO:     Epoch: 78
2023-01-05 03:01:48,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4218079348405202, 'Total loss': 0.4218079348405202} | train loss {'Reaction outcome loss': 0.18406081032325333, 'Total loss': 0.18406081032325333}
2023-01-05 03:01:48,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:48,563 INFO:     Epoch: 79
2023-01-05 03:01:50,843 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46636881430943805, 'Total loss': 0.46636881430943805} | train loss {'Reaction outcome loss': 0.1830537723945926, 'Total loss': 0.1830537723945926}
2023-01-05 03:01:50,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:50,843 INFO:     Epoch: 80
2023-01-05 03:01:53,106 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.432795974612236, 'Total loss': 0.432795974612236} | train loss {'Reaction outcome loss': 0.1797077097181682, 'Total loss': 0.1797077097181682}
2023-01-05 03:01:53,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:53,107 INFO:     Epoch: 81
2023-01-05 03:01:55,343 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40460314210504295, 'Total loss': 0.40460314210504295} | train loss {'Reaction outcome loss': 0.17883326633233557, 'Total loss': 0.17883326633233557}
2023-01-05 03:01:55,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:55,344 INFO:     Epoch: 82
2023-01-05 03:01:57,603 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38004609396060307, 'Total loss': 0.38004609396060307} | train loss {'Reaction outcome loss': 0.17921029203284558, 'Total loss': 0.17921029203284558}
2023-01-05 03:01:57,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:57,604 INFO:     Epoch: 83
2023-01-05 03:01:59,856 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42945956339438757, 'Total loss': 0.42945956339438757} | train loss {'Reaction outcome loss': 0.17616680401134427, 'Total loss': 0.17616680401134427}
2023-01-05 03:01:59,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:01:59,856 INFO:     Epoch: 84
2023-01-05 03:02:02,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40662747422854106, 'Total loss': 0.40662747422854106} | train loss {'Reaction outcome loss': 0.1877599468562698, 'Total loss': 0.1877599468562698}
2023-01-05 03:02:02,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:02,105 INFO:     Epoch: 85
2023-01-05 03:02:04,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40720613797505695, 'Total loss': 0.40720613797505695} | train loss {'Reaction outcome loss': 0.21712187397550198, 'Total loss': 0.21712187397550198}
2023-01-05 03:02:04,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:04,322 INFO:     Epoch: 86
2023-01-05 03:02:06,543 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4068540811538696, 'Total loss': 0.4068540811538696} | train loss {'Reaction outcome loss': 0.1874945236339216, 'Total loss': 0.1874945236339216}
2023-01-05 03:02:06,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:06,543 INFO:     Epoch: 87
2023-01-05 03:02:08,758 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40911406924327215, 'Total loss': 0.40911406924327215} | train loss {'Reaction outcome loss': 0.17894298734777755, 'Total loss': 0.17894298734777755}
2023-01-05 03:02:08,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:08,758 INFO:     Epoch: 88
2023-01-05 03:02:10,990 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40940486590067543, 'Total loss': 0.40940486590067543} | train loss {'Reaction outcome loss': 0.17903930379247868, 'Total loss': 0.17903930379247868}
2023-01-05 03:02:10,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:10,990 INFO:     Epoch: 89
2023-01-05 03:02:13,118 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41658296684424084, 'Total loss': 0.41658296684424084} | train loss {'Reaction outcome loss': 0.17295250438858772, 'Total loss': 0.17295250438858772}
2023-01-05 03:02:13,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:13,119 INFO:     Epoch: 90
2023-01-05 03:02:15,353 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4350349396467209, 'Total loss': 0.4350349396467209} | train loss {'Reaction outcome loss': 0.1744200431714779, 'Total loss': 0.1744200431714779}
2023-01-05 03:02:15,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:15,354 INFO:     Epoch: 91
2023-01-05 03:02:17,591 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4087907632191976, 'Total loss': 0.4087907632191976} | train loss {'Reaction outcome loss': 0.17354361830992907, 'Total loss': 0.17354361830992907}
2023-01-05 03:02:17,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:17,592 INFO:     Epoch: 92
2023-01-05 03:02:19,818 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39292257726192475, 'Total loss': 0.39292257726192475} | train loss {'Reaction outcome loss': 0.17381240557332986, 'Total loss': 0.17381240557332986}
2023-01-05 03:02:19,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:19,819 INFO:     Epoch: 93
2023-01-05 03:02:22,085 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.409427543481191, 'Total loss': 0.409427543481191} | train loss {'Reaction outcome loss': 0.17368430334781937, 'Total loss': 0.17368430334781937}
2023-01-05 03:02:22,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:22,085 INFO:     Epoch: 94
2023-01-05 03:02:24,361 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3912919414540132, 'Total loss': 0.3912919414540132} | train loss {'Reaction outcome loss': 0.17543828012118035, 'Total loss': 0.17543828012118035}
2023-01-05 03:02:24,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:24,362 INFO:     Epoch: 95
2023-01-05 03:02:26,620 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4394146978855133, 'Total loss': 0.4394146978855133} | train loss {'Reaction outcome loss': 0.17241468748305624, 'Total loss': 0.17241468748305624}
2023-01-05 03:02:26,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:26,620 INFO:     Epoch: 96
2023-01-05 03:02:28,841 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41601751099030176, 'Total loss': 0.41601751099030176} | train loss {'Reaction outcome loss': 0.16998220373373613, 'Total loss': 0.16998220373373613}
2023-01-05 03:02:28,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:28,841 INFO:     Epoch: 97
2023-01-05 03:02:31,049 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40245117247104645, 'Total loss': 0.40245117247104645} | train loss {'Reaction outcome loss': 0.16765631885315035, 'Total loss': 0.16765631885315035}
2023-01-05 03:02:31,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:31,049 INFO:     Epoch: 98
2023-01-05 03:02:33,295 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3795502041776975, 'Total loss': 0.3795502041776975} | train loss {'Reaction outcome loss': 0.17036992277396654, 'Total loss': 0.17036992277396654}
2023-01-05 03:02:33,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:33,296 INFO:     Epoch: 99
2023-01-05 03:02:35,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3699163007705162, 'Total loss': 0.3699163007705162} | train loss {'Reaction outcome loss': 0.17003746865636946, 'Total loss': 0.17003746865636946}
2023-01-05 03:02:35,540 INFO:     Best model found after epoch 44 of 100.
2023-01-05 03:02:35,541 INFO:   Done with stage: TRAINING
2023-01-05 03:02:35,541 INFO:   Starting stage: EVALUATION
2023-01-05 03:02:35,675 INFO:   Done with stage: EVALUATION
2023-01-05 03:02:35,675 INFO:   Leaving out SEQ value Fold_5
2023-01-05 03:02:35,687 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:02:35,687 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:02:36,329 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:02:36,329 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:02:36,398 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:02:36,398 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:02:36,398 INFO:     No hyperparam tuning for this model
2023-01-05 03:02:36,398 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:02:36,398 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:02:36,399 INFO:     None feature selector for col prot
2023-01-05 03:02:36,399 INFO:     None feature selector for col prot
2023-01-05 03:02:36,400 INFO:     None feature selector for col prot
2023-01-05 03:02:36,400 INFO:     None feature selector for col chem
2023-01-05 03:02:36,400 INFO:     None feature selector for col chem
2023-01-05 03:02:36,400 INFO:     None feature selector for col chem
2023-01-05 03:02:36,400 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:02:36,400 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:02:36,402 INFO:     Number of params in model 72931
2023-01-05 03:02:36,405 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:02:36,405 INFO:   Starting stage: TRAINING
2023-01-05 03:02:36,464 INFO:     Val loss before train {'Reaction outcome loss': 1.0456666827201844, 'Total loss': 1.0456666827201844}
2023-01-05 03:02:36,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:36,465 INFO:     Epoch: 0
2023-01-05 03:02:38,707 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7359699050585429, 'Total loss': 0.7359699050585429} | train loss {'Reaction outcome loss': 0.9394582428739987, 'Total loss': 0.9394582428739987}
2023-01-05 03:02:38,707 INFO:     Found new best model at epoch 0
2023-01-05 03:02:38,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:38,708 INFO:     Epoch: 1
2023-01-05 03:02:40,934 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5152212758858998, 'Total loss': 0.5152212758858998} | train loss {'Reaction outcome loss': 0.6068319806041815, 'Total loss': 0.6068319806041815}
2023-01-05 03:02:40,935 INFO:     Found new best model at epoch 1
2023-01-05 03:02:40,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:40,937 INFO:     Epoch: 2
2023-01-05 03:02:43,171 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4671094457308451, 'Total loss': 0.4671094457308451} | train loss {'Reaction outcome loss': 0.5320979933375898, 'Total loss': 0.5320979933375898}
2023-01-05 03:02:43,171 INFO:     Found new best model at epoch 2
2023-01-05 03:02:43,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:43,172 INFO:     Epoch: 3
2023-01-05 03:02:45,414 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43183156053225197, 'Total loss': 0.43183156053225197} | train loss {'Reaction outcome loss': 0.4887473372121652, 'Total loss': 0.4887473372121652}
2023-01-05 03:02:45,415 INFO:     Found new best model at epoch 3
2023-01-05 03:02:45,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:45,416 INFO:     Epoch: 4
2023-01-05 03:02:47,639 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.41172171433766686, 'Total loss': 0.41172171433766686} | train loss {'Reaction outcome loss': 0.46803656895307527, 'Total loss': 0.46803656895307527}
2023-01-05 03:02:47,639 INFO:     Found new best model at epoch 4
2023-01-05 03:02:47,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:47,640 INFO:     Epoch: 5
2023-01-05 03:02:49,895 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4176275779803594, 'Total loss': 0.4176275779803594} | train loss {'Reaction outcome loss': 0.4427685985945678, 'Total loss': 0.4427685985945678}
2023-01-05 03:02:49,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:49,896 INFO:     Epoch: 6
2023-01-05 03:02:52,126 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3902101695537567, 'Total loss': 0.3902101695537567} | train loss {'Reaction outcome loss': 0.41717025552592846, 'Total loss': 0.41717025552592846}
2023-01-05 03:02:52,126 INFO:     Found new best model at epoch 6
2023-01-05 03:02:52,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:52,128 INFO:     Epoch: 7
2023-01-05 03:02:54,369 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.408120725552241, 'Total loss': 0.408120725552241} | train loss {'Reaction outcome loss': 0.40849527749030484, 'Total loss': 0.40849527749030484}
2023-01-05 03:02:54,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:54,370 INFO:     Epoch: 8
2023-01-05 03:02:56,628 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37496230006217957, 'Total loss': 0.37496230006217957} | train loss {'Reaction outcome loss': 0.4158188384026289, 'Total loss': 0.4158188384026289}
2023-01-05 03:02:56,629 INFO:     Found new best model at epoch 8
2023-01-05 03:02:56,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:56,630 INFO:     Epoch: 9
2023-01-05 03:02:58,903 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3689212332169215, 'Total loss': 0.3689212332169215} | train loss {'Reaction outcome loss': 0.3772530072922076, 'Total loss': 0.3772530072922076}
2023-01-05 03:02:58,903 INFO:     Found new best model at epoch 9
2023-01-05 03:02:58,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:02:58,904 INFO:     Epoch: 10
2023-01-05 03:03:01,110 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35694621205329896, 'Total loss': 0.35694621205329896} | train loss {'Reaction outcome loss': 0.3697576082169848, 'Total loss': 0.3697576082169848}
2023-01-05 03:03:01,110 INFO:     Found new best model at epoch 10
2023-01-05 03:03:01,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:01,112 INFO:     Epoch: 11
2023-01-05 03:03:03,366 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3850071499745051, 'Total loss': 0.3850071499745051} | train loss {'Reaction outcome loss': 0.36010636750986613, 'Total loss': 0.36010636750986613}
2023-01-05 03:03:03,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:03,366 INFO:     Epoch: 12
2023-01-05 03:03:05,578 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3418451637029648, 'Total loss': 0.3418451637029648} | train loss {'Reaction outcome loss': 0.35464323737888015, 'Total loss': 0.35464323737888015}
2023-01-05 03:03:05,578 INFO:     Found new best model at epoch 12
2023-01-05 03:03:05,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:05,580 INFO:     Epoch: 13
2023-01-05 03:03:07,821 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36049716770648954, 'Total loss': 0.36049716770648954} | train loss {'Reaction outcome loss': 0.3559786806665901, 'Total loss': 0.3559786806665901}
2023-01-05 03:03:07,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:07,821 INFO:     Epoch: 14
2023-01-05 03:03:10,030 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.348215592900912, 'Total loss': 0.348215592900912} | train loss {'Reaction outcome loss': 0.3464568240268673, 'Total loss': 0.3464568240268673}
2023-01-05 03:03:10,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:10,031 INFO:     Epoch: 15
2023-01-05 03:03:12,271 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3330537259578705, 'Total loss': 0.3330537259578705} | train loss {'Reaction outcome loss': 0.333470055948187, 'Total loss': 0.333470055948187}
2023-01-05 03:03:12,272 INFO:     Found new best model at epoch 15
2023-01-05 03:03:12,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:12,273 INFO:     Epoch: 16
2023-01-05 03:03:14,424 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35253456234931946, 'Total loss': 0.35253456234931946} | train loss {'Reaction outcome loss': 0.32265439281574165, 'Total loss': 0.32265439281574165}
2023-01-05 03:03:14,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:14,424 INFO:     Epoch: 17
2023-01-05 03:03:16,638 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3450481335322062, 'Total loss': 0.3450481335322062} | train loss {'Reaction outcome loss': 0.3196902662748471, 'Total loss': 0.3196902662748471}
2023-01-05 03:03:16,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:16,639 INFO:     Epoch: 18
2023-01-05 03:03:18,887 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35177855640649797, 'Total loss': 0.35177855640649797} | train loss {'Reaction outcome loss': 0.31272706202150363, 'Total loss': 0.31272706202150363}
2023-01-05 03:03:18,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:18,888 INFO:     Epoch: 19
2023-01-05 03:03:21,138 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36082011709610623, 'Total loss': 0.36082011709610623} | train loss {'Reaction outcome loss': 0.3038246827841183, 'Total loss': 0.3038246827841183}
2023-01-05 03:03:21,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:21,138 INFO:     Epoch: 20
2023-01-05 03:03:23,353 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3495006581147512, 'Total loss': 0.3495006581147512} | train loss {'Reaction outcome loss': 0.3035720050178023, 'Total loss': 0.3035720050178023}
2023-01-05 03:03:23,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:23,353 INFO:     Epoch: 21
2023-01-05 03:03:25,574 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35698908294240633, 'Total loss': 0.35698908294240633} | train loss {'Reaction outcome loss': 0.29386598342840653, 'Total loss': 0.29386598342840653}
2023-01-05 03:03:25,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:25,574 INFO:     Epoch: 22
2023-01-05 03:03:27,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36887116531531017, 'Total loss': 0.36887116531531017} | train loss {'Reaction outcome loss': 0.2893719376820693, 'Total loss': 0.2893719376820693}
2023-01-05 03:03:27,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:27,772 INFO:     Epoch: 23
2023-01-05 03:03:29,996 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38429116308689115, 'Total loss': 0.38429116308689115} | train loss {'Reaction outcome loss': 0.2913406732613626, 'Total loss': 0.2913406732613626}
2023-01-05 03:03:29,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:29,997 INFO:     Epoch: 24
2023-01-05 03:03:32,223 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38746493061383563, 'Total loss': 0.38746493061383563} | train loss {'Reaction outcome loss': 0.2824818244401325, 'Total loss': 0.2824818244401325}
2023-01-05 03:03:32,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:32,224 INFO:     Epoch: 25
2023-01-05 03:03:34,473 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3594574918349584, 'Total loss': 0.3594574918349584} | train loss {'Reaction outcome loss': 0.27181609870403656, 'Total loss': 0.27181609870403656}
2023-01-05 03:03:34,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:34,474 INFO:     Epoch: 26
2023-01-05 03:03:36,716 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.32996292610963185, 'Total loss': 0.32996292610963185} | train loss {'Reaction outcome loss': 0.266024745289621, 'Total loss': 0.266024745289621}
2023-01-05 03:03:36,716 INFO:     Found new best model at epoch 26
2023-01-05 03:03:36,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:36,717 INFO:     Epoch: 27
2023-01-05 03:03:38,966 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36281325966119765, 'Total loss': 0.36281325966119765} | train loss {'Reaction outcome loss': 0.26289997446988506, 'Total loss': 0.26289997446988506}
2023-01-05 03:03:38,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:38,966 INFO:     Epoch: 28
2023-01-05 03:03:41,174 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.369671106338501, 'Total loss': 0.369671106338501} | train loss {'Reaction outcome loss': 0.2587110515265469, 'Total loss': 0.2587110515265469}
2023-01-05 03:03:41,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:41,175 INFO:     Epoch: 29
2023-01-05 03:03:43,369 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3497859865427017, 'Total loss': 0.3497859865427017} | train loss {'Reaction outcome loss': 0.2516631583398587, 'Total loss': 0.2516631583398587}
2023-01-05 03:03:43,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:43,369 INFO:     Epoch: 30
2023-01-05 03:03:45,563 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3650469015041987, 'Total loss': 0.3650469015041987} | train loss {'Reaction outcome loss': 0.24947258523594507, 'Total loss': 0.24947258523594507}
2023-01-05 03:03:45,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:45,564 INFO:     Epoch: 31
2023-01-05 03:03:47,812 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3760433236757914, 'Total loss': 0.3760433236757914} | train loss {'Reaction outcome loss': 0.244934686611447, 'Total loss': 0.244934686611447}
2023-01-05 03:03:47,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:47,813 INFO:     Epoch: 32
2023-01-05 03:03:50,023 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3759296158949534, 'Total loss': 0.3759296158949534} | train loss {'Reaction outcome loss': 0.2390469483781498, 'Total loss': 0.2390469483781498}
2023-01-05 03:03:50,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:50,023 INFO:     Epoch: 33
2023-01-05 03:03:52,245 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.367730517188708, 'Total loss': 0.367730517188708} | train loss {'Reaction outcome loss': 0.24068169080841262, 'Total loss': 0.24068169080841262}
2023-01-05 03:03:52,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:52,246 INFO:     Epoch: 34
2023-01-05 03:03:54,424 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3638128439585368, 'Total loss': 0.3638128439585368} | train loss {'Reaction outcome loss': 0.23395613554253097, 'Total loss': 0.23395613554253097}
2023-01-05 03:03:54,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:54,425 INFO:     Epoch: 35
2023-01-05 03:03:56,582 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3728018268942833, 'Total loss': 0.3728018268942833} | train loss {'Reaction outcome loss': 0.23107546920136487, 'Total loss': 0.23107546920136487}
2023-01-05 03:03:56,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:56,582 INFO:     Epoch: 36
2023-01-05 03:03:58,833 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3888853470484416, 'Total loss': 0.3888853470484416} | train loss {'Reaction outcome loss': 0.24060645480167822, 'Total loss': 0.24060645480167822}
2023-01-05 03:03:58,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:03:58,833 INFO:     Epoch: 37
2023-01-05 03:04:01,151 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36568526923656464, 'Total loss': 0.36568526923656464} | train loss {'Reaction outcome loss': 0.24546952498001148, 'Total loss': 0.24546952498001148}
2023-01-05 03:04:01,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:01,151 INFO:     Epoch: 38
2023-01-05 03:04:03,376 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3532367537419001, 'Total loss': 0.3532367537419001} | train loss {'Reaction outcome loss': 0.2303536424020896, 'Total loss': 0.2303536424020896}
2023-01-05 03:04:03,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:03,376 INFO:     Epoch: 39
2023-01-05 03:04:05,623 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3427531356612841, 'Total loss': 0.3427531356612841} | train loss {'Reaction outcome loss': 0.22302945392141776, 'Total loss': 0.22302945392141776}
2023-01-05 03:04:05,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:05,624 INFO:     Epoch: 40
2023-01-05 03:04:07,834 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3436671723922094, 'Total loss': 0.3436671723922094} | train loss {'Reaction outcome loss': 0.22185672155804545, 'Total loss': 0.22185672155804545}
2023-01-05 03:04:07,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:07,834 INFO:     Epoch: 41
2023-01-05 03:04:09,974 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3498147547245026, 'Total loss': 0.3498147547245026} | train loss {'Reaction outcome loss': 0.21414506215353413, 'Total loss': 0.21414506215353413}
2023-01-05 03:04:09,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:09,974 INFO:     Epoch: 42
2023-01-05 03:04:12,229 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3434164419770241, 'Total loss': 0.3434164419770241} | train loss {'Reaction outcome loss': 0.21089424040721919, 'Total loss': 0.21089424040721919}
2023-01-05 03:04:12,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:12,229 INFO:     Epoch: 43
2023-01-05 03:04:14,424 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3472636818885803, 'Total loss': 0.3472636818885803} | train loss {'Reaction outcome loss': 0.21025818716599673, 'Total loss': 0.21025818716599673}
2023-01-05 03:04:14,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:14,424 INFO:     Epoch: 44
2023-01-05 03:04:16,669 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36334043741226196, 'Total loss': 0.36334043741226196} | train loss {'Reaction outcome loss': 0.2095978679211365, 'Total loss': 0.2095978679211365}
2023-01-05 03:04:16,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:16,669 INFO:     Epoch: 45
2023-01-05 03:04:18,879 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3708269427220027, 'Total loss': 0.3708269427220027} | train loss {'Reaction outcome loss': 0.20434799469776277, 'Total loss': 0.20434799469776277}
2023-01-05 03:04:18,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:18,880 INFO:     Epoch: 46
2023-01-05 03:04:21,044 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37434325019518533, 'Total loss': 0.37434325019518533} | train loss {'Reaction outcome loss': 0.20040972565597706, 'Total loss': 0.20040972565597706}
2023-01-05 03:04:21,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:21,045 INFO:     Epoch: 47
2023-01-05 03:04:23,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33971680055061976, 'Total loss': 0.33971680055061976} | train loss {'Reaction outcome loss': 0.19987489328904948, 'Total loss': 0.19987489328904948}
2023-01-05 03:04:23,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:23,288 INFO:     Epoch: 48
2023-01-05 03:04:25,489 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3651735380291939, 'Total loss': 0.3651735380291939} | train loss {'Reaction outcome loss': 0.2034338923893275, 'Total loss': 0.2034338923893275}
2023-01-05 03:04:25,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:25,489 INFO:     Epoch: 49
2023-01-05 03:04:27,655 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34455701857805254, 'Total loss': 0.34455701857805254} | train loss {'Reaction outcome loss': 0.2285076851111217, 'Total loss': 0.2285076851111217}
2023-01-05 03:04:27,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:27,655 INFO:     Epoch: 50
2023-01-05 03:04:29,853 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35697963933149973, 'Total loss': 0.35697963933149973} | train loss {'Reaction outcome loss': 0.20726719324116805, 'Total loss': 0.20726719324116805}
2023-01-05 03:04:29,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:29,853 INFO:     Epoch: 51
2023-01-05 03:04:32,101 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3351366048057874, 'Total loss': 0.3351366048057874} | train loss {'Reaction outcome loss': 0.19833725093243024, 'Total loss': 0.19833725093243024}
2023-01-05 03:04:32,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:32,101 INFO:     Epoch: 52
2023-01-05 03:04:34,346 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3434436450401942, 'Total loss': 0.3434436450401942} | train loss {'Reaction outcome loss': 0.1964618767277621, 'Total loss': 0.1964618767277621}
2023-01-05 03:04:34,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:34,347 INFO:     Epoch: 53
2023-01-05 03:04:36,598 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3316213086247444, 'Total loss': 0.3316213086247444} | train loss {'Reaction outcome loss': 0.18946122908559831, 'Total loss': 0.18946122908559831}
2023-01-05 03:04:36,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:36,598 INFO:     Epoch: 54
2023-01-05 03:04:38,825 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.33578424379229543, 'Total loss': 0.33578424379229543} | train loss {'Reaction outcome loss': 0.1872774492173145, 'Total loss': 0.1872774492173145}
2023-01-05 03:04:38,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:38,826 INFO:     Epoch: 55
2023-01-05 03:04:41,084 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.31278653840223947, 'Total loss': 0.31278653840223947} | train loss {'Reaction outcome loss': 0.18661618695013982, 'Total loss': 0.18661618695013982}
2023-01-05 03:04:41,085 INFO:     Found new best model at epoch 55
2023-01-05 03:04:41,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:41,087 INFO:     Epoch: 56
2023-01-05 03:04:43,344 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3753468538324038, 'Total loss': 0.3753468538324038} | train loss {'Reaction outcome loss': 0.1957232185902641, 'Total loss': 0.1957232185902641}
2023-01-05 03:04:43,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:43,344 INFO:     Epoch: 57
2023-01-05 03:04:45,582 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35718661844730376, 'Total loss': 0.35718661844730376} | train loss {'Reaction outcome loss': 0.21167344160410034, 'Total loss': 0.21167344160410034}
2023-01-05 03:04:45,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:45,583 INFO:     Epoch: 58
2023-01-05 03:04:47,840 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4007371028264364, 'Total loss': 0.4007371028264364} | train loss {'Reaction outcome loss': 0.1888278165589208, 'Total loss': 0.1888278165589208}
2023-01-05 03:04:47,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:47,840 INFO:     Epoch: 59
2023-01-05 03:04:50,061 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33248142202695213, 'Total loss': 0.33248142202695213} | train loss {'Reaction outcome loss': 0.18559473387363867, 'Total loss': 0.18559473387363867}
2023-01-05 03:04:50,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:50,062 INFO:     Epoch: 60
2023-01-05 03:04:52,316 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35690097014109295, 'Total loss': 0.35690097014109295} | train loss {'Reaction outcome loss': 0.18583988901577803, 'Total loss': 0.18583988901577803}
2023-01-05 03:04:52,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:52,316 INFO:     Epoch: 61
2023-01-05 03:04:54,532 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3670266469319661, 'Total loss': 0.3670266469319661} | train loss {'Reaction outcome loss': 0.18326643095658085, 'Total loss': 0.18326643095658085}
2023-01-05 03:04:54,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:54,532 INFO:     Epoch: 62
2023-01-05 03:04:56,836 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3665539582570394, 'Total loss': 0.3665539582570394} | train loss {'Reaction outcome loss': 0.17945053697853902, 'Total loss': 0.17945053697853902}
2023-01-05 03:04:56,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:56,837 INFO:     Epoch: 63
2023-01-05 03:04:59,097 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3650298446416855, 'Total loss': 0.3650298446416855} | train loss {'Reaction outcome loss': 0.20630357507278846, 'Total loss': 0.20630357507278846}
2023-01-05 03:04:59,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:04:59,097 INFO:     Epoch: 64
2023-01-05 03:05:01,298 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3285070406893889, 'Total loss': 0.3285070406893889} | train loss {'Reaction outcome loss': 0.1773893138163038, 'Total loss': 0.1773893138163038}
2023-01-05 03:05:01,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:01,299 INFO:     Epoch: 65
2023-01-05 03:05:03,508 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3466181712845961, 'Total loss': 0.3466181712845961} | train loss {'Reaction outcome loss': 0.17475763350333748, 'Total loss': 0.17475763350333748}
2023-01-05 03:05:03,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:03,509 INFO:     Epoch: 66
2023-01-05 03:05:05,732 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3580057114362717, 'Total loss': 0.3580057114362717} | train loss {'Reaction outcome loss': 0.17855247078246, 'Total loss': 0.17855247078246}
2023-01-05 03:05:05,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:05,732 INFO:     Epoch: 67
2023-01-05 03:05:07,979 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.356550336877505, 'Total loss': 0.356550336877505} | train loss {'Reaction outcome loss': 0.17686433360432746, 'Total loss': 0.17686433360432746}
2023-01-05 03:05:07,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:07,980 INFO:     Epoch: 68
2023-01-05 03:05:10,239 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34183231691519417, 'Total loss': 0.34183231691519417} | train loss {'Reaction outcome loss': 0.1795192886720938, 'Total loss': 0.1795192886720938}
2023-01-05 03:05:10,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:10,239 INFO:     Epoch: 69
2023-01-05 03:05:12,456 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36870059569676716, 'Total loss': 0.36870059569676716} | train loss {'Reaction outcome loss': 0.1692044533014321, 'Total loss': 0.1692044533014321}
2023-01-05 03:05:12,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:12,456 INFO:     Epoch: 70
2023-01-05 03:05:14,659 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3413853749632835, 'Total loss': 0.3413853749632835} | train loss {'Reaction outcome loss': 0.1749582050333384, 'Total loss': 0.1749582050333384}
2023-01-05 03:05:14,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:14,659 INFO:     Epoch: 71
2023-01-05 03:05:16,890 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33098709881305693, 'Total loss': 0.33098709881305693} | train loss {'Reaction outcome loss': 0.17318690408770318, 'Total loss': 0.17318690408770318}
2023-01-05 03:05:16,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:16,891 INFO:     Epoch: 72
2023-01-05 03:05:18,926 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.31929187203447024, 'Total loss': 0.31929187203447024} | train loss {'Reaction outcome loss': 0.17551494984334146, 'Total loss': 0.17551494984334146}
2023-01-05 03:05:18,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:18,926 INFO:     Epoch: 73
2023-01-05 03:05:21,165 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33477408861120544, 'Total loss': 0.33477408861120544} | train loss {'Reaction outcome loss': 0.1709095944205056, 'Total loss': 0.1709095944205056}
2023-01-05 03:05:21,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:21,165 INFO:     Epoch: 74
2023-01-05 03:05:23,367 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33508982757727307, 'Total loss': 0.33508982757727307} | train loss {'Reaction outcome loss': 0.1761286365875529, 'Total loss': 0.1761286365875529}
2023-01-05 03:05:23,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:23,368 INFO:     Epoch: 75
2023-01-05 03:05:25,555 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34752300282319387, 'Total loss': 0.34752300282319387} | train loss {'Reaction outcome loss': 0.16655866692325208, 'Total loss': 0.16655866692325208}
2023-01-05 03:05:25,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:25,555 INFO:     Epoch: 76
2023-01-05 03:05:27,803 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3692692115902901, 'Total loss': 0.3692692115902901} | train loss {'Reaction outcome loss': 0.1700224810355249, 'Total loss': 0.1700224810355249}
2023-01-05 03:05:27,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:27,803 INFO:     Epoch: 77
2023-01-05 03:05:30,000 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3367467229564985, 'Total loss': 0.3367467229564985} | train loss {'Reaction outcome loss': 0.17153038478827642, 'Total loss': 0.17153038478827642}
2023-01-05 03:05:30,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:30,000 INFO:     Epoch: 78
2023-01-05 03:05:32,258 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35923080494006476, 'Total loss': 0.35923080494006476} | train loss {'Reaction outcome loss': 0.16780956060983296, 'Total loss': 0.16780956060983296}
2023-01-05 03:05:32,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:32,259 INFO:     Epoch: 79
2023-01-05 03:05:34,484 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4107530872027079, 'Total loss': 0.4107530872027079} | train loss {'Reaction outcome loss': 0.17129035317845157, 'Total loss': 0.17129035317845157}
2023-01-05 03:05:34,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:34,485 INFO:     Epoch: 80
2023-01-05 03:05:36,678 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3684970716635386, 'Total loss': 0.3684970716635386} | train loss {'Reaction outcome loss': 0.16560372722960892, 'Total loss': 0.16560372722960892}
2023-01-05 03:05:36,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:36,678 INFO:     Epoch: 81
2023-01-05 03:05:38,883 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3883637358744939, 'Total loss': 0.3883637358744939} | train loss {'Reaction outcome loss': 0.1668831903885618, 'Total loss': 0.1668831903885618}
2023-01-05 03:05:38,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:38,884 INFO:     Epoch: 82
2023-01-05 03:05:41,117 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34845244089762367, 'Total loss': 0.34845244089762367} | train loss {'Reaction outcome loss': 0.16241327860423527, 'Total loss': 0.16241327860423527}
2023-01-05 03:05:41,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:41,117 INFO:     Epoch: 83
2023-01-05 03:05:43,366 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3689222723245621, 'Total loss': 0.3689222723245621} | train loss {'Reaction outcome loss': 0.1648512167410682, 'Total loss': 0.1648512167410682}
2023-01-05 03:05:43,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:43,366 INFO:     Epoch: 84
2023-01-05 03:05:45,564 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3737194150686264, 'Total loss': 0.3737194150686264} | train loss {'Reaction outcome loss': 0.17888338894893727, 'Total loss': 0.17888338894893727}
2023-01-05 03:05:45,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:45,564 INFO:     Epoch: 85
2023-01-05 03:05:47,766 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3632464816172918, 'Total loss': 0.3632464816172918} | train loss {'Reaction outcome loss': 0.1634046775508213, 'Total loss': 0.1634046775508213}
2023-01-05 03:05:47,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:47,766 INFO:     Epoch: 86
2023-01-05 03:05:49,953 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3712812195221583, 'Total loss': 0.3712812195221583} | train loss {'Reaction outcome loss': 0.1585377266805997, 'Total loss': 0.1585377266805997}
2023-01-05 03:05:49,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:49,954 INFO:     Epoch: 87
2023-01-05 03:05:52,131 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35112598463892936, 'Total loss': 0.35112598463892936} | train loss {'Reaction outcome loss': 0.15855562259473474, 'Total loss': 0.15855562259473474}
2023-01-05 03:05:52,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:52,132 INFO:     Epoch: 88
2023-01-05 03:05:54,378 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38524927000204723, 'Total loss': 0.38524927000204723} | train loss {'Reaction outcome loss': 0.1584390403476773, 'Total loss': 0.1584390403476773}
2023-01-05 03:05:54,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:54,379 INFO:     Epoch: 89
2023-01-05 03:05:56,633 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3948296656211217, 'Total loss': 0.3948296656211217} | train loss {'Reaction outcome loss': 0.15850011310101472, 'Total loss': 0.15850011310101472}
2023-01-05 03:05:56,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:56,633 INFO:     Epoch: 90
2023-01-05 03:05:58,849 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36714041531085967, 'Total loss': 0.36714041531085967} | train loss {'Reaction outcome loss': 0.15671944624246217, 'Total loss': 0.15671944624246217}
2023-01-05 03:05:58,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:05:58,850 INFO:     Epoch: 91
2023-01-05 03:06:01,069 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3484954615434011, 'Total loss': 0.3484954615434011} | train loss {'Reaction outcome loss': 0.154126324995625, 'Total loss': 0.154126324995625}
2023-01-05 03:06:01,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:01,070 INFO:     Epoch: 92
2023-01-05 03:06:03,318 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3744833921392759, 'Total loss': 0.3744833921392759} | train loss {'Reaction outcome loss': 0.1569633400282275, 'Total loss': 0.1569633400282275}
2023-01-05 03:06:03,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:03,318 INFO:     Epoch: 93
2023-01-05 03:06:05,564 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3464925820628802, 'Total loss': 0.3464925820628802} | train loss {'Reaction outcome loss': 0.1541639661163572, 'Total loss': 0.1541639661163572}
2023-01-05 03:06:05,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:05,564 INFO:     Epoch: 94
2023-01-05 03:06:07,741 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3878372219701608, 'Total loss': 0.3878372219701608} | train loss {'Reaction outcome loss': 0.15680495522876986, 'Total loss': 0.15680495522876986}
2023-01-05 03:06:07,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:07,741 INFO:     Epoch: 95
2023-01-05 03:06:09,968 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35260828137397765, 'Total loss': 0.35260828137397765} | train loss {'Reaction outcome loss': 0.15938293752501984, 'Total loss': 0.15938293752501984}
2023-01-05 03:06:09,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:09,969 INFO:     Epoch: 96
2023-01-05 03:06:12,165 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36136115392049156, 'Total loss': 0.36136115392049156} | train loss {'Reaction outcome loss': 0.15765957179823803, 'Total loss': 0.15765957179823803}
2023-01-05 03:06:12,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:12,166 INFO:     Epoch: 97
2023-01-05 03:06:14,409 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3691434780756632, 'Total loss': 0.3691434780756632} | train loss {'Reaction outcome loss': 0.15765083074350422, 'Total loss': 0.15765083074350422}
2023-01-05 03:06:14,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:14,409 INFO:     Epoch: 98
2023-01-05 03:06:16,654 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3528781811396281, 'Total loss': 0.3528781811396281} | train loss {'Reaction outcome loss': 0.15134755135648817, 'Total loss': 0.15134755135648817}
2023-01-05 03:06:16,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:16,655 INFO:     Epoch: 99
2023-01-05 03:06:18,885 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3807987799247106, 'Total loss': 0.3807987799247106} | train loss {'Reaction outcome loss': 0.15215359928497768, 'Total loss': 0.15215359928497768}
2023-01-05 03:06:18,885 INFO:     Best model found after epoch 56 of 100.
2023-01-05 03:06:18,885 INFO:   Done with stage: TRAINING
2023-01-05 03:06:18,885 INFO:   Starting stage: EVALUATION
2023-01-05 03:06:19,020 INFO:   Done with stage: EVALUATION
2023-01-05 03:06:19,020 INFO:   Leaving out SEQ value Fold_6
2023-01-05 03:06:19,033 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:06:19,033 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:06:19,669 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:06:19,669 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:06:19,738 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:06:19,738 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:06:19,738 INFO:     No hyperparam tuning for this model
2023-01-05 03:06:19,738 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:06:19,738 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:06:19,739 INFO:     None feature selector for col prot
2023-01-05 03:06:19,739 INFO:     None feature selector for col prot
2023-01-05 03:06:19,739 INFO:     None feature selector for col prot
2023-01-05 03:06:19,739 INFO:     None feature selector for col chem
2023-01-05 03:06:19,740 INFO:     None feature selector for col chem
2023-01-05 03:06:19,740 INFO:     None feature selector for col chem
2023-01-05 03:06:19,740 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:06:19,740 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:06:19,741 INFO:     Number of params in model 72931
2023-01-05 03:06:19,744 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:06:19,744 INFO:   Starting stage: TRAINING
2023-01-05 03:06:19,805 INFO:     Val loss before train {'Reaction outcome loss': 1.0177812099456787, 'Total loss': 1.0177812099456787}
2023-01-05 03:06:19,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:19,805 INFO:     Epoch: 0
2023-01-05 03:06:21,980 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8412585775057475, 'Total loss': 0.8412585775057475} | train loss {'Reaction outcome loss': 0.9626697746739872, 'Total loss': 0.9626697746739872}
2023-01-05 03:06:21,981 INFO:     Found new best model at epoch 0
2023-01-05 03:06:21,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:21,982 INFO:     Epoch: 1
2023-01-05 03:06:24,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6089883248011271, 'Total loss': 0.6089883248011271} | train loss {'Reaction outcome loss': 0.6903128802702101, 'Total loss': 0.6903128802702101}
2023-01-05 03:06:24,144 INFO:     Found new best model at epoch 1
2023-01-05 03:06:24,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:24,145 INFO:     Epoch: 2
2023-01-05 03:06:26,392 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5525097906589508, 'Total loss': 0.5525097906589508} | train loss {'Reaction outcome loss': 0.5500859084836058, 'Total loss': 0.5500859084836058}
2023-01-05 03:06:26,392 INFO:     Found new best model at epoch 2
2023-01-05 03:06:26,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:26,393 INFO:     Epoch: 3
2023-01-05 03:06:28,588 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5110871394475301, 'Total loss': 0.5110871394475301} | train loss {'Reaction outcome loss': 0.5128214390192559, 'Total loss': 0.5128214390192559}
2023-01-05 03:06:28,588 INFO:     Found new best model at epoch 3
2023-01-05 03:06:28,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:28,589 INFO:     Epoch: 4
2023-01-05 03:06:30,833 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5185246845086415, 'Total loss': 0.5185246845086415} | train loss {'Reaction outcome loss': 0.4733645753543554, 'Total loss': 0.4733645753543554}
2023-01-05 03:06:30,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:30,834 INFO:     Epoch: 5
2023-01-05 03:06:33,013 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46852778693040215, 'Total loss': 0.46852778693040215} | train loss {'Reaction outcome loss': 0.4564439430878535, 'Total loss': 0.4564439430878535}
2023-01-05 03:06:33,013 INFO:     Found new best model at epoch 5
2023-01-05 03:06:33,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:33,014 INFO:     Epoch: 6
2023-01-05 03:06:35,223 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4946827073891958, 'Total loss': 0.4946827073891958} | train loss {'Reaction outcome loss': 0.43861070519610157, 'Total loss': 0.43861070519610157}
2023-01-05 03:06:35,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:35,223 INFO:     Epoch: 7
2023-01-05 03:06:37,435 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45794527331988016, 'Total loss': 0.45794527331988016} | train loss {'Reaction outcome loss': 0.42457804507643415, 'Total loss': 0.42457804507643415}
2023-01-05 03:06:37,435 INFO:     Found new best model at epoch 7
2023-01-05 03:06:37,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:37,436 INFO:     Epoch: 8
2023-01-05 03:06:39,666 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4856456756591797, 'Total loss': 0.4856456756591797} | train loss {'Reaction outcome loss': 0.4091530080101844, 'Total loss': 0.4091530080101844}
2023-01-05 03:06:39,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:39,667 INFO:     Epoch: 9
2023-01-05 03:06:41,878 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48713279962539674, 'Total loss': 0.48713279962539674} | train loss {'Reaction outcome loss': 0.3934849465604993, 'Total loss': 0.3934849465604993}
2023-01-05 03:06:41,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:41,878 INFO:     Epoch: 10
2023-01-05 03:06:44,065 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46614144841829935, 'Total loss': 0.46614144841829935} | train loss {'Reaction outcome loss': 0.38528485716307076, 'Total loss': 0.38528485716307076}
2023-01-05 03:06:44,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:44,066 INFO:     Epoch: 11
2023-01-05 03:06:46,223 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4399363706509272, 'Total loss': 0.4399363706509272} | train loss {'Reaction outcome loss': 0.37325298040767835, 'Total loss': 0.37325298040767835}
2023-01-05 03:06:46,224 INFO:     Found new best model at epoch 11
2023-01-05 03:06:46,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:46,225 INFO:     Epoch: 12
2023-01-05 03:06:48,435 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4580567131439845, 'Total loss': 0.4580567131439845} | train loss {'Reaction outcome loss': 0.36158968083411996, 'Total loss': 0.36158968083411996}
2023-01-05 03:06:48,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:48,436 INFO:     Epoch: 13
2023-01-05 03:06:50,656 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4429208638767401, 'Total loss': 0.4429208638767401} | train loss {'Reaction outcome loss': 0.35459672505764855, 'Total loss': 0.35459672505764855}
2023-01-05 03:06:50,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:50,656 INFO:     Epoch: 14
2023-01-05 03:06:52,870 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45208726475636163, 'Total loss': 0.45208726475636163} | train loss {'Reaction outcome loss': 0.34600471656312287, 'Total loss': 0.34600471656312287}
2023-01-05 03:06:52,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:52,870 INFO:     Epoch: 15
2023-01-05 03:06:55,122 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4584849754969279, 'Total loss': 0.4584849754969279} | train loss {'Reaction outcome loss': 0.3357588298757142, 'Total loss': 0.3357588298757142}
2023-01-05 03:06:55,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:55,122 INFO:     Epoch: 16
2023-01-05 03:06:57,325 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4671955506006877, 'Total loss': 0.4671955506006877} | train loss {'Reaction outcome loss': 0.33853371209208516, 'Total loss': 0.33853371209208516}
2023-01-05 03:06:57,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:57,326 INFO:     Epoch: 17
2023-01-05 03:06:59,545 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4420577238003413, 'Total loss': 0.4420577238003413} | train loss {'Reaction outcome loss': 0.32938181155064294, 'Total loss': 0.32938181155064294}
2023-01-05 03:06:59,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:06:59,546 INFO:     Epoch: 18
2023-01-05 03:07:01,737 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45650537808736164, 'Total loss': 0.45650537808736164} | train loss {'Reaction outcome loss': 0.31667371258895466, 'Total loss': 0.31667371258895466}
2023-01-05 03:07:01,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:01,738 INFO:     Epoch: 19
2023-01-05 03:07:03,916 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4555983344713847, 'Total loss': 0.4555983344713847} | train loss {'Reaction outcome loss': 0.31387742469762114, 'Total loss': 0.31387742469762114}
2023-01-05 03:07:03,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:03,916 INFO:     Epoch: 20
2023-01-05 03:07:06,113 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4433057248592377, 'Total loss': 0.4433057248592377} | train loss {'Reaction outcome loss': 0.3052356857628763, 'Total loss': 0.3052356857628763}
2023-01-05 03:07:06,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:06,114 INFO:     Epoch: 21
2023-01-05 03:07:08,328 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47768522997697194, 'Total loss': 0.47768522997697194} | train loss {'Reaction outcome loss': 0.29705272580601055, 'Total loss': 0.29705272580601055}
2023-01-05 03:07:08,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:08,328 INFO:     Epoch: 22
2023-01-05 03:07:10,539 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4562347948551178, 'Total loss': 0.4562347948551178} | train loss {'Reaction outcome loss': 0.29206050545031176, 'Total loss': 0.29206050545031176}
2023-01-05 03:07:10,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:10,539 INFO:     Epoch: 23
2023-01-05 03:07:12,785 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4338718285163244, 'Total loss': 0.4338718285163244} | train loss {'Reaction outcome loss': 0.28647790977434406, 'Total loss': 0.28647790977434406}
2023-01-05 03:07:12,785 INFO:     Found new best model at epoch 23
2023-01-05 03:07:12,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:12,787 INFO:     Epoch: 24
2023-01-05 03:07:14,974 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4780347906053066, 'Total loss': 0.4780347906053066} | train loss {'Reaction outcome loss': 0.285831197115181, 'Total loss': 0.285831197115181}
2023-01-05 03:07:14,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:14,975 INFO:     Epoch: 25
2023-01-05 03:07:17,195 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41706619660059613, 'Total loss': 0.41706619660059613} | train loss {'Reaction outcome loss': 0.28134856568916194, 'Total loss': 0.28134856568916194}
2023-01-05 03:07:17,195 INFO:     Found new best model at epoch 25
2023-01-05 03:07:17,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:17,196 INFO:     Epoch: 26
2023-01-05 03:07:19,319 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43547212382157646, 'Total loss': 0.43547212382157646} | train loss {'Reaction outcome loss': 0.2739985645107547, 'Total loss': 0.2739985645107547}
2023-01-05 03:07:19,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:19,319 INFO:     Epoch: 27
2023-01-05 03:07:21,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4415491426984469, 'Total loss': 0.4415491426984469} | train loss {'Reaction outcome loss': 0.27464272474682494, 'Total loss': 0.27464272474682494}
2023-01-05 03:07:21,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:21,522 INFO:     Epoch: 28
2023-01-05 03:07:23,696 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44037897487481437, 'Total loss': 0.44037897487481437} | train loss {'Reaction outcome loss': 0.2710340162401722, 'Total loss': 0.2710340162401722}
2023-01-05 03:07:23,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:23,697 INFO:     Epoch: 29
2023-01-05 03:07:25,903 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4500836988290151, 'Total loss': 0.4500836988290151} | train loss {'Reaction outcome loss': 0.26344705734572266, 'Total loss': 0.26344705734572266}
2023-01-05 03:07:25,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:25,903 INFO:     Epoch: 30
2023-01-05 03:07:28,135 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4599431892236074, 'Total loss': 0.4599431892236074} | train loss {'Reaction outcome loss': 0.2601598515259642, 'Total loss': 0.2601598515259642}
2023-01-05 03:07:28,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:28,136 INFO:     Epoch: 31
2023-01-05 03:07:30,393 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45526011561354, 'Total loss': 0.45526011561354} | train loss {'Reaction outcome loss': 0.26237780376855435, 'Total loss': 0.26237780376855435}
2023-01-05 03:07:30,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:30,393 INFO:     Epoch: 32
2023-01-05 03:07:32,591 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4245060900847117, 'Total loss': 0.4245060900847117} | train loss {'Reaction outcome loss': 0.2582481282533727, 'Total loss': 0.2582481282533727}
2023-01-05 03:07:32,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:32,591 INFO:     Epoch: 33
2023-01-05 03:07:34,822 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4445718223849932, 'Total loss': 0.4445718223849932} | train loss {'Reaction outcome loss': 0.2542650096989034, 'Total loss': 0.2542650096989034}
2023-01-05 03:07:34,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:34,823 INFO:     Epoch: 34
2023-01-05 03:07:36,992 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.476077002286911, 'Total loss': 0.476077002286911} | train loss {'Reaction outcome loss': 0.25173999639767886, 'Total loss': 0.25173999639767886}
2023-01-05 03:07:36,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:36,992 INFO:     Epoch: 35
2023-01-05 03:07:39,205 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4535940945148468, 'Total loss': 0.4535940945148468} | train loss {'Reaction outcome loss': 0.2486051986047971, 'Total loss': 0.2486051986047971}
2023-01-05 03:07:39,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:39,205 INFO:     Epoch: 36
2023-01-05 03:07:41,459 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4438453823328018, 'Total loss': 0.4438453823328018} | train loss {'Reaction outcome loss': 0.24288161190739577, 'Total loss': 0.24288161190739577}
2023-01-05 03:07:41,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:41,459 INFO:     Epoch: 37
2023-01-05 03:07:43,638 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44856496651967365, 'Total loss': 0.44856496651967365} | train loss {'Reaction outcome loss': 0.2395490328038948, 'Total loss': 0.2395490328038948}
2023-01-05 03:07:43,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:43,638 INFO:     Epoch: 38
2023-01-05 03:07:45,852 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44847066005071007, 'Total loss': 0.44847066005071007} | train loss {'Reaction outcome loss': 0.24187194713791224, 'Total loss': 0.24187194713791224}
2023-01-05 03:07:45,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:45,852 INFO:     Epoch: 39
2023-01-05 03:07:48,091 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4445818493763606, 'Total loss': 0.4445818493763606} | train loss {'Reaction outcome loss': 0.23790406671258202, 'Total loss': 0.23790406671258202}
2023-01-05 03:07:48,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:48,091 INFO:     Epoch: 40
2023-01-05 03:07:50,261 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44408970276514687, 'Total loss': 0.44408970276514687} | train loss {'Reaction outcome loss': 0.24226391334356606, 'Total loss': 0.24226391334356606}
2023-01-05 03:07:50,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:50,261 INFO:     Epoch: 41
2023-01-05 03:07:52,448 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4312815099954605, 'Total loss': 0.4312815099954605} | train loss {'Reaction outcome loss': 0.24767442568428005, 'Total loss': 0.24767442568428005}
2023-01-05 03:07:52,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:52,449 INFO:     Epoch: 42
2023-01-05 03:07:54,635 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4372863292694092, 'Total loss': 0.4372863292694092} | train loss {'Reaction outcome loss': 0.2333788619999077, 'Total loss': 0.2333788619999077}
2023-01-05 03:07:54,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:54,636 INFO:     Epoch: 43
2023-01-05 03:07:56,864 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44722832640012106, 'Total loss': 0.44722832640012106} | train loss {'Reaction outcome loss': 0.22716960888204124, 'Total loss': 0.22716960888204124}
2023-01-05 03:07:56,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:56,865 INFO:     Epoch: 44
2023-01-05 03:07:59,092 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4474272221326828, 'Total loss': 0.4474272221326828} | train loss {'Reaction outcome loss': 0.2233621467403772, 'Total loss': 0.2233621467403772}
2023-01-05 03:07:59,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:07:59,093 INFO:     Epoch: 45
2023-01-05 03:08:01,245 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4368233859539032, 'Total loss': 0.4368233859539032} | train loss {'Reaction outcome loss': 0.2212756324991368, 'Total loss': 0.2212756324991368}
2023-01-05 03:08:01,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:01,246 INFO:     Epoch: 46
2023-01-05 03:08:03,367 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4146527752280235, 'Total loss': 0.4146527752280235} | train loss {'Reaction outcome loss': 0.22106949400907636, 'Total loss': 0.22106949400907636}
2023-01-05 03:08:03,368 INFO:     Found new best model at epoch 46
2023-01-05 03:08:03,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:03,369 INFO:     Epoch: 47
2023-01-05 03:08:05,616 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43751413623491925, 'Total loss': 0.43751413623491925} | train loss {'Reaction outcome loss': 0.2236306499251151, 'Total loss': 0.2236306499251151}
2023-01-05 03:08:05,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:05,616 INFO:     Epoch: 48
2023-01-05 03:08:07,848 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4294125904639562, 'Total loss': 0.4294125904639562} | train loss {'Reaction outcome loss': 0.21778116766295896, 'Total loss': 0.21778116766295896}
2023-01-05 03:08:07,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:07,848 INFO:     Epoch: 49
2023-01-05 03:08:10,082 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4378097355365753, 'Total loss': 0.4378097355365753} | train loss {'Reaction outcome loss': 0.21587302250807863, 'Total loss': 0.21587302250807863}
2023-01-05 03:08:10,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:10,082 INFO:     Epoch: 50
2023-01-05 03:08:12,328 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42208661139011383, 'Total loss': 0.42208661139011383} | train loss {'Reaction outcome loss': 0.21447469876485242, 'Total loss': 0.21447469876485242}
2023-01-05 03:08:12,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:12,328 INFO:     Epoch: 51
2023-01-05 03:08:14,574 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4269834131002426, 'Total loss': 0.4269834131002426} | train loss {'Reaction outcome loss': 0.21719323661860815, 'Total loss': 0.21719323661860815}
2023-01-05 03:08:14,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:14,574 INFO:     Epoch: 52
2023-01-05 03:08:16,796 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4543194631735484, 'Total loss': 0.4543194631735484} | train loss {'Reaction outcome loss': 0.2109775702349683, 'Total loss': 0.2109775702349683}
2023-01-05 03:08:16,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:16,796 INFO:     Epoch: 53
2023-01-05 03:08:19,008 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4719016661246618, 'Total loss': 0.4719016661246618} | train loss {'Reaction outcome loss': 0.2117619081106133, 'Total loss': 0.2117619081106133}
2023-01-05 03:08:19,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:19,008 INFO:     Epoch: 54
2023-01-05 03:08:21,222 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44228724638621014, 'Total loss': 0.44228724638621014} | train loss {'Reaction outcome loss': 0.20724176527658963, 'Total loss': 0.20724176527658963}
2023-01-05 03:08:21,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:21,222 INFO:     Epoch: 55
2023-01-05 03:08:23,445 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4407537927230199, 'Total loss': 0.4407537927230199} | train loss {'Reaction outcome loss': 0.205996292684374, 'Total loss': 0.205996292684374}
2023-01-05 03:08:23,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:23,446 INFO:     Epoch: 56
2023-01-05 03:08:25,685 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46927154858907066, 'Total loss': 0.46927154858907066} | train loss {'Reaction outcome loss': 0.2082556216046214, 'Total loss': 0.2082556216046214}
2023-01-05 03:08:25,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:25,685 INFO:     Epoch: 57
2023-01-05 03:08:27,823 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44299746056397754, 'Total loss': 0.44299746056397754} | train loss {'Reaction outcome loss': 0.20441622733673337, 'Total loss': 0.20441622733673337}
2023-01-05 03:08:27,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:27,824 INFO:     Epoch: 58
2023-01-05 03:08:29,981 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44553185602029166, 'Total loss': 0.44553185602029166} | train loss {'Reaction outcome loss': 0.20580837784328268, 'Total loss': 0.20580837784328268}
2023-01-05 03:08:29,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:29,981 INFO:     Epoch: 59
2023-01-05 03:08:32,208 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44547261397043864, 'Total loss': 0.44547261397043864} | train loss {'Reaction outcome loss': 0.19449387309651828, 'Total loss': 0.19449387309651828}
2023-01-05 03:08:32,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:32,209 INFO:     Epoch: 60
2023-01-05 03:08:34,440 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4828369677066803, 'Total loss': 0.4828369677066803} | train loss {'Reaction outcome loss': 0.19805262454589695, 'Total loss': 0.19805262454589695}
2023-01-05 03:08:34,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:34,441 INFO:     Epoch: 61
2023-01-05 03:08:36,601 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4422735244035721, 'Total loss': 0.4422735244035721} | train loss {'Reaction outcome loss': 0.19436905478477312, 'Total loss': 0.19436905478477312}
2023-01-05 03:08:36,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:36,601 INFO:     Epoch: 62
2023-01-05 03:08:38,840 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45511270662148795, 'Total loss': 0.45511270662148795} | train loss {'Reaction outcome loss': 0.1996550066329107, 'Total loss': 0.1996550066329107}
2023-01-05 03:08:38,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:38,841 INFO:     Epoch: 63
2023-01-05 03:08:41,027 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46298378507296245, 'Total loss': 0.46298378507296245} | train loss {'Reaction outcome loss': 0.20595193572976775, 'Total loss': 0.20595193572976775}
2023-01-05 03:08:41,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:41,027 INFO:     Epoch: 64
2023-01-05 03:08:43,227 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4184609939654668, 'Total loss': 0.4184609939654668} | train loss {'Reaction outcome loss': 0.1897218721082343, 'Total loss': 0.1897218721082343}
2023-01-05 03:08:43,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:43,227 INFO:     Epoch: 65
2023-01-05 03:08:45,440 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4478659858306249, 'Total loss': 0.4478659858306249} | train loss {'Reaction outcome loss': 0.18953398454165005, 'Total loss': 0.18953398454165005}
2023-01-05 03:08:45,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:45,440 INFO:     Epoch: 66
2023-01-05 03:08:47,677 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4591329236825307, 'Total loss': 0.4591329236825307} | train loss {'Reaction outcome loss': 0.19387743407160218, 'Total loss': 0.19387743407160218}
2023-01-05 03:08:47,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:47,678 INFO:     Epoch: 67
2023-01-05 03:08:49,823 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4561996152003606, 'Total loss': 0.4561996152003606} | train loss {'Reaction outcome loss': 0.19071363537585823, 'Total loss': 0.19071363537585823}
2023-01-05 03:08:49,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:49,823 INFO:     Epoch: 68
2023-01-05 03:08:52,021 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4525554736455282, 'Total loss': 0.4525554736455282} | train loss {'Reaction outcome loss': 0.1874688103022324, 'Total loss': 0.1874688103022324}
2023-01-05 03:08:52,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:52,021 INFO:     Epoch: 69
2023-01-05 03:08:54,238 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4721161444981893, 'Total loss': 0.4721161444981893} | train loss {'Reaction outcome loss': 0.1932314176912136, 'Total loss': 0.1932314176912136}
2023-01-05 03:08:54,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:54,239 INFO:     Epoch: 70
2023-01-05 03:08:56,466 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4610652307669322, 'Total loss': 0.4610652307669322} | train loss {'Reaction outcome loss': 0.1870509071669548, 'Total loss': 0.1870509071669548}
2023-01-05 03:08:56,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:56,466 INFO:     Epoch: 71
2023-01-05 03:08:58,716 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45343462427457176, 'Total loss': 0.45343462427457176} | train loss {'Reaction outcome loss': 0.21338278105806396, 'Total loss': 0.21338278105806396}
2023-01-05 03:08:58,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:08:58,718 INFO:     Epoch: 72
2023-01-05 03:09:00,949 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4346536924441656, 'Total loss': 0.4346536924441656} | train loss {'Reaction outcome loss': 0.18870797739942066, 'Total loss': 0.18870797739942066}
2023-01-05 03:09:00,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:00,950 INFO:     Epoch: 73
2023-01-05 03:09:03,160 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46741389532883965, 'Total loss': 0.46741389532883965} | train loss {'Reaction outcome loss': 0.18807354480842428, 'Total loss': 0.18807354480842428}
2023-01-05 03:09:03,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:03,160 INFO:     Epoch: 74
2023-01-05 03:09:05,383 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4299514517188072, 'Total loss': 0.4299514517188072} | train loss {'Reaction outcome loss': 0.1853939967020752, 'Total loss': 0.1853939967020752}
2023-01-05 03:09:05,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:05,384 INFO:     Epoch: 75
2023-01-05 03:09:07,573 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4304649382829666, 'Total loss': 0.4304649382829666} | train loss {'Reaction outcome loss': 0.18264586202618058, 'Total loss': 0.18264586202618058}
2023-01-05 03:09:07,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:07,573 INFO:     Epoch: 76
2023-01-05 03:09:09,824 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4209957520167033, 'Total loss': 0.4209957520167033} | train loss {'Reaction outcome loss': 0.18132132695388523, 'Total loss': 0.18132132695388523}
2023-01-05 03:09:09,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:09,824 INFO:     Epoch: 77
2023-01-05 03:09:12,007 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45862810015678407, 'Total loss': 0.45862810015678407} | train loss {'Reaction outcome loss': 0.17936105512679837, 'Total loss': 0.17936105512679837}
2023-01-05 03:09:12,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:12,008 INFO:     Epoch: 78
2023-01-05 03:09:14,257 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44568858047326404, 'Total loss': 0.44568858047326404} | train loss {'Reaction outcome loss': 0.17904986170364334, 'Total loss': 0.17904986170364334}
2023-01-05 03:09:14,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:14,257 INFO:     Epoch: 79
2023-01-05 03:09:16,462 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4527580638726552, 'Total loss': 0.4527580638726552} | train loss {'Reaction outcome loss': 0.1754973506689092, 'Total loss': 0.1754973506689092}
2023-01-05 03:09:16,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:16,463 INFO:     Epoch: 80
2023-01-05 03:09:18,693 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4698668052752813, 'Total loss': 0.4698668052752813} | train loss {'Reaction outcome loss': 0.1725145919970574, 'Total loss': 0.1725145919970574}
2023-01-05 03:09:18,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:18,694 INFO:     Epoch: 81
2023-01-05 03:09:20,946 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4814265211423238, 'Total loss': 0.4814265211423238} | train loss {'Reaction outcome loss': 0.17882017884740903, 'Total loss': 0.17882017884740903}
2023-01-05 03:09:20,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:20,947 INFO:     Epoch: 82
2023-01-05 03:09:23,003 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49161045054594676, 'Total loss': 0.49161045054594676} | train loss {'Reaction outcome loss': 0.17269875518316083, 'Total loss': 0.17269875518316083}
2023-01-05 03:09:23,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:23,004 INFO:     Epoch: 83
2023-01-05 03:09:25,253 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4846902459859848, 'Total loss': 0.4846902459859848} | train loss {'Reaction outcome loss': 0.17522668045527046, 'Total loss': 0.17522668045527046}
2023-01-05 03:09:25,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:25,253 INFO:     Epoch: 84
2023-01-05 03:09:27,473 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4468067745367686, 'Total loss': 0.4468067745367686} | train loss {'Reaction outcome loss': 0.17763988564020375, 'Total loss': 0.17763988564020375}
2023-01-05 03:09:27,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:27,474 INFO:     Epoch: 85
2023-01-05 03:09:29,702 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4394431759913762, 'Total loss': 0.4394431759913762} | train loss {'Reaction outcome loss': 0.17445103704939474, 'Total loss': 0.17445103704939474}
2023-01-05 03:09:29,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:29,703 INFO:     Epoch: 86
2023-01-05 03:09:31,931 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4444457828998566, 'Total loss': 0.4444457828998566} | train loss {'Reaction outcome loss': 0.17680417850404384, 'Total loss': 0.17680417850404384}
2023-01-05 03:09:31,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:31,931 INFO:     Epoch: 87
2023-01-05 03:09:34,185 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.478977233171463, 'Total loss': 0.478977233171463} | train loss {'Reaction outcome loss': 0.17617488669676948, 'Total loss': 0.17617488669676948}
2023-01-05 03:09:34,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:34,185 INFO:     Epoch: 88
2023-01-05 03:09:36,430 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4596149792273839, 'Total loss': 0.4596149792273839} | train loss {'Reaction outcome loss': 0.1690550523373953, 'Total loss': 0.1690550523373953}
2023-01-05 03:09:36,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:36,431 INFO:     Epoch: 89
2023-01-05 03:09:38,647 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4536991457144419, 'Total loss': 0.4536991457144419} | train loss {'Reaction outcome loss': 0.1727898338804548, 'Total loss': 0.1727898338804548}
2023-01-05 03:09:38,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:38,647 INFO:     Epoch: 90
2023-01-05 03:09:40,877 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4694476713736852, 'Total loss': 0.4694476713736852} | train loss {'Reaction outcome loss': 0.16469239507210476, 'Total loss': 0.16469239507210476}
2023-01-05 03:09:40,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:40,877 INFO:     Epoch: 91
2023-01-05 03:09:43,103 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44754117478926975, 'Total loss': 0.44754117478926975} | train loss {'Reaction outcome loss': 0.17144384423285164, 'Total loss': 0.17144384423285164}
2023-01-05 03:09:43,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:43,103 INFO:     Epoch: 92
2023-01-05 03:09:45,351 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4670156925916672, 'Total loss': 0.4670156925916672} | train loss {'Reaction outcome loss': 0.16968191068229752, 'Total loss': 0.16968191068229752}
2023-01-05 03:09:45,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:45,352 INFO:     Epoch: 93
2023-01-05 03:09:47,599 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4828476905822754, 'Total loss': 0.4828476905822754} | train loss {'Reaction outcome loss': 0.16661908809244091, 'Total loss': 0.16661908809244091}
2023-01-05 03:09:47,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:47,599 INFO:     Epoch: 94
2023-01-05 03:09:49,833 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44792937437693275, 'Total loss': 0.44792937437693275} | train loss {'Reaction outcome loss': 0.19798518409210164, 'Total loss': 0.19798518409210164}
2023-01-05 03:09:49,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:49,834 INFO:     Epoch: 95
2023-01-05 03:09:52,056 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44756647845109304, 'Total loss': 0.44756647845109304} | train loss {'Reaction outcome loss': 0.17041145925295365, 'Total loss': 0.17041145925295365}
2023-01-05 03:09:52,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:52,057 INFO:     Epoch: 96
2023-01-05 03:09:54,085 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4738464390238126, 'Total loss': 0.4738464390238126} | train loss {'Reaction outcome loss': 0.16907979994004194, 'Total loss': 0.16907979994004194}
2023-01-05 03:09:54,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:54,085 INFO:     Epoch: 97
2023-01-05 03:09:55,912 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4752993086973826, 'Total loss': 0.4752993086973826} | train loss {'Reaction outcome loss': 0.16336399940131663, 'Total loss': 0.16336399940131663}
2023-01-05 03:09:55,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:55,912 INFO:     Epoch: 98
2023-01-05 03:09:57,838 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47357571721076963, 'Total loss': 0.47357571721076963} | train loss {'Reaction outcome loss': 0.16445698388818436, 'Total loss': 0.16445698388818436}
2023-01-05 03:09:57,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:09:57,838 INFO:     Epoch: 99
2023-01-05 03:10:00,120 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4820081735650698, 'Total loss': 0.4820081735650698} | train loss {'Reaction outcome loss': 0.16520103429312535, 'Total loss': 0.16520103429312535}
2023-01-05 03:10:00,121 INFO:     Best model found after epoch 47 of 100.
2023-01-05 03:10:00,121 INFO:   Done with stage: TRAINING
2023-01-05 03:10:00,121 INFO:   Starting stage: EVALUATION
2023-01-05 03:10:00,253 INFO:   Done with stage: EVALUATION
2023-01-05 03:10:00,253 INFO:   Leaving out SEQ value Fold_7
2023-01-05 03:10:00,265 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 03:10:00,265 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:10:00,901 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:10:00,902 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:10:00,970 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:10:00,970 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:10:00,970 INFO:     No hyperparam tuning for this model
2023-01-05 03:10:00,970 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:10:00,970 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:10:00,971 INFO:     None feature selector for col prot
2023-01-05 03:10:00,971 INFO:     None feature selector for col prot
2023-01-05 03:10:00,971 INFO:     None feature selector for col prot
2023-01-05 03:10:00,972 INFO:     None feature selector for col chem
2023-01-05 03:10:00,972 INFO:     None feature selector for col chem
2023-01-05 03:10:00,972 INFO:     None feature selector for col chem
2023-01-05 03:10:00,972 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:10:00,972 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:10:00,974 INFO:     Number of params in model 72931
2023-01-05 03:10:00,978 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:10:00,978 INFO:   Starting stage: TRAINING
2023-01-05 03:10:01,037 INFO:     Val loss before train {'Reaction outcome loss': 1.049622639020284, 'Total loss': 1.049622639020284}
2023-01-05 03:10:01,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:01,037 INFO:     Epoch: 0
2023-01-05 03:10:03,274 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7745408117771149, 'Total loss': 0.7745408117771149} | train loss {'Reaction outcome loss': 0.9425910509019982, 'Total loss': 0.9425910509019982}
2023-01-05 03:10:03,274 INFO:     Found new best model at epoch 0
2023-01-05 03:10:03,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:03,276 INFO:     Epoch: 1
2023-01-05 03:10:05,517 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5829548239707947, 'Total loss': 0.5829548239707947} | train loss {'Reaction outcome loss': 0.628469890313028, 'Total loss': 0.628469890313028}
2023-01-05 03:10:05,518 INFO:     Found new best model at epoch 1
2023-01-05 03:10:05,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:05,519 INFO:     Epoch: 2
2023-01-05 03:10:07,712 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5423677494128545, 'Total loss': 0.5423677494128545} | train loss {'Reaction outcome loss': 0.537288605198533, 'Total loss': 0.537288605198533}
2023-01-05 03:10:07,713 INFO:     Found new best model at epoch 2
2023-01-05 03:10:07,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:07,715 INFO:     Epoch: 3
2023-01-05 03:10:09,943 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5136962254842122, 'Total loss': 0.5136962254842122} | train loss {'Reaction outcome loss': 0.49498422599871666, 'Total loss': 0.49498422599871666}
2023-01-05 03:10:09,943 INFO:     Found new best model at epoch 3
2023-01-05 03:10:09,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:09,944 INFO:     Epoch: 4
2023-01-05 03:10:12,152 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.503629595041275, 'Total loss': 0.503629595041275} | train loss {'Reaction outcome loss': 0.4715898073537255, 'Total loss': 0.4715898073537255}
2023-01-05 03:10:12,152 INFO:     Found new best model at epoch 4
2023-01-05 03:10:12,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:12,153 INFO:     Epoch: 5
2023-01-05 03:10:14,412 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49455490907033284, 'Total loss': 0.49455490907033284} | train loss {'Reaction outcome loss': 0.4491780893036605, 'Total loss': 0.4491780893036605}
2023-01-05 03:10:14,412 INFO:     Found new best model at epoch 5
2023-01-05 03:10:14,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:14,413 INFO:     Epoch: 6
2023-01-05 03:10:16,668 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48489860792954764, 'Total loss': 0.48489860792954764} | train loss {'Reaction outcome loss': 0.4313510801064839, 'Total loss': 0.4313510801064839}
2023-01-05 03:10:16,668 INFO:     Found new best model at epoch 6
2023-01-05 03:10:16,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:16,670 INFO:     Epoch: 7
2023-01-05 03:10:18,926 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4809845199187597, 'Total loss': 0.4809845199187597} | train loss {'Reaction outcome loss': 0.4155933512946329, 'Total loss': 0.4155933512946329}
2023-01-05 03:10:18,927 INFO:     Found new best model at epoch 7
2023-01-05 03:10:18,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:18,928 INFO:     Epoch: 8
2023-01-05 03:10:21,174 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4823222319285075, 'Total loss': 0.4823222319285075} | train loss {'Reaction outcome loss': 0.4020341260876466, 'Total loss': 0.4020341260876466}
2023-01-05 03:10:21,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:21,175 INFO:     Epoch: 9
2023-01-05 03:10:23,410 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4736505329608917, 'Total loss': 0.4736505329608917} | train loss {'Reaction outcome loss': 0.3902784938039762, 'Total loss': 0.3902784938039762}
2023-01-05 03:10:23,411 INFO:     Found new best model at epoch 9
2023-01-05 03:10:23,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:23,412 INFO:     Epoch: 10
2023-01-05 03:10:25,635 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4625017245610555, 'Total loss': 0.4625017245610555} | train loss {'Reaction outcome loss': 0.3827933147011681, 'Total loss': 0.3827933147011681}
2023-01-05 03:10:25,635 INFO:     Found new best model at epoch 10
2023-01-05 03:10:25,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:25,637 INFO:     Epoch: 11
2023-01-05 03:10:27,864 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.467295570174853, 'Total loss': 0.467295570174853} | train loss {'Reaction outcome loss': 0.3732992503186856, 'Total loss': 0.3732992503186856}
2023-01-05 03:10:27,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:27,865 INFO:     Epoch: 12
2023-01-05 03:10:30,075 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4525210897127787, 'Total loss': 0.4525210897127787} | train loss {'Reaction outcome loss': 0.36518999659842966, 'Total loss': 0.36518999659842966}
2023-01-05 03:10:30,076 INFO:     Found new best model at epoch 12
2023-01-05 03:10:30,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:30,078 INFO:     Epoch: 13
2023-01-05 03:10:32,326 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4502128044764201, 'Total loss': 0.4502128044764201} | train loss {'Reaction outcome loss': 0.35544874519109726, 'Total loss': 0.35544874519109726}
2023-01-05 03:10:32,326 INFO:     Found new best model at epoch 13
2023-01-05 03:10:32,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:32,327 INFO:     Epoch: 14
2023-01-05 03:10:34,568 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4528784404198329, 'Total loss': 0.4528784404198329} | train loss {'Reaction outcome loss': 0.34798807330725423, 'Total loss': 0.34798807330725423}
2023-01-05 03:10:34,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:34,568 INFO:     Epoch: 15
2023-01-05 03:10:36,804 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46033502419789635, 'Total loss': 0.46033502419789635} | train loss {'Reaction outcome loss': 0.34000188812936255, 'Total loss': 0.34000188812936255}
2023-01-05 03:10:36,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:36,805 INFO:     Epoch: 16
2023-01-05 03:10:39,079 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.451038126150767, 'Total loss': 0.451038126150767} | train loss {'Reaction outcome loss': 0.32833360625088, 'Total loss': 0.32833360625088}
2023-01-05 03:10:39,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:39,079 INFO:     Epoch: 17
2023-01-05 03:10:41,333 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43868441780408224, 'Total loss': 0.43868441780408224} | train loss {'Reaction outcome loss': 0.33005418348721216, 'Total loss': 0.33005418348721216}
2023-01-05 03:10:41,333 INFO:     Found new best model at epoch 17
2023-01-05 03:10:41,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:41,335 INFO:     Epoch: 18
2023-01-05 03:10:43,542 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4483431696891785, 'Total loss': 0.4483431696891785} | train loss {'Reaction outcome loss': 0.3222630603326357, 'Total loss': 0.3222630603326357}
2023-01-05 03:10:43,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:43,542 INFO:     Epoch: 19
2023-01-05 03:10:45,784 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45242599546909334, 'Total loss': 0.45242599546909334} | train loss {'Reaction outcome loss': 0.3144205122486779, 'Total loss': 0.3144205122486779}
2023-01-05 03:10:45,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:45,784 INFO:     Epoch: 20
2023-01-05 03:10:47,991 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45041948854923247, 'Total loss': 0.45041948854923247} | train loss {'Reaction outcome loss': 0.31034422033745457, 'Total loss': 0.31034422033745457}
2023-01-05 03:10:47,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:47,991 INFO:     Epoch: 21
2023-01-05 03:10:50,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4807047933340073, 'Total loss': 0.4807047933340073} | train loss {'Reaction outcome loss': 0.30223232562845365, 'Total loss': 0.30223232562845365}
2023-01-05 03:10:50,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:50,202 INFO:     Epoch: 22
2023-01-05 03:10:52,466 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45874876777331036, 'Total loss': 0.45874876777331036} | train loss {'Reaction outcome loss': 0.29663602719991217, 'Total loss': 0.29663602719991217}
2023-01-05 03:10:52,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:52,466 INFO:     Epoch: 23
2023-01-05 03:10:54,719 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4444278419017792, 'Total loss': 0.4444278419017792} | train loss {'Reaction outcome loss': 0.29750490683510844, 'Total loss': 0.29750490683510844}
2023-01-05 03:10:54,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:54,720 INFO:     Epoch: 24
2023-01-05 03:10:56,984 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4589683363835017, 'Total loss': 0.4589683363835017} | train loss {'Reaction outcome loss': 0.2936508324441066, 'Total loss': 0.2936508324441066}
2023-01-05 03:10:56,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:56,984 INFO:     Epoch: 25
2023-01-05 03:10:59,205 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4302196304003398, 'Total loss': 0.4302196304003398} | train loss {'Reaction outcome loss': 0.28562636517445533, 'Total loss': 0.28562636517445533}
2023-01-05 03:10:59,205 INFO:     Found new best model at epoch 25
2023-01-05 03:10:59,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:10:59,207 INFO:     Epoch: 26
2023-01-05 03:11:01,383 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4482079207897186, 'Total loss': 0.4482079207897186} | train loss {'Reaction outcome loss': 0.2800911079137334, 'Total loss': 0.2800911079137334}
2023-01-05 03:11:01,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:01,383 INFO:     Epoch: 27
2023-01-05 03:11:03,579 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4362772971391678, 'Total loss': 0.4362772971391678} | train loss {'Reaction outcome loss': 0.27123480269329, 'Total loss': 0.27123480269329}
2023-01-05 03:11:03,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:03,579 INFO:     Epoch: 28
2023-01-05 03:11:05,810 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4319518526395162, 'Total loss': 0.4319518526395162} | train loss {'Reaction outcome loss': 0.2698655627022366, 'Total loss': 0.2698655627022366}
2023-01-05 03:11:05,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:05,811 INFO:     Epoch: 29
2023-01-05 03:11:08,032 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46056538820266724, 'Total loss': 0.46056538820266724} | train loss {'Reaction outcome loss': 0.26664525986941606, 'Total loss': 0.26664525986941606}
2023-01-05 03:11:08,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:08,032 INFO:     Epoch: 30
2023-01-05 03:11:10,225 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45527120331923165, 'Total loss': 0.45527120331923165} | train loss {'Reaction outcome loss': 0.2593597827970121, 'Total loss': 0.2593597827970121}
2023-01-05 03:11:10,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:10,225 INFO:     Epoch: 31
2023-01-05 03:11:12,475 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4626904308795929, 'Total loss': 0.4626904308795929} | train loss {'Reaction outcome loss': 0.2617844651295175, 'Total loss': 0.2617844651295175}
2023-01-05 03:11:12,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:12,476 INFO:     Epoch: 32
2023-01-05 03:11:14,733 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45867394606272377, 'Total loss': 0.45867394606272377} | train loss {'Reaction outcome loss': 0.25805388668061163, 'Total loss': 0.25805388668061163}
2023-01-05 03:11:14,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:14,734 INFO:     Epoch: 33
2023-01-05 03:11:16,993 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47247567027807236, 'Total loss': 0.47247567027807236} | train loss {'Reaction outcome loss': 0.24665843796267406, 'Total loss': 0.24665843796267406}
2023-01-05 03:11:16,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:16,993 INFO:     Epoch: 34
2023-01-05 03:11:19,235 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47303402572870257, 'Total loss': 0.47303402572870257} | train loss {'Reaction outcome loss': 0.2494711394855477, 'Total loss': 0.2494711394855477}
2023-01-05 03:11:19,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:19,235 INFO:     Epoch: 35
2023-01-05 03:11:21,463 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4636665105819702, 'Total loss': 0.4636665105819702} | train loss {'Reaction outcome loss': 0.24435551558026122, 'Total loss': 0.24435551558026122}
2023-01-05 03:11:21,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:21,464 INFO:     Epoch: 36
2023-01-05 03:11:23,657 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4709113905827204, 'Total loss': 0.4709113905827204} | train loss {'Reaction outcome loss': 0.24006032829411625, 'Total loss': 0.24006032829411625}
2023-01-05 03:11:23,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:23,658 INFO:     Epoch: 37
2023-01-05 03:11:25,979 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44634342888991035, 'Total loss': 0.44634342888991035} | train loss {'Reaction outcome loss': 0.24433883193490308, 'Total loss': 0.24433883193490308}
2023-01-05 03:11:25,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:25,980 INFO:     Epoch: 38
2023-01-05 03:11:28,250 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46674925486246743, 'Total loss': 0.46674925486246743} | train loss {'Reaction outcome loss': 0.23687207963089005, 'Total loss': 0.23687207963089005}
2023-01-05 03:11:28,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:28,251 INFO:     Epoch: 39
2023-01-05 03:11:30,518 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4659448802471161, 'Total loss': 0.4659448802471161} | train loss {'Reaction outcome loss': 0.23563236292007814, 'Total loss': 0.23563236292007814}
2023-01-05 03:11:30,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:30,518 INFO:     Epoch: 40
2023-01-05 03:11:32,688 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4353146533171336, 'Total loss': 0.4353146533171336} | train loss {'Reaction outcome loss': 0.23204825260417555, 'Total loss': 0.23204825260417555}
2023-01-05 03:11:32,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:32,688 INFO:     Epoch: 41
2023-01-05 03:11:34,848 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4534569273392359, 'Total loss': 0.4534569273392359} | train loss {'Reaction outcome loss': 0.22375821866202655, 'Total loss': 0.22375821866202655}
2023-01-05 03:11:34,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:34,848 INFO:     Epoch: 42
2023-01-05 03:11:37,092 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4777638614177704, 'Total loss': 0.4777638614177704} | train loss {'Reaction outcome loss': 0.22365571875192414, 'Total loss': 0.22365571875192414}
2023-01-05 03:11:37,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:37,093 INFO:     Epoch: 43
2023-01-05 03:11:39,347 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46511098742485046, 'Total loss': 0.46511098742485046} | train loss {'Reaction outcome loss': 0.22529742199362723, 'Total loss': 0.22529742199362723}
2023-01-05 03:11:39,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:39,347 INFO:     Epoch: 44
2023-01-05 03:11:41,610 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46363260348637897, 'Total loss': 0.46363260348637897} | train loss {'Reaction outcome loss': 0.22200399189380532, 'Total loss': 0.22200399189380532}
2023-01-05 03:11:41,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:41,612 INFO:     Epoch: 45
2023-01-05 03:11:43,853 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4724715133508047, 'Total loss': 0.4724715133508047} | train loss {'Reaction outcome loss': 0.22167365519255938, 'Total loss': 0.22167365519255938}
2023-01-05 03:11:43,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:43,854 INFO:     Epoch: 46
2023-01-05 03:11:46,112 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46078504125277203, 'Total loss': 0.46078504125277203} | train loss {'Reaction outcome loss': 0.22105421220365953, 'Total loss': 0.22105421220365953}
2023-01-05 03:11:46,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:46,113 INFO:     Epoch: 47
2023-01-05 03:11:48,387 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4970781515041987, 'Total loss': 0.4970781515041987} | train loss {'Reaction outcome loss': 0.21547422640442526, 'Total loss': 0.21547422640442526}
2023-01-05 03:11:48,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:48,388 INFO:     Epoch: 48
2023-01-05 03:11:50,666 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4681164562702179, 'Total loss': 0.4681164562702179} | train loss {'Reaction outcome loss': 0.2203644021693281, 'Total loss': 0.2203644021693281}
2023-01-05 03:11:50,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:50,666 INFO:     Epoch: 49
2023-01-05 03:11:52,938 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4781596486767133, 'Total loss': 0.4781596486767133} | train loss {'Reaction outcome loss': 0.21209909019837095, 'Total loss': 0.21209909019837095}
2023-01-05 03:11:52,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:52,938 INFO:     Epoch: 50
2023-01-05 03:11:55,189 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49633641839027404, 'Total loss': 0.49633641839027404} | train loss {'Reaction outcome loss': 0.21616720221936703, 'Total loss': 0.21616720221936703}
2023-01-05 03:11:55,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:55,190 INFO:     Epoch: 51
2023-01-05 03:11:57,433 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4727816581726074, 'Total loss': 0.4727816581726074} | train loss {'Reaction outcome loss': 0.20700677147047722, 'Total loss': 0.20700677147047722}
2023-01-05 03:11:57,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:57,433 INFO:     Epoch: 52
2023-01-05 03:11:59,692 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5160421639680862, 'Total loss': 0.5160421639680862} | train loss {'Reaction outcome loss': 0.20516857834842178, 'Total loss': 0.20516857834842178}
2023-01-05 03:11:59,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:11:59,692 INFO:     Epoch: 53
2023-01-05 03:12:01,850 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48016049365202584, 'Total loss': 0.48016049365202584} | train loss {'Reaction outcome loss': 0.2090643492295316, 'Total loss': 0.2090643492295316}
2023-01-05 03:12:01,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:01,851 INFO:     Epoch: 54
2023-01-05 03:12:04,059 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4760703464349111, 'Total loss': 0.4760703464349111} | train loss {'Reaction outcome loss': 0.20685963220356388, 'Total loss': 0.20685963220356388}
2023-01-05 03:12:04,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:04,059 INFO:     Epoch: 55
2023-01-05 03:12:06,252 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49088081518809, 'Total loss': 0.49088081518809} | train loss {'Reaction outcome loss': 0.20675704619487487, 'Total loss': 0.20675704619487487}
2023-01-05 03:12:06,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:06,253 INFO:     Epoch: 56
2023-01-05 03:12:08,492 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44516334136327107, 'Total loss': 0.44516334136327107} | train loss {'Reaction outcome loss': 0.20351689095047407, 'Total loss': 0.20351689095047407}
2023-01-05 03:12:08,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:08,492 INFO:     Epoch: 57
2023-01-05 03:12:10,708 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4813371181488037, 'Total loss': 0.4813371181488037} | train loss {'Reaction outcome loss': 0.20185245024141207, 'Total loss': 0.20185245024141207}
2023-01-05 03:12:10,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:10,708 INFO:     Epoch: 58
2023-01-05 03:12:12,925 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4761741101741791, 'Total loss': 0.4761741101741791} | train loss {'Reaction outcome loss': 0.20186621201349025, 'Total loss': 0.20186621201349025}
2023-01-05 03:12:12,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:12,925 INFO:     Epoch: 59
2023-01-05 03:12:15,147 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45744119882583617, 'Total loss': 0.45744119882583617} | train loss {'Reaction outcome loss': 0.19987647389381155, 'Total loss': 0.19987647389381155}
2023-01-05 03:12:15,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:15,148 INFO:     Epoch: 60
2023-01-05 03:12:17,362 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47538169423739113, 'Total loss': 0.47538169423739113} | train loss {'Reaction outcome loss': 0.1980400995825441, 'Total loss': 0.1980400995825441}
2023-01-05 03:12:17,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:17,364 INFO:     Epoch: 61
2023-01-05 03:12:19,551 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49101815223693845, 'Total loss': 0.49101815223693845} | train loss {'Reaction outcome loss': 0.19376199387538412, 'Total loss': 0.19376199387538412}
2023-01-05 03:12:19,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:19,551 INFO:     Epoch: 62
2023-01-05 03:12:21,775 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5097840905189515, 'Total loss': 0.5097840905189515} | train loss {'Reaction outcome loss': 0.197302824283012, 'Total loss': 0.197302824283012}
2023-01-05 03:12:21,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:21,775 INFO:     Epoch: 63
2023-01-05 03:12:23,965 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4894221107165019, 'Total loss': 0.4894221107165019} | train loss {'Reaction outcome loss': 0.1904255285495993, 'Total loss': 0.1904255285495993}
2023-01-05 03:12:23,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:23,965 INFO:     Epoch: 64
2023-01-05 03:12:26,161 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4843269328276316, 'Total loss': 0.4843269328276316} | train loss {'Reaction outcome loss': 0.19063655482705966, 'Total loss': 0.19063655482705966}
2023-01-05 03:12:26,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:26,162 INFO:     Epoch: 65
2023-01-05 03:12:28,382 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48318404853343966, 'Total loss': 0.48318404853343966} | train loss {'Reaction outcome loss': 0.19161602825309665, 'Total loss': 0.19161602825309665}
2023-01-05 03:12:28,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:28,382 INFO:     Epoch: 66
2023-01-05 03:12:30,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4821624755859375, 'Total loss': 0.4821624755859375} | train loss {'Reaction outcome loss': 0.1882668090614386, 'Total loss': 0.1882668090614386}
2023-01-05 03:12:30,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:30,629 INFO:     Epoch: 67
2023-01-05 03:12:32,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4862325042486191, 'Total loss': 0.4862325042486191} | train loss {'Reaction outcome loss': 0.1919543041514791, 'Total loss': 0.1919543041514791}
2023-01-05 03:12:32,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:32,840 INFO:     Epoch: 68
2023-01-05 03:12:35,098 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45132570937275884, 'Total loss': 0.45132570937275884} | train loss {'Reaction outcome loss': 0.18907952518454527, 'Total loss': 0.18907952518454527}
2023-01-05 03:12:35,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:35,099 INFO:     Epoch: 69
2023-01-05 03:12:37,348 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5008174141248067, 'Total loss': 0.5008174141248067} | train loss {'Reaction outcome loss': 0.18675643988020907, 'Total loss': 0.18675643988020907}
2023-01-05 03:12:37,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:37,349 INFO:     Epoch: 70
2023-01-05 03:12:39,588 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45494799812634784, 'Total loss': 0.45494799812634784} | train loss {'Reaction outcome loss': 0.18708896940147055, 'Total loss': 0.18708896940147055}
2023-01-05 03:12:39,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:39,588 INFO:     Epoch: 71
2023-01-05 03:12:41,792 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4451788991689682, 'Total loss': 0.4451788991689682} | train loss {'Reaction outcome loss': 0.18646947676752987, 'Total loss': 0.18646947676752987}
2023-01-05 03:12:41,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:41,792 INFO:     Epoch: 72
2023-01-05 03:12:43,991 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49242246747016905, 'Total loss': 0.49242246747016905} | train loss {'Reaction outcome loss': 0.1845294834629024, 'Total loss': 0.1845294834629024}
2023-01-05 03:12:43,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:43,992 INFO:     Epoch: 73
2023-01-05 03:12:46,192 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48086739182472227, 'Total loss': 0.48086739182472227} | train loss {'Reaction outcome loss': 0.18503298578844388, 'Total loss': 0.18503298578844388}
2023-01-05 03:12:46,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:46,192 INFO:     Epoch: 74
2023-01-05 03:12:48,401 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48186748623847964, 'Total loss': 0.48186748623847964} | train loss {'Reaction outcome loss': 0.18251694309515104, 'Total loss': 0.18251694309515104}
2023-01-05 03:12:48,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:48,401 INFO:     Epoch: 75
2023-01-05 03:12:50,645 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47370444039503734, 'Total loss': 0.47370444039503734} | train loss {'Reaction outcome loss': 0.18134392458367218, 'Total loss': 0.18134392458367218}
2023-01-05 03:12:50,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:50,645 INFO:     Epoch: 76
2023-01-05 03:12:52,864 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5039072543382644, 'Total loss': 0.5039072543382644} | train loss {'Reaction outcome loss': 0.18541383391266372, 'Total loss': 0.18541383391266372}
2023-01-05 03:12:52,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:52,866 INFO:     Epoch: 77
2023-01-05 03:12:55,068 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4929460982481639, 'Total loss': 0.4929460982481639} | train loss {'Reaction outcome loss': 0.17958851042960094, 'Total loss': 0.17958851042960094}
2023-01-05 03:12:55,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:55,069 INFO:     Epoch: 78
2023-01-05 03:12:57,249 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4850278561313947, 'Total loss': 0.4850278561313947} | train loss {'Reaction outcome loss': 0.17882005461165512, 'Total loss': 0.17882005461165512}
2023-01-05 03:12:57,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:57,250 INFO:     Epoch: 79
2023-01-05 03:12:59,387 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4866135676701864, 'Total loss': 0.4866135676701864} | train loss {'Reaction outcome loss': 0.17800794379778934, 'Total loss': 0.17800794379778934}
2023-01-05 03:12:59,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:12:59,388 INFO:     Epoch: 80
2023-01-05 03:13:01,611 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4769400952383876, 'Total loss': 0.4769400952383876} | train loss {'Reaction outcome loss': 0.17567343110494343, 'Total loss': 0.17567343110494343}
2023-01-05 03:13:01,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:01,611 INFO:     Epoch: 81
2023-01-05 03:13:03,844 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5033451795578003, 'Total loss': 0.5033451795578003} | train loss {'Reaction outcome loss': 0.1782519783528811, 'Total loss': 0.1782519783528811}
2023-01-05 03:13:03,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:03,844 INFO:     Epoch: 82
2023-01-05 03:13:06,015 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5232886334260305, 'Total loss': 0.5232886334260305} | train loss {'Reaction outcome loss': 0.17499449319586105, 'Total loss': 0.17499449319586105}
2023-01-05 03:13:06,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:06,016 INFO:     Epoch: 83
2023-01-05 03:13:08,231 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4716477205355962, 'Total loss': 0.4716477205355962} | train loss {'Reaction outcome loss': 0.17700652095542999, 'Total loss': 0.17700652095542999}
2023-01-05 03:13:08,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:08,231 INFO:     Epoch: 84
2023-01-05 03:13:10,463 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48508271972338357, 'Total loss': 0.48508271972338357} | train loss {'Reaction outcome loss': 0.17225758229056204, 'Total loss': 0.17225758229056204}
2023-01-05 03:13:10,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:10,463 INFO:     Epoch: 85
2023-01-05 03:13:12,693 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49563262760639193, 'Total loss': 0.49563262760639193} | train loss {'Reaction outcome loss': 0.18164808897886572, 'Total loss': 0.18164808897886572}
2023-01-05 03:13:12,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:12,694 INFO:     Epoch: 86
2023-01-05 03:13:14,886 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5039499759674072, 'Total loss': 0.5039499759674072} | train loss {'Reaction outcome loss': 0.17380487720653523, 'Total loss': 0.17380487720653523}
2023-01-05 03:13:14,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:14,886 INFO:     Epoch: 87
2023-01-05 03:13:17,079 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47866378128528597, 'Total loss': 0.47866378128528597} | train loss {'Reaction outcome loss': 0.17531551287546485, 'Total loss': 0.17531551287546485}
2023-01-05 03:13:17,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:17,080 INFO:     Epoch: 88
2023-01-05 03:13:19,295 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.468729426463445, 'Total loss': 0.468729426463445} | train loss {'Reaction outcome loss': 0.1683010710823595, 'Total loss': 0.1683010710823595}
2023-01-05 03:13:19,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:19,296 INFO:     Epoch: 89
2023-01-05 03:13:21,543 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4735014552871386, 'Total loss': 0.4735014552871386} | train loss {'Reaction outcome loss': 0.1721688540247252, 'Total loss': 0.1721688540247252}
2023-01-05 03:13:21,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:21,544 INFO:     Epoch: 90
2023-01-05 03:13:23,731 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49848753213882446, 'Total loss': 0.49848753213882446} | train loss {'Reaction outcome loss': 0.17416158258168546, 'Total loss': 0.17416158258168546}
2023-01-05 03:13:23,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:23,731 INFO:     Epoch: 91
2023-01-05 03:13:25,972 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5069160083929698, 'Total loss': 0.5069160083929698} | train loss {'Reaction outcome loss': 0.1740464102106996, 'Total loss': 0.1740464102106996}
2023-01-05 03:13:25,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:25,972 INFO:     Epoch: 92
2023-01-05 03:13:28,002 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4873785446087519, 'Total loss': 0.4873785446087519} | train loss {'Reaction outcome loss': 0.17229744160904242, 'Total loss': 0.17229744160904242}
2023-01-05 03:13:28,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:28,002 INFO:     Epoch: 93
2023-01-05 03:13:30,177 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4830577701330185, 'Total loss': 0.4830577701330185} | train loss {'Reaction outcome loss': 0.1689263656500068, 'Total loss': 0.1689263656500068}
2023-01-05 03:13:30,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:30,178 INFO:     Epoch: 94
2023-01-05 03:13:32,411 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4807731330394745, 'Total loss': 0.4807731330394745} | train loss {'Reaction outcome loss': 0.1620053727052003, 'Total loss': 0.1620053727052003}
2023-01-05 03:13:32,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:32,411 INFO:     Epoch: 95
2023-01-05 03:13:34,596 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5147075295448303, 'Total loss': 0.5147075295448303} | train loss {'Reaction outcome loss': 0.1677953655720564, 'Total loss': 0.1677953655720564}
2023-01-05 03:13:34,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:34,596 INFO:     Epoch: 96
2023-01-05 03:13:36,829 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5059428691864014, 'Total loss': 0.5059428691864014} | train loss {'Reaction outcome loss': 0.1721016242057892, 'Total loss': 0.1721016242057892}
2023-01-05 03:13:36,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:36,830 INFO:     Epoch: 97
2023-01-05 03:13:39,041 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48797318935394285, 'Total loss': 0.48797318935394285} | train loss {'Reaction outcome loss': 0.16683324915945313, 'Total loss': 0.16683324915945313}
2023-01-05 03:13:39,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:39,041 INFO:     Epoch: 98
2023-01-05 03:13:41,247 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5095811684926351, 'Total loss': 0.5095811684926351} | train loss {'Reaction outcome loss': 0.16414381796326016, 'Total loss': 0.16414381796326016}
2023-01-05 03:13:41,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:41,247 INFO:     Epoch: 99
2023-01-05 03:13:43,480 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4794560670852661, 'Total loss': 0.4794560670852661} | train loss {'Reaction outcome loss': 0.1678091089345434, 'Total loss': 0.1678091089345434}
2023-01-05 03:13:43,480 INFO:     Best model found after epoch 26 of 100.
2023-01-05 03:13:43,480 INFO:   Done with stage: TRAINING
2023-01-05 03:13:43,480 INFO:   Starting stage: EVALUATION
2023-01-05 03:13:43,607 INFO:   Done with stage: EVALUATION
2023-01-05 03:13:43,607 INFO:   Leaving out SEQ value Fold_8
2023-01-05 03:13:43,619 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 03:13:43,619 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:13:44,247 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:13:44,247 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:13:44,314 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:13:44,314 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:13:44,314 INFO:     No hyperparam tuning for this model
2023-01-05 03:13:44,314 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:13:44,314 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:13:44,315 INFO:     None feature selector for col prot
2023-01-05 03:13:44,315 INFO:     None feature selector for col prot
2023-01-05 03:13:44,315 INFO:     None feature selector for col prot
2023-01-05 03:13:44,316 INFO:     None feature selector for col chem
2023-01-05 03:13:44,316 INFO:     None feature selector for col chem
2023-01-05 03:13:44,316 INFO:     None feature selector for col chem
2023-01-05 03:13:44,316 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:13:44,316 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:13:44,317 INFO:     Number of params in model 72931
2023-01-05 03:13:44,320 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:13:44,320 INFO:   Starting stage: TRAINING
2023-01-05 03:13:44,381 INFO:     Val loss before train {'Reaction outcome loss': 1.0191865682601928, 'Total loss': 1.0191865682601928}
2023-01-05 03:13:44,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:44,382 INFO:     Epoch: 0
2023-01-05 03:13:46,564 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8056832750638326, 'Total loss': 0.8056832750638326} | train loss {'Reaction outcome loss': 0.9553745907523257, 'Total loss': 0.9553745907523257}
2023-01-05 03:13:46,564 INFO:     Found new best model at epoch 0
2023-01-05 03:13:46,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:46,565 INFO:     Epoch: 1
2023-01-05 03:13:48,731 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5439931253592173, 'Total loss': 0.5439931253592173} | train loss {'Reaction outcome loss': 0.6674615336861802, 'Total loss': 0.6674615336861802}
2023-01-05 03:13:48,731 INFO:     Found new best model at epoch 1
2023-01-05 03:13:48,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:48,733 INFO:     Epoch: 2
2023-01-05 03:13:50,912 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5198483268419901, 'Total loss': 0.5198483268419901} | train loss {'Reaction outcome loss': 0.5520437138202863, 'Total loss': 0.5520437138202863}
2023-01-05 03:13:50,912 INFO:     Found new best model at epoch 2
2023-01-05 03:13:50,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:50,914 INFO:     Epoch: 3
2023-01-05 03:13:53,120 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5106450815995535, 'Total loss': 0.5106450815995535} | train loss {'Reaction outcome loss': 0.5126857516857294, 'Total loss': 0.5126857516857294}
2023-01-05 03:13:53,121 INFO:     Found new best model at epoch 3
2023-01-05 03:13:53,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:53,122 INFO:     Epoch: 4
2023-01-05 03:13:55,302 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48625346819559734, 'Total loss': 0.48625346819559734} | train loss {'Reaction outcome loss': 0.49165963864588474, 'Total loss': 0.49165963864588474}
2023-01-05 03:13:55,303 INFO:     Found new best model at epoch 4
2023-01-05 03:13:55,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:55,304 INFO:     Epoch: 5
2023-01-05 03:13:57,534 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4497101833422979, 'Total loss': 0.4497101833422979} | train loss {'Reaction outcome loss': 0.46672459175953496, 'Total loss': 0.46672459175953496}
2023-01-05 03:13:57,534 INFO:     Found new best model at epoch 5
2023-01-05 03:13:57,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:57,535 INFO:     Epoch: 6
2023-01-05 03:13:59,773 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49224021037419635, 'Total loss': 0.49224021037419635} | train loss {'Reaction outcome loss': 0.4503719113603398, 'Total loss': 0.4503719113603398}
2023-01-05 03:13:59,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:13:59,774 INFO:     Epoch: 7
2023-01-05 03:14:01,995 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4536407748858134, 'Total loss': 0.4536407748858134} | train loss {'Reaction outcome loss': 0.44080317457080326, 'Total loss': 0.44080317457080326}
2023-01-05 03:14:01,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:01,996 INFO:     Epoch: 8
2023-01-05 03:14:04,172 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4575567305088043, 'Total loss': 0.4575567305088043} | train loss {'Reaction outcome loss': 0.4263172039946357, 'Total loss': 0.4263172039946357}
2023-01-05 03:14:04,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:04,173 INFO:     Epoch: 9
2023-01-05 03:14:06,400 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46092522144317627, 'Total loss': 0.46092522144317627} | train loss {'Reaction outcome loss': 0.4125676678814294, 'Total loss': 0.4125676678814294}
2023-01-05 03:14:06,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:06,401 INFO:     Epoch: 10
2023-01-05 03:14:08,626 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4748238484064738, 'Total loss': 0.4748238484064738} | train loss {'Reaction outcome loss': 0.40708546340465546, 'Total loss': 0.40708546340465546}
2023-01-05 03:14:08,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:08,626 INFO:     Epoch: 11
2023-01-05 03:14:10,862 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43442902763684593, 'Total loss': 0.43442902763684593} | train loss {'Reaction outcome loss': 0.3950268481022272, 'Total loss': 0.3950268481022272}
2023-01-05 03:14:10,862 INFO:     Found new best model at epoch 11
2023-01-05 03:14:10,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:10,864 INFO:     Epoch: 12
2023-01-05 03:14:13,076 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.435988908012708, 'Total loss': 0.435988908012708} | train loss {'Reaction outcome loss': 0.384617469167753, 'Total loss': 0.384617469167753}
2023-01-05 03:14:13,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:13,076 INFO:     Epoch: 13
2023-01-05 03:14:15,246 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4232914388179779, 'Total loss': 0.4232914388179779} | train loss {'Reaction outcome loss': 0.3752590727893424, 'Total loss': 0.3752590727893424}
2023-01-05 03:14:15,246 INFO:     Found new best model at epoch 13
2023-01-05 03:14:15,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:15,247 INFO:     Epoch: 14
2023-01-05 03:14:17,461 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3956036483248075, 'Total loss': 0.3956036483248075} | train loss {'Reaction outcome loss': 0.365456933257999, 'Total loss': 0.365456933257999}
2023-01-05 03:14:17,461 INFO:     Found new best model at epoch 14
2023-01-05 03:14:17,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:17,462 INFO:     Epoch: 15
2023-01-05 03:14:19,669 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43080490827560425, 'Total loss': 0.43080490827560425} | train loss {'Reaction outcome loss': 0.3581868719869044, 'Total loss': 0.3581868719869044}
2023-01-05 03:14:19,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:19,670 INFO:     Epoch: 16
2023-01-05 03:14:21,885 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40242324247956274, 'Total loss': 0.40242324247956274} | train loss {'Reaction outcome loss': 0.35176942014432216, 'Total loss': 0.35176942014432216}
2023-01-05 03:14:21,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:21,885 INFO:     Epoch: 17
2023-01-05 03:14:24,081 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3988587846358617, 'Total loss': 0.3988587846358617} | train loss {'Reaction outcome loss': 0.3469919061813599, 'Total loss': 0.3469919061813599}
2023-01-05 03:14:24,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:24,082 INFO:     Epoch: 18
2023-01-05 03:14:26,225 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4043088763952255, 'Total loss': 0.4043088763952255} | train loss {'Reaction outcome loss': 0.3418616083187935, 'Total loss': 0.3418616083187935}
2023-01-05 03:14:26,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:26,226 INFO:     Epoch: 19
2023-01-05 03:14:28,374 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4223577817281087, 'Total loss': 0.4223577817281087} | train loss {'Reaction outcome loss': 0.3323182042810943, 'Total loss': 0.3323182042810943}
2023-01-05 03:14:28,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:28,374 INFO:     Epoch: 20
2023-01-05 03:14:30,577 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41740409334500633, 'Total loss': 0.41740409334500633} | train loss {'Reaction outcome loss': 0.3318815381699429, 'Total loss': 0.3318815381699429}
2023-01-05 03:14:30,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:30,577 INFO:     Epoch: 21
2023-01-05 03:14:32,812 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40497121612230935, 'Total loss': 0.40497121612230935} | train loss {'Reaction outcome loss': 0.31788401706860614, 'Total loss': 0.31788401706860614}
2023-01-05 03:14:32,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:32,812 INFO:     Epoch: 22
2023-01-05 03:14:35,026 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4226219892501831, 'Total loss': 0.4226219892501831} | train loss {'Reaction outcome loss': 0.3156185850037105, 'Total loss': 0.3156185850037105}
2023-01-05 03:14:35,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:35,027 INFO:     Epoch: 23
2023-01-05 03:14:37,262 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3852074553569158, 'Total loss': 0.3852074553569158} | train loss {'Reaction outcome loss': 0.3084472589222066, 'Total loss': 0.3084472589222066}
2023-01-05 03:14:37,262 INFO:     Found new best model at epoch 23
2023-01-05 03:14:37,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:37,264 INFO:     Epoch: 24
2023-01-05 03:14:39,472 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4066044194002946, 'Total loss': 0.4066044194002946} | train loss {'Reaction outcome loss': 0.31016428920102646, 'Total loss': 0.31016428920102646}
2023-01-05 03:14:39,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:39,472 INFO:     Epoch: 25
2023-01-05 03:14:41,649 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3792572021484375, 'Total loss': 0.3792572021484375} | train loss {'Reaction outcome loss': 0.29999722832397663, 'Total loss': 0.29999722832397663}
2023-01-05 03:14:41,650 INFO:     Found new best model at epoch 25
2023-01-05 03:14:41,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:41,652 INFO:     Epoch: 26
2023-01-05 03:14:43,818 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36561086525519687, 'Total loss': 0.36561086525519687} | train loss {'Reaction outcome loss': 0.294080622917239, 'Total loss': 0.294080622917239}
2023-01-05 03:14:43,818 INFO:     Found new best model at epoch 26
2023-01-05 03:14:43,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:43,820 INFO:     Epoch: 27
2023-01-05 03:14:46,055 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39643558909495674, 'Total loss': 0.39643558909495674} | train loss {'Reaction outcome loss': 0.28926067274309447, 'Total loss': 0.28926067274309447}
2023-01-05 03:14:46,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:46,056 INFO:     Epoch: 28
2023-01-05 03:14:48,279 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3747989585002263, 'Total loss': 0.3747989585002263} | train loss {'Reaction outcome loss': 0.285805509108436, 'Total loss': 0.285805509108436}
2023-01-05 03:14:48,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:48,279 INFO:     Epoch: 29
2023-01-05 03:14:50,489 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3937668750683467, 'Total loss': 0.3937668750683467} | train loss {'Reaction outcome loss': 0.28752646340064075, 'Total loss': 0.28752646340064075}
2023-01-05 03:14:50,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:50,490 INFO:     Epoch: 30
2023-01-05 03:14:52,745 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35014896641174953, 'Total loss': 0.35014896641174953} | train loss {'Reaction outcome loss': 0.28065623288407865, 'Total loss': 0.28065623288407865}
2023-01-05 03:14:52,745 INFO:     Found new best model at epoch 30
2023-01-05 03:14:52,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:52,747 INFO:     Epoch: 31
2023-01-05 03:14:54,993 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3957470029592514, 'Total loss': 0.3957470029592514} | train loss {'Reaction outcome loss': 0.27205658903270413, 'Total loss': 0.27205658903270413}
2023-01-05 03:14:54,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:54,994 INFO:     Epoch: 32
2023-01-05 03:14:57,250 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36934697528680166, 'Total loss': 0.36934697528680166} | train loss {'Reaction outcome loss': 0.2714438467480979, 'Total loss': 0.2714438467480979}
2023-01-05 03:14:57,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:57,251 INFO:     Epoch: 33
2023-01-05 03:14:59,498 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3589600995182991, 'Total loss': 0.3589600995182991} | train loss {'Reaction outcome loss': 0.26929316546890764, 'Total loss': 0.26929316546890764}
2023-01-05 03:14:59,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:14:59,498 INFO:     Epoch: 34
2023-01-05 03:15:01,706 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3788721521695455, 'Total loss': 0.3788721521695455} | train loss {'Reaction outcome loss': 0.2693330125248694, 'Total loss': 0.2693330125248694}
2023-01-05 03:15:01,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:01,707 INFO:     Epoch: 35
2023-01-05 03:15:03,914 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3647581527630488, 'Total loss': 0.3647581527630488} | train loss {'Reaction outcome loss': 0.2616799488158781, 'Total loss': 0.2616799488158781}
2023-01-05 03:15:03,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:03,915 INFO:     Epoch: 36
2023-01-05 03:15:06,127 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3725788563489914, 'Total loss': 0.3725788563489914} | train loss {'Reaction outcome loss': 0.2614854252027286, 'Total loss': 0.2614854252027286}
2023-01-05 03:15:06,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:06,127 INFO:     Epoch: 37
2023-01-05 03:15:08,330 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36238621870676674, 'Total loss': 0.36238621870676674} | train loss {'Reaction outcome loss': 0.2562189820758152, 'Total loss': 0.2562189820758152}
2023-01-05 03:15:08,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:08,330 INFO:     Epoch: 38
2023-01-05 03:15:10,562 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3999845216671626, 'Total loss': 0.3999845216671626} | train loss {'Reaction outcome loss': 0.2544534600752614, 'Total loss': 0.2544534600752614}
2023-01-05 03:15:10,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:10,563 INFO:     Epoch: 39
2023-01-05 03:15:12,676 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3512509102622668, 'Total loss': 0.3512509102622668} | train loss {'Reaction outcome loss': 0.2566542538230891, 'Total loss': 0.2566542538230891}
2023-01-05 03:15:12,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:12,677 INFO:     Epoch: 40
2023-01-05 03:15:14,801 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3971940596898397, 'Total loss': 0.3971940596898397} | train loss {'Reaction outcome loss': 0.2510562597197436, 'Total loss': 0.2510562597197436}
2023-01-05 03:15:14,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:14,801 INFO:     Epoch: 41
2023-01-05 03:15:17,016 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36235172500212987, 'Total loss': 0.36235172500212987} | train loss {'Reaction outcome loss': 0.24432813481260568, 'Total loss': 0.24432813481260568}
2023-01-05 03:15:17,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:17,017 INFO:     Epoch: 42
2023-01-05 03:15:19,222 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38064354807138445, 'Total loss': 0.38064354807138445} | train loss {'Reaction outcome loss': 0.24305158870588073, 'Total loss': 0.24305158870588073}
2023-01-05 03:15:19,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:19,223 INFO:     Epoch: 43
2023-01-05 03:15:21,472 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39948147584994637, 'Total loss': 0.39948147584994637} | train loss {'Reaction outcome loss': 0.242164058276476, 'Total loss': 0.242164058276476}
2023-01-05 03:15:21,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:21,473 INFO:     Epoch: 44
2023-01-05 03:15:23,693 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37627092699209846, 'Total loss': 0.37627092699209846} | train loss {'Reaction outcome loss': 0.2477892606686323, 'Total loss': 0.2477892606686323}
2023-01-05 03:15:23,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:23,693 INFO:     Epoch: 45
2023-01-05 03:15:25,667 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4046792964140574, 'Total loss': 0.4046792964140574} | train loss {'Reaction outcome loss': 0.2415695931257564, 'Total loss': 0.2415695931257564}
2023-01-05 03:15:25,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:25,667 INFO:     Epoch: 46
2023-01-05 03:15:27,521 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41229121685028075, 'Total loss': 0.41229121685028075} | train loss {'Reaction outcome loss': 0.2380272910585661, 'Total loss': 0.2380272910585661}
2023-01-05 03:15:27,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:27,521 INFO:     Epoch: 47
2023-01-05 03:15:29,494 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3708138088385264, 'Total loss': 0.3708138088385264} | train loss {'Reaction outcome loss': 0.23704034519201014, 'Total loss': 0.23704034519201014}
2023-01-05 03:15:29,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:29,494 INFO:     Epoch: 48
2023-01-05 03:15:31,708 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3831543336311976, 'Total loss': 0.3831543336311976} | train loss {'Reaction outcome loss': 0.23015776085547912, 'Total loss': 0.23015776085547912}
2023-01-05 03:15:31,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:31,709 INFO:     Epoch: 49
2023-01-05 03:15:33,939 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3768557478984197, 'Total loss': 0.3768557478984197} | train loss {'Reaction outcome loss': 0.2281742183962366, 'Total loss': 0.2281742183962366}
2023-01-05 03:15:33,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:33,939 INFO:     Epoch: 50
2023-01-05 03:15:36,140 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3599345825922986, 'Total loss': 0.3599345825922986} | train loss {'Reaction outcome loss': 0.22955804860608264, 'Total loss': 0.22955804860608264}
2023-01-05 03:15:36,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:36,141 INFO:     Epoch: 51
2023-01-05 03:15:38,369 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3718203028043111, 'Total loss': 0.3718203028043111} | train loss {'Reaction outcome loss': 0.231169170157595, 'Total loss': 0.231169170157595}
2023-01-05 03:15:38,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:38,369 INFO:     Epoch: 52
2023-01-05 03:15:40,571 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41233638723691307, 'Total loss': 0.41233638723691307} | train loss {'Reaction outcome loss': 0.22258361732594042, 'Total loss': 0.22258361732594042}
2023-01-05 03:15:40,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:40,571 INFO:     Epoch: 53
2023-01-05 03:15:42,746 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38309418012698493, 'Total loss': 0.38309418012698493} | train loss {'Reaction outcome loss': 0.2288318526190825, 'Total loss': 0.2288318526190825}
2023-01-05 03:15:42,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:42,747 INFO:     Epoch: 54
2023-01-05 03:15:44,937 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3684041609366735, 'Total loss': 0.3684041609366735} | train loss {'Reaction outcome loss': 0.2299287173685519, 'Total loss': 0.2299287173685519}
2023-01-05 03:15:44,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:44,937 INFO:     Epoch: 55
2023-01-05 03:15:47,126 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38083484073479973, 'Total loss': 0.38083484073479973} | train loss {'Reaction outcome loss': 0.22227429383990419, 'Total loss': 0.22227429383990419}
2023-01-05 03:15:47,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:47,127 INFO:     Epoch: 56
2023-01-05 03:15:49,344 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38796317478020986, 'Total loss': 0.38796317478020986} | train loss {'Reaction outcome loss': 0.21874402311285993, 'Total loss': 0.21874402311285993}
2023-01-05 03:15:49,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:49,345 INFO:     Epoch: 57
2023-01-05 03:15:51,568 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36948752105236055, 'Total loss': 0.36948752105236055} | train loss {'Reaction outcome loss': 0.21969400322057933, 'Total loss': 0.21969400322057933}
2023-01-05 03:15:51,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:51,569 INFO:     Epoch: 58
2023-01-05 03:15:53,741 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3709595779577891, 'Total loss': 0.3709595779577891} | train loss {'Reaction outcome loss': 0.22086190158712776, 'Total loss': 0.22086190158712776}
2023-01-05 03:15:53,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:53,741 INFO:     Epoch: 59
2023-01-05 03:15:55,923 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3897804419199626, 'Total loss': 0.3897804419199626} | train loss {'Reaction outcome loss': 0.22140883014711377, 'Total loss': 0.22140883014711377}
2023-01-05 03:15:55,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:55,923 INFO:     Epoch: 60
2023-01-05 03:15:58,039 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38725675791502, 'Total loss': 0.38725675791502} | train loss {'Reaction outcome loss': 0.21241801857416118, 'Total loss': 0.21241801857416118}
2023-01-05 03:15:58,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:15:58,039 INFO:     Epoch: 61
2023-01-05 03:16:00,234 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3672579954067866, 'Total loss': 0.3672579954067866} | train loss {'Reaction outcome loss': 0.21514495356424607, 'Total loss': 0.21514495356424607}
2023-01-05 03:16:00,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:00,235 INFO:     Epoch: 62
2023-01-05 03:16:02,470 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39675736700495084, 'Total loss': 0.39675736700495084} | train loss {'Reaction outcome loss': 0.2078287271107291, 'Total loss': 0.2078287271107291}
2023-01-05 03:16:02,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:02,471 INFO:     Epoch: 63
2023-01-05 03:16:04,679 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40744642664988834, 'Total loss': 0.40744642664988834} | train loss {'Reaction outcome loss': 0.20901356934955267, 'Total loss': 0.20901356934955267}
2023-01-05 03:16:04,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:04,680 INFO:     Epoch: 64
2023-01-05 03:16:06,909 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4134757399559021, 'Total loss': 0.4134757399559021} | train loss {'Reaction outcome loss': 0.2151077811097924, 'Total loss': 0.2151077811097924}
2023-01-05 03:16:06,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:06,909 INFO:     Epoch: 65
2023-01-05 03:16:09,163 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4216955125331879, 'Total loss': 0.4216955125331879} | train loss {'Reaction outcome loss': 0.2064941520649162, 'Total loss': 0.2064941520649162}
2023-01-05 03:16:09,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:09,163 INFO:     Epoch: 66
2023-01-05 03:16:11,381 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4328745762507121, 'Total loss': 0.4328745762507121} | train loss {'Reaction outcome loss': 0.21148902824619314, 'Total loss': 0.21148902824619314}
2023-01-05 03:16:11,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:11,382 INFO:     Epoch: 67
2023-01-05 03:16:13,558 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4037151182691256, 'Total loss': 0.4037151182691256} | train loss {'Reaction outcome loss': 0.21161234007991386, 'Total loss': 0.21161234007991386}
2023-01-05 03:16:13,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:13,559 INFO:     Epoch: 68
2023-01-05 03:16:15,736 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39529611269632975, 'Total loss': 0.39529611269632975} | train loss {'Reaction outcome loss': 0.20692381936197096, 'Total loss': 0.20692381936197096}
2023-01-05 03:16:15,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:15,736 INFO:     Epoch: 69
2023-01-05 03:16:17,967 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4100510567426682, 'Total loss': 0.4100510567426682} | train loss {'Reaction outcome loss': 0.20364201072630755, 'Total loss': 0.20364201072630755}
2023-01-05 03:16:17,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:17,969 INFO:     Epoch: 70
2023-01-05 03:16:20,213 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3974508454402288, 'Total loss': 0.3974508454402288} | train loss {'Reaction outcome loss': 0.19938519237829105, 'Total loss': 0.19938519237829105}
2023-01-05 03:16:20,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:20,213 INFO:     Epoch: 71
2023-01-05 03:16:22,453 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.402257298429807, 'Total loss': 0.402257298429807} | train loss {'Reaction outcome loss': 0.20342962863094313, 'Total loss': 0.20342962863094313}
2023-01-05 03:16:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:22,453 INFO:     Epoch: 72
2023-01-05 03:16:24,656 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4004355053106944, 'Total loss': 0.4004355053106944} | train loss {'Reaction outcome loss': 0.1987654226303319, 'Total loss': 0.1987654226303319}
2023-01-05 03:16:24,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:24,657 INFO:     Epoch: 73
2023-01-05 03:16:26,900 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4361925811196367, 'Total loss': 0.4361925811196367} | train loss {'Reaction outcome loss': 0.19937281818180294, 'Total loss': 0.19937281818180294}
2023-01-05 03:16:26,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:26,900 INFO:     Epoch: 74
2023-01-05 03:16:29,117 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4369790603717168, 'Total loss': 0.4369790603717168} | train loss {'Reaction outcome loss': 0.2007469022168945, 'Total loss': 0.2007469022168945}
2023-01-05 03:16:29,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:29,117 INFO:     Epoch: 75
2023-01-05 03:16:31,321 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4126835751036803, 'Total loss': 0.4126835751036803} | train loss {'Reaction outcome loss': 0.1936388376506639, 'Total loss': 0.1936388376506639}
2023-01-05 03:16:31,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:31,321 INFO:     Epoch: 76
2023-01-05 03:16:33,508 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42716034054756163, 'Total loss': 0.42716034054756163} | train loss {'Reaction outcome loss': 0.1965735347313813, 'Total loss': 0.1965735347313813}
2023-01-05 03:16:33,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:33,508 INFO:     Epoch: 77
2023-01-05 03:16:35,733 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42905208965142566, 'Total loss': 0.42905208965142566} | train loss {'Reaction outcome loss': 0.19515703803426399, 'Total loss': 0.19515703803426399}
2023-01-05 03:16:35,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:35,734 INFO:     Epoch: 78
2023-01-05 03:16:37,965 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4129957139492035, 'Total loss': 0.4129957139492035} | train loss {'Reaction outcome loss': 0.19529605731231608, 'Total loss': 0.19529605731231608}
2023-01-05 03:16:37,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:37,966 INFO:     Epoch: 79
2023-01-05 03:16:40,130 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4403798480828603, 'Total loss': 0.4403798480828603} | train loss {'Reaction outcome loss': 0.1925347661599517, 'Total loss': 0.1925347661599517}
2023-01-05 03:16:40,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:40,130 INFO:     Epoch: 80
2023-01-05 03:16:42,287 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41404257093866664, 'Total loss': 0.41404257093866664} | train loss {'Reaction outcome loss': 0.19069530514338406, 'Total loss': 0.19069530514338406}
2023-01-05 03:16:42,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:42,287 INFO:     Epoch: 81
2023-01-05 03:16:44,513 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44210464557011925, 'Total loss': 0.44210464557011925} | train loss {'Reaction outcome loss': 0.18201857592719486, 'Total loss': 0.18201857592719486}
2023-01-05 03:16:44,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:44,513 INFO:     Epoch: 82
2023-01-05 03:16:46,673 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44161185920238494, 'Total loss': 0.44161185920238494} | train loss {'Reaction outcome loss': 0.18855823113859355, 'Total loss': 0.18855823113859355}
2023-01-05 03:16:46,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:46,674 INFO:     Epoch: 83
2023-01-05 03:16:48,831 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4015713334083557, 'Total loss': 0.4015713334083557} | train loss {'Reaction outcome loss': 0.18960792381289132, 'Total loss': 0.18960792381289132}
2023-01-05 03:16:48,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:48,831 INFO:     Epoch: 84
2023-01-05 03:16:51,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3818982173999151, 'Total loss': 0.3818982173999151} | train loss {'Reaction outcome loss': 0.18799713442286292, 'Total loss': 0.18799713442286292}
2023-01-05 03:16:51,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:51,042 INFO:     Epoch: 85
2023-01-05 03:16:53,193 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41412288347880044, 'Total loss': 0.41412288347880044} | train loss {'Reaction outcome loss': 0.18092131440914935, 'Total loss': 0.18092131440914935}
2023-01-05 03:16:53,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:53,194 INFO:     Epoch: 86
2023-01-05 03:16:55,416 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.393018768231074, 'Total loss': 0.393018768231074} | train loss {'Reaction outcome loss': 0.1882935365945128, 'Total loss': 0.1882935365945128}
2023-01-05 03:16:55,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:55,416 INFO:     Epoch: 87
2023-01-05 03:16:57,625 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4520668998360634, 'Total loss': 0.4520668998360634} | train loss {'Reaction outcome loss': 0.18661082586471414, 'Total loss': 0.18661082586471414}
2023-01-05 03:16:57,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:57,625 INFO:     Epoch: 88
2023-01-05 03:16:59,739 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4030102342367172, 'Total loss': 0.4030102342367172} | train loss {'Reaction outcome loss': 0.18396034895275265, 'Total loss': 0.18396034895275265}
2023-01-05 03:16:59,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:16:59,740 INFO:     Epoch: 89
2023-01-05 03:17:02,004 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3972626358270645, 'Total loss': 0.3972626358270645} | train loss {'Reaction outcome loss': 0.18645853995116968, 'Total loss': 0.18645853995116968}
2023-01-05 03:17:02,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:02,004 INFO:     Epoch: 90
2023-01-05 03:17:04,232 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4159937560558319, 'Total loss': 0.4159937560558319} | train loss {'Reaction outcome loss': 0.1849404603870579, 'Total loss': 0.1849404603870579}
2023-01-05 03:17:04,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:04,232 INFO:     Epoch: 91
2023-01-05 03:17:06,479 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4145082138478756, 'Total loss': 0.4145082138478756} | train loss {'Reaction outcome loss': 0.18152645652288155, 'Total loss': 0.18152645652288155}
2023-01-05 03:17:06,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:06,479 INFO:     Epoch: 92
2023-01-05 03:17:08,708 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42706940372784935, 'Total loss': 0.42706940372784935} | train loss {'Reaction outcome loss': 0.18094868192128538, 'Total loss': 0.18094868192128538}
2023-01-05 03:17:08,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:08,708 INFO:     Epoch: 93
2023-01-05 03:17:10,930 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45337643325328825, 'Total loss': 0.45337643325328825} | train loss {'Reaction outcome loss': 0.17994845642506968, 'Total loss': 0.17994845642506968}
2023-01-05 03:17:10,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:10,930 INFO:     Epoch: 94
2023-01-05 03:17:13,151 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45965281426906585, 'Total loss': 0.45965281426906585} | train loss {'Reaction outcome loss': 0.17798852756442057, 'Total loss': 0.17798852756442057}
2023-01-05 03:17:13,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:13,152 INFO:     Epoch: 95
2023-01-05 03:17:15,371 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4368377881745497, 'Total loss': 0.4368377881745497} | train loss {'Reaction outcome loss': 0.1792361973801921, 'Total loss': 0.1792361973801921}
2023-01-05 03:17:15,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:15,371 INFO:     Epoch: 96
2023-01-05 03:17:17,621 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45607825219631193, 'Total loss': 0.45607825219631193} | train loss {'Reaction outcome loss': 0.17516733935928389, 'Total loss': 0.17516733935928389}
2023-01-05 03:17:17,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:17,622 INFO:     Epoch: 97
2023-01-05 03:17:19,856 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4221870462099711, 'Total loss': 0.4221870462099711} | train loss {'Reaction outcome loss': 0.17671578945148558, 'Total loss': 0.17671578945148558}
2023-01-05 03:17:19,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:19,857 INFO:     Epoch: 98
2023-01-05 03:17:22,078 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40048734049002327, 'Total loss': 0.40048734049002327} | train loss {'Reaction outcome loss': 0.17602948807248156, 'Total loss': 0.17602948807248156}
2023-01-05 03:17:22,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:22,079 INFO:     Epoch: 99
2023-01-05 03:17:24,316 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4426876346270243, 'Total loss': 0.4426876346270243} | train loss {'Reaction outcome loss': 0.1731322886722483, 'Total loss': 0.1731322886722483}
2023-01-05 03:17:24,316 INFO:     Best model found after epoch 31 of 100.
2023-01-05 03:17:24,317 INFO:   Done with stage: TRAINING
2023-01-05 03:17:24,317 INFO:   Starting stage: EVALUATION
2023-01-05 03:17:24,465 INFO:   Done with stage: EVALUATION
2023-01-05 03:17:24,465 INFO:   Leaving out SEQ value Fold_9
2023-01-05 03:17:24,478 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 03:17:24,478 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:17:25,133 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:17:25,133 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:17:25,203 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:17:25,203 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:17:25,203 INFO:     No hyperparam tuning for this model
2023-01-05 03:17:25,203 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:17:25,203 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:17:25,204 INFO:     None feature selector for col prot
2023-01-05 03:17:25,204 INFO:     None feature selector for col prot
2023-01-05 03:17:25,204 INFO:     None feature selector for col prot
2023-01-05 03:17:25,205 INFO:     None feature selector for col chem
2023-01-05 03:17:25,205 INFO:     None feature selector for col chem
2023-01-05 03:17:25,205 INFO:     None feature selector for col chem
2023-01-05 03:17:25,205 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:17:25,205 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:17:25,207 INFO:     Number of params in model 72931
2023-01-05 03:17:25,210 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:17:25,210 INFO:   Starting stage: TRAINING
2023-01-05 03:17:25,269 INFO:     Val loss before train {'Reaction outcome loss': 0.9471339424451192, 'Total loss': 0.9471339424451192}
2023-01-05 03:17:25,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:25,270 INFO:     Epoch: 0
2023-01-05 03:17:27,533 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.801033631960551, 'Total loss': 0.801033631960551} | train loss {'Reaction outcome loss': 0.9493435133880657, 'Total loss': 0.9493435133880657}
2023-01-05 03:17:27,533 INFO:     Found new best model at epoch 0
2023-01-05 03:17:27,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:27,534 INFO:     Epoch: 1
2023-01-05 03:17:29,804 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5654651105403901, 'Total loss': 0.5654651105403901} | train loss {'Reaction outcome loss': 0.6863165108843401, 'Total loss': 0.6863165108843401}
2023-01-05 03:17:29,805 INFO:     Found new best model at epoch 1
2023-01-05 03:17:29,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:29,807 INFO:     Epoch: 2
2023-01-05 03:17:31,973 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5171469330787659, 'Total loss': 0.5171469330787659} | train loss {'Reaction outcome loss': 0.5474502398541689, 'Total loss': 0.5474502398541689}
2023-01-05 03:17:31,973 INFO:     Found new best model at epoch 2
2023-01-05 03:17:31,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:31,974 INFO:     Epoch: 3
2023-01-05 03:17:34,145 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46010183095932006, 'Total loss': 0.46010183095932006} | train loss {'Reaction outcome loss': 0.5020064937508923, 'Total loss': 0.5020064937508923}
2023-01-05 03:17:34,145 INFO:     Found new best model at epoch 3
2023-01-05 03:17:34,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:34,147 INFO:     Epoch: 4
2023-01-05 03:17:36,382 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4624877691268921, 'Total loss': 0.4624877691268921} | train loss {'Reaction outcome loss': 0.466147372761358, 'Total loss': 0.466147372761358}
2023-01-05 03:17:36,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:36,383 INFO:     Epoch: 5
2023-01-05 03:17:38,654 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43500585357348126, 'Total loss': 0.43500585357348126} | train loss {'Reaction outcome loss': 0.44217782195939914, 'Total loss': 0.44217782195939914}
2023-01-05 03:17:38,654 INFO:     Found new best model at epoch 5
2023-01-05 03:17:38,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:38,655 INFO:     Epoch: 6
2023-01-05 03:17:40,861 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4134540855884552, 'Total loss': 0.4134540855884552} | train loss {'Reaction outcome loss': 0.41892642675754393, 'Total loss': 0.41892642675754393}
2023-01-05 03:17:40,861 INFO:     Found new best model at epoch 6
2023-01-05 03:17:40,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:40,862 INFO:     Epoch: 7
2023-01-05 03:17:43,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41531739830970765, 'Total loss': 0.41531739830970765} | train loss {'Reaction outcome loss': 0.4019077259926159, 'Total loss': 0.4019077259926159}
2023-01-05 03:17:43,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:43,094 INFO:     Epoch: 8
2023-01-05 03:17:45,294 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3958029955625534, 'Total loss': 0.3958029955625534} | train loss {'Reaction outcome loss': 0.3863368792331606, 'Total loss': 0.3863368792331606}
2023-01-05 03:17:45,294 INFO:     Found new best model at epoch 8
2023-01-05 03:17:45,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:45,296 INFO:     Epoch: 9
2023-01-05 03:17:47,564 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3941822956005732, 'Total loss': 0.3941822956005732} | train loss {'Reaction outcome loss': 0.3755888697634105, 'Total loss': 0.3755888697634105}
2023-01-05 03:17:47,564 INFO:     Found new best model at epoch 9
2023-01-05 03:17:47,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:47,565 INFO:     Epoch: 10
2023-01-05 03:17:49,751 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3666422039270401, 'Total loss': 0.3666422039270401} | train loss {'Reaction outcome loss': 0.358973805950652, 'Total loss': 0.358973805950652}
2023-01-05 03:17:49,752 INFO:     Found new best model at epoch 10
2023-01-05 03:17:49,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:49,754 INFO:     Epoch: 11
2023-01-05 03:17:51,984 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36235598226388294, 'Total loss': 0.36235598226388294} | train loss {'Reaction outcome loss': 0.35192727980738514, 'Total loss': 0.35192727980738514}
2023-01-05 03:17:51,984 INFO:     Found new best model at epoch 11
2023-01-05 03:17:51,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:51,986 INFO:     Epoch: 12
2023-01-05 03:17:54,231 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3675798575083415, 'Total loss': 0.3675798575083415} | train loss {'Reaction outcome loss': 0.34210178307139916, 'Total loss': 0.34210178307139916}
2023-01-05 03:17:54,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:54,231 INFO:     Epoch: 13
2023-01-05 03:17:56,485 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3734301517407099, 'Total loss': 0.3734301517407099} | train loss {'Reaction outcome loss': 0.33436455690581013, 'Total loss': 0.33436455690581013}
2023-01-05 03:17:56,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:56,485 INFO:     Epoch: 14
2023-01-05 03:17:58,707 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35438272356987, 'Total loss': 0.35438272356987} | train loss {'Reaction outcome loss': 0.3239135458554387, 'Total loss': 0.3239135458554387}
2023-01-05 03:17:58,707 INFO:     Found new best model at epoch 14
2023-01-05 03:17:58,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:17:58,708 INFO:     Epoch: 15
2023-01-05 03:18:00,946 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3607673595348994, 'Total loss': 0.3607673595348994} | train loss {'Reaction outcome loss': 0.31847897885427795, 'Total loss': 0.31847897885427795}
2023-01-05 03:18:00,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:00,946 INFO:     Epoch: 16
2023-01-05 03:18:03,211 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3730484833319982, 'Total loss': 0.3730484833319982} | train loss {'Reaction outcome loss': 0.3126351781566005, 'Total loss': 0.3126351781566005}
2023-01-05 03:18:03,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:03,211 INFO:     Epoch: 17
2023-01-05 03:18:05,473 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3708417475223541, 'Total loss': 0.3708417475223541} | train loss {'Reaction outcome loss': 0.30506767840242344, 'Total loss': 0.30506767840242344}
2023-01-05 03:18:05,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:05,474 INFO:     Epoch: 18
2023-01-05 03:18:07,715 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3661620020866394, 'Total loss': 0.3661620020866394} | train loss {'Reaction outcome loss': 0.29962139493291556, 'Total loss': 0.29962139493291556}
2023-01-05 03:18:07,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:07,716 INFO:     Epoch: 19
2023-01-05 03:18:09,921 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37090004483858746, 'Total loss': 0.37090004483858746} | train loss {'Reaction outcome loss': 0.29225356885591786, 'Total loss': 0.29225356885591786}
2023-01-05 03:18:09,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:09,921 INFO:     Epoch: 20
2023-01-05 03:18:12,170 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34877041876316073, 'Total loss': 0.34877041876316073} | train loss {'Reaction outcome loss': 0.2829438684649416, 'Total loss': 0.2829438684649416}
2023-01-05 03:18:12,171 INFO:     Found new best model at epoch 20
2023-01-05 03:18:12,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:12,173 INFO:     Epoch: 21
2023-01-05 03:18:14,422 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37007701496283213, 'Total loss': 0.37007701496283213} | train loss {'Reaction outcome loss': 0.2819687552777008, 'Total loss': 0.2819687552777008}
2023-01-05 03:18:14,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:14,422 INFO:     Epoch: 22
2023-01-05 03:18:16,685 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3553432747721672, 'Total loss': 0.3553432747721672} | train loss {'Reaction outcome loss': 0.2754692122716766, 'Total loss': 0.2754692122716766}
2023-01-05 03:18:16,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:16,686 INFO:     Epoch: 23
2023-01-05 03:18:18,915 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36896386196215947, 'Total loss': 0.36896386196215947} | train loss {'Reaction outcome loss': 0.273103304610786, 'Total loss': 0.273103304610786}
2023-01-05 03:18:18,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:18,915 INFO:     Epoch: 24
2023-01-05 03:18:21,149 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3539142683148384, 'Total loss': 0.3539142683148384} | train loss {'Reaction outcome loss': 0.26671063146866614, 'Total loss': 0.26671063146866614}
2023-01-05 03:18:21,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:21,150 INFO:     Epoch: 25
2023-01-05 03:18:23,305 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37040233810742695, 'Total loss': 0.37040233810742695} | train loss {'Reaction outcome loss': 0.2653551287411137, 'Total loss': 0.2653551287411137}
2023-01-05 03:18:23,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:23,305 INFO:     Epoch: 26
2023-01-05 03:18:25,492 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37806574404239657, 'Total loss': 0.37806574404239657} | train loss {'Reaction outcome loss': 0.26185606721291044, 'Total loss': 0.26185606721291044}
2023-01-05 03:18:25,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:25,493 INFO:     Epoch: 27
2023-01-05 03:18:27,673 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3734016234676043, 'Total loss': 0.3734016234676043} | train loss {'Reaction outcome loss': 0.2586710018169686, 'Total loss': 0.2586710018169686}
2023-01-05 03:18:27,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:27,673 INFO:     Epoch: 28
2023-01-05 03:18:29,862 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3718800355990728, 'Total loss': 0.3718800355990728} | train loss {'Reaction outcome loss': 0.25376647391393514, 'Total loss': 0.25376647391393514}
2023-01-05 03:18:29,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:29,862 INFO:     Epoch: 29
2023-01-05 03:18:32,064 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36730376780033114, 'Total loss': 0.36730376780033114} | train loss {'Reaction outcome loss': 0.25459000088328276, 'Total loss': 0.25459000088328276}
2023-01-05 03:18:32,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:32,064 INFO:     Epoch: 30
2023-01-05 03:18:34,300 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.352490089337031, 'Total loss': 0.352490089337031} | train loss {'Reaction outcome loss': 0.24846675919389036, 'Total loss': 0.24846675919389036}
2023-01-05 03:18:34,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:34,300 INFO:     Epoch: 31
2023-01-05 03:18:36,526 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3685028399030367, 'Total loss': 0.3685028399030367} | train loss {'Reaction outcome loss': 0.2400124424039672, 'Total loss': 0.2400124424039672}
2023-01-05 03:18:36,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:36,526 INFO:     Epoch: 32
2023-01-05 03:18:38,689 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37436774174372356, 'Total loss': 0.37436774174372356} | train loss {'Reaction outcome loss': 0.24078718345571942, 'Total loss': 0.24078718345571942}
2023-01-05 03:18:38,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:38,689 INFO:     Epoch: 33
2023-01-05 03:18:40,941 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36450168962279955, 'Total loss': 0.36450168962279955} | train loss {'Reaction outcome loss': 0.2362657902419352, 'Total loss': 0.2362657902419352}
2023-01-05 03:18:40,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:40,942 INFO:     Epoch: 34
2023-01-05 03:18:43,123 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.365322408080101, 'Total loss': 0.365322408080101} | train loss {'Reaction outcome loss': 0.23615274866471328, 'Total loss': 0.23615274866471328}
2023-01-05 03:18:43,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:43,123 INFO:     Epoch: 35
2023-01-05 03:18:45,371 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3637621839841207, 'Total loss': 0.3637621839841207} | train loss {'Reaction outcome loss': 0.23183895298195767, 'Total loss': 0.23183895298195767}
2023-01-05 03:18:45,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:45,371 INFO:     Epoch: 36
2023-01-05 03:18:47,605 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3611242117981116, 'Total loss': 0.3611242117981116} | train loss {'Reaction outcome loss': 0.2299809689055254, 'Total loss': 0.2299809689055254}
2023-01-05 03:18:47,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:47,606 INFO:     Epoch: 37
2023-01-05 03:18:49,851 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37756966551144916, 'Total loss': 0.37756966551144916} | train loss {'Reaction outcome loss': 0.2259652958006097, 'Total loss': 0.2259652958006097}
2023-01-05 03:18:49,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:49,852 INFO:     Epoch: 38
2023-01-05 03:18:52,138 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36994569301605223, 'Total loss': 0.36994569301605223} | train loss {'Reaction outcome loss': 0.2266634821972477, 'Total loss': 0.2266634821972477}
2023-01-05 03:18:52,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:52,138 INFO:     Epoch: 39
2023-01-05 03:18:54,423 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37319987316926323, 'Total loss': 0.37319987316926323} | train loss {'Reaction outcome loss': 0.2257687915587253, 'Total loss': 0.2257687915587253}
2023-01-05 03:18:54,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:54,423 INFO:     Epoch: 40
2023-01-05 03:18:56,698 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37180235783259075, 'Total loss': 0.37180235783259075} | train loss {'Reaction outcome loss': 0.22033727484072696, 'Total loss': 0.22033727484072696}
2023-01-05 03:18:56,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:56,698 INFO:     Epoch: 41
2023-01-05 03:18:58,956 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3644056657950083, 'Total loss': 0.3644056657950083} | train loss {'Reaction outcome loss': 0.21849619337636642, 'Total loss': 0.21849619337636642}
2023-01-05 03:18:58,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:18:58,957 INFO:     Epoch: 42
2023-01-05 03:19:01,210 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37984529534975686, 'Total loss': 0.37984529534975686} | train loss {'Reaction outcome loss': 0.21476588137313346, 'Total loss': 0.21476588137313346}
2023-01-05 03:19:01,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:01,211 INFO:     Epoch: 43
2023-01-05 03:19:03,456 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36266423960526784, 'Total loss': 0.36266423960526784} | train loss {'Reaction outcome loss': 0.21430171415586333, 'Total loss': 0.21430171415586333}
2023-01-05 03:19:03,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:03,456 INFO:     Epoch: 44
2023-01-05 03:19:05,707 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.357687587539355, 'Total loss': 0.357687587539355} | train loss {'Reaction outcome loss': 0.2122514087720253, 'Total loss': 0.2122514087720253}
2023-01-05 03:19:05,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:05,707 INFO:     Epoch: 45
2023-01-05 03:19:07,958 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3704039520273606, 'Total loss': 0.3704039520273606} | train loss {'Reaction outcome loss': 0.2059294668762585, 'Total loss': 0.2059294668762585}
2023-01-05 03:19:07,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:07,958 INFO:     Epoch: 46
2023-01-05 03:19:10,142 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38421294167637826, 'Total loss': 0.38421294167637826} | train loss {'Reaction outcome loss': 0.20827649702025502, 'Total loss': 0.20827649702025502}
2023-01-05 03:19:10,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:10,142 INFO:     Epoch: 47
2023-01-05 03:19:12,407 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37135217686494193, 'Total loss': 0.37135217686494193} | train loss {'Reaction outcome loss': 0.20698796581671933, 'Total loss': 0.20698796581671933}
2023-01-05 03:19:12,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:12,407 INFO:     Epoch: 48
2023-01-05 03:19:14,622 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4025496418277423, 'Total loss': 0.4025496418277423} | train loss {'Reaction outcome loss': 0.20267819925564398, 'Total loss': 0.20267819925564398}
2023-01-05 03:19:14,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:14,622 INFO:     Epoch: 49
2023-01-05 03:19:16,888 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.335350180665652, 'Total loss': 0.335350180665652} | train loss {'Reaction outcome loss': 0.20271837819091948, 'Total loss': 0.20271837819091948}
2023-01-05 03:19:16,889 INFO:     Found new best model at epoch 49
2023-01-05 03:19:16,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:16,890 INFO:     Epoch: 50
2023-01-05 03:19:19,149 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3829597050944964, 'Total loss': 0.3829597050944964} | train loss {'Reaction outcome loss': 0.20203677992528096, 'Total loss': 0.20203677992528096}
2023-01-05 03:19:19,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:19,150 INFO:     Epoch: 51
2023-01-05 03:19:21,355 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37628790984551114, 'Total loss': 0.37628790984551114} | train loss {'Reaction outcome loss': 0.20190600917711585, 'Total loss': 0.20190600917711585}
2023-01-05 03:19:21,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:21,355 INFO:     Epoch: 52
2023-01-05 03:19:23,560 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3889981816212336, 'Total loss': 0.3889981816212336} | train loss {'Reaction outcome loss': 0.20014904779701456, 'Total loss': 0.20014904779701456}
2023-01-05 03:19:23,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:23,561 INFO:     Epoch: 53
2023-01-05 03:19:25,811 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38741840024789176, 'Total loss': 0.38741840024789176} | train loss {'Reaction outcome loss': 0.19478511065244675, 'Total loss': 0.19478511065244675}
2023-01-05 03:19:25,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:25,811 INFO:     Epoch: 54
2023-01-05 03:19:28,079 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38313716153303784, 'Total loss': 0.38313716153303784} | train loss {'Reaction outcome loss': 0.19724369907771852, 'Total loss': 0.19724369907771852}
2023-01-05 03:19:28,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:28,079 INFO:     Epoch: 55
2023-01-05 03:19:30,298 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37752181142568586, 'Total loss': 0.37752181142568586} | train loss {'Reaction outcome loss': 0.19741230314792493, 'Total loss': 0.19741230314792493}
2023-01-05 03:19:30,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:30,298 INFO:     Epoch: 56
2023-01-05 03:19:32,486 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3817792125046253, 'Total loss': 0.3817792125046253} | train loss {'Reaction outcome loss': 0.192545529713834, 'Total loss': 0.192545529713834}
2023-01-05 03:19:32,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:32,487 INFO:     Epoch: 57
2023-01-05 03:19:34,740 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3904018426934878, 'Total loss': 0.3904018426934878} | train loss {'Reaction outcome loss': 0.19504602352957434, 'Total loss': 0.19504602352957434}
2023-01-05 03:19:34,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:34,740 INFO:     Epoch: 58
2023-01-05 03:19:36,970 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3864021768172582, 'Total loss': 0.3864021768172582} | train loss {'Reaction outcome loss': 0.19058687197185703, 'Total loss': 0.19058687197185703}
2023-01-05 03:19:36,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:36,971 INFO:     Epoch: 59
2023-01-05 03:19:39,238 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37726599872112276, 'Total loss': 0.37726599872112276} | train loss {'Reaction outcome loss': 0.191494944629794, 'Total loss': 0.191494944629794}
2023-01-05 03:19:39,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:39,238 INFO:     Epoch: 60
2023-01-05 03:19:41,501 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3767046382029851, 'Total loss': 0.3767046382029851} | train loss {'Reaction outcome loss': 0.18780149547685784, 'Total loss': 0.18780149547685784}
2023-01-05 03:19:41,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:41,502 INFO:     Epoch: 61
2023-01-05 03:19:43,747 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40219380607207617, 'Total loss': 0.40219380607207617} | train loss {'Reaction outcome loss': 0.1867381062573797, 'Total loss': 0.1867381062573797}
2023-01-05 03:19:43,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:43,747 INFO:     Epoch: 62
2023-01-05 03:19:45,915 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36564625998338063, 'Total loss': 0.36564625998338063} | train loss {'Reaction outcome loss': 0.18747420669180284, 'Total loss': 0.18747420669180284}
2023-01-05 03:19:45,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:45,915 INFO:     Epoch: 63
2023-01-05 03:19:48,176 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3991923650105794, 'Total loss': 0.3991923650105794} | train loss {'Reaction outcome loss': 0.1899007424655024, 'Total loss': 0.1899007424655024}
2023-01-05 03:19:48,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:48,177 INFO:     Epoch: 64
2023-01-05 03:19:50,438 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4106884409983953, 'Total loss': 0.4106884409983953} | train loss {'Reaction outcome loss': 0.18104895857408213, 'Total loss': 0.18104895857408213}
2023-01-05 03:19:50,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:50,438 INFO:     Epoch: 65
2023-01-05 03:19:52,668 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3656724954644839, 'Total loss': 0.3656724954644839} | train loss {'Reaction outcome loss': 0.18393861699936784, 'Total loss': 0.18393861699936784}
2023-01-05 03:19:52,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:52,669 INFO:     Epoch: 66
2023-01-05 03:19:54,912 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3723487546046575, 'Total loss': 0.3723487546046575} | train loss {'Reaction outcome loss': 0.18029750982343154, 'Total loss': 0.18029750982343154}
2023-01-05 03:19:54,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:54,913 INFO:     Epoch: 67
2023-01-05 03:19:57,201 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3871618921558062, 'Total loss': 0.3871618921558062} | train loss {'Reaction outcome loss': 0.17891192053602706, 'Total loss': 0.17891192053602706}
2023-01-05 03:19:57,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:57,201 INFO:     Epoch: 68
2023-01-05 03:19:59,483 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3901711126168569, 'Total loss': 0.3901711126168569} | train loss {'Reaction outcome loss': 0.18373660440304543, 'Total loss': 0.18373660440304543}
2023-01-05 03:19:59,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:19:59,484 INFO:     Epoch: 69
2023-01-05 03:20:01,726 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3673643201589584, 'Total loss': 0.3673643201589584} | train loss {'Reaction outcome loss': 0.18428671020772375, 'Total loss': 0.18428671020772375}
2023-01-05 03:20:01,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:01,726 INFO:     Epoch: 70
2023-01-05 03:20:04,002 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38308982104063033, 'Total loss': 0.38308982104063033} | train loss {'Reaction outcome loss': 0.1778132941721794, 'Total loss': 0.1778132941721794}
2023-01-05 03:20:04,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:04,002 INFO:     Epoch: 71
2023-01-05 03:20:06,260 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3746012769639492, 'Total loss': 0.3746012769639492} | train loss {'Reaction outcome loss': 0.1763452628042401, 'Total loss': 0.1763452628042401}
2023-01-05 03:20:06,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:06,261 INFO:     Epoch: 72
2023-01-05 03:20:08,522 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3850840191046397, 'Total loss': 0.3850840191046397} | train loss {'Reaction outcome loss': 0.17490999598143495, 'Total loss': 0.17490999598143495}
2023-01-05 03:20:08,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:08,522 INFO:     Epoch: 73
2023-01-05 03:20:10,757 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3897227714459101, 'Total loss': 0.3897227714459101} | train loss {'Reaction outcome loss': 0.17831746777284233, 'Total loss': 0.17831746777284233}
2023-01-05 03:20:10,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:10,757 INFO:     Epoch: 74
2023-01-05 03:20:13,008 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38678245345751444, 'Total loss': 0.38678245345751444} | train loss {'Reaction outcome loss': 0.1784531750753253, 'Total loss': 0.1784531750753253}
2023-01-05 03:20:13,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:13,009 INFO:     Epoch: 75
2023-01-05 03:20:15,238 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37580511073271433, 'Total loss': 0.37580511073271433} | train loss {'Reaction outcome loss': 0.17096893654611728, 'Total loss': 0.17096893654611728}
2023-01-05 03:20:15,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:15,238 INFO:     Epoch: 76
2023-01-05 03:20:17,464 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35692993402481077, 'Total loss': 0.35692993402481077} | train loss {'Reaction outcome loss': 0.17542295402339542, 'Total loss': 0.17542295402339542}
2023-01-05 03:20:17,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:17,464 INFO:     Epoch: 77
2023-01-05 03:20:19,662 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3793798595666885, 'Total loss': 0.3793798595666885} | train loss {'Reaction outcome loss': 0.17236646845439174, 'Total loss': 0.17236646845439174}
2023-01-05 03:20:19,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:19,663 INFO:     Epoch: 78
2023-01-05 03:20:21,904 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37920677065849306, 'Total loss': 0.37920677065849306} | train loss {'Reaction outcome loss': 0.17376887562284615, 'Total loss': 0.17376887562284615}
2023-01-05 03:20:21,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:21,904 INFO:     Epoch: 79
2023-01-05 03:20:24,113 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3661764507492383, 'Total loss': 0.3661764507492383} | train loss {'Reaction outcome loss': 0.17324409098616575, 'Total loss': 0.17324409098616575}
2023-01-05 03:20:24,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:24,113 INFO:     Epoch: 80
2023-01-05 03:20:26,313 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3812140832344691, 'Total loss': 0.3812140832344691} | train loss {'Reaction outcome loss': 0.17495608060126486, 'Total loss': 0.17495608060126486}
2023-01-05 03:20:26,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:26,313 INFO:     Epoch: 81
2023-01-05 03:20:28,524 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3662794937690099, 'Total loss': 0.3662794937690099} | train loss {'Reaction outcome loss': 0.16588046445279292, 'Total loss': 0.16588046445279292}
2023-01-05 03:20:28,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:28,526 INFO:     Epoch: 82
2023-01-05 03:20:30,741 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40257585247357686, 'Total loss': 0.40257585247357686} | train loss {'Reaction outcome loss': 0.16549533318782003, 'Total loss': 0.16549533318782003}
2023-01-05 03:20:30,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:30,742 INFO:     Epoch: 83
2023-01-05 03:20:32,984 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41630785365899403, 'Total loss': 0.41630785365899403} | train loss {'Reaction outcome loss': 0.1714627914406386, 'Total loss': 0.1714627914406386}
2023-01-05 03:20:32,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:32,984 INFO:     Epoch: 84
2023-01-05 03:20:35,235 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38363078037897747, 'Total loss': 0.38363078037897747} | train loss {'Reaction outcome loss': 0.16827839727274777, 'Total loss': 0.16827839727274777}
2023-01-05 03:20:35,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:35,236 INFO:     Epoch: 85
2023-01-05 03:20:37,469 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38156933983167013, 'Total loss': 0.38156933983167013} | train loss {'Reaction outcome loss': 0.16581774143407976, 'Total loss': 0.16581774143407976}
2023-01-05 03:20:37,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:37,469 INFO:     Epoch: 86
2023-01-05 03:20:39,706 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36445408562819165, 'Total loss': 0.36445408562819165} | train loss {'Reaction outcome loss': 0.16715896256530274, 'Total loss': 0.16715896256530274}
2023-01-05 03:20:39,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:39,707 INFO:     Epoch: 87
2023-01-05 03:20:41,931 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39543527861436206, 'Total loss': 0.39543527861436206} | train loss {'Reaction outcome loss': 0.16773421902105293, 'Total loss': 0.16773421902105293}
2023-01-05 03:20:41,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:41,932 INFO:     Epoch: 88
2023-01-05 03:20:44,118 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3632437122364839, 'Total loss': 0.3632437122364839} | train loss {'Reaction outcome loss': 0.16611876828253053, 'Total loss': 0.16611876828253053}
2023-01-05 03:20:44,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:44,118 INFO:     Epoch: 89
2023-01-05 03:20:46,309 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38270631233851116, 'Total loss': 0.38270631233851116} | train loss {'Reaction outcome loss': 0.16720380159162174, 'Total loss': 0.16720380159162174}
2023-01-05 03:20:46,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:46,310 INFO:     Epoch: 90
2023-01-05 03:20:48,553 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3683185706535975, 'Total loss': 0.3683185706535975} | train loss {'Reaction outcome loss': 0.1640984051918026, 'Total loss': 0.1640984051918026}
2023-01-05 03:20:48,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:48,554 INFO:     Epoch: 91
2023-01-05 03:20:50,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39806089699268343, 'Total loss': 0.39806089699268343} | train loss {'Reaction outcome loss': 0.16329181450503183, 'Total loss': 0.16329181450503183}
2023-01-05 03:20:50,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:50,796 INFO:     Epoch: 92
2023-01-05 03:20:53,046 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3951115536193053, 'Total loss': 0.3951115536193053} | train loss {'Reaction outcome loss': 0.1621817377587572, 'Total loss': 0.1621817377587572}
2023-01-05 03:20:53,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:53,046 INFO:     Epoch: 93
2023-01-05 03:20:55,309 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3900998751322428, 'Total loss': 0.3900998751322428} | train loss {'Reaction outcome loss': 0.16543371283990543, 'Total loss': 0.16543371283990543}
2023-01-05 03:20:55,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:55,309 INFO:     Epoch: 94
2023-01-05 03:20:57,587 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3995829035838445, 'Total loss': 0.3995829035838445} | train loss {'Reaction outcome loss': 0.16129691045502678, 'Total loss': 0.16129691045502678}
2023-01-05 03:20:57,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:57,587 INFO:     Epoch: 95
2023-01-05 03:20:59,874 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37102388342221576, 'Total loss': 0.37102388342221576} | train loss {'Reaction outcome loss': 0.16364675863656059, 'Total loss': 0.16364675863656059}
2023-01-05 03:20:59,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:20:59,874 INFO:     Epoch: 96
2023-01-05 03:21:02,155 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37437690372268356, 'Total loss': 0.37437690372268356} | train loss {'Reaction outcome loss': 0.1577804825749477, 'Total loss': 0.1577804825749477}
2023-01-05 03:21:02,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:02,155 INFO:     Epoch: 97
2023-01-05 03:21:04,435 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.399140660961469, 'Total loss': 0.399140660961469} | train loss {'Reaction outcome loss': 0.16044592228634047, 'Total loss': 0.16044592228634047}
2023-01-05 03:21:04,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:04,436 INFO:     Epoch: 98
2023-01-05 03:21:06,684 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3783085117737452, 'Total loss': 0.3783085117737452} | train loss {'Reaction outcome loss': 0.1537403271765539, 'Total loss': 0.1537403271765539}
2023-01-05 03:21:06,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:06,684 INFO:     Epoch: 99
2023-01-05 03:21:08,981 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37511895696322123, 'Total loss': 0.37511895696322123} | train loss {'Reaction outcome loss': 0.15872070403258562, 'Total loss': 0.15872070403258562}
2023-01-05 03:21:08,982 INFO:     Best model found after epoch 50 of 100.
2023-01-05 03:21:08,982 INFO:   Done with stage: TRAINING
2023-01-05 03:21:08,982 INFO:   Starting stage: EVALUATION
2023-01-05 03:21:09,111 INFO:   Done with stage: EVALUATION
2023-01-05 03:21:09,119 INFO:   Leaving out SEQ value Fold_0
2023-01-05 03:21:09,132 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:21:09,133 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:21:09,787 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:21:09,787 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:21:09,857 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:21:09,857 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:21:09,857 INFO:     No hyperparam tuning for this model
2023-01-05 03:21:09,857 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:21:09,857 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:21:09,858 INFO:     None feature selector for col prot
2023-01-05 03:21:09,858 INFO:     None feature selector for col prot
2023-01-05 03:21:09,858 INFO:     None feature selector for col prot
2023-01-05 03:21:09,859 INFO:     None feature selector for col chem
2023-01-05 03:21:09,859 INFO:     None feature selector for col chem
2023-01-05 03:21:09,859 INFO:     None feature selector for col chem
2023-01-05 03:21:09,859 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:21:09,859 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:21:09,861 INFO:     Number of params in model 72931
2023-01-05 03:21:09,864 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:21:09,864 INFO:   Starting stage: TRAINING
2023-01-05 03:21:09,924 INFO:     Val loss before train {'Reaction outcome loss': 0.9672020872433981, 'Total loss': 0.9672020872433981}
2023-01-05 03:21:09,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:09,924 INFO:     Epoch: 0
2023-01-05 03:21:12,212 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7435978809992473, 'Total loss': 0.7435978809992473} | train loss {'Reaction outcome loss': 0.9437132210005602, 'Total loss': 0.9437132210005602}
2023-01-05 03:21:12,213 INFO:     Found new best model at epoch 0
2023-01-05 03:21:12,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:12,215 INFO:     Epoch: 1
2023-01-05 03:21:14,509 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5268895665804545, 'Total loss': 0.5268895665804545} | train loss {'Reaction outcome loss': 0.641876528780246, 'Total loss': 0.641876528780246}
2023-01-05 03:21:14,509 INFO:     Found new best model at epoch 1
2023-01-05 03:21:14,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:14,511 INFO:     Epoch: 2
2023-01-05 03:21:16,785 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4948454757531484, 'Total loss': 0.4948454757531484} | train loss {'Reaction outcome loss': 0.5431269453703493, 'Total loss': 0.5431269453703493}
2023-01-05 03:21:16,786 INFO:     Found new best model at epoch 2
2023-01-05 03:21:16,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:16,787 INFO:     Epoch: 3
2023-01-05 03:21:19,062 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44716291228930155, 'Total loss': 0.44716291228930155} | train loss {'Reaction outcome loss': 0.4971138936656433, 'Total loss': 0.4971138936656433}
2023-01-05 03:21:19,062 INFO:     Found new best model at epoch 3
2023-01-05 03:21:19,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:19,063 INFO:     Epoch: 4
2023-01-05 03:21:21,355 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44615260461966194, 'Total loss': 0.44615260461966194} | train loss {'Reaction outcome loss': 0.4616979383053663, 'Total loss': 0.4616979383053663}
2023-01-05 03:21:21,355 INFO:     Found new best model at epoch 4
2023-01-05 03:21:21,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:21,356 INFO:     Epoch: 5
2023-01-05 03:21:23,642 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4248030920823415, 'Total loss': 0.4248030920823415} | train loss {'Reaction outcome loss': 0.43482709122632723, 'Total loss': 0.43482709122632723}
2023-01-05 03:21:23,642 INFO:     Found new best model at epoch 5
2023-01-05 03:21:23,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:23,643 INFO:     Epoch: 6
2023-01-05 03:21:25,934 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4073577612638474, 'Total loss': 0.4073577612638474} | train loss {'Reaction outcome loss': 0.4167347895183965, 'Total loss': 0.4167347895183965}
2023-01-05 03:21:25,934 INFO:     Found new best model at epoch 6
2023-01-05 03:21:25,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:25,936 INFO:     Epoch: 7
2023-01-05 03:21:28,210 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3936228805532058, 'Total loss': 0.3936228805532058} | train loss {'Reaction outcome loss': 0.3995509940483, 'Total loss': 0.3995509940483}
2023-01-05 03:21:28,210 INFO:     Found new best model at epoch 7
2023-01-05 03:21:28,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:28,212 INFO:     Epoch: 8
2023-01-05 03:21:30,501 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.432600192228953, 'Total loss': 0.432600192228953} | train loss {'Reaction outcome loss': 0.3871848910669054, 'Total loss': 0.3871848910669054}
2023-01-05 03:21:30,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:30,501 INFO:     Epoch: 9
2023-01-05 03:21:32,830 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40405816237131753, 'Total loss': 0.40405816237131753} | train loss {'Reaction outcome loss': 0.3788969001816704, 'Total loss': 0.3788969001816704}
2023-01-05 03:21:32,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:32,830 INFO:     Epoch: 10
2023-01-05 03:21:35,113 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40135993659496305, 'Total loss': 0.40135993659496305} | train loss {'Reaction outcome loss': 0.36197455961297714, 'Total loss': 0.36197455961297714}
2023-01-05 03:21:35,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:35,113 INFO:     Epoch: 11
2023-01-05 03:21:37,387 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4172387878100077, 'Total loss': 0.4172387878100077} | train loss {'Reaction outcome loss': 0.3507449823685591, 'Total loss': 0.3507449823685591}
2023-01-05 03:21:37,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:37,388 INFO:     Epoch: 12
2023-01-05 03:21:39,506 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43551418582598367, 'Total loss': 0.43551418582598367} | train loss {'Reaction outcome loss': 0.3422727238494849, 'Total loss': 0.3422727238494849}
2023-01-05 03:21:39,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:39,506 INFO:     Epoch: 13
2023-01-05 03:21:41,755 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37581466635068256, 'Total loss': 0.37581466635068256} | train loss {'Reaction outcome loss': 0.33636037517630873, 'Total loss': 0.33636037517630873}
2023-01-05 03:21:41,756 INFO:     Found new best model at epoch 13
2023-01-05 03:21:41,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:41,758 INFO:     Epoch: 14
2023-01-05 03:21:44,021 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3963410129149755, 'Total loss': 0.3963410129149755} | train loss {'Reaction outcome loss': 0.32441889204663155, 'Total loss': 0.32441889204663155}
2023-01-05 03:21:44,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:44,021 INFO:     Epoch: 15
2023-01-05 03:21:46,256 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4035290400187174, 'Total loss': 0.4035290400187174} | train loss {'Reaction outcome loss': 0.32249112878133124, 'Total loss': 0.32249112878133124}
2023-01-05 03:21:46,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:46,256 INFO:     Epoch: 16
2023-01-05 03:21:48,478 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4091584950685501, 'Total loss': 0.4091584950685501} | train loss {'Reaction outcome loss': 0.3096023904019629, 'Total loss': 0.3096023904019629}
2023-01-05 03:21:48,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:48,479 INFO:     Epoch: 17
2023-01-05 03:21:50,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39346903239687286, 'Total loss': 0.39346903239687286} | train loss {'Reaction outcome loss': 0.2983831483904488, 'Total loss': 0.2983831483904488}
2023-01-05 03:21:50,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:50,735 INFO:     Epoch: 18
2023-01-05 03:21:52,924 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39808003703753153, 'Total loss': 0.39808003703753153} | train loss {'Reaction outcome loss': 0.2983336327329659, 'Total loss': 0.2983336327329659}
2023-01-05 03:21:52,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:52,925 INFO:     Epoch: 19
2023-01-05 03:21:55,194 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36946865071853, 'Total loss': 0.36946865071853} | train loss {'Reaction outcome loss': 0.28549932304588804, 'Total loss': 0.28549932304588804}
2023-01-05 03:21:55,194 INFO:     Found new best model at epoch 19
2023-01-05 03:21:55,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:55,195 INFO:     Epoch: 20
2023-01-05 03:21:57,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3833733320236206, 'Total loss': 0.3833733320236206} | train loss {'Reaction outcome loss': 0.28472798640259367, 'Total loss': 0.28472798640259367}
2023-01-05 03:21:57,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:57,472 INFO:     Epoch: 21
2023-01-05 03:21:59,748 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3953227172295252, 'Total loss': 0.3953227172295252} | train loss {'Reaction outcome loss': 0.27761560417222453, 'Total loss': 0.27761560417222453}
2023-01-05 03:21:59,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:21:59,748 INFO:     Epoch: 22
2023-01-05 03:22:02,040 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4005635152260462, 'Total loss': 0.4005635152260462} | train loss {'Reaction outcome loss': 0.27321064150959684, 'Total loss': 0.27321064150959684}
2023-01-05 03:22:02,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:02,041 INFO:     Epoch: 23
2023-01-05 03:22:04,273 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3912173102299372, 'Total loss': 0.3912173102299372} | train loss {'Reaction outcome loss': 0.27043569576589094, 'Total loss': 0.27043569576589094}
2023-01-05 03:22:04,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:04,273 INFO:     Epoch: 24
2023-01-05 03:22:06,552 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4041789690653483, 'Total loss': 0.4041789690653483} | train loss {'Reaction outcome loss': 0.2637533025100719, 'Total loss': 0.2637533025100719}
2023-01-05 03:22:06,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:06,553 INFO:     Epoch: 25
2023-01-05 03:22:08,855 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39945771197477975, 'Total loss': 0.39945771197477975} | train loss {'Reaction outcome loss': 0.26008936905207625, 'Total loss': 0.26008936905207625}
2023-01-05 03:22:08,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:08,855 INFO:     Epoch: 26
2023-01-05 03:22:11,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4157637884219488, 'Total loss': 0.4157637884219488} | train loss {'Reaction outcome loss': 0.25623500347474887, 'Total loss': 0.25623500347474887}
2023-01-05 03:22:11,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:11,152 INFO:     Epoch: 27
2023-01-05 03:22:13,434 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40980320374170937, 'Total loss': 0.40980320374170937} | train loss {'Reaction outcome loss': 0.25498916778335534, 'Total loss': 0.25498916778335534}
2023-01-05 03:22:13,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:13,434 INFO:     Epoch: 28
2023-01-05 03:22:15,731 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4233066201210022, 'Total loss': 0.4233066201210022} | train loss {'Reaction outcome loss': 0.2506989775654907, 'Total loss': 0.2506989775654907}
2023-01-05 03:22:15,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:15,731 INFO:     Epoch: 29
2023-01-05 03:22:18,088 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3989462246497472, 'Total loss': 0.3989462246497472} | train loss {'Reaction outcome loss': 0.2509859539365963, 'Total loss': 0.2509859539365963}
2023-01-05 03:22:18,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:18,089 INFO:     Epoch: 30
2023-01-05 03:22:20,466 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39650926887989046, 'Total loss': 0.39650926887989046} | train loss {'Reaction outcome loss': 0.24656807093719102, 'Total loss': 0.24656807093719102}
2023-01-05 03:22:20,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:20,466 INFO:     Epoch: 31
2023-01-05 03:22:22,842 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40017458895842234, 'Total loss': 0.40017458895842234} | train loss {'Reaction outcome loss': 0.24171185028482822, 'Total loss': 0.24171185028482822}
2023-01-05 03:22:22,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:22,842 INFO:     Epoch: 32
2023-01-05 03:22:25,120 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44035116136074065, 'Total loss': 0.44035116136074065} | train loss {'Reaction outcome loss': 0.23315383689613015, 'Total loss': 0.23315383689613015}
2023-01-05 03:22:25,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:25,120 INFO:     Epoch: 33
2023-01-05 03:22:27,363 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.401325265566508, 'Total loss': 0.401325265566508} | train loss {'Reaction outcome loss': 0.23914350596243056, 'Total loss': 0.23914350596243056}
2023-01-05 03:22:27,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:27,363 INFO:     Epoch: 34
2023-01-05 03:22:29,637 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3938445431490739, 'Total loss': 0.3938445431490739} | train loss {'Reaction outcome loss': 0.22902038963207894, 'Total loss': 0.22902038963207894}
2023-01-05 03:22:29,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:29,637 INFO:     Epoch: 35
2023-01-05 03:22:31,910 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.403372301099201, 'Total loss': 0.403372301099201} | train loss {'Reaction outcome loss': 0.232193861647671, 'Total loss': 0.232193861647671}
2023-01-05 03:22:31,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:31,911 INFO:     Epoch: 36
2023-01-05 03:22:34,177 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40442024171352386, 'Total loss': 0.40442024171352386} | train loss {'Reaction outcome loss': 0.2274354852658386, 'Total loss': 0.2274354852658386}
2023-01-05 03:22:34,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:34,178 INFO:     Epoch: 37
2023-01-05 03:22:36,418 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4114903748035431, 'Total loss': 0.4114903748035431} | train loss {'Reaction outcome loss': 0.22705435497665097, 'Total loss': 0.22705435497665097}
2023-01-05 03:22:36,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:36,418 INFO:     Epoch: 38
2023-01-05 03:22:38,678 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4323906868696213, 'Total loss': 0.4323906868696213} | train loss {'Reaction outcome loss': 0.21858874117226704, 'Total loss': 0.21858874117226704}
2023-01-05 03:22:38,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:38,678 INFO:     Epoch: 39
2023-01-05 03:22:40,927 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4008499542872111, 'Total loss': 0.4008499542872111} | train loss {'Reaction outcome loss': 0.2238797792132296, 'Total loss': 0.2238797792132296}
2023-01-05 03:22:40,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:40,928 INFO:     Epoch: 40
2023-01-05 03:22:43,180 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4163916622598966, 'Total loss': 0.4163916622598966} | train loss {'Reaction outcome loss': 0.22025736574846963, 'Total loss': 0.22025736574846963}
2023-01-05 03:22:43,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:43,180 INFO:     Epoch: 41
2023-01-05 03:22:45,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40970401267210643, 'Total loss': 0.40970401267210643} | train loss {'Reaction outcome loss': 0.22132386349340263, 'Total loss': 0.22132386349340263}
2023-01-05 03:22:45,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:45,420 INFO:     Epoch: 42
2023-01-05 03:22:47,600 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39223941415548325, 'Total loss': 0.39223941415548325} | train loss {'Reaction outcome loss': 0.2149986805482025, 'Total loss': 0.2149986805482025}
2023-01-05 03:22:47,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:47,601 INFO:     Epoch: 43
2023-01-05 03:22:49,836 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.420519033074379, 'Total loss': 0.420519033074379} | train loss {'Reaction outcome loss': 0.21741492728756714, 'Total loss': 0.21741492728756714}
2023-01-05 03:22:49,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:49,836 INFO:     Epoch: 44
2023-01-05 03:22:52,064 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43197441697120664, 'Total loss': 0.43197441697120664} | train loss {'Reaction outcome loss': 0.21451045846755523, 'Total loss': 0.21451045846755523}
2023-01-05 03:22:52,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:52,065 INFO:     Epoch: 45
2023-01-05 03:22:54,319 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3975676308075587, 'Total loss': 0.3975676308075587} | train loss {'Reaction outcome loss': 0.2182254281724454, 'Total loss': 0.2182254281724454}
2023-01-05 03:22:54,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:54,320 INFO:     Epoch: 46
2023-01-05 03:22:56,575 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4517324388027191, 'Total loss': 0.4517324388027191} | train loss {'Reaction outcome loss': 0.20888083751850095, 'Total loss': 0.20888083751850095}
2023-01-05 03:22:56,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:56,575 INFO:     Epoch: 47
2023-01-05 03:22:58,839 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42664307554562886, 'Total loss': 0.42664307554562886} | train loss {'Reaction outcome loss': 0.2057501442970428, 'Total loss': 0.2057501442970428}
2023-01-05 03:22:58,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:22:58,839 INFO:     Epoch: 48
2023-01-05 03:23:01,095 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4419014116128286, 'Total loss': 0.4419014116128286} | train loss {'Reaction outcome loss': 0.2100606465432118, 'Total loss': 0.2100606465432118}
2023-01-05 03:23:01,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:01,095 INFO:     Epoch: 49
2023-01-05 03:23:03,300 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43009338875611625, 'Total loss': 0.43009338875611625} | train loss {'Reaction outcome loss': 0.20533519791965577, 'Total loss': 0.20533519791965577}
2023-01-05 03:23:03,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:03,300 INFO:     Epoch: 50
2023-01-05 03:23:05,458 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44733087917168934, 'Total loss': 0.44733087917168934} | train loss {'Reaction outcome loss': 0.2197428690539538, 'Total loss': 0.2197428690539538}
2023-01-05 03:23:05,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:05,459 INFO:     Epoch: 51
2023-01-05 03:23:07,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40972676674524944, 'Total loss': 0.40972676674524944} | train loss {'Reaction outcome loss': 0.23219927322065484, 'Total loss': 0.23219927322065484}
2023-01-05 03:23:07,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:07,636 INFO:     Epoch: 52
2023-01-05 03:23:09,860 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3985700865586599, 'Total loss': 0.3985700865586599} | train loss {'Reaction outcome loss': 0.20672667093669483, 'Total loss': 0.20672667093669483}
2023-01-05 03:23:09,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:09,860 INFO:     Epoch: 53
2023-01-05 03:23:12,125 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4157423354685307, 'Total loss': 0.4157423354685307} | train loss {'Reaction outcome loss': 0.2046815281416681, 'Total loss': 0.2046815281416681}
2023-01-05 03:23:12,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:12,125 INFO:     Epoch: 54
2023-01-05 03:23:14,371 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4292675336201986, 'Total loss': 0.4292675336201986} | train loss {'Reaction outcome loss': 0.2009985192581434, 'Total loss': 0.2009985192581434}
2023-01-05 03:23:14,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:14,371 INFO:     Epoch: 55
2023-01-05 03:23:16,699 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.400382000207901, 'Total loss': 0.400382000207901} | train loss {'Reaction outcome loss': 0.19757674078362575, 'Total loss': 0.19757674078362575}
2023-01-05 03:23:16,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:16,699 INFO:     Epoch: 56
2023-01-05 03:23:18,992 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41756207471092543, 'Total loss': 0.41756207471092543} | train loss {'Reaction outcome loss': 0.19095724622081395, 'Total loss': 0.19095724622081395}
2023-01-05 03:23:18,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:18,993 INFO:     Epoch: 57
2023-01-05 03:23:21,212 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4423630644877752, 'Total loss': 0.4423630644877752} | train loss {'Reaction outcome loss': 0.19353081226417207, 'Total loss': 0.19353081226417207}
2023-01-05 03:23:21,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:21,212 INFO:     Epoch: 58
2023-01-05 03:23:23,457 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40187668800354004, 'Total loss': 0.40187668800354004} | train loss {'Reaction outcome loss': 0.1919901567548939, 'Total loss': 0.1919901567548939}
2023-01-05 03:23:23,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:23,458 INFO:     Epoch: 59
2023-01-05 03:23:25,641 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45402466133236885, 'Total loss': 0.45402466133236885} | train loss {'Reaction outcome loss': 0.19360800058896438, 'Total loss': 0.19360800058896438}
2023-01-05 03:23:25,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:25,641 INFO:     Epoch: 60
2023-01-05 03:23:27,831 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44967954556147255, 'Total loss': 0.44967954556147255} | train loss {'Reaction outcome loss': 0.18676145252623205, 'Total loss': 0.18676145252623205}
2023-01-05 03:23:27,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:27,831 INFO:     Epoch: 61
2023-01-05 03:23:29,956 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4328626016775767, 'Total loss': 0.4328626016775767} | train loss {'Reaction outcome loss': 0.19386822317408034, 'Total loss': 0.19386822317408034}
2023-01-05 03:23:29,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:29,957 INFO:     Epoch: 62
2023-01-05 03:23:32,201 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41066330919663113, 'Total loss': 0.41066330919663113} | train loss {'Reaction outcome loss': 0.18802897956397763, 'Total loss': 0.18802897956397763}
2023-01-05 03:23:32,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:32,201 INFO:     Epoch: 63
2023-01-05 03:23:34,437 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4627466231584549, 'Total loss': 0.4627466231584549} | train loss {'Reaction outcome loss': 0.1894868811589507, 'Total loss': 0.1894868811589507}
2023-01-05 03:23:34,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:34,437 INFO:     Epoch: 64
2023-01-05 03:23:36,615 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4216824551423391, 'Total loss': 0.4216824551423391} | train loss {'Reaction outcome loss': 0.18822533247167367, 'Total loss': 0.18822533247167367}
2023-01-05 03:23:36,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:36,616 INFO:     Epoch: 65
2023-01-05 03:23:38,773 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4005406588315964, 'Total loss': 0.4005406588315964} | train loss {'Reaction outcome loss': 0.1899064732161882, 'Total loss': 0.1899064732161882}
2023-01-05 03:23:38,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:38,774 INFO:     Epoch: 66
2023-01-05 03:23:40,959 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43633196254571277, 'Total loss': 0.43633196254571277} | train loss {'Reaction outcome loss': 0.17831491323295925, 'Total loss': 0.17831491323295925}
2023-01-05 03:23:40,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:40,960 INFO:     Epoch: 67
2023-01-05 03:23:43,167 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46015650232632954, 'Total loss': 0.46015650232632954} | train loss {'Reaction outcome loss': 0.18385946304173875, 'Total loss': 0.18385946304173875}
2023-01-05 03:23:43,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:43,167 INFO:     Epoch: 68
2023-01-05 03:23:45,391 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43800825426975887, 'Total loss': 0.43800825426975887} | train loss {'Reaction outcome loss': 0.18379779576755845, 'Total loss': 0.18379779576755845}
2023-01-05 03:23:45,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:45,391 INFO:     Epoch: 69
2023-01-05 03:23:47,637 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4507787972688675, 'Total loss': 0.4507787972688675} | train loss {'Reaction outcome loss': 0.19161789201915372, 'Total loss': 0.19161789201915372}
2023-01-05 03:23:47,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:47,637 INFO:     Epoch: 70
2023-01-05 03:23:49,775 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43945203522841136, 'Total loss': 0.43945203522841136} | train loss {'Reaction outcome loss': 0.19950708570431216, 'Total loss': 0.19950708570431216}
2023-01-05 03:23:49,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:49,776 INFO:     Epoch: 71
2023-01-05 03:23:51,992 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4726435979207357, 'Total loss': 0.4726435979207357} | train loss {'Reaction outcome loss': 0.18048018103370297, 'Total loss': 0.18048018103370297}
2023-01-05 03:23:51,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:51,992 INFO:     Epoch: 72
2023-01-05 03:23:54,163 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46658628980318706, 'Total loss': 0.46658628980318706} | train loss {'Reaction outcome loss': 0.2089140381599925, 'Total loss': 0.2089140381599925}
2023-01-05 03:23:54,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:54,163 INFO:     Epoch: 73
2023-01-05 03:23:56,439 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44227364857991536, 'Total loss': 0.44227364857991536} | train loss {'Reaction outcome loss': 0.1832683519131261, 'Total loss': 0.1832683519131261}
2023-01-05 03:23:56,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:56,439 INFO:     Epoch: 74
2023-01-05 03:23:58,684 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42987464418013893, 'Total loss': 0.42987464418013893} | train loss {'Reaction outcome loss': 0.17661480803339594, 'Total loss': 0.17661480803339594}
2023-01-05 03:23:58,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:23:58,685 INFO:     Epoch: 75
2023-01-05 03:24:00,917 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4154174233476321, 'Total loss': 0.4154174233476321} | train loss {'Reaction outcome loss': 0.1784878694789781, 'Total loss': 0.1784878694789781}
2023-01-05 03:24:00,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:00,917 INFO:     Epoch: 76
2023-01-05 03:24:03,157 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4465472569068273, 'Total loss': 0.4465472569068273} | train loss {'Reaction outcome loss': 0.1927453652581038, 'Total loss': 0.1927453652581038}
2023-01-05 03:24:03,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:03,157 INFO:     Epoch: 77
2023-01-05 03:24:05,428 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4603018045425415, 'Total loss': 0.4603018045425415} | train loss {'Reaction outcome loss': 0.27305744631355966, 'Total loss': 0.27305744631355966}
2023-01-05 03:24:05,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:05,429 INFO:     Epoch: 78
2023-01-05 03:24:07,572 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46169635554154714, 'Total loss': 0.46169635554154714} | train loss {'Reaction outcome loss': 0.19029913705847887, 'Total loss': 0.19029913705847887}
2023-01-05 03:24:07,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:07,572 INFO:     Epoch: 79
2023-01-05 03:24:09,769 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44140696128209433, 'Total loss': 0.44140696128209433} | train loss {'Reaction outcome loss': 0.17886877990584227, 'Total loss': 0.17886877990584227}
2023-01-05 03:24:09,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:09,770 INFO:     Epoch: 80
2023-01-05 03:24:12,007 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44987944066524505, 'Total loss': 0.44987944066524505} | train loss {'Reaction outcome loss': 0.17693016344877094, 'Total loss': 0.17693016344877094}
2023-01-05 03:24:12,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:12,007 INFO:     Epoch: 81
2023-01-05 03:24:14,276 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4378535389900208, 'Total loss': 0.4378535389900208} | train loss {'Reaction outcome loss': 0.17475960400409257, 'Total loss': 0.17475960400409257}
2023-01-05 03:24:14,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:14,276 INFO:     Epoch: 82
2023-01-05 03:24:16,504 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4408963407079379, 'Total loss': 0.4408963407079379} | train loss {'Reaction outcome loss': 0.1736806119695994, 'Total loss': 0.1736806119695994}
2023-01-05 03:24:16,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:16,504 INFO:     Epoch: 83
2023-01-05 03:24:18,658 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42909313589334486, 'Total loss': 0.42909313589334486} | train loss {'Reaction outcome loss': 0.1726824861570081, 'Total loss': 0.1726824861570081}
2023-01-05 03:24:18,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:18,659 INFO:     Epoch: 84
2023-01-05 03:24:20,921 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4411493425567945, 'Total loss': 0.4411493425567945} | train loss {'Reaction outcome loss': 0.16886394134063312, 'Total loss': 0.16886394134063312}
2023-01-05 03:24:20,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:20,921 INFO:     Epoch: 85
2023-01-05 03:24:23,098 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4428044597307841, 'Total loss': 0.4428044597307841} | train loss {'Reaction outcome loss': 0.17278336636819944, 'Total loss': 0.17278336636819944}
2023-01-05 03:24:23,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:23,098 INFO:     Epoch: 86
2023-01-05 03:24:25,321 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4130520964662234, 'Total loss': 0.4130520964662234} | train loss {'Reaction outcome loss': 0.16856287115066743, 'Total loss': 0.16856287115066743}
2023-01-05 03:24:25,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:25,321 INFO:     Epoch: 87
2023-01-05 03:24:27,567 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4374389121929804, 'Total loss': 0.4374389121929804} | train loss {'Reaction outcome loss': 0.17027756901781843, 'Total loss': 0.17027756901781843}
2023-01-05 03:24:27,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:27,568 INFO:     Epoch: 88
2023-01-05 03:24:29,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4489678571621577, 'Total loss': 0.4489678571621577} | train loss {'Reaction outcome loss': 0.16737000863583218, 'Total loss': 0.16737000863583218}
2023-01-05 03:24:29,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:29,794 INFO:     Epoch: 89
2023-01-05 03:24:32,024 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46290411551793414, 'Total loss': 0.46290411551793414} | train loss {'Reaction outcome loss': 0.171681186504851, 'Total loss': 0.171681186504851}
2023-01-05 03:24:32,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:32,025 INFO:     Epoch: 90
2023-01-05 03:24:34,237 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47259403864542643, 'Total loss': 0.47259403864542643} | train loss {'Reaction outcome loss': 0.17838487010094864, 'Total loss': 0.17838487010094864}
2023-01-05 03:24:34,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:34,238 INFO:     Epoch: 91
2023-01-05 03:24:36,450 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4295553982257843, 'Total loss': 0.4295553982257843} | train loss {'Reaction outcome loss': 0.17004593817999694, 'Total loss': 0.17004593817999694}
2023-01-05 03:24:36,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:36,450 INFO:     Epoch: 92
2023-01-05 03:24:38,701 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42578380803267163, 'Total loss': 0.42578380803267163} | train loss {'Reaction outcome loss': 0.1714865302037915, 'Total loss': 0.1714865302037915}
2023-01-05 03:24:38,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:38,701 INFO:     Epoch: 93
2023-01-05 03:24:40,952 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4184550493955612, 'Total loss': 0.4184550493955612} | train loss {'Reaction outcome loss': 0.17014886924659114, 'Total loss': 0.17014886924659114}
2023-01-05 03:24:40,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:40,953 INFO:     Epoch: 94
2023-01-05 03:24:43,138 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45471102992693585, 'Total loss': 0.45471102992693585} | train loss {'Reaction outcome loss': 0.16643857694546477, 'Total loss': 0.16643857694546477}
2023-01-05 03:24:43,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:43,138 INFO:     Epoch: 95
2023-01-05 03:24:45,328 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4499264985322952, 'Total loss': 0.4499264985322952} | train loss {'Reaction outcome loss': 0.16499587793984666, 'Total loss': 0.16499587793984666}
2023-01-05 03:24:45,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:45,329 INFO:     Epoch: 96
2023-01-05 03:24:47,544 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4477038363615672, 'Total loss': 0.4477038363615672} | train loss {'Reaction outcome loss': 0.16323702212801014, 'Total loss': 0.16323702212801014}
2023-01-05 03:24:47,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:47,544 INFO:     Epoch: 97
2023-01-05 03:24:49,816 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4476486504077911, 'Total loss': 0.4476486504077911} | train loss {'Reaction outcome loss': 0.165615414381255, 'Total loss': 0.165615414381255}
2023-01-05 03:24:49,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:49,816 INFO:     Epoch: 98
2023-01-05 03:24:52,037 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45296601752440135, 'Total loss': 0.45296601752440135} | train loss {'Reaction outcome loss': 0.16742702784435148, 'Total loss': 0.16742702784435148}
2023-01-05 03:24:52,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:52,037 INFO:     Epoch: 99
2023-01-05 03:24:54,232 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4578565170367559, 'Total loss': 0.4578565170367559} | train loss {'Reaction outcome loss': 0.16499150883079722, 'Total loss': 0.16499150883079722}
2023-01-05 03:24:54,232 INFO:     Best model found after epoch 20 of 100.
2023-01-05 03:24:54,233 INFO:   Done with stage: TRAINING
2023-01-05 03:24:54,233 INFO:   Starting stage: EVALUATION
2023-01-05 03:24:54,366 INFO:   Done with stage: EVALUATION
2023-01-05 03:24:54,367 INFO:   Leaving out SEQ value Fold_1
2023-01-05 03:24:54,379 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 03:24:54,380 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:24:55,013 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:24:55,013 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:24:55,081 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:24:55,081 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:24:55,081 INFO:     No hyperparam tuning for this model
2023-01-05 03:24:55,081 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:24:55,081 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:24:55,082 INFO:     None feature selector for col prot
2023-01-05 03:24:55,082 INFO:     None feature selector for col prot
2023-01-05 03:24:55,082 INFO:     None feature selector for col prot
2023-01-05 03:24:55,083 INFO:     None feature selector for col chem
2023-01-05 03:24:55,083 INFO:     None feature selector for col chem
2023-01-05 03:24:55,083 INFO:     None feature selector for col chem
2023-01-05 03:24:55,083 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:24:55,083 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:24:55,085 INFO:     Number of params in model 72931
2023-01-05 03:24:55,088 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:24:55,088 INFO:   Starting stage: TRAINING
2023-01-05 03:24:55,148 INFO:     Val loss before train {'Reaction outcome loss': 1.1386305967966714, 'Total loss': 1.1386305967966714}
2023-01-05 03:24:55,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:55,148 INFO:     Epoch: 0
2023-01-05 03:24:57,349 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9769370595614115, 'Total loss': 0.9769370595614115} | train loss {'Reaction outcome loss': 0.9378356405729737, 'Total loss': 0.9378356405729737}
2023-01-05 03:24:57,350 INFO:     Found new best model at epoch 0
2023-01-05 03:24:57,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:57,351 INFO:     Epoch: 1
2023-01-05 03:24:59,516 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6112273057301839, 'Total loss': 0.6112273057301839} | train loss {'Reaction outcome loss': 0.7023167242863082, 'Total loss': 0.7023167242863082}
2023-01-05 03:24:59,517 INFO:     Found new best model at epoch 1
2023-01-05 03:24:59,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:24:59,518 INFO:     Epoch: 2
2023-01-05 03:25:01,735 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5885309060414632, 'Total loss': 0.5885309060414632} | train loss {'Reaction outcome loss': 0.5431382843599109, 'Total loss': 0.5431382843599109}
2023-01-05 03:25:01,735 INFO:     Found new best model at epoch 2
2023-01-05 03:25:01,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:01,736 INFO:     Epoch: 3
2023-01-05 03:25:03,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5029298921426137, 'Total loss': 0.5029298921426137} | train loss {'Reaction outcome loss': 0.49319990688584386, 'Total loss': 0.49319990688584386}
2023-01-05 03:25:03,952 INFO:     Found new best model at epoch 3
2023-01-05 03:25:03,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:03,954 INFO:     Epoch: 4
2023-01-05 03:25:06,164 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4896745344003042, 'Total loss': 0.4896745344003042} | train loss {'Reaction outcome loss': 0.4564045753976076, 'Total loss': 0.4564045753976076}
2023-01-05 03:25:06,164 INFO:     Found new best model at epoch 4
2023-01-05 03:25:06,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:06,166 INFO:     Epoch: 5
2023-01-05 03:25:08,377 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5109796464443207, 'Total loss': 0.5109796464443207} | train loss {'Reaction outcome loss': 0.43422741671109993, 'Total loss': 0.43422741671109993}
2023-01-05 03:25:08,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:08,377 INFO:     Epoch: 6
2023-01-05 03:25:10,579 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48549173374970755, 'Total loss': 0.48549173374970755} | train loss {'Reaction outcome loss': 0.4168965347468633, 'Total loss': 0.4168965347468633}
2023-01-05 03:25:10,580 INFO:     Found new best model at epoch 6
2023-01-05 03:25:10,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:10,581 INFO:     Epoch: 7
2023-01-05 03:25:12,778 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4816372076670329, 'Total loss': 0.4816372076670329} | train loss {'Reaction outcome loss': 0.3987992457028245, 'Total loss': 0.3987992457028245}
2023-01-05 03:25:12,778 INFO:     Found new best model at epoch 7
2023-01-05 03:25:12,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:12,780 INFO:     Epoch: 8
2023-01-05 03:25:14,980 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46249023675918577, 'Total loss': 0.46249023675918577} | train loss {'Reaction outcome loss': 0.3875502112056936, 'Total loss': 0.3875502112056936}
2023-01-05 03:25:14,980 INFO:     Found new best model at epoch 8
2023-01-05 03:25:14,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:14,981 INFO:     Epoch: 9
2023-01-05 03:25:17,193 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46804241140683495, 'Total loss': 0.46804241140683495} | train loss {'Reaction outcome loss': 0.37169750845850175, 'Total loss': 0.37169750845850175}
2023-01-05 03:25:17,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:17,194 INFO:     Epoch: 10
2023-01-05 03:25:19,413 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5248010536034902, 'Total loss': 0.5248010536034902} | train loss {'Reaction outcome loss': 0.3646617198287341, 'Total loss': 0.3646617198287341}
2023-01-05 03:25:19,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:19,413 INFO:     Epoch: 11
2023-01-05 03:25:21,607 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.460459170738856, 'Total loss': 0.460459170738856} | train loss {'Reaction outcome loss': 0.3525828025492795, 'Total loss': 0.3525828025492795}
2023-01-05 03:25:21,607 INFO:     Found new best model at epoch 11
2023-01-05 03:25:21,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:21,609 INFO:     Epoch: 12
2023-01-05 03:25:23,807 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4485492527484894, 'Total loss': 0.4485492527484894} | train loss {'Reaction outcome loss': 0.34618532762096377, 'Total loss': 0.34618532762096377}
2023-01-05 03:25:23,807 INFO:     Found new best model at epoch 12
2023-01-05 03:25:23,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:23,808 INFO:     Epoch: 13
2023-01-05 03:25:25,960 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5108733917276065, 'Total loss': 0.5108733917276065} | train loss {'Reaction outcome loss': 0.3372975212016669, 'Total loss': 0.3372975212016669}
2023-01-05 03:25:25,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:25,961 INFO:     Epoch: 14
2023-01-05 03:25:28,140 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5270869006713231, 'Total loss': 0.5270869006713231} | train loss {'Reaction outcome loss': 0.3207030931824468, 'Total loss': 0.3207030931824468}
2023-01-05 03:25:28,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:28,140 INFO:     Epoch: 15
2023-01-05 03:25:30,319 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4195725212494532, 'Total loss': 0.4195725212494532} | train loss {'Reaction outcome loss': 0.31761429720039297, 'Total loss': 0.31761429720039297}
2023-01-05 03:25:30,320 INFO:     Found new best model at epoch 15
2023-01-05 03:25:30,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:30,321 INFO:     Epoch: 16
2023-01-05 03:25:32,516 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4584390287597974, 'Total loss': 0.4584390287597974} | train loss {'Reaction outcome loss': 0.310480788281373, 'Total loss': 0.310480788281373}
2023-01-05 03:25:32,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:32,516 INFO:     Epoch: 17
2023-01-05 03:25:34,716 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44369517962137855, 'Total loss': 0.44369517962137855} | train loss {'Reaction outcome loss': 0.3037480211290926, 'Total loss': 0.3037480211290926}
2023-01-05 03:25:34,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:34,716 INFO:     Epoch: 18
2023-01-05 03:25:36,883 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45421109795570375, 'Total loss': 0.45421109795570375} | train loss {'Reaction outcome loss': 0.29823847976942786, 'Total loss': 0.29823847976942786}
2023-01-05 03:25:36,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:36,884 INFO:     Epoch: 19
2023-01-05 03:25:39,050 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4150526026884715, 'Total loss': 0.4150526026884715} | train loss {'Reaction outcome loss': 0.2902223789768905, 'Total loss': 0.2902223789768905}
2023-01-05 03:25:39,050 INFO:     Found new best model at epoch 19
2023-01-05 03:25:39,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:39,051 INFO:     Epoch: 20
2023-01-05 03:25:41,254 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4215403508084516, 'Total loss': 0.4215403508084516} | train loss {'Reaction outcome loss': 0.28736001079922674, 'Total loss': 0.28736001079922674}
2023-01-05 03:25:41,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:41,254 INFO:     Epoch: 21
2023-01-05 03:25:43,461 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39638554578026136, 'Total loss': 0.39638554578026136} | train loss {'Reaction outcome loss': 0.2811988380864757, 'Total loss': 0.2811988380864757}
2023-01-05 03:25:43,462 INFO:     Found new best model at epoch 21
2023-01-05 03:25:43,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:43,463 INFO:     Epoch: 22
2023-01-05 03:25:45,477 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4383221407731374, 'Total loss': 0.4383221407731374} | train loss {'Reaction outcome loss': 0.2752710904898569, 'Total loss': 0.2752710904898569}
2023-01-05 03:25:45,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:45,477 INFO:     Epoch: 23
2023-01-05 03:25:47,642 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4767504413922628, 'Total loss': 0.4767504413922628} | train loss {'Reaction outcome loss': 0.2760023617519004, 'Total loss': 0.2760023617519004}
2023-01-05 03:25:47,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:47,643 INFO:     Epoch: 24
2023-01-05 03:25:49,851 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4668704688549042, 'Total loss': 0.4668704688549042} | train loss {'Reaction outcome loss': 0.2696503623632707, 'Total loss': 0.2696503623632707}
2023-01-05 03:25:49,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:49,852 INFO:     Epoch: 25
2023-01-05 03:25:52,058 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43061232765515645, 'Total loss': 0.43061232765515645} | train loss {'Reaction outcome loss': 0.26440266215300867, 'Total loss': 0.26440266215300867}
2023-01-05 03:25:52,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:52,058 INFO:     Epoch: 26
2023-01-05 03:25:54,258 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4562974621852239, 'Total loss': 0.4562974621852239} | train loss {'Reaction outcome loss': 0.2590419389307499, 'Total loss': 0.2590419389307499}
2023-01-05 03:25:54,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:54,259 INFO:     Epoch: 27
2023-01-05 03:25:56,464 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4860489030679067, 'Total loss': 0.4860489030679067} | train loss {'Reaction outcome loss': 0.25430458962120034, 'Total loss': 0.25430458962120034}
2023-01-05 03:25:56,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:56,464 INFO:     Epoch: 28
2023-01-05 03:25:58,647 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44319564501444497, 'Total loss': 0.44319564501444497} | train loss {'Reaction outcome loss': 0.2554820622575239, 'Total loss': 0.2554820622575239}
2023-01-05 03:25:58,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:25:58,648 INFO:     Epoch: 29
2023-01-05 03:26:00,829 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44245733618736266, 'Total loss': 0.44245733618736266} | train loss {'Reaction outcome loss': 0.24994589571198414, 'Total loss': 0.24994589571198414}
2023-01-05 03:26:00,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:00,830 INFO:     Epoch: 30
2023-01-05 03:26:03,050 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4816159139076869, 'Total loss': 0.4816159139076869} | train loss {'Reaction outcome loss': 0.24889281513066308, 'Total loss': 0.24889281513066308}
2023-01-05 03:26:03,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:03,050 INFO:     Epoch: 31
2023-01-05 03:26:05,276 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4164040589084228, 'Total loss': 0.4164040589084228} | train loss {'Reaction outcome loss': 0.2432045909710146, 'Total loss': 0.2432045909710146}
2023-01-05 03:26:05,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:05,276 INFO:     Epoch: 32
2023-01-05 03:26:07,481 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42165917058785757, 'Total loss': 0.42165917058785757} | train loss {'Reaction outcome loss': 0.23981354193163973, 'Total loss': 0.23981354193163973}
2023-01-05 03:26:07,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:07,482 INFO:     Epoch: 33
2023-01-05 03:26:09,688 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45177927017211916, 'Total loss': 0.45177927017211916} | train loss {'Reaction outcome loss': 0.2377175673210093, 'Total loss': 0.2377175673210093}
2023-01-05 03:26:09,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:09,688 INFO:     Epoch: 34
2023-01-05 03:26:11,906 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3951892246802648, 'Total loss': 0.3951892246802648} | train loss {'Reaction outcome loss': 0.24088889976269204, 'Total loss': 0.24088889976269204}
2023-01-05 03:26:11,906 INFO:     Found new best model at epoch 34
2023-01-05 03:26:11,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:11,907 INFO:     Epoch: 35
2023-01-05 03:26:14,130 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4428683112064997, 'Total loss': 0.4428683112064997} | train loss {'Reaction outcome loss': 0.23340834301941069, 'Total loss': 0.23340834301941069}
2023-01-05 03:26:14,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:14,131 INFO:     Epoch: 36
2023-01-05 03:26:16,343 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43756161630153656, 'Total loss': 0.43756161630153656} | train loss {'Reaction outcome loss': 0.22943652324323505, 'Total loss': 0.22943652324323505}
2023-01-05 03:26:16,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:16,344 INFO:     Epoch: 37
2023-01-05 03:26:18,551 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40785357107718784, 'Total loss': 0.40785357107718784} | train loss {'Reaction outcome loss': 0.23168766548740247, 'Total loss': 0.23168766548740247}
2023-01-05 03:26:18,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:18,551 INFO:     Epoch: 38
2023-01-05 03:26:20,768 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41857714354991915, 'Total loss': 0.41857714354991915} | train loss {'Reaction outcome loss': 0.22573211442720406, 'Total loss': 0.22573211442720406}
2023-01-05 03:26:20,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:20,768 INFO:     Epoch: 39
2023-01-05 03:26:22,988 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4490453282992045, 'Total loss': 0.4490453282992045} | train loss {'Reaction outcome loss': 0.22640719386745534, 'Total loss': 0.22640719386745534}
2023-01-05 03:26:22,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:22,989 INFO:     Epoch: 40
2023-01-05 03:26:25,214 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4414143959681193, 'Total loss': 0.4414143959681193} | train loss {'Reaction outcome loss': 0.2264908248304331, 'Total loss': 0.2264908248304331}
2023-01-05 03:26:25,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:25,214 INFO:     Epoch: 41
2023-01-05 03:26:27,430 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4019005596637726, 'Total loss': 0.4019005596637726} | train loss {'Reaction outcome loss': 0.21964969228595715, 'Total loss': 0.21964969228595715}
2023-01-05 03:26:27,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:27,430 INFO:     Epoch: 42
2023-01-05 03:26:29,642 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46755949159463245, 'Total loss': 0.46755949159463245} | train loss {'Reaction outcome loss': 0.21606007908433125, 'Total loss': 0.21606007908433125}
2023-01-05 03:26:29,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:29,643 INFO:     Epoch: 43
2023-01-05 03:26:31,729 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39058962541942793, 'Total loss': 0.39058962541942793} | train loss {'Reaction outcome loss': 0.21760180535489124, 'Total loss': 0.21760180535489124}
2023-01-05 03:26:31,729 INFO:     Found new best model at epoch 43
2023-01-05 03:26:31,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:31,730 INFO:     Epoch: 44
2023-01-05 03:26:33,885 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.430107260743777, 'Total loss': 0.430107260743777} | train loss {'Reaction outcome loss': 0.2120180760864237, 'Total loss': 0.2120180760864237}
2023-01-05 03:26:33,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:33,885 INFO:     Epoch: 45
2023-01-05 03:26:36,056 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.408023938536644, 'Total loss': 0.408023938536644} | train loss {'Reaction outcome loss': 0.21395311910810286, 'Total loss': 0.21395311910810286}
2023-01-05 03:26:36,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:36,056 INFO:     Epoch: 46
2023-01-05 03:26:38,202 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.456760643919309, 'Total loss': 0.456760643919309} | train loss {'Reaction outcome loss': 0.21092137879936018, 'Total loss': 0.21092137879936018}
2023-01-05 03:26:38,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:38,202 INFO:     Epoch: 47
2023-01-05 03:26:40,405 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49515998661518096, 'Total loss': 0.49515998661518096} | train loss {'Reaction outcome loss': 0.21071898452662674, 'Total loss': 0.21071898452662674}
2023-01-05 03:26:40,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:40,405 INFO:     Epoch: 48
2023-01-05 03:26:42,574 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40389877259731294, 'Total loss': 0.40389877259731294} | train loss {'Reaction outcome loss': 0.21334676183347773, 'Total loss': 0.21334676183347773}
2023-01-05 03:26:42,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:42,575 INFO:     Epoch: 49
2023-01-05 03:26:44,699 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43498450616995493, 'Total loss': 0.43498450616995493} | train loss {'Reaction outcome loss': 0.20702919073925247, 'Total loss': 0.20702919073925247}
2023-01-05 03:26:44,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:44,699 INFO:     Epoch: 50
2023-01-05 03:26:46,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4156845579544703, 'Total loss': 0.4156845579544703} | train loss {'Reaction outcome loss': 0.20954307636101746, 'Total loss': 0.20954307636101746}
2023-01-05 03:26:46,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:46,883 INFO:     Epoch: 51
2023-01-05 03:26:49,094 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4087671915690104, 'Total loss': 0.4087671915690104} | train loss {'Reaction outcome loss': 0.20801544813198686, 'Total loss': 0.20801544813198686}
2023-01-05 03:26:49,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:49,094 INFO:     Epoch: 52
2023-01-05 03:26:51,294 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4381991843382517, 'Total loss': 0.4381991843382517} | train loss {'Reaction outcome loss': 0.20200795707777416, 'Total loss': 0.20200795707777416}
2023-01-05 03:26:51,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:51,294 INFO:     Epoch: 53
2023-01-05 03:26:53,468 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4347742954889933, 'Total loss': 0.4347742954889933} | train loss {'Reaction outcome loss': 0.2027112227620564, 'Total loss': 0.2027112227620564}
2023-01-05 03:26:53,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:53,469 INFO:     Epoch: 54
2023-01-05 03:26:55,625 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41433635155359905, 'Total loss': 0.41433635155359905} | train loss {'Reaction outcome loss': 0.2025740191175489, 'Total loss': 0.2025740191175489}
2023-01-05 03:26:55,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:55,625 INFO:     Epoch: 55
2023-01-05 03:26:57,810 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43352706034978233, 'Total loss': 0.43352706034978233} | train loss {'Reaction outcome loss': 0.2002238551587746, 'Total loss': 0.2002238551587746}
2023-01-05 03:26:57,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:57,810 INFO:     Epoch: 56
2023-01-05 03:26:59,960 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3929971324900786, 'Total loss': 0.3929971324900786} | train loss {'Reaction outcome loss': 0.1981112029664631, 'Total loss': 0.1981112029664631}
2023-01-05 03:26:59,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:26:59,961 INFO:     Epoch: 57
2023-01-05 03:27:02,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39507119233409566, 'Total loss': 0.39507119233409566} | train loss {'Reaction outcome loss': 0.20007757065522164, 'Total loss': 0.20007757065522164}
2023-01-05 03:27:02,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:02,088 INFO:     Epoch: 58
2023-01-05 03:27:04,270 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4106668015321096, 'Total loss': 0.4106668015321096} | train loss {'Reaction outcome loss': 0.20164097503611192, 'Total loss': 0.20164097503611192}
2023-01-05 03:27:04,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:04,270 INFO:     Epoch: 59
2023-01-05 03:27:06,432 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4350133757417401, 'Total loss': 0.4350133757417401} | train loss {'Reaction outcome loss': 0.19414305490376324, 'Total loss': 0.19414305490376324}
2023-01-05 03:27:06,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:06,432 INFO:     Epoch: 60
2023-01-05 03:27:08,564 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4335327128569285, 'Total loss': 0.4335327128569285} | train loss {'Reaction outcome loss': 0.18953078456147404, 'Total loss': 0.18953078456147404}
2023-01-05 03:27:08,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:08,564 INFO:     Epoch: 61
2023-01-05 03:27:10,764 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4185896245141824, 'Total loss': 0.4185896245141824} | train loss {'Reaction outcome loss': 0.19351499911218992, 'Total loss': 0.19351499911218992}
2023-01-05 03:27:10,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:10,764 INFO:     Epoch: 62
2023-01-05 03:27:12,869 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47442746808131536, 'Total loss': 0.47442746808131536} | train loss {'Reaction outcome loss': 0.19341290021500795, 'Total loss': 0.19341290021500795}
2023-01-05 03:27:12,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:12,869 INFO:     Epoch: 63
2023-01-05 03:27:14,995 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4262212763230006, 'Total loss': 0.4262212763230006} | train loss {'Reaction outcome loss': 0.18896591180172573, 'Total loss': 0.18896591180172573}
2023-01-05 03:27:14,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:14,995 INFO:     Epoch: 64
2023-01-05 03:27:17,162 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44869374533494316, 'Total loss': 0.44869374533494316} | train loss {'Reaction outcome loss': 0.1927765209203744, 'Total loss': 0.1927765209203744}
2023-01-05 03:27:17,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:17,162 INFO:     Epoch: 65
2023-01-05 03:27:19,324 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39738885482462744, 'Total loss': 0.39738885482462744} | train loss {'Reaction outcome loss': 0.1884140347601413, 'Total loss': 0.1884140347601413}
2023-01-05 03:27:19,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:19,325 INFO:     Epoch: 66
2023-01-05 03:27:21,481 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39656069576740266, 'Total loss': 0.39656069576740266} | train loss {'Reaction outcome loss': 0.1855367291615623, 'Total loss': 0.1855367291615623}
2023-01-05 03:27:21,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:21,481 INFO:     Epoch: 67
2023-01-05 03:27:23,624 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39833528896172843, 'Total loss': 0.39833528896172843} | train loss {'Reaction outcome loss': 0.1866951217166942, 'Total loss': 0.1866951217166942}
2023-01-05 03:27:23,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:23,624 INFO:     Epoch: 68
2023-01-05 03:27:25,743 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4020224762459596, 'Total loss': 0.4020224762459596} | train loss {'Reaction outcome loss': 0.1855526523152538, 'Total loss': 0.1855526523152538}
2023-01-05 03:27:25,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:25,743 INFO:     Epoch: 69
2023-01-05 03:27:27,955 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40102292547623314, 'Total loss': 0.40102292547623314} | train loss {'Reaction outcome loss': 0.181186520384549, 'Total loss': 0.181186520384549}
2023-01-05 03:27:27,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:27,955 INFO:     Epoch: 70
2023-01-05 03:27:30,054 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38924981988966467, 'Total loss': 0.38924981988966467} | train loss {'Reaction outcome loss': 0.18216951883559518, 'Total loss': 0.18216951883559518}
2023-01-05 03:27:30,055 INFO:     Found new best model at epoch 70
2023-01-05 03:27:30,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:30,056 INFO:     Epoch: 71
2023-01-05 03:27:32,185 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47227949897448224, 'Total loss': 0.47227949897448224} | train loss {'Reaction outcome loss': 0.18304162225565732, 'Total loss': 0.18304162225565732}
2023-01-05 03:27:32,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:32,186 INFO:     Epoch: 72
2023-01-05 03:27:34,358 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44929557740688325, 'Total loss': 0.44929557740688325} | train loss {'Reaction outcome loss': 0.17769569441731126, 'Total loss': 0.17769569441731126}
2023-01-05 03:27:34,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:34,359 INFO:     Epoch: 73
2023-01-05 03:27:36,490 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3990784221639236, 'Total loss': 0.3990784221639236} | train loss {'Reaction outcome loss': 0.17928231347393506, 'Total loss': 0.17928231347393506}
2023-01-05 03:27:36,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:36,491 INFO:     Epoch: 74
2023-01-05 03:27:38,694 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44312506119410194, 'Total loss': 0.44312506119410194} | train loss {'Reaction outcome loss': 0.18321071258605187, 'Total loss': 0.18321071258605187}
2023-01-05 03:27:38,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:38,695 INFO:     Epoch: 75
2023-01-05 03:27:40,882 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4132636105020841, 'Total loss': 0.4132636105020841} | train loss {'Reaction outcome loss': 0.18036296580852837, 'Total loss': 0.18036296580852837}
2023-01-05 03:27:40,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:40,882 INFO:     Epoch: 76
2023-01-05 03:27:43,059 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3946381580705444, 'Total loss': 0.3946381580705444} | train loss {'Reaction outcome loss': 0.180925686596257, 'Total loss': 0.180925686596257}
2023-01-05 03:27:43,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:43,059 INFO:     Epoch: 77
2023-01-05 03:27:45,219 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42374001319209736, 'Total loss': 0.42374001319209736} | train loss {'Reaction outcome loss': 0.17323951880925256, 'Total loss': 0.17323951880925256}
2023-01-05 03:27:45,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:45,219 INFO:     Epoch: 78
2023-01-05 03:27:47,349 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4481706440448761, 'Total loss': 0.4481706440448761} | train loss {'Reaction outcome loss': 0.17841751152319607, 'Total loss': 0.17841751152319607}
2023-01-05 03:27:47,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:47,349 INFO:     Epoch: 79
2023-01-05 03:27:49,541 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4098898462951183, 'Total loss': 0.4098898462951183} | train loss {'Reaction outcome loss': 0.17391301379143861, 'Total loss': 0.17391301379143861}
2023-01-05 03:27:49,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:49,542 INFO:     Epoch: 80
2023-01-05 03:27:51,709 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4457463324069977, 'Total loss': 0.4457463324069977} | train loss {'Reaction outcome loss': 0.17545420060972117, 'Total loss': 0.17545420060972117}
2023-01-05 03:27:51,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:51,709 INFO:     Epoch: 81
2023-01-05 03:27:53,858 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41652332129888237, 'Total loss': 0.41652332129888237} | train loss {'Reaction outcome loss': 0.17300109471266614, 'Total loss': 0.17300109471266614}
2023-01-05 03:27:53,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:53,858 INFO:     Epoch: 82
2023-01-05 03:27:56,001 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4551440278689067, 'Total loss': 0.4551440278689067} | train loss {'Reaction outcome loss': 0.16864023211917314, 'Total loss': 0.16864023211917314}
2023-01-05 03:27:56,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:56,001 INFO:     Epoch: 83
2023-01-05 03:27:58,169 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.480706117550532, 'Total loss': 0.480706117550532} | train loss {'Reaction outcome loss': 0.1705137434934448, 'Total loss': 0.1705137434934448}
2023-01-05 03:27:58,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:27:58,169 INFO:     Epoch: 84
2023-01-05 03:28:00,374 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41709617177645364, 'Total loss': 0.41709617177645364} | train loss {'Reaction outcome loss': 0.167094959925544, 'Total loss': 0.167094959925544}
2023-01-05 03:28:00,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:00,374 INFO:     Epoch: 85
2023-01-05 03:28:02,532 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46102221608161925, 'Total loss': 0.46102221608161925} | train loss {'Reaction outcome loss': 0.16602398241557373, 'Total loss': 0.16602398241557373}
2023-01-05 03:28:02,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:02,532 INFO:     Epoch: 86
2023-01-05 03:28:04,723 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4548846940199534, 'Total loss': 0.4548846940199534} | train loss {'Reaction outcome loss': 0.17363202367733985, 'Total loss': 0.17363202367733985}
2023-01-05 03:28:04,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:04,724 INFO:     Epoch: 87
2023-01-05 03:28:06,923 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40295315235853196, 'Total loss': 0.40295315235853196} | train loss {'Reaction outcome loss': 0.17187098990026106, 'Total loss': 0.17187098990026106}
2023-01-05 03:28:06,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:06,924 INFO:     Epoch: 88
2023-01-05 03:28:09,120 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4083106535176436, 'Total loss': 0.4083106535176436} | train loss {'Reaction outcome loss': 0.16787109447718768, 'Total loss': 0.16787109447718768}
2023-01-05 03:28:09,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:09,120 INFO:     Epoch: 89
2023-01-05 03:28:11,330 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41279789408047995, 'Total loss': 0.41279789408047995} | train loss {'Reaction outcome loss': 0.17111020480588462, 'Total loss': 0.17111020480588462}
2023-01-05 03:28:11,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:11,330 INFO:     Epoch: 90
2023-01-05 03:28:13,550 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4238697210947672, 'Total loss': 0.4238697210947672} | train loss {'Reaction outcome loss': 0.16805800606197646, 'Total loss': 0.16805800606197646}
2023-01-05 03:28:13,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:13,550 INFO:     Epoch: 91
2023-01-05 03:28:15,748 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4159452001253764, 'Total loss': 0.4159452001253764} | train loss {'Reaction outcome loss': 0.16556163751812328, 'Total loss': 0.16556163751812328}
2023-01-05 03:28:15,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:15,749 INFO:     Epoch: 92
2023-01-05 03:28:17,940 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38574947578211627, 'Total loss': 0.38574947578211627} | train loss {'Reaction outcome loss': 0.16612498448453705, 'Total loss': 0.16612498448453705}
2023-01-05 03:28:17,940 INFO:     Found new best model at epoch 92
2023-01-05 03:28:17,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:17,941 INFO:     Epoch: 93
2023-01-05 03:28:20,075 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4629190443083644, 'Total loss': 0.4629190443083644} | train loss {'Reaction outcome loss': 0.16332664351903478, 'Total loss': 0.16332664351903478}
2023-01-05 03:28:20,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:20,075 INFO:     Epoch: 94
2023-01-05 03:28:22,217 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.408268283183376, 'Total loss': 0.408268283183376} | train loss {'Reaction outcome loss': 0.16030451919319885, 'Total loss': 0.16030451919319885}
2023-01-05 03:28:22,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:22,217 INFO:     Epoch: 95
2023-01-05 03:28:24,419 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4307281613349915, 'Total loss': 0.4307281613349915} | train loss {'Reaction outcome loss': 0.1639447144655394, 'Total loss': 0.1639447144655394}
2023-01-05 03:28:24,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:24,420 INFO:     Epoch: 96
2023-01-05 03:28:26,618 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4256497224171956, 'Total loss': 0.4256497224171956} | train loss {'Reaction outcome loss': 0.16364049590862875, 'Total loss': 0.16364049590862875}
2023-01-05 03:28:26,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:26,619 INFO:     Epoch: 97
2023-01-05 03:28:28,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42364575167497, 'Total loss': 0.42364575167497} | train loss {'Reaction outcome loss': 0.1627407807502827, 'Total loss': 0.1627407807502827}
2023-01-05 03:28:28,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:28,843 INFO:     Epoch: 98
2023-01-05 03:28:31,034 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44884651253620783, 'Total loss': 0.44884651253620783} | train loss {'Reaction outcome loss': 0.16016915570978915, 'Total loss': 0.16016915570978915}
2023-01-05 03:28:31,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:31,034 INFO:     Epoch: 99
2023-01-05 03:28:33,145 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4210740469396114, 'Total loss': 0.4210740469396114} | train loss {'Reaction outcome loss': 0.16287068849621938, 'Total loss': 0.16287068849621938}
2023-01-05 03:28:33,145 INFO:     Best model found after epoch 93 of 100.
2023-01-05 03:28:33,146 INFO:   Done with stage: TRAINING
2023-01-05 03:28:33,146 INFO:   Starting stage: EVALUATION
2023-01-05 03:28:33,296 INFO:   Done with stage: EVALUATION
2023-01-05 03:28:33,297 INFO:   Leaving out SEQ value Fold_2
2023-01-05 03:28:33,309 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 03:28:33,309 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:28:33,939 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:28:33,939 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:28:34,007 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:28:34,008 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:28:34,008 INFO:     No hyperparam tuning for this model
2023-01-05 03:28:34,008 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:28:34,008 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:28:34,008 INFO:     None feature selector for col prot
2023-01-05 03:28:34,009 INFO:     None feature selector for col prot
2023-01-05 03:28:34,009 INFO:     None feature selector for col prot
2023-01-05 03:28:34,009 INFO:     None feature selector for col chem
2023-01-05 03:28:34,009 INFO:     None feature selector for col chem
2023-01-05 03:28:34,009 INFO:     None feature selector for col chem
2023-01-05 03:28:34,009 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:28:34,009 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:28:34,011 INFO:     Number of params in model 72931
2023-01-05 03:28:34,014 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:28:34,014 INFO:   Starting stage: TRAINING
2023-01-05 03:28:34,075 INFO:     Val loss before train {'Reaction outcome loss': 0.9650421579678853, 'Total loss': 0.9650421579678853}
2023-01-05 03:28:34,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:34,075 INFO:     Epoch: 0
2023-01-05 03:28:36,218 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7495579242706298, 'Total loss': 0.7495579242706298} | train loss {'Reaction outcome loss': 0.9509877100260589, 'Total loss': 0.9509877100260589}
2023-01-05 03:28:36,218 INFO:     Found new best model at epoch 0
2023-01-05 03:28:36,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:36,220 INFO:     Epoch: 1
2023-01-05 03:28:38,408 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5464463313420613, 'Total loss': 0.5464463313420613} | train loss {'Reaction outcome loss': 0.6399210615314707, 'Total loss': 0.6399210615314707}
2023-01-05 03:28:38,409 INFO:     Found new best model at epoch 1
2023-01-05 03:28:38,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:38,410 INFO:     Epoch: 2
2023-01-05 03:28:40,571 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4958104824026426, 'Total loss': 0.4958104824026426} | train loss {'Reaction outcome loss': 0.5431770929237352, 'Total loss': 0.5431770929237352}
2023-01-05 03:28:40,572 INFO:     Found new best model at epoch 2
2023-01-05 03:28:40,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:40,573 INFO:     Epoch: 3
2023-01-05 03:28:42,805 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.493173615137736, 'Total loss': 0.493173615137736} | train loss {'Reaction outcome loss': 0.5031696474247606, 'Total loss': 0.5031696474247606}
2023-01-05 03:28:42,805 INFO:     Found new best model at epoch 3
2023-01-05 03:28:42,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:42,807 INFO:     Epoch: 4
2023-01-05 03:28:45,081 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4694901208082835, 'Total loss': 0.4694901208082835} | train loss {'Reaction outcome loss': 0.47239288701301946, 'Total loss': 0.47239288701301946}
2023-01-05 03:28:45,081 INFO:     Found new best model at epoch 4
2023-01-05 03:28:45,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:45,083 INFO:     Epoch: 5
2023-01-05 03:28:47,332 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.445144572108984, 'Total loss': 0.445144572108984} | train loss {'Reaction outcome loss': 0.4529537420964589, 'Total loss': 0.4529537420964589}
2023-01-05 03:28:47,333 INFO:     Found new best model at epoch 5
2023-01-05 03:28:47,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:47,334 INFO:     Epoch: 6
2023-01-05 03:28:49,581 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4323166787624359, 'Total loss': 0.4323166787624359} | train loss {'Reaction outcome loss': 0.44045151903355206, 'Total loss': 0.44045151903355206}
2023-01-05 03:28:49,581 INFO:     Found new best model at epoch 6
2023-01-05 03:28:49,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:49,583 INFO:     Epoch: 7
2023-01-05 03:28:51,834 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4443998982508977, 'Total loss': 0.4443998982508977} | train loss {'Reaction outcome loss': 0.4194838070738925, 'Total loss': 0.4194838070738925}
2023-01-05 03:28:51,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:51,835 INFO:     Epoch: 8
2023-01-05 03:28:54,041 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42255127827326455, 'Total loss': 0.42255127827326455} | train loss {'Reaction outcome loss': 0.4064770293061751, 'Total loss': 0.4064770293061751}
2023-01-05 03:28:54,041 INFO:     Found new best model at epoch 8
2023-01-05 03:28:54,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:54,042 INFO:     Epoch: 9
2023-01-05 03:28:56,238 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.431728074947993, 'Total loss': 0.431728074947993} | train loss {'Reaction outcome loss': 0.39721737250033085, 'Total loss': 0.39721737250033085}
2023-01-05 03:28:56,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:56,238 INFO:     Epoch: 10
2023-01-05 03:28:58,464 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4178475608428319, 'Total loss': 0.4178475608428319} | train loss {'Reaction outcome loss': 0.3878996774119182, 'Total loss': 0.3878996774119182}
2023-01-05 03:28:58,464 INFO:     Found new best model at epoch 10
2023-01-05 03:28:58,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:28:58,465 INFO:     Epoch: 11
2023-01-05 03:29:00,659 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4485500911871592, 'Total loss': 0.4485500911871592} | train loss {'Reaction outcome loss': 0.38141733617351875, 'Total loss': 0.38141733617351875}
2023-01-05 03:29:00,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:00,660 INFO:     Epoch: 12
2023-01-05 03:29:02,885 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41546263098716735, 'Total loss': 0.41546263098716735} | train loss {'Reaction outcome loss': 0.3711228123492133, 'Total loss': 0.3711228123492133}
2023-01-05 03:29:02,885 INFO:     Found new best model at epoch 12
2023-01-05 03:29:02,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:02,887 INFO:     Epoch: 13
2023-01-05 03:29:05,109 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4172509402036667, 'Total loss': 0.4172509402036667} | train loss {'Reaction outcome loss': 0.3650149201335263, 'Total loss': 0.3650149201335263}
2023-01-05 03:29:05,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:05,109 INFO:     Epoch: 14
2023-01-05 03:29:07,349 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40575623710950215, 'Total loss': 0.40575623710950215} | train loss {'Reaction outcome loss': 0.35613713568470773, 'Total loss': 0.35613713568470773}
2023-01-05 03:29:07,349 INFO:     Found new best model at epoch 14
2023-01-05 03:29:07,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:07,350 INFO:     Epoch: 15
2023-01-05 03:29:09,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40408489604791004, 'Total loss': 0.40408489604791004} | train loss {'Reaction outcome loss': 0.3488276210090105, 'Total loss': 0.3488276210090105}
2023-01-05 03:29:09,536 INFO:     Found new best model at epoch 15
2023-01-05 03:29:09,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:09,538 INFO:     Epoch: 16
2023-01-05 03:29:11,766 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4113165179888407, 'Total loss': 0.4113165179888407} | train loss {'Reaction outcome loss': 0.3464076676725471, 'Total loss': 0.3464076676725471}
2023-01-05 03:29:11,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:11,766 INFO:     Epoch: 17
2023-01-05 03:29:13,962 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4084841658671697, 'Total loss': 0.4084841658671697} | train loss {'Reaction outcome loss': 0.34017361408221897, 'Total loss': 0.34017361408221897}
2023-01-05 03:29:13,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:13,962 INFO:     Epoch: 18
2023-01-05 03:29:16,168 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4022274742523829, 'Total loss': 0.4022274742523829} | train loss {'Reaction outcome loss': 0.329306401108412, 'Total loss': 0.329306401108412}
2023-01-05 03:29:16,169 INFO:     Found new best model at epoch 18
2023-01-05 03:29:16,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:16,171 INFO:     Epoch: 19
2023-01-05 03:29:18,377 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.428842830657959, 'Total loss': 0.428842830657959} | train loss {'Reaction outcome loss': 0.32686767150668333, 'Total loss': 0.32686767150668333}
2023-01-05 03:29:18,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:18,378 INFO:     Epoch: 20
2023-01-05 03:29:20,600 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4329875965913137, 'Total loss': 0.4329875965913137} | train loss {'Reaction outcome loss': 0.32044249666977104, 'Total loss': 0.32044249666977104}
2023-01-05 03:29:20,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:20,600 INFO:     Epoch: 21
2023-01-05 03:29:22,823 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41694410840670265, 'Total loss': 0.41694410840670265} | train loss {'Reaction outcome loss': 0.3162927677052735, 'Total loss': 0.3162927677052735}
2023-01-05 03:29:22,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:22,824 INFO:     Epoch: 22
2023-01-05 03:29:25,027 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4020273953676224, 'Total loss': 0.4020273953676224} | train loss {'Reaction outcome loss': 0.3107546375398218, 'Total loss': 0.3107546375398218}
2023-01-05 03:29:25,027 INFO:     Found new best model at epoch 22
2023-01-05 03:29:25,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:25,028 INFO:     Epoch: 23
2023-01-05 03:29:27,255 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42028530438741046, 'Total loss': 0.42028530438741046} | train loss {'Reaction outcome loss': 0.3055786305943327, 'Total loss': 0.3055786305943327}
2023-01-05 03:29:27,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:27,256 INFO:     Epoch: 24
2023-01-05 03:29:29,315 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43029295206069945, 'Total loss': 0.43029295206069945} | train loss {'Reaction outcome loss': 0.3024577122915835, 'Total loss': 0.3024577122915835}
2023-01-05 03:29:29,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:29,315 INFO:     Epoch: 25
2023-01-05 03:29:31,138 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4101989063123862, 'Total loss': 0.4101989063123862} | train loss {'Reaction outcome loss': 0.2935762194318384, 'Total loss': 0.2935762194318384}
2023-01-05 03:29:31,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:31,138 INFO:     Epoch: 26
2023-01-05 03:29:33,000 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4386676251888275, 'Total loss': 0.4386676251888275} | train loss {'Reaction outcome loss': 0.2957203710710045, 'Total loss': 0.2957203710710045}
2023-01-05 03:29:33,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:33,000 INFO:     Epoch: 27
2023-01-05 03:29:35,201 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4298882484436035, 'Total loss': 0.4298882484436035} | train loss {'Reaction outcome loss': 0.2876132401454188, 'Total loss': 0.2876132401454188}
2023-01-05 03:29:35,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:35,202 INFO:     Epoch: 28
2023-01-05 03:29:37,299 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4243348012367884, 'Total loss': 0.4243348012367884} | train loss {'Reaction outcome loss': 0.28387904044131945, 'Total loss': 0.28387904044131945}
2023-01-05 03:29:37,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:37,299 INFO:     Epoch: 29
2023-01-05 03:29:39,494 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39907700518767036, 'Total loss': 0.39907700518767036} | train loss {'Reaction outcome loss': 0.28011544583106995, 'Total loss': 0.28011544583106995}
2023-01-05 03:29:39,494 INFO:     Found new best model at epoch 29
2023-01-05 03:29:39,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:39,495 INFO:     Epoch: 30
2023-01-05 03:29:41,690 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4074219048023224, 'Total loss': 0.4074219048023224} | train loss {'Reaction outcome loss': 0.2757671625645709, 'Total loss': 0.2757671625645709}
2023-01-05 03:29:41,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:41,690 INFO:     Epoch: 31
2023-01-05 03:29:43,870 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45805948277314507, 'Total loss': 0.45805948277314507} | train loss {'Reaction outcome loss': 0.2731811548753159, 'Total loss': 0.2731811548753159}
2023-01-05 03:29:43,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:43,871 INFO:     Epoch: 32
2023-01-05 03:29:46,076 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40226049621899923, 'Total loss': 0.40226049621899923} | train loss {'Reaction outcome loss': 0.27431151485682403, 'Total loss': 0.27431151485682403}
2023-01-05 03:29:46,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:46,076 INFO:     Epoch: 33
2023-01-05 03:29:48,299 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40950836638609567, 'Total loss': 0.40950836638609567} | train loss {'Reaction outcome loss': 0.26497959153876255, 'Total loss': 0.26497959153876255}
2023-01-05 03:29:48,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:48,299 INFO:     Epoch: 34
2023-01-05 03:29:50,333 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41595009913047154, 'Total loss': 0.41595009913047154} | train loss {'Reaction outcome loss': 0.26486191871392467, 'Total loss': 0.26486191871392467}
2023-01-05 03:29:50,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:50,333 INFO:     Epoch: 35
2023-01-05 03:29:52,561 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4124885012706121, 'Total loss': 0.4124885012706121} | train loss {'Reaction outcome loss': 0.2604866552363782, 'Total loss': 0.2604866552363782}
2023-01-05 03:29:52,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:52,562 INFO:     Epoch: 36
2023-01-05 03:29:54,813 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40543449893593786, 'Total loss': 0.40543449893593786} | train loss {'Reaction outcome loss': 0.25719841906841656, 'Total loss': 0.25719841906841656}
2023-01-05 03:29:54,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:54,814 INFO:     Epoch: 37
2023-01-05 03:29:56,973 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.401259708404541, 'Total loss': 0.401259708404541} | train loss {'Reaction outcome loss': 0.24864351251808398, 'Total loss': 0.24864351251808398}
2023-01-05 03:29:56,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:56,974 INFO:     Epoch: 38
2023-01-05 03:29:59,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4194204678138097, 'Total loss': 0.4194204678138097} | train loss {'Reaction outcome loss': 0.24029548520589397, 'Total loss': 0.24029548520589397}
2023-01-05 03:29:59,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:29:59,185 INFO:     Epoch: 39
2023-01-05 03:30:01,422 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4142601013183594, 'Total loss': 0.4142601013183594} | train loss {'Reaction outcome loss': 0.24991787546552227, 'Total loss': 0.24991787546552227}
2023-01-05 03:30:01,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:01,423 INFO:     Epoch: 40
2023-01-05 03:30:03,649 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43172154227892556, 'Total loss': 0.43172154227892556} | train loss {'Reaction outcome loss': 0.2484173046452177, 'Total loss': 0.2484173046452177}
2023-01-05 03:30:03,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:03,649 INFO:     Epoch: 41
2023-01-05 03:30:05,870 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42297667264938354, 'Total loss': 0.42297667264938354} | train loss {'Reaction outcome loss': 0.24594358454057336, 'Total loss': 0.24594358454057336}
2023-01-05 03:30:05,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:05,871 INFO:     Epoch: 42
2023-01-05 03:30:08,060 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40841392874717714, 'Total loss': 0.40841392874717714} | train loss {'Reaction outcome loss': 0.24210816887581219, 'Total loss': 0.24210816887581219}
2023-01-05 03:30:08,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:08,060 INFO:     Epoch: 43
2023-01-05 03:30:10,281 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4191758746902148, 'Total loss': 0.4191758746902148} | train loss {'Reaction outcome loss': 0.2392670315330046, 'Total loss': 0.2392670315330046}
2023-01-05 03:30:10,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:10,281 INFO:     Epoch: 44
2023-01-05 03:30:12,509 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4215288000802199, 'Total loss': 0.4215288000802199} | train loss {'Reaction outcome loss': 0.23962589169777657, 'Total loss': 0.23962589169777657}
2023-01-05 03:30:12,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:12,510 INFO:     Epoch: 45
2023-01-05 03:30:14,708 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4329955031474431, 'Total loss': 0.4329955031474431} | train loss {'Reaction outcome loss': 0.22680011645883974, 'Total loss': 0.22680011645883974}
2023-01-05 03:30:14,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:14,708 INFO:     Epoch: 46
2023-01-05 03:30:16,872 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43053837462017935, 'Total loss': 0.43053837462017935} | train loss {'Reaction outcome loss': 0.22885963163019096, 'Total loss': 0.22885963163019096}
2023-01-05 03:30:16,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:16,872 INFO:     Epoch: 47
2023-01-05 03:30:19,071 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42006477117538454, 'Total loss': 0.42006477117538454} | train loss {'Reaction outcome loss': 0.22667956541897388, 'Total loss': 0.22667956541897388}
2023-01-05 03:30:19,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:19,071 INFO:     Epoch: 48
2023-01-05 03:30:21,278 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41910351514816285, 'Total loss': 0.41910351514816285} | train loss {'Reaction outcome loss': 0.22881896770049404, 'Total loss': 0.22881896770049404}
2023-01-05 03:30:21,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:21,278 INFO:     Epoch: 49
2023-01-05 03:30:23,442 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41198944399754206, 'Total loss': 0.41198944399754206} | train loss {'Reaction outcome loss': 0.224675888977401, 'Total loss': 0.224675888977401}
2023-01-05 03:30:23,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:23,443 INFO:     Epoch: 50
2023-01-05 03:30:25,665 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4222453912099203, 'Total loss': 0.4222453912099203} | train loss {'Reaction outcome loss': 0.22090561836142175, 'Total loss': 0.22090561836142175}
2023-01-05 03:30:25,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:25,666 INFO:     Epoch: 51
2023-01-05 03:30:27,885 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42811029075334467, 'Total loss': 0.42811029075334467} | train loss {'Reaction outcome loss': 0.22060606558297347, 'Total loss': 0.22060606558297347}
2023-01-05 03:30:27,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:27,886 INFO:     Epoch: 52
2023-01-05 03:30:30,098 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4311039686203003, 'Total loss': 0.4311039686203003} | train loss {'Reaction outcome loss': 0.22068858009348385, 'Total loss': 0.22068858009348385}
2023-01-05 03:30:30,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:30,098 INFO:     Epoch: 53
2023-01-05 03:30:32,266 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4264754150994122, 'Total loss': 0.4264754150994122} | train loss {'Reaction outcome loss': 0.2193795660014407, 'Total loss': 0.2193795660014407}
2023-01-05 03:30:32,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:32,266 INFO:     Epoch: 54
2023-01-05 03:30:34,481 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4341076741615931, 'Total loss': 0.4341076741615931} | train loss {'Reaction outcome loss': 0.21335160289381216, 'Total loss': 0.21335160289381216}
2023-01-05 03:30:34,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:34,482 INFO:     Epoch: 55
2023-01-05 03:30:36,701 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4363895505666733, 'Total loss': 0.4363895505666733} | train loss {'Reaction outcome loss': 0.2082253103926234, 'Total loss': 0.2082253103926234}
2023-01-05 03:30:36,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:36,701 INFO:     Epoch: 56
2023-01-05 03:30:38,916 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4480471595500906, 'Total loss': 0.4480471595500906} | train loss {'Reaction outcome loss': 0.2109145901886488, 'Total loss': 0.2109145901886488}
2023-01-05 03:30:38,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:38,916 INFO:     Epoch: 57
2023-01-05 03:30:41,135 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4052371536691984, 'Total loss': 0.4052371536691984} | train loss {'Reaction outcome loss': 0.21043051365953291, 'Total loss': 0.21043051365953291}
2023-01-05 03:30:41,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:41,135 INFO:     Epoch: 58
2023-01-05 03:30:43,330 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45664656658967334, 'Total loss': 0.45664656658967334} | train loss {'Reaction outcome loss': 0.20650529773756318, 'Total loss': 0.20650529773756318}
2023-01-05 03:30:43,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:43,330 INFO:     Epoch: 59
2023-01-05 03:30:45,538 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41750296807537474, 'Total loss': 0.41750296807537474} | train loss {'Reaction outcome loss': 0.21075025738903533, 'Total loss': 0.21075025738903533}
2023-01-05 03:30:45,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:45,538 INFO:     Epoch: 60
2023-01-05 03:30:47,768 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44111828605333964, 'Total loss': 0.44111828605333964} | train loss {'Reaction outcome loss': 0.20301403159302842, 'Total loss': 0.20301403159302842}
2023-01-05 03:30:47,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:47,768 INFO:     Epoch: 61
2023-01-05 03:30:49,980 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44154868721961976, 'Total loss': 0.44154868721961976} | train loss {'Reaction outcome loss': 0.21065492640473765, 'Total loss': 0.21065492640473765}
2023-01-05 03:30:49,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:49,980 INFO:     Epoch: 62
2023-01-05 03:30:52,223 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39741753538449603, 'Total loss': 0.39741753538449603} | train loss {'Reaction outcome loss': 0.21007916378877023, 'Total loss': 0.21007916378877023}
2023-01-05 03:30:52,223 INFO:     Found new best model at epoch 62
2023-01-05 03:30:52,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:52,225 INFO:     Epoch: 63
2023-01-05 03:30:54,420 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4450973242521286, 'Total loss': 0.4450973242521286} | train loss {'Reaction outcome loss': 0.19734186947644844, 'Total loss': 0.19734186947644844}
2023-01-05 03:30:54,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:54,420 INFO:     Epoch: 64
2023-01-05 03:30:56,634 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4183717598517736, 'Total loss': 0.4183717598517736} | train loss {'Reaction outcome loss': 0.20310442488178285, 'Total loss': 0.20310442488178285}
2023-01-05 03:30:56,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:56,634 INFO:     Epoch: 65
2023-01-05 03:30:58,861 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43014673292636874, 'Total loss': 0.43014673292636874} | train loss {'Reaction outcome loss': 0.2032328585951324, 'Total loss': 0.2032328585951324}
2023-01-05 03:30:58,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:30:58,861 INFO:     Epoch: 66
2023-01-05 03:31:01,084 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4364199057221413, 'Total loss': 0.4364199057221413} | train loss {'Reaction outcome loss': 0.19394258504570291, 'Total loss': 0.19394258504570291}
2023-01-05 03:31:01,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:01,084 INFO:     Epoch: 67
2023-01-05 03:31:03,318 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44171890020370486, 'Total loss': 0.44171890020370486} | train loss {'Reaction outcome loss': 0.1924858602769945, 'Total loss': 0.1924858602769945}
2023-01-05 03:31:03,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:03,319 INFO:     Epoch: 68
2023-01-05 03:31:05,469 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4675095245242119, 'Total loss': 0.4675095245242119} | train loss {'Reaction outcome loss': 0.19550338053878696, 'Total loss': 0.19550338053878696}
2023-01-05 03:31:05,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:05,469 INFO:     Epoch: 69
2023-01-05 03:31:07,605 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46806418349345524, 'Total loss': 0.46806418349345524} | train loss {'Reaction outcome loss': 0.19539603839941105, 'Total loss': 0.19539603839941105}
2023-01-05 03:31:07,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:07,605 INFO:     Epoch: 70
2023-01-05 03:31:09,829 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44563887218634285, 'Total loss': 0.44563887218634285} | train loss {'Reaction outcome loss': 0.193834474145428, 'Total loss': 0.193834474145428}
2023-01-05 03:31:09,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:09,830 INFO:     Epoch: 71
2023-01-05 03:31:12,034 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4182273974021276, 'Total loss': 0.4182273974021276} | train loss {'Reaction outcome loss': 0.19127148616188852, 'Total loss': 0.19127148616188852}
2023-01-05 03:31:12,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:12,034 INFO:     Epoch: 72
2023-01-05 03:31:14,286 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4394092122713725, 'Total loss': 0.4394092122713725} | train loss {'Reaction outcome loss': 0.19489095721353036, 'Total loss': 0.19489095721353036}
2023-01-05 03:31:14,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:14,286 INFO:     Epoch: 73
2023-01-05 03:31:16,531 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4526600147287051, 'Total loss': 0.4526600147287051} | train loss {'Reaction outcome loss': 0.19466687091898147, 'Total loss': 0.19466687091898147}
2023-01-05 03:31:16,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:16,531 INFO:     Epoch: 74
2023-01-05 03:31:18,829 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4346380223830541, 'Total loss': 0.4346380223830541} | train loss {'Reaction outcome loss': 0.19059163689558958, 'Total loss': 0.19059163689558958}
2023-01-05 03:31:18,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:18,829 INFO:     Epoch: 75
2023-01-05 03:31:21,050 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4068200950821241, 'Total loss': 0.4068200950821241} | train loss {'Reaction outcome loss': 0.18683606168649491, 'Total loss': 0.18683606168649491}
2023-01-05 03:31:21,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:21,050 INFO:     Epoch: 76
2023-01-05 03:31:23,300 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45406152680516243, 'Total loss': 0.45406152680516243} | train loss {'Reaction outcome loss': 0.18610663789861503, 'Total loss': 0.18610663789861503}
2023-01-05 03:31:23,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:23,301 INFO:     Epoch: 77
2023-01-05 03:31:25,543 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4661033570766449, 'Total loss': 0.4661033570766449} | train loss {'Reaction outcome loss': 0.18677820079028606, 'Total loss': 0.18677820079028606}
2023-01-05 03:31:25,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:25,543 INFO:     Epoch: 78
2023-01-05 03:31:27,788 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.435085525115331, 'Total loss': 0.435085525115331} | train loss {'Reaction outcome loss': 0.1820841174076454, 'Total loss': 0.1820841174076454}
2023-01-05 03:31:27,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:27,788 INFO:     Epoch: 79
2023-01-05 03:31:30,002 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4576127847035726, 'Total loss': 0.4576127847035726} | train loss {'Reaction outcome loss': 0.1795066828044118, 'Total loss': 0.1795066828044118}
2023-01-05 03:31:30,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:30,002 INFO:     Epoch: 80
2023-01-05 03:31:32,193 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44236934085687, 'Total loss': 0.44236934085687} | train loss {'Reaction outcome loss': 0.1835559773238471, 'Total loss': 0.1835559773238471}
2023-01-05 03:31:32,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:32,194 INFO:     Epoch: 81
2023-01-05 03:31:34,371 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43325264751911163, 'Total loss': 0.43325264751911163} | train loss {'Reaction outcome loss': 0.183545190446677, 'Total loss': 0.183545190446677}
2023-01-05 03:31:34,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:34,371 INFO:     Epoch: 82
2023-01-05 03:31:36,511 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44336550186077756, 'Total loss': 0.44336550186077756} | train loss {'Reaction outcome loss': 0.17920357259806163, 'Total loss': 0.17920357259806163}
2023-01-05 03:31:36,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:36,511 INFO:     Epoch: 83
2023-01-05 03:31:38,764 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47398668626944224, 'Total loss': 0.47398668626944224} | train loss {'Reaction outcome loss': 0.18030531636446062, 'Total loss': 0.18030531636446062}
2023-01-05 03:31:38,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:38,764 INFO:     Epoch: 84
2023-01-05 03:31:40,921 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4402911365032196, 'Total loss': 0.4402911365032196} | train loss {'Reaction outcome loss': 0.181132556386224, 'Total loss': 0.181132556386224}
2023-01-05 03:31:40,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:40,922 INFO:     Epoch: 85
2023-01-05 03:31:43,089 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4692103644212087, 'Total loss': 0.4692103644212087} | train loss {'Reaction outcome loss': 0.1793800424240584, 'Total loss': 0.1793800424240584}
2023-01-05 03:31:43,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:43,089 INFO:     Epoch: 86
2023-01-05 03:31:45,260 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44432064360007645, 'Total loss': 0.44432064360007645} | train loss {'Reaction outcome loss': 0.17964741736174608, 'Total loss': 0.17964741736174608}
2023-01-05 03:31:45,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:45,260 INFO:     Epoch: 87
2023-01-05 03:31:47,453 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4729885637760162, 'Total loss': 0.4729885637760162} | train loss {'Reaction outcome loss': 0.17444594144263734, 'Total loss': 0.17444594144263734}
2023-01-05 03:31:47,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:47,454 INFO:     Epoch: 88
2023-01-05 03:31:49,710 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4253377561767896, 'Total loss': 0.4253377561767896} | train loss {'Reaction outcome loss': 0.17748246083280791, 'Total loss': 0.17748246083280791}
2023-01-05 03:31:49,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:49,710 INFO:     Epoch: 89
2023-01-05 03:31:51,968 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4724368949731191, 'Total loss': 0.4724368949731191} | train loss {'Reaction outcome loss': 0.1771788108179577, 'Total loss': 0.1771788108179577}
2023-01-05 03:31:51,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:51,968 INFO:     Epoch: 90
2023-01-05 03:31:54,204 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44515811627109847, 'Total loss': 0.44515811627109847} | train loss {'Reaction outcome loss': 0.1787518909180632, 'Total loss': 0.1787518909180632}
2023-01-05 03:31:54,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:54,205 INFO:     Epoch: 91
2023-01-05 03:31:56,493 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48030200799306233, 'Total loss': 0.48030200799306233} | train loss {'Reaction outcome loss': 0.1752042266315896, 'Total loss': 0.1752042266315896}
2023-01-05 03:31:56,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:56,493 INFO:     Epoch: 92
2023-01-05 03:31:58,762 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42765342791875205, 'Total loss': 0.42765342791875205} | train loss {'Reaction outcome loss': 0.17124310830084566, 'Total loss': 0.17124310830084566}
2023-01-05 03:31:58,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:31:58,762 INFO:     Epoch: 93
2023-01-05 03:32:01,028 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4669144394497077, 'Total loss': 0.4669144394497077} | train loss {'Reaction outcome loss': 0.17006125017987006, 'Total loss': 0.17006125017987006}
2023-01-05 03:32:01,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:01,028 INFO:     Epoch: 94
2023-01-05 03:32:03,281 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4802947531143824, 'Total loss': 0.4802947531143824} | train loss {'Reaction outcome loss': 0.16746923766765118, 'Total loss': 0.16746923766765118}
2023-01-05 03:32:03,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:03,281 INFO:     Epoch: 95
2023-01-05 03:32:05,495 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4619989757736524, 'Total loss': 0.4619989757736524} | train loss {'Reaction outcome loss': 0.1719217687627695, 'Total loss': 0.1719217687627695}
2023-01-05 03:32:05,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:05,496 INFO:     Epoch: 96
2023-01-05 03:32:07,751 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4700007975101471, 'Total loss': 0.4700007975101471} | train loss {'Reaction outcome loss': 0.17737254250733467, 'Total loss': 0.17737254250733467}
2023-01-05 03:32:07,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:07,752 INFO:     Epoch: 97
2023-01-05 03:32:09,957 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45451472798983256, 'Total loss': 0.45451472798983256} | train loss {'Reaction outcome loss': 0.1743651386996201, 'Total loss': 0.1743651386996201}
2023-01-05 03:32:09,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:09,958 INFO:     Epoch: 98
2023-01-05 03:32:12,188 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48101813395818077, 'Total loss': 0.48101813395818077} | train loss {'Reaction outcome loss': 0.17309452729286068, 'Total loss': 0.17309452729286068}
2023-01-05 03:32:12,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:12,188 INFO:     Epoch: 99
2023-01-05 03:32:14,409 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47310880521933235, 'Total loss': 0.47310880521933235} | train loss {'Reaction outcome loss': 0.17211165661876002, 'Total loss': 0.17211165661876002}
2023-01-05 03:32:14,409 INFO:     Best model found after epoch 63 of 100.
2023-01-05 03:32:14,409 INFO:   Done with stage: TRAINING
2023-01-05 03:32:14,409 INFO:   Starting stage: EVALUATION
2023-01-05 03:32:14,550 INFO:   Done with stage: EVALUATION
2023-01-05 03:32:14,550 INFO:   Leaving out SEQ value Fold_3
2023-01-05 03:32:14,563 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 03:32:14,563 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:32:15,204 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:32:15,204 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:32:15,273 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:32:15,274 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:32:15,274 INFO:     No hyperparam tuning for this model
2023-01-05 03:32:15,274 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:32:15,274 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:32:15,274 INFO:     None feature selector for col prot
2023-01-05 03:32:15,275 INFO:     None feature selector for col prot
2023-01-05 03:32:15,275 INFO:     None feature selector for col prot
2023-01-05 03:32:15,275 INFO:     None feature selector for col chem
2023-01-05 03:32:15,275 INFO:     None feature selector for col chem
2023-01-05 03:32:15,275 INFO:     None feature selector for col chem
2023-01-05 03:32:15,275 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:32:15,275 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:32:15,277 INFO:     Number of params in model 72931
2023-01-05 03:32:15,280 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:32:15,280 INFO:   Starting stage: TRAINING
2023-01-05 03:32:15,339 INFO:     Val loss before train {'Reaction outcome loss': 0.9738998651504517, 'Total loss': 0.9738998651504517}
2023-01-05 03:32:15,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:15,339 INFO:     Epoch: 0
2023-01-05 03:32:17,542 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7205138405164083, 'Total loss': 0.7205138405164083} | train loss {'Reaction outcome loss': 0.9429821928922277, 'Total loss': 0.9429821928922277}
2023-01-05 03:32:17,542 INFO:     Found new best model at epoch 0
2023-01-05 03:32:17,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:17,544 INFO:     Epoch: 1
2023-01-05 03:32:19,793 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5414248565832774, 'Total loss': 0.5414248565832774} | train loss {'Reaction outcome loss': 0.6318507094452851, 'Total loss': 0.6318507094452851}
2023-01-05 03:32:19,793 INFO:     Found new best model at epoch 1
2023-01-05 03:32:19,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:19,795 INFO:     Epoch: 2
2023-01-05 03:32:21,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5054687857627869, 'Total loss': 0.5054687857627869} | train loss {'Reaction outcome loss': 0.5444937731771573, 'Total loss': 0.5444937731771573}
2023-01-05 03:32:21,985 INFO:     Found new best model at epoch 2
2023-01-05 03:32:21,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:21,987 INFO:     Epoch: 3
2023-01-05 03:32:24,239 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4839806059996287, 'Total loss': 0.4839806059996287} | train loss {'Reaction outcome loss': 0.5032798570111721, 'Total loss': 0.5032798570111721}
2023-01-05 03:32:24,239 INFO:     Found new best model at epoch 3
2023-01-05 03:32:24,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:24,240 INFO:     Epoch: 4
2023-01-05 03:32:26,488 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4646863987048467, 'Total loss': 0.4646863987048467} | train loss {'Reaction outcome loss': 0.478060348299298, 'Total loss': 0.478060348299298}
2023-01-05 03:32:26,488 INFO:     Found new best model at epoch 4
2023-01-05 03:32:26,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:26,490 INFO:     Epoch: 5
2023-01-05 03:32:28,693 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45622071623802185, 'Total loss': 0.45622071623802185} | train loss {'Reaction outcome loss': 0.45154789296814996, 'Total loss': 0.45154789296814996}
2023-01-05 03:32:28,693 INFO:     Found new best model at epoch 5
2023-01-05 03:32:28,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:28,694 INFO:     Epoch: 6
2023-01-05 03:32:30,937 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41127296884854636, 'Total loss': 0.41127296884854636} | train loss {'Reaction outcome loss': 0.43461206781059286, 'Total loss': 0.43461206781059286}
2023-01-05 03:32:30,938 INFO:     Found new best model at epoch 6
2023-01-05 03:32:30,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:30,939 INFO:     Epoch: 7
2023-01-05 03:32:33,193 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4103377322355906, 'Total loss': 0.4103377322355906} | train loss {'Reaction outcome loss': 0.4191325370521441, 'Total loss': 0.4191325370521441}
2023-01-05 03:32:33,193 INFO:     Found new best model at epoch 7
2023-01-05 03:32:33,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:33,194 INFO:     Epoch: 8
2023-01-05 03:32:35,453 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4205176333586375, 'Total loss': 0.4205176333586375} | train loss {'Reaction outcome loss': 0.4010915773628402, 'Total loss': 0.4010915773628402}
2023-01-05 03:32:35,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:35,454 INFO:     Epoch: 9
2023-01-05 03:32:37,706 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4167952428261439, 'Total loss': 0.4167952428261439} | train loss {'Reaction outcome loss': 0.38855774910019264, 'Total loss': 0.38855774910019264}
2023-01-05 03:32:37,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:37,707 INFO:     Epoch: 10
2023-01-05 03:32:39,902 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39661485254764556, 'Total loss': 0.39661485254764556} | train loss {'Reaction outcome loss': 0.3739064272194013, 'Total loss': 0.3739064272194013}
2023-01-05 03:32:39,903 INFO:     Found new best model at epoch 10
2023-01-05 03:32:39,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:39,904 INFO:     Epoch: 11
2023-01-05 03:32:42,150 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42015463709831236, 'Total loss': 0.42015463709831236} | train loss {'Reaction outcome loss': 0.36637145245488545, 'Total loss': 0.36637145245488545}
2023-01-05 03:32:42,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:42,150 INFO:     Epoch: 12
2023-01-05 03:32:44,396 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.371804312368234, 'Total loss': 0.371804312368234} | train loss {'Reaction outcome loss': 0.3541727718101801, 'Total loss': 0.3541727718101801}
2023-01-05 03:32:44,396 INFO:     Found new best model at epoch 12
2023-01-05 03:32:44,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:44,398 INFO:     Epoch: 13
2023-01-05 03:32:46,627 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38587429920832317, 'Total loss': 0.38587429920832317} | train loss {'Reaction outcome loss': 0.34532698109256527, 'Total loss': 0.34532698109256527}
2023-01-05 03:32:46,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:46,628 INFO:     Epoch: 14
2023-01-05 03:32:48,861 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3890671581029892, 'Total loss': 0.3890671581029892} | train loss {'Reaction outcome loss': 0.33462059489675683, 'Total loss': 0.33462059489675683}
2023-01-05 03:32:48,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:48,861 INFO:     Epoch: 15
2023-01-05 03:32:51,058 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3747046858072281, 'Total loss': 0.3747046858072281} | train loss {'Reaction outcome loss': 0.3295395094765364, 'Total loss': 0.3295395094765364}
2023-01-05 03:32:51,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:51,059 INFO:     Epoch: 16
2023-01-05 03:32:53,280 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3791035056114197, 'Total loss': 0.3791035056114197} | train loss {'Reaction outcome loss': 0.32213387661443577, 'Total loss': 0.32213387661443577}
2023-01-05 03:32:53,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:53,281 INFO:     Epoch: 17
2023-01-05 03:32:55,489 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37731825311978656, 'Total loss': 0.37731825311978656} | train loss {'Reaction outcome loss': 0.30960861422175906, 'Total loss': 0.30960861422175906}
2023-01-05 03:32:55,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:55,489 INFO:     Epoch: 18
2023-01-05 03:32:57,722 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40811400214831034, 'Total loss': 0.40811400214831034} | train loss {'Reaction outcome loss': 0.30533197499050274, 'Total loss': 0.30533197499050274}
2023-01-05 03:32:57,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:57,722 INFO:     Epoch: 19
2023-01-05 03:32:59,966 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3991335978110631, 'Total loss': 0.3991335978110631} | train loss {'Reaction outcome loss': 0.29989156852999743, 'Total loss': 0.29989156852999743}
2023-01-05 03:32:59,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:32:59,966 INFO:     Epoch: 20
2023-01-05 03:33:02,087 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40538249438007673, 'Total loss': 0.40538249438007673} | train loss {'Reaction outcome loss': 0.2912352208496772, 'Total loss': 0.2912352208496772}
2023-01-05 03:33:02,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:02,087 INFO:     Epoch: 21
2023-01-05 03:33:04,297 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3837794209520022, 'Total loss': 0.3837794209520022} | train loss {'Reaction outcome loss': 0.2869619281867342, 'Total loss': 0.2869619281867342}
2023-01-05 03:33:04,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:04,297 INFO:     Epoch: 22
2023-01-05 03:33:06,532 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.390382852156957, 'Total loss': 0.390382852156957} | train loss {'Reaction outcome loss': 0.284523475520911, 'Total loss': 0.284523475520911}
2023-01-05 03:33:06,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:06,533 INFO:     Epoch: 23
2023-01-05 03:33:08,781 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40882505277792613, 'Total loss': 0.40882505277792613} | train loss {'Reaction outcome loss': 0.27384559644291, 'Total loss': 0.27384559644291}
2023-01-05 03:33:08,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:08,781 INFO:     Epoch: 24
2023-01-05 03:33:11,039 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4051295762260755, 'Total loss': 0.4051295762260755} | train loss {'Reaction outcome loss': 0.27153947236301906, 'Total loss': 0.27153947236301906}
2023-01-05 03:33:11,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:11,040 INFO:     Epoch: 25
2023-01-05 03:33:13,293 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40166476666927337, 'Total loss': 0.40166476666927337} | train loss {'Reaction outcome loss': 0.2683261742842567, 'Total loss': 0.2683261742842567}
2023-01-05 03:33:13,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:13,293 INFO:     Epoch: 26
2023-01-05 03:33:15,508 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3774918819467227, 'Total loss': 0.3774918819467227} | train loss {'Reaction outcome loss': 0.26639304132656244, 'Total loss': 0.26639304132656244}
2023-01-05 03:33:15,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:15,508 INFO:     Epoch: 27
2023-01-05 03:33:17,762 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3795479347308477, 'Total loss': 0.3795479347308477} | train loss {'Reaction outcome loss': 0.2533393939345205, 'Total loss': 0.2533393939345205}
2023-01-05 03:33:17,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:17,762 INFO:     Epoch: 28
2023-01-05 03:33:20,003 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40055420994758606, 'Total loss': 0.40055420994758606} | train loss {'Reaction outcome loss': 0.2551750182751974, 'Total loss': 0.2551750182751974}
2023-01-05 03:33:20,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:20,003 INFO:     Epoch: 29
2023-01-05 03:33:22,273 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.399669803182284, 'Total loss': 0.399669803182284} | train loss {'Reaction outcome loss': 0.2565261987105936, 'Total loss': 0.2565261987105936}
2023-01-05 03:33:22,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:22,274 INFO:     Epoch: 30
2023-01-05 03:33:24,507 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38727974096934, 'Total loss': 0.38727974096934} | train loss {'Reaction outcome loss': 0.24500472340256954, 'Total loss': 0.24500472340256954}
2023-01-05 03:33:24,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:24,508 INFO:     Epoch: 31
2023-01-05 03:33:26,705 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.396738238632679, 'Total loss': 0.396738238632679} | train loss {'Reaction outcome loss': 0.24651627843506144, 'Total loss': 0.24651627843506144}
2023-01-05 03:33:26,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:26,705 INFO:     Epoch: 32
2023-01-05 03:33:28,952 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3826253419121107, 'Total loss': 0.3826253419121107} | train loss {'Reaction outcome loss': 0.2432195262262856, 'Total loss': 0.2432195262262856}
2023-01-05 03:33:28,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:28,953 INFO:     Epoch: 33
2023-01-05 03:33:31,200 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40392566174268724, 'Total loss': 0.40392566174268724} | train loss {'Reaction outcome loss': 0.24341223073484253, 'Total loss': 0.24341223073484253}
2023-01-05 03:33:31,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:31,200 INFO:     Epoch: 34
2023-01-05 03:33:33,453 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41168936192989347, 'Total loss': 0.41168936192989347} | train loss {'Reaction outcome loss': 0.2369056010523634, 'Total loss': 0.2369056010523634}
2023-01-05 03:33:33,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:33,454 INFO:     Epoch: 35
2023-01-05 03:33:35,708 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39375170816977817, 'Total loss': 0.39375170816977817} | train loss {'Reaction outcome loss': 0.2379078371722224, 'Total loss': 0.2379078371722224}
2023-01-05 03:33:35,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:35,708 INFO:     Epoch: 36
2023-01-05 03:33:37,955 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40430650959412257, 'Total loss': 0.40430650959412257} | train loss {'Reaction outcome loss': 0.2335702969257577, 'Total loss': 0.2335702969257577}
2023-01-05 03:33:37,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:37,955 INFO:     Epoch: 37
2023-01-05 03:33:40,195 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3992814098795255, 'Total loss': 0.3992814098795255} | train loss {'Reaction outcome loss': 0.22827684266125634, 'Total loss': 0.22827684266125634}
2023-01-05 03:33:40,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:40,195 INFO:     Epoch: 38
2023-01-05 03:33:42,445 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38665533574918903, 'Total loss': 0.38665533574918903} | train loss {'Reaction outcome loss': 0.23029686535715405, 'Total loss': 0.23029686535715405}
2023-01-05 03:33:42,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:42,446 INFO:     Epoch: 39
2023-01-05 03:33:44,690 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44340900679429374, 'Total loss': 0.44340900679429374} | train loss {'Reaction outcome loss': 0.22721424614194863, 'Total loss': 0.22721424614194863}
2023-01-05 03:33:44,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:44,690 INFO:     Epoch: 40
2023-01-05 03:33:46,912 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4283549537261327, 'Total loss': 0.4283549537261327} | train loss {'Reaction outcome loss': 0.2244802280295178, 'Total loss': 0.2244802280295178}
2023-01-05 03:33:46,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:46,912 INFO:     Epoch: 41
2023-01-05 03:33:49,132 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39531562564273676, 'Total loss': 0.39531562564273676} | train loss {'Reaction outcome loss': 0.22349550731371354, 'Total loss': 0.22349550731371354}
2023-01-05 03:33:49,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:49,132 INFO:     Epoch: 42
2023-01-05 03:33:51,283 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4075301776329676, 'Total loss': 0.4075301776329676} | train loss {'Reaction outcome loss': 0.22540516629271265, 'Total loss': 0.22540516629271265}
2023-01-05 03:33:51,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:51,283 INFO:     Epoch: 43
2023-01-05 03:33:53,421 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4033067693312963, 'Total loss': 0.4033067693312963} | train loss {'Reaction outcome loss': 0.21751909474604322, 'Total loss': 0.21751909474604322}
2023-01-05 03:33:53,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:53,421 INFO:     Epoch: 44
2023-01-05 03:33:55,581 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4150292764107386, 'Total loss': 0.4150292764107386} | train loss {'Reaction outcome loss': 0.21112562201740423, 'Total loss': 0.21112562201740423}
2023-01-05 03:33:55,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:55,582 INFO:     Epoch: 45
2023-01-05 03:33:57,621 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4209716200828552, 'Total loss': 0.4209716200828552} | train loss {'Reaction outcome loss': 0.21849991628274756, 'Total loss': 0.21849991628274756}
2023-01-05 03:33:57,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:57,622 INFO:     Epoch: 46
2023-01-05 03:33:59,870 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.457997457186381, 'Total loss': 0.457997457186381} | train loss {'Reaction outcome loss': 0.21465906239094307, 'Total loss': 0.21465906239094307}
2023-01-05 03:33:59,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:33:59,871 INFO:     Epoch: 47
2023-01-05 03:34:02,070 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40851256599028907, 'Total loss': 0.40851256599028907} | train loss {'Reaction outcome loss': 0.2130371261809538, 'Total loss': 0.2130371261809538}
2023-01-05 03:34:02,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:02,070 INFO:     Epoch: 48
2023-01-05 03:34:04,326 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4323297023773193, 'Total loss': 0.4323297023773193} | train loss {'Reaction outcome loss': 0.21410642889919726, 'Total loss': 0.21410642889919726}
2023-01-05 03:34:04,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:04,327 INFO:     Epoch: 49
2023-01-05 03:34:06,586 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42029167314370475, 'Total loss': 0.42029167314370475} | train loss {'Reaction outcome loss': 0.21157549501797795, 'Total loss': 0.21157549501797795}
2023-01-05 03:34:06,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:06,587 INFO:     Epoch: 50
2023-01-05 03:34:08,842 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3905701501915852, 'Total loss': 0.3905701501915852} | train loss {'Reaction outcome loss': 0.20713930337751, 'Total loss': 0.20713930337751}
2023-01-05 03:34:08,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:08,842 INFO:     Epoch: 51
2023-01-05 03:34:11,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40234632343053817, 'Total loss': 0.40234632343053817} | train loss {'Reaction outcome loss': 0.20505180346174506, 'Total loss': 0.20505180346174506}
2023-01-05 03:34:11,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:11,064 INFO:     Epoch: 52
2023-01-05 03:34:13,252 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4015888154506683, 'Total loss': 0.4015888154506683} | train loss {'Reaction outcome loss': 0.2051824799800006, 'Total loss': 0.2051824799800006}
2023-01-05 03:34:13,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:13,252 INFO:     Epoch: 53
2023-01-05 03:34:15,485 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3873390590151151, 'Total loss': 0.3873390590151151} | train loss {'Reaction outcome loss': 0.20106574091856388, 'Total loss': 0.20106574091856388}
2023-01-05 03:34:15,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:15,486 INFO:     Epoch: 54
2023-01-05 03:34:17,680 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4340432360768318, 'Total loss': 0.4340432360768318} | train loss {'Reaction outcome loss': 0.20405007803635875, 'Total loss': 0.20405007803635875}
2023-01-05 03:34:17,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:17,681 INFO:     Epoch: 55
2023-01-05 03:34:19,892 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4313062846660614, 'Total loss': 0.4313062846660614} | train loss {'Reaction outcome loss': 0.20240829858493847, 'Total loss': 0.20240829858493847}
2023-01-05 03:34:19,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:19,892 INFO:     Epoch: 56
2023-01-05 03:34:22,113 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44098976651827493, 'Total loss': 0.44098976651827493} | train loss {'Reaction outcome loss': 0.198868706910769, 'Total loss': 0.198868706910769}
2023-01-05 03:34:22,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:22,113 INFO:     Epoch: 57
2023-01-05 03:34:24,356 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43029513011376064, 'Total loss': 0.43029513011376064} | train loss {'Reaction outcome loss': 0.19940801826135737, 'Total loss': 0.19940801826135737}
2023-01-05 03:34:24,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:24,356 INFO:     Epoch: 58
2023-01-05 03:34:26,572 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42488030592600506, 'Total loss': 0.42488030592600506} | train loss {'Reaction outcome loss': 0.20344004695419304, 'Total loss': 0.20344004695419304}
2023-01-05 03:34:26,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:26,573 INFO:     Epoch: 59
2023-01-05 03:34:28,784 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43914086868365604, 'Total loss': 0.43914086868365604} | train loss {'Reaction outcome loss': 0.19689478256474555, 'Total loss': 0.19689478256474555}
2023-01-05 03:34:28,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:28,784 INFO:     Epoch: 60
2023-01-05 03:34:31,020 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42232457796732586, 'Total loss': 0.42232457796732586} | train loss {'Reaction outcome loss': 0.1930605581159411, 'Total loss': 0.1930605581159411}
2023-01-05 03:34:31,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:31,020 INFO:     Epoch: 61
2023-01-05 03:34:33,251 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4398531277974447, 'Total loss': 0.4398531277974447} | train loss {'Reaction outcome loss': 0.19935229064108137, 'Total loss': 0.19935229064108137}
2023-01-05 03:34:33,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:33,252 INFO:     Epoch: 62
2023-01-05 03:34:35,450 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39957931637763977, 'Total loss': 0.39957931637763977} | train loss {'Reaction outcome loss': 0.19575484714939864, 'Total loss': 0.19575484714939864}
2023-01-05 03:34:35,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:35,450 INFO:     Epoch: 63
2023-01-05 03:34:37,666 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43432066440582273, 'Total loss': 0.43432066440582273} | train loss {'Reaction outcome loss': 0.19164413987339413, 'Total loss': 0.19164413987339413}
2023-01-05 03:34:37,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:37,666 INFO:     Epoch: 64
2023-01-05 03:34:39,858 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40761493345101674, 'Total loss': 0.40761493345101674} | train loss {'Reaction outcome loss': 0.19034324146562467, 'Total loss': 0.19034324146562467}
2023-01-05 03:34:39,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:39,859 INFO:     Epoch: 65
2023-01-05 03:34:42,059 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.435572416583697, 'Total loss': 0.435572416583697} | train loss {'Reaction outcome loss': 0.19251982568436893, 'Total loss': 0.19251982568436893}
2023-01-05 03:34:42,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:42,059 INFO:     Epoch: 66
2023-01-05 03:34:44,296 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43256149093310037, 'Total loss': 0.43256149093310037} | train loss {'Reaction outcome loss': 0.1873476291313278, 'Total loss': 0.1873476291313278}
2023-01-05 03:34:44,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:44,296 INFO:     Epoch: 67
2023-01-05 03:34:46,472 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45166223843892417, 'Total loss': 0.45166223843892417} | train loss {'Reaction outcome loss': 0.1889075192972936, 'Total loss': 0.1889075192972936}
2023-01-05 03:34:46,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:46,473 INFO:     Epoch: 68
2023-01-05 03:34:48,301 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44001771907011666, 'Total loss': 0.44001771907011666} | train loss {'Reaction outcome loss': 0.19288381520169276, 'Total loss': 0.19288381520169276}
2023-01-05 03:34:48,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:48,301 INFO:     Epoch: 69
2023-01-05 03:34:50,122 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42815367331107457, 'Total loss': 0.42815367331107457} | train loss {'Reaction outcome loss': 0.18758212527545698, 'Total loss': 0.18758212527545698}
2023-01-05 03:34:50,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:50,122 INFO:     Epoch: 70
2023-01-05 03:34:52,257 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4646816631158193, 'Total loss': 0.4646816631158193} | train loss {'Reaction outcome loss': 0.18699477169064493, 'Total loss': 0.18699477169064493}
2023-01-05 03:34:52,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:52,258 INFO:     Epoch: 71
2023-01-05 03:34:54,414 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45924398948748907, 'Total loss': 0.45924398948748907} | train loss {'Reaction outcome loss': 0.19309613510735169, 'Total loss': 0.19309613510735169}
2023-01-05 03:34:54,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:54,415 INFO:     Epoch: 72
2023-01-05 03:34:56,570 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4561103478074074, 'Total loss': 0.4561103478074074} | train loss {'Reaction outcome loss': 0.1835588178780936, 'Total loss': 0.1835588178780936}
2023-01-05 03:34:56,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:56,570 INFO:     Epoch: 73
2023-01-05 03:34:58,781 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.430646998838832, 'Total loss': 0.430646998838832} | train loss {'Reaction outcome loss': 0.1898093932209686, 'Total loss': 0.1898093932209686}
2023-01-05 03:34:58,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:34:58,781 INFO:     Epoch: 74
2023-01-05 03:35:00,970 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4483571782708168, 'Total loss': 0.4483571782708168} | train loss {'Reaction outcome loss': 0.18620544352507504, 'Total loss': 0.18620544352507504}
2023-01-05 03:35:00,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:00,971 INFO:     Epoch: 75
2023-01-05 03:35:03,145 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44293894469738004, 'Total loss': 0.44293894469738004} | train loss {'Reaction outcome loss': 0.18035465822194832, 'Total loss': 0.18035465822194832}
2023-01-05 03:35:03,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:03,145 INFO:     Epoch: 76
2023-01-05 03:35:05,287 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4258163750171661, 'Total loss': 0.4258163750171661} | train loss {'Reaction outcome loss': 0.18425839838068797, 'Total loss': 0.18425839838068797}
2023-01-05 03:35:05,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:05,287 INFO:     Epoch: 77
2023-01-05 03:35:07,529 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44988258679707843, 'Total loss': 0.44988258679707843} | train loss {'Reaction outcome loss': 0.187420939724131, 'Total loss': 0.187420939724131}
2023-01-05 03:35:07,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:07,529 INFO:     Epoch: 78
2023-01-05 03:35:09,766 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46350891987482706, 'Total loss': 0.46350891987482706} | train loss {'Reaction outcome loss': 0.18301605203114177, 'Total loss': 0.18301605203114177}
2023-01-05 03:35:09,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:09,767 INFO:     Epoch: 79
2023-01-05 03:35:11,955 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4417859767874082, 'Total loss': 0.4417859767874082} | train loss {'Reaction outcome loss': 0.18022456961636343, 'Total loss': 0.18022456961636343}
2023-01-05 03:35:11,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:11,955 INFO:     Epoch: 80
2023-01-05 03:35:14,145 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4310417880614599, 'Total loss': 0.4310417880614599} | train loss {'Reaction outcome loss': 0.18181735485533837, 'Total loss': 0.18181735485533837}
2023-01-05 03:35:14,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:14,145 INFO:     Epoch: 81
2023-01-05 03:35:16,315 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4523605446020762, 'Total loss': 0.4523605446020762} | train loss {'Reaction outcome loss': 0.18011063336306354, 'Total loss': 0.18011063336306354}
2023-01-05 03:35:16,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:16,315 INFO:     Epoch: 82
2023-01-05 03:35:18,533 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45845422657827534, 'Total loss': 0.45845422657827534} | train loss {'Reaction outcome loss': 0.17786728984329606, 'Total loss': 0.17786728984329606}
2023-01-05 03:35:18,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:18,533 INFO:     Epoch: 83
2023-01-05 03:35:20,720 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4307969103256861, 'Total loss': 0.4307969103256861} | train loss {'Reaction outcome loss': 0.17612069898903587, 'Total loss': 0.17612069898903587}
2023-01-05 03:35:20,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:20,721 INFO:     Epoch: 84
2023-01-05 03:35:22,902 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4252481202284495, 'Total loss': 0.4252481202284495} | train loss {'Reaction outcome loss': 0.17981351213869604, 'Total loss': 0.17981351213869604}
2023-01-05 03:35:22,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:22,902 INFO:     Epoch: 85
2023-01-05 03:35:25,056 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44784989456335705, 'Total loss': 0.44784989456335705} | train loss {'Reaction outcome loss': 0.1754991515390031, 'Total loss': 0.1754991515390031}
2023-01-05 03:35:25,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:25,056 INFO:     Epoch: 86
2023-01-05 03:35:27,239 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4414861877759298, 'Total loss': 0.4414861877759298} | train loss {'Reaction outcome loss': 0.17967428493204723, 'Total loss': 0.17967428493204723}
2023-01-05 03:35:27,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:27,240 INFO:     Epoch: 87
2023-01-05 03:35:29,411 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41528055667877195, 'Total loss': 0.41528055667877195} | train loss {'Reaction outcome loss': 0.18237951204153527, 'Total loss': 0.18237951204153527}
2023-01-05 03:35:29,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:29,412 INFO:     Epoch: 88
2023-01-05 03:35:31,632 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45351631144682564, 'Total loss': 0.45351631144682564} | train loss {'Reaction outcome loss': 0.175117850142198, 'Total loss': 0.175117850142198}
2023-01-05 03:35:31,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:31,633 INFO:     Epoch: 89
2023-01-05 03:35:33,852 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4561982716123263, 'Total loss': 0.4561982716123263} | train loss {'Reaction outcome loss': 0.1789592785597609, 'Total loss': 0.1789592785597609}
2023-01-05 03:35:33,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:33,853 INFO:     Epoch: 90
2023-01-05 03:35:36,053 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42106933342292907, 'Total loss': 0.42106933342292907} | train loss {'Reaction outcome loss': 0.1749208819709147, 'Total loss': 0.1749208819709147}
2023-01-05 03:35:36,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:36,053 INFO:     Epoch: 91
2023-01-05 03:35:38,219 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48503735264142356, 'Total loss': 0.48503735264142356} | train loss {'Reaction outcome loss': 0.1694698508448192, 'Total loss': 0.1694698508448192}
2023-01-05 03:35:38,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:38,219 INFO:     Epoch: 92
2023-01-05 03:35:40,454 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4555496791998545, 'Total loss': 0.4555496791998545} | train loss {'Reaction outcome loss': 0.17564684701199731, 'Total loss': 0.17564684701199731}
2023-01-05 03:35:40,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:40,454 INFO:     Epoch: 93
2023-01-05 03:35:42,642 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4618824337919553, 'Total loss': 0.4618824337919553} | train loss {'Reaction outcome loss': 0.17583081436030784, 'Total loss': 0.17583081436030784}
2023-01-05 03:35:42,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:42,642 INFO:     Epoch: 94
2023-01-05 03:35:44,857 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42947458823521933, 'Total loss': 0.42947458823521933} | train loss {'Reaction outcome loss': 0.17023804140052873, 'Total loss': 0.17023804140052873}
2023-01-05 03:35:44,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:44,859 INFO:     Epoch: 95
2023-01-05 03:35:47,037 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4519523173570633, 'Total loss': 0.4519523173570633} | train loss {'Reaction outcome loss': 0.17439201256994458, 'Total loss': 0.17439201256994458}
2023-01-05 03:35:47,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:47,037 INFO:     Epoch: 96
2023-01-05 03:35:49,231 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4390632172425588, 'Total loss': 0.4390632172425588} | train loss {'Reaction outcome loss': 0.17177160926006843, 'Total loss': 0.17177160926006843}
2023-01-05 03:35:49,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:49,231 INFO:     Epoch: 97
2023-01-05 03:35:51,428 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42049210220575334, 'Total loss': 0.42049210220575334} | train loss {'Reaction outcome loss': 0.17733911163663071, 'Total loss': 0.17733911163663071}
2023-01-05 03:35:51,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:51,429 INFO:     Epoch: 98
2023-01-05 03:35:53,622 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40771244565645853, 'Total loss': 0.40771244565645853} | train loss {'Reaction outcome loss': 0.1720871695038611, 'Total loss': 0.1720871695038611}
2023-01-05 03:35:53,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:53,622 INFO:     Epoch: 99
2023-01-05 03:35:55,823 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4393475453058879, 'Total loss': 0.4393475453058879} | train loss {'Reaction outcome loss': 0.17124290148095384, 'Total loss': 0.17124290148095384}
2023-01-05 03:35:55,823 INFO:     Best model found after epoch 13 of 100.
2023-01-05 03:35:55,823 INFO:   Done with stage: TRAINING
2023-01-05 03:35:55,823 INFO:   Starting stage: EVALUATION
2023-01-05 03:35:55,962 INFO:   Done with stage: EVALUATION
2023-01-05 03:35:55,962 INFO:   Leaving out SEQ value Fold_4
2023-01-05 03:35:55,974 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:35:55,974 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:35:56,614 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:35:56,614 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:35:56,682 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:35:56,683 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:35:56,683 INFO:     No hyperparam tuning for this model
2023-01-05 03:35:56,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:35:56,683 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:35:56,683 INFO:     None feature selector for col prot
2023-01-05 03:35:56,684 INFO:     None feature selector for col prot
2023-01-05 03:35:56,684 INFO:     None feature selector for col prot
2023-01-05 03:35:56,684 INFO:     None feature selector for col chem
2023-01-05 03:35:56,684 INFO:     None feature selector for col chem
2023-01-05 03:35:56,684 INFO:     None feature selector for col chem
2023-01-05 03:35:56,684 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:35:56,684 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:35:56,686 INFO:     Number of params in model 72931
2023-01-05 03:35:56,689 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:35:56,689 INFO:   Starting stage: TRAINING
2023-01-05 03:35:56,750 INFO:     Val loss before train {'Reaction outcome loss': 0.9047085920969645, 'Total loss': 0.9047085920969645}
2023-01-05 03:35:56,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:56,750 INFO:     Epoch: 0
2023-01-05 03:35:59,000 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6780427674452464, 'Total loss': 0.6780427674452464} | train loss {'Reaction outcome loss': 0.9347635984852694, 'Total loss': 0.9347635984852694}
2023-01-05 03:35:59,000 INFO:     Found new best model at epoch 0
2023-01-05 03:35:59,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:35:59,001 INFO:     Epoch: 1
2023-01-05 03:36:01,250 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5293278674284617, 'Total loss': 0.5293278674284617} | train loss {'Reaction outcome loss': 0.611102216620592, 'Total loss': 0.611102216620592}
2023-01-05 03:36:01,250 INFO:     Found new best model at epoch 1
2023-01-05 03:36:01,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:01,252 INFO:     Epoch: 2
2023-01-05 03:36:03,510 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.481204163034757, 'Total loss': 0.481204163034757} | train loss {'Reaction outcome loss': 0.5222348459604857, 'Total loss': 0.5222348459604857}
2023-01-05 03:36:03,511 INFO:     Found new best model at epoch 2
2023-01-05 03:36:03,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:03,512 INFO:     Epoch: 3
2023-01-05 03:36:05,769 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4371003270149231, 'Total loss': 0.4371003270149231} | train loss {'Reaction outcome loss': 0.48052318631738855, 'Total loss': 0.48052318631738855}
2023-01-05 03:36:05,769 INFO:     Found new best model at epoch 3
2023-01-05 03:36:05,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:05,771 INFO:     Epoch: 4
2023-01-05 03:36:08,022 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4347537100315094, 'Total loss': 0.4347537100315094} | train loss {'Reaction outcome loss': 0.44706780470153096, 'Total loss': 0.44706780470153096}
2023-01-05 03:36:08,022 INFO:     Found new best model at epoch 4
2023-01-05 03:36:08,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:08,024 INFO:     Epoch: 5
2023-01-05 03:36:10,237 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4326821217934291, 'Total loss': 0.4326821217934291} | train loss {'Reaction outcome loss': 0.4219887789230848, 'Total loss': 0.4219887789230848}
2023-01-05 03:36:10,237 INFO:     Found new best model at epoch 5
2023-01-05 03:36:10,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:10,239 INFO:     Epoch: 6
2023-01-05 03:36:12,460 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4303951273361842, 'Total loss': 0.4303951273361842} | train loss {'Reaction outcome loss': 0.4078827283979542, 'Total loss': 0.4078827283979542}
2023-01-05 03:36:12,460 INFO:     Found new best model at epoch 6
2023-01-05 03:36:12,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:12,462 INFO:     Epoch: 7
2023-01-05 03:36:14,701 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3980145022273064, 'Total loss': 0.3980145022273064} | train loss {'Reaction outcome loss': 0.3921952632507242, 'Total loss': 0.3921952632507242}
2023-01-05 03:36:14,701 INFO:     Found new best model at epoch 7
2023-01-05 03:36:14,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:14,702 INFO:     Epoch: 8
2023-01-05 03:36:16,949 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40534165998299915, 'Total loss': 0.40534165998299915} | train loss {'Reaction outcome loss': 0.37855468398850894, 'Total loss': 0.37855468398850894}
2023-01-05 03:36:16,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:16,949 INFO:     Epoch: 9
2023-01-05 03:36:19,184 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36971838424603143, 'Total loss': 0.36971838424603143} | train loss {'Reaction outcome loss': 0.3648798876683282, 'Total loss': 0.3648798876683282}
2023-01-05 03:36:19,184 INFO:     Found new best model at epoch 9
2023-01-05 03:36:19,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:19,185 INFO:     Epoch: 10
2023-01-05 03:36:21,389 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37505302131175994, 'Total loss': 0.37505302131175994} | train loss {'Reaction outcome loss': 0.35866645565998834, 'Total loss': 0.35866645565998834}
2023-01-05 03:36:21,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:21,391 INFO:     Epoch: 11
2023-01-05 03:36:23,589 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37728012502193453, 'Total loss': 0.37728012502193453} | train loss {'Reaction outcome loss': 0.3480232447175734, 'Total loss': 0.3480232447175734}
2023-01-05 03:36:23,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:23,590 INFO:     Epoch: 12
2023-01-05 03:36:25,833 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36518281797568003, 'Total loss': 0.36518281797568003} | train loss {'Reaction outcome loss': 0.33606668771075865, 'Total loss': 0.33606668771075865}
2023-01-05 03:36:25,833 INFO:     Found new best model at epoch 12
2023-01-05 03:36:25,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:25,835 INFO:     Epoch: 13
2023-01-05 03:36:28,073 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37290439096589884, 'Total loss': 0.37290439096589884} | train loss {'Reaction outcome loss': 0.3483552940567766, 'Total loss': 0.3483552940567766}
2023-01-05 03:36:28,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:28,074 INFO:     Epoch: 14
2023-01-05 03:36:30,335 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3794151167074839, 'Total loss': 0.3794151167074839} | train loss {'Reaction outcome loss': 0.3324549089635527, 'Total loss': 0.3324549089635527}
2023-01-05 03:36:30,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:30,335 INFO:     Epoch: 15
2023-01-05 03:36:32,564 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3753229429324468, 'Total loss': 0.3753229429324468} | train loss {'Reaction outcome loss': 0.31554676841529805, 'Total loss': 0.31554676841529805}
2023-01-05 03:36:32,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:32,565 INFO:     Epoch: 16
2023-01-05 03:36:34,781 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37908143500487007, 'Total loss': 0.37908143500487007} | train loss {'Reaction outcome loss': 0.3071742844362946, 'Total loss': 0.3071742844362946}
2023-01-05 03:36:34,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:34,781 INFO:     Epoch: 17
2023-01-05 03:36:37,004 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3414457579453786, 'Total loss': 0.3414457579453786} | train loss {'Reaction outcome loss': 0.3020275515652653, 'Total loss': 0.3020275515652653}
2023-01-05 03:36:37,005 INFO:     Found new best model at epoch 17
2023-01-05 03:36:37,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:37,006 INFO:     Epoch: 18
2023-01-05 03:36:39,227 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36987177083889644, 'Total loss': 0.36987177083889644} | train loss {'Reaction outcome loss': 0.2924363663878994, 'Total loss': 0.2924363663878994}
2023-01-05 03:36:39,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:39,227 INFO:     Epoch: 19
2023-01-05 03:36:41,418 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36547486086686454, 'Total loss': 0.36547486086686454} | train loss {'Reaction outcome loss': 0.2929680317343361, 'Total loss': 0.2929680317343361}
2023-01-05 03:36:41,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:41,419 INFO:     Epoch: 20
2023-01-05 03:36:43,645 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34927205989758175, 'Total loss': 0.34927205989758175} | train loss {'Reaction outcome loss': 0.28567757058308285, 'Total loss': 0.28567757058308285}
2023-01-05 03:36:43,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:43,645 INFO:     Epoch: 21
2023-01-05 03:36:45,873 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3701933960119883, 'Total loss': 0.3701933960119883} | train loss {'Reaction outcome loss': 0.27803777484518505, 'Total loss': 0.27803777484518505}
2023-01-05 03:36:45,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:45,873 INFO:     Epoch: 22
2023-01-05 03:36:48,078 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3964924233655135, 'Total loss': 0.3964924233655135} | train loss {'Reaction outcome loss': 0.2728404631463649, 'Total loss': 0.2728404631463649}
2023-01-05 03:36:48,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:48,078 INFO:     Epoch: 23
2023-01-05 03:36:50,232 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3530370126167933, 'Total loss': 0.3530370126167933} | train loss {'Reaction outcome loss': 0.27016921930919413, 'Total loss': 0.27016921930919413}
2023-01-05 03:36:50,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:50,232 INFO:     Epoch: 24
2023-01-05 03:36:52,475 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37723415195941923, 'Total loss': 0.37723415195941923} | train loss {'Reaction outcome loss': 0.2638338631148909, 'Total loss': 0.2638338631148909}
2023-01-05 03:36:52,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:52,475 INFO:     Epoch: 25
2023-01-05 03:36:54,716 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3601039300362269, 'Total loss': 0.3601039300362269} | train loss {'Reaction outcome loss': 0.2622255691617135, 'Total loss': 0.2622255691617135}
2023-01-05 03:36:54,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:54,716 INFO:     Epoch: 26
2023-01-05 03:36:56,954 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36408301889896394, 'Total loss': 0.36408301889896394} | train loss {'Reaction outcome loss': 0.2553064816131972, 'Total loss': 0.2553064816131972}
2023-01-05 03:36:56,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:56,955 INFO:     Epoch: 27
2023-01-05 03:36:59,122 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36199452976385754, 'Total loss': 0.36199452976385754} | train loss {'Reaction outcome loss': 0.24857803202652629, 'Total loss': 0.24857803202652629}
2023-01-05 03:36:59,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:36:59,122 INFO:     Epoch: 28
2023-01-05 03:37:01,364 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3784846395254135, 'Total loss': 0.3784846395254135} | train loss {'Reaction outcome loss': 0.24743253215443026, 'Total loss': 0.24743253215443026}
2023-01-05 03:37:01,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:01,364 INFO:     Epoch: 29
2023-01-05 03:37:03,601 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3741545786460241, 'Total loss': 0.3741545786460241} | train loss {'Reaction outcome loss': 0.24303602323145268, 'Total loss': 0.24303602323145268}
2023-01-05 03:37:03,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:03,601 INFO:     Epoch: 30
2023-01-05 03:37:05,825 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37475983301798504, 'Total loss': 0.37475983301798504} | train loss {'Reaction outcome loss': 0.24357272067868177, 'Total loss': 0.24357272067868177}
2023-01-05 03:37:05,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:05,826 INFO:     Epoch: 31
2023-01-05 03:37:07,987 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3695218453804652, 'Total loss': 0.3695218453804652} | train loss {'Reaction outcome loss': 0.23662828936147084, 'Total loss': 0.23662828936147084}
2023-01-05 03:37:07,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:07,987 INFO:     Epoch: 32
2023-01-05 03:37:10,186 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36900933384895324, 'Total loss': 0.36900933384895324} | train loss {'Reaction outcome loss': 0.23410475024265115, 'Total loss': 0.23410475024265115}
2023-01-05 03:37:10,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:10,186 INFO:     Epoch: 33
2023-01-05 03:37:12,385 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3717136194308599, 'Total loss': 0.3717136194308599} | train loss {'Reaction outcome loss': 0.2334303313501827, 'Total loss': 0.2334303313501827}
2023-01-05 03:37:12,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:12,386 INFO:     Epoch: 34
2023-01-05 03:37:14,631 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37692919572194417, 'Total loss': 0.37692919572194417} | train loss {'Reaction outcome loss': 0.22248264497354772, 'Total loss': 0.22248264497354772}
2023-01-05 03:37:14,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:14,631 INFO:     Epoch: 35
2023-01-05 03:37:16,867 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3885031168659528, 'Total loss': 0.3885031168659528} | train loss {'Reaction outcome loss': 0.22504527248995568, 'Total loss': 0.22504527248995568}
2023-01-05 03:37:16,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:16,868 INFO:     Epoch: 36
2023-01-05 03:37:19,035 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3746751497189204, 'Total loss': 0.3746751497189204} | train loss {'Reaction outcome loss': 0.2222255562708702, 'Total loss': 0.2222255562708702}
2023-01-05 03:37:19,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:19,035 INFO:     Epoch: 37
2023-01-05 03:37:21,234 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3774651930357019, 'Total loss': 0.3774651930357019} | train loss {'Reaction outcome loss': 0.2211740465929219, 'Total loss': 0.2211740465929219}
2023-01-05 03:37:21,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:21,234 INFO:     Epoch: 38
2023-01-05 03:37:23,473 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3664738178253174, 'Total loss': 0.3664738178253174} | train loss {'Reaction outcome loss': 0.21500889488147484, 'Total loss': 0.21500889488147484}
2023-01-05 03:37:23,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:23,473 INFO:     Epoch: 39
2023-01-05 03:37:25,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3735126147667567, 'Total loss': 0.3735126147667567} | train loss {'Reaction outcome loss': 0.21747172052425373, 'Total loss': 0.21747172052425373}
2023-01-05 03:37:25,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:25,700 INFO:     Epoch: 40
2023-01-05 03:37:27,940 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3497910579045614, 'Total loss': 0.3497910579045614} | train loss {'Reaction outcome loss': 0.21134142874085438, 'Total loss': 0.21134142874085438}
2023-01-05 03:37:27,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:27,940 INFO:     Epoch: 41
2023-01-05 03:37:30,185 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39276424050331116, 'Total loss': 0.39276424050331116} | train loss {'Reaction outcome loss': 0.21240747001586013, 'Total loss': 0.21240747001586013}
2023-01-05 03:37:30,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:30,185 INFO:     Epoch: 42
2023-01-05 03:37:32,396 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38167230834563576, 'Total loss': 0.38167230834563576} | train loss {'Reaction outcome loss': 0.2120198644385538, 'Total loss': 0.2120198644385538}
2023-01-05 03:37:32,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:32,397 INFO:     Epoch: 43
2023-01-05 03:37:34,621 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34981067577997843, 'Total loss': 0.34981067577997843} | train loss {'Reaction outcome loss': 0.20801159472399003, 'Total loss': 0.20801159472399003}
2023-01-05 03:37:34,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:34,621 INFO:     Epoch: 44
2023-01-05 03:37:36,856 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38215122669935225, 'Total loss': 0.38215122669935225} | train loss {'Reaction outcome loss': 0.20547146141863146, 'Total loss': 0.20547146141863146}
2023-01-05 03:37:36,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:36,856 INFO:     Epoch: 45
2023-01-05 03:37:39,095 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3791133135557175, 'Total loss': 0.3791133135557175} | train loss {'Reaction outcome loss': 0.20087961342389885, 'Total loss': 0.20087961342389885}
2023-01-05 03:37:39,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:39,096 INFO:     Epoch: 46
2023-01-05 03:37:41,282 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3656899104515711, 'Total loss': 0.3656899104515711} | train loss {'Reaction outcome loss': 0.2034874611392455, 'Total loss': 0.2034874611392455}
2023-01-05 03:37:41,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:41,282 INFO:     Epoch: 47
2023-01-05 03:37:43,515 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3706394791603088, 'Total loss': 0.3706394791603088} | train loss {'Reaction outcome loss': 0.19986422740233442, 'Total loss': 0.19986422740233442}
2023-01-05 03:37:43,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:43,516 INFO:     Epoch: 48
2023-01-05 03:37:45,728 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36993956565856934, 'Total loss': 0.36993956565856934} | train loss {'Reaction outcome loss': 0.19489876834742734, 'Total loss': 0.19489876834742734}
2023-01-05 03:37:45,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:45,728 INFO:     Epoch: 49
2023-01-05 03:37:47,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3362622077266375, 'Total loss': 0.3362622077266375} | train loss {'Reaction outcome loss': 0.20992087320411118, 'Total loss': 0.20992087320411118}
2023-01-05 03:37:47,936 INFO:     Found new best model at epoch 49
2023-01-05 03:37:47,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:47,938 INFO:     Epoch: 50
2023-01-05 03:37:50,132 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4214004629602035, 'Total loss': 0.4214004629602035} | train loss {'Reaction outcome loss': 0.2111131400814739, 'Total loss': 0.2111131400814739}
2023-01-05 03:37:50,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:50,132 INFO:     Epoch: 51
2023-01-05 03:37:52,362 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3878939817349116, 'Total loss': 0.3878939817349116} | train loss {'Reaction outcome loss': 0.19600624971064753, 'Total loss': 0.19600624971064753}
2023-01-05 03:37:52,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:52,363 INFO:     Epoch: 52
2023-01-05 03:37:54,568 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3530632207791011, 'Total loss': 0.3530632207791011} | train loss {'Reaction outcome loss': 0.1983089657796486, 'Total loss': 0.1983089657796486}
2023-01-05 03:37:54,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:54,569 INFO:     Epoch: 53
2023-01-05 03:37:56,746 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3819774294892947, 'Total loss': 0.3819774294892947} | train loss {'Reaction outcome loss': 0.19047482257482826, 'Total loss': 0.19047482257482826}
2023-01-05 03:37:56,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:56,746 INFO:     Epoch: 54
2023-01-05 03:37:58,978 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3645811978727579, 'Total loss': 0.3645811978727579} | train loss {'Reaction outcome loss': 0.18808751857919442, 'Total loss': 0.18808751857919442}
2023-01-05 03:37:58,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:37:58,978 INFO:     Epoch: 55
2023-01-05 03:38:01,126 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36541188061237334, 'Total loss': 0.36541188061237334} | train loss {'Reaction outcome loss': 0.1844544291430477, 'Total loss': 0.1844544291430477}
2023-01-05 03:38:01,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:01,127 INFO:     Epoch: 56
2023-01-05 03:38:03,257 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3742920140425364, 'Total loss': 0.3742920140425364} | train loss {'Reaction outcome loss': 0.18553527374920584, 'Total loss': 0.18553527374920584}
2023-01-05 03:38:03,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:03,257 INFO:     Epoch: 57
2023-01-05 03:38:05,497 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3882920503616333, 'Total loss': 0.3882920503616333} | train loss {'Reaction outcome loss': 0.18349365334828346, 'Total loss': 0.18349365334828346}
2023-01-05 03:38:05,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:05,497 INFO:     Epoch: 58
2023-01-05 03:38:07,689 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42722137918074926, 'Total loss': 0.42722137918074926} | train loss {'Reaction outcome loss': 0.18043232397030806, 'Total loss': 0.18043232397030806}
2023-01-05 03:38:07,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:07,690 INFO:     Epoch: 59
2023-01-05 03:38:09,899 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36714426055550575, 'Total loss': 0.36714426055550575} | train loss {'Reaction outcome loss': 0.181970124915993, 'Total loss': 0.181970124915993}
2023-01-05 03:38:09,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:09,900 INFO:     Epoch: 60
2023-01-05 03:38:12,084 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4066166564822197, 'Total loss': 0.4066166564822197} | train loss {'Reaction outcome loss': 0.18097750440980578, 'Total loss': 0.18097750440980578}
2023-01-05 03:38:12,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:12,085 INFO:     Epoch: 61
2023-01-05 03:38:14,319 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4131533622431258, 'Total loss': 0.4131533622431258} | train loss {'Reaction outcome loss': 0.17620545198155593, 'Total loss': 0.17620545198155593}
2023-01-05 03:38:14,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:14,320 INFO:     Epoch: 62
2023-01-05 03:38:16,553 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39168180227279664, 'Total loss': 0.39168180227279664} | train loss {'Reaction outcome loss': 0.17741732040008504, 'Total loss': 0.17741732040008504}
2023-01-05 03:38:16,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:16,554 INFO:     Epoch: 63
2023-01-05 03:38:18,770 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3854151864846547, 'Total loss': 0.3854151864846547} | train loss {'Reaction outcome loss': 0.18534148821060586, 'Total loss': 0.18534148821060586}
2023-01-05 03:38:18,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:18,771 INFO:     Epoch: 64
2023-01-05 03:38:21,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4277057041724523, 'Total loss': 0.4277057041724523} | train loss {'Reaction outcome loss': 0.188956694355221, 'Total loss': 0.188956694355221}
2023-01-05 03:38:21,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:21,021 INFO:     Epoch: 65
2023-01-05 03:38:23,262 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37477529247601826, 'Total loss': 0.37477529247601826} | train loss {'Reaction outcome loss': 0.17534518400983265, 'Total loss': 0.17534518400983265}
2023-01-05 03:38:23,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:23,262 INFO:     Epoch: 66
2023-01-05 03:38:25,413 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39795592774947486, 'Total loss': 0.39795592774947486} | train loss {'Reaction outcome loss': 0.17584543236205427, 'Total loss': 0.17584543236205427}
2023-01-05 03:38:25,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:25,413 INFO:     Epoch: 67
2023-01-05 03:38:27,658 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37417591717094184, 'Total loss': 0.37417591717094184} | train loss {'Reaction outcome loss': 0.17223573587893887, 'Total loss': 0.17223573587893887}
2023-01-05 03:38:27,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:27,659 INFO:     Epoch: 68
2023-01-05 03:38:29,880 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3833914960424105, 'Total loss': 0.3833914960424105} | train loss {'Reaction outcome loss': 0.16829137268684027, 'Total loss': 0.16829137268684027}
2023-01-05 03:38:29,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:29,880 INFO:     Epoch: 69
2023-01-05 03:38:32,098 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3851594999432564, 'Total loss': 0.3851594999432564} | train loss {'Reaction outcome loss': 0.17422901334551474, 'Total loss': 0.17422901334551474}
2023-01-05 03:38:32,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:32,098 INFO:     Epoch: 70
2023-01-05 03:38:34,312 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37741632759571075, 'Total loss': 0.37741632759571075} | train loss {'Reaction outcome loss': 0.17019418283703946, 'Total loss': 0.17019418283703946}
2023-01-05 03:38:34,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:34,312 INFO:     Epoch: 71
2023-01-05 03:38:36,558 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3573693302770456, 'Total loss': 0.3573693302770456} | train loss {'Reaction outcome loss': 0.16844873150947262, 'Total loss': 0.16844873150947262}
2023-01-05 03:38:36,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:36,558 INFO:     Epoch: 72
2023-01-05 03:38:38,774 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3556568350177258, 'Total loss': 0.3556568350177258} | train loss {'Reaction outcome loss': 0.16848726981710688, 'Total loss': 0.16848726981710688}
2023-01-05 03:38:38,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:38,775 INFO:     Epoch: 73
2023-01-05 03:38:41,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3871362308661143, 'Total loss': 0.3871362308661143} | train loss {'Reaction outcome loss': 0.16940806686450716, 'Total loss': 0.16940806686450716}
2023-01-05 03:38:41,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:41,013 INFO:     Epoch: 74
2023-01-05 03:38:43,208 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39043625071644783, 'Total loss': 0.39043625071644783} | train loss {'Reaction outcome loss': 0.16971494897650014, 'Total loss': 0.16971494897650014}
2023-01-05 03:38:43,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:43,209 INFO:     Epoch: 75
2023-01-05 03:38:45,464 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41910002926985424, 'Total loss': 0.41910002926985424} | train loss {'Reaction outcome loss': 0.16875640487726912, 'Total loss': 0.16875640487726912}
2023-01-05 03:38:45,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:45,465 INFO:     Epoch: 76
2023-01-05 03:38:47,664 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3654688759318863, 'Total loss': 0.3654688759318863} | train loss {'Reaction outcome loss': 0.16635983244539576, 'Total loss': 0.16635983244539576}
2023-01-05 03:38:47,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:47,664 INFO:     Epoch: 77
2023-01-05 03:38:49,828 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4109429160753886, 'Total loss': 0.4109429160753886} | train loss {'Reaction outcome loss': 0.16892781885732236, 'Total loss': 0.16892781885732236}
2023-01-05 03:38:49,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:49,829 INFO:     Epoch: 78
2023-01-05 03:38:52,052 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42150945365428927, 'Total loss': 0.42150945365428927} | train loss {'Reaction outcome loss': 0.1668914064825715, 'Total loss': 0.1668914064825715}
2023-01-05 03:38:52,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:52,052 INFO:     Epoch: 79
2023-01-05 03:38:54,264 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.403473403211683, 'Total loss': 0.403473403211683} | train loss {'Reaction outcome loss': 0.18011415280330845, 'Total loss': 0.18011415280330845}
2023-01-05 03:38:54,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:54,264 INFO:     Epoch: 80
2023-01-05 03:38:56,512 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42121780117352803, 'Total loss': 0.42121780117352803} | train loss {'Reaction outcome loss': 0.1687465123482136, 'Total loss': 0.1687465123482136}
2023-01-05 03:38:56,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:56,512 INFO:     Epoch: 81
2023-01-05 03:38:58,713 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41644433985153834, 'Total loss': 0.41644433985153834} | train loss {'Reaction outcome loss': 0.16439984900795895, 'Total loss': 0.16439984900795895}
2023-01-05 03:38:58,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:38:58,714 INFO:     Epoch: 82
2023-01-05 03:39:00,959 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40164946715037025, 'Total loss': 0.40164946715037025} | train loss {'Reaction outcome loss': 0.16642142345528185, 'Total loss': 0.16642142345528185}
2023-01-05 03:39:00,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:00,960 INFO:     Epoch: 83
2023-01-05 03:39:03,206 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3892364958922068, 'Total loss': 0.3892364958922068} | train loss {'Reaction outcome loss': 0.16395409919061713, 'Total loss': 0.16395409919061713}
2023-01-05 03:39:03,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:03,206 INFO:     Epoch: 84
2023-01-05 03:39:05,413 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4081377605597178, 'Total loss': 0.4081377605597178} | train loss {'Reaction outcome loss': 0.16105835633483156, 'Total loss': 0.16105835633483156}
2023-01-05 03:39:05,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:05,414 INFO:     Epoch: 85
2023-01-05 03:39:07,661 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3743259092171987, 'Total loss': 0.3743259092171987} | train loss {'Reaction outcome loss': 0.15978404705453178, 'Total loss': 0.15978404705453178}
2023-01-05 03:39:07,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:07,661 INFO:     Epoch: 86
2023-01-05 03:39:09,861 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4047903299331665, 'Total loss': 0.4047903299331665} | train loss {'Reaction outcome loss': 0.16424207129866641, 'Total loss': 0.16424207129866641}
2023-01-05 03:39:09,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:09,862 INFO:     Epoch: 87
2023-01-05 03:39:12,097 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4142852157354355, 'Total loss': 0.4142852157354355} | train loss {'Reaction outcome loss': 0.15995760396649333, 'Total loss': 0.15995760396649333}
2023-01-05 03:39:12,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:12,097 INFO:     Epoch: 88
2023-01-05 03:39:14,348 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3928383350372314, 'Total loss': 0.3928383350372314} | train loss {'Reaction outcome loss': 0.16213484462924246, 'Total loss': 0.16213484462924246}
2023-01-05 03:39:14,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:14,348 INFO:     Epoch: 89
2023-01-05 03:39:16,522 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4032940258582433, 'Total loss': 0.4032940258582433} | train loss {'Reaction outcome loss': 0.1689999154163609, 'Total loss': 0.1689999154163609}
2023-01-05 03:39:16,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:16,524 INFO:     Epoch: 90
2023-01-05 03:39:18,705 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39680687089761096, 'Total loss': 0.39680687089761096} | train loss {'Reaction outcome loss': 0.15629147934111934, 'Total loss': 0.15629147934111934}
2023-01-05 03:39:18,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:18,705 INFO:     Epoch: 91
2023-01-05 03:39:20,873 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4294179379940033, 'Total loss': 0.4294179379940033} | train loss {'Reaction outcome loss': 0.1542893187176652, 'Total loss': 0.1542893187176652}
2023-01-05 03:39:20,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:20,873 INFO:     Epoch: 92
2023-01-05 03:39:23,095 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4221800277630488, 'Total loss': 0.4221800277630488} | train loss {'Reaction outcome loss': 0.15691943206228895, 'Total loss': 0.15691943206228895}
2023-01-05 03:39:23,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:23,096 INFO:     Epoch: 93
2023-01-05 03:39:25,251 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4431272159020106, 'Total loss': 0.4431272159020106} | train loss {'Reaction outcome loss': 0.15437543526981692, 'Total loss': 0.15437543526981692}
2023-01-05 03:39:25,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:25,251 INFO:     Epoch: 94
2023-01-05 03:39:27,494 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39225969314575193, 'Total loss': 0.39225969314575193} | train loss {'Reaction outcome loss': 0.16126059424267083, 'Total loss': 0.16126059424267083}
2023-01-05 03:39:27,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:27,495 INFO:     Epoch: 95
2023-01-05 03:39:29,649 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3873652535180251, 'Total loss': 0.3873652535180251} | train loss {'Reaction outcome loss': 0.15388417877577434, 'Total loss': 0.15388417877577434}
2023-01-05 03:39:29,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:29,649 INFO:     Epoch: 96
2023-01-05 03:39:31,879 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3779286960760752, 'Total loss': 0.3779286960760752} | train loss {'Reaction outcome loss': 0.15436239414607963, 'Total loss': 0.15436239414607963}
2023-01-05 03:39:31,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:31,879 INFO:     Epoch: 97
2023-01-05 03:39:34,096 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3830307831366857, 'Total loss': 0.3830307831366857} | train loss {'Reaction outcome loss': 0.1553249345540636, 'Total loss': 0.1553249345540636}
2023-01-05 03:39:34,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:34,096 INFO:     Epoch: 98
2023-01-05 03:39:36,342 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3929528425137202, 'Total loss': 0.3929528425137202} | train loss {'Reaction outcome loss': 0.1614267238824075, 'Total loss': 0.1614267238824075}
2023-01-05 03:39:36,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:36,343 INFO:     Epoch: 99
2023-01-05 03:39:38,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4207538266976674, 'Total loss': 0.4207538266976674} | train loss {'Reaction outcome loss': 0.15624579756378965, 'Total loss': 0.15624579756378965}
2023-01-05 03:39:38,581 INFO:     Best model found after epoch 50 of 100.
2023-01-05 03:39:38,581 INFO:   Done with stage: TRAINING
2023-01-05 03:39:38,581 INFO:   Starting stage: EVALUATION
2023-01-05 03:39:38,712 INFO:   Done with stage: EVALUATION
2023-01-05 03:39:38,713 INFO:   Leaving out SEQ value Fold_5
2023-01-05 03:39:38,725 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 03:39:38,725 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:39:39,358 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:39:39,358 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:39:39,427 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:39:39,427 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:39:39,427 INFO:     No hyperparam tuning for this model
2023-01-05 03:39:39,427 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:39:39,427 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:39:39,428 INFO:     None feature selector for col prot
2023-01-05 03:39:39,428 INFO:     None feature selector for col prot
2023-01-05 03:39:39,428 INFO:     None feature selector for col prot
2023-01-05 03:39:39,429 INFO:     None feature selector for col chem
2023-01-05 03:39:39,429 INFO:     None feature selector for col chem
2023-01-05 03:39:39,429 INFO:     None feature selector for col chem
2023-01-05 03:39:39,429 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:39:39,429 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:39:39,430 INFO:     Number of params in model 72931
2023-01-05 03:39:39,433 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:39:39,434 INFO:   Starting stage: TRAINING
2023-01-05 03:39:39,491 INFO:     Val loss before train {'Reaction outcome loss': 0.9197912633419036, 'Total loss': 0.9197912633419036}
2023-01-05 03:39:39,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:39,491 INFO:     Epoch: 0
2023-01-05 03:39:41,623 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7432595034440358, 'Total loss': 0.7432595034440358} | train loss {'Reaction outcome loss': 0.9390025899513533, 'Total loss': 0.9390025899513533}
2023-01-05 03:39:41,623 INFO:     Found new best model at epoch 0
2023-01-05 03:39:41,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:41,624 INFO:     Epoch: 1
2023-01-05 03:39:43,880 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5687504688898722, 'Total loss': 0.5687504688898722} | train loss {'Reaction outcome loss': 0.6303169774664868, 'Total loss': 0.6303169774664868}
2023-01-05 03:39:43,881 INFO:     Found new best model at epoch 1
2023-01-05 03:39:43,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:43,882 INFO:     Epoch: 2
2023-01-05 03:39:46,142 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5593848645687103, 'Total loss': 0.5593848645687103} | train loss {'Reaction outcome loss': 0.5340097845676574, 'Total loss': 0.5340097845676574}
2023-01-05 03:39:46,143 INFO:     Found new best model at epoch 2
2023-01-05 03:39:46,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:46,144 INFO:     Epoch: 3
2023-01-05 03:39:48,298 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5700537492831548, 'Total loss': 0.5700537492831548} | train loss {'Reaction outcome loss': 0.49570576518451265, 'Total loss': 0.49570576518451265}
2023-01-05 03:39:48,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:48,298 INFO:     Epoch: 4
2023-01-05 03:39:50,496 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5528358817100525, 'Total loss': 0.5528358817100525} | train loss {'Reaction outcome loss': 0.46824309875388437, 'Total loss': 0.46824309875388437}
2023-01-05 03:39:50,496 INFO:     Found new best model at epoch 4
2023-01-05 03:39:50,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:50,497 INFO:     Epoch: 5
2023-01-05 03:39:52,670 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.552817024787267, 'Total loss': 0.552817024787267} | train loss {'Reaction outcome loss': 0.44461105032302844, 'Total loss': 0.44461105032302844}
2023-01-05 03:39:52,671 INFO:     Found new best model at epoch 5
2023-01-05 03:39:52,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:52,672 INFO:     Epoch: 6
2023-01-05 03:39:54,878 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5109208345413208, 'Total loss': 0.5109208345413208} | train loss {'Reaction outcome loss': 0.42450808351758584, 'Total loss': 0.42450808351758584}
2023-01-05 03:39:54,878 INFO:     Found new best model at epoch 6
2023-01-05 03:39:54,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:54,879 INFO:     Epoch: 7
2023-01-05 03:39:57,105 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.522481640179952, 'Total loss': 0.522481640179952} | train loss {'Reaction outcome loss': 0.4089411252887671, 'Total loss': 0.4089411252887671}
2023-01-05 03:39:57,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:57,105 INFO:     Epoch: 8
2023-01-05 03:39:59,306 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5185597976048787, 'Total loss': 0.5185597976048787} | train loss {'Reaction outcome loss': 0.39438716733713874, 'Total loss': 0.39438716733713874}
2023-01-05 03:39:59,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:39:59,306 INFO:     Epoch: 9
2023-01-05 03:40:01,505 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49976242979367574, 'Total loss': 0.49976242979367574} | train loss {'Reaction outcome loss': 0.3894937873048042, 'Total loss': 0.3894937873048042}
2023-01-05 03:40:01,505 INFO:     Found new best model at epoch 9
2023-01-05 03:40:01,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:01,507 INFO:     Epoch: 10
2023-01-05 03:40:03,673 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4996326526006063, 'Total loss': 0.4996326526006063} | train loss {'Reaction outcome loss': 0.3726804465969977, 'Total loss': 0.3726804465969977}
2023-01-05 03:40:03,673 INFO:     Found new best model at epoch 10
2023-01-05 03:40:03,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:03,674 INFO:     Epoch: 11
2023-01-05 03:40:05,865 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5057889367143313, 'Total loss': 0.5057889367143313} | train loss {'Reaction outcome loss': 0.3626850811152682, 'Total loss': 0.3626850811152682}
2023-01-05 03:40:05,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:05,866 INFO:     Epoch: 12
2023-01-05 03:40:08,073 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5125355859597523, 'Total loss': 0.5125355859597523} | train loss {'Reaction outcome loss': 0.35436580279028373, 'Total loss': 0.35436580279028373}
2023-01-05 03:40:08,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:08,073 INFO:     Epoch: 13
2023-01-05 03:40:10,342 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5382274389266968, 'Total loss': 0.5382274389266968} | train loss {'Reaction outcome loss': 0.3473500701252519, 'Total loss': 0.3473500701252519}
2023-01-05 03:40:10,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:10,342 INFO:     Epoch: 14
2023-01-05 03:40:12,596 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5081102853020032, 'Total loss': 0.5081102853020032} | train loss {'Reaction outcome loss': 0.3413619374594103, 'Total loss': 0.3413619374594103}
2023-01-05 03:40:12,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:12,597 INFO:     Epoch: 15
2023-01-05 03:40:14,800 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5027398347854615, 'Total loss': 0.5027398347854615} | train loss {'Reaction outcome loss': 0.3307031164826684, 'Total loss': 0.3307031164826684}
2023-01-05 03:40:14,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:14,800 INFO:     Epoch: 16
2023-01-05 03:40:17,051 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5234151005744934, 'Total loss': 0.5234151005744934} | train loss {'Reaction outcome loss': 0.32148258369214266, 'Total loss': 0.32148258369214266}
2023-01-05 03:40:17,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:17,051 INFO:     Epoch: 17
2023-01-05 03:40:19,257 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5013812164465586, 'Total loss': 0.5013812164465586} | train loss {'Reaction outcome loss': 0.3149192291127, 'Total loss': 0.3149192291127}
2023-01-05 03:40:19,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:19,257 INFO:     Epoch: 18
2023-01-05 03:40:21,478 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5411618113517761, 'Total loss': 0.5411618113517761} | train loss {'Reaction outcome loss': 0.3115816631687247, 'Total loss': 0.3115816631687247}
2023-01-05 03:40:21,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:21,479 INFO:     Epoch: 19
2023-01-05 03:40:23,692 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5069531182448069, 'Total loss': 0.5069531182448069} | train loss {'Reaction outcome loss': 0.30528112646151967, 'Total loss': 0.30528112646151967}
2023-01-05 03:40:23,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:23,693 INFO:     Epoch: 20
2023-01-05 03:40:25,921 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5255918145179749, 'Total loss': 0.5255918145179749} | train loss {'Reaction outcome loss': 0.29977556552052065, 'Total loss': 0.29977556552052065}
2023-01-05 03:40:25,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:25,921 INFO:     Epoch: 21
2023-01-05 03:40:28,083 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5091364105542501, 'Total loss': 0.5091364105542501} | train loss {'Reaction outcome loss': 0.293740456110196, 'Total loss': 0.293740456110196}
2023-01-05 03:40:28,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:28,084 INFO:     Epoch: 22
2023-01-05 03:40:30,218 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.505288823445638, 'Total loss': 0.505288823445638} | train loss {'Reaction outcome loss': 0.2871599867267514, 'Total loss': 0.2871599867267514}
2023-01-05 03:40:30,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:30,218 INFO:     Epoch: 23
2023-01-05 03:40:32,426 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5371370156606038, 'Total loss': 0.5371370156606038} | train loss {'Reaction outcome loss': 0.2863269872452378, 'Total loss': 0.2863269872452378}
2023-01-05 03:40:32,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:32,427 INFO:     Epoch: 24
2023-01-05 03:40:34,678 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4888700465361277, 'Total loss': 0.4888700465361277} | train loss {'Reaction outcome loss': 0.2805903137052963, 'Total loss': 0.2805903137052963}
2023-01-05 03:40:34,678 INFO:     Found new best model at epoch 24
2023-01-05 03:40:34,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:34,679 INFO:     Epoch: 25
2023-01-05 03:40:36,886 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5518467605113984, 'Total loss': 0.5518467605113984} | train loss {'Reaction outcome loss': 0.2736098148628047, 'Total loss': 0.2736098148628047}
2023-01-05 03:40:36,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:36,886 INFO:     Epoch: 26
2023-01-05 03:40:39,096 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5356571465730667, 'Total loss': 0.5356571465730667} | train loss {'Reaction outcome loss': 0.27362035304334836, 'Total loss': 0.27362035304334836}
2023-01-05 03:40:39,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:39,096 INFO:     Epoch: 27
2023-01-05 03:40:41,327 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5134704391161601, 'Total loss': 0.5134704391161601} | train loss {'Reaction outcome loss': 0.2668053146438263, 'Total loss': 0.2668053146438263}
2023-01-05 03:40:41,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:41,328 INFO:     Epoch: 28
2023-01-05 03:40:43,494 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4903183321158091, 'Total loss': 0.4903183321158091} | train loss {'Reaction outcome loss': 0.2638267417529107, 'Total loss': 0.2638267417529107}
2023-01-05 03:40:43,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:43,495 INFO:     Epoch: 29
2023-01-05 03:40:45,706 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4700201501448949, 'Total loss': 0.4700201501448949} | train loss {'Reaction outcome loss': 0.2635655662966119, 'Total loss': 0.2635655662966119}
2023-01-05 03:40:45,706 INFO:     Found new best model at epoch 29
2023-01-05 03:40:45,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:45,708 INFO:     Epoch: 30
2023-01-05 03:40:47,944 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47300597429275515, 'Total loss': 0.47300597429275515} | train loss {'Reaction outcome loss': 0.2570920958308106, 'Total loss': 0.2570920958308106}
2023-01-05 03:40:47,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:47,945 INFO:     Epoch: 31
2023-01-05 03:40:50,169 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48688494563102724, 'Total loss': 0.48688494563102724} | train loss {'Reaction outcome loss': 0.25407491150961026, 'Total loss': 0.25407491150961026}
2023-01-05 03:40:50,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:50,169 INFO:     Epoch: 32
2023-01-05 03:40:52,433 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46114860773086547, 'Total loss': 0.46114860773086547} | train loss {'Reaction outcome loss': 0.253450197406409, 'Total loss': 0.253450197406409}
2023-01-05 03:40:52,433 INFO:     Found new best model at epoch 32
2023-01-05 03:40:52,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:52,435 INFO:     Epoch: 33
2023-01-05 03:40:54,673 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.516711778442065, 'Total loss': 0.516711778442065} | train loss {'Reaction outcome loss': 0.25041996565939934, 'Total loss': 0.25041996565939934}
2023-01-05 03:40:54,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:54,673 INFO:     Epoch: 34
2023-01-05 03:40:56,925 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5070239285628001, 'Total loss': 0.5070239285628001} | train loss {'Reaction outcome loss': 0.24765294862554715, 'Total loss': 0.24765294862554715}
2023-01-05 03:40:56,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:56,926 INFO:     Epoch: 35
2023-01-05 03:40:59,142 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4873997151851654, 'Total loss': 0.4873997151851654} | train loss {'Reaction outcome loss': 0.24556204904583603, 'Total loss': 0.24556204904583603}
2023-01-05 03:40:59,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:40:59,143 INFO:     Epoch: 36
2023-01-05 03:41:01,373 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5049738407135009, 'Total loss': 0.5049738407135009} | train loss {'Reaction outcome loss': 0.2372794585699209, 'Total loss': 0.2372794585699209}
2023-01-05 03:41:01,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:01,374 INFO:     Epoch: 37
2023-01-05 03:41:03,577 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47611846923828127, 'Total loss': 0.47611846923828127} | train loss {'Reaction outcome loss': 0.23851158268857303, 'Total loss': 0.23851158268857303}
2023-01-05 03:41:03,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:03,577 INFO:     Epoch: 38
2023-01-05 03:41:05,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4705612301826477, 'Total loss': 0.4705612301826477} | train loss {'Reaction outcome loss': 0.23910828560779027, 'Total loss': 0.23910828560779027}
2023-01-05 03:41:05,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:05,806 INFO:     Epoch: 39
2023-01-05 03:41:08,012 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5059138000011444, 'Total loss': 0.5059138000011444} | train loss {'Reaction outcome loss': 0.2318278518858423, 'Total loss': 0.2318278518858423}
2023-01-05 03:41:08,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:08,013 INFO:     Epoch: 40
2023-01-05 03:41:10,255 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.50287171403567, 'Total loss': 0.50287171403567} | train loss {'Reaction outcome loss': 0.22970222954769426, 'Total loss': 0.22970222954769426}
2023-01-05 03:41:10,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:10,256 INFO:     Epoch: 41
2023-01-05 03:41:12,447 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4827945907910665, 'Total loss': 0.4827945907910665} | train loss {'Reaction outcome loss': 0.2357076408092726, 'Total loss': 0.2357076408092726}
2023-01-05 03:41:12,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:12,448 INFO:     Epoch: 42
2023-01-05 03:41:14,686 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4961856265862783, 'Total loss': 0.4961856265862783} | train loss {'Reaction outcome loss': 0.22469529367324353, 'Total loss': 0.22469529367324353}
2023-01-05 03:41:14,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:14,686 INFO:     Epoch: 43
2023-01-05 03:41:16,927 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48590198953946434, 'Total loss': 0.48590198953946434} | train loss {'Reaction outcome loss': 0.225168562487494, 'Total loss': 0.225168562487494}
2023-01-05 03:41:16,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:16,927 INFO:     Epoch: 44
2023-01-05 03:41:19,184 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48513100246588386, 'Total loss': 0.48513100246588386} | train loss {'Reaction outcome loss': 0.22491988521203776, 'Total loss': 0.22491988521203776}
2023-01-05 03:41:19,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:19,184 INFO:     Epoch: 45
2023-01-05 03:41:21,405 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4882249981164932, 'Total loss': 0.4882249981164932} | train loss {'Reaction outcome loss': 0.21894259326536517, 'Total loss': 0.21894259326536517}
2023-01-05 03:41:21,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:21,406 INFO:     Epoch: 46
2023-01-05 03:41:23,551 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5227924863497416, 'Total loss': 0.5227924863497416} | train loss {'Reaction outcome loss': 0.21847016980958975, 'Total loss': 0.21847016980958975}
2023-01-05 03:41:23,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:23,552 INFO:     Epoch: 47
2023-01-05 03:41:25,773 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.460100128253301, 'Total loss': 0.460100128253301} | train loss {'Reaction outcome loss': 0.2179000221448362, 'Total loss': 0.2179000221448362}
2023-01-05 03:41:25,773 INFO:     Found new best model at epoch 47
2023-01-05 03:41:25,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:25,774 INFO:     Epoch: 48
2023-01-05 03:41:27,972 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4830798675616582, 'Total loss': 0.4830798675616582} | train loss {'Reaction outcome loss': 0.22016082077357743, 'Total loss': 0.22016082077357743}
2023-01-05 03:41:27,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:27,972 INFO:     Epoch: 49
2023-01-05 03:41:30,187 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4954572359720866, 'Total loss': 0.4954572359720866} | train loss {'Reaction outcome loss': 0.21720912090304312, 'Total loss': 0.21720912090304312}
2023-01-05 03:41:30,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:30,187 INFO:     Epoch: 50
2023-01-05 03:41:32,382 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49949030180772147, 'Total loss': 0.49949030180772147} | train loss {'Reaction outcome loss': 0.21476315633672885, 'Total loss': 0.21476315633672885}
2023-01-05 03:41:32,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:32,382 INFO:     Epoch: 51
2023-01-05 03:41:34,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4999729176362356, 'Total loss': 0.4999729176362356} | train loss {'Reaction outcome loss': 0.20950270441465, 'Total loss': 0.20950270441465}
2023-01-05 03:41:34,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:34,636 INFO:     Epoch: 52
2023-01-05 03:41:36,863 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47690638278921443, 'Total loss': 0.47690638278921443} | train loss {'Reaction outcome loss': 0.21518839527230832, 'Total loss': 0.21518839527230832}
2023-01-05 03:41:36,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:36,864 INFO:     Epoch: 53
2023-01-05 03:41:39,112 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4780933161576589, 'Total loss': 0.4780933161576589} | train loss {'Reaction outcome loss': 0.20872109502701874, 'Total loss': 0.20872109502701874}
2023-01-05 03:41:39,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:39,112 INFO:     Epoch: 54
2023-01-05 03:41:41,372 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4884048730134964, 'Total loss': 0.4884048730134964} | train loss {'Reaction outcome loss': 0.21285375456799777, 'Total loss': 0.21285375456799777}
2023-01-05 03:41:41,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:41,373 INFO:     Epoch: 55
2023-01-05 03:41:43,604 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4776867975791295, 'Total loss': 0.4776867975791295} | train loss {'Reaction outcome loss': 0.20915047015443392, 'Total loss': 0.20915047015443392}
2023-01-05 03:41:43,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:43,604 INFO:     Epoch: 56
2023-01-05 03:41:45,862 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5229255159695944, 'Total loss': 0.5229255159695944} | train loss {'Reaction outcome loss': 0.2020284035243094, 'Total loss': 0.2020284035243094}
2023-01-05 03:41:45,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:45,862 INFO:     Epoch: 57
2023-01-05 03:41:48,053 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5054694851239522, 'Total loss': 0.5054694851239522} | train loss {'Reaction outcome loss': 0.2025339007831518, 'Total loss': 0.2025339007831518}
2023-01-05 03:41:48,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:48,053 INFO:     Epoch: 58
2023-01-05 03:41:50,303 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5241550892591477, 'Total loss': 0.5241550892591477} | train loss {'Reaction outcome loss': 0.20601916811109558, 'Total loss': 0.20601916811109558}
2023-01-05 03:41:50,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:50,303 INFO:     Epoch: 59
2023-01-05 03:41:52,580 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5045350184043248, 'Total loss': 0.5045350184043248} | train loss {'Reaction outcome loss': 0.20289651784602056, 'Total loss': 0.20289651784602056}
2023-01-05 03:41:52,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:52,580 INFO:     Epoch: 60
2023-01-05 03:41:54,825 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4774127521862586, 'Total loss': 0.4774127521862586} | train loss {'Reaction outcome loss': 0.20494289747994085, 'Total loss': 0.20494289747994085}
2023-01-05 03:41:54,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:54,826 INFO:     Epoch: 61
2023-01-05 03:41:57,080 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5074624091386795, 'Total loss': 0.5074624091386795} | train loss {'Reaction outcome loss': 0.1983134046765145, 'Total loss': 0.1983134046765145}
2023-01-05 03:41:57,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:57,081 INFO:     Epoch: 62
2023-01-05 03:41:59,322 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5084614038467408, 'Total loss': 0.5084614038467408} | train loss {'Reaction outcome loss': 0.19708026663168243, 'Total loss': 0.19708026663168243}
2023-01-05 03:41:59,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:41:59,322 INFO:     Epoch: 63
2023-01-05 03:42:01,551 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4858051458994547, 'Total loss': 0.4858051458994547} | train loss {'Reaction outcome loss': 0.19228515874540655, 'Total loss': 0.19228515874540655}
2023-01-05 03:42:01,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:01,551 INFO:     Epoch: 64
2023-01-05 03:42:03,724 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4994721293449402, 'Total loss': 0.4994721293449402} | train loss {'Reaction outcome loss': 0.20198276770781953, 'Total loss': 0.20198276770781953}
2023-01-05 03:42:03,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:03,725 INFO:     Epoch: 65
2023-01-05 03:42:05,838 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5138097832600276, 'Total loss': 0.5138097832600276} | train loss {'Reaction outcome loss': 0.19523526278966602, 'Total loss': 0.19523526278966602}
2023-01-05 03:42:05,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:05,838 INFO:     Epoch: 66
2023-01-05 03:42:08,005 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4960052768389384, 'Total loss': 0.4960052768389384} | train loss {'Reaction outcome loss': 0.193111880763101, 'Total loss': 0.193111880763101}
2023-01-05 03:42:08,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:08,006 INFO:     Epoch: 67
2023-01-05 03:42:10,205 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5296186914046606, 'Total loss': 0.5296186914046606} | train loss {'Reaction outcome loss': 0.19142872873787845, 'Total loss': 0.19142872873787845}
2023-01-05 03:42:10,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:10,206 INFO:     Epoch: 68
2023-01-05 03:42:12,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5339085300763448, 'Total loss': 0.5339085300763448} | train loss {'Reaction outcome loss': 0.1939262363703296, 'Total loss': 0.1939262363703296}
2023-01-05 03:42:12,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:12,432 INFO:     Epoch: 69
2023-01-05 03:42:14,622 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5107942471901575, 'Total loss': 0.5107942471901575} | train loss {'Reaction outcome loss': 0.18532173901742546, 'Total loss': 0.18532173901742546}
2023-01-05 03:42:14,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:14,622 INFO:     Epoch: 70
2023-01-05 03:42:16,876 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5641100724538167, 'Total loss': 0.5641100724538167} | train loss {'Reaction outcome loss': 0.18557736342806463, 'Total loss': 0.18557736342806463}
2023-01-05 03:42:16,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:16,876 INFO:     Epoch: 71
2023-01-05 03:42:19,111 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5234515726566314, 'Total loss': 0.5234515726566314} | train loss {'Reaction outcome loss': 0.1899371066480364, 'Total loss': 0.1899371066480364}
2023-01-05 03:42:19,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:19,111 INFO:     Epoch: 72
2023-01-05 03:42:21,326 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5269035577774048, 'Total loss': 0.5269035577774048} | train loss {'Reaction outcome loss': 0.18902639148333228, 'Total loss': 0.18902639148333228}
2023-01-05 03:42:21,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:21,326 INFO:     Epoch: 73
2023-01-05 03:42:23,464 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4916654646396637, 'Total loss': 0.4916654646396637} | train loss {'Reaction outcome loss': 0.18985146965952557, 'Total loss': 0.18985146965952557}
2023-01-05 03:42:23,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:23,465 INFO:     Epoch: 74
2023-01-05 03:42:25,618 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5245415608088175, 'Total loss': 0.5245415608088175} | train loss {'Reaction outcome loss': 0.1863124075745794, 'Total loss': 0.1863124075745794}
2023-01-05 03:42:25,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:25,618 INFO:     Epoch: 75
2023-01-05 03:42:27,851 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4911108613014221, 'Total loss': 0.4911108613014221} | train loss {'Reaction outcome loss': 0.1819025703087207, 'Total loss': 0.1819025703087207}
2023-01-05 03:42:27,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:27,851 INFO:     Epoch: 76
2023-01-05 03:42:30,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5176592101653417, 'Total loss': 0.5176592101653417} | train loss {'Reaction outcome loss': 0.18182582246637247, 'Total loss': 0.18182582246637247}
2023-01-05 03:42:30,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:30,100 INFO:     Epoch: 77
2023-01-05 03:42:32,317 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5474810580412547, 'Total loss': 0.5474810580412547} | train loss {'Reaction outcome loss': 0.18008501771904717, 'Total loss': 0.18008501771904717}
2023-01-05 03:42:32,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:32,318 INFO:     Epoch: 78
2023-01-05 03:42:34,504 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5387346914658944, 'Total loss': 0.5387346914658944} | train loss {'Reaction outcome loss': 0.18322825672891704, 'Total loss': 0.18322825672891704}
2023-01-05 03:42:34,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:34,505 INFO:     Epoch: 79
2023-01-05 03:42:36,737 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5224668716390928, 'Total loss': 0.5224668716390928} | train loss {'Reaction outcome loss': 0.1771381631987808, 'Total loss': 0.1771381631987808}
2023-01-05 03:42:36,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:36,738 INFO:     Epoch: 80
2023-01-05 03:42:38,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5158719629049301, 'Total loss': 0.5158719629049301} | train loss {'Reaction outcome loss': 0.1815971338395231, 'Total loss': 0.1815971338395231}
2023-01-05 03:42:38,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:38,969 INFO:     Epoch: 81
2023-01-05 03:42:41,209 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5178820063670476, 'Total loss': 0.5178820063670476} | train loss {'Reaction outcome loss': 0.1854536775533204, 'Total loss': 0.1854536775533204}
2023-01-05 03:42:41,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:41,210 INFO:     Epoch: 82
2023-01-05 03:42:43,422 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5262514889240265, 'Total loss': 0.5262514889240265} | train loss {'Reaction outcome loss': 0.17913339084639662, 'Total loss': 0.17913339084639662}
2023-01-05 03:42:43,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:43,422 INFO:     Epoch: 83
2023-01-05 03:42:45,658 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5279658317565918, 'Total loss': 0.5279658317565918} | train loss {'Reaction outcome loss': 0.18009479675737852, 'Total loss': 0.18009479675737852}
2023-01-05 03:42:45,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:45,658 INFO:     Epoch: 84
2023-01-05 03:42:47,871 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5286589344342549, 'Total loss': 0.5286589344342549} | train loss {'Reaction outcome loss': 0.17692940882558428, 'Total loss': 0.17692940882558428}
2023-01-05 03:42:47,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:47,872 INFO:     Epoch: 85
2023-01-05 03:42:50,107 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5075330326954524, 'Total loss': 0.5075330326954524} | train loss {'Reaction outcome loss': 0.1742505837931207, 'Total loss': 0.1742505837931207}
2023-01-05 03:42:50,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:50,107 INFO:     Epoch: 86
2023-01-05 03:42:52,339 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5301997907459736, 'Total loss': 0.5301997907459736} | train loss {'Reaction outcome loss': 0.17441284392593892, 'Total loss': 0.17441284392593892}
2023-01-05 03:42:52,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:52,339 INFO:     Epoch: 87
2023-01-05 03:42:54,599 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5146727393070857, 'Total loss': 0.5146727393070857} | train loss {'Reaction outcome loss': 0.17750405336625955, 'Total loss': 0.17750405336625955}
2023-01-05 03:42:54,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:54,599 INFO:     Epoch: 88
2023-01-05 03:42:56,824 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5390476624170939, 'Total loss': 0.5390476624170939} | train loss {'Reaction outcome loss': 0.17578419749978055, 'Total loss': 0.17578419749978055}
2023-01-05 03:42:56,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:56,824 INFO:     Epoch: 89
2023-01-05 03:42:59,058 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.563873502612114, 'Total loss': 0.563873502612114} | train loss {'Reaction outcome loss': 0.17394749695159467, 'Total loss': 0.17394749695159467}
2023-01-05 03:42:59,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:42:59,059 INFO:     Epoch: 90
2023-01-05 03:43:01,286 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5028219282627105, 'Total loss': 0.5028219282627105} | train loss {'Reaction outcome loss': 0.17334222495354148, 'Total loss': 0.17334222495354148}
2023-01-05 03:43:01,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:01,287 INFO:     Epoch: 91
2023-01-05 03:43:03,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5556921660900116, 'Total loss': 0.5556921660900116} | train loss {'Reaction outcome loss': 0.17761067294646793, 'Total loss': 0.17761067294646793}
2023-01-05 03:43:03,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:03,492 INFO:     Epoch: 92
2023-01-05 03:43:05,692 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5434293453892072, 'Total loss': 0.5434293453892072} | train loss {'Reaction outcome loss': 0.17392331843066033, 'Total loss': 0.17392331843066033}
2023-01-05 03:43:05,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:05,692 INFO:     Epoch: 93
2023-01-05 03:43:07,914 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5256711055835088, 'Total loss': 0.5256711055835088} | train loss {'Reaction outcome loss': 0.17279041122093744, 'Total loss': 0.17279041122093744}
2023-01-05 03:43:07,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:07,915 INFO:     Epoch: 94
2023-01-05 03:43:10,108 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.534483794371287, 'Total loss': 0.534483794371287} | train loss {'Reaction outcome loss': 0.1752332163157634, 'Total loss': 0.1752332163157634}
2023-01-05 03:43:10,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:10,109 INFO:     Epoch: 95
2023-01-05 03:43:12,260 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5207327683766683, 'Total loss': 0.5207327683766683} | train loss {'Reaction outcome loss': 0.16811829808316048, 'Total loss': 0.16811829808316048}
2023-01-05 03:43:12,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:12,261 INFO:     Epoch: 96
2023-01-05 03:43:14,491 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.550133087237676, 'Total loss': 0.550133087237676} | train loss {'Reaction outcome loss': 0.17359968979543727, 'Total loss': 0.17359968979543727}
2023-01-05 03:43:14,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:14,492 INFO:     Epoch: 97
2023-01-05 03:43:16,712 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5327774743239085, 'Total loss': 0.5327774743239085} | train loss {'Reaction outcome loss': 0.1703964285787854, 'Total loss': 0.1703964285787854}
2023-01-05 03:43:16,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:16,713 INFO:     Epoch: 98
2023-01-05 03:43:18,960 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5596470415592194, 'Total loss': 0.5596470415592194} | train loss {'Reaction outcome loss': 0.16737932717639428, 'Total loss': 0.16737932717639428}
2023-01-05 03:43:18,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:18,960 INFO:     Epoch: 99
2023-01-05 03:43:21,151 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.540605115890503, 'Total loss': 0.540605115890503} | train loss {'Reaction outcome loss': 0.17187352420338547, 'Total loss': 0.17187352420338547}
2023-01-05 03:43:21,151 INFO:     Best model found after epoch 48 of 100.
2023-01-05 03:43:21,152 INFO:   Done with stage: TRAINING
2023-01-05 03:43:21,152 INFO:   Starting stage: EVALUATION
2023-01-05 03:43:21,278 INFO:   Done with stage: EVALUATION
2023-01-05 03:43:21,278 INFO:   Leaving out SEQ value Fold_6
2023-01-05 03:43:21,290 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 03:43:21,290 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:43:21,931 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:43:21,931 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:43:22,000 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:43:22,000 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:43:22,001 INFO:     No hyperparam tuning for this model
2023-01-05 03:43:22,001 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:43:22,001 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:43:22,001 INFO:     None feature selector for col prot
2023-01-05 03:43:22,001 INFO:     None feature selector for col prot
2023-01-05 03:43:22,002 INFO:     None feature selector for col prot
2023-01-05 03:43:22,002 INFO:     None feature selector for col chem
2023-01-05 03:43:22,002 INFO:     None feature selector for col chem
2023-01-05 03:43:22,002 INFO:     None feature selector for col chem
2023-01-05 03:43:22,002 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:43:22,002 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:43:22,004 INFO:     Number of params in model 72931
2023-01-05 03:43:22,007 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:43:22,007 INFO:   Starting stage: TRAINING
2023-01-05 03:43:22,066 INFO:     Val loss before train {'Reaction outcome loss': 0.9324411114056905, 'Total loss': 0.9324411114056905}
2023-01-05 03:43:22,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:22,066 INFO:     Epoch: 0
2023-01-05 03:43:24,269 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6810576955477396, 'Total loss': 0.6810576955477396} | train loss {'Reaction outcome loss': 0.9220502819825596, 'Total loss': 0.9220502819825596}
2023-01-05 03:43:24,269 INFO:     Found new best model at epoch 0
2023-01-05 03:43:24,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:24,271 INFO:     Epoch: 1
2023-01-05 03:43:26,522 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.566312430302302, 'Total loss': 0.566312430302302} | train loss {'Reaction outcome loss': 0.6085585164787106, 'Total loss': 0.6085585164787106}
2023-01-05 03:43:26,522 INFO:     Found new best model at epoch 1
2023-01-05 03:43:26,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:26,524 INFO:     Epoch: 2
2023-01-05 03:43:28,715 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5376037240028382, 'Total loss': 0.5376037240028382} | train loss {'Reaction outcome loss': 0.5344725692853171, 'Total loss': 0.5344725692853171}
2023-01-05 03:43:28,716 INFO:     Found new best model at epoch 2
2023-01-05 03:43:28,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:28,717 INFO:     Epoch: 3
2023-01-05 03:43:30,949 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5139887819687525, 'Total loss': 0.5139887819687525} | train loss {'Reaction outcome loss': 0.49177430648128045, 'Total loss': 0.49177430648128045}
2023-01-05 03:43:30,949 INFO:     Found new best model at epoch 3
2023-01-05 03:43:30,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:30,951 INFO:     Epoch: 4
2023-01-05 03:43:33,198 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4641831378142039, 'Total loss': 0.4641831378142039} | train loss {'Reaction outcome loss': 0.45933738157206927, 'Total loss': 0.45933738157206927}
2023-01-05 03:43:33,198 INFO:     Found new best model at epoch 4
2023-01-05 03:43:33,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:33,199 INFO:     Epoch: 5
2023-01-05 03:43:35,348 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4586779574553172, 'Total loss': 0.4586779574553172} | train loss {'Reaction outcome loss': 0.4366189962797647, 'Total loss': 0.4366189962797647}
2023-01-05 03:43:35,348 INFO:     Found new best model at epoch 5
2023-01-05 03:43:35,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:35,349 INFO:     Epoch: 6
2023-01-05 03:43:37,614 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4557529091835022, 'Total loss': 0.4557529091835022} | train loss {'Reaction outcome loss': 0.41634864787762776, 'Total loss': 0.41634864787762776}
2023-01-05 03:43:37,614 INFO:     Found new best model at epoch 6
2023-01-05 03:43:37,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:37,616 INFO:     Epoch: 7
2023-01-05 03:43:39,831 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4590088705221812, 'Total loss': 0.4590088705221812} | train loss {'Reaction outcome loss': 0.40077082199525316, 'Total loss': 0.40077082199525316}
2023-01-05 03:43:39,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:39,831 INFO:     Epoch: 8
2023-01-05 03:43:42,025 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43750266879796984, 'Total loss': 0.43750266879796984} | train loss {'Reaction outcome loss': 0.38815853908819414, 'Total loss': 0.38815853908819414}
2023-01-05 03:43:42,025 INFO:     Found new best model at epoch 8
2023-01-05 03:43:42,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:42,026 INFO:     Epoch: 9
2023-01-05 03:43:44,269 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4480900933345159, 'Total loss': 0.4480900933345159} | train loss {'Reaction outcome loss': 0.37579904493980026, 'Total loss': 0.37579904493980026}
2023-01-05 03:43:44,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:44,270 INFO:     Epoch: 10
2023-01-05 03:43:46,512 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4127917061249415, 'Total loss': 0.4127917061249415} | train loss {'Reaction outcome loss': 0.364226358434999, 'Total loss': 0.364226358434999}
2023-01-05 03:43:46,514 INFO:     Found new best model at epoch 10
2023-01-05 03:43:46,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:46,515 INFO:     Epoch: 11
2023-01-05 03:43:48,749 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44105800489584607, 'Total loss': 0.44105800489584607} | train loss {'Reaction outcome loss': 0.35599511853731924, 'Total loss': 0.35599511853731924}
2023-01-05 03:43:48,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:48,749 INFO:     Epoch: 12
2023-01-05 03:43:50,981 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3759636878967285, 'Total loss': 0.3759636878967285} | train loss {'Reaction outcome loss': 0.3519999714642225, 'Total loss': 0.3519999714642225}
2023-01-05 03:43:50,981 INFO:     Found new best model at epoch 12
2023-01-05 03:43:50,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:50,983 INFO:     Epoch: 13
2023-01-05 03:43:53,230 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42494215965271, 'Total loss': 0.42494215965271} | train loss {'Reaction outcome loss': 0.3387325920890815, 'Total loss': 0.3387325920890815}
2023-01-05 03:43:53,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:53,231 INFO:     Epoch: 14
2023-01-05 03:43:55,480 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.407125053803126, 'Total loss': 0.407125053803126} | train loss {'Reaction outcome loss': 0.3345281749909966, 'Total loss': 0.3345281749909966}
2023-01-05 03:43:55,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:55,480 INFO:     Epoch: 15
2023-01-05 03:43:57,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41688165863355003, 'Total loss': 0.41688165863355003} | train loss {'Reaction outcome loss': 0.32463017738145183, 'Total loss': 0.32463017738145183}
2023-01-05 03:43:57,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:57,721 INFO:     Epoch: 16
2023-01-05 03:43:59,972 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40283791720867157, 'Total loss': 0.40283791720867157} | train loss {'Reaction outcome loss': 0.32101626629648655, 'Total loss': 0.32101626629648655}
2023-01-05 03:43:59,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:43:59,972 INFO:     Epoch: 17
2023-01-05 03:44:02,196 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.401190688709418, 'Total loss': 0.401190688709418} | train loss {'Reaction outcome loss': 0.31244243724466664, 'Total loss': 0.31244243724466664}
2023-01-05 03:44:02,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:02,196 INFO:     Epoch: 18
2023-01-05 03:44:04,400 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42082094252109525, 'Total loss': 0.42082094252109525} | train loss {'Reaction outcome loss': 0.30488860139132407, 'Total loss': 0.30488860139132407}
2023-01-05 03:44:04,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:04,401 INFO:     Epoch: 19
2023-01-05 03:44:06,577 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43592026134332024, 'Total loss': 0.43592026134332024} | train loss {'Reaction outcome loss': 0.3032066739073514, 'Total loss': 0.3032066739073514}
2023-01-05 03:44:06,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:06,578 INFO:     Epoch: 20
2023-01-05 03:44:08,777 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4127253522475561, 'Total loss': 0.4127253522475561} | train loss {'Reaction outcome loss': 0.29391607409511233, 'Total loss': 0.29391607409511233}
2023-01-05 03:44:08,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:08,777 INFO:     Epoch: 21
2023-01-05 03:44:10,978 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3875187158584595, 'Total loss': 0.3875187158584595} | train loss {'Reaction outcome loss': 0.2910612033216101, 'Total loss': 0.2910612033216101}
2023-01-05 03:44:10,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:10,979 INFO:     Epoch: 22
2023-01-05 03:44:13,208 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4069542984167735, 'Total loss': 0.4069542984167735} | train loss {'Reaction outcome loss': 0.2840359769021884, 'Total loss': 0.2840359769021884}
2023-01-05 03:44:13,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:13,209 INFO:     Epoch: 23
2023-01-05 03:44:15,436 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40967742204666135, 'Total loss': 0.40967742204666135} | train loss {'Reaction outcome loss': 0.2806624217691835, 'Total loss': 0.2806624217691835}
2023-01-05 03:44:15,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:15,437 INFO:     Epoch: 24
2023-01-05 03:44:17,633 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40656584600607554, 'Total loss': 0.40656584600607554} | train loss {'Reaction outcome loss': 0.27453163703264744, 'Total loss': 0.27453163703264744}
2023-01-05 03:44:17,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:17,633 INFO:     Epoch: 25
2023-01-05 03:44:19,861 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40152027904987336, 'Total loss': 0.40152027904987336} | train loss {'Reaction outcome loss': 0.2696806340871735, 'Total loss': 0.2696806340871735}
2023-01-05 03:44:19,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:19,861 INFO:     Epoch: 26
2023-01-05 03:44:22,104 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4234572112560272, 'Total loss': 0.4234572112560272} | train loss {'Reaction outcome loss': 0.2690350509884125, 'Total loss': 0.2690350509884125}
2023-01-05 03:44:22,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:22,106 INFO:     Epoch: 27
2023-01-05 03:44:24,339 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4098513831694921, 'Total loss': 0.4098513831694921} | train loss {'Reaction outcome loss': 0.26470779963779106, 'Total loss': 0.26470779963779106}
2023-01-05 03:44:24,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:24,339 INFO:     Epoch: 28
2023-01-05 03:44:26,545 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38517027298609413, 'Total loss': 0.38517027298609413} | train loss {'Reaction outcome loss': 0.26356076554728114, 'Total loss': 0.26356076554728114}
2023-01-05 03:44:26,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:26,546 INFO:     Epoch: 29
2023-01-05 03:44:28,781 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42564757764339445, 'Total loss': 0.42564757764339445} | train loss {'Reaction outcome loss': 0.2558548162129812, 'Total loss': 0.2558548162129812}
2023-01-05 03:44:28,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:28,782 INFO:     Epoch: 30
2023-01-05 03:44:31,032 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43296342889467876, 'Total loss': 0.43296342889467876} | train loss {'Reaction outcome loss': 0.25354965598682205, 'Total loss': 0.25354965598682205}
2023-01-05 03:44:31,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:31,033 INFO:     Epoch: 31
2023-01-05 03:44:33,226 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4135339001814524, 'Total loss': 0.4135339001814524} | train loss {'Reaction outcome loss': 0.2465018932388201, 'Total loss': 0.2465018932388201}
2023-01-05 03:44:33,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:33,226 INFO:     Epoch: 32
2023-01-05 03:44:35,463 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4004782785971959, 'Total loss': 0.4004782785971959} | train loss {'Reaction outcome loss': 0.2464955616271668, 'Total loss': 0.2464955616271668}
2023-01-05 03:44:35,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:35,464 INFO:     Epoch: 33
2023-01-05 03:44:37,698 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4138924330472946, 'Total loss': 0.4138924330472946} | train loss {'Reaction outcome loss': 0.24915906801712212, 'Total loss': 0.24915906801712212}
2023-01-05 03:44:37,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:37,698 INFO:     Epoch: 34
2023-01-05 03:44:39,853 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.432490818699201, 'Total loss': 0.432490818699201} | train loss {'Reaction outcome loss': 0.24310591626603034, 'Total loss': 0.24310591626603034}
2023-01-05 03:44:39,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:39,853 INFO:     Epoch: 35
2023-01-05 03:44:42,078 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40495813488960264, 'Total loss': 0.40495813488960264} | train loss {'Reaction outcome loss': 0.23720274355921506, 'Total loss': 0.23720274355921506}
2023-01-05 03:44:42,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:42,079 INFO:     Epoch: 36
2023-01-05 03:44:44,279 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44261316806077955, 'Total loss': 0.44261316806077955} | train loss {'Reaction outcome loss': 0.24128047204727732, 'Total loss': 0.24128047204727732}
2023-01-05 03:44:44,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:44,279 INFO:     Epoch: 37
2023-01-05 03:44:46,423 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4285398026307424, 'Total loss': 0.4285398026307424} | train loss {'Reaction outcome loss': 0.23441299021459228, 'Total loss': 0.23441299021459228}
2023-01-05 03:44:46,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:46,423 INFO:     Epoch: 38
2023-01-05 03:44:48,672 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4169959336519241, 'Total loss': 0.4169959336519241} | train loss {'Reaction outcome loss': 0.2292146489481418, 'Total loss': 0.2292146489481418}
2023-01-05 03:44:48,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:48,672 INFO:     Epoch: 39
2023-01-05 03:44:50,900 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4245809664328893, 'Total loss': 0.4245809664328893} | train loss {'Reaction outcome loss': 0.23108215455221356, 'Total loss': 0.23108215455221356}
2023-01-05 03:44:50,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:50,900 INFO:     Epoch: 40
2023-01-05 03:44:53,138 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4390518516302109, 'Total loss': 0.4390518516302109} | train loss {'Reaction outcome loss': 0.22744029933176532, 'Total loss': 0.22744029933176532}
2023-01-05 03:44:53,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:53,139 INFO:     Epoch: 41
2023-01-05 03:44:55,377 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.438925039768219, 'Total loss': 0.438925039768219} | train loss {'Reaction outcome loss': 0.2226107466817978, 'Total loss': 0.2226107466817978}
2023-01-05 03:44:55,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:55,377 INFO:     Epoch: 42
2023-01-05 03:44:57,645 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43534065584341686, 'Total loss': 0.43534065584341686} | train loss {'Reaction outcome loss': 0.22227470632239046, 'Total loss': 0.22227470632239046}
2023-01-05 03:44:57,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:57,646 INFO:     Epoch: 43
2023-01-05 03:44:59,925 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4346867541472117, 'Total loss': 0.4346867541472117} | train loss {'Reaction outcome loss': 0.2205481793099362, 'Total loss': 0.2205481793099362}
2023-01-05 03:44:59,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:44:59,925 INFO:     Epoch: 44
2023-01-05 03:45:02,180 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42127036054929096, 'Total loss': 0.42127036054929096} | train loss {'Reaction outcome loss': 0.21652849034039767, 'Total loss': 0.21652849034039767}
2023-01-05 03:45:02,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:02,181 INFO:     Epoch: 45
2023-01-05 03:45:04,375 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4229640007019043, 'Total loss': 0.4229640007019043} | train loss {'Reaction outcome loss': 0.21462322556370003, 'Total loss': 0.21462322556370003}
2023-01-05 03:45:04,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:04,376 INFO:     Epoch: 46
2023-01-05 03:45:06,603 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4619631052017212, 'Total loss': 0.4619631052017212} | train loss {'Reaction outcome loss': 0.21395939678316836, 'Total loss': 0.21395939678316836}
2023-01-05 03:45:06,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:06,603 INFO:     Epoch: 47
2023-01-05 03:45:08,858 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44105325837930043, 'Total loss': 0.44105325837930043} | train loss {'Reaction outcome loss': 0.21281537938096462, 'Total loss': 0.21281537938096462}
2023-01-05 03:45:08,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:08,858 INFO:     Epoch: 48
2023-01-05 03:45:11,099 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4305344045162201, 'Total loss': 0.4305344045162201} | train loss {'Reaction outcome loss': 0.21015899563847035, 'Total loss': 0.21015899563847035}
2023-01-05 03:45:11,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:11,100 INFO:     Epoch: 49
2023-01-05 03:45:13,303 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4174895197153091, 'Total loss': 0.4174895197153091} | train loss {'Reaction outcome loss': 0.20955611234160967, 'Total loss': 0.20955611234160967}
2023-01-05 03:45:13,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:13,303 INFO:     Epoch: 50
2023-01-05 03:45:15,515 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43217267096042633, 'Total loss': 0.43217267096042633} | train loss {'Reaction outcome loss': 0.20879235216466852, 'Total loss': 0.20879235216466852}
2023-01-05 03:45:15,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:15,515 INFO:     Epoch: 51
2023-01-05 03:45:17,729 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42753286361694337, 'Total loss': 0.42753286361694337} | train loss {'Reaction outcome loss': 0.19941697288842516, 'Total loss': 0.19941697288842516}
2023-01-05 03:45:17,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:17,730 INFO:     Epoch: 52
2023-01-05 03:45:19,946 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4093103691935539, 'Total loss': 0.4093103691935539} | train loss {'Reaction outcome loss': 0.20999319131220506, 'Total loss': 0.20999319131220506}
2023-01-05 03:45:19,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:19,947 INFO:     Epoch: 53
2023-01-05 03:45:22,187 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44778325061003366, 'Total loss': 0.44778325061003366} | train loss {'Reaction outcome loss': 0.20180642446133204, 'Total loss': 0.20180642446133204}
2023-01-05 03:45:22,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:22,187 INFO:     Epoch: 54
2023-01-05 03:45:24,394 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41743072072664894, 'Total loss': 0.41743072072664894} | train loss {'Reaction outcome loss': 0.20411830786144905, 'Total loss': 0.20411830786144905}
2023-01-05 03:45:24,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:24,394 INFO:     Epoch: 55
2023-01-05 03:45:26,624 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4386945014198621, 'Total loss': 0.4386945014198621} | train loss {'Reaction outcome loss': 0.2006537197224984, 'Total loss': 0.2006537197224984}
2023-01-05 03:45:26,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:26,625 INFO:     Epoch: 56
2023-01-05 03:45:28,878 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4343082199494044, 'Total loss': 0.4343082199494044} | train loss {'Reaction outcome loss': 0.20385295048772967, 'Total loss': 0.20385295048772967}
2023-01-05 03:45:28,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:28,879 INFO:     Epoch: 57
2023-01-05 03:45:31,111 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44887673258781435, 'Total loss': 0.44887673258781435} | train loss {'Reaction outcome loss': 0.20056931174188744, 'Total loss': 0.20056931174188744}
2023-01-05 03:45:31,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:31,112 INFO:     Epoch: 58
2023-01-05 03:45:33,273 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44063648382822673, 'Total loss': 0.44063648382822673} | train loss {'Reaction outcome loss': 0.19916507554331303, 'Total loss': 0.19916507554331303}
2023-01-05 03:45:33,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:33,273 INFO:     Epoch: 59
2023-01-05 03:45:35,510 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4703246037165324, 'Total loss': 0.4703246037165324} | train loss {'Reaction outcome loss': 0.19960311417289697, 'Total loss': 0.19960311417289697}
2023-01-05 03:45:35,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:35,511 INFO:     Epoch: 60
2023-01-05 03:45:37,751 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48574791351954144, 'Total loss': 0.48574791351954144} | train loss {'Reaction outcome loss': 0.19515058559463075, 'Total loss': 0.19515058559463075}
2023-01-05 03:45:37,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:37,752 INFO:     Epoch: 61
2023-01-05 03:45:39,950 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.438981839021047, 'Total loss': 0.438981839021047} | train loss {'Reaction outcome loss': 0.19657585441070988, 'Total loss': 0.19657585441070988}
2023-01-05 03:45:39,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:39,950 INFO:     Epoch: 62
2023-01-05 03:45:42,131 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4442555089791616, 'Total loss': 0.4442555089791616} | train loss {'Reaction outcome loss': 0.1902531057525601, 'Total loss': 0.1902531057525601}
2023-01-05 03:45:42,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:42,131 INFO:     Epoch: 63
2023-01-05 03:45:44,318 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4456979811191559, 'Total loss': 0.4456979811191559} | train loss {'Reaction outcome loss': 0.1982594686409035, 'Total loss': 0.1982594686409035}
2023-01-05 03:45:44,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:44,319 INFO:     Epoch: 64
2023-01-05 03:45:46,555 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.444399439295133, 'Total loss': 0.444399439295133} | train loss {'Reaction outcome loss': 0.19087623014696453, 'Total loss': 0.19087623014696453}
2023-01-05 03:45:46,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:46,555 INFO:     Epoch: 65
2023-01-05 03:45:48,810 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4164873460928599, 'Total loss': 0.4164873460928599} | train loss {'Reaction outcome loss': 0.19299371192561268, 'Total loss': 0.19299371192561268}
2023-01-05 03:45:48,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:48,810 INFO:     Epoch: 66
2023-01-05 03:45:51,043 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46687657038370767, 'Total loss': 0.46687657038370767} | train loss {'Reaction outcome loss': 0.18706617899750114, 'Total loss': 0.18706617899750114}
2023-01-05 03:45:51,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:51,043 INFO:     Epoch: 67
2023-01-05 03:45:53,260 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42215049962202705, 'Total loss': 0.42215049962202705} | train loss {'Reaction outcome loss': 0.1915111574899096, 'Total loss': 0.1915111574899096}
2023-01-05 03:45:53,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:53,260 INFO:     Epoch: 68
2023-01-05 03:45:55,512 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48417488038539885, 'Total loss': 0.48417488038539885} | train loss {'Reaction outcome loss': 0.1942193391010004, 'Total loss': 0.1942193391010004}
2023-01-05 03:45:55,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:55,513 INFO:     Epoch: 69
2023-01-05 03:45:57,762 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43786050379276276, 'Total loss': 0.43786050379276276} | train loss {'Reaction outcome loss': 0.19160864395274368, 'Total loss': 0.19160864395274368}
2023-01-05 03:45:57,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:45:57,762 INFO:     Epoch: 70
2023-01-05 03:46:00,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4208020860950152, 'Total loss': 0.4208020860950152} | train loss {'Reaction outcome loss': 0.18826947750906975, 'Total loss': 0.18826947750906975}
2023-01-05 03:46:00,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:00,006 INFO:     Epoch: 71
2023-01-05 03:46:02,246 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45250308364629743, 'Total loss': 0.45250308364629743} | train loss {'Reaction outcome loss': 0.1829668080756972, 'Total loss': 0.1829668080756972}
2023-01-05 03:46:02,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:02,247 INFO:     Epoch: 72
2023-01-05 03:46:04,408 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.458050270875295, 'Total loss': 0.458050270875295} | train loss {'Reaction outcome loss': 0.1813942220109088, 'Total loss': 0.1813942220109088}
2023-01-05 03:46:04,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:04,410 INFO:     Epoch: 73
2023-01-05 03:46:06,640 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43170858547091484, 'Total loss': 0.43170858547091484} | train loss {'Reaction outcome loss': 0.18887914142097323, 'Total loss': 0.18887914142097323}
2023-01-05 03:46:06,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:06,641 INFO:     Epoch: 74
2023-01-05 03:46:08,863 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43593667844931283, 'Total loss': 0.43593667844931283} | train loss {'Reaction outcome loss': 0.18325486232187022, 'Total loss': 0.18325486232187022}
2023-01-05 03:46:08,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:08,863 INFO:     Epoch: 75
2023-01-05 03:46:10,922 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40484985932707784, 'Total loss': 0.40484985932707784} | train loss {'Reaction outcome loss': 0.1802819454151505, 'Total loss': 0.1802819454151505}
2023-01-05 03:46:10,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:10,923 INFO:     Epoch: 76
2023-01-05 03:46:13,168 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41942130227883656, 'Total loss': 0.41942130227883656} | train loss {'Reaction outcome loss': 0.18422160426235426, 'Total loss': 0.18422160426235426}
2023-01-05 03:46:13,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:13,168 INFO:     Epoch: 77
2023-01-05 03:46:15,401 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42781800727049507, 'Total loss': 0.42781800727049507} | train loss {'Reaction outcome loss': 0.1772784907202697, 'Total loss': 0.1772784907202697}
2023-01-05 03:46:15,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:15,401 INFO:     Epoch: 78
2023-01-05 03:46:17,622 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43785347044467926, 'Total loss': 0.43785347044467926} | train loss {'Reaction outcome loss': 0.17971804452596052, 'Total loss': 0.17971804452596052}
2023-01-05 03:46:17,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:17,623 INFO:     Epoch: 79
2023-01-05 03:46:19,890 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4353140672047933, 'Total loss': 0.4353140672047933} | train loss {'Reaction outcome loss': 0.18388282875816206, 'Total loss': 0.18388282875816206}
2023-01-05 03:46:19,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:19,890 INFO:     Epoch: 80
2023-01-05 03:46:22,163 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45408195157845815, 'Total loss': 0.45408195157845815} | train loss {'Reaction outcome loss': 0.17718361891698536, 'Total loss': 0.17718361891698536}
2023-01-05 03:46:22,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:22,163 INFO:     Epoch: 81
2023-01-05 03:46:24,412 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43532962203025816, 'Total loss': 0.43532962203025816} | train loss {'Reaction outcome loss': 0.17560223952298884, 'Total loss': 0.17560223952298884}
2023-01-05 03:46:24,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:24,413 INFO:     Epoch: 82
2023-01-05 03:46:26,683 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43412925203641256, 'Total loss': 0.43412925203641256} | train loss {'Reaction outcome loss': 0.17969137319911688, 'Total loss': 0.17969137319911688}
2023-01-05 03:46:26,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:26,684 INFO:     Epoch: 83
2023-01-05 03:46:28,941 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4429662346839905, 'Total loss': 0.4429662346839905} | train loss {'Reaction outcome loss': 0.18022861804086918, 'Total loss': 0.18022861804086918}
2023-01-05 03:46:28,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:28,941 INFO:     Epoch: 84
2023-01-05 03:46:31,203 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43920344511667886, 'Total loss': 0.43920344511667886} | train loss {'Reaction outcome loss': 0.1796684414635846, 'Total loss': 0.1796684414635846}
2023-01-05 03:46:31,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:31,203 INFO:     Epoch: 85
2023-01-05 03:46:33,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40427447855472565, 'Total loss': 0.40427447855472565} | train loss {'Reaction outcome loss': 0.18040372986289327, 'Total loss': 0.18040372986289327}
2023-01-05 03:46:33,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:33,463 INFO:     Epoch: 86
2023-01-05 03:46:35,713 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4219892680644989, 'Total loss': 0.4219892680644989} | train loss {'Reaction outcome loss': 0.17874026827561243, 'Total loss': 0.17874026827561243}
2023-01-05 03:46:35,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:35,713 INFO:     Epoch: 87
2023-01-05 03:46:37,907 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4169934877504905, 'Total loss': 0.4169934877504905} | train loss {'Reaction outcome loss': 0.175144143355506, 'Total loss': 0.175144143355506}
2023-01-05 03:46:37,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:37,907 INFO:     Epoch: 88
2023-01-05 03:46:40,122 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.449385067820549, 'Total loss': 0.449385067820549} | train loss {'Reaction outcome loss': 0.1804313965037546, 'Total loss': 0.1804313965037546}
2023-01-05 03:46:40,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:40,123 INFO:     Epoch: 89
2023-01-05 03:46:42,328 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46218135555585227, 'Total loss': 0.46218135555585227} | train loss {'Reaction outcome loss': 0.17797351800349107, 'Total loss': 0.17797351800349107}
2023-01-05 03:46:42,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:42,328 INFO:     Epoch: 90
2023-01-05 03:46:44,556 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44691209495067596, 'Total loss': 0.44691209495067596} | train loss {'Reaction outcome loss': 0.17050683262694075, 'Total loss': 0.17050683262694075}
2023-01-05 03:46:44,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:44,556 INFO:     Epoch: 91
2023-01-05 03:46:46,729 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4538794363538424, 'Total loss': 0.4538794363538424} | train loss {'Reaction outcome loss': 0.17068497258631868, 'Total loss': 0.17068497258631868}
2023-01-05 03:46:46,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:46,730 INFO:     Epoch: 92
2023-01-05 03:46:48,954 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4271489734450976, 'Total loss': 0.4271489734450976} | train loss {'Reaction outcome loss': 0.17392435801528153, 'Total loss': 0.17392435801528153}
2023-01-05 03:46:48,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:48,954 INFO:     Epoch: 93
2023-01-05 03:46:51,209 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4466716816027959, 'Total loss': 0.4466716816027959} | train loss {'Reaction outcome loss': 0.17340293348790398, 'Total loss': 0.17340293348790398}
2023-01-05 03:46:51,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:51,210 INFO:     Epoch: 94
2023-01-05 03:46:53,427 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4369329258799553, 'Total loss': 0.4369329258799553} | train loss {'Reaction outcome loss': 0.17064869085609213, 'Total loss': 0.17064869085609213}
2023-01-05 03:46:53,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:53,428 INFO:     Epoch: 95
2023-01-05 03:46:55,684 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4717290793855985, 'Total loss': 0.4717290793855985} | train loss {'Reaction outcome loss': 0.17115650061578472, 'Total loss': 0.17115650061578472}
2023-01-05 03:46:55,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:55,685 INFO:     Epoch: 96
2023-01-05 03:46:57,923 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4042755420009295, 'Total loss': 0.4042755420009295} | train loss {'Reaction outcome loss': 0.16749546901299367, 'Total loss': 0.16749546901299367}
2023-01-05 03:46:57,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:46:57,923 INFO:     Epoch: 97
2023-01-05 03:47:00,153 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4168605198462804, 'Total loss': 0.4168605198462804} | train loss {'Reaction outcome loss': 0.17107146071095275, 'Total loss': 0.17107146071095275}
2023-01-05 03:47:00,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:00,154 INFO:     Epoch: 98
2023-01-05 03:47:02,399 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4447223941485087, 'Total loss': 0.4447223941485087} | train loss {'Reaction outcome loss': 0.16742648756373607, 'Total loss': 0.16742648756373607}
2023-01-05 03:47:02,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:02,399 INFO:     Epoch: 99
2023-01-05 03:47:04,645 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43932376950979235, 'Total loss': 0.43932376950979235} | train loss {'Reaction outcome loss': 0.16993864918285678, 'Total loss': 0.16993864918285678}
2023-01-05 03:47:04,645 INFO:     Best model found after epoch 13 of 100.
2023-01-05 03:47:04,645 INFO:   Done with stage: TRAINING
2023-01-05 03:47:04,646 INFO:   Starting stage: EVALUATION
2023-01-05 03:47:04,772 INFO:   Done with stage: EVALUATION
2023-01-05 03:47:04,772 INFO:   Leaving out SEQ value Fold_7
2023-01-05 03:47:04,785 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:47:04,785 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:47:05,427 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:47:05,427 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:47:05,496 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:47:05,496 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:47:05,496 INFO:     No hyperparam tuning for this model
2023-01-05 03:47:05,496 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:47:05,496 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:47:05,497 INFO:     None feature selector for col prot
2023-01-05 03:47:05,497 INFO:     None feature selector for col prot
2023-01-05 03:47:05,497 INFO:     None feature selector for col prot
2023-01-05 03:47:05,498 INFO:     None feature selector for col chem
2023-01-05 03:47:05,498 INFO:     None feature selector for col chem
2023-01-05 03:47:05,498 INFO:     None feature selector for col chem
2023-01-05 03:47:05,498 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:47:05,498 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:47:05,499 INFO:     Number of params in model 72931
2023-01-05 03:47:05,503 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:47:05,503 INFO:   Starting stage: TRAINING
2023-01-05 03:47:05,564 INFO:     Val loss before train {'Reaction outcome loss': 1.158545692761739, 'Total loss': 1.158545692761739}
2023-01-05 03:47:05,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:05,564 INFO:     Epoch: 0
2023-01-05 03:47:07,819 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8628817876180013, 'Total loss': 0.8628817876180013} | train loss {'Reaction outcome loss': 0.9147396880620415, 'Total loss': 0.9147396880620415}
2023-01-05 03:47:07,819 INFO:     Found new best model at epoch 0
2023-01-05 03:47:07,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:07,820 INFO:     Epoch: 1
2023-01-05 03:47:10,063 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6392953197161356, 'Total loss': 0.6392953197161356} | train loss {'Reaction outcome loss': 0.6513623855535643, 'Total loss': 0.6513623855535643}
2023-01-05 03:47:10,063 INFO:     Found new best model at epoch 1
2023-01-05 03:47:10,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:10,065 INFO:     Epoch: 2
2023-01-05 03:47:12,299 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6145624399185181, 'Total loss': 0.6145624399185181} | train loss {'Reaction outcome loss': 0.5422526332347289, 'Total loss': 0.5422526332347289}
2023-01-05 03:47:12,299 INFO:     Found new best model at epoch 2
2023-01-05 03:47:12,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:12,300 INFO:     Epoch: 3
2023-01-05 03:47:14,539 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5733602027098338, 'Total loss': 0.5733602027098338} | train loss {'Reaction outcome loss': 0.49624288459207216, 'Total loss': 0.49624288459207216}
2023-01-05 03:47:14,539 INFO:     Found new best model at epoch 3
2023-01-05 03:47:14,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:14,540 INFO:     Epoch: 4
2023-01-05 03:47:16,694 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5716146290302276, 'Total loss': 0.5716146290302276} | train loss {'Reaction outcome loss': 0.46719991507521574, 'Total loss': 0.46719991507521574}
2023-01-05 03:47:16,696 INFO:     Found new best model at epoch 4
2023-01-05 03:47:16,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:16,697 INFO:     Epoch: 5
2023-01-05 03:47:18,923 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5830162187417348, 'Total loss': 0.5830162187417348} | train loss {'Reaction outcome loss': 0.4425964566028636, 'Total loss': 0.4425964566028636}
2023-01-05 03:47:18,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:18,924 INFO:     Epoch: 6
2023-01-05 03:47:21,063 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5418793062369028, 'Total loss': 0.5418793062369028} | train loss {'Reaction outcome loss': 0.4168150382845298, 'Total loss': 0.4168150382845298}
2023-01-05 03:47:21,063 INFO:     Found new best model at epoch 6
2023-01-05 03:47:21,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:21,065 INFO:     Epoch: 7
2023-01-05 03:47:23,231 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5289549787839254, 'Total loss': 0.5289549787839254} | train loss {'Reaction outcome loss': 0.40103564697818517, 'Total loss': 0.40103564697818517}
2023-01-05 03:47:23,232 INFO:     Found new best model at epoch 7
2023-01-05 03:47:23,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:23,233 INFO:     Epoch: 8
2023-01-05 03:47:25,403 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5311665713787079, 'Total loss': 0.5311665713787079} | train loss {'Reaction outcome loss': 0.38734373899743607, 'Total loss': 0.38734373899743607}
2023-01-05 03:47:25,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:25,403 INFO:     Epoch: 9
2023-01-05 03:47:27,624 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5336658398310343, 'Total loss': 0.5336658398310343} | train loss {'Reaction outcome loss': 0.3735468485072066, 'Total loss': 0.3735468485072066}
2023-01-05 03:47:27,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:27,624 INFO:     Epoch: 10
2023-01-05 03:47:29,873 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5032437105973562, 'Total loss': 0.5032437105973562} | train loss {'Reaction outcome loss': 0.3636156370782334, 'Total loss': 0.3636156370782334}
2023-01-05 03:47:29,873 INFO:     Found new best model at epoch 10
2023-01-05 03:47:29,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:29,874 INFO:     Epoch: 11
2023-01-05 03:47:32,125 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5104577680428822, 'Total loss': 0.5104577680428822} | train loss {'Reaction outcome loss': 0.3536067323192306, 'Total loss': 0.3536067323192306}
2023-01-05 03:47:32,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:32,126 INFO:     Epoch: 12
2023-01-05 03:47:34,347 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.499594380458196, 'Total loss': 0.499594380458196} | train loss {'Reaction outcome loss': 0.3399990465849692, 'Total loss': 0.3399990465849692}
2023-01-05 03:47:34,347 INFO:     Found new best model at epoch 12
2023-01-05 03:47:34,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:34,348 INFO:     Epoch: 13
2023-01-05 03:47:36,609 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5185851633548737, 'Total loss': 0.5185851633548737} | train loss {'Reaction outcome loss': 0.3330000275948449, 'Total loss': 0.3330000275948449}
2023-01-05 03:47:36,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:36,610 INFO:     Epoch: 14
2023-01-05 03:47:38,860 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4993998756011327, 'Total loss': 0.4993998756011327} | train loss {'Reaction outcome loss': 0.3286383258987832, 'Total loss': 0.3286383258987832}
2023-01-05 03:47:38,860 INFO:     Found new best model at epoch 14
2023-01-05 03:47:38,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:38,861 INFO:     Epoch: 15
2023-01-05 03:47:41,114 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4759777287642161, 'Total loss': 0.4759777287642161} | train loss {'Reaction outcome loss': 0.32061022048048105, 'Total loss': 0.32061022048048105}
2023-01-05 03:47:41,115 INFO:     Found new best model at epoch 15
2023-01-05 03:47:41,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:41,116 INFO:     Epoch: 16
2023-01-05 03:47:43,351 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4938550641139348, 'Total loss': 0.4938550641139348} | train loss {'Reaction outcome loss': 0.30846524374910456, 'Total loss': 0.30846524374910456}
2023-01-05 03:47:43,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:43,352 INFO:     Epoch: 17
2023-01-05 03:47:45,591 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49773061672846475, 'Total loss': 0.49773061672846475} | train loss {'Reaction outcome loss': 0.3094881747079932, 'Total loss': 0.3094881747079932}
2023-01-05 03:47:45,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:45,592 INFO:     Epoch: 18
2023-01-05 03:47:47,846 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49116516709327696, 'Total loss': 0.49116516709327696} | train loss {'Reaction outcome loss': 0.3038157860246956, 'Total loss': 0.3038157860246956}
2023-01-05 03:47:47,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:47,846 INFO:     Epoch: 19
2023-01-05 03:47:50,011 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49110291600227357, 'Total loss': 0.49110291600227357} | train loss {'Reaction outcome loss': 0.2950968977487376, 'Total loss': 0.2950968977487376}
2023-01-05 03:47:50,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:50,011 INFO:     Epoch: 20
2023-01-05 03:47:52,255 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5353503406047821, 'Total loss': 0.5353503406047821} | train loss {'Reaction outcome loss': 0.28959515049253876, 'Total loss': 0.28959515049253876}
2023-01-05 03:47:52,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:52,257 INFO:     Epoch: 21
2023-01-05 03:47:54,455 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5311150014400482, 'Total loss': 0.5311150014400482} | train loss {'Reaction outcome loss': 0.28282606046802056, 'Total loss': 0.28282606046802056}
2023-01-05 03:47:54,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:54,455 INFO:     Epoch: 22
2023-01-05 03:47:56,604 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4918459872404734, 'Total loss': 0.4918459872404734} | train loss {'Reaction outcome loss': 0.2800326053995008, 'Total loss': 0.2800326053995008}
2023-01-05 03:47:56,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:56,605 INFO:     Epoch: 23
2023-01-05 03:47:58,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4908965657154719, 'Total loss': 0.4908965657154719} | train loss {'Reaction outcome loss': 0.2775293658791191, 'Total loss': 0.2775293658791191}
2023-01-05 03:47:58,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:47:58,799 INFO:     Epoch: 24
2023-01-05 03:48:01,055 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49326064984003704, 'Total loss': 0.49326064984003704} | train loss {'Reaction outcome loss': 0.2756047733290725, 'Total loss': 0.2756047733290725}
2023-01-05 03:48:01,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:01,055 INFO:     Epoch: 25
2023-01-05 03:48:03,207 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5021631866693497, 'Total loss': 0.5021631866693497} | train loss {'Reaction outcome loss': 0.2655146285972517, 'Total loss': 0.2655146285972517}
2023-01-05 03:48:03,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:03,207 INFO:     Epoch: 26
2023-01-05 03:48:05,343 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4986989080905914, 'Total loss': 0.4986989080905914} | train loss {'Reaction outcome loss': 0.2650845967827068, 'Total loss': 0.2650845967827068}
2023-01-05 03:48:05,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:05,344 INFO:     Epoch: 27
2023-01-05 03:48:07,561 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5107899953921636, 'Total loss': 0.5107899953921636} | train loss {'Reaction outcome loss': 0.26176829897272197, 'Total loss': 0.26176829897272197}
2023-01-05 03:48:07,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:07,561 INFO:     Epoch: 28
2023-01-05 03:48:09,804 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5167290916045507, 'Total loss': 0.5167290916045507} | train loss {'Reaction outcome loss': 0.2674059361433783, 'Total loss': 0.2674059361433783}
2023-01-05 03:48:09,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:09,805 INFO:     Epoch: 29
2023-01-05 03:48:12,049 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.526442962884903, 'Total loss': 0.526442962884903} | train loss {'Reaction outcome loss': 0.25590485019906273, 'Total loss': 0.25590485019906273}
2023-01-05 03:48:12,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:12,049 INFO:     Epoch: 30
2023-01-05 03:48:14,289 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5095645666122437, 'Total loss': 0.5095645666122437} | train loss {'Reaction outcome loss': 0.2502826733330764, 'Total loss': 0.2502826733330764}
2023-01-05 03:48:14,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:14,289 INFO:     Epoch: 31
2023-01-05 03:48:16,428 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5253628154595693, 'Total loss': 0.5253628154595693} | train loss {'Reaction outcome loss': 0.24699101517435865, 'Total loss': 0.24699101517435865}
2023-01-05 03:48:16,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:16,428 INFO:     Epoch: 32
2023-01-05 03:48:18,691 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5195967435836792, 'Total loss': 0.5195967435836792} | train loss {'Reaction outcome loss': 0.24636506804015063, 'Total loss': 0.24636506804015063}
2023-01-05 03:48:18,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:18,691 INFO:     Epoch: 33
2023-01-05 03:48:20,929 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5142268508672714, 'Total loss': 0.5142268508672714} | train loss {'Reaction outcome loss': 0.24833578848536464, 'Total loss': 0.24833578848536464}
2023-01-05 03:48:20,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:20,930 INFO:     Epoch: 34
2023-01-05 03:48:23,166 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5013249059518178, 'Total loss': 0.5013249059518178} | train loss {'Reaction outcome loss': 0.24361751277056232, 'Total loss': 0.24361751277056232}
2023-01-05 03:48:23,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:23,167 INFO:     Epoch: 35
2023-01-05 03:48:25,403 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5204229334990184, 'Total loss': 0.5204229334990184} | train loss {'Reaction outcome loss': 0.2393064386771479, 'Total loss': 0.2393064386771479}
2023-01-05 03:48:25,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:25,403 INFO:     Epoch: 36
2023-01-05 03:48:27,665 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4909817015131315, 'Total loss': 0.4909817015131315} | train loss {'Reaction outcome loss': 0.2404312305962262, 'Total loss': 0.2404312305962262}
2023-01-05 03:48:27,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:27,666 INFO:     Epoch: 37
2023-01-05 03:48:29,912 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5095343043406805, 'Total loss': 0.5095343043406805} | train loss {'Reaction outcome loss': 0.23747385864523982, 'Total loss': 0.23747385864523982}
2023-01-05 03:48:29,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:29,912 INFO:     Epoch: 38
2023-01-05 03:48:32,159 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5097049673398336, 'Total loss': 0.5097049673398336} | train loss {'Reaction outcome loss': 0.23681210017209683, 'Total loss': 0.23681210017209683}
2023-01-05 03:48:32,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:32,160 INFO:     Epoch: 39
2023-01-05 03:48:34,408 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5110293120145798, 'Total loss': 0.5110293120145798} | train loss {'Reaction outcome loss': 0.23166517337676193, 'Total loss': 0.23166517337676193}
2023-01-05 03:48:34,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:34,409 INFO:     Epoch: 40
2023-01-05 03:48:36,653 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5174398293097814, 'Total loss': 0.5174398293097814} | train loss {'Reaction outcome loss': 0.23036996215059713, 'Total loss': 0.23036996215059713}
2023-01-05 03:48:36,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:36,653 INFO:     Epoch: 41
2023-01-05 03:48:38,860 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5006675784786542, 'Total loss': 0.5006675784786542} | train loss {'Reaction outcome loss': 0.22553586681454402, 'Total loss': 0.22553586681454402}
2023-01-05 03:48:38,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:38,860 INFO:     Epoch: 42
2023-01-05 03:48:41,100 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5183052281538646, 'Total loss': 0.5183052281538646} | train loss {'Reaction outcome loss': 0.22668427365167282, 'Total loss': 0.22668427365167282}
2023-01-05 03:48:41,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:41,100 INFO:     Epoch: 43
2023-01-05 03:48:43,306 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5473165422677994, 'Total loss': 0.5473165422677994} | train loss {'Reaction outcome loss': 0.22207218366573847, 'Total loss': 0.22207218366573847}
2023-01-05 03:48:43,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:43,306 INFO:     Epoch: 44
2023-01-05 03:48:45,564 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5192330638567607, 'Total loss': 0.5192330638567607} | train loss {'Reaction outcome loss': 0.22255443232100242, 'Total loss': 0.22255443232100242}
2023-01-05 03:48:45,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:45,564 INFO:     Epoch: 45
2023-01-05 03:48:47,836 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5045564234256744, 'Total loss': 0.5045564234256744} | train loss {'Reaction outcome loss': 0.22177886376764788, 'Total loss': 0.22177886376764788}
2023-01-05 03:48:47,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:47,837 INFO:     Epoch: 46
2023-01-05 03:48:50,079 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49150986870129904, 'Total loss': 0.49150986870129904} | train loss {'Reaction outcome loss': 0.21776035766832638, 'Total loss': 0.21776035766832638}
2023-01-05 03:48:50,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:50,080 INFO:     Epoch: 47
2023-01-05 03:48:52,308 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5175757850209872, 'Total loss': 0.5175757850209872} | train loss {'Reaction outcome loss': 0.2200098771676151, 'Total loss': 0.2200098771676151}
2023-01-05 03:48:52,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:52,308 INFO:     Epoch: 48
2023-01-05 03:48:54,547 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5169146796067555, 'Total loss': 0.5169146796067555} | train loss {'Reaction outcome loss': 0.21486461120472033, 'Total loss': 0.21486461120472033}
2023-01-05 03:48:54,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:54,547 INFO:     Epoch: 49
2023-01-05 03:48:56,709 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5160661111275355, 'Total loss': 0.5160661111275355} | train loss {'Reaction outcome loss': 0.2155575436114779, 'Total loss': 0.2155575436114779}
2023-01-05 03:48:56,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:56,709 INFO:     Epoch: 50
2023-01-05 03:48:58,857 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5123402496178945, 'Total loss': 0.5123402496178945} | train loss {'Reaction outcome loss': 0.21366430996188326, 'Total loss': 0.21366430996188326}
2023-01-05 03:48:58,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:48:58,857 INFO:     Epoch: 51
2023-01-05 03:49:00,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48807015965382256, 'Total loss': 0.48807015965382256} | train loss {'Reaction outcome loss': 0.21019865750618602, 'Total loss': 0.21019865750618602}
2023-01-05 03:49:00,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:00,941 INFO:     Epoch: 52
2023-01-05 03:49:02,784 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5348846753438313, 'Total loss': 0.5348846753438313} | train loss {'Reaction outcome loss': 0.21075565739791247, 'Total loss': 0.21075565739791247}
2023-01-05 03:49:02,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:02,784 INFO:     Epoch: 53
2023-01-05 03:49:04,678 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5196206152439118, 'Total loss': 0.5196206152439118} | train loss {'Reaction outcome loss': 0.20835037255302016, 'Total loss': 0.20835037255302016}
2023-01-05 03:49:04,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:04,680 INFO:     Epoch: 54
2023-01-05 03:49:06,819 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5073388716826837, 'Total loss': 0.5073388716826837} | train loss {'Reaction outcome loss': 0.20896504143319614, 'Total loss': 0.20896504143319614}
2023-01-05 03:49:06,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:06,819 INFO:     Epoch: 55
2023-01-05 03:49:08,989 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5225266640384992, 'Total loss': 0.5225266640384992} | train loss {'Reaction outcome loss': 0.2047316068572505, 'Total loss': 0.2047316068572505}
2023-01-05 03:49:08,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:08,990 INFO:     Epoch: 56
2023-01-05 03:49:11,152 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5316309789816539, 'Total loss': 0.5316309789816539} | train loss {'Reaction outcome loss': 0.20824851883926254, 'Total loss': 0.20824851883926254}
2023-01-05 03:49:11,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:11,153 INFO:     Epoch: 57
2023-01-05 03:49:13,410 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5713802864154179, 'Total loss': 0.5713802864154179} | train loss {'Reaction outcome loss': 0.2020768036245895, 'Total loss': 0.2020768036245895}
2023-01-05 03:49:13,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:13,411 INFO:     Epoch: 58
2023-01-05 03:49:15,599 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5389870901902517, 'Total loss': 0.5389870901902517} | train loss {'Reaction outcome loss': 0.19764910725137705, 'Total loss': 0.19764910725137705}
2023-01-05 03:49:15,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:15,599 INFO:     Epoch: 59
2023-01-05 03:49:17,803 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5191948235034942, 'Total loss': 0.5191948235034942} | train loss {'Reaction outcome loss': 0.19827929396057659, 'Total loss': 0.19827929396057659}
2023-01-05 03:49:17,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:17,803 INFO:     Epoch: 60
2023-01-05 03:49:20,057 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5256161818901698, 'Total loss': 0.5256161818901698} | train loss {'Reaction outcome loss': 0.19654234101746124, 'Total loss': 0.19654234101746124}
2023-01-05 03:49:20,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:20,057 INFO:     Epoch: 61
2023-01-05 03:49:22,300 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5245930343866348, 'Total loss': 0.5245930343866348} | train loss {'Reaction outcome loss': 0.1979095303281413, 'Total loss': 0.1979095303281413}
2023-01-05 03:49:22,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:22,300 INFO:     Epoch: 62
2023-01-05 03:49:24,544 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4957187831401825, 'Total loss': 0.4957187831401825} | train loss {'Reaction outcome loss': 0.18812466249969936, 'Total loss': 0.18812466249969936}
2023-01-05 03:49:24,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:24,545 INFO:     Epoch: 63
2023-01-05 03:49:26,791 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.527661257982254, 'Total loss': 0.527661257982254} | train loss {'Reaction outcome loss': 0.18799759353767487, 'Total loss': 0.18799759353767487}
2023-01-05 03:49:26,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:26,791 INFO:     Epoch: 64
2023-01-05 03:49:28,963 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5367611368497213, 'Total loss': 0.5367611368497213} | train loss {'Reaction outcome loss': 0.19619850296378677, 'Total loss': 0.19619850296378677}
2023-01-05 03:49:28,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:28,963 INFO:     Epoch: 65
2023-01-05 03:49:31,197 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5381694912910462, 'Total loss': 0.5381694912910462} | train loss {'Reaction outcome loss': 0.18849535056643366, 'Total loss': 0.18849535056643366}
2023-01-05 03:49:31,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:31,197 INFO:     Epoch: 66
2023-01-05 03:49:33,434 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5020260989665986, 'Total loss': 0.5020260989665986} | train loss {'Reaction outcome loss': 0.18455236778085027, 'Total loss': 0.18455236778085027}
2023-01-05 03:49:33,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:33,434 INFO:     Epoch: 67
2023-01-05 03:49:35,699 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5311303506294887, 'Total loss': 0.5311303506294887} | train loss {'Reaction outcome loss': 0.18661530614945546, 'Total loss': 0.18661530614945546}
2023-01-05 03:49:35,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:35,700 INFO:     Epoch: 68
2023-01-05 03:49:37,945 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.526904551188151, 'Total loss': 0.526904551188151} | train loss {'Reaction outcome loss': 0.1814917137633766, 'Total loss': 0.1814917137633766}
2023-01-05 03:49:37,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:37,946 INFO:     Epoch: 69
2023-01-05 03:49:40,175 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5318312704563141, 'Total loss': 0.5318312704563141} | train loss {'Reaction outcome loss': 0.1874556485614132, 'Total loss': 0.1874556485614132}
2023-01-05 03:49:40,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:40,175 INFO:     Epoch: 70
2023-01-05 03:49:42,400 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5252771198749542, 'Total loss': 0.5252771198749542} | train loss {'Reaction outcome loss': 0.18143236712363642, 'Total loss': 0.18143236712363642}
2023-01-05 03:49:42,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:42,401 INFO:     Epoch: 71
2023-01-05 03:49:44,648 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5442986539565027, 'Total loss': 0.5442986539565027} | train loss {'Reaction outcome loss': 0.1795943532226796, 'Total loss': 0.1795943532226796}
2023-01-05 03:49:44,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:44,649 INFO:     Epoch: 72
2023-01-05 03:49:46,843 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5437693337599436, 'Total loss': 0.5437693337599436} | train loss {'Reaction outcome loss': 0.18191318924452746, 'Total loss': 0.18191318924452746}
2023-01-05 03:49:46,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:46,843 INFO:     Epoch: 73
2023-01-05 03:49:49,055 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5326623837153117, 'Total loss': 0.5326623837153117} | train loss {'Reaction outcome loss': 0.20569355455834581, 'Total loss': 0.20569355455834581}
2023-01-05 03:49:49,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:49,055 INFO:     Epoch: 74
2023-01-05 03:49:51,297 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5130382299423217, 'Total loss': 0.5130382299423217} | train loss {'Reaction outcome loss': 0.17736424790696154, 'Total loss': 0.17736424790696154}
2023-01-05 03:49:51,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:51,297 INFO:     Epoch: 75
2023-01-05 03:49:53,487 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5167759895324707, 'Total loss': 0.5167759895324707} | train loss {'Reaction outcome loss': 0.1810328803076645, 'Total loss': 0.1810328803076645}
2023-01-05 03:49:53,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:53,487 INFO:     Epoch: 76
2023-01-05 03:49:55,721 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.55546648701032, 'Total loss': 0.55546648701032} | train loss {'Reaction outcome loss': 0.17617485669602484, 'Total loss': 0.17617485669602484}
2023-01-05 03:49:55,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:55,722 INFO:     Epoch: 77
2023-01-05 03:49:57,981 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.571651088198026, 'Total loss': 0.571651088198026} | train loss {'Reaction outcome loss': 0.1781574201368789, 'Total loss': 0.1781574201368789}
2023-01-05 03:49:57,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:49:57,981 INFO:     Epoch: 78
2023-01-05 03:50:00,203 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4917260487874349, 'Total loss': 0.4917260487874349} | train loss {'Reaction outcome loss': 0.17814498112652538, 'Total loss': 0.17814498112652538}
2023-01-05 03:50:00,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:00,203 INFO:     Epoch: 79
2023-01-05 03:50:02,458 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5266396929820378, 'Total loss': 0.5266396929820378} | train loss {'Reaction outcome loss': 0.1745412411962035, 'Total loss': 0.1745412411962035}
2023-01-05 03:50:02,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:02,458 INFO:     Epoch: 80
2023-01-05 03:50:04,633 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5349901348352433, 'Total loss': 0.5349901348352433} | train loss {'Reaction outcome loss': 0.17307440808339827, 'Total loss': 0.17307440808339827}
2023-01-05 03:50:04,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:04,633 INFO:     Epoch: 81
2023-01-05 03:50:06,788 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5534896334012349, 'Total loss': 0.5534896334012349} | train loss {'Reaction outcome loss': 0.17146055299225196, 'Total loss': 0.17146055299225196}
2023-01-05 03:50:06,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:06,789 INFO:     Epoch: 82
2023-01-05 03:50:09,049 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5436415155728658, 'Total loss': 0.5436415155728658} | train loss {'Reaction outcome loss': 0.17751973485439151, 'Total loss': 0.17751973485439151}
2023-01-05 03:50:09,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:09,049 INFO:     Epoch: 83
2023-01-05 03:50:11,254 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5210752189159393, 'Total loss': 0.5210752189159393} | train loss {'Reaction outcome loss': 0.1680591724278966, 'Total loss': 0.1680591724278966}
2023-01-05 03:50:11,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:11,254 INFO:     Epoch: 84
2023-01-05 03:50:13,475 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5084311803181966, 'Total loss': 0.5084311803181966} | train loss {'Reaction outcome loss': 0.1691585383353123, 'Total loss': 0.1691585383353123}
2023-01-05 03:50:13,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:13,476 INFO:     Epoch: 85
2023-01-05 03:50:15,482 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5386756102244059, 'Total loss': 0.5386756102244059} | train loss {'Reaction outcome loss': 0.16885750546740988, 'Total loss': 0.16885750546740988}
2023-01-05 03:50:15,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:15,483 INFO:     Epoch: 86
2023-01-05 03:50:17,699 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.518629448612531, 'Total loss': 0.518629448612531} | train loss {'Reaction outcome loss': 0.17736453345371073, 'Total loss': 0.17736453345371073}
2023-01-05 03:50:17,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:17,699 INFO:     Epoch: 87
2023-01-05 03:50:19,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5598230640093486, 'Total loss': 0.5598230640093486} | train loss {'Reaction outcome loss': 0.16641093042251642, 'Total loss': 0.16641093042251642}
2023-01-05 03:50:19,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:19,940 INFO:     Epoch: 88
2023-01-05 03:50:22,162 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5269017428159714, 'Total loss': 0.5269017428159714} | train loss {'Reaction outcome loss': 0.16241129317685313, 'Total loss': 0.16241129317685313}
2023-01-05 03:50:22,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:22,162 INFO:     Epoch: 89
2023-01-05 03:50:24,381 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5833874473969142, 'Total loss': 0.5833874473969142} | train loss {'Reaction outcome loss': 0.16529149044283153, 'Total loss': 0.16529149044283153}
2023-01-05 03:50:24,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:24,381 INFO:     Epoch: 90
2023-01-05 03:50:26,624 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5728916545708974, 'Total loss': 0.5728916545708974} | train loss {'Reaction outcome loss': 0.16992159221199868, 'Total loss': 0.16992159221199868}
2023-01-05 03:50:26,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:26,625 INFO:     Epoch: 91
2023-01-05 03:50:28,872 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.544536832968394, 'Total loss': 0.544536832968394} | train loss {'Reaction outcome loss': 0.16656045439531622, 'Total loss': 0.16656045439531622}
2023-01-05 03:50:28,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:28,873 INFO:     Epoch: 92
2023-01-05 03:50:31,132 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5202546412746112, 'Total loss': 0.5202546412746112} | train loss {'Reaction outcome loss': 0.1686059808623437, 'Total loss': 0.1686059808623437}
2023-01-05 03:50:31,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:31,133 INFO:     Epoch: 93
2023-01-05 03:50:33,390 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5324289580186208, 'Total loss': 0.5324289580186208} | train loss {'Reaction outcome loss': 0.16351454253510936, 'Total loss': 0.16351454253510936}
2023-01-05 03:50:33,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:33,390 INFO:     Epoch: 94
2023-01-05 03:50:35,584 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5382624725500743, 'Total loss': 0.5382624725500743} | train loss {'Reaction outcome loss': 0.16268038731473294, 'Total loss': 0.16268038731473294}
2023-01-05 03:50:35,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:35,585 INFO:     Epoch: 95
2023-01-05 03:50:37,850 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5556073288122813, 'Total loss': 0.5556073288122813} | train loss {'Reaction outcome loss': 0.1636679576308318, 'Total loss': 0.1636679576308318}
2023-01-05 03:50:37,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:37,850 INFO:     Epoch: 96
2023-01-05 03:50:40,082 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5615177929401398, 'Total loss': 0.5615177929401398} | train loss {'Reaction outcome loss': 0.1716496625858913, 'Total loss': 0.1716496625858913}
2023-01-05 03:50:40,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:40,082 INFO:     Epoch: 97
2023-01-05 03:50:42,237 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5560833672682445, 'Total loss': 0.5560833672682445} | train loss {'Reaction outcome loss': 0.16448021545010558, 'Total loss': 0.16448021545010558}
2023-01-05 03:50:42,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:42,238 INFO:     Epoch: 98
2023-01-05 03:50:44,505 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5531329174836477, 'Total loss': 0.5531329174836477} | train loss {'Reaction outcome loss': 0.16468097737980197, 'Total loss': 0.16468097737980197}
2023-01-05 03:50:44,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:44,505 INFO:     Epoch: 99
2023-01-05 03:50:46,769 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5453814208507538, 'Total loss': 0.5453814208507538} | train loss {'Reaction outcome loss': 0.1675740083809074, 'Total loss': 0.1675740083809074}
2023-01-05 03:50:46,769 INFO:     Best model found after epoch 16 of 100.
2023-01-05 03:50:46,769 INFO:   Done with stage: TRAINING
2023-01-05 03:50:46,769 INFO:   Starting stage: EVALUATION
2023-01-05 03:50:46,905 INFO:   Done with stage: EVALUATION
2023-01-05 03:50:46,905 INFO:   Leaving out SEQ value Fold_8
2023-01-05 03:50:46,917 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 03:50:46,918 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:50:47,562 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:50:47,562 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:50:47,631 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:50:47,631 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:50:47,631 INFO:     No hyperparam tuning for this model
2023-01-05 03:50:47,631 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:50:47,631 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:50:47,632 INFO:     None feature selector for col prot
2023-01-05 03:50:47,632 INFO:     None feature selector for col prot
2023-01-05 03:50:47,632 INFO:     None feature selector for col prot
2023-01-05 03:50:47,633 INFO:     None feature selector for col chem
2023-01-05 03:50:47,633 INFO:     None feature selector for col chem
2023-01-05 03:50:47,633 INFO:     None feature selector for col chem
2023-01-05 03:50:47,633 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:50:47,633 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:50:47,635 INFO:     Number of params in model 72931
2023-01-05 03:50:47,638 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:50:47,638 INFO:   Starting stage: TRAINING
2023-01-05 03:50:47,701 INFO:     Val loss before train {'Reaction outcome loss': 0.8244044641653697, 'Total loss': 0.8244044641653697}
2023-01-05 03:50:47,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:47,701 INFO:     Epoch: 0
2023-01-05 03:50:49,899 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6963578462600708, 'Total loss': 0.6963578462600708} | train loss {'Reaction outcome loss': 0.9563850240550772, 'Total loss': 0.9563850240550772}
2023-01-05 03:50:49,899 INFO:     Found new best model at epoch 0
2023-01-05 03:50:49,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:49,901 INFO:     Epoch: 1
2023-01-05 03:50:52,149 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5317521115144094, 'Total loss': 0.5317521115144094} | train loss {'Reaction outcome loss': 0.6403054226271427, 'Total loss': 0.6403054226271427}
2023-01-05 03:50:52,149 INFO:     Found new best model at epoch 1
2023-01-05 03:50:52,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:52,151 INFO:     Epoch: 2
2023-01-05 03:50:54,398 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5095644255479177, 'Total loss': 0.5095644255479177} | train loss {'Reaction outcome loss': 0.531521376793402, 'Total loss': 0.531521376793402}
2023-01-05 03:50:54,398 INFO:     Found new best model at epoch 2
2023-01-05 03:50:54,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:54,400 INFO:     Epoch: 3
2023-01-05 03:50:56,556 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49073871970176697, 'Total loss': 0.49073871970176697} | train loss {'Reaction outcome loss': 0.4925815848647243, 'Total loss': 0.4925815848647243}
2023-01-05 03:50:56,557 INFO:     Found new best model at epoch 3
2023-01-05 03:50:56,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:56,558 INFO:     Epoch: 4
2023-01-05 03:50:58,805 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4695138851801554, 'Total loss': 0.4695138851801554} | train loss {'Reaction outcome loss': 0.4697487879626072, 'Total loss': 0.4697487879626072}
2023-01-05 03:50:58,805 INFO:     Found new best model at epoch 4
2023-01-05 03:50:58,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:50:58,807 INFO:     Epoch: 5
2023-01-05 03:51:01,053 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4632106880346934, 'Total loss': 0.4632106880346934} | train loss {'Reaction outcome loss': 0.45386382007468357, 'Total loss': 0.45386382007468357}
2023-01-05 03:51:01,053 INFO:     Found new best model at epoch 5
2023-01-05 03:51:01,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:01,055 INFO:     Epoch: 6
2023-01-05 03:51:03,249 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47457187324762345, 'Total loss': 0.47457187324762345} | train loss {'Reaction outcome loss': 0.43651596130463327, 'Total loss': 0.43651596130463327}
2023-01-05 03:51:03,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:03,249 INFO:     Epoch: 7
2023-01-05 03:51:05,477 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4327477167050044, 'Total loss': 0.4327477167050044} | train loss {'Reaction outcome loss': 0.4268116392195225, 'Total loss': 0.4268116392195225}
2023-01-05 03:51:05,477 INFO:     Found new best model at epoch 7
2023-01-05 03:51:05,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:05,479 INFO:     Epoch: 8
2023-01-05 03:51:07,695 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4482682764530182, 'Total loss': 0.4482682764530182} | train loss {'Reaction outcome loss': 0.41439477887249343, 'Total loss': 0.41439477887249343}
2023-01-05 03:51:07,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:07,696 INFO:     Epoch: 9
2023-01-05 03:51:09,944 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43041026691595713, 'Total loss': 0.43041026691595713} | train loss {'Reaction outcome loss': 0.40154533058296155, 'Total loss': 0.40154533058296155}
2023-01-05 03:51:09,944 INFO:     Found new best model at epoch 9
2023-01-05 03:51:09,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:09,946 INFO:     Epoch: 10
2023-01-05 03:51:12,193 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4530611475308736, 'Total loss': 0.4530611475308736} | train loss {'Reaction outcome loss': 0.39268357121813907, 'Total loss': 0.39268357121813907}
2023-01-05 03:51:12,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:12,194 INFO:     Epoch: 11
2023-01-05 03:51:14,413 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43742343386014304, 'Total loss': 0.43742343386014304} | train loss {'Reaction outcome loss': 0.38111734229826577, 'Total loss': 0.38111734229826577}
2023-01-05 03:51:14,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:14,414 INFO:     Epoch: 12
2023-01-05 03:51:16,659 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4140559136867523, 'Total loss': 0.4140559136867523} | train loss {'Reaction outcome loss': 0.37238820367594705, 'Total loss': 0.37238820367594705}
2023-01-05 03:51:16,659 INFO:     Found new best model at epoch 12
2023-01-05 03:51:16,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:16,661 INFO:     Epoch: 13
2023-01-05 03:51:18,911 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4233986834685008, 'Total loss': 0.4233986834685008} | train loss {'Reaction outcome loss': 0.3600112175310615, 'Total loss': 0.3600112175310615}
2023-01-05 03:51:18,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:18,911 INFO:     Epoch: 14
2023-01-05 03:51:21,133 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4418618194758892, 'Total loss': 0.4418618194758892} | train loss {'Reaction outcome loss': 0.3584892203501106, 'Total loss': 0.3584892203501106}
2023-01-05 03:51:21,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:21,133 INFO:     Epoch: 15
2023-01-05 03:51:23,367 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4244645059108734, 'Total loss': 0.4244645059108734} | train loss {'Reaction outcome loss': 0.34937127844097404, 'Total loss': 0.34937127844097404}
2023-01-05 03:51:23,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:23,367 INFO:     Epoch: 16
2023-01-05 03:51:25,574 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4484490881363551, 'Total loss': 0.4484490881363551} | train loss {'Reaction outcome loss': 0.3376018784015718, 'Total loss': 0.3376018784015718}
2023-01-05 03:51:25,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:25,574 INFO:     Epoch: 17
2023-01-05 03:51:27,792 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4286946098009745, 'Total loss': 0.4286946098009745} | train loss {'Reaction outcome loss': 0.33075678847512624, 'Total loss': 0.33075678847512624}
2023-01-05 03:51:27,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:27,792 INFO:     Epoch: 18
2023-01-05 03:51:30,005 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4205995430548986, 'Total loss': 0.4205995430548986} | train loss {'Reaction outcome loss': 0.32395173815915185, 'Total loss': 0.32395173815915185}
2023-01-05 03:51:30,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:30,005 INFO:     Epoch: 19
2023-01-05 03:51:32,219 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42110201468070346, 'Total loss': 0.42110201468070346} | train loss {'Reaction outcome loss': 0.31827872478994573, 'Total loss': 0.31827872478994573}
2023-01-05 03:51:32,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:32,220 INFO:     Epoch: 20
2023-01-05 03:51:34,443 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4230481028556824, 'Total loss': 0.4230481028556824} | train loss {'Reaction outcome loss': 0.3109141514385051, 'Total loss': 0.3109141514385051}
2023-01-05 03:51:34,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:34,443 INFO:     Epoch: 21
2023-01-05 03:51:36,562 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4298984577258428, 'Total loss': 0.4298984577258428} | train loss {'Reaction outcome loss': 0.30900068419312476, 'Total loss': 0.30900068419312476}
2023-01-05 03:51:36,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:36,562 INFO:     Epoch: 22
2023-01-05 03:51:38,779 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4542198379834493, 'Total loss': 0.4542198379834493} | train loss {'Reaction outcome loss': 0.3019652763368004, 'Total loss': 0.3019652763368004}
2023-01-05 03:51:38,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:38,779 INFO:     Epoch: 23
2023-01-05 03:51:40,995 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43977635304133095, 'Total loss': 0.43977635304133095} | train loss {'Reaction outcome loss': 0.2972578384580403, 'Total loss': 0.2972578384580403}
2023-01-05 03:51:40,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:40,995 INFO:     Epoch: 24
2023-01-05 03:51:43,141 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4453155428171158, 'Total loss': 0.4453155428171158} | train loss {'Reaction outcome loss': 0.2882046871784612, 'Total loss': 0.2882046871784612}
2023-01-05 03:51:43,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:43,142 INFO:     Epoch: 25
2023-01-05 03:51:45,361 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4379354884227117, 'Total loss': 0.4379354884227117} | train loss {'Reaction outcome loss': 0.2865144077851607, 'Total loss': 0.2865144077851607}
2023-01-05 03:51:45,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:45,361 INFO:     Epoch: 26
2023-01-05 03:51:47,575 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4203445424636205, 'Total loss': 0.4203445424636205} | train loss {'Reaction outcome loss': 0.2859108363325796, 'Total loss': 0.2859108363325796}
2023-01-05 03:51:47,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:47,576 INFO:     Epoch: 27
2023-01-05 03:51:49,761 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41981618280212085, 'Total loss': 0.41981618280212085} | train loss {'Reaction outcome loss': 0.28106030564836776, 'Total loss': 0.28106030564836776}
2023-01-05 03:51:49,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:49,761 INFO:     Epoch: 28
2023-01-05 03:51:51,995 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43206166426340736, 'Total loss': 0.43206166426340736} | train loss {'Reaction outcome loss': 0.2737961474289424, 'Total loss': 0.2737961474289424}
2023-01-05 03:51:51,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:51,995 INFO:     Epoch: 29
2023-01-05 03:51:54,136 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.456086665391922, 'Total loss': 0.456086665391922} | train loss {'Reaction outcome loss': 0.2638021991146307, 'Total loss': 0.2638021991146307}
2023-01-05 03:51:54,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:54,136 INFO:     Epoch: 30
2023-01-05 03:51:56,369 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43890364865461984, 'Total loss': 0.43890364865461984} | train loss {'Reaction outcome loss': 0.2622366982518974, 'Total loss': 0.2622366982518974}
2023-01-05 03:51:56,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:56,369 INFO:     Epoch: 31
2023-01-05 03:51:58,612 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4373612254858017, 'Total loss': 0.4373612254858017} | train loss {'Reaction outcome loss': 0.2619147514312589, 'Total loss': 0.2619147514312589}
2023-01-05 03:51:58,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:51:58,612 INFO:     Epoch: 32
2023-01-05 03:52:00,838 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46317781805992125, 'Total loss': 0.46317781805992125} | train loss {'Reaction outcome loss': 0.2569772795141831, 'Total loss': 0.2569772795141831}
2023-01-05 03:52:00,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:00,838 INFO:     Epoch: 33
2023-01-05 03:52:03,079 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43179727693398795, 'Total loss': 0.43179727693398795} | train loss {'Reaction outcome loss': 0.2586561545974364, 'Total loss': 0.2586561545974364}
2023-01-05 03:52:03,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:03,079 INFO:     Epoch: 34
2023-01-05 03:52:05,323 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4527975340684255, 'Total loss': 0.4527975340684255} | train loss {'Reaction outcome loss': 0.25332183438441613, 'Total loss': 0.25332183438441613}
2023-01-05 03:52:05,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:05,323 INFO:     Epoch: 35
2023-01-05 03:52:07,494 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4605737626552582, 'Total loss': 0.4605737626552582} | train loss {'Reaction outcome loss': 0.25134784990690484, 'Total loss': 0.25134784990690484}
2023-01-05 03:52:07,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:07,495 INFO:     Epoch: 36
2023-01-05 03:52:09,733 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4431303560733795, 'Total loss': 0.4431303560733795} | train loss {'Reaction outcome loss': 0.24805988302712675, 'Total loss': 0.24805988302712675}
2023-01-05 03:52:09,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:09,733 INFO:     Epoch: 37
2023-01-05 03:52:11,887 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44828373889128365, 'Total loss': 0.44828373889128365} | train loss {'Reaction outcome loss': 0.2429969420343855, 'Total loss': 0.2429969420343855}
2023-01-05 03:52:11,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:11,887 INFO:     Epoch: 38
2023-01-05 03:52:14,124 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46759337385495503, 'Total loss': 0.46759337385495503} | train loss {'Reaction outcome loss': 0.23672399722569942, 'Total loss': 0.23672399722569942}
2023-01-05 03:52:14,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:14,124 INFO:     Epoch: 39
2023-01-05 03:52:16,338 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4372205818692843, 'Total loss': 0.4372205818692843} | train loss {'Reaction outcome loss': 0.2386657806711584, 'Total loss': 0.2386657806711584}
2023-01-05 03:52:16,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:16,338 INFO:     Epoch: 40
2023-01-05 03:52:18,586 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4555911660194397, 'Total loss': 0.4555911660194397} | train loss {'Reaction outcome loss': 0.2372425725941893, 'Total loss': 0.2372425725941893}
2023-01-05 03:52:18,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:18,586 INFO:     Epoch: 41
2023-01-05 03:52:20,807 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44162222743034363, 'Total loss': 0.44162222743034363} | train loss {'Reaction outcome loss': 0.2302086156483631, 'Total loss': 0.2302086156483631}
2023-01-05 03:52:20,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:20,808 INFO:     Epoch: 42
2023-01-05 03:52:23,055 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4578916261593501, 'Total loss': 0.4578916261593501} | train loss {'Reaction outcome loss': 0.22886704699387841, 'Total loss': 0.22886704699387841}
2023-01-05 03:52:23,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:23,056 INFO:     Epoch: 43
2023-01-05 03:52:25,298 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43007364658017955, 'Total loss': 0.43007364658017955} | train loss {'Reaction outcome loss': 0.2230785500910813, 'Total loss': 0.2230785500910813}
2023-01-05 03:52:25,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:25,298 INFO:     Epoch: 44
2023-01-05 03:52:27,548 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47365658183892567, 'Total loss': 0.47365658183892567} | train loss {'Reaction outcome loss': 0.2215183320281905, 'Total loss': 0.2215183320281905}
2023-01-05 03:52:27,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:27,549 INFO:     Epoch: 45
2023-01-05 03:52:29,799 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4669691781202952, 'Total loss': 0.4669691781202952} | train loss {'Reaction outcome loss': 0.2199514746584379, 'Total loss': 0.2199514746584379}
2023-01-05 03:52:29,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:29,800 INFO:     Epoch: 46
2023-01-05 03:52:31,985 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4503792424996694, 'Total loss': 0.4503792424996694} | train loss {'Reaction outcome loss': 0.22203270025061864, 'Total loss': 0.22203270025061864}
2023-01-05 03:52:31,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:31,985 INFO:     Epoch: 47
2023-01-05 03:52:34,186 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.472008686264356, 'Total loss': 0.472008686264356} | train loss {'Reaction outcome loss': 0.22096685615680894, 'Total loss': 0.22096685615680894}
2023-01-05 03:52:34,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:34,187 INFO:     Epoch: 48
2023-01-05 03:52:36,411 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47178955872853595, 'Total loss': 0.47178955872853595} | train loss {'Reaction outcome loss': 0.21870261956903622, 'Total loss': 0.21870261956903622}
2023-01-05 03:52:36,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:36,411 INFO:     Epoch: 49
2023-01-05 03:52:38,649 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4895565450191498, 'Total loss': 0.4895565450191498} | train loss {'Reaction outcome loss': 0.21532365183148833, 'Total loss': 0.21532365183148833}
2023-01-05 03:52:38,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:38,649 INFO:     Epoch: 50
2023-01-05 03:52:40,905 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4760557512442271, 'Total loss': 0.4760557512442271} | train loss {'Reaction outcome loss': 0.21309062224017442, 'Total loss': 0.21309062224017442}
2023-01-05 03:52:40,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:40,905 INFO:     Epoch: 51
2023-01-05 03:52:43,123 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4702562895913919, 'Total loss': 0.4702562895913919} | train loss {'Reaction outcome loss': 0.21039653675508324, 'Total loss': 0.21039653675508324}
2023-01-05 03:52:43,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:43,124 INFO:     Epoch: 52
2023-01-05 03:52:45,277 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47538943191369376, 'Total loss': 0.47538943191369376} | train loss {'Reaction outcome loss': 0.20970589895290834, 'Total loss': 0.20970589895290834}
2023-01-05 03:52:45,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:45,277 INFO:     Epoch: 53
2023-01-05 03:52:47,465 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47335297365983325, 'Total loss': 0.47335297365983325} | train loss {'Reaction outcome loss': 0.2124708804444675, 'Total loss': 0.2124708804444675}
2023-01-05 03:52:47,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:47,465 INFO:     Epoch: 54
2023-01-05 03:52:49,698 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4949807792901993, 'Total loss': 0.4949807792901993} | train loss {'Reaction outcome loss': 0.2045482776032584, 'Total loss': 0.2045482776032584}
2023-01-05 03:52:49,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:49,698 INFO:     Epoch: 55
2023-01-05 03:52:51,920 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4408376197020213, 'Total loss': 0.4408376197020213} | train loss {'Reaction outcome loss': 0.20603564658616907, 'Total loss': 0.20603564658616907}
2023-01-05 03:52:51,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:51,920 INFO:     Epoch: 56
2023-01-05 03:52:54,121 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4703918218612671, 'Total loss': 0.4703918218612671} | train loss {'Reaction outcome loss': 0.20271153431929592, 'Total loss': 0.20271153431929592}
2023-01-05 03:52:54,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:54,122 INFO:     Epoch: 57
2023-01-05 03:52:56,346 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45827071319023766, 'Total loss': 0.45827071319023766} | train loss {'Reaction outcome loss': 0.20368426396803807, 'Total loss': 0.20368426396803807}
2023-01-05 03:52:56,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:56,346 INFO:     Epoch: 58
2023-01-05 03:52:58,533 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46016894380251566, 'Total loss': 0.46016894380251566} | train loss {'Reaction outcome loss': 0.2036281149956758, 'Total loss': 0.2036281149956758}
2023-01-05 03:52:58,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:52:58,534 INFO:     Epoch: 59
2023-01-05 03:53:00,751 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4825087929765383, 'Total loss': 0.4825087929765383} | train loss {'Reaction outcome loss': 0.1978881732870002, 'Total loss': 0.1978881732870002}
2023-01-05 03:53:00,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:00,752 INFO:     Epoch: 60
2023-01-05 03:53:03,000 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4617999772230784, 'Total loss': 0.4617999772230784} | train loss {'Reaction outcome loss': 0.20043462942809845, 'Total loss': 0.20043462942809845}
2023-01-05 03:53:03,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:03,001 INFO:     Epoch: 61
2023-01-05 03:53:05,141 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47271024286746977, 'Total loss': 0.47271024286746977} | train loss {'Reaction outcome loss': 0.19573760770234097, 'Total loss': 0.19573760770234097}
2023-01-05 03:53:05,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:05,141 INFO:     Epoch: 62
2023-01-05 03:53:07,363 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.497451251745224, 'Total loss': 0.497451251745224} | train loss {'Reaction outcome loss': 0.1988443951054483, 'Total loss': 0.1988443951054483}
2023-01-05 03:53:07,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:07,364 INFO:     Epoch: 63
2023-01-05 03:53:09,533 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4454163450592508, 'Total loss': 0.4454163450592508} | train loss {'Reaction outcome loss': 0.194938191134537, 'Total loss': 0.194938191134537}
2023-01-05 03:53:09,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:09,533 INFO:     Epoch: 64
2023-01-05 03:53:11,755 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4667605032523473, 'Total loss': 0.4667605032523473} | train loss {'Reaction outcome loss': 0.19884042098547203, 'Total loss': 0.19884042098547203}
2023-01-05 03:53:11,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:11,755 INFO:     Epoch: 65
2023-01-05 03:53:13,983 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46291227142016095, 'Total loss': 0.46291227142016095} | train loss {'Reaction outcome loss': 0.1913522954989415, 'Total loss': 0.1913522954989415}
2023-01-05 03:53:13,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:13,984 INFO:     Epoch: 66
2023-01-05 03:53:16,212 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4682440479596456, 'Total loss': 0.4682440479596456} | train loss {'Reaction outcome loss': 0.19097602228042634, 'Total loss': 0.19097602228042634}
2023-01-05 03:53:16,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:16,213 INFO:     Epoch: 67
2023-01-05 03:53:18,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48022763232390087, 'Total loss': 0.48022763232390087} | train loss {'Reaction outcome loss': 0.19318771746050376, 'Total loss': 0.19318771746050376}
2023-01-05 03:53:18,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:18,435 INFO:     Epoch: 68
2023-01-05 03:53:20,604 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4861125896374385, 'Total loss': 0.4861125896374385} | train loss {'Reaction outcome loss': 0.18939354840536893, 'Total loss': 0.18939354840536893}
2023-01-05 03:53:20,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:20,605 INFO:     Epoch: 69
2023-01-05 03:53:22,726 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5054676314194997, 'Total loss': 0.5054676314194997} | train loss {'Reaction outcome loss': 0.18847321257688596, 'Total loss': 0.18847321257688596}
2023-01-05 03:53:22,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:22,727 INFO:     Epoch: 70
2023-01-05 03:53:24,952 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48104732831319175, 'Total loss': 0.48104732831319175} | train loss {'Reaction outcome loss': 0.18887292378901566, 'Total loss': 0.18887292378901566}
2023-01-05 03:53:24,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:24,953 INFO:     Epoch: 71
2023-01-05 03:53:27,210 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4936723530292511, 'Total loss': 0.4936723530292511} | train loss {'Reaction outcome loss': 0.19172573363218104, 'Total loss': 0.19172573363218104}
2023-01-05 03:53:27,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:27,211 INFO:     Epoch: 72
2023-01-05 03:53:29,469 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5060095449288686, 'Total loss': 0.5060095449288686} | train loss {'Reaction outcome loss': 0.18558762208592608, 'Total loss': 0.18558762208592608}
2023-01-05 03:53:29,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:29,469 INFO:     Epoch: 73
2023-01-05 03:53:31,711 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49072401771942775, 'Total loss': 0.49072401771942775} | train loss {'Reaction outcome loss': 0.18651209517048983, 'Total loss': 0.18651209517048983}
2023-01-05 03:53:31,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:31,712 INFO:     Epoch: 74
2023-01-05 03:53:33,859 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5266482373078664, 'Total loss': 0.5266482373078664} | train loss {'Reaction outcome loss': 0.18601825993752827, 'Total loss': 0.18601825993752827}
2023-01-05 03:53:33,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:33,859 INFO:     Epoch: 75
2023-01-05 03:53:36,111 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.489585002263387, 'Total loss': 0.489585002263387} | train loss {'Reaction outcome loss': 0.1882189831638668, 'Total loss': 0.1882189831638668}
2023-01-05 03:53:36,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:36,111 INFO:     Epoch: 76
2023-01-05 03:53:38,423 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4837939689556758, 'Total loss': 0.4837939689556758} | train loss {'Reaction outcome loss': 0.1860561477781756, 'Total loss': 0.1860561477781756}
2023-01-05 03:53:38,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:38,424 INFO:     Epoch: 77
2023-01-05 03:53:40,670 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47737169166405996, 'Total loss': 0.47737169166405996} | train loss {'Reaction outcome loss': 0.18626812339359283, 'Total loss': 0.18626812339359283}
2023-01-05 03:53:40,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:40,670 INFO:     Epoch: 78
2023-01-05 03:53:42,927 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49215171138445535, 'Total loss': 0.49215171138445535} | train loss {'Reaction outcome loss': 0.18219279163571442, 'Total loss': 0.18219279163571442}
2023-01-05 03:53:42,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:42,928 INFO:     Epoch: 79
2023-01-05 03:53:45,090 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4995187471310298, 'Total loss': 0.4995187471310298} | train loss {'Reaction outcome loss': 0.18031914676981467, 'Total loss': 0.18031914676981467}
2023-01-05 03:53:45,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:45,090 INFO:     Epoch: 80
2023-01-05 03:53:47,325 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5184602282941342, 'Total loss': 0.5184602282941342} | train loss {'Reaction outcome loss': 0.18004999247406792, 'Total loss': 0.18004999247406792}
2023-01-05 03:53:47,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:47,326 INFO:     Epoch: 81
2023-01-05 03:53:49,559 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46273133456707, 'Total loss': 0.46273133456707} | train loss {'Reaction outcome loss': 0.1801285600140147, 'Total loss': 0.1801285600140147}
2023-01-05 03:53:49,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:49,559 INFO:     Epoch: 82
2023-01-05 03:53:51,757 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4885715901851654, 'Total loss': 0.4885715901851654} | train loss {'Reaction outcome loss': 0.18037218202660063, 'Total loss': 0.18037218202660063}
2023-01-05 03:53:51,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:51,757 INFO:     Epoch: 83
2023-01-05 03:53:53,990 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49334541261196135, 'Total loss': 0.49334541261196135} | train loss {'Reaction outcome loss': 0.18043432918540372, 'Total loss': 0.18043432918540372}
2023-01-05 03:53:53,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:53,990 INFO:     Epoch: 84
2023-01-05 03:53:56,186 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49968663454055784, 'Total loss': 0.49968663454055784} | train loss {'Reaction outcome loss': 0.17469611522286152, 'Total loss': 0.17469611522286152}
2023-01-05 03:53:56,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:56,186 INFO:     Epoch: 85
2023-01-05 03:53:58,417 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.520850587884585, 'Total loss': 0.520850587884585} | train loss {'Reaction outcome loss': 0.1765890408538445, 'Total loss': 0.1765890408538445}
2023-01-05 03:53:58,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:53:58,418 INFO:     Epoch: 86
2023-01-05 03:54:00,641 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5237299531698227, 'Total loss': 0.5237299531698227} | train loss {'Reaction outcome loss': 0.1732128023350081, 'Total loss': 0.1732128023350081}
2023-01-05 03:54:00,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:00,642 INFO:     Epoch: 87
2023-01-05 03:54:02,864 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5044449051221211, 'Total loss': 0.5044449051221211} | train loss {'Reaction outcome loss': 0.18089785348338477, 'Total loss': 0.18089785348338477}
2023-01-05 03:54:02,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:02,865 INFO:     Epoch: 88
2023-01-05 03:54:05,048 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4911048809687297, 'Total loss': 0.4911048809687297} | train loss {'Reaction outcome loss': 0.17457807936236588, 'Total loss': 0.17457807936236588}
2023-01-05 03:54:05,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:05,049 INFO:     Epoch: 89
2023-01-05 03:54:07,282 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4862818107008934, 'Total loss': 0.4862818107008934} | train loss {'Reaction outcome loss': 0.17436030597840674, 'Total loss': 0.17436030597840674}
2023-01-05 03:54:07,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:07,283 INFO:     Epoch: 90
2023-01-05 03:54:09,123 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5213537474473318, 'Total loss': 0.5213537474473318} | train loss {'Reaction outcome loss': 0.17385631161707923, 'Total loss': 0.17385631161707923}
2023-01-05 03:54:09,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:09,124 INFO:     Epoch: 91
2023-01-05 03:54:10,972 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47499008824427924, 'Total loss': 0.47499008824427924} | train loss {'Reaction outcome loss': 0.17553163214797413, 'Total loss': 0.17553163214797413}
2023-01-05 03:54:10,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:10,972 INFO:     Epoch: 92
2023-01-05 03:54:13,099 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5035722295443217, 'Total loss': 0.5035722295443217} | train loss {'Reaction outcome loss': 0.1678811987848395, 'Total loss': 0.1678811987848395}
2023-01-05 03:54:13,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:13,100 INFO:     Epoch: 93
2023-01-05 03:54:15,346 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4967782576878866, 'Total loss': 0.4967782576878866} | train loss {'Reaction outcome loss': 0.18044779782972034, 'Total loss': 0.18044779782972034}
2023-01-05 03:54:15,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:15,347 INFO:     Epoch: 94
2023-01-05 03:54:17,579 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49957933127880094, 'Total loss': 0.49957933127880094} | train loss {'Reaction outcome loss': 0.1752435816213978, 'Total loss': 0.1752435816213978}
2023-01-05 03:54:17,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:17,579 INFO:     Epoch: 95
2023-01-05 03:54:19,765 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5331516226132711, 'Total loss': 0.5331516226132711} | train loss {'Reaction outcome loss': 0.17073075391392964, 'Total loss': 0.17073075391392964}
2023-01-05 03:54:19,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:19,766 INFO:     Epoch: 96
2023-01-05 03:54:21,829 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4673298999822388, 'Total loss': 0.4673298999822388} | train loss {'Reaction outcome loss': 0.17003682200341438, 'Total loss': 0.17003682200341438}
2023-01-05 03:54:21,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:21,829 INFO:     Epoch: 97
2023-01-05 03:54:24,044 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4544696912790338, 'Total loss': 0.4544696912790338} | train loss {'Reaction outcome loss': 0.17185447283809746, 'Total loss': 0.17185447283809746}
2023-01-05 03:54:24,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:24,045 INFO:     Epoch: 98
2023-01-05 03:54:26,281 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49856922527154285, 'Total loss': 0.49856922527154285} | train loss {'Reaction outcome loss': 0.16986589911087913, 'Total loss': 0.16986589911087913}
2023-01-05 03:54:26,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:26,282 INFO:     Epoch: 99
2023-01-05 03:54:28,508 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5126369257767995, 'Total loss': 0.5126369257767995} | train loss {'Reaction outcome loss': 0.16832830365679233, 'Total loss': 0.16832830365679233}
2023-01-05 03:54:28,509 INFO:     Best model found after epoch 13 of 100.
2023-01-05 03:54:28,509 INFO:   Done with stage: TRAINING
2023-01-05 03:54:28,509 INFO:   Starting stage: EVALUATION
2023-01-05 03:54:28,649 INFO:   Done with stage: EVALUATION
2023-01-05 03:54:28,649 INFO:   Leaving out SEQ value Fold_9
2023-01-05 03:54:28,662 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 03:54:28,662 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:54:29,307 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:54:29,307 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:54:29,376 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:54:29,376 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:54:29,377 INFO:     No hyperparam tuning for this model
2023-01-05 03:54:29,377 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:54:29,377 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:54:29,377 INFO:     None feature selector for col prot
2023-01-05 03:54:29,378 INFO:     None feature selector for col prot
2023-01-05 03:54:29,378 INFO:     None feature selector for col prot
2023-01-05 03:54:29,378 INFO:     None feature selector for col chem
2023-01-05 03:54:29,378 INFO:     None feature selector for col chem
2023-01-05 03:54:29,378 INFO:     None feature selector for col chem
2023-01-05 03:54:29,378 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:54:29,378 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:54:29,380 INFO:     Number of params in model 72931
2023-01-05 03:54:29,383 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:54:29,383 INFO:   Starting stage: TRAINING
2023-01-05 03:54:29,443 INFO:     Val loss before train {'Reaction outcome loss': 1.0596318324406941, 'Total loss': 1.0596318324406941}
2023-01-05 03:54:29,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:29,443 INFO:     Epoch: 0
2023-01-05 03:54:31,669 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7915038188298543, 'Total loss': 0.7915038188298543} | train loss {'Reaction outcome loss': 0.9325873312958772, 'Total loss': 0.9325873312958772}
2023-01-05 03:54:31,669 INFO:     Found new best model at epoch 0
2023-01-05 03:54:31,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:31,670 INFO:     Epoch: 1
2023-01-05 03:54:33,838 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6276014069716136, 'Total loss': 0.6276014069716136} | train loss {'Reaction outcome loss': 0.6283967341093913, 'Total loss': 0.6283967341093913}
2023-01-05 03:54:33,838 INFO:     Found new best model at epoch 1
2023-01-05 03:54:33,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:33,840 INFO:     Epoch: 2
2023-01-05 03:54:36,049 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5782465656598409, 'Total loss': 0.5782465656598409} | train loss {'Reaction outcome loss': 0.5399772640582565, 'Total loss': 0.5399772640582565}
2023-01-05 03:54:36,049 INFO:     Found new best model at epoch 2
2023-01-05 03:54:36,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:36,050 INFO:     Epoch: 3
2023-01-05 03:54:38,311 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.562001555164655, 'Total loss': 0.562001555164655} | train loss {'Reaction outcome loss': 0.5054957595100438, 'Total loss': 0.5054957595100438}
2023-01-05 03:54:38,312 INFO:     Found new best model at epoch 3
2023-01-05 03:54:38,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:38,314 INFO:     Epoch: 4
2023-01-05 03:54:40,577 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5439620594183604, 'Total loss': 0.5439620594183604} | train loss {'Reaction outcome loss': 0.47696633627671964, 'Total loss': 0.47696633627671964}
2023-01-05 03:54:40,577 INFO:     Found new best model at epoch 4
2023-01-05 03:54:40,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:40,579 INFO:     Epoch: 5
2023-01-05 03:54:42,818 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5121973335742951, 'Total loss': 0.5121973335742951} | train loss {'Reaction outcome loss': 0.44890564767157903, 'Total loss': 0.44890564767157903}
2023-01-05 03:54:42,818 INFO:     Found new best model at epoch 5
2023-01-05 03:54:42,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:42,819 INFO:     Epoch: 6
2023-01-05 03:54:45,073 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4848095407088598, 'Total loss': 0.4848095407088598} | train loss {'Reaction outcome loss': 0.4414239520126063, 'Total loss': 0.4414239520126063}
2023-01-05 03:54:45,074 INFO:     Found new best model at epoch 6
2023-01-05 03:54:45,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:45,075 INFO:     Epoch: 7
2023-01-05 03:54:47,233 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48725185096263884, 'Total loss': 0.48725185096263884} | train loss {'Reaction outcome loss': 0.42481093186939106, 'Total loss': 0.42481093186939106}
2023-01-05 03:54:47,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:47,233 INFO:     Epoch: 8
2023-01-05 03:54:49,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48161369959513345, 'Total loss': 0.48161369959513345} | train loss {'Reaction outcome loss': 0.4071029170805243, 'Total loss': 0.4071029170805243}
2023-01-05 03:54:49,470 INFO:     Found new best model at epoch 8
2023-01-05 03:54:49,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:49,471 INFO:     Epoch: 9
2023-01-05 03:54:51,695 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4723760565121969, 'Total loss': 0.4723760565121969} | train loss {'Reaction outcome loss': 0.3923670158222102, 'Total loss': 0.3923670158222102}
2023-01-05 03:54:51,695 INFO:     Found new best model at epoch 9
2023-01-05 03:54:51,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:51,697 INFO:     Epoch: 10
2023-01-05 03:54:53,941 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45567541221777597, 'Total loss': 0.45567541221777597} | train loss {'Reaction outcome loss': 0.3859329643875252, 'Total loss': 0.3859329643875252}
2023-01-05 03:54:53,941 INFO:     Found new best model at epoch 10
2023-01-05 03:54:53,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:53,943 INFO:     Epoch: 11
2023-01-05 03:54:56,182 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49456491669019065, 'Total loss': 0.49456491669019065} | train loss {'Reaction outcome loss': 0.369372334959748, 'Total loss': 0.369372334959748}
2023-01-05 03:54:56,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:56,182 INFO:     Epoch: 12
2023-01-05 03:54:58,425 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4636420746644338, 'Total loss': 0.4636420746644338} | train loss {'Reaction outcome loss': 0.3604557075659218, 'Total loss': 0.3604557075659218}
2023-01-05 03:54:58,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:54:58,426 INFO:     Epoch: 13
2023-01-05 03:55:00,618 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48047801355520886, 'Total loss': 0.48047801355520886} | train loss {'Reaction outcome loss': 0.35008167736405216, 'Total loss': 0.35008167736405216}
2023-01-05 03:55:00,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:00,618 INFO:     Epoch: 14
2023-01-05 03:55:02,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4783934464057287, 'Total loss': 0.4783934464057287} | train loss {'Reaction outcome loss': 0.3449886002393517, 'Total loss': 0.3449886002393517}
2023-01-05 03:55:02,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:02,873 INFO:     Epoch: 15
2023-01-05 03:55:05,136 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4555811430017153, 'Total loss': 0.4555811430017153} | train loss {'Reaction outcome loss': 0.33447482082250435, 'Total loss': 0.33447482082250435}
2023-01-05 03:55:05,136 INFO:     Found new best model at epoch 15
2023-01-05 03:55:05,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:05,138 INFO:     Epoch: 16
2023-01-05 03:55:07,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4447129209836324, 'Total loss': 0.4447129209836324} | train loss {'Reaction outcome loss': 0.3262554986277541, 'Total loss': 0.3262554986277541}
2023-01-05 03:55:07,380 INFO:     Found new best model at epoch 16
2023-01-05 03:55:07,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:07,381 INFO:     Epoch: 17
2023-01-05 03:55:09,630 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45028440753618876, 'Total loss': 0.45028440753618876} | train loss {'Reaction outcome loss': 0.3207646876226004, 'Total loss': 0.3207646876226004}
2023-01-05 03:55:09,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:09,630 INFO:     Epoch: 18
2023-01-05 03:55:11,909 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4794986834128698, 'Total loss': 0.4794986834128698} | train loss {'Reaction outcome loss': 0.31937470646031824, 'Total loss': 0.31937470646031824}
2023-01-05 03:55:11,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:11,910 INFO:     Epoch: 19
2023-01-05 03:55:14,180 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4416857788960139, 'Total loss': 0.4416857788960139} | train loss {'Reaction outcome loss': 0.3085683401086894, 'Total loss': 0.3085683401086894}
2023-01-05 03:55:14,180 INFO:     Found new best model at epoch 19
2023-01-05 03:55:14,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:14,182 INFO:     Epoch: 20
2023-01-05 03:55:16,437 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4709494729836782, 'Total loss': 0.4709494729836782} | train loss {'Reaction outcome loss': 0.30549459512500715, 'Total loss': 0.30549459512500715}
2023-01-05 03:55:16,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:16,438 INFO:     Epoch: 21
2023-01-05 03:55:18,680 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4589908997217814, 'Total loss': 0.4589908997217814} | train loss {'Reaction outcome loss': 0.29944873398736765, 'Total loss': 0.29944873398736765}
2023-01-05 03:55:18,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:18,680 INFO:     Epoch: 22
2023-01-05 03:55:20,923 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46928810675938926, 'Total loss': 0.46928810675938926} | train loss {'Reaction outcome loss': 0.29711319942472747, 'Total loss': 0.29711319942472747}
2023-01-05 03:55:20,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:20,923 INFO:     Epoch: 23
2023-01-05 03:55:23,190 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49333444933096565, 'Total loss': 0.49333444933096565} | train loss {'Reaction outcome loss': 0.28657002372589585, 'Total loss': 0.28657002372589585}
2023-01-05 03:55:23,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:23,191 INFO:     Epoch: 24
2023-01-05 03:55:25,440 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46265007853507994, 'Total loss': 0.46265007853507994} | train loss {'Reaction outcome loss': 0.29526277269790135, 'Total loss': 0.29526277269790135}
2023-01-05 03:55:25,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:25,440 INFO:     Epoch: 25
2023-01-05 03:55:27,706 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4529723823070526, 'Total loss': 0.4529723823070526} | train loss {'Reaction outcome loss': 0.29482169582616485, 'Total loss': 0.29482169582616485}
2023-01-05 03:55:27,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:27,707 INFO:     Epoch: 26
2023-01-05 03:55:29,958 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4460920711358388, 'Total loss': 0.4460920711358388} | train loss {'Reaction outcome loss': 0.2736956785176543, 'Total loss': 0.2736956785176543}
2023-01-05 03:55:29,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:29,959 INFO:     Epoch: 27
2023-01-05 03:55:32,220 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4537109891573588, 'Total loss': 0.4537109891573588} | train loss {'Reaction outcome loss': 0.2676987823610746, 'Total loss': 0.2676987823610746}
2023-01-05 03:55:32,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:32,220 INFO:     Epoch: 28
2023-01-05 03:55:34,468 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4436571935812632, 'Total loss': 0.4436571935812632} | train loss {'Reaction outcome loss': 0.2655744280478836, 'Total loss': 0.2655744280478836}
2023-01-05 03:55:34,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:34,469 INFO:     Epoch: 29
2023-01-05 03:55:36,718 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46183837155501045, 'Total loss': 0.46183837155501045} | train loss {'Reaction outcome loss': 0.28766616100472386, 'Total loss': 0.28766616100472386}
2023-01-05 03:55:36,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:36,718 INFO:     Epoch: 30
2023-01-05 03:55:38,971 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44356443534294765, 'Total loss': 0.44356443534294765} | train loss {'Reaction outcome loss': 0.25748639470101264, 'Total loss': 0.25748639470101264}
2023-01-05 03:55:38,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:38,972 INFO:     Epoch: 31
2023-01-05 03:55:41,216 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4640179534753164, 'Total loss': 0.4640179534753164} | train loss {'Reaction outcome loss': 0.25350944278761744, 'Total loss': 0.25350944278761744}
2023-01-05 03:55:41,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:41,216 INFO:     Epoch: 32
2023-01-05 03:55:43,464 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46352894405523937, 'Total loss': 0.46352894405523937} | train loss {'Reaction outcome loss': 0.2524604428035673, 'Total loss': 0.2524604428035673}
2023-01-05 03:55:43,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:43,465 INFO:     Epoch: 33
2023-01-05 03:55:45,705 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4531354049841563, 'Total loss': 0.4531354049841563} | train loss {'Reaction outcome loss': 0.2453660128850733, 'Total loss': 0.2453660128850733}
2023-01-05 03:55:45,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:45,706 INFO:     Epoch: 34
2023-01-05 03:55:47,968 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42779952933390936, 'Total loss': 0.42779952933390936} | train loss {'Reaction outcome loss': 0.24428518512286246, 'Total loss': 0.24428518512286246}
2023-01-05 03:55:47,969 INFO:     Found new best model at epoch 34
2023-01-05 03:55:47,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:47,970 INFO:     Epoch: 35
2023-01-05 03:55:50,223 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4766453782717387, 'Total loss': 0.4766453782717387} | train loss {'Reaction outcome loss': 0.24492157175057178, 'Total loss': 0.24492157175057178}
2023-01-05 03:55:50,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:50,224 INFO:     Epoch: 36
2023-01-05 03:55:52,484 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4801392376422882, 'Total loss': 0.4801392376422882} | train loss {'Reaction outcome loss': 0.24285491594481215, 'Total loss': 0.24285491594481215}
2023-01-05 03:55:52,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:52,484 INFO:     Epoch: 37
2023-01-05 03:55:54,715 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47744428912798564, 'Total loss': 0.47744428912798564} | train loss {'Reaction outcome loss': 0.2396613159486889, 'Total loss': 0.2396613159486889}
2023-01-05 03:55:54,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:54,716 INFO:     Epoch: 38
2023-01-05 03:55:56,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5107812662919362, 'Total loss': 0.5107812662919362} | train loss {'Reaction outcome loss': 0.24381271714641564, 'Total loss': 0.24381271714641564}
2023-01-05 03:55:56,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:56,972 INFO:     Epoch: 39
2023-01-05 03:55:59,241 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4827922542889913, 'Total loss': 0.4827922542889913} | train loss {'Reaction outcome loss': 0.23474654799624198, 'Total loss': 0.23474654799624198}
2023-01-05 03:55:59,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:55:59,242 INFO:     Epoch: 40
2023-01-05 03:56:01,507 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46673262283826866, 'Total loss': 0.46673262283826866} | train loss {'Reaction outcome loss': 0.22666042951354082, 'Total loss': 0.22666042951354082}
2023-01-05 03:56:01,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:01,508 INFO:     Epoch: 41
2023-01-05 03:56:03,767 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47568186521530154, 'Total loss': 0.47568186521530154} | train loss {'Reaction outcome loss': 0.22754126917441128, 'Total loss': 0.22754126917441128}
2023-01-05 03:56:03,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:03,768 INFO:     Epoch: 42
2023-01-05 03:56:06,015 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4836808691422145, 'Total loss': 0.4836808691422145} | train loss {'Reaction outcome loss': 0.22362907759278364, 'Total loss': 0.22362907759278364}
2023-01-05 03:56:06,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:06,015 INFO:     Epoch: 43
2023-01-05 03:56:08,261 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4716745376586914, 'Total loss': 0.4716745376586914} | train loss {'Reaction outcome loss': 0.23189450667131747, 'Total loss': 0.23189450667131747}
2023-01-05 03:56:08,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:08,261 INFO:     Epoch: 44
2023-01-05 03:56:10,533 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4713207562764486, 'Total loss': 0.4713207562764486} | train loss {'Reaction outcome loss': 0.21749931835886632, 'Total loss': 0.21749931835886632}
2023-01-05 03:56:10,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:10,533 INFO:     Epoch: 45
2023-01-05 03:56:12,796 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48153398633003236, 'Total loss': 0.48153398633003236} | train loss {'Reaction outcome loss': 0.21396667303085543, 'Total loss': 0.21396667303085543}
2023-01-05 03:56:12,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:12,796 INFO:     Epoch: 46
2023-01-05 03:56:15,093 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4812423686186473, 'Total loss': 0.4812423686186473} | train loss {'Reaction outcome loss': 0.21810410570427505, 'Total loss': 0.21810410570427505}
2023-01-05 03:56:15,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:15,094 INFO:     Epoch: 47
2023-01-05 03:56:17,295 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.489711915453275, 'Total loss': 0.489711915453275} | train loss {'Reaction outcome loss': 0.21365891893704733, 'Total loss': 0.21365891893704733}
2023-01-05 03:56:17,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:17,296 INFO:     Epoch: 48
2023-01-05 03:56:19,520 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48229633768399555, 'Total loss': 0.48229633768399555} | train loss {'Reaction outcome loss': 0.22291706629988292, 'Total loss': 0.22291706629988292}
2023-01-05 03:56:19,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:19,521 INFO:     Epoch: 49
2023-01-05 03:56:21,749 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49012683431307474, 'Total loss': 0.49012683431307474} | train loss {'Reaction outcome loss': 0.21368960010569435, 'Total loss': 0.21368960010569435}
2023-01-05 03:56:21,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:21,749 INFO:     Epoch: 50
2023-01-05 03:56:23,985 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4847823272148768, 'Total loss': 0.4847823272148768} | train loss {'Reaction outcome loss': 0.21001069636324668, 'Total loss': 0.21001069636324668}
2023-01-05 03:56:23,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:23,986 INFO:     Epoch: 51
2023-01-05 03:56:26,229 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49864229212204614, 'Total loss': 0.49864229212204614} | train loss {'Reaction outcome loss': 0.2055487203128312, 'Total loss': 0.2055487203128312}
2023-01-05 03:56:26,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:26,230 INFO:     Epoch: 52
2023-01-05 03:56:28,469 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5107325712839762, 'Total loss': 0.5107325712839762} | train loss {'Reaction outcome loss': 0.20236429788992213, 'Total loss': 0.20236429788992213}
2023-01-05 03:56:28,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:28,470 INFO:     Epoch: 53
2023-01-05 03:56:30,686 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5238223095734914, 'Total loss': 0.5238223095734914} | train loss {'Reaction outcome loss': 0.20412242850811774, 'Total loss': 0.20412242850811774}
2023-01-05 03:56:30,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:30,686 INFO:     Epoch: 54
2023-01-05 03:56:32,969 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5083573405941327, 'Total loss': 0.5083573405941327} | train loss {'Reaction outcome loss': 0.20645812578920636, 'Total loss': 0.20645812578920636}
2023-01-05 03:56:32,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:32,970 INFO:     Epoch: 55
2023-01-05 03:56:35,222 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5223375846942265, 'Total loss': 0.5223375846942265} | train loss {'Reaction outcome loss': 0.19810914054985576, 'Total loss': 0.19810914054985576}
2023-01-05 03:56:35,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:35,222 INFO:     Epoch: 56
2023-01-05 03:56:37,420 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4912146379550298, 'Total loss': 0.4912146379550298} | train loss {'Reaction outcome loss': 0.20028540919272506, 'Total loss': 0.20028540919272506}
2023-01-05 03:56:37,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:37,420 INFO:     Epoch: 57
2023-01-05 03:56:39,666 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4641178255900741, 'Total loss': 0.4641178255900741} | train loss {'Reaction outcome loss': 0.20092772477832826, 'Total loss': 0.20092772477832826}
2023-01-05 03:56:39,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:39,666 INFO:     Epoch: 58
2023-01-05 03:56:41,853 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4879859964052836, 'Total loss': 0.4879859964052836} | train loss {'Reaction outcome loss': 0.19807049326693127, 'Total loss': 0.19807049326693127}
2023-01-05 03:56:41,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:41,853 INFO:     Epoch: 59
2023-01-05 03:56:44,073 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49103932281335194, 'Total loss': 0.49103932281335194} | train loss {'Reaction outcome loss': 0.19141853618624527, 'Total loss': 0.19141853618624527}
2023-01-05 03:56:44,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:44,073 INFO:     Epoch: 60
2023-01-05 03:56:46,293 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48488487899303434, 'Total loss': 0.48488487899303434} | train loss {'Reaction outcome loss': 0.1926435136784833, 'Total loss': 0.1926435136784833}
2023-01-05 03:56:46,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:46,293 INFO:     Epoch: 61
2023-01-05 03:56:48,506 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5092467894156774, 'Total loss': 0.5092467894156774} | train loss {'Reaction outcome loss': 0.1912331925333896, 'Total loss': 0.1912331925333896}
2023-01-05 03:56:48,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:48,506 INFO:     Epoch: 62
2023-01-05 03:56:50,754 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5136387010415395, 'Total loss': 0.5136387010415395} | train loss {'Reaction outcome loss': 0.19389566645469936, 'Total loss': 0.19389566645469936}
2023-01-05 03:56:50,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:50,754 INFO:     Epoch: 63
2023-01-05 03:56:52,980 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49077196419239044, 'Total loss': 0.49077196419239044} | train loss {'Reaction outcome loss': 0.18920364917974677, 'Total loss': 0.18920364917974677}
2023-01-05 03:56:52,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:52,980 INFO:     Epoch: 64
2023-01-05 03:56:55,183 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47253558337688445, 'Total loss': 0.47253558337688445} | train loss {'Reaction outcome loss': 0.18724189423222054, 'Total loss': 0.18724189423222054}
2023-01-05 03:56:55,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:55,184 INFO:     Epoch: 65
2023-01-05 03:56:57,373 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4552148739496867, 'Total loss': 0.4552148739496867} | train loss {'Reaction outcome loss': 0.18701732739609198, 'Total loss': 0.18701732739609198}
2023-01-05 03:56:57,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:57,373 INFO:     Epoch: 66
2023-01-05 03:56:59,618 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4962409108877182, 'Total loss': 0.4962409108877182} | train loss {'Reaction outcome loss': 0.18868798859994454, 'Total loss': 0.18868798859994454}
2023-01-05 03:56:59,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:56:59,618 INFO:     Epoch: 67
2023-01-05 03:57:01,803 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47760049005349475, 'Total loss': 0.47760049005349475} | train loss {'Reaction outcome loss': 0.18855355902021562, 'Total loss': 0.18855355902021562}
2023-01-05 03:57:01,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:01,804 INFO:     Epoch: 68
2023-01-05 03:57:04,032 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4680456062157949, 'Total loss': 0.4680456062157949} | train loss {'Reaction outcome loss': 0.18320420119903577, 'Total loss': 0.18320420119903577}
2023-01-05 03:57:04,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:04,033 INFO:     Epoch: 69
2023-01-05 03:57:06,242 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48853802879651387, 'Total loss': 0.48853802879651387} | train loss {'Reaction outcome loss': 0.18166305701036606, 'Total loss': 0.18166305701036606}
2023-01-05 03:57:06,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:06,242 INFO:     Epoch: 70
2023-01-05 03:57:08,470 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5144804616769155, 'Total loss': 0.5144804616769155} | train loss {'Reaction outcome loss': 0.18857521937510077, 'Total loss': 0.18857521937510077}
2023-01-05 03:57:08,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:08,470 INFO:     Epoch: 71
2023-01-05 03:57:10,641 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5180123845736185, 'Total loss': 0.5180123845736185} | train loss {'Reaction outcome loss': 0.2044453011923537, 'Total loss': 0.2044453011923537}
2023-01-05 03:57:10,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:10,641 INFO:     Epoch: 72
2023-01-05 03:57:12,777 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48693667848904926, 'Total loss': 0.48693667848904926} | train loss {'Reaction outcome loss': 0.18286297436517102, 'Total loss': 0.18286297436517102}
2023-01-05 03:57:12,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:12,777 INFO:     Epoch: 73
2023-01-05 03:57:14,987 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4975949654976527, 'Total loss': 0.4975949654976527} | train loss {'Reaction outcome loss': 0.17622439232292125, 'Total loss': 0.17622439232292125}
2023-01-05 03:57:14,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:14,987 INFO:     Epoch: 74
2023-01-05 03:57:17,222 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4763483464717865, 'Total loss': 0.4763483464717865} | train loss {'Reaction outcome loss': 0.1794527479787839, 'Total loss': 0.1794527479787839}
2023-01-05 03:57:17,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:17,222 INFO:     Epoch: 75
2023-01-05 03:57:19,536 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5090429762999217, 'Total loss': 0.5090429762999217} | train loss {'Reaction outcome loss': 0.1820201222207802, 'Total loss': 0.1820201222207802}
2023-01-05 03:57:19,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:19,536 INFO:     Epoch: 76
2023-01-05 03:57:21,758 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48938108136256536, 'Total loss': 0.48938108136256536} | train loss {'Reaction outcome loss': 0.18128883430018913, 'Total loss': 0.18128883430018913}
2023-01-05 03:57:21,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:21,759 INFO:     Epoch: 77
2023-01-05 03:57:23,946 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49257616996765136, 'Total loss': 0.49257616996765136} | train loss {'Reaction outcome loss': 0.22609424792682292, 'Total loss': 0.22609424792682292}
2023-01-05 03:57:23,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:23,946 INFO:     Epoch: 78
2023-01-05 03:57:26,075 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5403389732042948, 'Total loss': 0.5403389732042948} | train loss {'Reaction outcome loss': 0.1821251459811153, 'Total loss': 0.1821251459811153}
2023-01-05 03:57:26,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:26,075 INFO:     Epoch: 79
2023-01-05 03:57:28,262 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5053448654866467, 'Total loss': 0.5053448654866467} | train loss {'Reaction outcome loss': 0.19584221670416097, 'Total loss': 0.19584221670416097}
2023-01-05 03:57:28,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:28,262 INFO:     Epoch: 80
2023-01-05 03:57:30,482 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.527484580874443, 'Total loss': 0.527484580874443} | train loss {'Reaction outcome loss': 0.17817520003840057, 'Total loss': 0.17817520003840057}
2023-01-05 03:57:30,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:30,483 INFO:     Epoch: 81
2023-01-05 03:57:32,733 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5125380535920461, 'Total loss': 0.5125380535920461} | train loss {'Reaction outcome loss': 0.172160815911543, 'Total loss': 0.172160815911543}
2023-01-05 03:57:32,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:32,733 INFO:     Epoch: 82
2023-01-05 03:57:34,868 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5188071618477503, 'Total loss': 0.5188071618477503} | train loss {'Reaction outcome loss': 0.17300716530239763, 'Total loss': 0.17300716530239763}
2023-01-05 03:57:34,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:34,868 INFO:     Epoch: 83
2023-01-05 03:57:37,112 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5003328998883565, 'Total loss': 0.5003328998883565} | train loss {'Reaction outcome loss': 0.1725897902379865, 'Total loss': 0.1725897902379865}
2023-01-05 03:57:37,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:37,112 INFO:     Epoch: 84
2023-01-05 03:57:39,334 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49828518331050875, 'Total loss': 0.49828518331050875} | train loss {'Reaction outcome loss': 0.17112973722565136, 'Total loss': 0.17112973722565136}
2023-01-05 03:57:39,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:39,334 INFO:     Epoch: 85
2023-01-05 03:57:41,575 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4901037206252416, 'Total loss': 0.4901037206252416} | train loss {'Reaction outcome loss': 0.17468980733911335, 'Total loss': 0.17468980733911335}
2023-01-05 03:57:41,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:41,575 INFO:     Epoch: 86
2023-01-05 03:57:43,838 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5119933833678564, 'Total loss': 0.5119933833678564} | train loss {'Reaction outcome loss': 0.16915783775861518, 'Total loss': 0.16915783775861518}
2023-01-05 03:57:43,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:43,838 INFO:     Epoch: 87
2023-01-05 03:57:46,067 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4777692089478175, 'Total loss': 0.4777692089478175} | train loss {'Reaction outcome loss': 0.1752291327153427, 'Total loss': 0.1752291327153427}
2023-01-05 03:57:46,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:46,067 INFO:     Epoch: 88
2023-01-05 03:57:48,336 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4935340603192647, 'Total loss': 0.4935340603192647} | train loss {'Reaction outcome loss': 0.16827945485778584, 'Total loss': 0.16827945485778584}
2023-01-05 03:57:48,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:48,336 INFO:     Epoch: 89
2023-01-05 03:57:50,600 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5161040226618449, 'Total loss': 0.5161040226618449} | train loss {'Reaction outcome loss': 0.1702036157191775, 'Total loss': 0.1702036157191775}
2023-01-05 03:57:50,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:50,601 INFO:     Epoch: 90
2023-01-05 03:57:52,803 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4842454930146535, 'Total loss': 0.4842454930146535} | train loss {'Reaction outcome loss': 0.1670108131865677, 'Total loss': 0.1670108131865677}
2023-01-05 03:57:52,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:52,803 INFO:     Epoch: 91
2023-01-05 03:57:55,054 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5166656126578649, 'Total loss': 0.5166656126578649} | train loss {'Reaction outcome loss': 0.16661106002699683, 'Total loss': 0.16661106002699683}
2023-01-05 03:57:55,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:55,054 INFO:     Epoch: 92
2023-01-05 03:57:57,295 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5147204309701919, 'Total loss': 0.5147204309701919} | train loss {'Reaction outcome loss': 0.1687705176410036, 'Total loss': 0.1687705176410036}
2023-01-05 03:57:57,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:57,295 INFO:     Epoch: 93
2023-01-05 03:57:59,437 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5339389383792877, 'Total loss': 0.5339389383792877} | train loss {'Reaction outcome loss': 0.16200713839972866, 'Total loss': 0.16200713839972866}
2023-01-05 03:57:59,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:57:59,437 INFO:     Epoch: 94
2023-01-05 03:58:01,691 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5118977948712806, 'Total loss': 0.5118977948712806} | train loss {'Reaction outcome loss': 0.16989169402293794, 'Total loss': 0.16989169402293794}
2023-01-05 03:58:01,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:01,691 INFO:     Epoch: 95
2023-01-05 03:58:03,916 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5108007147908211, 'Total loss': 0.5108007147908211} | train loss {'Reaction outcome loss': 0.16664031619388814, 'Total loss': 0.16664031619388814}
2023-01-05 03:58:03,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:03,917 INFO:     Epoch: 96
2023-01-05 03:58:06,141 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5273640910784404, 'Total loss': 0.5273640910784404} | train loss {'Reaction outcome loss': 0.17359833265789718, 'Total loss': 0.17359833265789718}
2023-01-05 03:58:06,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:06,142 INFO:     Epoch: 97
2023-01-05 03:58:08,360 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5051550726095836, 'Total loss': 0.5051550726095836} | train loss {'Reaction outcome loss': 0.16549626691266894, 'Total loss': 0.16549626691266894}
2023-01-05 03:58:08,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:08,360 INFO:     Epoch: 98
2023-01-05 03:58:10,560 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5139303167661031, 'Total loss': 0.5139303167661031} | train loss {'Reaction outcome loss': 0.16342719335323705, 'Total loss': 0.16342719335323705}
2023-01-05 03:58:10,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:10,560 INFO:     Epoch: 99
2023-01-05 03:58:12,805 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5544238477945328, 'Total loss': 0.5544238477945328} | train loss {'Reaction outcome loss': 0.1682709509314536, 'Total loss': 0.1682709509314536}
2023-01-05 03:58:12,806 INFO:     Best model found after epoch 35 of 100.
2023-01-05 03:58:12,806 INFO:   Done with stage: TRAINING
2023-01-05 03:58:12,806 INFO:   Starting stage: EVALUATION
2023-01-05 03:58:12,941 INFO:   Done with stage: EVALUATION
2023-01-05 03:58:12,941 INFO: Done with stage: RUNNING SPLITS
2023-01-05 03:58:12,941 INFO: Starting stage: COMPUTE METRICS
2023-01-05 03:58:14,112 INFO: Done with stage: COMPUTE METRICS
2023-01-05 03:58:14,112 INFO: Starting stage: EXPORT RESULTS
2023-01-05 03:58:14,130 INFO:   Final results averaged over 50 folds: 
2023-01-05 03:58:14,133 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.163398           NaN  0.317146       NaN
2023-01-05 03:58:15,913 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 03:58:15,919 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 03:58:15,920 DEBUG:   interactive is False
2023-01-05 03:58:15,920 DEBUG:   platform is linux
2023-01-05 03:58:15,920 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 03:58:16,092 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 03:58:16,095 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 03:58:16,537 DEBUG:   Loaded backend agg version unknown.
2023-01-05 03:58:16,539 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 03:58:16,539 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,540 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,541 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,542 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,542 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 03:58:16,579 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,579 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,580 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,581 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,581 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 03:58:16,590 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 03:58:16,592 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,593 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,593 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 03:58:16,593 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 03:58:16,593 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 03:58:16,593 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 03:58:16,980 INFO: Done with stage: EXPORT RESULTS
2023-01-05 03:58:16,980 INFO: Starting stage: SAVE MODEL
2023-01-05 03:58:17,035 INFO: Done with stage: SAVE MODEL
2023-01-05 03:58:17,069 INFO: Wall time for program:  11152.36 seconds
