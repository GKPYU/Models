2023-01-04 01:09:35,915 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/f537efcb4358b601001f3077efa89dd1/2023_01_03-225547",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 01:09:35,923 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 01:09:35,925 INFO:   Creating esm representation model
2023-01-04 01:09:35,925 INFO:   Done esm representation model
2023-01-04 01:09:35,926 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 01:09:35,926 INFO: Starting stage: BUILDING DATASET
2023-01-04 01:09:35,979 INFO: Done with stage: BUILDING DATASET
2023-01-04 01:09:35,979 INFO: Starting stage: FEATURIZING DATA
2023-01-04 01:09:35,979 INFO:   Featurizing proteins
2023-01-04 01:09:35,981 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 01:09:35,985 INFO:   Loaded feature cache of size 489
2023-01-04 01:09:35,986 INFO:   Starting to pool ESM Embeddings
2023-01-04 01:09:36,089 INFO:   Featurizing molecules
2023-01-04 01:09:36,090 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 01:09:36,092 INFO:   Loaded feature cache of size 498
2023-01-04 01:09:37,434 INFO: Done with stage: FEATURIZING DATA
2023-01-04 01:09:37,434 INFO: Starting stage: RUNNING SPLITS
2023-01-04 01:09:37,443 INFO:   Leaving out SEQ value Fold_0
2023-01-04 01:09:37,457 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 01:09:37,457 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:09:38,113 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:09:38,113 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:09:38,180 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:09:38,180 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:09:38,180 INFO:     No hyperparam tuning for this model
2023-01-04 01:09:38,180 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:09:38,180 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:09:38,181 INFO:     None feature selector for col prot
2023-01-04 01:09:38,181 INFO:     None feature selector for col prot
2023-01-04 01:09:38,181 INFO:     None feature selector for col prot
2023-01-04 01:09:38,182 INFO:     None feature selector for col chem
2023-01-04 01:09:38,182 INFO:     None feature selector for col chem
2023-01-04 01:09:38,182 INFO:     None feature selector for col chem
2023-01-04 01:09:38,182 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:09:38,182 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:09:38,183 INFO:     Number of params in model 70141
2023-01-04 01:09:38,184 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:09:38,184 INFO:   Starting stage: TRAINING
2023-01-04 01:09:39,788 INFO:     Val loss before train {'Reaction outcome loss': 1.1259175817171732, 'Total loss': 1.1259175817171732}
2023-01-04 01:09:39,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:39,789 INFO:     Epoch: 0
2023-01-04 01:09:41,386 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7525273005167643, 'Total loss': 0.7525273005167643} | train loss {'Reaction outcome loss': 0.8423777173508654, 'Total loss': 0.8423777173508654}
2023-01-04 01:09:41,386 INFO:     Found new best model at epoch 0
2023-01-04 01:09:41,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:41,387 INFO:     Epoch: 1
2023-01-04 01:09:42,997 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.592026553551356, 'Total loss': 0.592026553551356} | train loss {'Reaction outcome loss': 0.619023574468417, 'Total loss': 0.619023574468417}
2023-01-04 01:09:42,997 INFO:     Found new best model at epoch 1
2023-01-04 01:09:42,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:42,998 INFO:     Epoch: 2
2023-01-04 01:09:44,595 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5511041104793548, 'Total loss': 0.5511041104793548} | train loss {'Reaction outcome loss': 0.5365485904581381, 'Total loss': 0.5365485904581381}
2023-01-04 01:09:44,595 INFO:     Found new best model at epoch 2
2023-01-04 01:09:44,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:44,596 INFO:     Epoch: 3
2023-01-04 01:09:46,180 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5163094600041708, 'Total loss': 0.5163094600041708} | train loss {'Reaction outcome loss': 0.4992529413638971, 'Total loss': 0.4992529413638971}
2023-01-04 01:09:46,180 INFO:     Found new best model at epoch 3
2023-01-04 01:09:46,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:46,181 INFO:     Epoch: 4
2023-01-04 01:09:47,759 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5358104626337687, 'Total loss': 0.5358104626337687} | train loss {'Reaction outcome loss': 0.47377707358900006, 'Total loss': 0.47377707358900006}
2023-01-04 01:09:47,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:47,759 INFO:     Epoch: 5
2023-01-04 01:09:49,343 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5071283638477325, 'Total loss': 0.5071283638477325} | train loss {'Reaction outcome loss': 0.45168062895809336, 'Total loss': 0.45168062895809336}
2023-01-04 01:09:49,343 INFO:     Found new best model at epoch 5
2023-01-04 01:09:49,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:49,344 INFO:     Epoch: 6
2023-01-04 01:09:50,928 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.495625501871109, 'Total loss': 0.495625501871109} | train loss {'Reaction outcome loss': 0.436143907216879, 'Total loss': 0.436143907216879}
2023-01-04 01:09:50,928 INFO:     Found new best model at epoch 6
2023-01-04 01:09:50,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:50,929 INFO:     Epoch: 7
2023-01-04 01:09:52,511 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5285304665565491, 'Total loss': 0.5285304665565491} | train loss {'Reaction outcome loss': 0.42218298225530554, 'Total loss': 0.42218298225530554}
2023-01-04 01:09:52,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:52,512 INFO:     Epoch: 8
2023-01-04 01:09:54,077 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49308855334917706, 'Total loss': 0.49308855334917706} | train loss {'Reaction outcome loss': 0.4093750164103814, 'Total loss': 0.4093750164103814}
2023-01-04 01:09:54,077 INFO:     Found new best model at epoch 8
2023-01-04 01:09:54,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:54,078 INFO:     Epoch: 9
2023-01-04 01:09:55,691 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49883042375246683, 'Total loss': 0.49883042375246683} | train loss {'Reaction outcome loss': 0.39842896305379416, 'Total loss': 0.39842896305379416}
2023-01-04 01:09:55,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:55,691 INFO:     Epoch: 10
2023-01-04 01:09:57,258 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5145668471852939, 'Total loss': 0.5145668471852939} | train loss {'Reaction outcome loss': 0.38979647229442665, 'Total loss': 0.38979647229442665}
2023-01-04 01:09:57,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:57,258 INFO:     Epoch: 11
2023-01-04 01:09:58,856 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5075765391190846, 'Total loss': 0.5075765391190846} | train loss {'Reaction outcome loss': 0.381043037379181, 'Total loss': 0.381043037379181}
2023-01-04 01:09:58,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:58,857 INFO:     Epoch: 12
2023-01-04 01:10:00,464 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48115174372990926, 'Total loss': 0.48115174372990926} | train loss {'Reaction outcome loss': 0.37089922636638195, 'Total loss': 0.37089922636638195}
2023-01-04 01:10:00,464 INFO:     Found new best model at epoch 12
2023-01-04 01:10:00,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:00,465 INFO:     Epoch: 13
2023-01-04 01:10:02,062 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4785490890343984, 'Total loss': 0.4785490890343984} | train loss {'Reaction outcome loss': 0.3635410439673361, 'Total loss': 0.3635410439673361}
2023-01-04 01:10:02,062 INFO:     Found new best model at epoch 13
2023-01-04 01:10:02,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:02,063 INFO:     Epoch: 14
2023-01-04 01:10:03,634 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.482304980357488, 'Total loss': 0.482304980357488} | train loss {'Reaction outcome loss': 0.35924977440755446, 'Total loss': 0.35924977440755446}
2023-01-04 01:10:03,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:03,634 INFO:     Epoch: 15
2023-01-04 01:10:05,220 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49115638534228007, 'Total loss': 0.49115638534228007} | train loss {'Reaction outcome loss': 0.34732268821625484, 'Total loss': 0.34732268821625484}
2023-01-04 01:10:05,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:05,220 INFO:     Epoch: 16
2023-01-04 01:10:06,447 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4645483622948329, 'Total loss': 0.4645483622948329} | train loss {'Reaction outcome loss': 0.3391260808477035, 'Total loss': 0.3391260808477035}
2023-01-04 01:10:06,447 INFO:     Found new best model at epoch 16
2023-01-04 01:10:06,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:06,448 INFO:     Epoch: 17
2023-01-04 01:10:07,515 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46386107405026755, 'Total loss': 0.46386107405026755} | train loss {'Reaction outcome loss': 0.33548985176034024, 'Total loss': 0.33548985176034024}
2023-01-04 01:10:07,515 INFO:     Found new best model at epoch 17
2023-01-04 01:10:07,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:07,516 INFO:     Epoch: 18
2023-01-04 01:10:08,577 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4838428795337677, 'Total loss': 0.4838428795337677} | train loss {'Reaction outcome loss': 0.3294501896033357, 'Total loss': 0.3294501896033357}
2023-01-04 01:10:08,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:08,577 INFO:     Epoch: 19
2023-01-04 01:10:09,637 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49939536849657695, 'Total loss': 0.49939536849657695} | train loss {'Reaction outcome loss': 0.31991409034137325, 'Total loss': 0.31991409034137325}
2023-01-04 01:10:09,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:09,638 INFO:     Epoch: 20
2023-01-04 01:10:11,135 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46500630875428517, 'Total loss': 0.46500630875428517} | train loss {'Reaction outcome loss': 0.316398116285766, 'Total loss': 0.316398116285766}
2023-01-04 01:10:11,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:11,136 INFO:     Epoch: 21
2023-01-04 01:10:12,736 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4876840949058533, 'Total loss': 0.4876840949058533} | train loss {'Reaction outcome loss': 0.3109742543308726, 'Total loss': 0.3109742543308726}
2023-01-04 01:10:12,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:12,736 INFO:     Epoch: 22
2023-01-04 01:10:14,343 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4973500291506449, 'Total loss': 0.4973500291506449} | train loss {'Reaction outcome loss': 0.3071214482734055, 'Total loss': 0.3071214482734055}
2023-01-04 01:10:14,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:14,344 INFO:     Epoch: 23
2023-01-04 01:10:15,948 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4909368018309275, 'Total loss': 0.4909368018309275} | train loss {'Reaction outcome loss': 0.30097447625010004, 'Total loss': 0.30097447625010004}
2023-01-04 01:10:15,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:15,949 INFO:     Epoch: 24
2023-01-04 01:10:17,546 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4922667404015859, 'Total loss': 0.4922667404015859} | train loss {'Reaction outcome loss': 0.2950206588366966, 'Total loss': 0.2950206588366966}
2023-01-04 01:10:17,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:17,546 INFO:     Epoch: 25
2023-01-04 01:10:19,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4635139226913452, 'Total loss': 0.4635139226913452} | train loss {'Reaction outcome loss': 0.28875380246848853, 'Total loss': 0.28875380246848853}
2023-01-04 01:10:19,083 INFO:     Found new best model at epoch 25
2023-01-04 01:10:19,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:19,084 INFO:     Epoch: 26
2023-01-04 01:10:20,694 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.528020171324412, 'Total loss': 0.528020171324412} | train loss {'Reaction outcome loss': 0.2823398181206577, 'Total loss': 0.2823398181206577}
2023-01-04 01:10:20,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:20,694 INFO:     Epoch: 27
2023-01-04 01:10:22,306 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47193082769711814, 'Total loss': 0.47193082769711814} | train loss {'Reaction outcome loss': 0.28066867614512914, 'Total loss': 0.28066867614512914}
2023-01-04 01:10:22,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:22,306 INFO:     Epoch: 28
2023-01-04 01:10:23,880 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4800571362177531, 'Total loss': 0.4800571362177531} | train loss {'Reaction outcome loss': 0.2787420439086991, 'Total loss': 0.2787420439086991}
2023-01-04 01:10:23,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:23,880 INFO:     Epoch: 29
2023-01-04 01:10:25,481 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4841727589567502, 'Total loss': 0.4841727589567502} | train loss {'Reaction outcome loss': 0.2735904220478002, 'Total loss': 0.2735904220478002}
2023-01-04 01:10:25,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:25,482 INFO:     Epoch: 30
2023-01-04 01:10:27,078 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4926019191741943, 'Total loss': 0.4926019191741943} | train loss {'Reaction outcome loss': 0.269446122777331, 'Total loss': 0.269446122777331}
2023-01-04 01:10:27,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:27,078 INFO:     Epoch: 31
2023-01-04 01:10:28,642 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47951512535413104, 'Total loss': 0.47951512535413104} | train loss {'Reaction outcome loss': 0.26649775053118613, 'Total loss': 0.26649775053118613}
2023-01-04 01:10:28,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:28,643 INFO:     Epoch: 32
2023-01-04 01:10:30,231 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48273530999819436, 'Total loss': 0.48273530999819436} | train loss {'Reaction outcome loss': 0.26383192946404327, 'Total loss': 0.26383192946404327}
2023-01-04 01:10:30,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:30,231 INFO:     Epoch: 33
2023-01-04 01:10:31,842 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46126417418320975, 'Total loss': 0.46126417418320975} | train loss {'Reaction outcome loss': 0.25982225577145707, 'Total loss': 0.25982225577145707}
2023-01-04 01:10:31,842 INFO:     Found new best model at epoch 33
2023-01-04 01:10:31,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:31,843 INFO:     Epoch: 34
2023-01-04 01:10:33,431 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4825628697872162, 'Total loss': 0.4825628697872162} | train loss {'Reaction outcome loss': 0.2560310108321054, 'Total loss': 0.2560310108321054}
2023-01-04 01:10:33,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:33,432 INFO:     Epoch: 35
2023-01-04 01:10:35,045 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4706250727176666, 'Total loss': 0.4706250727176666} | train loss {'Reaction outcome loss': 0.255000395011225, 'Total loss': 0.255000395011225}
2023-01-04 01:10:35,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:35,045 INFO:     Epoch: 36
2023-01-04 01:10:36,647 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47985258102416994, 'Total loss': 0.47985258102416994} | train loss {'Reaction outcome loss': 0.2514561902554262, 'Total loss': 0.2514561902554262}
2023-01-04 01:10:36,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:36,647 INFO:     Epoch: 37
2023-01-04 01:10:38,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4949162662029266, 'Total loss': 0.4949162662029266} | train loss {'Reaction outcome loss': 0.24822388864344075, 'Total loss': 0.24822388864344075}
2023-01-04 01:10:38,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:38,194 INFO:     Epoch: 38
2023-01-04 01:10:39,799 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.491475248336792, 'Total loss': 0.491475248336792} | train loss {'Reaction outcome loss': 0.24619534821846548, 'Total loss': 0.24619534821846548}
2023-01-04 01:10:39,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:39,799 INFO:     Epoch: 39
2023-01-04 01:10:41,400 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46174407104651133, 'Total loss': 0.46174407104651133} | train loss {'Reaction outcome loss': 0.24318592116618767, 'Total loss': 0.24318592116618767}
2023-01-04 01:10:41,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:41,400 INFO:     Epoch: 40
2023-01-04 01:10:43,005 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5199398219585418, 'Total loss': 0.5199398219585418} | train loss {'Reaction outcome loss': 0.2411035199687158, 'Total loss': 0.2411035199687158}
2023-01-04 01:10:43,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:43,005 INFO:     Epoch: 41
2023-01-04 01:10:44,609 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46811316112677254, 'Total loss': 0.46811316112677254} | train loss {'Reaction outcome loss': 0.2362333291752653, 'Total loss': 0.2362333291752653}
2023-01-04 01:10:44,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:44,609 INFO:     Epoch: 42
2023-01-04 01:10:46,152 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4521813974405328, 'Total loss': 0.4521813974405328} | train loss {'Reaction outcome loss': 0.23535016128595496, 'Total loss': 0.23535016128595496}
2023-01-04 01:10:46,153 INFO:     Found new best model at epoch 42
2023-01-04 01:10:46,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:46,154 INFO:     Epoch: 43
2023-01-04 01:10:47,725 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46455812950929004, 'Total loss': 0.46455812950929004} | train loss {'Reaction outcome loss': 0.23311982769177947, 'Total loss': 0.23311982769177947}
2023-01-04 01:10:47,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:47,725 INFO:     Epoch: 44
2023-01-04 01:10:49,330 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.514442773660024, 'Total loss': 0.514442773660024} | train loss {'Reaction outcome loss': 0.23208862532189478, 'Total loss': 0.23208862532189478}
2023-01-04 01:10:49,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:49,330 INFO:     Epoch: 45
2023-01-04 01:10:50,940 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4828032066424688, 'Total loss': 0.4828032066424688} | train loss {'Reaction outcome loss': 0.2283442459877703, 'Total loss': 0.2283442459877703}
2023-01-04 01:10:50,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:50,940 INFO:     Epoch: 46
2023-01-04 01:10:52,524 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45572457859913507, 'Total loss': 0.45572457859913507} | train loss {'Reaction outcome loss': 0.2287366703125365, 'Total loss': 0.2287366703125365}
2023-01-04 01:10:52,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:52,525 INFO:     Epoch: 47
2023-01-04 01:10:54,112 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4705407480398814, 'Total loss': 0.4705407480398814} | train loss {'Reaction outcome loss': 0.22485504251642105, 'Total loss': 0.22485504251642105}
2023-01-04 01:10:54,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:54,112 INFO:     Epoch: 48
2023-01-04 01:10:55,669 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4665990153948466, 'Total loss': 0.4665990153948466} | train loss {'Reaction outcome loss': 0.22249542860375657, 'Total loss': 0.22249542860375657}
2023-01-04 01:10:55,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:55,669 INFO:     Epoch: 49
2023-01-04 01:10:57,278 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4676559090614319, 'Total loss': 0.4676559090614319} | train loss {'Reaction outcome loss': 0.22352281302868665, 'Total loss': 0.22352281302868665}
2023-01-04 01:10:57,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:57,279 INFO:     Epoch: 50
2023-01-04 01:10:58,872 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4877611637115479, 'Total loss': 0.4877611637115479} | train loss {'Reaction outcome loss': 0.22064213345557343, 'Total loss': 0.22064213345557343}
2023-01-04 01:10:58,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:10:58,873 INFO:     Epoch: 51
2023-01-04 01:11:00,481 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48474944829940797, 'Total loss': 0.48474944829940797} | train loss {'Reaction outcome loss': 0.2150336871599103, 'Total loss': 0.2150336871599103}
2023-01-04 01:11:00,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:00,481 INFO:     Epoch: 52
2023-01-04 01:11:02,053 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49467947085698444, 'Total loss': 0.49467947085698444} | train loss {'Reaction outcome loss': 0.21616472475803816, 'Total loss': 0.21616472475803816}
2023-01-04 01:11:02,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:02,053 INFO:     Epoch: 53
2023-01-04 01:11:03,655 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4812509407599767, 'Total loss': 0.4812509407599767} | train loss {'Reaction outcome loss': 0.2124804081634069, 'Total loss': 0.2124804081634069}
2023-01-04 01:11:03,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:03,655 INFO:     Epoch: 54
2023-01-04 01:11:05,216 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4735444486141205, 'Total loss': 0.4735444486141205} | train loss {'Reaction outcome loss': 0.21387365429010582, 'Total loss': 0.21387365429010582}
2023-01-04 01:11:05,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:05,217 INFO:     Epoch: 55
2023-01-04 01:11:06,814 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4992077946662903, 'Total loss': 0.4992077946662903} | train loss {'Reaction outcome loss': 0.20846661936232458, 'Total loss': 0.20846661936232458}
2023-01-04 01:11:06,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:06,814 INFO:     Epoch: 56
2023-01-04 01:11:08,417 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4587598333756129, 'Total loss': 0.4587598333756129} | train loss {'Reaction outcome loss': 0.2083245026554926, 'Total loss': 0.2083245026554926}
2023-01-04 01:11:08,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:08,417 INFO:     Epoch: 57
2023-01-04 01:11:10,001 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5248750964800517, 'Total loss': 0.5248750964800517} | train loss {'Reaction outcome loss': 0.20812527165362688, 'Total loss': 0.20812527165362688}
2023-01-04 01:11:10,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:10,002 INFO:     Epoch: 58
2023-01-04 01:11:11,617 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47994635105133054, 'Total loss': 0.47994635105133054} | train loss {'Reaction outcome loss': 0.20486299809573333, 'Total loss': 0.20486299809573333}
2023-01-04 01:11:11,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:11,618 INFO:     Epoch: 59
2023-01-04 01:11:13,163 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5159008840719859, 'Total loss': 0.5159008840719859} | train loss {'Reaction outcome loss': 0.20287158330663657, 'Total loss': 0.20287158330663657}
2023-01-04 01:11:13,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:13,163 INFO:     Epoch: 60
2023-01-04 01:11:14,735 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4788341045379639, 'Total loss': 0.4788341045379639} | train loss {'Reaction outcome loss': 0.20290994494061768, 'Total loss': 0.20290994494061768}
2023-01-04 01:11:14,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:14,735 INFO:     Epoch: 61
2023-01-04 01:11:16,315 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47934576670328777, 'Total loss': 0.47934576670328777} | train loss {'Reaction outcome loss': 0.198990324846445, 'Total loss': 0.198990324846445}
2023-01-04 01:11:16,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:16,316 INFO:     Epoch: 62
2023-01-04 01:11:17,895 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4692524239420891, 'Total loss': 0.4692524239420891} | train loss {'Reaction outcome loss': 0.1990661961964635, 'Total loss': 0.1990661961964635}
2023-01-04 01:11:17,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:17,895 INFO:     Epoch: 63
2023-01-04 01:11:19,475 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45917505224545796, 'Total loss': 0.45917505224545796} | train loss {'Reaction outcome loss': 0.19530995747572555, 'Total loss': 0.19530995747572555}
2023-01-04 01:11:19,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:19,475 INFO:     Epoch: 64
2023-01-04 01:11:21,054 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5068291385968526, 'Total loss': 0.5068291385968526} | train loss {'Reaction outcome loss': 0.19926265882321328, 'Total loss': 0.19926265882321328}
2023-01-04 01:11:21,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:21,054 INFO:     Epoch: 65
2023-01-04 01:11:22,603 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49183035691579186, 'Total loss': 0.49183035691579186} | train loss {'Reaction outcome loss': 0.19823894060247546, 'Total loss': 0.19823894060247546}
2023-01-04 01:11:22,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:22,604 INFO:     Epoch: 66
2023-01-04 01:11:24,182 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4653785340487957, 'Total loss': 0.4653785340487957} | train loss {'Reaction outcome loss': 0.19217311983907615, 'Total loss': 0.19217311983907615}
2023-01-04 01:11:24,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:24,183 INFO:     Epoch: 67
2023-01-04 01:11:25,763 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5181124071280162, 'Total loss': 0.5181124071280162} | train loss {'Reaction outcome loss': 0.19113576439492433, 'Total loss': 0.19113576439492433}
2023-01-04 01:11:25,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:25,763 INFO:     Epoch: 68
2023-01-04 01:11:27,343 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4832342763741811, 'Total loss': 0.4832342763741811} | train loss {'Reaction outcome loss': 0.192652930904712, 'Total loss': 0.192652930904712}
2023-01-04 01:11:27,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:27,343 INFO:     Epoch: 69
2023-01-04 01:11:28,922 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4898097356160482, 'Total loss': 0.4898097356160482} | train loss {'Reaction outcome loss': 0.19113990585336754, 'Total loss': 0.19113990585336754}
2023-01-04 01:11:28,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:28,922 INFO:     Epoch: 70
2023-01-04 01:11:30,497 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4942354530096054, 'Total loss': 0.4942354530096054} | train loss {'Reaction outcome loss': 0.19268333608960056, 'Total loss': 0.19268333608960056}
2023-01-04 01:11:30,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:30,497 INFO:     Epoch: 71
2023-01-04 01:11:32,068 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5250322818756104, 'Total loss': 0.5250322818756104} | train loss {'Reaction outcome loss': 0.1898038875543591, 'Total loss': 0.1898038875543591}
2023-01-04 01:11:32,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:32,068 INFO:     Epoch: 72
2023-01-04 01:11:33,684 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49834887584050497, 'Total loss': 0.49834887584050497} | train loss {'Reaction outcome loss': 0.1890133090944954, 'Total loss': 0.1890133090944954}
2023-01-04 01:11:33,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:33,684 INFO:     Epoch: 73
2023-01-04 01:11:35,301 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4964151958624522, 'Total loss': 0.4964151958624522} | train loss {'Reaction outcome loss': 0.18864999252333964, 'Total loss': 0.18864999252333964}
2023-01-04 01:11:35,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:35,302 INFO:     Epoch: 74
2023-01-04 01:11:36,918 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5164031287034353, 'Total loss': 0.5164031287034353} | train loss {'Reaction outcome loss': 0.1838539009350915, 'Total loss': 0.1838539009350915}
2023-01-04 01:11:36,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:36,919 INFO:     Epoch: 75
2023-01-04 01:11:38,528 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48614142537117006, 'Total loss': 0.48614142537117006} | train loss {'Reaction outcome loss': 0.18565657165160765, 'Total loss': 0.18565657165160765}
2023-01-04 01:11:38,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:38,529 INFO:     Epoch: 76
2023-01-04 01:11:40,096 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5116235633691152, 'Total loss': 0.5116235633691152} | train loss {'Reaction outcome loss': 0.18459617852782592, 'Total loss': 0.18459617852782592}
2023-01-04 01:11:40,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:40,096 INFO:     Epoch: 77
2023-01-04 01:11:41,656 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47734418511390686, 'Total loss': 0.47734418511390686} | train loss {'Reaction outcome loss': 0.18368966570431058, 'Total loss': 0.18368966570431058}
2023-01-04 01:11:41,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:41,656 INFO:     Epoch: 78
2023-01-04 01:11:43,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5174253642559051, 'Total loss': 0.5174253642559051} | train loss {'Reaction outcome loss': 0.1814450978031962, 'Total loss': 0.1814450978031962}
2023-01-04 01:11:43,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:43,272 INFO:     Epoch: 79
2023-01-04 01:11:44,888 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.509431395928065, 'Total loss': 0.509431395928065} | train loss {'Reaction outcome loss': 0.18440566341573503, 'Total loss': 0.18440566341573503}
2023-01-04 01:11:44,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:44,888 INFO:     Epoch: 80
2023-01-04 01:11:46,481 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5241383035977681, 'Total loss': 0.5241383035977681} | train loss {'Reaction outcome loss': 0.18241297725192357, 'Total loss': 0.18241297725192357}
2023-01-04 01:11:46,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:46,481 INFO:     Epoch: 81
2023-01-04 01:11:48,100 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5007804175217946, 'Total loss': 0.5007804175217946} | train loss {'Reaction outcome loss': 0.17963665837742687, 'Total loss': 0.17963665837742687}
2023-01-04 01:11:48,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:48,100 INFO:     Epoch: 82
2023-01-04 01:11:49,656 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5465944677591323, 'Total loss': 0.5465944677591323} | train loss {'Reaction outcome loss': 0.1799465019610666, 'Total loss': 0.1799465019610666}
2023-01-04 01:11:49,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:49,656 INFO:     Epoch: 83
2023-01-04 01:11:51,262 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5097851852575938, 'Total loss': 0.5097851852575938} | train loss {'Reaction outcome loss': 0.17876814842060373, 'Total loss': 0.17876814842060373}
2023-01-04 01:11:51,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:51,262 INFO:     Epoch: 84
2023-01-04 01:11:52,865 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5151214768489202, 'Total loss': 0.5151214768489202} | train loss {'Reaction outcome loss': 0.1771722124393129, 'Total loss': 0.1771722124393129}
2023-01-04 01:11:52,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:52,866 INFO:     Epoch: 85
2023-01-04 01:11:54,481 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5209143320719402, 'Total loss': 0.5209143320719402} | train loss {'Reaction outcome loss': 0.17672840479911464, 'Total loss': 0.17672840479911464}
2023-01-04 01:11:54,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:54,481 INFO:     Epoch: 86
2023-01-04 01:11:56,083 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46712063203255333, 'Total loss': 0.46712063203255333} | train loss {'Reaction outcome loss': 0.17734057961147784, 'Total loss': 0.17734057961147784}
2023-01-04 01:11:56,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:56,084 INFO:     Epoch: 87
2023-01-04 01:11:57,697 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5236755073070526, 'Total loss': 0.5236755073070526} | train loss {'Reaction outcome loss': 0.17258720097196845, 'Total loss': 0.17258720097196845}
2023-01-04 01:11:57,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:57,697 INFO:     Epoch: 88
2023-01-04 01:11:59,267 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49828539888064066, 'Total loss': 0.49828539888064066} | train loss {'Reaction outcome loss': 0.17567332479215803, 'Total loss': 0.17567332479215803}
2023-01-04 01:11:59,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:11:59,268 INFO:     Epoch: 89
2023-01-04 01:12:00,849 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4873797801633676, 'Total loss': 0.4873797801633676} | train loss {'Reaction outcome loss': 0.17290705033738316, 'Total loss': 0.17290705033738316}
2023-01-04 01:12:00,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:00,849 INFO:     Epoch: 90
2023-01-04 01:12:02,452 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5051067839066188, 'Total loss': 0.5051067839066188} | train loss {'Reaction outcome loss': 0.1757974574622108, 'Total loss': 0.1757974574622108}
2023-01-04 01:12:02,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:02,452 INFO:     Epoch: 91
2023-01-04 01:12:04,055 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5243238737185796, 'Total loss': 0.5243238737185796} | train loss {'Reaction outcome loss': 0.17316767577450354, 'Total loss': 0.17316767577450354}
2023-01-04 01:12:04,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:04,056 INFO:     Epoch: 92
2023-01-04 01:12:05,674 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5120047638813655, 'Total loss': 0.5120047638813655} | train loss {'Reaction outcome loss': 0.17430688008911663, 'Total loss': 0.17430688008911663}
2023-01-04 01:12:05,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:05,674 INFO:     Epoch: 93
2023-01-04 01:12:07,246 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5759035170078277, 'Total loss': 0.5759035170078277} | train loss {'Reaction outcome loss': 0.17151142669084307, 'Total loss': 0.17151142669084307}
2023-01-04 01:12:07,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:07,246 INFO:     Epoch: 94
2023-01-04 01:12:08,848 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5252190113067627, 'Total loss': 0.5252190113067627} | train loss {'Reaction outcome loss': 0.1712338669914684, 'Total loss': 0.1712338669914684}
2023-01-04 01:12:08,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:08,848 INFO:     Epoch: 95
2023-01-04 01:12:10,467 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5319944649934769, 'Total loss': 0.5319944649934769} | train loss {'Reaction outcome loss': 0.17008768604734006, 'Total loss': 0.17008768604734006}
2023-01-04 01:12:10,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:10,468 INFO:     Epoch: 96
2023-01-04 01:12:12,082 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4948302090167999, 'Total loss': 0.4948302090167999} | train loss {'Reaction outcome loss': 0.1710291721008636, 'Total loss': 0.1710291721008636}
2023-01-04 01:12:12,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:12,083 INFO:     Epoch: 97
2023-01-04 01:12:13,677 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5226269781589508, 'Total loss': 0.5226269781589508} | train loss {'Reaction outcome loss': 0.16716684115156805, 'Total loss': 0.16716684115156805}
2023-01-04 01:12:13,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:13,677 INFO:     Epoch: 98
2023-01-04 01:12:15,297 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.52753444314003, 'Total loss': 0.52753444314003} | train loss {'Reaction outcome loss': 0.16878868226685148, 'Total loss': 0.16878868226685148}
2023-01-04 01:12:15,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:15,297 INFO:     Epoch: 99
2023-01-04 01:12:16,859 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5025246635079383, 'Total loss': 0.5025246635079383} | train loss {'Reaction outcome loss': 0.16710179827889024, 'Total loss': 0.16710179827889024}
2023-01-04 01:12:16,859 INFO:     Best model found after epoch 43 of 100.
2023-01-04 01:12:16,859 INFO:   Done with stage: TRAINING
2023-01-04 01:12:16,859 INFO:   Starting stage: EVALUATION
2023-01-04 01:12:17,000 INFO:   Done with stage: EVALUATION
2023-01-04 01:12:17,000 INFO:   Leaving out SEQ value Fold_1
2023-01-04 01:12:17,012 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:12:17,013 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:12:17,676 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:12:17,676 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:12:17,746 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:12:17,746 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:12:17,746 INFO:     No hyperparam tuning for this model
2023-01-04 01:12:17,746 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:12:17,746 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:12:17,747 INFO:     None feature selector for col prot
2023-01-04 01:12:17,747 INFO:     None feature selector for col prot
2023-01-04 01:12:17,747 INFO:     None feature selector for col prot
2023-01-04 01:12:17,748 INFO:     None feature selector for col chem
2023-01-04 01:12:17,748 INFO:     None feature selector for col chem
2023-01-04 01:12:17,748 INFO:     None feature selector for col chem
2023-01-04 01:12:17,748 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:12:17,748 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:12:17,749 INFO:     Number of params in model 70141
2023-01-04 01:12:17,752 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:12:17,752 INFO:   Starting stage: TRAINING
2023-01-04 01:12:17,796 INFO:     Val loss before train {'Reaction outcome loss': 1.1069801767667136, 'Total loss': 1.1069801767667136}
2023-01-04 01:12:17,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:17,796 INFO:     Epoch: 0
2023-01-04 01:12:19,423 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7787215828895568, 'Total loss': 0.7787215828895568} | train loss {'Reaction outcome loss': 0.8423128973764783, 'Total loss': 0.8423128973764783}
2023-01-04 01:12:19,423 INFO:     Found new best model at epoch 0
2023-01-04 01:12:19,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:19,424 INFO:     Epoch: 1
2023-01-04 01:12:21,022 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5985443075497945, 'Total loss': 0.5985443075497945} | train loss {'Reaction outcome loss': 0.6130696783533284, 'Total loss': 0.6130696783533284}
2023-01-04 01:12:21,022 INFO:     Found new best model at epoch 1
2023-01-04 01:12:21,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:21,023 INFO:     Epoch: 2
2023-01-04 01:12:22,649 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5737862467765809, 'Total loss': 0.5737862467765809} | train loss {'Reaction outcome loss': 0.5309351810163049, 'Total loss': 0.5309351810163049}
2023-01-04 01:12:22,649 INFO:     Found new best model at epoch 2
2023-01-04 01:12:22,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:22,650 INFO:     Epoch: 3
2023-01-04 01:12:24,260 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5509146749973297, 'Total loss': 0.5509146749973297} | train loss {'Reaction outcome loss': 0.4947772549222345, 'Total loss': 0.4947772549222345}
2023-01-04 01:12:24,261 INFO:     Found new best model at epoch 3
2023-01-04 01:12:24,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:24,262 INFO:     Epoch: 4
2023-01-04 01:12:25,828 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5293633699417114, 'Total loss': 0.5293633699417114} | train loss {'Reaction outcome loss': 0.46524960798737797, 'Total loss': 0.46524960798737797}
2023-01-04 01:12:25,828 INFO:     Found new best model at epoch 4
2023-01-04 01:12:25,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:25,829 INFO:     Epoch: 5
2023-01-04 01:12:27,431 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5430919249852498, 'Total loss': 0.5430919249852498} | train loss {'Reaction outcome loss': 0.4465747607177616, 'Total loss': 0.4465747607177616}
2023-01-04 01:12:27,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:27,431 INFO:     Epoch: 6
2023-01-04 01:12:29,033 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5390225847562155, 'Total loss': 0.5390225847562155} | train loss {'Reaction outcome loss': 0.4441739264605702, 'Total loss': 0.4441739264605702}
2023-01-04 01:12:29,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:29,033 INFO:     Epoch: 7
2023-01-04 01:12:30,633 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5040405412515004, 'Total loss': 0.5040405412515004} | train loss {'Reaction outcome loss': 0.41849787775862607, 'Total loss': 0.41849787775862607}
2023-01-04 01:12:30,634 INFO:     Found new best model at epoch 7
2023-01-04 01:12:30,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:30,635 INFO:     Epoch: 8
2023-01-04 01:12:32,234 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.504628312587738, 'Total loss': 0.504628312587738} | train loss {'Reaction outcome loss': 0.4050301127945599, 'Total loss': 0.4050301127945599}
2023-01-04 01:12:32,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:32,234 INFO:     Epoch: 9
2023-01-04 01:12:33,810 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4928895572821299, 'Total loss': 0.4928895572821299} | train loss {'Reaction outcome loss': 0.39301913047690334, 'Total loss': 0.39301913047690334}
2023-01-04 01:12:33,810 INFO:     Found new best model at epoch 9
2023-01-04 01:12:33,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:33,811 INFO:     Epoch: 10
2023-01-04 01:12:35,395 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4962198853492737, 'Total loss': 0.4962198853492737} | train loss {'Reaction outcome loss': 0.38446664372863976, 'Total loss': 0.38446664372863976}
2023-01-04 01:12:35,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:35,395 INFO:     Epoch: 11
2023-01-04 01:12:36,998 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49212344686190285, 'Total loss': 0.49212344686190285} | train loss {'Reaction outcome loss': 0.37523100746498594, 'Total loss': 0.37523100746498594}
2023-01-04 01:12:36,998 INFO:     Found new best model at epoch 11
2023-01-04 01:12:36,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:36,999 INFO:     Epoch: 12
2023-01-04 01:12:38,598 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4916034738222758, 'Total loss': 0.4916034738222758} | train loss {'Reaction outcome loss': 0.3740161889759095, 'Total loss': 0.3740161889759095}
2023-01-04 01:12:38,598 INFO:     Found new best model at epoch 12
2023-01-04 01:12:38,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:38,599 INFO:     Epoch: 13
2023-01-04 01:12:40,199 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4940220554669698, 'Total loss': 0.4940220554669698} | train loss {'Reaction outcome loss': 0.36822969061524974, 'Total loss': 0.36822969061524974}
2023-01-04 01:12:40,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:40,200 INFO:     Epoch: 14
2023-01-04 01:12:41,821 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47627967993418374, 'Total loss': 0.47627967993418374} | train loss {'Reaction outcome loss': 0.353867837710414, 'Total loss': 0.353867837710414}
2023-01-04 01:12:41,821 INFO:     Found new best model at epoch 14
2023-01-04 01:12:41,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:41,822 INFO:     Epoch: 15
2023-01-04 01:12:43,398 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46343162655830383, 'Total loss': 0.46343162655830383} | train loss {'Reaction outcome loss': 0.3500203648177178, 'Total loss': 0.3500203648177178}
2023-01-04 01:12:43,398 INFO:     Found new best model at epoch 15
2023-01-04 01:12:43,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:43,399 INFO:     Epoch: 16
2023-01-04 01:12:45,021 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49350885550181073, 'Total loss': 0.49350885550181073} | train loss {'Reaction outcome loss': 0.34253736500729737, 'Total loss': 0.34253736500729737}
2023-01-04 01:12:45,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:45,021 INFO:     Epoch: 17
2023-01-04 01:12:46,654 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47232434650262195, 'Total loss': 0.47232434650262195} | train loss {'Reaction outcome loss': 0.3369106457178967, 'Total loss': 0.3369106457178967}
2023-01-04 01:12:46,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:46,654 INFO:     Epoch: 18
2023-01-04 01:12:48,282 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47387290596961973, 'Total loss': 0.47387290596961973} | train loss {'Reaction outcome loss': 0.3320807699903684, 'Total loss': 0.3320807699903684}
2023-01-04 01:12:48,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:48,283 INFO:     Epoch: 19
2023-01-04 01:12:49,886 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47677349944909414, 'Total loss': 0.47677349944909414} | train loss {'Reaction outcome loss': 0.3385801349591086, 'Total loss': 0.3385801349591086}
2023-01-04 01:12:49,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:49,886 INFO:     Epoch: 20
2023-01-04 01:12:51,507 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4718576471010844, 'Total loss': 0.4718576471010844} | train loss {'Reaction outcome loss': 0.331272524997484, 'Total loss': 0.331272524997484}
2023-01-04 01:12:51,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:51,507 INFO:     Epoch: 21
2023-01-04 01:12:53,087 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4860161989927292, 'Total loss': 0.4860161989927292} | train loss {'Reaction outcome loss': 0.3207800920944715, 'Total loss': 0.3207800920944715}
2023-01-04 01:12:53,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:53,088 INFO:     Epoch: 22
2023-01-04 01:12:54,719 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4821268449227015, 'Total loss': 0.4821268449227015} | train loss {'Reaction outcome loss': 0.313482199539093, 'Total loss': 0.313482199539093}
2023-01-04 01:12:54,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:54,720 INFO:     Epoch: 23
2023-01-04 01:12:56,342 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47844124933083854, 'Total loss': 0.47844124933083854} | train loss {'Reaction outcome loss': 0.304554387149266, 'Total loss': 0.304554387149266}
2023-01-04 01:12:56,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:56,343 INFO:     Epoch: 24
2023-01-04 01:12:57,977 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48232376178105674, 'Total loss': 0.48232376178105674} | train loss {'Reaction outcome loss': 0.30103046850777027, 'Total loss': 0.30103046850777027}
2023-01-04 01:12:57,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:57,977 INFO:     Epoch: 25
2023-01-04 01:12:59,582 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48790099124113717, 'Total loss': 0.48790099124113717} | train loss {'Reaction outcome loss': 0.2987564262103937, 'Total loss': 0.2987564262103937}
2023-01-04 01:12:59,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:12:59,584 INFO:     Epoch: 26
2023-01-04 01:13:01,150 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47569480538368225, 'Total loss': 0.47569480538368225} | train loss {'Reaction outcome loss': 0.29271923875068384, 'Total loss': 0.29271923875068384}
2023-01-04 01:13:01,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:01,150 INFO:     Epoch: 27
2023-01-04 01:13:02,784 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4618213171760241, 'Total loss': 0.4618213171760241} | train loss {'Reaction outcome loss': 0.29070804991372995, 'Total loss': 0.29070804991372995}
2023-01-04 01:13:02,784 INFO:     Found new best model at epoch 27
2023-01-04 01:13:02,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:02,785 INFO:     Epoch: 28
2023-01-04 01:13:04,406 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48090115984280907, 'Total loss': 0.48090115984280907} | train loss {'Reaction outcome loss': 0.28804199688918586, 'Total loss': 0.28804199688918586}
2023-01-04 01:13:04,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:04,407 INFO:     Epoch: 29
2023-01-04 01:13:06,035 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49768216411272687, 'Total loss': 0.49768216411272687} | train loss {'Reaction outcome loss': 0.2831787134336028, 'Total loss': 0.2831787134336028}
2023-01-04 01:13:06,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:06,036 INFO:     Epoch: 30
2023-01-04 01:13:07,628 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46185404658317564, 'Total loss': 0.46185404658317564} | train loss {'Reaction outcome loss': 0.2782318635077715, 'Total loss': 0.2782318635077715}
2023-01-04 01:13:07,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:07,629 INFO:     Epoch: 31
2023-01-04 01:13:09,253 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48415141900380454, 'Total loss': 0.48415141900380454} | train loss {'Reaction outcome loss': 0.2755742621784389, 'Total loss': 0.2755742621784389}
2023-01-04 01:13:09,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:09,253 INFO:     Epoch: 32
2023-01-04 01:13:10,816 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48183128237724304, 'Total loss': 0.48183128237724304} | train loss {'Reaction outcome loss': 0.27448912858423113, 'Total loss': 0.27448912858423113}
2023-01-04 01:13:10,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:10,816 INFO:     Epoch: 33
2023-01-04 01:13:12,426 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4753877858320872, 'Total loss': 0.4753877858320872} | train loss {'Reaction outcome loss': 0.2709645138464085, 'Total loss': 0.2709645138464085}
2023-01-04 01:13:12,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:12,427 INFO:     Epoch: 34
2023-01-04 01:13:14,063 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4670603414376577, 'Total loss': 0.4670603414376577} | train loss {'Reaction outcome loss': 0.2684142487933454, 'Total loss': 0.2684142487933454}
2023-01-04 01:13:14,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:14,064 INFO:     Epoch: 35
2023-01-04 01:13:15,686 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5009120921293895, 'Total loss': 0.5009120921293895} | train loss {'Reaction outcome loss': 0.26440935158103274, 'Total loss': 0.26440935158103274}
2023-01-04 01:13:15,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:15,686 INFO:     Epoch: 36
2023-01-04 01:13:17,320 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49808393518129984, 'Total loss': 0.49808393518129984} | train loss {'Reaction outcome loss': 0.2612900397037288, 'Total loss': 0.2612900397037288}
2023-01-04 01:13:17,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:17,320 INFO:     Epoch: 37
2023-01-04 01:13:18,927 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5060698678096135, 'Total loss': 0.5060698678096135} | train loss {'Reaction outcome loss': 0.26181373818764003, 'Total loss': 0.26181373818764003}
2023-01-04 01:13:18,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:18,928 INFO:     Epoch: 38
2023-01-04 01:13:20,538 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5235861559708913, 'Total loss': 0.5235861559708913} | train loss {'Reaction outcome loss': 0.2576645593347865, 'Total loss': 0.2576645593347865}
2023-01-04 01:13:20,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:20,538 INFO:     Epoch: 39
2023-01-04 01:13:22,172 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49317966103553773, 'Total loss': 0.49317966103553773} | train loss {'Reaction outcome loss': 0.2543331879609521, 'Total loss': 0.2543331879609521}
2023-01-04 01:13:22,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:22,172 INFO:     Epoch: 40
2023-01-04 01:13:23,802 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.503199788928032, 'Total loss': 0.503199788928032} | train loss {'Reaction outcome loss': 0.25152374558366725, 'Total loss': 0.25152374558366725}
2023-01-04 01:13:23,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:23,803 INFO:     Epoch: 41
2023-01-04 01:13:25,432 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5129018664360047, 'Total loss': 0.5129018664360047} | train loss {'Reaction outcome loss': 0.2504349974117139, 'Total loss': 0.2504349974117139}
2023-01-04 01:13:25,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:25,432 INFO:     Epoch: 42
2023-01-04 01:13:27,024 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5058033625284831, 'Total loss': 0.5058033625284831} | train loss {'Reaction outcome loss': 0.2493499878227063, 'Total loss': 0.2493499878227063}
2023-01-04 01:13:27,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:27,024 INFO:     Epoch: 43
2023-01-04 01:13:28,589 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5250026772419611, 'Total loss': 0.5250026772419611} | train loss {'Reaction outcome loss': 0.25032980421531026, 'Total loss': 0.25032980421531026}
2023-01-04 01:13:28,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:28,589 INFO:     Epoch: 44
2023-01-04 01:13:30,218 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4765242795149485, 'Total loss': 0.4765242795149485} | train loss {'Reaction outcome loss': 0.2563739185294991, 'Total loss': 0.2563739185294991}
2023-01-04 01:13:30,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:30,218 INFO:     Epoch: 45
2023-01-04 01:13:31,854 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4943483054637909, 'Total loss': 0.4943483054637909} | train loss {'Reaction outcome loss': 0.24105254453910596, 'Total loss': 0.24105254453910596}
2023-01-04 01:13:31,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:31,854 INFO:     Epoch: 46
2023-01-04 01:13:33,475 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4830601399143537, 'Total loss': 0.4830601399143537} | train loss {'Reaction outcome loss': 0.24085564842359905, 'Total loss': 0.24085564842359905}
2023-01-04 01:13:33,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:33,475 INFO:     Epoch: 47
2023-01-04 01:13:35,104 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4807548155387243, 'Total loss': 0.4807548155387243} | train loss {'Reaction outcome loss': 0.23771454134080355, 'Total loss': 0.23771454134080355}
2023-01-04 01:13:35,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:35,105 INFO:     Epoch: 48
2023-01-04 01:13:36,695 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5065092245737711, 'Total loss': 0.5065092245737711} | train loss {'Reaction outcome loss': 0.23651747296199852, 'Total loss': 0.23651747296199852}
2023-01-04 01:13:36,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:36,696 INFO:     Epoch: 49
2023-01-04 01:13:38,267 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5052207867304485, 'Total loss': 0.5052207867304485} | train loss {'Reaction outcome loss': 0.23555561985257015, 'Total loss': 0.23555561985257015}
2023-01-04 01:13:38,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:38,267 INFO:     Epoch: 50
2023-01-04 01:13:39,889 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5278040702144305, 'Total loss': 0.5278040702144305} | train loss {'Reaction outcome loss': 0.23186012886616073, 'Total loss': 0.23186012886616073}
2023-01-04 01:13:39,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:39,889 INFO:     Epoch: 51
2023-01-04 01:13:41,507 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5411440292994182, 'Total loss': 0.5411440292994182} | train loss {'Reaction outcome loss': 0.22902984788938277, 'Total loss': 0.22902984788938277}
2023-01-04 01:13:41,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:41,508 INFO:     Epoch: 52
2023-01-04 01:13:43,138 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5131513754526774, 'Total loss': 0.5131513754526774} | train loss {'Reaction outcome loss': 0.22757623480983835, 'Total loss': 0.22757623480983835}
2023-01-04 01:13:43,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:43,138 INFO:     Epoch: 53
2023-01-04 01:13:44,752 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5285410185654958, 'Total loss': 0.5285410185654958} | train loss {'Reaction outcome loss': 0.22998400531925153, 'Total loss': 0.22998400531925153}
2023-01-04 01:13:44,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:44,752 INFO:     Epoch: 54
2023-01-04 01:13:46,337 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5242577314376831, 'Total loss': 0.5242577314376831} | train loss {'Reaction outcome loss': 0.23089071583218765, 'Total loss': 0.23089071583218765}
2023-01-04 01:13:46,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:46,337 INFO:     Epoch: 55
2023-01-04 01:13:47,953 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5134737213452657, 'Total loss': 0.5134737213452657} | train loss {'Reaction outcome loss': 0.2250448424070466, 'Total loss': 0.2250448424070466}
2023-01-04 01:13:47,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:47,954 INFO:     Epoch: 56
2023-01-04 01:13:49,582 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5440711120764414, 'Total loss': 0.5440711120764414} | train loss {'Reaction outcome loss': 0.22153779098785573, 'Total loss': 0.22153779098785573}
2023-01-04 01:13:49,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:49,582 INFO:     Epoch: 57
2023-01-04 01:13:51,214 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5932495931784312, 'Total loss': 0.5932495931784312} | train loss {'Reaction outcome loss': 0.21853796812322707, 'Total loss': 0.21853796812322707}
2023-01-04 01:13:51,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:51,214 INFO:     Epoch: 58
2023-01-04 01:13:52,829 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49276788930098214, 'Total loss': 0.49276788930098214} | train loss {'Reaction outcome loss': 0.22092395304175821, 'Total loss': 0.22092395304175821}
2023-01-04 01:13:52,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:52,829 INFO:     Epoch: 59
2023-01-04 01:13:54,454 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5450707564751307, 'Total loss': 0.5450707564751307} | train loss {'Reaction outcome loss': 0.21918720289882596, 'Total loss': 0.21918720289882596}
2023-01-04 01:13:54,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:54,454 INFO:     Epoch: 60
2023-01-04 01:13:56,021 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5249336024125417, 'Total loss': 0.5249336024125417} | train loss {'Reaction outcome loss': 0.21538216584915484, 'Total loss': 0.21538216584915484}
2023-01-04 01:13:56,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:56,021 INFO:     Epoch: 61
2023-01-04 01:13:57,648 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5021240174770355, 'Total loss': 0.5021240174770355} | train loss {'Reaction outcome loss': 0.213668653137469, 'Total loss': 0.213668653137469}
2023-01-04 01:13:57,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:57,649 INFO:     Epoch: 62
2023-01-04 01:13:59,260 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5635828067859013, 'Total loss': 0.5635828067859013} | train loss {'Reaction outcome loss': 0.21576273949619423, 'Total loss': 0.21576273949619423}
2023-01-04 01:13:59,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:13:59,261 INFO:     Epoch: 63
2023-01-04 01:14:00,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5178771148125331, 'Total loss': 0.5178771148125331} | train loss {'Reaction outcome loss': 0.213985949830638, 'Total loss': 0.213985949830638}
2023-01-04 01:14:00,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:00,872 INFO:     Epoch: 64
2023-01-04 01:14:02,501 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5450142800807953, 'Total loss': 0.5450142800807953} | train loss {'Reaction outcome loss': 0.20940556223301784, 'Total loss': 0.20940556223301784}
2023-01-04 01:14:02,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:02,501 INFO:     Epoch: 65
2023-01-04 01:14:04,113 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5621365964412689, 'Total loss': 0.5621365964412689} | train loss {'Reaction outcome loss': 0.2078987878986231, 'Total loss': 0.2078987878986231}
2023-01-04 01:14:04,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:04,114 INFO:     Epoch: 66
2023-01-04 01:14:05,710 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.548213666677475, 'Total loss': 0.548213666677475} | train loss {'Reaction outcome loss': 0.20581139568779347, 'Total loss': 0.20581139568779347}
2023-01-04 01:14:05,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:05,711 INFO:     Epoch: 67
2023-01-04 01:14:07,321 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5316326240698497, 'Total loss': 0.5316326240698497} | train loss {'Reaction outcome loss': 0.20858482792444166, 'Total loss': 0.20858482792444166}
2023-01-04 01:14:07,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:07,321 INFO:     Epoch: 68
2023-01-04 01:14:08,954 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5745435933272044, 'Total loss': 0.5745435933272044} | train loss {'Reaction outcome loss': 0.20657042700770326, 'Total loss': 0.20657042700770326}
2023-01-04 01:14:08,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:08,954 INFO:     Epoch: 69
2023-01-04 01:14:10,583 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5630590379238128, 'Total loss': 0.5630590379238128} | train loss {'Reaction outcome loss': 0.2043987850597857, 'Total loss': 0.2043987850597857}
2023-01-04 01:14:10,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:10,584 INFO:     Epoch: 70
2023-01-04 01:14:12,218 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5306019186973572, 'Total loss': 0.5306019186973572} | train loss {'Reaction outcome loss': 0.20249233009467454, 'Total loss': 0.20249233009467454}
2023-01-04 01:14:12,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:12,219 INFO:     Epoch: 71
2023-01-04 01:14:13,809 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5951136330763499, 'Total loss': 0.5951136330763499} | train loss {'Reaction outcome loss': 0.2014165540690885, 'Total loss': 0.2014165540690885}
2023-01-04 01:14:13,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:13,809 INFO:     Epoch: 72
2023-01-04 01:14:15,431 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5178868512312571, 'Total loss': 0.5178868512312571} | train loss {'Reaction outcome loss': 0.20260931482619565, 'Total loss': 0.20260931482619565}
2023-01-04 01:14:15,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:15,431 INFO:     Epoch: 73
2023-01-04 01:14:17,068 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5411559671163559, 'Total loss': 0.5411559671163559} | train loss {'Reaction outcome loss': 0.20253837539180033, 'Total loss': 0.20253837539180033}
2023-01-04 01:14:17,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:17,069 INFO:     Epoch: 74
2023-01-04 01:14:18,695 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5470092972119649, 'Total loss': 0.5470092972119649} | train loss {'Reaction outcome loss': 0.19989889683168166, 'Total loss': 0.19989889683168166}
2023-01-04 01:14:18,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:18,695 INFO:     Epoch: 75
2023-01-04 01:14:20,318 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5458499252796173, 'Total loss': 0.5458499252796173} | train loss {'Reaction outcome loss': 0.19930743859583963, 'Total loss': 0.19930743859583963}
2023-01-04 01:14:20,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:20,318 INFO:     Epoch: 76
2023-01-04 01:14:21,938 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5518334885438283, 'Total loss': 0.5518334885438283} | train loss {'Reaction outcome loss': 0.19615921875853362, 'Total loss': 0.19615921875853362}
2023-01-04 01:14:21,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:21,939 INFO:     Epoch: 77
2023-01-04 01:14:23,496 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5465923567612966, 'Total loss': 0.5465923567612966} | train loss {'Reaction outcome loss': 0.19623750358469028, 'Total loss': 0.19623750358469028}
2023-01-04 01:14:23,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:23,496 INFO:     Epoch: 78
2023-01-04 01:14:25,123 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.545177940527598, 'Total loss': 0.545177940527598} | train loss {'Reaction outcome loss': 0.19450722370580162, 'Total loss': 0.19450722370580162}
2023-01-04 01:14:25,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:25,124 INFO:     Epoch: 79
2023-01-04 01:14:26,744 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5690041929483414, 'Total loss': 0.5690041929483414} | train loss {'Reaction outcome loss': 0.19318068497860635, 'Total loss': 0.19318068497860635}
2023-01-04 01:14:26,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:26,744 INFO:     Epoch: 80
2023-01-04 01:14:28,366 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5756006906429927, 'Total loss': 0.5756006906429927} | train loss {'Reaction outcome loss': 0.1946671376138946, 'Total loss': 0.1946671376138946}
2023-01-04 01:14:28,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:28,366 INFO:     Epoch: 81
2023-01-04 01:14:30,000 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5600402653217316, 'Total loss': 0.5600402653217316} | train loss {'Reaction outcome loss': 0.190886886572986, 'Total loss': 0.190886886572986}
2023-01-04 01:14:30,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:30,001 INFO:     Epoch: 82
2023-01-04 01:14:31,600 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5504828085501988, 'Total loss': 0.5504828085501988} | train loss {'Reaction outcome loss': 0.1951507041365772, 'Total loss': 0.1951507041365772}
2023-01-04 01:14:31,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:31,600 INFO:     Epoch: 83
2023-01-04 01:14:33,205 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5797296275695165, 'Total loss': 0.5797296275695165} | train loss {'Reaction outcome loss': 0.19524273037846349, 'Total loss': 0.19524273037846349}
2023-01-04 01:14:33,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:33,206 INFO:     Epoch: 84
2023-01-04 01:14:34,797 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5716413532694181, 'Total loss': 0.5716413532694181} | train loss {'Reaction outcome loss': 0.18976925135085249, 'Total loss': 0.18976925135085249}
2023-01-04 01:14:34,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:34,797 INFO:     Epoch: 85
2023-01-04 01:14:36,387 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5591782331466675, 'Total loss': 0.5591782331466675} | train loss {'Reaction outcome loss': 0.18752008295901443, 'Total loss': 0.18752008295901443}
2023-01-04 01:14:36,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:36,388 INFO:     Epoch: 86
2023-01-04 01:14:37,975 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5804788072903951, 'Total loss': 0.5804788072903951} | train loss {'Reaction outcome loss': 0.19458946087937531, 'Total loss': 0.19458946087937531}
2023-01-04 01:14:37,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:37,975 INFO:     Epoch: 87
2023-01-04 01:14:39,587 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5520900974671046, 'Total loss': 0.5520900974671046} | train loss {'Reaction outcome loss': 0.18546897313026947, 'Total loss': 0.18546897313026947}
2023-01-04 01:14:39,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:39,588 INFO:     Epoch: 88
2023-01-04 01:14:41,155 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5766944388548533, 'Total loss': 0.5766944388548533} | train loss {'Reaction outcome loss': 0.1877060166592908, 'Total loss': 0.1877060166592908}
2023-01-04 01:14:41,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:41,155 INFO:     Epoch: 89
2023-01-04 01:14:42,779 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5550181448459626, 'Total loss': 0.5550181448459626} | train loss {'Reaction outcome loss': 0.1829956184791218, 'Total loss': 0.1829956184791218}
2023-01-04 01:14:42,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:42,780 INFO:     Epoch: 90
2023-01-04 01:14:44,401 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5520059535900752, 'Total loss': 0.5520059535900752} | train loss {'Reaction outcome loss': 0.1833105700514853, 'Total loss': 0.1833105700514853}
2023-01-04 01:14:44,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:44,401 INFO:     Epoch: 91
2023-01-04 01:14:46,022 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.588818566997846, 'Total loss': 0.588818566997846} | train loss {'Reaction outcome loss': 0.18271514109464065, 'Total loss': 0.18271514109464065}
2023-01-04 01:14:46,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:46,022 INFO:     Epoch: 92
2023-01-04 01:14:47,618 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5135182579358418, 'Total loss': 0.5135182579358418} | train loss {'Reaction outcome loss': 0.1839401074849129, 'Total loss': 0.1839401074849129}
2023-01-04 01:14:47,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:47,618 INFO:     Epoch: 93
2023-01-04 01:14:49,226 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5691547691822052, 'Total loss': 0.5691547691822052} | train loss {'Reaction outcome loss': 0.18217550757622847, 'Total loss': 0.18217550757622847}
2023-01-04 01:14:49,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:49,226 INFO:     Epoch: 94
2023-01-04 01:14:50,794 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5701128204663595, 'Total loss': 0.5701128204663595} | train loss {'Reaction outcome loss': 0.18205765749503305, 'Total loss': 0.18205765749503305}
2023-01-04 01:14:50,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:50,794 INFO:     Epoch: 95
2023-01-04 01:14:52,389 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5417284478743871, 'Total loss': 0.5417284478743871} | train loss {'Reaction outcome loss': 0.18595869371357907, 'Total loss': 0.18595869371357907}
2023-01-04 01:14:52,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:52,389 INFO:     Epoch: 96
2023-01-04 01:14:53,986 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.570796400308609, 'Total loss': 0.570796400308609} | train loss {'Reaction outcome loss': 0.17705283137173325, 'Total loss': 0.17705283137173325}
2023-01-04 01:14:53,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:53,986 INFO:     Epoch: 97
2023-01-04 01:14:55,581 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5467077364524205, 'Total loss': 0.5467077364524205} | train loss {'Reaction outcome loss': 0.1796297816787677, 'Total loss': 0.1796297816787677}
2023-01-04 01:14:55,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:55,582 INFO:     Epoch: 98
2023-01-04 01:14:57,180 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5658010999361675, 'Total loss': 0.5658010999361675} | train loss {'Reaction outcome loss': 0.18013055530795152, 'Total loss': 0.18013055530795152}
2023-01-04 01:14:57,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:57,180 INFO:     Epoch: 99
2023-01-04 01:14:58,747 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5438217163085938, 'Total loss': 0.5438217163085938} | train loss {'Reaction outcome loss': 0.19132868945846407, 'Total loss': 0.19132868945846407}
2023-01-04 01:14:58,747 INFO:     Best model found after epoch 28 of 100.
2023-01-04 01:14:58,748 INFO:   Done with stage: TRAINING
2023-01-04 01:14:58,748 INFO:   Starting stage: EVALUATION
2023-01-04 01:14:58,873 INFO:   Done with stage: EVALUATION
2023-01-04 01:14:58,873 INFO:   Leaving out SEQ value Fold_2
2023-01-04 01:14:58,886 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 01:14:58,886 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:14:59,547 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:14:59,547 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:14:59,618 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:14:59,618 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:14:59,618 INFO:     No hyperparam tuning for this model
2023-01-04 01:14:59,618 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:14:59,618 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:14:59,619 INFO:     None feature selector for col prot
2023-01-04 01:14:59,619 INFO:     None feature selector for col prot
2023-01-04 01:14:59,619 INFO:     None feature selector for col prot
2023-01-04 01:14:59,620 INFO:     None feature selector for col chem
2023-01-04 01:14:59,620 INFO:     None feature selector for col chem
2023-01-04 01:14:59,620 INFO:     None feature selector for col chem
2023-01-04 01:14:59,620 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:14:59,620 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:14:59,621 INFO:     Number of params in model 70141
2023-01-04 01:14:59,624 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:14:59,624 INFO:   Starting stage: TRAINING
2023-01-04 01:14:59,667 INFO:     Val loss before train {'Reaction outcome loss': 0.910417381922404, 'Total loss': 0.910417381922404}
2023-01-04 01:14:59,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:14:59,667 INFO:     Epoch: 0
2023-01-04 01:15:01,291 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5707835257053375, 'Total loss': 0.5707835257053375} | train loss {'Reaction outcome loss': 0.8424324927321316, 'Total loss': 0.8424324927321316}
2023-01-04 01:15:01,291 INFO:     Found new best model at epoch 0
2023-01-04 01:15:01,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:01,292 INFO:     Epoch: 1
2023-01-04 01:15:02,895 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48984699646631874, 'Total loss': 0.48984699646631874} | train loss {'Reaction outcome loss': 0.5933980862915951, 'Total loss': 0.5933980862915951}
2023-01-04 01:15:02,895 INFO:     Found new best model at epoch 1
2023-01-04 01:15:02,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:02,896 INFO:     Epoch: 2
2023-01-04 01:15:04,523 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49355908632278445, 'Total loss': 0.49355908632278445} | train loss {'Reaction outcome loss': 0.5311115447730914, 'Total loss': 0.5311115447730914}
2023-01-04 01:15:04,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:04,523 INFO:     Epoch: 3
2023-01-04 01:15:06,133 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46263826290766397, 'Total loss': 0.46263826290766397} | train loss {'Reaction outcome loss': 0.49353873370772733, 'Total loss': 0.49353873370772733}
2023-01-04 01:15:06,134 INFO:     Found new best model at epoch 3
2023-01-04 01:15:06,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:06,134 INFO:     Epoch: 4
2023-01-04 01:15:07,675 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44012718796730044, 'Total loss': 0.44012718796730044} | train loss {'Reaction outcome loss': 0.46739542873127615, 'Total loss': 0.46739542873127615}
2023-01-04 01:15:07,676 INFO:     Found new best model at epoch 4
2023-01-04 01:15:07,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:07,677 INFO:     Epoch: 5
2023-01-04 01:15:09,294 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43930145502090456, 'Total loss': 0.43930145502090456} | train loss {'Reaction outcome loss': 0.4489047934104056, 'Total loss': 0.4489047934104056}
2023-01-04 01:15:09,294 INFO:     Found new best model at epoch 5
2023-01-04 01:15:09,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:09,295 INFO:     Epoch: 6
2023-01-04 01:15:10,919 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4362561841805776, 'Total loss': 0.4362561841805776} | train loss {'Reaction outcome loss': 0.42909517606897074, 'Total loss': 0.42909517606897074}
2023-01-04 01:15:10,919 INFO:     Found new best model at epoch 6
2023-01-04 01:15:10,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:10,920 INFO:     Epoch: 7
2023-01-04 01:15:12,499 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4668417473634084, 'Total loss': 0.4668417473634084} | train loss {'Reaction outcome loss': 0.4156626619561745, 'Total loss': 0.4156626619561745}
2023-01-04 01:15:12,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:12,499 INFO:     Epoch: 8
2023-01-04 01:15:14,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4170504053433736, 'Total loss': 0.4170504053433736} | train loss {'Reaction outcome loss': 0.4042840423810221, 'Total loss': 0.4042840423810221}
2023-01-04 01:15:14,105 INFO:     Found new best model at epoch 8
2023-01-04 01:15:14,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:14,106 INFO:     Epoch: 9
2023-01-04 01:15:15,694 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41156068444252014, 'Total loss': 0.41156068444252014} | train loss {'Reaction outcome loss': 0.39492470890718656, 'Total loss': 0.39492470890718656}
2023-01-04 01:15:15,694 INFO:     Found new best model at epoch 9
2023-01-04 01:15:15,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:15,695 INFO:     Epoch: 10
2023-01-04 01:15:17,252 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4252226243416468, 'Total loss': 0.4252226243416468} | train loss {'Reaction outcome loss': 0.38362858077361633, 'Total loss': 0.38362858077361633}
2023-01-04 01:15:17,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:17,252 INFO:     Epoch: 11
2023-01-04 01:15:18,872 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4169212887684504, 'Total loss': 0.4169212887684504} | train loss {'Reaction outcome loss': 0.37929556154421645, 'Total loss': 0.37929556154421645}
2023-01-04 01:15:18,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:18,872 INFO:     Epoch: 12
2023-01-04 01:15:20,451 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4129333237806956, 'Total loss': 0.4129333237806956} | train loss {'Reaction outcome loss': 0.36966823835442536, 'Total loss': 0.36966823835442536}
2023-01-04 01:15:20,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:20,452 INFO:     Epoch: 13
2023-01-04 01:15:22,063 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42085084517796834, 'Total loss': 0.42085084517796834} | train loss {'Reaction outcome loss': 0.35646115085721886, 'Total loss': 0.35646115085721886}
2023-01-04 01:15:22,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:22,064 INFO:     Epoch: 14
2023-01-04 01:15:23,674 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4149927447239558, 'Total loss': 0.4149927447239558} | train loss {'Reaction outcome loss': 0.35432741948722923, 'Total loss': 0.35432741948722923}
2023-01-04 01:15:23,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:23,674 INFO:     Epoch: 15
2023-01-04 01:15:25,265 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3939731140931447, 'Total loss': 0.3939731140931447} | train loss {'Reaction outcome loss': 0.3454522507632301, 'Total loss': 0.3454522507632301}
2023-01-04 01:15:25,266 INFO:     Found new best model at epoch 15
2023-01-04 01:15:25,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:25,266 INFO:     Epoch: 16
2023-01-04 01:15:26,836 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3778777812918027, 'Total loss': 0.3778777812918027} | train loss {'Reaction outcome loss': 0.3406983151433677, 'Total loss': 0.3406983151433677}
2023-01-04 01:15:26,837 INFO:     Found new best model at epoch 16
2023-01-04 01:15:26,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:26,838 INFO:     Epoch: 17
2023-01-04 01:15:28,425 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38053188025951384, 'Total loss': 0.38053188025951384} | train loss {'Reaction outcome loss': 0.33304235447932334, 'Total loss': 0.33304235447932334}
2023-01-04 01:15:28,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:28,426 INFO:     Epoch: 18
2023-01-04 01:15:30,014 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3713742067416509, 'Total loss': 0.3713742067416509} | train loss {'Reaction outcome loss': 0.3257347483487025, 'Total loss': 0.3257347483487025}
2023-01-04 01:15:30,014 INFO:     Found new best model at epoch 18
2023-01-04 01:15:30,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:30,015 INFO:     Epoch: 19
2023-01-04 01:15:31,602 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39595497250556944, 'Total loss': 0.39595497250556944} | train loss {'Reaction outcome loss': 0.3246494512325221, 'Total loss': 0.3246494512325221}
2023-01-04 01:15:31,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:31,602 INFO:     Epoch: 20
2023-01-04 01:15:33,192 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.376253342628479, 'Total loss': 0.376253342628479} | train loss {'Reaction outcome loss': 0.3154404116318609, 'Total loss': 0.3154404116318609}
2023-01-04 01:15:33,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:33,192 INFO:     Epoch: 21
2023-01-04 01:15:34,742 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39218320747216545, 'Total loss': 0.39218320747216545} | train loss {'Reaction outcome loss': 0.3122603953917966, 'Total loss': 0.3122603953917966}
2023-01-04 01:15:34,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:34,742 INFO:     Epoch: 22
2023-01-04 01:15:36,331 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3560061385234197, 'Total loss': 0.3560061385234197} | train loss {'Reaction outcome loss': 0.3068995837421313, 'Total loss': 0.3068995837421313}
2023-01-04 01:15:36,331 INFO:     Found new best model at epoch 22
2023-01-04 01:15:36,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:36,332 INFO:     Epoch: 23
2023-01-04 01:15:37,920 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.34923260609308876, 'Total loss': 0.34923260609308876} | train loss {'Reaction outcome loss': 0.30253104161280786, 'Total loss': 0.30253104161280786}
2023-01-04 01:15:37,920 INFO:     Found new best model at epoch 23
2023-01-04 01:15:37,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:37,921 INFO:     Epoch: 24
2023-01-04 01:15:39,509 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39714340964953104, 'Total loss': 0.39714340964953104} | train loss {'Reaction outcome loss': 0.298921029008653, 'Total loss': 0.298921029008653}
2023-01-04 01:15:39,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:39,509 INFO:     Epoch: 25
2023-01-04 01:15:41,096 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36951810916264854, 'Total loss': 0.36951810916264854} | train loss {'Reaction outcome loss': 0.2925291618291479, 'Total loss': 0.2925291618291479}
2023-01-04 01:15:41,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:41,096 INFO:     Epoch: 26
2023-01-04 01:15:42,686 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37060182889302573, 'Total loss': 0.37060182889302573} | train loss {'Reaction outcome loss': 0.2905275502724804, 'Total loss': 0.2905275502724804}
2023-01-04 01:15:42,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:42,687 INFO:     Epoch: 27
2023-01-04 01:15:44,256 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3714602102835973, 'Total loss': 0.3714602102835973} | train loss {'Reaction outcome loss': 0.2871555349361287, 'Total loss': 0.2871555349361287}
2023-01-04 01:15:44,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:44,257 INFO:     Epoch: 28
2023-01-04 01:15:45,859 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37782479226589205, 'Total loss': 0.37782479226589205} | train loss {'Reaction outcome loss': 0.28282660267648907, 'Total loss': 0.28282660267648907}
2023-01-04 01:15:45,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:45,859 INFO:     Epoch: 29
2023-01-04 01:15:47,466 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3786363959312439, 'Total loss': 0.3786363959312439} | train loss {'Reaction outcome loss': 0.2768016823560652, 'Total loss': 0.2768016823560652}
2023-01-04 01:15:47,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:47,467 INFO:     Epoch: 30
2023-01-04 01:15:49,065 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3520740161339442, 'Total loss': 0.3520740161339442} | train loss {'Reaction outcome loss': 0.27529912654065736, 'Total loss': 0.27529912654065736}
2023-01-04 01:15:49,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:49,066 INFO:     Epoch: 31
2023-01-04 01:15:50,656 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3485465774933497, 'Total loss': 0.3485465774933497} | train loss {'Reaction outcome loss': 0.2728291133241932, 'Total loss': 0.2728291133241932}
2023-01-04 01:15:50,656 INFO:     Found new best model at epoch 31
2023-01-04 01:15:50,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:50,657 INFO:     Epoch: 32
2023-01-04 01:15:52,224 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34796659151713055, 'Total loss': 0.34796659151713055} | train loss {'Reaction outcome loss': 0.2682498213529152, 'Total loss': 0.2682498213529152}
2023-01-04 01:15:52,224 INFO:     Found new best model at epoch 32
2023-01-04 01:15:52,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:52,225 INFO:     Epoch: 33
2023-01-04 01:15:53,828 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3518215229113897, 'Total loss': 0.3518215229113897} | train loss {'Reaction outcome loss': 0.263518910012106, 'Total loss': 0.263518910012106}
2023-01-04 01:15:53,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:53,829 INFO:     Epoch: 34
2023-01-04 01:15:55,442 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3447519838809967, 'Total loss': 0.3447519838809967} | train loss {'Reaction outcome loss': 0.26288555372152883, 'Total loss': 0.26288555372152883}
2023-01-04 01:15:55,442 INFO:     Found new best model at epoch 34
2023-01-04 01:15:55,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:55,443 INFO:     Epoch: 35
2023-01-04 01:15:57,053 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34787025650342307, 'Total loss': 0.34787025650342307} | train loss {'Reaction outcome loss': 0.2581839074727392, 'Total loss': 0.2581839074727392}
2023-01-04 01:15:57,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:57,054 INFO:     Epoch: 36
2023-01-04 01:15:58,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36150624652703606, 'Total loss': 0.36150624652703606} | train loss {'Reaction outcome loss': 0.2559342616013367, 'Total loss': 0.2559342616013367}
2023-01-04 01:15:58,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:15:58,652 INFO:     Epoch: 37
2023-01-04 01:16:00,261 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3612849513689677, 'Total loss': 0.3612849513689677} | train loss {'Reaction outcome loss': 0.2533174180255754, 'Total loss': 0.2533174180255754}
2023-01-04 01:16:00,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:00,262 INFO:     Epoch: 38
2023-01-04 01:16:01,825 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3469982698559761, 'Total loss': 0.3469982698559761} | train loss {'Reaction outcome loss': 0.25322856002208527, 'Total loss': 0.25322856002208527}
2023-01-04 01:16:01,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:01,826 INFO:     Epoch: 39
2023-01-04 01:16:03,432 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35156600922346115, 'Total loss': 0.35156600922346115} | train loss {'Reaction outcome loss': 0.24782056984131354, 'Total loss': 0.24782056984131354}
2023-01-04 01:16:03,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:03,432 INFO:     Epoch: 40
2023-01-04 01:16:05,048 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3677897314230601, 'Total loss': 0.3677897314230601} | train loss {'Reaction outcome loss': 0.24464025662491357, 'Total loss': 0.24464025662491357}
2023-01-04 01:16:05,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:05,048 INFO:     Epoch: 41
2023-01-04 01:16:06,664 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3568631942073504, 'Total loss': 0.3568631942073504} | train loss {'Reaction outcome loss': 0.24320343558261864, 'Total loss': 0.24320343558261864}
2023-01-04 01:16:06,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:06,665 INFO:     Epoch: 42
2023-01-04 01:16:08,264 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3822535609205564, 'Total loss': 0.3822535609205564} | train loss {'Reaction outcome loss': 0.23876530081577543, 'Total loss': 0.23876530081577543}
2023-01-04 01:16:08,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:08,264 INFO:     Epoch: 43
2023-01-04 01:16:09,841 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3538083950678507, 'Total loss': 0.3538083950678507} | train loss {'Reaction outcome loss': 0.24060727925087413, 'Total loss': 0.24060727925087413}
2023-01-04 01:16:09,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:09,841 INFO:     Epoch: 44
2023-01-04 01:16:11,400 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3730325291554133, 'Total loss': 0.3730325291554133} | train loss {'Reaction outcome loss': 0.23632491090382537, 'Total loss': 0.23632491090382537}
2023-01-04 01:16:11,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:11,400 INFO:     Epoch: 45
2023-01-04 01:16:12,992 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3637703816095988, 'Total loss': 0.3637703816095988} | train loss {'Reaction outcome loss': 0.23550891944200453, 'Total loss': 0.23550891944200453}
2023-01-04 01:16:12,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:12,992 INFO:     Epoch: 46
2023-01-04 01:16:14,583 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36822448869546254, 'Total loss': 0.36822448869546254} | train loss {'Reaction outcome loss': 0.2319453045059621, 'Total loss': 0.2319453045059621}
2023-01-04 01:16:14,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:14,584 INFO:     Epoch: 47
2023-01-04 01:16:16,184 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3665870428085327, 'Total loss': 0.3665870428085327} | train loss {'Reaction outcome loss': 0.2291386147322011, 'Total loss': 0.2291386147322011}
2023-01-04 01:16:16,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:16,185 INFO:     Epoch: 48
2023-01-04 01:16:17,763 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3611032605171204, 'Total loss': 0.3611032605171204} | train loss {'Reaction outcome loss': 0.22701852137807513, 'Total loss': 0.22701852137807513}
2023-01-04 01:16:17,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:17,763 INFO:     Epoch: 49
2023-01-04 01:16:19,339 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35548242231210075, 'Total loss': 0.35548242231210075} | train loss {'Reaction outcome loss': 0.2251692252627907, 'Total loss': 0.2251692252627907}
2023-01-04 01:16:19,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:19,340 INFO:     Epoch: 50
2023-01-04 01:16:20,921 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40934329231580097, 'Total loss': 0.40934329231580097} | train loss {'Reaction outcome loss': 0.2255480237658659, 'Total loss': 0.2255480237658659}
2023-01-04 01:16:20,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:20,922 INFO:     Epoch: 51
2023-01-04 01:16:22,512 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.332918518781662, 'Total loss': 0.332918518781662} | train loss {'Reaction outcome loss': 0.22076847404241562, 'Total loss': 0.22076847404241562}
2023-01-04 01:16:22,512 INFO:     Found new best model at epoch 51
2023-01-04 01:16:22,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:22,513 INFO:     Epoch: 52
2023-01-04 01:16:24,102 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.366696905096372, 'Total loss': 0.366696905096372} | train loss {'Reaction outcome loss': 0.22126359064267934, 'Total loss': 0.22126359064267934}
2023-01-04 01:16:24,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:24,102 INFO:     Epoch: 53
2023-01-04 01:16:25,690 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36383917133013405, 'Total loss': 0.36383917133013405} | train loss {'Reaction outcome loss': 0.21637073495717596, 'Total loss': 0.21637073495717596}
2023-01-04 01:16:25,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:25,690 INFO:     Epoch: 54
2023-01-04 01:16:27,281 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3821443170309067, 'Total loss': 0.3821443170309067} | train loss {'Reaction outcome loss': 0.2167216235785371, 'Total loss': 0.2167216235785371}
2023-01-04 01:16:27,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:27,281 INFO:     Epoch: 55
2023-01-04 01:16:28,839 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3689204355080922, 'Total loss': 0.3689204355080922} | train loss {'Reaction outcome loss': 0.2141615838818524, 'Total loss': 0.2141615838818524}
2023-01-04 01:16:28,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:28,840 INFO:     Epoch: 56
2023-01-04 01:16:30,451 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34796231041351955, 'Total loss': 0.34796231041351955} | train loss {'Reaction outcome loss': 0.21167164479457115, 'Total loss': 0.21167164479457115}
2023-01-04 01:16:30,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:30,451 INFO:     Epoch: 57
2023-01-04 01:16:32,063 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3724415401617686, 'Total loss': 0.3724415401617686} | train loss {'Reaction outcome loss': 0.2108663951257502, 'Total loss': 0.2108663951257502}
2023-01-04 01:16:32,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:32,064 INFO:     Epoch: 58
2023-01-04 01:16:33,675 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3767238368590673, 'Total loss': 0.3767238368590673} | train loss {'Reaction outcome loss': 0.20934177434792484, 'Total loss': 0.20934177434792484}
2023-01-04 01:16:33,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:33,676 INFO:     Epoch: 59
2023-01-04 01:16:35,288 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37421823541323346, 'Total loss': 0.37421823541323346} | train loss {'Reaction outcome loss': 0.2075118971104822, 'Total loss': 0.2075118971104822}
2023-01-04 01:16:35,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:35,289 INFO:     Epoch: 60
2023-01-04 01:16:36,896 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36096504429976145, 'Total loss': 0.36096504429976145} | train loss {'Reaction outcome loss': 0.2066358465592574, 'Total loss': 0.2066358465592574}
2023-01-04 01:16:36,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:36,896 INFO:     Epoch: 61
2023-01-04 01:16:38,464 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4005130539337794, 'Total loss': 0.4005130539337794} | train loss {'Reaction outcome loss': 0.20354709873506188, 'Total loss': 0.20354709873506188}
2023-01-04 01:16:38,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:38,464 INFO:     Epoch: 62
2023-01-04 01:16:40,057 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3858316799004873, 'Total loss': 0.3858316799004873} | train loss {'Reaction outcome loss': 0.20197836607422706, 'Total loss': 0.20197836607422706}
2023-01-04 01:16:40,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:40,057 INFO:     Epoch: 63
2023-01-04 01:16:41,670 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3826437880595525, 'Total loss': 0.3826437880595525} | train loss {'Reaction outcome loss': 0.19987804571805645, 'Total loss': 0.19987804571805645}
2023-01-04 01:16:41,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:41,670 INFO:     Epoch: 64
2023-01-04 01:16:43,288 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37628799776236216, 'Total loss': 0.37628799776236216} | train loss {'Reaction outcome loss': 0.19891117288846605, 'Total loss': 0.19891117288846605}
2023-01-04 01:16:43,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:43,288 INFO:     Epoch: 65
2023-01-04 01:16:44,904 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35836711327234905, 'Total loss': 0.35836711327234905} | train loss {'Reaction outcome loss': 0.19802631010865643, 'Total loss': 0.19802631010865643}
2023-01-04 01:16:44,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:44,904 INFO:     Epoch: 66
2023-01-04 01:16:46,457 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3516144216060638, 'Total loss': 0.3516144216060638} | train loss {'Reaction outcome loss': 0.1970340118600722, 'Total loss': 0.1970340118600722}
2023-01-04 01:16:46,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:46,457 INFO:     Epoch: 67
2023-01-04 01:16:48,066 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36262924373149874, 'Total loss': 0.36262924373149874} | train loss {'Reaction outcome loss': 0.19568535265424392, 'Total loss': 0.19568535265424392}
2023-01-04 01:16:48,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:48,066 INFO:     Epoch: 68
2023-01-04 01:16:49,674 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3990677148103714, 'Total loss': 0.3990677148103714} | train loss {'Reaction outcome loss': 0.19347243635051878, 'Total loss': 0.19347243635051878}
2023-01-04 01:16:49,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:49,675 INFO:     Epoch: 69
2023-01-04 01:16:51,286 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.382398850719134, 'Total loss': 0.382398850719134} | train loss {'Reaction outcome loss': 0.19165313062360034, 'Total loss': 0.19165313062360034}
2023-01-04 01:16:51,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:51,286 INFO:     Epoch: 70
2023-01-04 01:16:52,891 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38901103238264717, 'Total loss': 0.38901103238264717} | train loss {'Reaction outcome loss': 0.1896413104051221, 'Total loss': 0.1896413104051221}
2023-01-04 01:16:52,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:52,891 INFO:     Epoch: 71
2023-01-04 01:16:54,507 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3726242130001386, 'Total loss': 0.3726242130001386} | train loss {'Reaction outcome loss': 0.1900195294352126, 'Total loss': 0.1900195294352126}
2023-01-04 01:16:54,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:54,507 INFO:     Epoch: 72
2023-01-04 01:16:56,062 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37136173049608867, 'Total loss': 0.37136173049608867} | train loss {'Reaction outcome loss': 0.18830707323920987, 'Total loss': 0.18830707323920987}
2023-01-04 01:16:56,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:56,062 INFO:     Epoch: 73
2023-01-04 01:16:57,665 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3854102700948715, 'Total loss': 0.3854102700948715} | train loss {'Reaction outcome loss': 0.1858208178386201, 'Total loss': 0.1858208178386201}
2023-01-04 01:16:57,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:57,666 INFO:     Epoch: 74
2023-01-04 01:16:59,250 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35713575085004173, 'Total loss': 0.35713575085004173} | train loss {'Reaction outcome loss': 0.18584647621062114, 'Total loss': 0.18584647621062114}
2023-01-04 01:16:59,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:16:59,250 INFO:     Epoch: 75
2023-01-04 01:17:00,861 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3819342777132988, 'Total loss': 0.3819342777132988} | train loss {'Reaction outcome loss': 0.1865744638141163, 'Total loss': 0.1865744638141163}
2023-01-04 01:17:00,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:00,862 INFO:     Epoch: 76
2023-01-04 01:17:02,454 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38637912422418597, 'Total loss': 0.38637912422418597} | train loss {'Reaction outcome loss': 0.18514464089279845, 'Total loss': 0.18514464089279845}
2023-01-04 01:17:02,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:02,454 INFO:     Epoch: 77
2023-01-04 01:17:04,035 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38198717484871547, 'Total loss': 0.38198717484871547} | train loss {'Reaction outcome loss': 0.18263256889733956, 'Total loss': 0.18263256889733956}
2023-01-04 01:17:04,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:04,036 INFO:     Epoch: 78
2023-01-04 01:17:05,612 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38646754225095115, 'Total loss': 0.38646754225095115} | train loss {'Reaction outcome loss': 0.18308891031048158, 'Total loss': 0.18308891031048158}
2023-01-04 01:17:05,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:05,612 INFO:     Epoch: 79
2023-01-04 01:17:07,200 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36759422620137533, 'Total loss': 0.36759422620137533} | train loss {'Reaction outcome loss': 0.18295405072969023, 'Total loss': 0.18295405072969023}
2023-01-04 01:17:07,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:07,200 INFO:     Epoch: 80
2023-01-04 01:17:08,800 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3686871697505315, 'Total loss': 0.3686871697505315} | train loss {'Reaction outcome loss': 0.17895577790854622, 'Total loss': 0.17895577790854622}
2023-01-04 01:17:08,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:08,801 INFO:     Epoch: 81
2023-01-04 01:17:10,416 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38031379083792366, 'Total loss': 0.38031379083792366} | train loss {'Reaction outcome loss': 0.1806688328361968, 'Total loss': 0.1806688328361968}
2023-01-04 01:17:10,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:10,416 INFO:     Epoch: 82
2023-01-04 01:17:12,021 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3792746509114901, 'Total loss': 0.3792746509114901} | train loss {'Reaction outcome loss': 0.1781969894077221, 'Total loss': 0.1781969894077221}
2023-01-04 01:17:12,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:12,021 INFO:     Epoch: 83
2023-01-04 01:17:13,587 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4077560156583786, 'Total loss': 0.4077560156583786} | train loss {'Reaction outcome loss': 0.17579227123735813, 'Total loss': 0.17579227123735813}
2023-01-04 01:17:13,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:13,587 INFO:     Epoch: 84
2023-01-04 01:17:15,201 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3855831652879715, 'Total loss': 0.3855831652879715} | train loss {'Reaction outcome loss': 0.17634009394495592, 'Total loss': 0.17634009394495592}
2023-01-04 01:17:15,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:15,201 INFO:     Epoch: 85
2023-01-04 01:17:16,803 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35927232801914216, 'Total loss': 0.35927232801914216} | train loss {'Reaction outcome loss': 0.17649421479253874, 'Total loss': 0.17649421479253874}
2023-01-04 01:17:16,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:16,803 INFO:     Epoch: 86
2023-01-04 01:17:18,387 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3621984273195267, 'Total loss': 0.3621984273195267} | train loss {'Reaction outcome loss': 0.17759124212728364, 'Total loss': 0.17759124212728364}
2023-01-04 01:17:18,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:18,388 INFO:     Epoch: 87
2023-01-04 01:17:19,996 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36976957619190215, 'Total loss': 0.36976957619190215} | train loss {'Reaction outcome loss': 0.17376283025301067, 'Total loss': 0.17376283025301067}
2023-01-04 01:17:19,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:19,997 INFO:     Epoch: 88
2023-01-04 01:17:21,612 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37629006107648216, 'Total loss': 0.37629006107648216} | train loss {'Reaction outcome loss': 0.17245791897340848, 'Total loss': 0.17245791897340848}
2023-01-04 01:17:21,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:21,613 INFO:     Epoch: 89
2023-01-04 01:17:23,177 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4070353945096334, 'Total loss': 0.4070353945096334} | train loss {'Reaction outcome loss': 0.1730547800496982, 'Total loss': 0.1730547800496982}
2023-01-04 01:17:23,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:23,177 INFO:     Epoch: 90
2023-01-04 01:17:24,802 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34487962126731875, 'Total loss': 0.34487962126731875} | train loss {'Reaction outcome loss': 0.17151102130675186, 'Total loss': 0.17151102130675186}
2023-01-04 01:17:24,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:24,802 INFO:     Epoch: 91
2023-01-04 01:17:26,415 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3774123291174571, 'Total loss': 0.3774123291174571} | train loss {'Reaction outcome loss': 0.17123423416140307, 'Total loss': 0.17123423416140307}
2023-01-04 01:17:26,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:26,416 INFO:     Epoch: 92
2023-01-04 01:17:27,992 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37200951029857, 'Total loss': 0.37200951029857} | train loss {'Reaction outcome loss': 0.17046707148670498, 'Total loss': 0.17046707148670498}
2023-01-04 01:17:27,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:27,992 INFO:     Epoch: 93
2023-01-04 01:17:29,606 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.395564271012942, 'Total loss': 0.395564271012942} | train loss {'Reaction outcome loss': 0.1665757730072976, 'Total loss': 0.1665757730072976}
2023-01-04 01:17:29,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:29,606 INFO:     Epoch: 94
2023-01-04 01:17:31,205 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39075390497843426, 'Total loss': 0.39075390497843426} | train loss {'Reaction outcome loss': 0.16836971090766636, 'Total loss': 0.16836971090766636}
2023-01-04 01:17:31,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:31,205 INFO:     Epoch: 95
2023-01-04 01:17:32,770 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3979828730225563, 'Total loss': 0.3979828730225563} | train loss {'Reaction outcome loss': 0.16901729816747627, 'Total loss': 0.16901729816747627}
2023-01-04 01:17:32,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:32,771 INFO:     Epoch: 96
2023-01-04 01:17:34,361 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39739143550395967, 'Total loss': 0.39739143550395967} | train loss {'Reaction outcome loss': 0.1668530163239606, 'Total loss': 0.1668530163239606}
2023-01-04 01:17:34,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:34,361 INFO:     Epoch: 97
2023-01-04 01:17:35,952 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3935914208491643, 'Total loss': 0.3935914208491643} | train loss {'Reaction outcome loss': 0.16669385375822113, 'Total loss': 0.16669385375822113}
2023-01-04 01:17:35,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:35,952 INFO:     Epoch: 98
2023-01-04 01:17:37,567 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37797122200330097, 'Total loss': 0.37797122200330097} | train loss {'Reaction outcome loss': 0.16469387720291415, 'Total loss': 0.16469387720291415}
2023-01-04 01:17:37,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:37,567 INFO:     Epoch: 99
2023-01-04 01:17:39,168 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37465355296929675, 'Total loss': 0.37465355296929675} | train loss {'Reaction outcome loss': 0.16633194539505636, 'Total loss': 0.16633194539505636}
2023-01-04 01:17:39,169 INFO:     Best model found after epoch 52 of 100.
2023-01-04 01:17:39,169 INFO:   Done with stage: TRAINING
2023-01-04 01:17:39,169 INFO:   Starting stage: EVALUATION
2023-01-04 01:17:39,303 INFO:   Done with stage: EVALUATION
2023-01-04 01:17:39,303 INFO:   Leaving out SEQ value Fold_3
2023-01-04 01:17:39,316 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 01:17:39,316 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:17:39,961 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:17:39,961 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:17:40,031 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:17:40,031 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:17:40,031 INFO:     No hyperparam tuning for this model
2023-01-04 01:17:40,031 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:17:40,031 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:17:40,032 INFO:     None feature selector for col prot
2023-01-04 01:17:40,032 INFO:     None feature selector for col prot
2023-01-04 01:17:40,032 INFO:     None feature selector for col prot
2023-01-04 01:17:40,033 INFO:     None feature selector for col chem
2023-01-04 01:17:40,033 INFO:     None feature selector for col chem
2023-01-04 01:17:40,033 INFO:     None feature selector for col chem
2023-01-04 01:17:40,033 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:17:40,033 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:17:40,034 INFO:     Number of params in model 70141
2023-01-04 01:17:40,038 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:17:40,038 INFO:   Starting stage: TRAINING
2023-01-04 01:17:40,079 INFO:     Val loss before train {'Reaction outcome loss': 0.9499588926633199, 'Total loss': 0.9499588926633199}
2023-01-04 01:17:40,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:40,079 INFO:     Epoch: 0
2023-01-04 01:17:41,646 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6890767653783162, 'Total loss': 0.6890767653783162} | train loss {'Reaction outcome loss': 0.8795446540628161, 'Total loss': 0.8795446540628161}
2023-01-04 01:17:41,646 INFO:     Found new best model at epoch 0
2023-01-04 01:17:41,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:41,647 INFO:     Epoch: 1
2023-01-04 01:17:43,228 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5349320948123932, 'Total loss': 0.5349320948123932} | train loss {'Reaction outcome loss': 0.6340092777005045, 'Total loss': 0.6340092777005045}
2023-01-04 01:17:43,229 INFO:     Found new best model at epoch 1
2023-01-04 01:17:43,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:43,230 INFO:     Epoch: 2
2023-01-04 01:17:44,811 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.469394056002299, 'Total loss': 0.469394056002299} | train loss {'Reaction outcome loss': 0.5395294863989938, 'Total loss': 0.5395294863989938}
2023-01-04 01:17:44,811 INFO:     Found new best model at epoch 2
2023-01-04 01:17:44,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:44,812 INFO:     Epoch: 3
2023-01-04 01:17:46,395 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4549183358748754, 'Total loss': 0.4549183358748754} | train loss {'Reaction outcome loss': 0.49913033570125426, 'Total loss': 0.49913033570125426}
2023-01-04 01:17:46,395 INFO:     Found new best model at epoch 3
2023-01-04 01:17:46,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:46,396 INFO:     Epoch: 4
2023-01-04 01:17:47,997 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45131147305170694, 'Total loss': 0.45131147305170694} | train loss {'Reaction outcome loss': 0.47084648317688116, 'Total loss': 0.47084648317688116}
2023-01-04 01:17:47,998 INFO:     Found new best model at epoch 4
2023-01-04 01:17:47,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:47,999 INFO:     Epoch: 5
2023-01-04 01:17:49,561 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4339727650086085, 'Total loss': 0.4339727650086085} | train loss {'Reaction outcome loss': 0.4518139151098964, 'Total loss': 0.4518139151098964}
2023-01-04 01:17:49,561 INFO:     Found new best model at epoch 5
2023-01-04 01:17:49,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:49,562 INFO:     Epoch: 6
2023-01-04 01:17:51,169 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4428839415311813, 'Total loss': 0.4428839415311813} | train loss {'Reaction outcome loss': 0.433673762467318, 'Total loss': 0.433673762467318}
2023-01-04 01:17:51,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:51,170 INFO:     Epoch: 7
2023-01-04 01:17:52,781 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4207798957824707, 'Total loss': 0.4207798957824707} | train loss {'Reaction outcome loss': 0.4160891690533676, 'Total loss': 0.4160891690533676}
2023-01-04 01:17:52,781 INFO:     Found new best model at epoch 7
2023-01-04 01:17:52,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:52,782 INFO:     Epoch: 8
2023-01-04 01:17:54,370 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39367830753326416, 'Total loss': 0.39367830753326416} | train loss {'Reaction outcome loss': 0.40599213464137834, 'Total loss': 0.40599213464137834}
2023-01-04 01:17:54,370 INFO:     Found new best model at epoch 8
2023-01-04 01:17:54,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:54,371 INFO:     Epoch: 9
2023-01-04 01:17:55,946 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41642898122469585, 'Total loss': 0.41642898122469585} | train loss {'Reaction outcome loss': 0.3932276265798034, 'Total loss': 0.3932276265798034}
2023-01-04 01:17:55,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:55,947 INFO:     Epoch: 10
2023-01-04 01:17:57,555 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.394584854443868, 'Total loss': 0.394584854443868} | train loss {'Reaction outcome loss': 0.3810307014010328, 'Total loss': 0.3810307014010328}
2023-01-04 01:17:57,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:57,556 INFO:     Epoch: 11
2023-01-04 01:17:59,120 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4099354604880015, 'Total loss': 0.4099354604880015} | train loss {'Reaction outcome loss': 0.37175715837504836, 'Total loss': 0.37175715837504836}
2023-01-04 01:17:59,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:17:59,120 INFO:     Epoch: 12
2023-01-04 01:18:00,732 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3983236163854599, 'Total loss': 0.3983236163854599} | train loss {'Reaction outcome loss': 0.3658084497128651, 'Total loss': 0.3658084497128651}
2023-01-04 01:18:00,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:00,733 INFO:     Epoch: 13
2023-01-04 01:18:02,325 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39148625830809275, 'Total loss': 0.39148625830809275} | train loss {'Reaction outcome loss': 0.35354272696452266, 'Total loss': 0.35354272696452266}
2023-01-04 01:18:02,325 INFO:     Found new best model at epoch 13
2023-01-04 01:18:02,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:02,326 INFO:     Epoch: 14
2023-01-04 01:18:03,937 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39849263727664946, 'Total loss': 0.39849263727664946} | train loss {'Reaction outcome loss': 0.34490461116690774, 'Total loss': 0.34490461116690774}
2023-01-04 01:18:03,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:03,938 INFO:     Epoch: 15
2023-01-04 01:18:05,550 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38818664650122325, 'Total loss': 0.38818664650122325} | train loss {'Reaction outcome loss': 0.33830446504302075, 'Total loss': 0.33830446504302075}
2023-01-04 01:18:05,550 INFO:     Found new best model at epoch 15
2023-01-04 01:18:05,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:05,551 INFO:     Epoch: 16
2023-01-04 01:18:07,155 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37814389367898305, 'Total loss': 0.37814389367898305} | train loss {'Reaction outcome loss': 0.3310403238449778, 'Total loss': 0.3310403238449778}
2023-01-04 01:18:07,156 INFO:     Found new best model at epoch 16
2023-01-04 01:18:07,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:07,156 INFO:     Epoch: 17
2023-01-04 01:18:08,743 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3798232475916545, 'Total loss': 0.3798232475916545} | train loss {'Reaction outcome loss': 0.3253364553896799, 'Total loss': 0.3253364553896799}
2023-01-04 01:18:08,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:08,743 INFO:     Epoch: 18
2023-01-04 01:18:10,362 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3939094622929891, 'Total loss': 0.3939094622929891} | train loss {'Reaction outcome loss': 0.3191444959505137, 'Total loss': 0.3191444959505137}
2023-01-04 01:18:10,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:10,363 INFO:     Epoch: 19
2023-01-04 01:18:11,976 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38585735062758125, 'Total loss': 0.38585735062758125} | train loss {'Reaction outcome loss': 0.3144992421016152, 'Total loss': 0.3144992421016152}
2023-01-04 01:18:11,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:11,976 INFO:     Epoch: 20
2023-01-04 01:18:13,596 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38035659193992616, 'Total loss': 0.38035659193992616} | train loss {'Reaction outcome loss': 0.3081124858323471, 'Total loss': 0.3081124858323471}
2023-01-04 01:18:13,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:13,596 INFO:     Epoch: 21
2023-01-04 01:18:15,212 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37091945509115853, 'Total loss': 0.37091945509115853} | train loss {'Reaction outcome loss': 0.30642668668167056, 'Total loss': 0.30642668668167056}
2023-01-04 01:18:15,212 INFO:     Found new best model at epoch 21
2023-01-04 01:18:15,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:15,213 INFO:     Epoch: 22
2023-01-04 01:18:16,795 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3823903908332189, 'Total loss': 0.3823903908332189} | train loss {'Reaction outcome loss': 0.30042006467015314, 'Total loss': 0.30042006467015314}
2023-01-04 01:18:16,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:16,795 INFO:     Epoch: 23
2023-01-04 01:18:18,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3754046420256297, 'Total loss': 0.3754046420256297} | train loss {'Reaction outcome loss': 0.29415373725223015, 'Total loss': 0.29415373725223015}
2023-01-04 01:18:18,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:18,366 INFO:     Epoch: 24
2023-01-04 01:18:19,936 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3762799213329951, 'Total loss': 0.3762799213329951} | train loss {'Reaction outcome loss': 0.2905956786467042, 'Total loss': 0.2905956786467042}
2023-01-04 01:18:19,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:19,937 INFO:     Epoch: 25
2023-01-04 01:18:21,546 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37852585117022197, 'Total loss': 0.37852585117022197} | train loss {'Reaction outcome loss': 0.2878003227405059, 'Total loss': 0.2878003227405059}
2023-01-04 01:18:21,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:21,547 INFO:     Epoch: 26
2023-01-04 01:18:23,145 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36919681429862977, 'Total loss': 0.36919681429862977} | train loss {'Reaction outcome loss': 0.2822442602761936, 'Total loss': 0.2822442602761936}
2023-01-04 01:18:23,145 INFO:     Found new best model at epoch 26
2023-01-04 01:18:23,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:23,146 INFO:     Epoch: 27
2023-01-04 01:18:24,737 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3834782679875692, 'Total loss': 0.3834782679875692} | train loss {'Reaction outcome loss': 0.28061380428381455, 'Total loss': 0.28061380428381455}
2023-01-04 01:18:24,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:24,737 INFO:     Epoch: 28
2023-01-04 01:18:26,290 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35664118230342867, 'Total loss': 0.35664118230342867} | train loss {'Reaction outcome loss': 0.2745556665700434, 'Total loss': 0.2745556665700434}
2023-01-04 01:18:26,290 INFO:     Found new best model at epoch 28
2023-01-04 01:18:26,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:26,291 INFO:     Epoch: 29
2023-01-04 01:18:27,899 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3457706535855929, 'Total loss': 0.3457706535855929} | train loss {'Reaction outcome loss': 0.2728001918275278, 'Total loss': 0.2728001918275278}
2023-01-04 01:18:27,900 INFO:     Found new best model at epoch 29
2023-01-04 01:18:27,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:27,901 INFO:     Epoch: 30
2023-01-04 01:18:29,508 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38209665815035504, 'Total loss': 0.38209665815035504} | train loss {'Reaction outcome loss': 0.26896898408894576, 'Total loss': 0.26896898408894576}
2023-01-04 01:18:29,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:29,508 INFO:     Epoch: 31
2023-01-04 01:18:31,116 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38015458087126414, 'Total loss': 0.38015458087126414} | train loss {'Reaction outcome loss': 0.26670423938787025, 'Total loss': 0.26670423938787025}
2023-01-04 01:18:31,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:31,117 INFO:     Epoch: 32
2023-01-04 01:18:32,725 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37006453474362694, 'Total loss': 0.37006453474362694} | train loss {'Reaction outcome loss': 0.2632410504305974, 'Total loss': 0.2632410504305974}
2023-01-04 01:18:32,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:32,725 INFO:     Epoch: 33
2023-01-04 01:18:34,335 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3737396776676178, 'Total loss': 0.3737396776676178} | train loss {'Reaction outcome loss': 0.25713844931660557, 'Total loss': 0.25713844931660557}
2023-01-04 01:18:34,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:34,336 INFO:     Epoch: 34
2023-01-04 01:18:35,879 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.371291184425354, 'Total loss': 0.371291184425354} | train loss {'Reaction outcome loss': 0.257250621341742, 'Total loss': 0.257250621341742}
2023-01-04 01:18:35,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:35,879 INFO:     Epoch: 35
2023-01-04 01:18:37,457 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3748017489910126, 'Total loss': 0.3748017489910126} | train loss {'Reaction outcome loss': 0.2527827073584546, 'Total loss': 0.2527827073584546}
2023-01-04 01:18:37,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:37,457 INFO:     Epoch: 36
2023-01-04 01:18:39,034 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3592427174250285, 'Total loss': 0.3592427174250285} | train loss {'Reaction outcome loss': 0.24875892885029316, 'Total loss': 0.24875892885029316}
2023-01-04 01:18:39,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:39,034 INFO:     Epoch: 37
2023-01-04 01:18:40,612 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36502372523148857, 'Total loss': 0.36502372523148857} | train loss {'Reaction outcome loss': 0.24609685593690628, 'Total loss': 0.24609685593690628}
2023-01-04 01:18:40,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:40,613 INFO:     Epoch: 38
2023-01-04 01:18:42,188 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3712440401315689, 'Total loss': 0.3712440401315689} | train loss {'Reaction outcome loss': 0.24429035418745362, 'Total loss': 0.24429035418745362}
2023-01-04 01:18:42,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:42,189 INFO:     Epoch: 39
2023-01-04 01:18:43,742 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3788292080163956, 'Total loss': 0.3788292080163956} | train loss {'Reaction outcome loss': 0.24468410633258766, 'Total loss': 0.24468410633258766}
2023-01-04 01:18:43,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:43,743 INFO:     Epoch: 40
2023-01-04 01:18:45,338 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37399948835372926, 'Total loss': 0.37399948835372926} | train loss {'Reaction outcome loss': 0.2422184354110515, 'Total loss': 0.2422184354110515}
2023-01-04 01:18:45,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:45,338 INFO:     Epoch: 41
2023-01-04 01:18:46,951 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3455415894587835, 'Total loss': 0.3455415894587835} | train loss {'Reaction outcome loss': 0.23861020799357813, 'Total loss': 0.23861020799357813}
2023-01-04 01:18:46,951 INFO:     Found new best model at epoch 41
2023-01-04 01:18:46,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:46,952 INFO:     Epoch: 42
2023-01-04 01:18:48,565 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3444718678792318, 'Total loss': 0.3444718678792318} | train loss {'Reaction outcome loss': 0.23688082858551662, 'Total loss': 0.23688082858551662}
2023-01-04 01:18:48,565 INFO:     Found new best model at epoch 42
2023-01-04 01:18:48,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:48,566 INFO:     Epoch: 43
2023-01-04 01:18:50,175 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34903042018413544, 'Total loss': 0.34903042018413544} | train loss {'Reaction outcome loss': 0.23278725454276736, 'Total loss': 0.23278725454276736}
2023-01-04 01:18:50,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:50,176 INFO:     Epoch: 44
2023-01-04 01:18:51,785 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35933863520622256, 'Total loss': 0.35933863520622256} | train loss {'Reaction outcome loss': 0.23286914571628467, 'Total loss': 0.23286914571628467}
2023-01-04 01:18:51,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:51,785 INFO:     Epoch: 45
2023-01-04 01:18:53,332 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35394588907559715, 'Total loss': 0.35394588907559715} | train loss {'Reaction outcome loss': 0.22892001171633874, 'Total loss': 0.22892001171633874}
2023-01-04 01:18:53,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:53,333 INFO:     Epoch: 46
2023-01-04 01:18:54,913 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35182564953962964, 'Total loss': 0.35182564953962964} | train loss {'Reaction outcome loss': 0.22652773710561322, 'Total loss': 0.22652773710561322}
2023-01-04 01:18:54,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:54,913 INFO:     Epoch: 47
2023-01-04 01:18:56,536 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3565035502115885, 'Total loss': 0.3565035502115885} | train loss {'Reaction outcome loss': 0.22479477190436462, 'Total loss': 0.22479477190436462}
2023-01-04 01:18:56,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:56,536 INFO:     Epoch: 48
2023-01-04 01:18:58,146 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3618063390254974, 'Total loss': 0.3618063390254974} | train loss {'Reaction outcome loss': 0.2230821424752351, 'Total loss': 0.2230821424752351}
2023-01-04 01:18:58,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:58,147 INFO:     Epoch: 49
2023-01-04 01:18:59,762 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3463924785455068, 'Total loss': 0.3463924785455068} | train loss {'Reaction outcome loss': 0.21944007237916027, 'Total loss': 0.21944007237916027}
2023-01-04 01:18:59,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:18:59,763 INFO:     Epoch: 50
2023-01-04 01:19:01,379 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35785094896952313, 'Total loss': 0.35785094896952313} | train loss {'Reaction outcome loss': 0.2198016440202465, 'Total loss': 0.2198016440202465}
2023-01-04 01:19:01,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:01,379 INFO:     Epoch: 51
2023-01-04 01:19:02,924 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36024466156959534, 'Total loss': 0.36024466156959534} | train loss {'Reaction outcome loss': 0.21765020405089025, 'Total loss': 0.21765020405089025}
2023-01-04 01:19:02,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:02,924 INFO:     Epoch: 52
2023-01-04 01:19:04,509 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37810143927733103, 'Total loss': 0.37810143927733103} | train loss {'Reaction outcome loss': 0.21710837138441455, 'Total loss': 0.21710837138441455}
2023-01-04 01:19:04,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:04,510 INFO:     Epoch: 53
2023-01-04 01:19:06,083 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3747311681509018, 'Total loss': 0.3747311681509018} | train loss {'Reaction outcome loss': 0.21538260650067104, 'Total loss': 0.21538260650067104}
2023-01-04 01:19:06,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:06,083 INFO:     Epoch: 54
2023-01-04 01:19:07,667 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39084459344546, 'Total loss': 0.39084459344546} | train loss {'Reaction outcome loss': 0.20951107497098465, 'Total loss': 0.20951107497098465}
2023-01-04 01:19:07,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:07,667 INFO:     Epoch: 55
2023-01-04 01:19:09,249 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3527040871481101, 'Total loss': 0.3527040871481101} | train loss {'Reaction outcome loss': 0.20884736621882016, 'Total loss': 0.20884736621882016}
2023-01-04 01:19:09,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:09,249 INFO:     Epoch: 56
2023-01-04 01:19:10,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34819703102111815, 'Total loss': 0.34819703102111815} | train loss {'Reaction outcome loss': 0.20781506824515242, 'Total loss': 0.20781506824515242}
2023-01-04 01:19:10,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:10,823 INFO:     Epoch: 57
2023-01-04 01:19:12,429 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37287458082040154, 'Total loss': 0.37287458082040154} | train loss {'Reaction outcome loss': 0.20700996953161646, 'Total loss': 0.20700996953161646}
2023-01-04 01:19:12,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:12,430 INFO:     Epoch: 58
2023-01-04 01:19:14,049 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36468521555264793, 'Total loss': 0.36468521555264793} | train loss {'Reaction outcome loss': 0.20702063902230053, 'Total loss': 0.20702063902230053}
2023-01-04 01:19:14,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:14,050 INFO:     Epoch: 59
2023-01-04 01:19:15,657 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3534164309501648, 'Total loss': 0.3534164309501648} | train loss {'Reaction outcome loss': 0.20413282575024352, 'Total loss': 0.20413282575024352}
2023-01-04 01:19:15,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:15,657 INFO:     Epoch: 60
2023-01-04 01:19:17,264 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38845475514729816, 'Total loss': 0.38845475514729816} | train loss {'Reaction outcome loss': 0.20376261945936705, 'Total loss': 0.20376261945936705}
2023-01-04 01:19:17,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:17,264 INFO:     Epoch: 61
2023-01-04 01:19:18,884 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3867686962087949, 'Total loss': 0.3867686962087949} | train loss {'Reaction outcome loss': 0.20215801717269988, 'Total loss': 0.20215801717269988}
2023-01-04 01:19:18,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:18,884 INFO:     Epoch: 62
2023-01-04 01:19:20,438 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3479344884554545, 'Total loss': 0.3479344884554545} | train loss {'Reaction outcome loss': 0.198222908797766, 'Total loss': 0.198222908797766}
2023-01-04 01:19:20,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:20,438 INFO:     Epoch: 63
2023-01-04 01:19:22,058 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3673788736263911, 'Total loss': 0.3673788736263911} | train loss {'Reaction outcome loss': 0.19856280121174488, 'Total loss': 0.19856280121174488}
2023-01-04 01:19:22,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:22,058 INFO:     Epoch: 64
2023-01-04 01:19:23,658 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36796751817067463, 'Total loss': 0.36796751817067463} | train loss {'Reaction outcome loss': 0.1984897450690632, 'Total loss': 0.1984897450690632}
2023-01-04 01:19:23,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:23,658 INFO:     Epoch: 65
2023-01-04 01:19:25,242 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38303474287192024, 'Total loss': 0.38303474287192024} | train loss {'Reaction outcome loss': 0.1964824028149411, 'Total loss': 0.1964824028149411}
2023-01-04 01:19:25,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:25,242 INFO:     Epoch: 66
2023-01-04 01:19:26,826 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37515708804130554, 'Total loss': 0.37515708804130554} | train loss {'Reaction outcome loss': 0.1957564726198986, 'Total loss': 0.1957564726198986}
2023-01-04 01:19:26,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:26,826 INFO:     Epoch: 67
2023-01-04 01:19:28,410 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36970102389653525, 'Total loss': 0.36970102389653525} | train loss {'Reaction outcome loss': 0.1939840324141167, 'Total loss': 0.1939840324141167}
2023-01-04 01:19:28,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:28,411 INFO:     Epoch: 68
2023-01-04 01:19:29,954 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3669972211122513, 'Total loss': 0.3669972211122513} | train loss {'Reaction outcome loss': 0.19342555210758478, 'Total loss': 0.19342555210758478}
2023-01-04 01:19:29,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:29,955 INFO:     Epoch: 69
2023-01-04 01:19:31,537 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35494604309399924, 'Total loss': 0.35494604309399924} | train loss {'Reaction outcome loss': 0.19006613173928016, 'Total loss': 0.19006613173928016}
2023-01-04 01:19:31,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:31,538 INFO:     Epoch: 70
2023-01-04 01:19:33,121 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.380833267668883, 'Total loss': 0.380833267668883} | train loss {'Reaction outcome loss': 0.18936683810674226, 'Total loss': 0.18936683810674226}
2023-01-04 01:19:33,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:33,121 INFO:     Epoch: 71
2023-01-04 01:19:34,704 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3575764755407969, 'Total loss': 0.3575764755407969} | train loss {'Reaction outcome loss': 0.18932133158430076, 'Total loss': 0.18932133158430076}
2023-01-04 01:19:34,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:34,705 INFO:     Epoch: 72
2023-01-04 01:19:36,286 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37433609714110694, 'Total loss': 0.37433609714110694} | train loss {'Reaction outcome loss': 0.18768186741013884, 'Total loss': 0.18768186741013884}
2023-01-04 01:19:36,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:36,287 INFO:     Epoch: 73
2023-01-04 01:19:37,765 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3715299487113953, 'Total loss': 0.3715299487113953} | train loss {'Reaction outcome loss': 0.18744398055823294, 'Total loss': 0.18744398055823294}
2023-01-04 01:19:37,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:37,766 INFO:     Epoch: 74
2023-01-04 01:19:38,832 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38043687442938484, 'Total loss': 0.38043687442938484} | train loss {'Reaction outcome loss': 0.18890255085114158, 'Total loss': 0.18890255085114158}
2023-01-04 01:19:38,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:38,832 INFO:     Epoch: 75
2023-01-04 01:19:39,888 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39254478414853416, 'Total loss': 0.39254478414853416} | train loss {'Reaction outcome loss': 0.1843894442539976, 'Total loss': 0.1843894442539976}
2023-01-04 01:19:39,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:39,888 INFO:     Epoch: 76
2023-01-04 01:19:40,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3750100831190745, 'Total loss': 0.3750100831190745} | train loss {'Reaction outcome loss': 0.18494078203107847, 'Total loss': 0.18494078203107847}
2023-01-04 01:19:40,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:40,946 INFO:     Epoch: 77
2023-01-04 01:19:42,000 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36049772600332897, 'Total loss': 0.36049772600332897} | train loss {'Reaction outcome loss': 0.18257851936878303, 'Total loss': 0.18257851936878303}
2023-01-04 01:19:42,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:42,000 INFO:     Epoch: 78
2023-01-04 01:19:43,566 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4033389940857887, 'Total loss': 0.4033389940857887} | train loss {'Reaction outcome loss': 0.180269665456626, 'Total loss': 0.180269665456626}
2023-01-04 01:19:43,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:43,566 INFO:     Epoch: 79
2023-01-04 01:19:45,124 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35568497429291407, 'Total loss': 0.35568497429291407} | train loss {'Reaction outcome loss': 0.18451131428950107, 'Total loss': 0.18451131428950107}
2023-01-04 01:19:45,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:45,124 INFO:     Epoch: 80
2023-01-04 01:19:46,747 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35553471744060516, 'Total loss': 0.35553471744060516} | train loss {'Reaction outcome loss': 0.18218698025759542, 'Total loss': 0.18218698025759542}
2023-01-04 01:19:46,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:46,748 INFO:     Epoch: 81
2023-01-04 01:19:48,372 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3639842391014099, 'Total loss': 0.3639842391014099} | train loss {'Reaction outcome loss': 0.1815187012087622, 'Total loss': 0.1815187012087622}
2023-01-04 01:19:48,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:48,373 INFO:     Epoch: 82
2023-01-04 01:19:49,976 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3552998771270116, 'Total loss': 0.3552998771270116} | train loss {'Reaction outcome loss': 0.17927399791449636, 'Total loss': 0.17927399791449636}
2023-01-04 01:19:49,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:49,976 INFO:     Epoch: 83
2023-01-04 01:19:51,534 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36443007588386533, 'Total loss': 0.36443007588386533} | train loss {'Reaction outcome loss': 0.1810591459383458, 'Total loss': 0.1810591459383458}
2023-01-04 01:19:51,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:51,534 INFO:     Epoch: 84
2023-01-04 01:19:53,137 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37440318961938224, 'Total loss': 0.37440318961938224} | train loss {'Reaction outcome loss': 0.18113762048165222, 'Total loss': 0.18113762048165222}
2023-01-04 01:19:53,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:53,137 INFO:     Epoch: 85
2023-01-04 01:19:54,720 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36794141083955767, 'Total loss': 0.36794141083955767} | train loss {'Reaction outcome loss': 0.17680521990981077, 'Total loss': 0.17680521990981077}
2023-01-04 01:19:54,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:54,720 INFO:     Epoch: 86
2023-01-04 01:19:56,331 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36701255838076274, 'Total loss': 0.36701255838076274} | train loss {'Reaction outcome loss': 0.17821203060311713, 'Total loss': 0.17821203060311713}
2023-01-04 01:19:56,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:56,332 INFO:     Epoch: 87
2023-01-04 01:19:57,948 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3807693958282471, 'Total loss': 0.3807693958282471} | train loss {'Reaction outcome loss': 0.17623820208395138, 'Total loss': 0.17623820208395138}
2023-01-04 01:19:57,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:57,949 INFO:     Epoch: 88
2023-01-04 01:19:59,560 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.379937836031119, 'Total loss': 0.379937836031119} | train loss {'Reaction outcome loss': 0.1778159874658554, 'Total loss': 0.1778159874658554}
2023-01-04 01:19:59,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:19:59,561 INFO:     Epoch: 89
2023-01-04 01:20:01,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36713257332642873, 'Total loss': 0.36713257332642873} | train loss {'Reaction outcome loss': 0.17440016421697516, 'Total loss': 0.17440016421697516}
2023-01-04 01:20:01,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:01,128 INFO:     Epoch: 90
2023-01-04 01:20:02,717 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35266470710436504, 'Total loss': 0.35266470710436504} | train loss {'Reaction outcome loss': 0.1729109640414025, 'Total loss': 0.1729109640414025}
2023-01-04 01:20:02,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:02,717 INFO:     Epoch: 91
2023-01-04 01:20:04,301 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37127213875452675, 'Total loss': 0.37127213875452675} | train loss {'Reaction outcome loss': 0.1736958479652038, 'Total loss': 0.1736958479652038}
2023-01-04 01:20:04,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:04,301 INFO:     Epoch: 92
2023-01-04 01:20:05,913 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3733783255020777, 'Total loss': 0.3733783255020777} | train loss {'Reaction outcome loss': 0.1749344655165906, 'Total loss': 0.1749344655165906}
2023-01-04 01:20:05,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:05,914 INFO:     Epoch: 93
2023-01-04 01:20:07,519 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38402275641759237, 'Total loss': 0.38402275641759237} | train loss {'Reaction outcome loss': 0.173268705033339, 'Total loss': 0.173268705033339}
2023-01-04 01:20:07,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:07,520 INFO:     Epoch: 94
2023-01-04 01:20:09,085 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37448734243710835, 'Total loss': 0.37448734243710835} | train loss {'Reaction outcome loss': 0.17248504050758295, 'Total loss': 0.17248504050758295}
2023-01-04 01:20:09,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:09,085 INFO:     Epoch: 95
2023-01-04 01:20:10,646 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3881467208266258, 'Total loss': 0.3881467208266258} | train loss {'Reaction outcome loss': 0.17126223824290565, 'Total loss': 0.17126223824290565}
2023-01-04 01:20:10,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:10,647 INFO:     Epoch: 96
2023-01-04 01:20:12,209 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3733075608809789, 'Total loss': 0.3733075608809789} | train loss {'Reaction outcome loss': 0.17013177612707728, 'Total loss': 0.17013177612707728}
2023-01-04 01:20:12,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:12,210 INFO:     Epoch: 97
2023-01-04 01:20:13,825 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3719259281953176, 'Total loss': 0.3719259281953176} | train loss {'Reaction outcome loss': 0.16922652975216015, 'Total loss': 0.16922652975216015}
2023-01-04 01:20:13,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:13,825 INFO:     Epoch: 98
2023-01-04 01:20:15,431 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38057486017545067, 'Total loss': 0.38057486017545067} | train loss {'Reaction outcome loss': 0.16926218755543232, 'Total loss': 0.16926218755543232}
2023-01-04 01:20:15,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:15,432 INFO:     Epoch: 99
2023-01-04 01:20:17,040 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39765727321306865, 'Total loss': 0.39765727321306865} | train loss {'Reaction outcome loss': 0.16922400616136662, 'Total loss': 0.16922400616136662}
2023-01-04 01:20:17,040 INFO:     Best model found after epoch 43 of 100.
2023-01-04 01:20:17,041 INFO:   Done with stage: TRAINING
2023-01-04 01:20:17,041 INFO:   Starting stage: EVALUATION
2023-01-04 01:20:17,181 INFO:   Done with stage: EVALUATION
2023-01-04 01:20:17,182 INFO:   Leaving out SEQ value Fold_4
2023-01-04 01:20:17,194 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:20:17,194 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:20:17,843 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:20:17,843 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:20:17,912 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:20:17,913 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:20:17,913 INFO:     No hyperparam tuning for this model
2023-01-04 01:20:17,913 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:20:17,913 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:20:17,914 INFO:     None feature selector for col prot
2023-01-04 01:20:17,914 INFO:     None feature selector for col prot
2023-01-04 01:20:17,914 INFO:     None feature selector for col prot
2023-01-04 01:20:17,915 INFO:     None feature selector for col chem
2023-01-04 01:20:17,915 INFO:     None feature selector for col chem
2023-01-04 01:20:17,915 INFO:     None feature selector for col chem
2023-01-04 01:20:17,915 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:20:17,915 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:20:17,916 INFO:     Number of params in model 70141
2023-01-04 01:20:17,919 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:20:17,919 INFO:   Starting stage: TRAINING
2023-01-04 01:20:17,959 INFO:     Val loss before train {'Reaction outcome loss': 1.0256847858428955, 'Total loss': 1.0256847858428955}
2023-01-04 01:20:17,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:17,960 INFO:     Epoch: 0
2023-01-04 01:20:19,589 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6987964312235514, 'Total loss': 0.6987964312235514} | train loss {'Reaction outcome loss': 0.8423371459172521, 'Total loss': 0.8423371459172521}
2023-01-04 01:20:19,589 INFO:     Found new best model at epoch 0
2023-01-04 01:20:19,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:19,590 INFO:     Epoch: 1
2023-01-04 01:20:21,181 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5602188964684804, 'Total loss': 0.5602188964684804} | train loss {'Reaction outcome loss': 0.6061006086182508, 'Total loss': 0.6061006086182508}
2023-01-04 01:20:21,181 INFO:     Found new best model at epoch 1
2023-01-04 01:20:21,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:21,182 INFO:     Epoch: 2
2023-01-04 01:20:22,804 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5399877349535624, 'Total loss': 0.5399877349535624} | train loss {'Reaction outcome loss': 0.5258400910920615, 'Total loss': 0.5258400910920615}
2023-01-04 01:20:22,804 INFO:     Found new best model at epoch 2
2023-01-04 01:20:22,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:22,805 INFO:     Epoch: 3
2023-01-04 01:20:24,437 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5047960698604583, 'Total loss': 0.5047960698604583} | train loss {'Reaction outcome loss': 0.4819008423425661, 'Total loss': 0.4819008423425661}
2023-01-04 01:20:24,437 INFO:     Found new best model at epoch 3
2023-01-04 01:20:24,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:24,438 INFO:     Epoch: 4
2023-01-04 01:20:26,068 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48804864784081775, 'Total loss': 0.48804864784081775} | train loss {'Reaction outcome loss': 0.45819240055359656, 'Total loss': 0.45819240055359656}
2023-01-04 01:20:26,068 INFO:     Found new best model at epoch 4
2023-01-04 01:20:26,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:26,069 INFO:     Epoch: 5
2023-01-04 01:20:27,669 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4851244846979777, 'Total loss': 0.4851244846979777} | train loss {'Reaction outcome loss': 0.4367337332305495, 'Total loss': 0.4367337332305495}
2023-01-04 01:20:27,669 INFO:     Found new best model at epoch 5
2023-01-04 01:20:27,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:27,670 INFO:     Epoch: 6
2023-01-04 01:20:29,287 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47653022209803264, 'Total loss': 0.47653022209803264} | train loss {'Reaction outcome loss': 0.4179841845635903, 'Total loss': 0.4179841845635903}
2023-01-04 01:20:29,287 INFO:     Found new best model at epoch 6
2023-01-04 01:20:29,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:29,288 INFO:     Epoch: 7
2023-01-04 01:20:30,896 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4803140590588252, 'Total loss': 0.4803140590588252} | train loss {'Reaction outcome loss': 0.40557849493267734, 'Total loss': 0.40557849493267734}
2023-01-04 01:20:30,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:30,897 INFO:     Epoch: 8
2023-01-04 01:20:32,504 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45515277087688444, 'Total loss': 0.45515277087688444} | train loss {'Reaction outcome loss': 0.3948306414678639, 'Total loss': 0.3948306414678639}
2023-01-04 01:20:32,504 INFO:     Found new best model at epoch 8
2023-01-04 01:20:32,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:32,505 INFO:     Epoch: 9
2023-01-04 01:20:34,112 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46582280000050863, 'Total loss': 0.46582280000050863} | train loss {'Reaction outcome loss': 0.38520962155898125, 'Total loss': 0.38520962155898125}
2023-01-04 01:20:34,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:34,113 INFO:     Epoch: 10
2023-01-04 01:20:35,754 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45186834037303925, 'Total loss': 0.45186834037303925} | train loss {'Reaction outcome loss': 0.37345309824504574, 'Total loss': 0.37345309824504574}
2023-01-04 01:20:35,755 INFO:     Found new best model at epoch 10
2023-01-04 01:20:35,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:35,756 INFO:     Epoch: 11
2023-01-04 01:20:37,340 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45209705630938213, 'Total loss': 0.45209705630938213} | train loss {'Reaction outcome loss': 0.36829789152321835, 'Total loss': 0.36829789152321835}
2023-01-04 01:20:37,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:37,340 INFO:     Epoch: 12
2023-01-04 01:20:38,947 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4472670018672943, 'Total loss': 0.4472670018672943} | train loss {'Reaction outcome loss': 0.3603850019698969, 'Total loss': 0.3603850019698969}
2023-01-04 01:20:38,947 INFO:     Found new best model at epoch 12
2023-01-04 01:20:38,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:38,948 INFO:     Epoch: 13
2023-01-04 01:20:40,579 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46730929613113403, 'Total loss': 0.46730929613113403} | train loss {'Reaction outcome loss': 0.3509331145172515, 'Total loss': 0.3509331145172515}
2023-01-04 01:20:40,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:40,580 INFO:     Epoch: 14
2023-01-04 01:20:42,211 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4569447616736094, 'Total loss': 0.4569447616736094} | train loss {'Reaction outcome loss': 0.34739821834577117, 'Total loss': 0.34739821834577117}
2023-01-04 01:20:42,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:42,212 INFO:     Epoch: 15
2023-01-04 01:20:43,837 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46288607915242513, 'Total loss': 0.46288607915242513} | train loss {'Reaction outcome loss': 0.33755897297540727, 'Total loss': 0.33755897297540727}
2023-01-04 01:20:43,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:43,837 INFO:     Epoch: 16
2023-01-04 01:20:45,437 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45608190894126893, 'Total loss': 0.45608190894126893} | train loss {'Reaction outcome loss': 0.3321903392080796, 'Total loss': 0.3321903392080796}
2023-01-04 01:20:45,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:45,437 INFO:     Epoch: 17
2023-01-04 01:20:47,063 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4472405880689621, 'Total loss': 0.4472405880689621} | train loss {'Reaction outcome loss': 0.3252044888448629, 'Total loss': 0.3252044888448629}
2023-01-04 01:20:47,064 INFO:     Found new best model at epoch 17
2023-01-04 01:20:47,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:47,064 INFO:     Epoch: 18
2023-01-04 01:20:48,664 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4387929220994314, 'Total loss': 0.4387929220994314} | train loss {'Reaction outcome loss': 0.32251795319443577, 'Total loss': 0.32251795319443577}
2023-01-04 01:20:48,664 INFO:     Found new best model at epoch 18
2023-01-04 01:20:48,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:48,665 INFO:     Epoch: 19
2023-01-04 01:20:50,267 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44549573411544163, 'Total loss': 0.44549573411544163} | train loss {'Reaction outcome loss': 0.31695522663825687, 'Total loss': 0.31695522663825687}
2023-01-04 01:20:50,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:50,267 INFO:     Epoch: 20
2023-01-04 01:20:51,892 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4489098648230235, 'Total loss': 0.4489098648230235} | train loss {'Reaction outcome loss': 0.31320153889565694, 'Total loss': 0.31320153889565694}
2023-01-04 01:20:51,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:51,892 INFO:     Epoch: 21
2023-01-04 01:20:53,496 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4379033803939819, 'Total loss': 0.4379033803939819} | train loss {'Reaction outcome loss': 0.3063243863976389, 'Total loss': 0.3063243863976389}
2023-01-04 01:20:53,497 INFO:     Found new best model at epoch 21
2023-01-04 01:20:53,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:53,497 INFO:     Epoch: 22
2023-01-04 01:20:55,095 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4436341106891632, 'Total loss': 0.4436341106891632} | train loss {'Reaction outcome loss': 0.30361308111718416, 'Total loss': 0.30361308111718416}
2023-01-04 01:20:55,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:55,096 INFO:     Epoch: 23
2023-01-04 01:20:56,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4294433643420537, 'Total loss': 0.4294433643420537} | train loss {'Reaction outcome loss': 0.29848155301292884, 'Total loss': 0.29848155301292884}
2023-01-04 01:20:56,697 INFO:     Found new best model at epoch 23
2023-01-04 01:20:56,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:56,698 INFO:     Epoch: 24
2023-01-04 01:20:58,299 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43799543877442676, 'Total loss': 0.43799543877442676} | train loss {'Reaction outcome loss': 0.29387881437363605, 'Total loss': 0.29387881437363605}
2023-01-04 01:20:58,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:58,299 INFO:     Epoch: 25
2023-01-04 01:20:59,928 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4355666438738505, 'Total loss': 0.4355666438738505} | train loss {'Reaction outcome loss': 0.2898000249847608, 'Total loss': 0.2898000249847608}
2023-01-04 01:20:59,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:20:59,928 INFO:     Epoch: 26
2023-01-04 01:21:01,562 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42540213267008464, 'Total loss': 0.42540213267008464} | train loss {'Reaction outcome loss': 0.2888510382670358, 'Total loss': 0.2888510382670358}
2023-01-04 01:21:01,562 INFO:     Found new best model at epoch 26
2023-01-04 01:21:01,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:01,563 INFO:     Epoch: 27
2023-01-04 01:21:03,174 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4362885336081187, 'Total loss': 0.4362885336081187} | train loss {'Reaction outcome loss': 0.2830660932761237, 'Total loss': 0.2830660932761237}
2023-01-04 01:21:03,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:03,174 INFO:     Epoch: 28
2023-01-04 01:21:04,781 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4365451882282893, 'Total loss': 0.4365451882282893} | train loss {'Reaction outcome loss': 0.2804598606289079, 'Total loss': 0.2804598606289079}
2023-01-04 01:21:04,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:04,781 INFO:     Epoch: 29
2023-01-04 01:21:06,376 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4462172120809555, 'Total loss': 0.4462172120809555} | train loss {'Reaction outcome loss': 0.27573167061977866, 'Total loss': 0.27573167061977866}
2023-01-04 01:21:06,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:06,376 INFO:     Epoch: 30
2023-01-04 01:21:08,001 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45499224166075386, 'Total loss': 0.45499224166075386} | train loss {'Reaction outcome loss': 0.2745200735836253, 'Total loss': 0.2745200735836253}
2023-01-04 01:21:08,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:08,002 INFO:     Epoch: 31
2023-01-04 01:21:09,631 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44288069009780884, 'Total loss': 0.44288069009780884} | train loss {'Reaction outcome loss': 0.2691492362465669, 'Total loss': 0.2691492362465669}
2023-01-04 01:21:09,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:09,631 INFO:     Epoch: 32
2023-01-04 01:21:11,260 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44056824247042337, 'Total loss': 0.44056824247042337} | train loss {'Reaction outcome loss': 0.2663171793256856, 'Total loss': 0.2663171793256856}
2023-01-04 01:21:11,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:11,262 INFO:     Epoch: 33
2023-01-04 01:21:12,853 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41969452425837517, 'Total loss': 0.41969452425837517} | train loss {'Reaction outcome loss': 0.2621075212820988, 'Total loss': 0.2621075212820988}
2023-01-04 01:21:12,853 INFO:     Found new best model at epoch 33
2023-01-04 01:21:12,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:12,854 INFO:     Epoch: 34
2023-01-04 01:21:14,456 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4420168419679006, 'Total loss': 0.4420168419679006} | train loss {'Reaction outcome loss': 0.260848574811048, 'Total loss': 0.260848574811048}
2023-01-04 01:21:14,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:14,456 INFO:     Epoch: 35
2023-01-04 01:21:16,051 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43061953186988833, 'Total loss': 0.43061953186988833} | train loss {'Reaction outcome loss': 0.25758581211797166, 'Total loss': 0.25758581211797166}
2023-01-04 01:21:16,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:16,051 INFO:     Epoch: 36
2023-01-04 01:21:17,631 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44429493844509127, 'Total loss': 0.44429493844509127} | train loss {'Reaction outcome loss': 0.254576826178963, 'Total loss': 0.254576826178963}
2023-01-04 01:21:17,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:17,632 INFO:     Epoch: 37
2023-01-04 01:21:19,217 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44462543924649556, 'Total loss': 0.44462543924649556} | train loss {'Reaction outcome loss': 0.25303085274752296, 'Total loss': 0.25303085274752296}
2023-01-04 01:21:19,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:19,217 INFO:     Epoch: 38
2023-01-04 01:21:20,846 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44960149625937146, 'Total loss': 0.44960149625937146} | train loss {'Reaction outcome loss': 0.24982114293568833, 'Total loss': 0.24982114293568833}
2023-01-04 01:21:20,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:20,846 INFO:     Epoch: 39
2023-01-04 01:21:22,458 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4356516549984614, 'Total loss': 0.4356516549984614} | train loss {'Reaction outcome loss': 0.24741413646011146, 'Total loss': 0.24741413646011146}
2023-01-04 01:21:22,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:22,459 INFO:     Epoch: 40
2023-01-04 01:21:24,060 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4435374061266581, 'Total loss': 0.4435374061266581} | train loss {'Reaction outcome loss': 0.24302951261293587, 'Total loss': 0.24302951261293587}
2023-01-04 01:21:24,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:24,060 INFO:     Epoch: 41
2023-01-04 01:21:25,690 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43759181002775827, 'Total loss': 0.43759181002775827} | train loss {'Reaction outcome loss': 0.2434927672282238, 'Total loss': 0.2434927672282238}
2023-01-04 01:21:25,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:25,690 INFO:     Epoch: 42
2023-01-04 01:21:27,324 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4331957459449768, 'Total loss': 0.4331957459449768} | train loss {'Reaction outcome loss': 0.24074359106350463, 'Total loss': 0.24074359106350463}
2023-01-04 01:21:27,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:27,324 INFO:     Epoch: 43
2023-01-04 01:21:28,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44805162250995634, 'Total loss': 0.44805162250995634} | train loss {'Reaction outcome loss': 0.23845659351036866, 'Total loss': 0.23845659351036866}
2023-01-04 01:21:28,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:28,955 INFO:     Epoch: 44
2023-01-04 01:21:30,554 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4290619949499766, 'Total loss': 0.4290619949499766} | train loss {'Reaction outcome loss': 0.23728714998986317, 'Total loss': 0.23728714998986317}
2023-01-04 01:21:30,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:30,554 INFO:     Epoch: 45
2023-01-04 01:21:32,160 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42317720552285515, 'Total loss': 0.42317720552285515} | train loss {'Reaction outcome loss': 0.23317867358776637, 'Total loss': 0.23317867358776637}
2023-01-04 01:21:32,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:32,160 INFO:     Epoch: 46
2023-01-04 01:21:33,762 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43783091406027475, 'Total loss': 0.43783091406027475} | train loss {'Reaction outcome loss': 0.23571349980329778, 'Total loss': 0.23571349980329778}
2023-01-04 01:21:33,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:33,763 INFO:     Epoch: 47
2023-01-04 01:21:35,425 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4369073102871577, 'Total loss': 0.4369073102871577} | train loss {'Reaction outcome loss': 0.22915225905712547, 'Total loss': 0.22915225905712547}
2023-01-04 01:21:35,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:35,425 INFO:     Epoch: 48
2023-01-04 01:21:37,087 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43593745231628417, 'Total loss': 0.43593745231628417} | train loss {'Reaction outcome loss': 0.2240618536591745, 'Total loss': 0.2240618536591745}
2023-01-04 01:21:37,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:37,088 INFO:     Epoch: 49
2023-01-04 01:21:38,722 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4241155425707499, 'Total loss': 0.4241155425707499} | train loss {'Reaction outcome loss': 0.2277014127088583, 'Total loss': 0.2277014127088583}
2023-01-04 01:21:38,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:38,723 INFO:     Epoch: 50
2023-01-04 01:21:40,364 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43377520541350045, 'Total loss': 0.43377520541350045} | train loss {'Reaction outcome loss': 0.22339135164979992, 'Total loss': 0.22339135164979992}
2023-01-04 01:21:40,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:40,365 INFO:     Epoch: 51
2023-01-04 01:21:42,011 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4499575008948644, 'Total loss': 0.4499575008948644} | train loss {'Reaction outcome loss': 0.22215697648077665, 'Total loss': 0.22215697648077665}
2023-01-04 01:21:42,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:42,011 INFO:     Epoch: 52
2023-01-04 01:21:43,672 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45275704662005106, 'Total loss': 0.45275704662005106} | train loss {'Reaction outcome loss': 0.21901262427818044, 'Total loss': 0.21901262427818044}
2023-01-04 01:21:43,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:43,672 INFO:     Epoch: 53
2023-01-04 01:21:45,336 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4301906585693359, 'Total loss': 0.4301906585693359} | train loss {'Reaction outcome loss': 0.2207821565091825, 'Total loss': 0.2207821565091825}
2023-01-04 01:21:45,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:45,336 INFO:     Epoch: 54
2023-01-04 01:21:46,993 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43625751733779905, 'Total loss': 0.43625751733779905} | train loss {'Reaction outcome loss': 0.21898361328410973, 'Total loss': 0.21898361328410973}
2023-01-04 01:21:46,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:46,994 INFO:     Epoch: 55
2023-01-04 01:21:48,637 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4342194179693858, 'Total loss': 0.4342194179693858} | train loss {'Reaction outcome loss': 0.2159069963337497, 'Total loss': 0.2159069963337497}
2023-01-04 01:21:48,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:48,637 INFO:     Epoch: 56
2023-01-04 01:21:50,297 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.431936659415563, 'Total loss': 0.431936659415563} | train loss {'Reaction outcome loss': 0.21534757424374565, 'Total loss': 0.21534757424374565}
2023-01-04 01:21:50,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:50,297 INFO:     Epoch: 57
2023-01-04 01:21:51,911 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43323733905951184, 'Total loss': 0.43323733905951184} | train loss {'Reaction outcome loss': 0.2101506884697327, 'Total loss': 0.2101506884697327}
2023-01-04 01:21:51,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:51,911 INFO:     Epoch: 58
2023-01-04 01:21:53,573 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43378275831540425, 'Total loss': 0.43378275831540425} | train loss {'Reaction outcome loss': 0.21106733891453983, 'Total loss': 0.21106733891453983}
2023-01-04 01:21:53,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:53,574 INFO:     Epoch: 59
2023-01-04 01:21:55,214 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4358299990495046, 'Total loss': 0.4358299990495046} | train loss {'Reaction outcome loss': 0.21154182671908867, 'Total loss': 0.21154182671908867}
2023-01-04 01:21:55,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:55,214 INFO:     Epoch: 60
2023-01-04 01:21:56,861 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4409137984116872, 'Total loss': 0.4409137984116872} | train loss {'Reaction outcome loss': 0.2094170147896028, 'Total loss': 0.2094170147896028}
2023-01-04 01:21:56,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:56,861 INFO:     Epoch: 61
2023-01-04 01:21:58,464 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.434600031375885, 'Total loss': 0.434600031375885} | train loss {'Reaction outcome loss': 0.20822618833141207, 'Total loss': 0.20822618833141207}
2023-01-04 01:21:58,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:21:58,465 INFO:     Epoch: 62
2023-01-04 01:22:00,063 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.435454273223877, 'Total loss': 0.435454273223877} | train loss {'Reaction outcome loss': 0.20328269239905078, 'Total loss': 0.20328269239905078}
2023-01-04 01:22:00,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:00,063 INFO:     Epoch: 63
2023-01-04 01:22:01,650 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4473143597443899, 'Total loss': 0.4473143597443899} | train loss {'Reaction outcome loss': 0.20376840197491303, 'Total loss': 0.20376840197491303}
2023-01-04 01:22:01,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:01,650 INFO:     Epoch: 64
2023-01-04 01:22:03,250 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4278457482655843, 'Total loss': 0.4278457482655843} | train loss {'Reaction outcome loss': 0.20349330221729803, 'Total loss': 0.20349330221729803}
2023-01-04 01:22:03,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:03,251 INFO:     Epoch: 65
2023-01-04 01:22:04,852 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4239289740721385, 'Total loss': 0.4239289740721385} | train loss {'Reaction outcome loss': 0.20180089802679602, 'Total loss': 0.20180089802679602}
2023-01-04 01:22:04,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:04,852 INFO:     Epoch: 66
2023-01-04 01:22:06,445 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44537010888258616, 'Total loss': 0.44537010888258616} | train loss {'Reaction outcome loss': 0.20112192782738147, 'Total loss': 0.20112192782738147}
2023-01-04 01:22:06,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:06,446 INFO:     Epoch: 67
2023-01-04 01:22:08,035 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42156655887762706, 'Total loss': 0.42156655887762706} | train loss {'Reaction outcome loss': 0.1990845510836973, 'Total loss': 0.1990845510836973}
2023-01-04 01:22:08,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:08,035 INFO:     Epoch: 68
2023-01-04 01:22:09,631 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4320237159729004, 'Total loss': 0.4320237159729004} | train loss {'Reaction outcome loss': 0.19592491193045777, 'Total loss': 0.19592491193045777}
2023-01-04 01:22:09,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:09,631 INFO:     Epoch: 69
2023-01-04 01:22:11,264 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42280900180339814, 'Total loss': 0.42280900180339814} | train loss {'Reaction outcome loss': 0.19634350978295295, 'Total loss': 0.19634350978295295}
2023-01-04 01:22:11,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:11,264 INFO:     Epoch: 70
2023-01-04 01:22:12,898 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.439122478167216, 'Total loss': 0.439122478167216} | train loss {'Reaction outcome loss': 0.19450171026888738, 'Total loss': 0.19450171026888738}
2023-01-04 01:22:12,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:12,899 INFO:     Epoch: 71
2023-01-04 01:22:14,535 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4350021888812383, 'Total loss': 0.4350021888812383} | train loss {'Reaction outcome loss': 0.19392281951591211, 'Total loss': 0.19392281951591211}
2023-01-04 01:22:14,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:14,535 INFO:     Epoch: 72
2023-01-04 01:22:16,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44674958288669586, 'Total loss': 0.44674958288669586} | train loss {'Reaction outcome loss': 0.1930220085481982, 'Total loss': 0.1930220085481982}
2023-01-04 01:22:16,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:16,132 INFO:     Epoch: 73
2023-01-04 01:22:17,764 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44672914495070776, 'Total loss': 0.44672914495070776} | train loss {'Reaction outcome loss': 0.19270761421333582, 'Total loss': 0.19270761421333582}
2023-01-04 01:22:17,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:17,764 INFO:     Epoch: 74
2023-01-04 01:22:19,358 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43273279468218484, 'Total loss': 0.43273279468218484} | train loss {'Reaction outcome loss': 0.19264582818246276, 'Total loss': 0.19264582818246276}
2023-01-04 01:22:19,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:19,358 INFO:     Epoch: 75
2023-01-04 01:22:20,965 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4175112595160802, 'Total loss': 0.4175112595160802} | train loss {'Reaction outcome loss': 0.18969588810140905, 'Total loss': 0.18969588810140905}
2023-01-04 01:22:20,965 INFO:     Found new best model at epoch 75
2023-01-04 01:22:20,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:20,966 INFO:     Epoch: 76
2023-01-04 01:22:22,567 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4205954293409983, 'Total loss': 0.4205954293409983} | train loss {'Reaction outcome loss': 0.19002673026537423, 'Total loss': 0.19002673026537423}
2023-01-04 01:22:22,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:22,568 INFO:     Epoch: 77
2023-01-04 01:22:24,166 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42853542367617287, 'Total loss': 0.42853542367617287} | train loss {'Reaction outcome loss': 0.18853296182498283, 'Total loss': 0.18853296182498283}
2023-01-04 01:22:24,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:24,166 INFO:     Epoch: 78
2023-01-04 01:22:25,756 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4355360150337219, 'Total loss': 0.4355360150337219} | train loss {'Reaction outcome loss': 0.1895464953263744, 'Total loss': 0.1895464953263744}
2023-01-04 01:22:25,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:25,756 INFO:     Epoch: 79
2023-01-04 01:22:27,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41586981614430746, 'Total loss': 0.41586981614430746} | train loss {'Reaction outcome loss': 0.18570233646121265, 'Total loss': 0.18570233646121265}
2023-01-04 01:22:27,344 INFO:     Found new best model at epoch 79
2023-01-04 01:22:27,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:27,345 INFO:     Epoch: 80
2023-01-04 01:22:28,947 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43610296994447706, 'Total loss': 0.43610296994447706} | train loss {'Reaction outcome loss': 0.18518258456396283, 'Total loss': 0.18518258456396283}
2023-01-04 01:22:28,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:28,948 INFO:     Epoch: 81
2023-01-04 01:22:30,549 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44621606469154357, 'Total loss': 0.44621606469154357} | train loss {'Reaction outcome loss': 0.18543110296990897, 'Total loss': 0.18543110296990897}
2023-01-04 01:22:30,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:30,549 INFO:     Epoch: 82
2023-01-04 01:22:32,153 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41791346073150637, 'Total loss': 0.41791346073150637} | train loss {'Reaction outcome loss': 0.18342878260659828, 'Total loss': 0.18342878260659828}
2023-01-04 01:22:32,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:32,153 INFO:     Epoch: 83
2023-01-04 01:22:33,736 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4473957051833471, 'Total loss': 0.4473957051833471} | train loss {'Reaction outcome loss': 0.18428388051016237, 'Total loss': 0.18428388051016237}
2023-01-04 01:22:33,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:33,736 INFO:     Epoch: 84
2023-01-04 01:22:35,361 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.443083389600118, 'Total loss': 0.443083389600118} | train loss {'Reaction outcome loss': 0.1826983525515248, 'Total loss': 0.1826983525515248}
2023-01-04 01:22:35,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:35,362 INFO:     Epoch: 85
2023-01-04 01:22:36,975 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44068966507911683, 'Total loss': 0.44068966507911683} | train loss {'Reaction outcome loss': 0.18014632478786718, 'Total loss': 0.18014632478786718}
2023-01-04 01:22:36,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:36,975 INFO:     Epoch: 86
2023-01-04 01:22:38,592 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4384903540213903, 'Total loss': 0.4384903540213903} | train loss {'Reaction outcome loss': 0.17919673451931897, 'Total loss': 0.17919673451931897}
2023-01-04 01:22:38,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:38,592 INFO:     Epoch: 87
2023-01-04 01:22:40,221 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4300342788298925, 'Total loss': 0.4300342788298925} | train loss {'Reaction outcome loss': 0.1777155665472311, 'Total loss': 0.1777155665472311}
2023-01-04 01:22:40,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:40,221 INFO:     Epoch: 88
2023-01-04 01:22:41,864 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42733814418315885, 'Total loss': 0.42733814418315885} | train loss {'Reaction outcome loss': 0.17625677217107388, 'Total loss': 0.17625677217107388}
2023-01-04 01:22:41,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:41,865 INFO:     Epoch: 89
2023-01-04 01:22:43,455 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43593598206837975, 'Total loss': 0.43593598206837975} | train loss {'Reaction outcome loss': 0.17886299220340776, 'Total loss': 0.17886299220340776}
2023-01-04 01:22:43,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:43,455 INFO:     Epoch: 90
2023-01-04 01:22:45,043 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4171386738618215, 'Total loss': 0.4171386738618215} | train loss {'Reaction outcome loss': 0.177498756978486, 'Total loss': 0.177498756978486}
2023-01-04 01:22:45,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:45,043 INFO:     Epoch: 91
2023-01-04 01:22:46,665 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43075745304425556, 'Total loss': 0.43075745304425556} | train loss {'Reaction outcome loss': 0.18008836556481542, 'Total loss': 0.18008836556481542}
2023-01-04 01:22:46,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:46,666 INFO:     Epoch: 92
2023-01-04 01:22:48,273 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4229212651650111, 'Total loss': 0.4229212651650111} | train loss {'Reaction outcome loss': 0.17617939927679108, 'Total loss': 0.17617939927679108}
2023-01-04 01:22:48,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:48,273 INFO:     Epoch: 93
2023-01-04 01:22:49,878 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4381071199973424, 'Total loss': 0.4381071199973424} | train loss {'Reaction outcome loss': 0.17390535832365928, 'Total loss': 0.17390535832365928}
2023-01-04 01:22:49,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:49,879 INFO:     Epoch: 94
2023-01-04 01:22:51,505 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4515296667814255, 'Total loss': 0.4515296667814255} | train loss {'Reaction outcome loss': 0.17338721571147225, 'Total loss': 0.17338721571147225}
2023-01-04 01:22:51,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:51,506 INFO:     Epoch: 95
2023-01-04 01:22:53,102 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42889987329641976, 'Total loss': 0.42889987329641976} | train loss {'Reaction outcome loss': 0.1745267972645992, 'Total loss': 0.1745267972645992}
2023-01-04 01:22:53,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:53,103 INFO:     Epoch: 96
2023-01-04 01:22:54,711 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42279944916566214, 'Total loss': 0.42279944916566214} | train loss {'Reaction outcome loss': 0.17449464065288378, 'Total loss': 0.17449464065288378}
2023-01-04 01:22:54,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:54,712 INFO:     Epoch: 97
2023-01-04 01:22:56,305 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43222047537565234, 'Total loss': 0.43222047537565234} | train loss {'Reaction outcome loss': 0.1707633427656945, 'Total loss': 0.1707633427656945}
2023-01-04 01:22:56,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:56,305 INFO:     Epoch: 98
2023-01-04 01:22:57,946 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.431195430457592, 'Total loss': 0.431195430457592} | train loss {'Reaction outcome loss': 0.17187948279513132, 'Total loss': 0.17187948279513132}
2023-01-04 01:22:57,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:22:57,946 INFO:     Epoch: 99
2023-01-04 01:22:59,574 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4218845327695211, 'Total loss': 0.4218845327695211} | train loss {'Reaction outcome loss': 0.17207923867749825, 'Total loss': 0.17207923867749825}
2023-01-04 01:22:59,574 INFO:     Best model found after epoch 80 of 100.
2023-01-04 01:22:59,575 INFO:   Done with stage: TRAINING
2023-01-04 01:22:59,575 INFO:   Starting stage: EVALUATION
2023-01-04 01:22:59,696 INFO:   Done with stage: EVALUATION
2023-01-04 01:22:59,696 INFO:   Leaving out SEQ value Fold_5
2023-01-04 01:22:59,709 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:22:59,709 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:23:00,362 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:23:00,362 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:23:00,432 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:23:00,432 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:23:00,432 INFO:     No hyperparam tuning for this model
2023-01-04 01:23:00,432 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:23:00,432 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:23:00,433 INFO:     None feature selector for col prot
2023-01-04 01:23:00,433 INFO:     None feature selector for col prot
2023-01-04 01:23:00,433 INFO:     None feature selector for col prot
2023-01-04 01:23:00,434 INFO:     None feature selector for col chem
2023-01-04 01:23:00,434 INFO:     None feature selector for col chem
2023-01-04 01:23:00,434 INFO:     None feature selector for col chem
2023-01-04 01:23:00,434 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:23:00,434 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:23:00,435 INFO:     Number of params in model 70141
2023-01-04 01:23:00,438 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:23:00,438 INFO:   Starting stage: TRAINING
2023-01-04 01:23:00,482 INFO:     Val loss before train {'Reaction outcome loss': 1.011014958222707, 'Total loss': 1.011014958222707}
2023-01-04 01:23:00,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:00,482 INFO:     Epoch: 0
2023-01-04 01:23:02,089 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6266336818536122, 'Total loss': 0.6266336818536122} | train loss {'Reaction outcome loss': 0.8547099944916873, 'Total loss': 0.8547099944916873}
2023-01-04 01:23:02,089 INFO:     Found new best model at epoch 0
2023-01-04 01:23:02,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:02,090 INFO:     Epoch: 1
2023-01-04 01:23:03,702 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5188931842645009, 'Total loss': 0.5188931842645009} | train loss {'Reaction outcome loss': 0.6029834336322137, 'Total loss': 0.6029834336322137}
2023-01-04 01:23:03,703 INFO:     Found new best model at epoch 1
2023-01-04 01:23:03,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:03,703 INFO:     Epoch: 2
2023-01-04 01:23:05,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4729325850804647, 'Total loss': 0.4729325850804647} | train loss {'Reaction outcome loss': 0.5334925033985923, 'Total loss': 0.5334925033985923}
2023-01-04 01:23:05,321 INFO:     Found new best model at epoch 2
2023-01-04 01:23:05,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:05,322 INFO:     Epoch: 3
2023-01-04 01:23:06,931 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45186298886934917, 'Total loss': 0.45186298886934917} | train loss {'Reaction outcome loss': 0.4905923763121939, 'Total loss': 0.4905923763121939}
2023-01-04 01:23:06,931 INFO:     Found new best model at epoch 3
2023-01-04 01:23:06,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:06,932 INFO:     Epoch: 4
2023-01-04 01:23:08,539 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43115826646486916, 'Total loss': 0.43115826646486916} | train loss {'Reaction outcome loss': 0.46366951289159725, 'Total loss': 0.46366951289159725}
2023-01-04 01:23:08,539 INFO:     Found new best model at epoch 4
2023-01-04 01:23:08,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:08,540 INFO:     Epoch: 5
2023-01-04 01:23:10,137 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4426356703042984, 'Total loss': 0.4426356703042984} | train loss {'Reaction outcome loss': 0.44114191663394337, 'Total loss': 0.44114191663394337}
2023-01-04 01:23:10,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:10,137 INFO:     Epoch: 6
2023-01-04 01:23:11,752 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42904710670312246, 'Total loss': 0.42904710670312246} | train loss {'Reaction outcome loss': 0.42292559146881104, 'Total loss': 0.42292559146881104}
2023-01-04 01:23:11,753 INFO:     Found new best model at epoch 6
2023-01-04 01:23:11,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:11,754 INFO:     Epoch: 7
2023-01-04 01:23:13,355 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41168185472488406, 'Total loss': 0.41168185472488406} | train loss {'Reaction outcome loss': 0.40745812358623806, 'Total loss': 0.40745812358623806}
2023-01-04 01:23:13,355 INFO:     Found new best model at epoch 7
2023-01-04 01:23:13,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:13,356 INFO:     Epoch: 8
2023-01-04 01:23:14,963 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4056713134050369, 'Total loss': 0.4056713134050369} | train loss {'Reaction outcome loss': 0.3939635939223672, 'Total loss': 0.3939635939223672}
2023-01-04 01:23:14,964 INFO:     Found new best model at epoch 8
2023-01-04 01:23:14,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:14,964 INFO:     Epoch: 9
2023-01-04 01:23:16,572 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4082357476154963, 'Total loss': 0.4082357476154963} | train loss {'Reaction outcome loss': 0.38126392716319984, 'Total loss': 0.38126392716319984}
2023-01-04 01:23:16,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:16,572 INFO:     Epoch: 10
2023-01-04 01:23:18,166 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39790412187576296, 'Total loss': 0.39790412187576296} | train loss {'Reaction outcome loss': 0.3741017908718612, 'Total loss': 0.3741017908718612}
2023-01-04 01:23:18,166 INFO:     Found new best model at epoch 10
2023-01-04 01:23:18,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:18,167 INFO:     Epoch: 11
2023-01-04 01:23:19,791 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39823928276697795, 'Total loss': 0.39823928276697795} | train loss {'Reaction outcome loss': 0.36386828533363685, 'Total loss': 0.36386828533363685}
2023-01-04 01:23:19,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:19,791 INFO:     Epoch: 12
2023-01-04 01:23:21,392 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39609068830808003, 'Total loss': 0.39609068830808003} | train loss {'Reaction outcome loss': 0.35498048432359625, 'Total loss': 0.35498048432359625}
2023-01-04 01:23:21,393 INFO:     Found new best model at epoch 12
2023-01-04 01:23:21,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:21,393 INFO:     Epoch: 13
2023-01-04 01:23:23,021 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3896976838509242, 'Total loss': 0.3896976838509242} | train loss {'Reaction outcome loss': 0.34708330524742387, 'Total loss': 0.34708330524742387}
2023-01-04 01:23:23,021 INFO:     Found new best model at epoch 13
2023-01-04 01:23:23,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:23,022 INFO:     Epoch: 14
2023-01-04 01:23:24,634 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4017677823702494, 'Total loss': 0.4017677823702494} | train loss {'Reaction outcome loss': 0.34115103823183246, 'Total loss': 0.34115103823183246}
2023-01-04 01:23:24,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:24,635 INFO:     Epoch: 15
2023-01-04 01:23:26,245 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40663796762625376, 'Total loss': 0.40663796762625376} | train loss {'Reaction outcome loss': 0.3345083800625285, 'Total loss': 0.3345083800625285}
2023-01-04 01:23:26,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:26,246 INFO:     Epoch: 16
2023-01-04 01:23:27,863 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39315242966016134, 'Total loss': 0.39315242966016134} | train loss {'Reaction outcome loss': 0.3287914007202813, 'Total loss': 0.3287914007202813}
2023-01-04 01:23:27,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:27,863 INFO:     Epoch: 17
2023-01-04 01:23:29,483 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38561652998129525, 'Total loss': 0.38561652998129525} | train loss {'Reaction outcome loss': 0.3226301411321447, 'Total loss': 0.3226301411321447}
2023-01-04 01:23:29,483 INFO:     Found new best model at epoch 17
2023-01-04 01:23:29,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:29,483 INFO:     Epoch: 18
2023-01-04 01:23:31,097 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38842745423316954, 'Total loss': 0.38842745423316954} | train loss {'Reaction outcome loss': 0.31575212533508396, 'Total loss': 0.31575212533508396}
2023-01-04 01:23:31,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:31,098 INFO:     Epoch: 19
2023-01-04 01:23:32,721 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3938579430182775, 'Total loss': 0.3938579430182775} | train loss {'Reaction outcome loss': 0.308214618760541, 'Total loss': 0.308214618760541}
2023-01-04 01:23:32,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:32,722 INFO:     Epoch: 20
2023-01-04 01:23:34,358 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39333730737368267, 'Total loss': 0.39333730737368267} | train loss {'Reaction outcome loss': 0.3048089271418024, 'Total loss': 0.3048089271418024}
2023-01-04 01:23:34,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:34,358 INFO:     Epoch: 21
2023-01-04 01:23:35,980 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3850575089454651, 'Total loss': 0.3850575089454651} | train loss {'Reaction outcome loss': 0.3011591814270088, 'Total loss': 0.3011591814270088}
2023-01-04 01:23:35,980 INFO:     Found new best model at epoch 21
2023-01-04 01:23:35,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:35,981 INFO:     Epoch: 22
2023-01-04 01:23:37,583 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3746112063527107, 'Total loss': 0.3746112063527107} | train loss {'Reaction outcome loss': 0.2967462142129237, 'Total loss': 0.2967462142129237}
2023-01-04 01:23:37,583 INFO:     Found new best model at epoch 22
2023-01-04 01:23:37,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:37,584 INFO:     Epoch: 23
2023-01-04 01:23:39,193 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37005331218242643, 'Total loss': 0.37005331218242643} | train loss {'Reaction outcome loss': 0.29169516816789065, 'Total loss': 0.29169516816789065}
2023-01-04 01:23:39,193 INFO:     Found new best model at epoch 23
2023-01-04 01:23:39,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:39,194 INFO:     Epoch: 24
2023-01-04 01:23:40,824 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38454244335492455, 'Total loss': 0.38454244335492455} | train loss {'Reaction outcome loss': 0.2867879439885005, 'Total loss': 0.2867879439885005}
2023-01-04 01:23:40,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:40,825 INFO:     Epoch: 25
2023-01-04 01:23:42,514 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38493021527926125, 'Total loss': 0.38493021527926125} | train loss {'Reaction outcome loss': 0.2823025918555604, 'Total loss': 0.2823025918555604}
2023-01-04 01:23:42,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:42,514 INFO:     Epoch: 26
2023-01-04 01:23:44,210 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38991327087084454, 'Total loss': 0.38991327087084454} | train loss {'Reaction outcome loss': 0.27920854344479873, 'Total loss': 0.27920854344479873}
2023-01-04 01:23:44,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:44,211 INFO:     Epoch: 27
2023-01-04 01:23:45,883 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3955449750026067, 'Total loss': 0.3955449750026067} | train loss {'Reaction outcome loss': 0.27399732531569493, 'Total loss': 0.27399732531569493}
2023-01-04 01:23:45,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:45,884 INFO:     Epoch: 28
2023-01-04 01:23:47,510 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3820173919200897, 'Total loss': 0.3820173919200897} | train loss {'Reaction outcome loss': 0.27024443883327803, 'Total loss': 0.27024443883327803}
2023-01-04 01:23:47,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:47,510 INFO:     Epoch: 29
2023-01-04 01:23:49,124 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37923548817634584, 'Total loss': 0.37923548817634584} | train loss {'Reaction outcome loss': 0.2651984175055251, 'Total loss': 0.2651984175055251}
2023-01-04 01:23:49,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:49,124 INFO:     Epoch: 30
2023-01-04 01:23:50,754 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.393840687473615, 'Total loss': 0.393840687473615} | train loss {'Reaction outcome loss': 0.26545912528995574, 'Total loss': 0.26545912528995574}
2023-01-04 01:23:50,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:50,755 INFO:     Epoch: 31
2023-01-04 01:23:52,387 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3711717729767164, 'Total loss': 0.3711717729767164} | train loss {'Reaction outcome loss': 0.2605904344778629, 'Total loss': 0.2605904344778629}
2023-01-04 01:23:52,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:52,388 INFO:     Epoch: 32
2023-01-04 01:23:54,019 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3790858576695124, 'Total loss': 0.3790858576695124} | train loss {'Reaction outcome loss': 0.2567815692954115, 'Total loss': 0.2567815692954115}
2023-01-04 01:23:54,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:54,020 INFO:     Epoch: 33
2023-01-04 01:23:55,615 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3725540469090144, 'Total loss': 0.3725540469090144} | train loss {'Reaction outcome loss': 0.25496166285517413, 'Total loss': 0.25496166285517413}
2023-01-04 01:23:55,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:55,616 INFO:     Epoch: 34
2023-01-04 01:23:57,193 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3794609387715658, 'Total loss': 0.3794609387715658} | train loss {'Reaction outcome loss': 0.25274584876770145, 'Total loss': 0.25274584876770145}
2023-01-04 01:23:57,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:57,193 INFO:     Epoch: 35
2023-01-04 01:23:58,815 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3884672045707703, 'Total loss': 0.3884672045707703} | train loss {'Reaction outcome loss': 0.25012980733698886, 'Total loss': 0.25012980733698886}
2023-01-04 01:23:58,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:23:58,815 INFO:     Epoch: 36
2023-01-04 01:24:00,415 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.380633611480395, 'Total loss': 0.380633611480395} | train loss {'Reaction outcome loss': 0.24727050392528735, 'Total loss': 0.24727050392528735}
2023-01-04 01:24:00,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:00,416 INFO:     Epoch: 37
2023-01-04 01:24:02,010 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39969628502925236, 'Total loss': 0.39969628502925236} | train loss {'Reaction outcome loss': 0.24560798599724304, 'Total loss': 0.24560798599724304}
2023-01-04 01:24:02,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:02,010 INFO:     Epoch: 38
2023-01-04 01:24:03,624 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3929393529891968, 'Total loss': 0.3929393529891968} | train loss {'Reaction outcome loss': 0.2400169710524461, 'Total loss': 0.2400169710524461}
2023-01-04 01:24:03,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:03,625 INFO:     Epoch: 39
2023-01-04 01:24:05,222 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40126792788505555, 'Total loss': 0.40126792788505555} | train loss {'Reaction outcome loss': 0.2413379001542119, 'Total loss': 0.2413379001542119}
2023-01-04 01:24:05,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:05,223 INFO:     Epoch: 40
2023-01-04 01:24:06,804 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3995712051788966, 'Total loss': 0.3995712051788966} | train loss {'Reaction outcome loss': 0.2365769207854133, 'Total loss': 0.2365769207854133}
2023-01-04 01:24:06,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:06,805 INFO:     Epoch: 41
2023-01-04 01:24:08,407 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3995655119419098, 'Total loss': 0.3995655119419098} | train loss {'Reaction outcome loss': 0.23337449530132842, 'Total loss': 0.23337449530132842}
2023-01-04 01:24:08,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:08,408 INFO:     Epoch: 42
2023-01-04 01:24:10,010 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3941559359431267, 'Total loss': 0.3941559359431267} | train loss {'Reaction outcome loss': 0.23266247248391383, 'Total loss': 0.23266247248391383}
2023-01-04 01:24:10,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:10,010 INFO:     Epoch: 43
2023-01-04 01:24:11,614 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38034296532471973, 'Total loss': 0.38034296532471973} | train loss {'Reaction outcome loss': 0.23039332996475567, 'Total loss': 0.23039332996475567}
2023-01-04 01:24:11,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:11,614 INFO:     Epoch: 44
2023-01-04 01:24:13,194 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40523452758789064, 'Total loss': 0.40523452758789064} | train loss {'Reaction outcome loss': 0.22869784672768106, 'Total loss': 0.22869784672768106}
2023-01-04 01:24:13,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:13,194 INFO:     Epoch: 45
2023-01-04 01:24:14,822 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39142606953779857, 'Total loss': 0.39142606953779857} | train loss {'Reaction outcome loss': 0.2263779004612124, 'Total loss': 0.2263779004612124}
2023-01-04 01:24:14,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:14,823 INFO:     Epoch: 46
2023-01-04 01:24:16,433 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39015455842018126, 'Total loss': 0.39015455842018126} | train loss {'Reaction outcome loss': 0.22510946597164289, 'Total loss': 0.22510946597164289}
2023-01-04 01:24:16,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:16,433 INFO:     Epoch: 47
2023-01-04 01:24:18,070 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3742163797219594, 'Total loss': 0.3742163797219594} | train loss {'Reaction outcome loss': 0.22281437362493806, 'Total loss': 0.22281437362493806}
2023-01-04 01:24:18,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:18,071 INFO:     Epoch: 48
2023-01-04 01:24:19,705 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3834992329279582, 'Total loss': 0.3834992329279582} | train loss {'Reaction outcome loss': 0.22135856462514789, 'Total loss': 0.22135856462514789}
2023-01-04 01:24:19,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:19,706 INFO:     Epoch: 49
2023-01-04 01:24:21,321 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3705599983533224, 'Total loss': 0.3705599983533224} | train loss {'Reaction outcome loss': 0.21949134449666158, 'Total loss': 0.21949134449666158}
2023-01-04 01:24:21,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:21,322 INFO:     Epoch: 50
2023-01-04 01:24:22,913 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39059122999509177, 'Total loss': 0.39059122999509177} | train loss {'Reaction outcome loss': 0.2180417438545382, 'Total loss': 0.2180417438545382}
2023-01-04 01:24:22,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:22,914 INFO:     Epoch: 51
2023-01-04 01:24:24,502 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39412357211112975, 'Total loss': 0.39412357211112975} | train loss {'Reaction outcome loss': 0.21680725503053905, 'Total loss': 0.21680725503053905}
2023-01-04 01:24:24,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:24,502 INFO:     Epoch: 52
2023-01-04 01:24:26,105 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38633649547894794, 'Total loss': 0.38633649547894794} | train loss {'Reaction outcome loss': 0.2158429337672163, 'Total loss': 0.2158429337672163}
2023-01-04 01:24:26,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:26,106 INFO:     Epoch: 53
2023-01-04 01:24:27,708 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4035554607709249, 'Total loss': 0.4035554607709249} | train loss {'Reaction outcome loss': 0.21473407617598664, 'Total loss': 0.21473407617598664}
2023-01-04 01:24:27,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:27,708 INFO:     Epoch: 54
2023-01-04 01:24:29,311 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.402981765071551, 'Total loss': 0.402981765071551} | train loss {'Reaction outcome loss': 0.21363417658995204, 'Total loss': 0.21363417658995204}
2023-01-04 01:24:29,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:29,311 INFO:     Epoch: 55
2023-01-04 01:24:30,908 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39923492868741356, 'Total loss': 0.39923492868741356} | train loss {'Reaction outcome loss': 0.21220821791768935, 'Total loss': 0.21220821791768935}
2023-01-04 01:24:30,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:30,908 INFO:     Epoch: 56
2023-01-04 01:24:32,502 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38885058263937633, 'Total loss': 0.38885058263937633} | train loss {'Reaction outcome loss': 0.20730888620287932, 'Total loss': 0.20730888620287932}
2023-01-04 01:24:32,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:32,502 INFO:     Epoch: 57
2023-01-04 01:24:34,104 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.392704646786054, 'Total loss': 0.392704646786054} | train loss {'Reaction outcome loss': 0.2043751547321516, 'Total loss': 0.2043751547321516}
2023-01-04 01:24:34,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:34,104 INFO:     Epoch: 58
2023-01-04 01:24:35,698 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39268845518430073, 'Total loss': 0.39268845518430073} | train loss {'Reaction outcome loss': 0.20519813598009223, 'Total loss': 0.20519813598009223}
2023-01-04 01:24:35,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:35,699 INFO:     Epoch: 59
2023-01-04 01:24:37,294 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39606958130995434, 'Total loss': 0.39606958130995434} | train loss {'Reaction outcome loss': 0.2041389405834976, 'Total loss': 0.2041389405834976}
2023-01-04 01:24:37,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:37,294 INFO:     Epoch: 60
2023-01-04 01:24:38,924 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39803718229134877, 'Total loss': 0.39803718229134877} | train loss {'Reaction outcome loss': 0.20268659754269605, 'Total loss': 0.20268659754269605}
2023-01-04 01:24:38,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:38,924 INFO:     Epoch: 61
2023-01-04 01:24:40,521 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4183583418528239, 'Total loss': 0.4183583418528239} | train loss {'Reaction outcome loss': 0.20261782390277308, 'Total loss': 0.20261782390277308}
2023-01-04 01:24:40,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:40,521 INFO:     Epoch: 62
2023-01-04 01:24:42,122 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3874003877242406, 'Total loss': 0.3874003877242406} | train loss {'Reaction outcome loss': 0.20342405239920325, 'Total loss': 0.20342405239920325}
2023-01-04 01:24:42,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:42,123 INFO:     Epoch: 63
2023-01-04 01:24:43,719 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.389106297492981, 'Total loss': 0.389106297492981} | train loss {'Reaction outcome loss': 0.19942666925758876, 'Total loss': 0.19942666925758876}
2023-01-04 01:24:43,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:43,720 INFO:     Epoch: 64
2023-01-04 01:24:45,338 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40138831436634065, 'Total loss': 0.40138831436634065} | train loss {'Reaction outcome loss': 0.1974180105750849, 'Total loss': 0.1974180105750849}
2023-01-04 01:24:45,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:45,338 INFO:     Epoch: 65
2023-01-04 01:24:46,968 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3938518981138865, 'Total loss': 0.3938518981138865} | train loss {'Reaction outcome loss': 0.19807617952677317, 'Total loss': 0.19807617952677317}
2023-01-04 01:24:46,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:46,968 INFO:     Epoch: 66
2023-01-04 01:24:48,571 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4066574603319168, 'Total loss': 0.4066574603319168} | train loss {'Reaction outcome loss': 0.19452415675677978, 'Total loss': 0.19452415675677978}
2023-01-04 01:24:48,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:48,572 INFO:     Epoch: 67
2023-01-04 01:24:50,200 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39797544479370117, 'Total loss': 0.39797544479370117} | train loss {'Reaction outcome loss': 0.19435615107309517, 'Total loss': 0.19435615107309517}
2023-01-04 01:24:50,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:50,200 INFO:     Epoch: 68
2023-01-04 01:24:51,792 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3975434606273969, 'Total loss': 0.3975434606273969} | train loss {'Reaction outcome loss': 0.19557846087410993, 'Total loss': 0.19557846087410993}
2023-01-04 01:24:51,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:51,792 INFO:     Epoch: 69
2023-01-04 01:24:53,404 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39427850643793744, 'Total loss': 0.39427850643793744} | train loss {'Reaction outcome loss': 0.19367325741676647, 'Total loss': 0.19367325741676647}
2023-01-04 01:24:53,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:53,405 INFO:     Epoch: 70
2023-01-04 01:24:54,997 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40262525180975595, 'Total loss': 0.40262525180975595} | train loss {'Reaction outcome loss': 0.19154135940683878, 'Total loss': 0.19154135940683878}
2023-01-04 01:24:54,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:54,997 INFO:     Epoch: 71
2023-01-04 01:24:56,614 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40594253142674763, 'Total loss': 0.40594253142674763} | train loss {'Reaction outcome loss': 0.19042392778428882, 'Total loss': 0.19042392778428882}
2023-01-04 01:24:56,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:56,614 INFO:     Epoch: 72
2023-01-04 01:24:58,220 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4024730841318766, 'Total loss': 0.4024730841318766} | train loss {'Reaction outcome loss': 0.19107533357902984, 'Total loss': 0.19107533357902984}
2023-01-04 01:24:58,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:58,220 INFO:     Epoch: 73
2023-01-04 01:24:59,846 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38535945999125637, 'Total loss': 0.38535945999125637} | train loss {'Reaction outcome loss': 0.18905725986410996, 'Total loss': 0.18905725986410996}
2023-01-04 01:24:59,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:24:59,847 INFO:     Epoch: 74
2023-01-04 01:25:01,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4037002921104431, 'Total loss': 0.4037002921104431} | train loss {'Reaction outcome loss': 0.18902255583971417, 'Total loss': 0.18902255583971417}
2023-01-04 01:25:01,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:01,445 INFO:     Epoch: 75
2023-01-04 01:25:03,076 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41023573676745095, 'Total loss': 0.41023573676745095} | train loss {'Reaction outcome loss': 0.18528634184023318, 'Total loss': 0.18528634184023318}
2023-01-04 01:25:03,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:03,076 INFO:     Epoch: 76
2023-01-04 01:25:04,709 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41698201845089594, 'Total loss': 0.41698201845089594} | train loss {'Reaction outcome loss': 0.18732672355504243, 'Total loss': 0.18732672355504243}
2023-01-04 01:25:04,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:04,709 INFO:     Epoch: 77
2023-01-04 01:25:06,323 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40610622862974805, 'Total loss': 0.40610622862974805} | train loss {'Reaction outcome loss': 0.18761680628902647, 'Total loss': 0.18761680628902647}
2023-01-04 01:25:06,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:06,324 INFO:     Epoch: 78
2023-01-04 01:25:07,919 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4020552853743235, 'Total loss': 0.4020552853743235} | train loss {'Reaction outcome loss': 0.18427499226338165, 'Total loss': 0.18427499226338165}
2023-01-04 01:25:07,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:07,919 INFO:     Epoch: 79
2023-01-04 01:25:09,348 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40412657608588537, 'Total loss': 0.40412657608588537} | train loss {'Reaction outcome loss': 0.18343516590497339, 'Total loss': 0.18343516590497339}
2023-01-04 01:25:09,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:09,349 INFO:     Epoch: 80
2023-01-04 01:25:10,436 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4107336799303691, 'Total loss': 0.4107336799303691} | train loss {'Reaction outcome loss': 0.18436125126610164, 'Total loss': 0.18436125126610164}
2023-01-04 01:25:10,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:10,436 INFO:     Epoch: 81
2023-01-04 01:25:11,520 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40739816427230835, 'Total loss': 0.40739816427230835} | train loss {'Reaction outcome loss': 0.18435892140634008, 'Total loss': 0.18435892140634008}
2023-01-04 01:25:11,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:11,520 INFO:     Epoch: 82
2023-01-04 01:25:12,600 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41223423679669696, 'Total loss': 0.41223423679669696} | train loss {'Reaction outcome loss': 0.18443687737579811, 'Total loss': 0.18443687737579811}
2023-01-04 01:25:12,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:12,601 INFO:     Epoch: 83
2023-01-04 01:25:13,883 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42048244426647824, 'Total loss': 0.42048244426647824} | train loss {'Reaction outcome loss': 0.17994496456283524, 'Total loss': 0.17994496456283524}
2023-01-04 01:25:13,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:13,883 INFO:     Epoch: 84
2023-01-04 01:25:15,503 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4326939652363459, 'Total loss': 0.4326939652363459} | train loss {'Reaction outcome loss': 0.18016267328486116, 'Total loss': 0.18016267328486116}
2023-01-04 01:25:15,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:15,503 INFO:     Epoch: 85
2023-01-04 01:25:17,128 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41254788637161255, 'Total loss': 0.41254788637161255} | train loss {'Reaction outcome loss': 0.17944240221074556, 'Total loss': 0.17944240221074556}
2023-01-04 01:25:17,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:17,128 INFO:     Epoch: 86
2023-01-04 01:25:18,744 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41630749801794686, 'Total loss': 0.41630749801794686} | train loss {'Reaction outcome loss': 0.17841597301515646, 'Total loss': 0.17841597301515646}
2023-01-04 01:25:18,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:18,744 INFO:     Epoch: 87
2023-01-04 01:25:20,347 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4248159686724345, 'Total loss': 0.4248159686724345} | train loss {'Reaction outcome loss': 0.17883675916638184, 'Total loss': 0.17883675916638184}
2023-01-04 01:25:20,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:20,347 INFO:     Epoch: 88
2023-01-04 01:25:21,950 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4282990574836731, 'Total loss': 0.4282990574836731} | train loss {'Reaction outcome loss': 0.17904219118750483, 'Total loss': 0.17904219118750483}
2023-01-04 01:25:21,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:21,950 INFO:     Epoch: 89
2023-01-04 01:25:23,475 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4162891109784444, 'Total loss': 0.4162891109784444} | train loss {'Reaction outcome loss': 0.1767283172585366, 'Total loss': 0.1767283172585366}
2023-01-04 01:25:23,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:23,475 INFO:     Epoch: 90
2023-01-04 01:25:25,102 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42535899877548217, 'Total loss': 0.42535899877548217} | train loss {'Reaction outcome loss': 0.17653405499923638, 'Total loss': 0.17653405499923638}
2023-01-04 01:25:25,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:25,103 INFO:     Epoch: 91
2023-01-04 01:25:26,717 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4239453752835592, 'Total loss': 0.4239453752835592} | train loss {'Reaction outcome loss': 0.17597454249697472, 'Total loss': 0.17597454249697472}
2023-01-04 01:25:26,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:26,717 INFO:     Epoch: 92
2023-01-04 01:25:28,345 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4180025219917297, 'Total loss': 0.4180025219917297} | train loss {'Reaction outcome loss': 0.17412998255624668, 'Total loss': 0.17412998255624668}
2023-01-04 01:25:28,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:28,345 INFO:     Epoch: 93
2023-01-04 01:25:29,980 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43501047293345135, 'Total loss': 0.43501047293345135} | train loss {'Reaction outcome loss': 0.1753316758812442, 'Total loss': 0.1753316758812442}
2023-01-04 01:25:29,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:29,980 INFO:     Epoch: 94
2023-01-04 01:25:31,520 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4376650512218475, 'Total loss': 0.4376650512218475} | train loss {'Reaction outcome loss': 0.17609566495844603, 'Total loss': 0.17609566495844603}
2023-01-04 01:25:31,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:31,520 INFO:     Epoch: 95
2023-01-04 01:25:33,154 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4332172811031342, 'Total loss': 0.4332172811031342} | train loss {'Reaction outcome loss': 0.1729000548055456, 'Total loss': 0.1729000548055456}
2023-01-04 01:25:33,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:33,154 INFO:     Epoch: 96
2023-01-04 01:25:34,788 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4196875353654226, 'Total loss': 0.4196875353654226} | train loss {'Reaction outcome loss': 0.17375120501763555, 'Total loss': 0.17375120501763555}
2023-01-04 01:25:34,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:34,788 INFO:     Epoch: 97
2023-01-04 01:25:36,424 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44494517147541046, 'Total loss': 0.44494517147541046} | train loss {'Reaction outcome loss': 0.16889741674522846, 'Total loss': 0.16889741674522846}
2023-01-04 01:25:36,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:36,425 INFO:     Epoch: 98
2023-01-04 01:25:38,053 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43650561620791756, 'Total loss': 0.43650561620791756} | train loss {'Reaction outcome loss': 0.16956263235921465, 'Total loss': 0.16956263235921465}
2023-01-04 01:25:38,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:38,053 INFO:     Epoch: 99
2023-01-04 01:25:39,686 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4338965853055318, 'Total loss': 0.4338965853055318} | train loss {'Reaction outcome loss': 0.169742930404815, 'Total loss': 0.169742930404815}
2023-01-04 01:25:39,686 INFO:     Best model found after epoch 24 of 100.
2023-01-04 01:25:39,687 INFO:   Done with stage: TRAINING
2023-01-04 01:25:39,687 INFO:   Starting stage: EVALUATION
2023-01-04 01:25:39,809 INFO:   Done with stage: EVALUATION
2023-01-04 01:25:39,809 INFO:   Leaving out SEQ value Fold_6
2023-01-04 01:25:39,822 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:25:39,822 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:25:40,468 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:25:40,468 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:25:40,539 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:25:40,539 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:25:40,539 INFO:     No hyperparam tuning for this model
2023-01-04 01:25:40,539 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:25:40,540 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:25:40,540 INFO:     None feature selector for col prot
2023-01-04 01:25:40,540 INFO:     None feature selector for col prot
2023-01-04 01:25:40,540 INFO:     None feature selector for col prot
2023-01-04 01:25:40,541 INFO:     None feature selector for col chem
2023-01-04 01:25:40,541 INFO:     None feature selector for col chem
2023-01-04 01:25:40,541 INFO:     None feature selector for col chem
2023-01-04 01:25:40,541 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:25:40,541 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:25:40,542 INFO:     Number of params in model 70141
2023-01-04 01:25:40,545 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:25:40,546 INFO:   Starting stage: TRAINING
2023-01-04 01:25:40,591 INFO:     Val loss before train {'Reaction outcome loss': 0.9430275559425354, 'Total loss': 0.9430275559425354}
2023-01-04 01:25:40,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:40,591 INFO:     Epoch: 0
2023-01-04 01:25:42,197 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6041752656300863, 'Total loss': 0.6041752656300863} | train loss {'Reaction outcome loss': 0.8518591599559096, 'Total loss': 0.8518591599559096}
2023-01-04 01:25:42,197 INFO:     Found new best model at epoch 0
2023-01-04 01:25:42,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:42,198 INFO:     Epoch: 1
2023-01-04 01:25:43,805 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5156862219174703, 'Total loss': 0.5156862219174703} | train loss {'Reaction outcome loss': 0.5994429981019953, 'Total loss': 0.5994429981019953}
2023-01-04 01:25:43,806 INFO:     Found new best model at epoch 1
2023-01-04 01:25:43,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:43,807 INFO:     Epoch: 2
2023-01-04 01:25:45,411 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48165855805079144, 'Total loss': 0.48165855805079144} | train loss {'Reaction outcome loss': 0.5198043148547734, 'Total loss': 0.5198043148547734}
2023-01-04 01:25:45,411 INFO:     Found new best model at epoch 2
2023-01-04 01:25:45,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:45,412 INFO:     Epoch: 3
2023-01-04 01:25:47,042 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4545082231362661, 'Total loss': 0.4545082231362661} | train loss {'Reaction outcome loss': 0.48436542500872903, 'Total loss': 0.48436542500872903}
2023-01-04 01:25:47,042 INFO:     Found new best model at epoch 3
2023-01-04 01:25:47,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:47,043 INFO:     Epoch: 4
2023-01-04 01:25:48,668 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43882680336634317, 'Total loss': 0.43882680336634317} | train loss {'Reaction outcome loss': 0.4583133973907478, 'Total loss': 0.4583133973907478}
2023-01-04 01:25:48,668 INFO:     Found new best model at epoch 4
2023-01-04 01:25:48,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:48,669 INFO:     Epoch: 5
2023-01-04 01:25:50,213 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4444604436556498, 'Total loss': 0.4444604436556498} | train loss {'Reaction outcome loss': 0.4412184180658216, 'Total loss': 0.4412184180658216}
2023-01-04 01:25:50,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:50,214 INFO:     Epoch: 6
2023-01-04 01:25:51,851 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42798294921716057, 'Total loss': 0.42798294921716057} | train loss {'Reaction outcome loss': 0.42760768928144816, 'Total loss': 0.42760768928144816}
2023-01-04 01:25:51,851 INFO:     Found new best model at epoch 6
2023-01-04 01:25:51,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:51,852 INFO:     Epoch: 7
2023-01-04 01:25:53,482 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4140522847572962, 'Total loss': 0.4140522847572962} | train loss {'Reaction outcome loss': 0.4169039861551261, 'Total loss': 0.4169039861551261}
2023-01-04 01:25:53,482 INFO:     Found new best model at epoch 7
2023-01-04 01:25:53,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:53,483 INFO:     Epoch: 8
2023-01-04 01:25:55,116 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4191441357135773, 'Total loss': 0.4191441357135773} | train loss {'Reaction outcome loss': 0.4032143584119714, 'Total loss': 0.4032143584119714}
2023-01-04 01:25:55,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:55,116 INFO:     Epoch: 9
2023-01-04 01:25:56,740 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41496100227038063, 'Total loss': 0.41496100227038063} | train loss {'Reaction outcome loss': 0.39296623133795355, 'Total loss': 0.39296623133795355}
2023-01-04 01:25:56,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:56,741 INFO:     Epoch: 10
2023-01-04 01:25:58,298 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4143115997314453, 'Total loss': 0.4143115997314453} | train loss {'Reaction outcome loss': 0.38286262960425355, 'Total loss': 0.38286262960425355}
2023-01-04 01:25:58,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:58,298 INFO:     Epoch: 11
2023-01-04 01:25:59,910 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4034244646628698, 'Total loss': 0.4034244646628698} | train loss {'Reaction outcome loss': 0.3778647010076778, 'Total loss': 0.3778647010076778}
2023-01-04 01:25:59,910 INFO:     Found new best model at epoch 11
2023-01-04 01:25:59,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:25:59,911 INFO:     Epoch: 12
2023-01-04 01:26:01,529 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.405429079135259, 'Total loss': 0.405429079135259} | train loss {'Reaction outcome loss': 0.3697577042484972, 'Total loss': 0.3697577042484972}
2023-01-04 01:26:01,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:01,529 INFO:     Epoch: 13
2023-01-04 01:26:03,142 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4035476863384247, 'Total loss': 0.4035476863384247} | train loss {'Reaction outcome loss': 0.3638995422944695, 'Total loss': 0.3638995422944695}
2023-01-04 01:26:03,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:03,142 INFO:     Epoch: 14
2023-01-04 01:26:04,776 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38822612166404724, 'Total loss': 0.38822612166404724} | train loss {'Reaction outcome loss': 0.358131911134892, 'Total loss': 0.358131911134892}
2023-01-04 01:26:04,776 INFO:     Found new best model at epoch 14
2023-01-04 01:26:04,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:04,777 INFO:     Epoch: 15
2023-01-04 01:26:06,393 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.406777685880661, 'Total loss': 0.406777685880661} | train loss {'Reaction outcome loss': 0.34997863900790577, 'Total loss': 0.34997863900790577}
2023-01-04 01:26:06,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:06,394 INFO:     Epoch: 16
2023-01-04 01:26:07,950 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3975946505864461, 'Total loss': 0.3975946505864461} | train loss {'Reaction outcome loss': 0.34312561151675797, 'Total loss': 0.34312561151675797}
2023-01-04 01:26:07,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:07,950 INFO:     Epoch: 17
2023-01-04 01:26:09,584 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39306638737519584, 'Total loss': 0.39306638737519584} | train loss {'Reaction outcome loss': 0.3414782943331808, 'Total loss': 0.3414782943331808}
2023-01-04 01:26:09,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:09,585 INFO:     Epoch: 18
2023-01-04 01:26:11,218 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3845928351084391, 'Total loss': 0.3845928351084391} | train loss {'Reaction outcome loss': 0.3315960355506477, 'Total loss': 0.3315960355506477}
2023-01-04 01:26:11,218 INFO:     Found new best model at epoch 18
2023-01-04 01:26:11,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:11,219 INFO:     Epoch: 19
2023-01-04 01:26:12,844 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39113174279530843, 'Total loss': 0.39113174279530843} | train loss {'Reaction outcome loss': 0.32526317580404696, 'Total loss': 0.32526317580404696}
2023-01-04 01:26:12,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:12,846 INFO:     Epoch: 20
2023-01-04 01:26:14,465 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3911031643549601, 'Total loss': 0.3911031643549601} | train loss {'Reaction outcome loss': 0.3206632438549496, 'Total loss': 0.3206632438549496}
2023-01-04 01:26:14,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:14,465 INFO:     Epoch: 21
2023-01-04 01:26:16,071 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41094643572966255, 'Total loss': 0.41094643572966255} | train loss {'Reaction outcome loss': 0.31486164719296705, 'Total loss': 0.31486164719296705}
2023-01-04 01:26:16,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:16,071 INFO:     Epoch: 22
2023-01-04 01:26:17,631 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38085611959298454, 'Total loss': 0.38085611959298454} | train loss {'Reaction outcome loss': 0.3103662995816568, 'Total loss': 0.3103662995816568}
2023-01-04 01:26:17,631 INFO:     Found new best model at epoch 22
2023-01-04 01:26:17,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:17,632 INFO:     Epoch: 23
2023-01-04 01:26:19,244 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3964731067419052, 'Total loss': 0.3964731067419052} | train loss {'Reaction outcome loss': 0.3067139600158168, 'Total loss': 0.3067139600158168}
2023-01-04 01:26:19,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:19,245 INFO:     Epoch: 24
2023-01-04 01:26:20,830 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4024784922599792, 'Total loss': 0.4024784922599792} | train loss {'Reaction outcome loss': 0.3006108993603865, 'Total loss': 0.3006108993603865}
2023-01-04 01:26:20,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:20,830 INFO:     Epoch: 25
2023-01-04 01:26:22,467 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38378303945064546, 'Total loss': 0.38378303945064546} | train loss {'Reaction outcome loss': 0.29332807030703617, 'Total loss': 0.29332807030703617}
2023-01-04 01:26:22,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:22,467 INFO:     Epoch: 26
2023-01-04 01:26:24,102 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39743296305338544, 'Total loss': 0.39743296305338544} | train loss {'Reaction outcome loss': 0.2924014106123886, 'Total loss': 0.2924014106123886}
2023-01-04 01:26:24,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:24,102 INFO:     Epoch: 27
2023-01-04 01:26:25,661 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40112703243891396, 'Total loss': 0.40112703243891396} | train loss {'Reaction outcome loss': 0.28759177610116743, 'Total loss': 0.28759177610116743}
2023-01-04 01:26:25,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:25,661 INFO:     Epoch: 28
2023-01-04 01:26:27,300 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38874417742093403, 'Total loss': 0.38874417742093403} | train loss {'Reaction outcome loss': 0.2844362645695786, 'Total loss': 0.2844362645695786}
2023-01-04 01:26:27,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:27,300 INFO:     Epoch: 29
2023-01-04 01:26:28,936 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4032124549150467, 'Total loss': 0.4032124549150467} | train loss {'Reaction outcome loss': 0.27946482208769247, 'Total loss': 0.27946482208769247}
2023-01-04 01:26:28,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:28,936 INFO:     Epoch: 30
2023-01-04 01:26:30,522 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39279040495554607, 'Total loss': 0.39279040495554607} | train loss {'Reaction outcome loss': 0.27606154948688155, 'Total loss': 0.27606154948688155}
2023-01-04 01:26:30,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:30,522 INFO:     Epoch: 31
2023-01-04 01:26:32,149 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40024149616559346, 'Total loss': 0.40024149616559346} | train loss {'Reaction outcome loss': 0.27381992011939577, 'Total loss': 0.27381992011939577}
2023-01-04 01:26:32,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:32,150 INFO:     Epoch: 32
2023-01-04 01:26:33,748 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3867256224155426, 'Total loss': 0.3867256224155426} | train loss {'Reaction outcome loss': 0.2677581430503608, 'Total loss': 0.2677581430503608}
2023-01-04 01:26:33,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:33,748 INFO:     Epoch: 33
2023-01-04 01:26:35,295 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3894180417060852, 'Total loss': 0.3894180417060852} | train loss {'Reaction outcome loss': 0.2663126983797507, 'Total loss': 0.2663126983797507}
2023-01-04 01:26:35,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:35,295 INFO:     Epoch: 34
2023-01-04 01:26:36,941 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3982373038927714, 'Total loss': 0.3982373038927714} | train loss {'Reaction outcome loss': 0.2618550939841821, 'Total loss': 0.2618550939841821}
2023-01-04 01:26:36,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:36,941 INFO:     Epoch: 35
2023-01-04 01:26:38,577 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39949913024902345, 'Total loss': 0.39949913024902345} | train loss {'Reaction outcome loss': 0.26034032311357747, 'Total loss': 0.26034032311357747}
2023-01-04 01:26:38,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:38,577 INFO:     Epoch: 36
2023-01-04 01:26:40,202 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3937244683504105, 'Total loss': 0.3937244683504105} | train loss {'Reaction outcome loss': 0.2551827471878124, 'Total loss': 0.2551827471878124}
2023-01-04 01:26:40,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:40,202 INFO:     Epoch: 37
2023-01-04 01:26:41,832 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41180470486481985, 'Total loss': 0.41180470486481985} | train loss {'Reaction outcome loss': 0.253967259119564, 'Total loss': 0.253967259119564}
2023-01-04 01:26:41,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:41,832 INFO:     Epoch: 38
2023-01-04 01:26:43,421 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4058209945758184, 'Total loss': 0.4058209945758184} | train loss {'Reaction outcome loss': 0.2502321849580491, 'Total loss': 0.2502321849580491}
2023-01-04 01:26:43,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:43,422 INFO:     Epoch: 39
2023-01-04 01:26:45,000 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40464415748914084, 'Total loss': 0.40464415748914084} | train loss {'Reaction outcome loss': 0.2480449742143335, 'Total loss': 0.2480449742143335}
2023-01-04 01:26:45,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:45,000 INFO:     Epoch: 40
2023-01-04 01:26:46,609 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4359625538190206, 'Total loss': 0.4359625538190206} | train loss {'Reaction outcome loss': 0.24596582211903717, 'Total loss': 0.24596582211903717}
2023-01-04 01:26:46,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:46,609 INFO:     Epoch: 41
2023-01-04 01:26:48,214 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4164893845717112, 'Total loss': 0.4164893845717112} | train loss {'Reaction outcome loss': 0.24418629533762537, 'Total loss': 0.24418629533762537}
2023-01-04 01:26:48,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:48,215 INFO:     Epoch: 42
2023-01-04 01:26:49,822 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41100607415040336, 'Total loss': 0.41100607415040336} | train loss {'Reaction outcome loss': 0.23835915904021435, 'Total loss': 0.23835915904021435}
2023-01-04 01:26:49,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:49,823 INFO:     Epoch: 43
2023-01-04 01:26:51,427 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3952747493982315, 'Total loss': 0.3952747493982315} | train loss {'Reaction outcome loss': 0.23866149830204916, 'Total loss': 0.23866149830204916}
2023-01-04 01:26:51,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:51,427 INFO:     Epoch: 44
2023-01-04 01:26:52,956 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4134160200754801, 'Total loss': 0.4134160200754801} | train loss {'Reaction outcome loss': 0.23819747801184224, 'Total loss': 0.23819747801184224}
2023-01-04 01:26:52,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:52,956 INFO:     Epoch: 45
2023-01-04 01:26:54,584 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4364049514134725, 'Total loss': 0.4364049514134725} | train loss {'Reaction outcome loss': 0.2370036820870982, 'Total loss': 0.2370036820870982}
2023-01-04 01:26:54,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:54,585 INFO:     Epoch: 46
2023-01-04 01:26:56,213 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4150551517804464, 'Total loss': 0.4150551517804464} | train loss {'Reaction outcome loss': 0.2327810862918623, 'Total loss': 0.2327810862918623}
2023-01-04 01:26:56,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:56,213 INFO:     Epoch: 47
2023-01-04 01:26:57,824 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42180875738461815, 'Total loss': 0.42180875738461815} | train loss {'Reaction outcome loss': 0.23159342567143887, 'Total loss': 0.23159342567143887}
2023-01-04 01:26:57,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:57,825 INFO:     Epoch: 48
2023-01-04 01:26:59,435 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41245820820331575, 'Total loss': 0.41245820820331575} | train loss {'Reaction outcome loss': 0.22894766501786476, 'Total loss': 0.22894766501786476}
2023-01-04 01:26:59,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:26:59,436 INFO:     Epoch: 49
2023-01-04 01:27:01,065 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44442622860272724, 'Total loss': 0.44442622860272724} | train loss {'Reaction outcome loss': 0.22581420830763635, 'Total loss': 0.22581420830763635}
2023-01-04 01:27:01,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:01,065 INFO:     Epoch: 50
2023-01-04 01:27:02,605 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43495440979798633, 'Total loss': 0.43495440979798633} | train loss {'Reaction outcome loss': 0.2278812928965806, 'Total loss': 0.2278812928965806}
2023-01-04 01:27:02,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:02,606 INFO:     Epoch: 51
2023-01-04 01:27:04,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42273653745651246, 'Total loss': 0.42273653745651246} | train loss {'Reaction outcome loss': 0.22177976914530195, 'Total loss': 0.22177976914530195}
2023-01-04 01:27:04,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:04,212 INFO:     Epoch: 52
2023-01-04 01:27:05,818 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4170809775590897, 'Total loss': 0.4170809775590897} | train loss {'Reaction outcome loss': 0.22207149639994658, 'Total loss': 0.22207149639994658}
2023-01-04 01:27:05,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:05,818 INFO:     Epoch: 53
2023-01-04 01:27:07,424 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4143269707759221, 'Total loss': 0.4143269707759221} | train loss {'Reaction outcome loss': 0.21858976022861495, 'Total loss': 0.21858976022861495}
2023-01-04 01:27:07,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:07,424 INFO:     Epoch: 54
2023-01-04 01:27:09,030 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4250343769788742, 'Total loss': 0.4250343769788742} | train loss {'Reaction outcome loss': 0.21947483465559647, 'Total loss': 0.21947483465559647}
2023-01-04 01:27:09,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:09,030 INFO:     Epoch: 55
2023-01-04 01:27:10,570 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41970206250747044, 'Total loss': 0.41970206250747044} | train loss {'Reaction outcome loss': 0.21749505319965445, 'Total loss': 0.21749505319965445}
2023-01-04 01:27:10,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:10,570 INFO:     Epoch: 56
2023-01-04 01:27:12,197 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42401841978232063, 'Total loss': 0.42401841978232063} | train loss {'Reaction outcome loss': 0.21513481153047473, 'Total loss': 0.21513481153047473}
2023-01-04 01:27:12,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:12,197 INFO:     Epoch: 57
2023-01-04 01:27:13,801 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4013481855392456, 'Total loss': 0.4013481855392456} | train loss {'Reaction outcome loss': 0.21243890972021254, 'Total loss': 0.21243890972021254}
2023-01-04 01:27:13,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:13,802 INFO:     Epoch: 58
2023-01-04 01:27:15,423 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40856173237164817, 'Total loss': 0.40856173237164817} | train loss {'Reaction outcome loss': 0.21239865006414993, 'Total loss': 0.21239865006414993}
2023-01-04 01:27:15,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:15,423 INFO:     Epoch: 59
2023-01-04 01:27:17,029 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44710345069567364, 'Total loss': 0.44710345069567364} | train loss {'Reaction outcome loss': 0.21279618472183653, 'Total loss': 0.21279618472183653}
2023-01-04 01:27:17,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:17,029 INFO:     Epoch: 60
2023-01-04 01:27:18,635 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43264493644237517, 'Total loss': 0.43264493644237517} | train loss {'Reaction outcome loss': 0.21050476585430788, 'Total loss': 0.21050476585430788}
2023-01-04 01:27:18,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:18,635 INFO:     Epoch: 61
2023-01-04 01:27:20,171 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4215286781390508, 'Total loss': 0.4215286781390508} | train loss {'Reaction outcome loss': 0.2077909256550164, 'Total loss': 0.2077909256550164}
2023-01-04 01:27:20,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:20,171 INFO:     Epoch: 62
2023-01-04 01:27:21,803 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42730036278565725, 'Total loss': 0.42730036278565725} | train loss {'Reaction outcome loss': 0.20832672362831095, 'Total loss': 0.20832672362831095}
2023-01-04 01:27:21,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:21,803 INFO:     Epoch: 63
2023-01-04 01:27:23,435 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4136415014664332, 'Total loss': 0.4136415014664332} | train loss {'Reaction outcome loss': 0.20646618644199216, 'Total loss': 0.20646618644199216}
2023-01-04 01:27:23,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:23,435 INFO:     Epoch: 64
2023-01-04 01:27:25,066 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43849550088246664, 'Total loss': 0.43849550088246664} | train loss {'Reaction outcome loss': 0.2026182073521485, 'Total loss': 0.2026182073521485}
2023-01-04 01:27:25,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:25,067 INFO:     Epoch: 65
2023-01-04 01:27:26,697 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40847239991029105, 'Total loss': 0.40847239991029105} | train loss {'Reaction outcome loss': 0.2030343596255306, 'Total loss': 0.2030343596255306}
2023-01-04 01:27:26,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:26,697 INFO:     Epoch: 66
2023-01-04 01:27:28,306 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4285601009925207, 'Total loss': 0.4285601009925207} | train loss {'Reaction outcome loss': 0.20169560102887102, 'Total loss': 0.20169560102887102}
2023-01-04 01:27:28,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:28,307 INFO:     Epoch: 67
2023-01-04 01:27:29,850 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.433490464091301, 'Total loss': 0.433490464091301} | train loss {'Reaction outcome loss': 0.2042146109125244, 'Total loss': 0.2042146109125244}
2023-01-04 01:27:29,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:29,850 INFO:     Epoch: 68
2023-01-04 01:27:31,454 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4273738374312719, 'Total loss': 0.4273738374312719} | train loss {'Reaction outcome loss': 0.20212838749001172, 'Total loss': 0.20212838749001172}
2023-01-04 01:27:31,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:31,454 INFO:     Epoch: 69
2023-01-04 01:27:33,059 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4320473104715347, 'Total loss': 0.4320473104715347} | train loss {'Reaction outcome loss': 0.19907372158410747, 'Total loss': 0.19907372158410747}
2023-01-04 01:27:33,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:33,060 INFO:     Epoch: 70
2023-01-04 01:27:34,665 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4406469662984212, 'Total loss': 0.4406469662984212} | train loss {'Reaction outcome loss': 0.19935778551314712, 'Total loss': 0.19935778551314712}
2023-01-04 01:27:34,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:34,665 INFO:     Epoch: 71
2023-01-04 01:27:36,269 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43314921458562217, 'Total loss': 0.43314921458562217} | train loss {'Reaction outcome loss': 0.19627275812819547, 'Total loss': 0.19627275812819547}
2023-01-04 01:27:36,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:36,270 INFO:     Epoch: 72
2023-01-04 01:27:37,827 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42731965482234957, 'Total loss': 0.42731965482234957} | train loss {'Reaction outcome loss': 0.19946890844818918, 'Total loss': 0.19946890844818918}
2023-01-04 01:27:37,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:37,827 INFO:     Epoch: 73
2023-01-04 01:27:39,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44529342552026113, 'Total loss': 0.44529342552026113} | train loss {'Reaction outcome loss': 0.19496351507381413, 'Total loss': 0.19496351507381413}
2023-01-04 01:27:39,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:39,457 INFO:     Epoch: 74
2023-01-04 01:27:41,084 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4275223702192307, 'Total loss': 0.4275223702192307} | train loss {'Reaction outcome loss': 0.19591069798445873, 'Total loss': 0.19591069798445873}
2023-01-04 01:27:41,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:41,084 INFO:     Epoch: 75
2023-01-04 01:27:42,704 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4473436971505483, 'Total loss': 0.4473436971505483} | train loss {'Reaction outcome loss': 0.19293373246889037, 'Total loss': 0.19293373246889037}
2023-01-04 01:27:42,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:42,704 INFO:     Epoch: 76
2023-01-04 01:27:44,342 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4238848964373271, 'Total loss': 0.4238848964373271} | train loss {'Reaction outcome loss': 0.19186344265009844, 'Total loss': 0.19186344265009844}
2023-01-04 01:27:44,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:44,342 INFO:     Epoch: 77
2023-01-04 01:27:45,963 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4504296084245046, 'Total loss': 0.4504296084245046} | train loss {'Reaction outcome loss': 0.19213212025940202, 'Total loss': 0.19213212025940202}
2023-01-04 01:27:45,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:45,963 INFO:     Epoch: 78
2023-01-04 01:27:47,519 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44900848269462584, 'Total loss': 0.44900848269462584} | train loss {'Reaction outcome loss': 0.19042143283499277, 'Total loss': 0.19042143283499277}
2023-01-04 01:27:47,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:47,519 INFO:     Epoch: 79
2023-01-04 01:27:49,147 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4448907673358917, 'Total loss': 0.4448907673358917} | train loss {'Reaction outcome loss': 0.19080154932631913, 'Total loss': 0.19080154932631913}
2023-01-04 01:27:49,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:49,147 INFO:     Epoch: 80
2023-01-04 01:27:50,778 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4521064579486847, 'Total loss': 0.4521064579486847} | train loss {'Reaction outcome loss': 0.18902295121808774, 'Total loss': 0.18902295121808774}
2023-01-04 01:27:50,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:50,780 INFO:     Epoch: 81
2023-01-04 01:27:52,433 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4320603787899017, 'Total loss': 0.4320603787899017} | train loss {'Reaction outcome loss': 0.18738648800401267, 'Total loss': 0.18738648800401267}
2023-01-04 01:27:52,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:52,434 INFO:     Epoch: 82
2023-01-04 01:27:54,089 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4659373770157496, 'Total loss': 0.4659373770157496} | train loss {'Reaction outcome loss': 0.186782166576988, 'Total loss': 0.186782166576988}
2023-01-04 01:27:54,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:54,089 INFO:     Epoch: 83
2023-01-04 01:27:55,748 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.459804967045784, 'Total loss': 0.459804967045784} | train loss {'Reaction outcome loss': 0.18647677042531624, 'Total loss': 0.18647677042531624}
2023-01-04 01:27:55,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:55,748 INFO:     Epoch: 84
2023-01-04 01:27:57,329 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4536402652661006, 'Total loss': 0.4536402652661006} | train loss {'Reaction outcome loss': 0.18706975701107015, 'Total loss': 0.18706975701107015}
2023-01-04 01:27:57,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:57,330 INFO:     Epoch: 85
2023-01-04 01:27:58,979 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44527234037717184, 'Total loss': 0.44527234037717184} | train loss {'Reaction outcome loss': 0.18703431820342256, 'Total loss': 0.18703431820342256}
2023-01-04 01:27:58,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:27:58,979 INFO:     Epoch: 86
2023-01-04 01:28:00,625 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4563196023305257, 'Total loss': 0.4563196023305257} | train loss {'Reaction outcome loss': 0.18315345078491563, 'Total loss': 0.18315345078491563}
2023-01-04 01:28:00,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:00,625 INFO:     Epoch: 87
2023-01-04 01:28:02,281 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46277263363202414, 'Total loss': 0.46277263363202414} | train loss {'Reaction outcome loss': 0.18363592383663577, 'Total loss': 0.18363592383663577}
2023-01-04 01:28:02,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:02,281 INFO:     Epoch: 88
2023-01-04 01:28:03,957 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41862649867932, 'Total loss': 0.41862649867932} | train loss {'Reaction outcome loss': 0.18009028425742787, 'Total loss': 0.18009028425742787}
2023-01-04 01:28:03,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:03,957 INFO:     Epoch: 89
2023-01-04 01:28:05,589 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4486441979805628, 'Total loss': 0.4486441979805628} | train loss {'Reaction outcome loss': 0.18118653112235697, 'Total loss': 0.18118653112235697}
2023-01-04 01:28:05,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:05,589 INFO:     Epoch: 90
2023-01-04 01:28:07,246 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4541020895044009, 'Total loss': 0.4541020895044009} | train loss {'Reaction outcome loss': 0.1805376150520915, 'Total loss': 0.1805376150520915}
2023-01-04 01:28:07,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:07,246 INFO:     Epoch: 91
2023-01-04 01:28:08,921 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4713912089665731, 'Total loss': 0.4713912089665731} | train loss {'Reaction outcome loss': 0.18279087632248978, 'Total loss': 0.18279087632248978}
2023-01-04 01:28:08,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:08,922 INFO:     Epoch: 92
2023-01-04 01:28:10,559 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46135356823603313, 'Total loss': 0.46135356823603313} | train loss {'Reaction outcome loss': 0.18001134261919272, 'Total loss': 0.18001134261919272}
2023-01-04 01:28:10,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:10,560 INFO:     Epoch: 93
2023-01-04 01:28:12,201 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46309628238280615, 'Total loss': 0.46309628238280615} | train loss {'Reaction outcome loss': 0.1803120405006387, 'Total loss': 0.1803120405006387}
2023-01-04 01:28:12,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:12,201 INFO:     Epoch: 94
2023-01-04 01:28:13,837 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4704910149176916, 'Total loss': 0.4704910149176916} | train loss {'Reaction outcome loss': 0.17941024191408597, 'Total loss': 0.17941024191408597}
2023-01-04 01:28:13,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:13,837 INFO:     Epoch: 95
2023-01-04 01:28:15,440 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45160228610038755, 'Total loss': 0.45160228610038755} | train loss {'Reaction outcome loss': 0.17890145659231538, 'Total loss': 0.17890145659231538}
2023-01-04 01:28:15,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:15,441 INFO:     Epoch: 96
2023-01-04 01:28:17,041 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44844442009925845, 'Total loss': 0.44844442009925845} | train loss {'Reaction outcome loss': 0.17775443906388128, 'Total loss': 0.17775443906388128}
2023-01-04 01:28:17,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:17,042 INFO:     Epoch: 97
2023-01-04 01:28:18,657 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4450421273708344, 'Total loss': 0.4450421273708344} | train loss {'Reaction outcome loss': 0.1746757754699633, 'Total loss': 0.1746757754699633}
2023-01-04 01:28:18,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:18,657 INFO:     Epoch: 98
2023-01-04 01:28:20,283 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.460060707728068, 'Total loss': 0.460060707728068} | train loss {'Reaction outcome loss': 0.17612250810253707, 'Total loss': 0.17612250810253707}
2023-01-04 01:28:20,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:20,284 INFO:     Epoch: 99
2023-01-04 01:28:21,911 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47148054937521616, 'Total loss': 0.47148054937521616} | train loss {'Reaction outcome loss': 0.1768423308776389, 'Total loss': 0.1768423308776389}
2023-01-04 01:28:21,911 INFO:     Best model found after epoch 23 of 100.
2023-01-04 01:28:21,912 INFO:   Done with stage: TRAINING
2023-01-04 01:28:21,912 INFO:   Starting stage: EVALUATION
2023-01-04 01:28:22,034 INFO:   Done with stage: EVALUATION
2023-01-04 01:28:22,034 INFO:   Leaving out SEQ value Fold_7
2023-01-04 01:28:22,047 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 01:28:22,047 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:28:22,692 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:28:22,692 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:28:22,760 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:28:22,760 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:28:22,760 INFO:     No hyperparam tuning for this model
2023-01-04 01:28:22,760 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:28:22,760 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:28:22,761 INFO:     None feature selector for col prot
2023-01-04 01:28:22,761 INFO:     None feature selector for col prot
2023-01-04 01:28:22,761 INFO:     None feature selector for col prot
2023-01-04 01:28:22,762 INFO:     None feature selector for col chem
2023-01-04 01:28:22,762 INFO:     None feature selector for col chem
2023-01-04 01:28:22,762 INFO:     None feature selector for col chem
2023-01-04 01:28:22,762 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:28:22,762 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:28:22,763 INFO:     Number of params in model 70141
2023-01-04 01:28:22,767 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:28:22,767 INFO:   Starting stage: TRAINING
2023-01-04 01:28:22,810 INFO:     Val loss before train {'Reaction outcome loss': 1.057417134443919, 'Total loss': 1.057417134443919}
2023-01-04 01:28:22,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:22,810 INFO:     Epoch: 0
2023-01-04 01:28:24,356 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7316546261310577, 'Total loss': 0.7316546261310577} | train loss {'Reaction outcome loss': 0.8416328860289884, 'Total loss': 0.8416328860289884}
2023-01-04 01:28:24,356 INFO:     Found new best model at epoch 0
2023-01-04 01:28:24,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:24,357 INFO:     Epoch: 1
2023-01-04 01:28:25,941 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5845864057540894, 'Total loss': 0.5845864057540894} | train loss {'Reaction outcome loss': 0.5994593672481648, 'Total loss': 0.5994593672481648}
2023-01-04 01:28:25,942 INFO:     Found new best model at epoch 1
2023-01-04 01:28:25,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:25,942 INFO:     Epoch: 2
2023-01-04 01:28:27,523 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5237469027439753, 'Total loss': 0.5237469027439753} | train loss {'Reaction outcome loss': 0.5156844940050181, 'Total loss': 0.5156844940050181}
2023-01-04 01:28:27,523 INFO:     Found new best model at epoch 2
2023-01-04 01:28:27,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:27,524 INFO:     Epoch: 3
2023-01-04 01:28:29,107 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5114153742790222, 'Total loss': 0.5114153742790222} | train loss {'Reaction outcome loss': 0.47216841660358094, 'Total loss': 0.47216841660358094}
2023-01-04 01:28:29,107 INFO:     Found new best model at epoch 3
2023-01-04 01:28:29,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:29,108 INFO:     Epoch: 4
2023-01-04 01:28:30,690 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5015539308389028, 'Total loss': 0.5015539308389028} | train loss {'Reaction outcome loss': 0.45114254907810647, 'Total loss': 0.45114254907810647}
2023-01-04 01:28:30,690 INFO:     Found new best model at epoch 4
2023-01-04 01:28:30,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:30,691 INFO:     Epoch: 5
2023-01-04 01:28:32,253 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.486219189564387, 'Total loss': 0.486219189564387} | train loss {'Reaction outcome loss': 0.434521204440585, 'Total loss': 0.434521204440585}
2023-01-04 01:28:32,254 INFO:     Found new best model at epoch 5
2023-01-04 01:28:32,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:32,255 INFO:     Epoch: 6
2023-01-04 01:28:33,820 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47814731001853944, 'Total loss': 0.47814731001853944} | train loss {'Reaction outcome loss': 0.418843619006894, 'Total loss': 0.418843619006894}
2023-01-04 01:28:33,820 INFO:     Found new best model at epoch 6
2023-01-04 01:28:33,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:33,821 INFO:     Epoch: 7
2023-01-04 01:28:35,408 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47028633058071134, 'Total loss': 0.47028633058071134} | train loss {'Reaction outcome loss': 0.40837560752372604, 'Total loss': 0.40837560752372604}
2023-01-04 01:28:35,408 INFO:     Found new best model at epoch 7
2023-01-04 01:28:35,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:35,409 INFO:     Epoch: 8
2023-01-04 01:28:37,002 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47095899979273476, 'Total loss': 0.47095899979273476} | train loss {'Reaction outcome loss': 0.39575951183453584, 'Total loss': 0.39575951183453584}
2023-01-04 01:28:37,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:37,003 INFO:     Epoch: 9
2023-01-04 01:28:38,606 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47858370741208395, 'Total loss': 0.47858370741208395} | train loss {'Reaction outcome loss': 0.3877076379709191, 'Total loss': 0.3877076379709191}
2023-01-04 01:28:38,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:38,607 INFO:     Epoch: 10
2023-01-04 01:28:40,210 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46516961256663003, 'Total loss': 0.46516961256663003} | train loss {'Reaction outcome loss': 0.3763153421463984, 'Total loss': 0.3763153421463984}
2023-01-04 01:28:40,210 INFO:     Found new best model at epoch 10
2023-01-04 01:28:40,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:40,211 INFO:     Epoch: 11
2023-01-04 01:28:41,776 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46166683236757916, 'Total loss': 0.46166683236757916} | train loss {'Reaction outcome loss': 0.37040248420430627, 'Total loss': 0.37040248420430627}
2023-01-04 01:28:41,776 INFO:     Found new best model at epoch 11
2023-01-04 01:28:41,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:41,777 INFO:     Epoch: 12
2023-01-04 01:28:43,380 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45750192006429036, 'Total loss': 0.45750192006429036} | train loss {'Reaction outcome loss': 0.36209491978744013, 'Total loss': 0.36209491978744013}
2023-01-04 01:28:43,380 INFO:     Found new best model at epoch 12
2023-01-04 01:28:43,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:43,381 INFO:     Epoch: 13
2023-01-04 01:28:44,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45850632786750795, 'Total loss': 0.45850632786750795} | train loss {'Reaction outcome loss': 0.3544421359187081, 'Total loss': 0.3544421359187081}
2023-01-04 01:28:44,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:44,957 INFO:     Epoch: 14
2023-01-04 01:28:46,559 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44648120999336244, 'Total loss': 0.44648120999336244} | train loss {'Reaction outcome loss': 0.34753378619859504, 'Total loss': 0.34753378619859504}
2023-01-04 01:28:46,559 INFO:     Found new best model at epoch 14
2023-01-04 01:28:46,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:46,560 INFO:     Epoch: 15
2023-01-04 01:28:48,166 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48392917911211647, 'Total loss': 0.48392917911211647} | train loss {'Reaction outcome loss': 0.340546065170468, 'Total loss': 0.340546065170468}
2023-01-04 01:28:48,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:48,166 INFO:     Epoch: 16
2023-01-04 01:28:49,783 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44839143455028535, 'Total loss': 0.44839143455028535} | train loss {'Reaction outcome loss': 0.3348953699072202, 'Total loss': 0.3348953699072202}
2023-01-04 01:28:49,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:49,783 INFO:     Epoch: 17
2023-01-04 01:28:51,334 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43954480191071826, 'Total loss': 0.43954480191071826} | train loss {'Reaction outcome loss': 0.3299943093524311, 'Total loss': 0.3299943093524311}
2023-01-04 01:28:51,334 INFO:     Found new best model at epoch 17
2023-01-04 01:28:51,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:51,335 INFO:     Epoch: 18
2023-01-04 01:28:52,917 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43224115868409474, 'Total loss': 0.43224115868409474} | train loss {'Reaction outcome loss': 0.3250981698924805, 'Total loss': 0.3250981698924805}
2023-01-04 01:28:52,917 INFO:     Found new best model at epoch 18
2023-01-04 01:28:52,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:52,918 INFO:     Epoch: 19
2023-01-04 01:28:54,499 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46239781777064004, 'Total loss': 0.46239781777064004} | train loss {'Reaction outcome loss': 0.3216384614616523, 'Total loss': 0.3216384614616523}
2023-01-04 01:28:54,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:54,499 INFO:     Epoch: 20
2023-01-04 01:28:56,079 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4452061553796132, 'Total loss': 0.4452061553796132} | train loss {'Reaction outcome loss': 0.3161018216648163, 'Total loss': 0.3161018216648163}
2023-01-04 01:28:56,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:56,081 INFO:     Epoch: 21
2023-01-04 01:28:57,662 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47120367487271625, 'Total loss': 0.47120367487271625} | train loss {'Reaction outcome loss': 0.31130270946484345, 'Total loss': 0.31130270946484345}
2023-01-04 01:28:57,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:57,662 INFO:     Epoch: 22
2023-01-04 01:28:59,225 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43177957932154337, 'Total loss': 0.43177957932154337} | train loss {'Reaction outcome loss': 0.3101373498529305, 'Total loss': 0.3101373498529305}
2023-01-04 01:28:59,225 INFO:     Found new best model at epoch 22
2023-01-04 01:28:59,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:28:59,226 INFO:     Epoch: 23
2023-01-04 01:29:00,778 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43992440899213153, 'Total loss': 0.43992440899213153} | train loss {'Reaction outcome loss': 0.3016475541278338, 'Total loss': 0.3016475541278338}
2023-01-04 01:29:00,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:00,778 INFO:     Epoch: 24
2023-01-04 01:29:02,385 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45960219502449035, 'Total loss': 0.45960219502449035} | train loss {'Reaction outcome loss': 0.2986503357524837, 'Total loss': 0.2986503357524837}
2023-01-04 01:29:02,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:02,386 INFO:     Epoch: 25
2023-01-04 01:29:03,952 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4515528609355291, 'Total loss': 0.4515528609355291} | train loss {'Reaction outcome loss': 0.2939023902237197, 'Total loss': 0.2939023902237197}
2023-01-04 01:29:03,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:03,952 INFO:     Epoch: 26
2023-01-04 01:29:05,560 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47038667897383374, 'Total loss': 0.47038667897383374} | train loss {'Reaction outcome loss': 0.29064913200480597, 'Total loss': 0.29064913200480597}
2023-01-04 01:29:05,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:05,560 INFO:     Epoch: 27
2023-01-04 01:29:07,166 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4573983917633692, 'Total loss': 0.4573983917633692} | train loss {'Reaction outcome loss': 0.29086934472178366, 'Total loss': 0.29086934472178366}
2023-01-04 01:29:07,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:07,166 INFO:     Epoch: 28
2023-01-04 01:29:08,709 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45531026224295296, 'Total loss': 0.45531026224295296} | train loss {'Reaction outcome loss': 0.2839297566139873, 'Total loss': 0.2839297566139873}
2023-01-04 01:29:08,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:08,710 INFO:     Epoch: 29
2023-01-04 01:29:10,315 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43742268880208335, 'Total loss': 0.43742268880208335} | train loss {'Reaction outcome loss': 0.28260872867845355, 'Total loss': 0.28260872867845355}
2023-01-04 01:29:10,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:10,316 INFO:     Epoch: 30
2023-01-04 01:29:11,903 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.437457616130511, 'Total loss': 0.437457616130511} | train loss {'Reaction outcome loss': 0.27715895002905705, 'Total loss': 0.27715895002905705}
2023-01-04 01:29:11,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:11,903 INFO:     Epoch: 31
2023-01-04 01:29:13,487 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4577071189880371, 'Total loss': 0.4577071189880371} | train loss {'Reaction outcome loss': 0.2747276417447097, 'Total loss': 0.2747276417447097}
2023-01-04 01:29:13,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:13,487 INFO:     Epoch: 32
2023-01-04 01:29:15,071 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4628086447715759, 'Total loss': 0.4628086447715759} | train loss {'Reaction outcome loss': 0.271524412045767, 'Total loss': 0.271524412045767}
2023-01-04 01:29:15,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:15,072 INFO:     Epoch: 33
2023-01-04 01:29:16,656 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43079090615113574, 'Total loss': 0.43079090615113574} | train loss {'Reaction outcome loss': 0.2712732324779252, 'Total loss': 0.2712732324779252}
2023-01-04 01:29:16,656 INFO:     Found new best model at epoch 33
2023-01-04 01:29:16,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:16,657 INFO:     Epoch: 34
2023-01-04 01:29:18,214 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4389642794926961, 'Total loss': 0.4389642794926961} | train loss {'Reaction outcome loss': 0.2654442562834247, 'Total loss': 0.2654442562834247}
2023-01-04 01:29:18,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:18,214 INFO:     Epoch: 35
2023-01-04 01:29:19,818 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42497652222712834, 'Total loss': 0.42497652222712834} | train loss {'Reaction outcome loss': 0.2609554691301597, 'Total loss': 0.2609554691301597}
2023-01-04 01:29:19,818 INFO:     Found new best model at epoch 35
2023-01-04 01:29:19,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:19,819 INFO:     Epoch: 36
2023-01-04 01:29:21,427 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43950590391953787, 'Total loss': 0.43950590391953787} | train loss {'Reaction outcome loss': 0.2586824750398105, 'Total loss': 0.2586824750398105}
2023-01-04 01:29:21,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:21,427 INFO:     Epoch: 37
2023-01-04 01:29:23,030 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4334031954407692, 'Total loss': 0.4334031954407692} | train loss {'Reaction outcome loss': 0.25863304802458803, 'Total loss': 0.25863304802458803}
2023-01-04 01:29:23,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:23,030 INFO:     Epoch: 38
2023-01-04 01:29:24,641 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45484434167544047, 'Total loss': 0.45484434167544047} | train loss {'Reaction outcome loss': 0.25366470021205945, 'Total loss': 0.25366470021205945}
2023-01-04 01:29:24,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:24,641 INFO:     Epoch: 39
2023-01-04 01:29:26,226 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4357219636440277, 'Total loss': 0.4357219636440277} | train loss {'Reaction outcome loss': 0.250936608816132, 'Total loss': 0.250936608816132}
2023-01-04 01:29:26,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:26,226 INFO:     Epoch: 40
2023-01-04 01:29:27,788 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45550669729709625, 'Total loss': 0.45550669729709625} | train loss {'Reaction outcome loss': 0.250103408900591, 'Total loss': 0.250103408900591}
2023-01-04 01:29:27,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:27,788 INFO:     Epoch: 41
2023-01-04 01:29:29,395 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4390596687793732, 'Total loss': 0.4390596687793732} | train loss {'Reaction outcome loss': 0.24551254167006567, 'Total loss': 0.24551254167006567}
2023-01-04 01:29:29,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:29,396 INFO:     Epoch: 42
2023-01-04 01:29:31,004 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44767448318501313, 'Total loss': 0.44767448318501313} | train loss {'Reaction outcome loss': 0.24664286388964443, 'Total loss': 0.24664286388964443}
2023-01-04 01:29:31,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:31,004 INFO:     Epoch: 43
2023-01-04 01:29:32,611 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4513726274172465, 'Total loss': 0.4513726274172465} | train loss {'Reaction outcome loss': 0.24197610698285557, 'Total loss': 0.24197610698285557}
2023-01-04 01:29:32,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:32,612 INFO:     Epoch: 44
2023-01-04 01:29:34,208 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.464796061317126, 'Total loss': 0.464796061317126} | train loss {'Reaction outcome loss': 0.23920424110614336, 'Total loss': 0.23920424110614336}
2023-01-04 01:29:34,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:34,209 INFO:     Epoch: 45
2023-01-04 01:29:35,765 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45819594065348307, 'Total loss': 0.45819594065348307} | train loss {'Reaction outcome loss': 0.23725017475394103, 'Total loss': 0.23725017475394103}
2023-01-04 01:29:35,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:35,765 INFO:     Epoch: 46
2023-01-04 01:29:37,351 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4770128558079402, 'Total loss': 0.4770128558079402} | train loss {'Reaction outcome loss': 0.2379660069696851, 'Total loss': 0.2379660069696851}
2023-01-04 01:29:37,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:37,351 INFO:     Epoch: 47
2023-01-04 01:29:38,924 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4619736065467199, 'Total loss': 0.4619736065467199} | train loss {'Reaction outcome loss': 0.2338873384718275, 'Total loss': 0.2338873384718275}
2023-01-04 01:29:38,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:38,925 INFO:     Epoch: 48
2023-01-04 01:29:40,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.457643461227417, 'Total loss': 0.457643461227417} | train loss {'Reaction outcome loss': 0.2316310859588913, 'Total loss': 0.2316310859588913}
2023-01-04 01:29:40,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:40,530 INFO:     Epoch: 49
2023-01-04 01:29:42,135 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4833469072977702, 'Total loss': 0.4833469072977702} | train loss {'Reaction outcome loss': 0.22948508837939183, 'Total loss': 0.22948508837939183}
2023-01-04 01:29:42,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:42,136 INFO:     Epoch: 50
2023-01-04 01:29:43,730 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47707926233609516, 'Total loss': 0.47707926233609516} | train loss {'Reaction outcome loss': 0.22709613801031323, 'Total loss': 0.22709613801031323}
2023-01-04 01:29:43,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:43,730 INFO:     Epoch: 51
2023-01-04 01:29:45,263 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4720484475294749, 'Total loss': 0.4720484475294749} | train loss {'Reaction outcome loss': 0.22674489086800878, 'Total loss': 0.22674489086800878}
2023-01-04 01:29:45,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:45,263 INFO:     Epoch: 52
2023-01-04 01:29:46,868 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4647985935211182, 'Total loss': 0.4647985935211182} | train loss {'Reaction outcome loss': 0.2251197466210568, 'Total loss': 0.2251197466210568}
2023-01-04 01:29:46,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:46,868 INFO:     Epoch: 53
2023-01-04 01:29:48,474 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45830721656481427, 'Total loss': 0.45830721656481427} | train loss {'Reaction outcome loss': 0.22297390670457604, 'Total loss': 0.22297390670457604}
2023-01-04 01:29:48,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:48,474 INFO:     Epoch: 54
2023-01-04 01:29:50,084 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46907775004704794, 'Total loss': 0.46907775004704794} | train loss {'Reaction outcome loss': 0.2220669695766363, 'Total loss': 0.2220669695766363}
2023-01-04 01:29:50,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:50,084 INFO:     Epoch: 55
2023-01-04 01:29:51,693 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.494523831208547, 'Total loss': 0.494523831208547} | train loss {'Reaction outcome loss': 0.2192881627233474, 'Total loss': 0.2192881627233474}
2023-01-04 01:29:51,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:51,694 INFO:     Epoch: 56
2023-01-04 01:29:53,264 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4665617605050405, 'Total loss': 0.4665617605050405} | train loss {'Reaction outcome loss': 0.21671639459255415, 'Total loss': 0.21671639459255415}
2023-01-04 01:29:53,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:53,264 INFO:     Epoch: 57
2023-01-04 01:29:54,832 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5174928536017736, 'Total loss': 0.5174928536017736} | train loss {'Reaction outcome loss': 0.22072008200290003, 'Total loss': 0.22072008200290003}
2023-01-04 01:29:54,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:54,832 INFO:     Epoch: 58
2023-01-04 01:29:56,417 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4814377357562383, 'Total loss': 0.4814377357562383} | train loss {'Reaction outcome loss': 0.2149635278261625, 'Total loss': 0.2149635278261625}
2023-01-04 01:29:56,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:56,417 INFO:     Epoch: 59
2023-01-04 01:29:58,000 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4936246688167254, 'Total loss': 0.4936246688167254} | train loss {'Reaction outcome loss': 0.21179417561698746, 'Total loss': 0.21179417561698746}
2023-01-04 01:29:58,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:58,001 INFO:     Epoch: 60
2023-01-04 01:29:59,580 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4602371712525686, 'Total loss': 0.4602371712525686} | train loss {'Reaction outcome loss': 0.21115138829300256, 'Total loss': 0.21115138829300256}
2023-01-04 01:29:59,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:29:59,581 INFO:     Epoch: 61
2023-01-04 01:30:01,161 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47340820034344994, 'Total loss': 0.47340820034344994} | train loss {'Reaction outcome loss': 0.21101466592933452, 'Total loss': 0.21101466592933452}
2023-01-04 01:30:01,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:01,161 INFO:     Epoch: 62
2023-01-04 01:30:02,705 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4860533316930135, 'Total loss': 0.4860533316930135} | train loss {'Reaction outcome loss': 0.20632131794815536, 'Total loss': 0.20632131794815536}
2023-01-04 01:30:02,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:02,706 INFO:     Epoch: 63
2023-01-04 01:30:04,282 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4910694400469462, 'Total loss': 0.4910694400469462} | train loss {'Reaction outcome loss': 0.20741132562195425, 'Total loss': 0.20741132562195425}
2023-01-04 01:30:04,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:04,282 INFO:     Epoch: 64
2023-01-04 01:30:05,863 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.504635214805603, 'Total loss': 0.504635214805603} | train loss {'Reaction outcome loss': 0.20473449956966844, 'Total loss': 0.20473449956966844}
2023-01-04 01:30:05,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:05,864 INFO:     Epoch: 65
2023-01-04 01:30:07,448 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4743443856636683, 'Total loss': 0.4743443856636683} | train loss {'Reaction outcome loss': 0.20543227427308158, 'Total loss': 0.20543227427308158}
2023-01-04 01:30:07,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:07,449 INFO:     Epoch: 66
2023-01-04 01:30:09,030 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4729995866616567, 'Total loss': 0.4729995866616567} | train loss {'Reaction outcome loss': 0.20221575484662266, 'Total loss': 0.20221575484662266}
2023-01-04 01:30:09,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:09,031 INFO:     Epoch: 67
2023-01-04 01:30:10,612 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4721003472805023, 'Total loss': 0.4721003472805023} | train loss {'Reaction outcome loss': 0.20486563347252734, 'Total loss': 0.20486563347252734}
2023-01-04 01:30:10,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:10,613 INFO:     Epoch: 68
2023-01-04 01:30:12,147 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47714483936627705, 'Total loss': 0.47714483936627705} | train loss {'Reaction outcome loss': 0.20312345510983204, 'Total loss': 0.20312345510983204}
2023-01-04 01:30:12,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:12,147 INFO:     Epoch: 69
2023-01-04 01:30:13,751 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.487657368183136, 'Total loss': 0.487657368183136} | train loss {'Reaction outcome loss': 0.19806083903098717, 'Total loss': 0.19806083903098717}
2023-01-04 01:30:13,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:13,751 INFO:     Epoch: 70
2023-01-04 01:30:15,347 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47876914540926613, 'Total loss': 0.47876914540926613} | train loss {'Reaction outcome loss': 0.1987968730388871, 'Total loss': 0.1987968730388871}
2023-01-04 01:30:15,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:15,347 INFO:     Epoch: 71
2023-01-04 01:30:16,951 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4669936756292979, 'Total loss': 0.4669936756292979} | train loss {'Reaction outcome loss': 0.19744912084642346, 'Total loss': 0.19744912084642346}
2023-01-04 01:30:16,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:16,951 INFO:     Epoch: 72
2023-01-04 01:30:18,560 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5156044085820516, 'Total loss': 0.5156044085820516} | train loss {'Reaction outcome loss': 0.19808643124997616, 'Total loss': 0.19808643124997616}
2023-01-04 01:30:18,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:18,560 INFO:     Epoch: 73
2023-01-04 01:30:20,151 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4893390774726868, 'Total loss': 0.4893390774726868} | train loss {'Reaction outcome loss': 0.19328515245255096, 'Total loss': 0.19328515245255096}
2023-01-04 01:30:20,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:20,151 INFO:     Epoch: 74
2023-01-04 01:30:21,732 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4908319373925527, 'Total loss': 0.4908319373925527} | train loss {'Reaction outcome loss': 0.19476501135353422, 'Total loss': 0.19476501135353422}
2023-01-04 01:30:21,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:21,733 INFO:     Epoch: 75
2023-01-04 01:30:23,359 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.51708704829216, 'Total loss': 0.51708704829216} | train loss {'Reaction outcome loss': 0.19643686654817163, 'Total loss': 0.19643686654817163}
2023-01-04 01:30:23,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:23,359 INFO:     Epoch: 76
2023-01-04 01:30:24,990 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48055145839850105, 'Total loss': 0.48055145839850105} | train loss {'Reaction outcome loss': 0.1918722957563706, 'Total loss': 0.1918722957563706}
2023-01-04 01:30:24,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:24,990 INFO:     Epoch: 77
2023-01-04 01:30:26,601 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47893973290920255, 'Total loss': 0.47893973290920255} | train loss {'Reaction outcome loss': 0.19313083969793476, 'Total loss': 0.19313083969793476}
2023-01-04 01:30:26,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:26,601 INFO:     Epoch: 78
2023-01-04 01:30:28,192 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5064608891805013, 'Total loss': 0.5064608891805013} | train loss {'Reaction outcome loss': 0.19086441473400856, 'Total loss': 0.19086441473400856}
2023-01-04 01:30:28,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:28,192 INFO:     Epoch: 79
2023-01-04 01:30:29,756 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48773911396662395, 'Total loss': 0.48773911396662395} | train loss {'Reaction outcome loss': 0.18934004442022614, 'Total loss': 0.18934004442022614}
2023-01-04 01:30:29,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:29,756 INFO:     Epoch: 80
2023-01-04 01:30:31,350 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48264248073101046, 'Total loss': 0.48264248073101046} | train loss {'Reaction outcome loss': 0.19111153759035, 'Total loss': 0.19111153759035}
2023-01-04 01:30:31,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:31,350 INFO:     Epoch: 81
2023-01-04 01:30:32,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4922028670708338, 'Total loss': 0.4922028670708338} | train loss {'Reaction outcome loss': 0.1868066286494198, 'Total loss': 0.1868066286494198}
2023-01-04 01:30:32,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:32,961 INFO:     Epoch: 82
2023-01-04 01:30:34,567 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5235578219095866, 'Total loss': 0.5235578219095866} | train loss {'Reaction outcome loss': 0.18346879015857484, 'Total loss': 0.18346879015857484}
2023-01-04 01:30:34,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:34,567 INFO:     Epoch: 83
2023-01-04 01:30:36,173 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48554187417030337, 'Total loss': 0.48554187417030337} | train loss {'Reaction outcome loss': 0.1854050334529344, 'Total loss': 0.1854050334529344}
2023-01-04 01:30:36,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:36,173 INFO:     Epoch: 84
2023-01-04 01:30:37,782 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.488635398944219, 'Total loss': 0.488635398944219} | train loss {'Reaction outcome loss': 0.18336030019399446, 'Total loss': 0.18336030019399446}
2023-01-04 01:30:37,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:37,782 INFO:     Epoch: 85
2023-01-04 01:30:39,330 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5127288381258647, 'Total loss': 0.5127288381258647} | train loss {'Reaction outcome loss': 0.18365734493685715, 'Total loss': 0.18365734493685715}
2023-01-04 01:30:39,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:39,331 INFO:     Epoch: 86
2023-01-04 01:30:40,914 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5158040920893351, 'Total loss': 0.5158040920893351} | train loss {'Reaction outcome loss': 0.18144285381386133, 'Total loss': 0.18144285381386133}
2023-01-04 01:30:40,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:40,914 INFO:     Epoch: 87
2023-01-04 01:30:42,528 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5307091176509857, 'Total loss': 0.5307091176509857} | train loss {'Reaction outcome loss': 0.18243845898125852, 'Total loss': 0.18243845898125852}
2023-01-04 01:30:42,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:42,528 INFO:     Epoch: 88
2023-01-04 01:30:44,133 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48401839633782706, 'Total loss': 0.48401839633782706} | train loss {'Reaction outcome loss': 0.18195075488516263, 'Total loss': 0.18195075488516263}
2023-01-04 01:30:44,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:44,133 INFO:     Epoch: 89
2023-01-04 01:30:45,740 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4958513855934143, 'Total loss': 0.4958513855934143} | train loss {'Reaction outcome loss': 0.18181651376269675, 'Total loss': 0.18181651376269675}
2023-01-04 01:30:45,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:45,741 INFO:     Epoch: 90
2023-01-04 01:30:47,314 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5075074513753255, 'Total loss': 0.5075074513753255} | train loss {'Reaction outcome loss': 0.17923056159079784, 'Total loss': 0.17923056159079784}
2023-01-04 01:30:47,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:47,314 INFO:     Epoch: 91
2023-01-04 01:30:48,875 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5273369471232097, 'Total loss': 0.5273369471232097} | train loss {'Reaction outcome loss': 0.17797401385047498, 'Total loss': 0.17797401385047498}
2023-01-04 01:30:48,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:48,875 INFO:     Epoch: 92
2023-01-04 01:30:50,485 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49398935039838154, 'Total loss': 0.49398935039838154} | train loss {'Reaction outcome loss': 0.17906339621451092, 'Total loss': 0.17906339621451092}
2023-01-04 01:30:50,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:50,485 INFO:     Epoch: 93
2023-01-04 01:30:52,094 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4931846340497335, 'Total loss': 0.4931846340497335} | train loss {'Reaction outcome loss': 0.1781705675353279, 'Total loss': 0.1781705675353279}
2023-01-04 01:30:52,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:52,095 INFO:     Epoch: 94
2023-01-04 01:30:53,701 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4999619642893473, 'Total loss': 0.4999619642893473} | train loss {'Reaction outcome loss': 0.17962241216456934, 'Total loss': 0.17962241216456934}
2023-01-04 01:30:53,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:53,701 INFO:     Epoch: 95
2023-01-04 01:30:55,289 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49863976836204527, 'Total loss': 0.49863976836204527} | train loss {'Reaction outcome loss': 0.17863692778534504, 'Total loss': 0.17863692778534504}
2023-01-04 01:30:55,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:55,289 INFO:     Epoch: 96
2023-01-04 01:30:56,831 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4861178709504505, 'Total loss': 0.4861178709504505} | train loss {'Reaction outcome loss': 0.17671440697305804, 'Total loss': 0.17671440697305804}
2023-01-04 01:30:56,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:56,831 INFO:     Epoch: 97
2023-01-04 01:30:58,439 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4927368183930715, 'Total loss': 0.4927368183930715} | train loss {'Reaction outcome loss': 0.17670141625808272, 'Total loss': 0.17670141625808272}
2023-01-04 01:30:58,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:30:58,440 INFO:     Epoch: 98
2023-01-04 01:31:00,046 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5216549038887024, 'Total loss': 0.5216549038887024} | train loss {'Reaction outcome loss': 0.17420571838461218, 'Total loss': 0.17420571838461218}
2023-01-04 01:31:00,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:00,046 INFO:     Epoch: 99
2023-01-04 01:31:01,649 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49915419419606527, 'Total loss': 0.49915419419606527} | train loss {'Reaction outcome loss': 0.17657251549618586, 'Total loss': 0.17657251549618586}
2023-01-04 01:31:01,649 INFO:     Best model found after epoch 36 of 100.
2023-01-04 01:31:01,649 INFO:   Done with stage: TRAINING
2023-01-04 01:31:01,649 INFO:   Starting stage: EVALUATION
2023-01-04 01:31:01,790 INFO:   Done with stage: EVALUATION
2023-01-04 01:31:01,790 INFO:   Leaving out SEQ value Fold_8
2023-01-04 01:31:01,802 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:31:01,802 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:31:02,449 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:31:02,449 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:31:02,518 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:31:02,518 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:31:02,518 INFO:     No hyperparam tuning for this model
2023-01-04 01:31:02,518 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:31:02,518 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:31:02,519 INFO:     None feature selector for col prot
2023-01-04 01:31:02,519 INFO:     None feature selector for col prot
2023-01-04 01:31:02,519 INFO:     None feature selector for col prot
2023-01-04 01:31:02,520 INFO:     None feature selector for col chem
2023-01-04 01:31:02,520 INFO:     None feature selector for col chem
2023-01-04 01:31:02,520 INFO:     None feature selector for col chem
2023-01-04 01:31:02,520 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:31:02,520 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:31:02,521 INFO:     Number of params in model 70141
2023-01-04 01:31:02,524 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:31:02,524 INFO:   Starting stage: TRAINING
2023-01-04 01:31:02,567 INFO:     Val loss before train {'Reaction outcome loss': 0.9674972613652547, 'Total loss': 0.9674972613652547}
2023-01-04 01:31:02,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:02,567 INFO:     Epoch: 0
2023-01-04 01:31:04,168 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6230936924616496, 'Total loss': 0.6230936924616496} | train loss {'Reaction outcome loss': 0.8483536773752691, 'Total loss': 0.8483536773752691}
2023-01-04 01:31:04,168 INFO:     Found new best model at epoch 0
2023-01-04 01:31:04,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:04,169 INFO:     Epoch: 1
2023-01-04 01:31:05,741 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5292027632395426, 'Total loss': 0.5292027632395426} | train loss {'Reaction outcome loss': 0.5972144384665982, 'Total loss': 0.5972144384665982}
2023-01-04 01:31:05,741 INFO:     Found new best model at epoch 1
2023-01-04 01:31:05,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:05,742 INFO:     Epoch: 2
2023-01-04 01:31:07,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5004568129777909, 'Total loss': 0.5004568129777909} | train loss {'Reaction outcome loss': 0.5269413209263829, 'Total loss': 0.5269413209263829}
2023-01-04 01:31:07,341 INFO:     Found new best model at epoch 2
2023-01-04 01:31:07,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:07,342 INFO:     Epoch: 3
2023-01-04 01:31:08,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4774234056472778, 'Total loss': 0.4774234056472778} | train loss {'Reaction outcome loss': 0.49093346971262625, 'Total loss': 0.49093346971262625}
2023-01-04 01:31:08,952 INFO:     Found new best model at epoch 3
2023-01-04 01:31:08,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:08,953 INFO:     Epoch: 4
2023-01-04 01:31:10,568 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4659091174602509, 'Total loss': 0.4659091174602509} | train loss {'Reaction outcome loss': 0.4630320366418016, 'Total loss': 0.4630320366418016}
2023-01-04 01:31:10,568 INFO:     Found new best model at epoch 4
2023-01-04 01:31:10,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:10,569 INFO:     Epoch: 5
2023-01-04 01:31:12,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4497950812180837, 'Total loss': 0.4497950812180837} | train loss {'Reaction outcome loss': 0.44157866657833045, 'Total loss': 0.44157866657833045}
2023-01-04 01:31:12,184 INFO:     Found new best model at epoch 5
2023-01-04 01:31:12,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:12,185 INFO:     Epoch: 6
2023-01-04 01:31:13,798 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4434883753458659, 'Total loss': 0.4434883753458659} | train loss {'Reaction outcome loss': 0.4259125638611453, 'Total loss': 0.4259125638611453}
2023-01-04 01:31:13,798 INFO:     Found new best model at epoch 6
2023-01-04 01:31:13,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:13,799 INFO:     Epoch: 7
2023-01-04 01:31:15,374 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43773352007071176, 'Total loss': 0.43773352007071176} | train loss {'Reaction outcome loss': 0.4346382803405109, 'Total loss': 0.4346382803405109}
2023-01-04 01:31:15,376 INFO:     Found new best model at epoch 7
2023-01-04 01:31:15,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:15,376 INFO:     Epoch: 8
2023-01-04 01:31:16,985 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41688315371672313, 'Total loss': 0.41688315371672313} | train loss {'Reaction outcome loss': 0.40379063841427904, 'Total loss': 0.40379063841427904}
2023-01-04 01:31:16,985 INFO:     Found new best model at epoch 8
2023-01-04 01:31:16,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:16,986 INFO:     Epoch: 9
2023-01-04 01:31:18,607 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4411005139350891, 'Total loss': 0.4411005139350891} | train loss {'Reaction outcome loss': 0.39295791224509047, 'Total loss': 0.39295791224509047}
2023-01-04 01:31:18,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:18,607 INFO:     Epoch: 10
2023-01-04 01:31:20,220 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41976659893989565, 'Total loss': 0.41976659893989565} | train loss {'Reaction outcome loss': 0.3844132331036288, 'Total loss': 0.3844132331036288}
2023-01-04 01:31:20,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:20,220 INFO:     Epoch: 11
2023-01-04 01:31:21,830 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.414009815454483, 'Total loss': 0.414009815454483} | train loss {'Reaction outcome loss': 0.37609495052500913, 'Total loss': 0.37609495052500913}
2023-01-04 01:31:21,831 INFO:     Found new best model at epoch 11
2023-01-04 01:31:21,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:21,832 INFO:     Epoch: 12
2023-01-04 01:31:23,394 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4176236778497696, 'Total loss': 0.4176236778497696} | train loss {'Reaction outcome loss': 0.367391146334779, 'Total loss': 0.367391146334779}
2023-01-04 01:31:23,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:23,395 INFO:     Epoch: 13
2023-01-04 01:31:25,015 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4034888515869776, 'Total loss': 0.4034888515869776} | train loss {'Reaction outcome loss': 0.3781365839143594, 'Total loss': 0.3781365839143594}
2023-01-04 01:31:25,015 INFO:     Found new best model at epoch 13
2023-01-04 01:31:25,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:25,016 INFO:     Epoch: 14
2023-01-04 01:31:26,629 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4116300125916799, 'Total loss': 0.4116300125916799} | train loss {'Reaction outcome loss': 0.36428169651712844, 'Total loss': 0.36428169651712844}
2023-01-04 01:31:26,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:26,629 INFO:     Epoch: 15
2023-01-04 01:31:28,245 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4036715547243754, 'Total loss': 0.4036715547243754} | train loss {'Reaction outcome loss': 0.35605660645102244, 'Total loss': 0.35605660645102244}
2023-01-04 01:31:28,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:28,246 INFO:     Epoch: 16
2023-01-04 01:31:29,867 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41230687300364177, 'Total loss': 0.41230687300364177} | train loss {'Reaction outcome loss': 0.3508934672884778, 'Total loss': 0.3508934672884778}
2023-01-04 01:31:29,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:29,867 INFO:     Epoch: 17
2023-01-04 01:31:31,488 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4069206347068151, 'Total loss': 0.4069206347068151} | train loss {'Reaction outcome loss': 0.33823012856537127, 'Total loss': 0.33823012856537127}
2023-01-04 01:31:31,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:31,489 INFO:     Epoch: 18
2023-01-04 01:31:33,053 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39388537406921387, 'Total loss': 0.39388537406921387} | train loss {'Reaction outcome loss': 0.3310224402938848, 'Total loss': 0.3310224402938848}
2023-01-04 01:31:33,053 INFO:     Found new best model at epoch 18
2023-01-04 01:31:33,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:33,054 INFO:     Epoch: 19
2023-01-04 01:31:34,671 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3900597875316938, 'Total loss': 0.3900597875316938} | train loss {'Reaction outcome loss': 0.32790484418417665, 'Total loss': 0.32790484418417665}
2023-01-04 01:31:34,671 INFO:     Found new best model at epoch 19
2023-01-04 01:31:34,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:34,672 INFO:     Epoch: 20
2023-01-04 01:31:36,291 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4090241511662801, 'Total loss': 0.4090241511662801} | train loss {'Reaction outcome loss': 0.3287743373193603, 'Total loss': 0.3287743373193603}
2023-01-04 01:31:36,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:36,291 INFO:     Epoch: 21
2023-01-04 01:31:37,914 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38811270942290627, 'Total loss': 0.38811270942290627} | train loss {'Reaction outcome loss': 0.31911348604151735, 'Total loss': 0.31911348604151735}
2023-01-04 01:31:37,914 INFO:     Found new best model at epoch 21
2023-01-04 01:31:37,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:37,915 INFO:     Epoch: 22
2023-01-04 01:31:39,528 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4067175567150116, 'Total loss': 0.4067175567150116} | train loss {'Reaction outcome loss': 0.30976780050474667, 'Total loss': 0.30976780050474667}
2023-01-04 01:31:39,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:39,528 INFO:     Epoch: 23
2023-01-04 01:31:41,108 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37958227743705114, 'Total loss': 0.37958227743705114} | train loss {'Reaction outcome loss': 0.3060149179933512, 'Total loss': 0.3060149179933512}
2023-01-04 01:31:41,108 INFO:     Found new best model at epoch 23
2023-01-04 01:31:41,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:41,109 INFO:     Epoch: 24
2023-01-04 01:31:42,690 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4078890452782313, 'Total loss': 0.4078890452782313} | train loss {'Reaction outcome loss': 0.299954937197322, 'Total loss': 0.299954937197322}
2023-01-04 01:31:42,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:42,690 INFO:     Epoch: 25
2023-01-04 01:31:44,289 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3933933089176814, 'Total loss': 0.3933933089176814} | train loss {'Reaction outcome loss': 0.2951370435606594, 'Total loss': 0.2951370435606594}
2023-01-04 01:31:44,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:44,290 INFO:     Epoch: 26
2023-01-04 01:31:45,888 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39850297768910725, 'Total loss': 0.39850297768910725} | train loss {'Reaction outcome loss': 0.28871025942625356, 'Total loss': 0.28871025942625356}
2023-01-04 01:31:45,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:45,888 INFO:     Epoch: 27
2023-01-04 01:31:47,509 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3894587198893229, 'Total loss': 0.3894587198893229} | train loss {'Reaction outcome loss': 0.28565896797100204, 'Total loss': 0.28565896797100204}
2023-01-04 01:31:47,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:47,509 INFO:     Epoch: 28
2023-01-04 01:31:49,127 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3941539506117503, 'Total loss': 0.3941539506117503} | train loss {'Reaction outcome loss': 0.2801512994034135, 'Total loss': 0.2801512994034135}
2023-01-04 01:31:49,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:49,128 INFO:     Epoch: 29
2023-01-04 01:31:50,698 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37983646790186565, 'Total loss': 0.37983646790186565} | train loss {'Reaction outcome loss': 0.2756320850451241, 'Total loss': 0.2756320850451241}
2023-01-04 01:31:50,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:50,699 INFO:     Epoch: 30
2023-01-04 01:31:52,287 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38711277494827906, 'Total loss': 0.38711277494827906} | train loss {'Reaction outcome loss': 0.2723813744302353, 'Total loss': 0.2723813744302353}
2023-01-04 01:31:52,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:52,287 INFO:     Epoch: 31
2023-01-04 01:31:53,908 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3992488900820414, 'Total loss': 0.3992488900820414} | train loss {'Reaction outcome loss': 0.2730688515348711, 'Total loss': 0.2730688515348711}
2023-01-04 01:31:53,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:53,908 INFO:     Epoch: 32
2023-01-04 01:31:55,530 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39229926268259685, 'Total loss': 0.39229926268259685} | train loss {'Reaction outcome loss': 0.27753262767109316, 'Total loss': 0.27753262767109316}
2023-01-04 01:31:55,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:55,530 INFO:     Epoch: 33
2023-01-04 01:31:57,130 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3682554642359416, 'Total loss': 0.3682554642359416} | train loss {'Reaction outcome loss': 0.2670065384048465, 'Total loss': 0.2670065384048465}
2023-01-04 01:31:57,131 INFO:     Found new best model at epoch 33
2023-01-04 01:31:57,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:57,132 INFO:     Epoch: 34
2023-01-04 01:31:58,730 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37769402712583544, 'Total loss': 0.37769402712583544} | train loss {'Reaction outcome loss': 0.2599714337240743, 'Total loss': 0.2599714337240743}
2023-01-04 01:31:58,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:31:58,730 INFO:     Epoch: 35
2023-01-04 01:32:00,294 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3816258574525515, 'Total loss': 0.3816258574525515} | train loss {'Reaction outcome loss': 0.2610127960202669, 'Total loss': 0.2610127960202669}
2023-01-04 01:32:00,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:00,294 INFO:     Epoch: 36
2023-01-04 01:32:01,889 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39540829261144, 'Total loss': 0.39540829261144} | train loss {'Reaction outcome loss': 0.2725058835863635, 'Total loss': 0.2725058835863635}
2023-01-04 01:32:01,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:01,889 INFO:     Epoch: 37
2023-01-04 01:32:03,480 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41452333132425945, 'Total loss': 0.41452333132425945} | train loss {'Reaction outcome loss': 0.2719079585125049, 'Total loss': 0.2719079585125049}
2023-01-04 01:32:03,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:03,481 INFO:     Epoch: 38
2023-01-04 01:32:05,103 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38955364127953845, 'Total loss': 0.38955364127953845} | train loss {'Reaction outcome loss': 0.2635815485348534, 'Total loss': 0.2635815485348534}
2023-01-04 01:32:05,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:05,104 INFO:     Epoch: 39
2023-01-04 01:32:06,722 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38420518338680265, 'Total loss': 0.38420518338680265} | train loss {'Reaction outcome loss': 0.24261617286643689, 'Total loss': 0.24261617286643689}
2023-01-04 01:32:06,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:06,722 INFO:     Epoch: 40
2023-01-04 01:32:08,306 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3928213357925415, 'Total loss': 0.3928213357925415} | train loss {'Reaction outcome loss': 0.26349377480969915, 'Total loss': 0.26349377480969915}
2023-01-04 01:32:08,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:08,306 INFO:     Epoch: 41
2023-01-04 01:32:09,917 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37774066676696144, 'Total loss': 0.37774066676696144} | train loss {'Reaction outcome loss': 0.2427851814260804, 'Total loss': 0.2427851814260804}
2023-01-04 01:32:09,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:09,918 INFO:     Epoch: 42
2023-01-04 01:32:11,504 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4086524297793706, 'Total loss': 0.4086524297793706} | train loss {'Reaction outcome loss': 0.2475789688743543, 'Total loss': 0.2475789688743543}
2023-01-04 01:32:11,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:11,505 INFO:     Epoch: 43
2023-01-04 01:32:13,091 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42132595578829446, 'Total loss': 0.42132595578829446} | train loss {'Reaction outcome loss': 0.24902460745711258, 'Total loss': 0.24902460745711258}
2023-01-04 01:32:13,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:13,091 INFO:     Epoch: 44
2023-01-04 01:32:14,696 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38973639607429506, 'Total loss': 0.38973639607429506} | train loss {'Reaction outcome loss': 0.23243847180940752, 'Total loss': 0.23243847180940752}
2023-01-04 01:32:14,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:14,696 INFO:     Epoch: 45
2023-01-04 01:32:16,324 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40100675225257876, 'Total loss': 0.40100675225257876} | train loss {'Reaction outcome loss': 0.2282652656169797, 'Total loss': 0.2282652656169797}
2023-01-04 01:32:16,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:16,324 INFO:     Epoch: 46
2023-01-04 01:32:17,889 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3835326492786407, 'Total loss': 0.3835326492786407} | train loss {'Reaction outcome loss': 0.22942563466241825, 'Total loss': 0.22942563466241825}
2023-01-04 01:32:17,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:17,890 INFO:     Epoch: 47
2023-01-04 01:32:19,491 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3955898324648539, 'Total loss': 0.3955898324648539} | train loss {'Reaction outcome loss': 0.22740238568550683, 'Total loss': 0.22740238568550683}
2023-01-04 01:32:19,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:19,492 INFO:     Epoch: 48
2023-01-04 01:32:21,091 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4181511024634043, 'Total loss': 0.4181511024634043} | train loss {'Reaction outcome loss': 0.22507652562057626, 'Total loss': 0.22507652562057626}
2023-01-04 01:32:21,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:21,092 INFO:     Epoch: 49
2023-01-04 01:32:22,694 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3929625928401947, 'Total loss': 0.3929625928401947} | train loss {'Reaction outcome loss': 0.22050182106634736, 'Total loss': 0.22050182106634736}
2023-01-04 01:32:22,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:22,694 INFO:     Epoch: 50
2023-01-04 01:32:24,318 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39341457883516945, 'Total loss': 0.39341457883516945} | train loss {'Reaction outcome loss': 0.21640868669716007, 'Total loss': 0.21640868669716007}
2023-01-04 01:32:24,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:24,318 INFO:     Epoch: 51
2023-01-04 01:32:25,924 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4103092690308889, 'Total loss': 0.4103092690308889} | train loss {'Reaction outcome loss': 0.21660039437067125, 'Total loss': 0.21660039437067125}
2023-01-04 01:32:25,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:25,924 INFO:     Epoch: 52
2023-01-04 01:32:27,499 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4017634292443593, 'Total loss': 0.4017634292443593} | train loss {'Reaction outcome loss': 0.21445594966138268, 'Total loss': 0.21445594966138268}
2023-01-04 01:32:27,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:27,500 INFO:     Epoch: 53
2023-01-04 01:32:29,101 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3862222760915756, 'Total loss': 0.3862222760915756} | train loss {'Reaction outcome loss': 0.2206545930787705, 'Total loss': 0.2206545930787705}
2023-01-04 01:32:29,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:29,101 INFO:     Epoch: 54
2023-01-04 01:32:30,701 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3897514412800471, 'Total loss': 0.3897514412800471} | train loss {'Reaction outcome loss': 0.22302774367146438, 'Total loss': 0.22302774367146438}
2023-01-04 01:32:30,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:30,702 INFO:     Epoch: 55
2023-01-04 01:32:32,303 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3936434328556061, 'Total loss': 0.3936434328556061} | train loss {'Reaction outcome loss': 0.21150740192177286, 'Total loss': 0.21150740192177286}
2023-01-04 01:32:32,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:32,303 INFO:     Epoch: 56
2023-01-04 01:32:33,904 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3907584215203921, 'Total loss': 0.3907584215203921} | train loss {'Reaction outcome loss': 0.21019104946458686, 'Total loss': 0.21019104946458686}
2023-01-04 01:32:33,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:33,905 INFO:     Epoch: 57
2023-01-04 01:32:35,465 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4096346884965897, 'Total loss': 0.4096346884965897} | train loss {'Reaction outcome loss': 0.20813251860575596, 'Total loss': 0.20813251860575596}
2023-01-04 01:32:35,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:35,466 INFO:     Epoch: 58
2023-01-04 01:32:37,066 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37563479095697405, 'Total loss': 0.37563479095697405} | train loss {'Reaction outcome loss': 0.2047954188585894, 'Total loss': 0.2047954188585894}
2023-01-04 01:32:37,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:37,066 INFO:     Epoch: 59
2023-01-04 01:32:38,667 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40232634643713633, 'Total loss': 0.40232634643713633} | train loss {'Reaction outcome loss': 0.20403662718751508, 'Total loss': 0.20403662718751508}
2023-01-04 01:32:38,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:38,667 INFO:     Epoch: 60
2023-01-04 01:32:40,268 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4107099215189616, 'Total loss': 0.4107099215189616} | train loss {'Reaction outcome loss': 0.2022195933816914, 'Total loss': 0.2022195933816914}
2023-01-04 01:32:40,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:40,269 INFO:     Epoch: 61
2023-01-04 01:32:41,869 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3883634120225906, 'Total loss': 0.3883634120225906} | train loss {'Reaction outcome loss': 0.20223787581861857, 'Total loss': 0.20223787581861857}
2023-01-04 01:32:41,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:41,869 INFO:     Epoch: 62
2023-01-04 01:32:43,469 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4309268822272619, 'Total loss': 0.4309268822272619} | train loss {'Reaction outcome loss': 0.20818029394022364, 'Total loss': 0.20818029394022364}
2023-01-04 01:32:43,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:43,469 INFO:     Epoch: 63
2023-01-04 01:32:45,043 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40385938485463463, 'Total loss': 0.40385938485463463} | train loss {'Reaction outcome loss': 0.21660760140208446, 'Total loss': 0.21660760140208446}
2023-01-04 01:32:45,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:45,043 INFO:     Epoch: 64
2023-01-04 01:32:46,636 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41030986309051515, 'Total loss': 0.41030986309051515} | train loss {'Reaction outcome loss': 0.19709266510967544, 'Total loss': 0.19709266510967544}
2023-01-04 01:32:46,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:46,636 INFO:     Epoch: 65
2023-01-04 01:32:48,266 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40839159935712815, 'Total loss': 0.40839159935712815} | train loss {'Reaction outcome loss': 0.19440152260569343, 'Total loss': 0.19440152260569343}
2023-01-04 01:32:48,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:48,266 INFO:     Epoch: 66
2023-01-04 01:32:49,902 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4197110871473948, 'Total loss': 0.4197110871473948} | train loss {'Reaction outcome loss': 0.197441830911186, 'Total loss': 0.197441830911186}
2023-01-04 01:32:49,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:49,903 INFO:     Epoch: 67
2023-01-04 01:32:51,525 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3827643641581138, 'Total loss': 0.3827643641581138} | train loss {'Reaction outcome loss': 0.19306857276925535, 'Total loss': 0.19306857276925535}
2023-01-04 01:32:51,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:51,526 INFO:     Epoch: 68
2023-01-04 01:32:53,124 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4276832967996597, 'Total loss': 0.4276832967996597} | train loss {'Reaction outcome loss': 0.1918503680019479, 'Total loss': 0.1918503680019479}
2023-01-04 01:32:53,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:53,125 INFO:     Epoch: 69
2023-01-04 01:32:54,699 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38638087759415307, 'Total loss': 0.38638087759415307} | train loss {'Reaction outcome loss': 0.19484023825413938, 'Total loss': 0.19484023825413938}
2023-01-04 01:32:54,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:54,700 INFO:     Epoch: 70
2023-01-04 01:32:56,322 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3950710266828537, 'Total loss': 0.3950710266828537} | train loss {'Reaction outcome loss': 0.19799667970020918, 'Total loss': 0.19799667970020918}
2023-01-04 01:32:56,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:56,322 INFO:     Epoch: 71
2023-01-04 01:32:57,936 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40227153301239016, 'Total loss': 0.40227153301239016} | train loss {'Reaction outcome loss': 0.18648827203930746, 'Total loss': 0.18648827203930746}
2023-01-04 01:32:57,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:57,937 INFO:     Epoch: 72
2023-01-04 01:32:59,558 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39755626519521076, 'Total loss': 0.39755626519521076} | train loss {'Reaction outcome loss': 0.18912074526702202, 'Total loss': 0.18912074526702202}
2023-01-04 01:32:59,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:32:59,559 INFO:     Epoch: 73
2023-01-04 01:33:01,165 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38345619986454643, 'Total loss': 0.38345619986454643} | train loss {'Reaction outcome loss': 0.18857127496891696, 'Total loss': 0.18857127496891696}
2023-01-04 01:33:01,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:01,166 INFO:     Epoch: 74
2023-01-04 01:33:02,739 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41125943859418235, 'Total loss': 0.41125943859418235} | train loss {'Reaction outcome loss': 0.188151311284552, 'Total loss': 0.188151311284552}
2023-01-04 01:33:02,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:02,739 INFO:     Epoch: 75
2023-01-04 01:33:04,338 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4030586396654447, 'Total loss': 0.4030586396654447} | train loss {'Reaction outcome loss': 0.18723997238861478, 'Total loss': 0.18723997238861478}
2023-01-04 01:33:04,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:04,338 INFO:     Epoch: 76
2023-01-04 01:33:05,952 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41077030400435127, 'Total loss': 0.41077030400435127} | train loss {'Reaction outcome loss': 0.18750402129565677, 'Total loss': 0.18750402129565677}
2023-01-04 01:33:05,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:05,952 INFO:     Epoch: 77
2023-01-04 01:33:07,579 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4339387118816376, 'Total loss': 0.4339387118816376} | train loss {'Reaction outcome loss': 0.17964232107455694, 'Total loss': 0.17964232107455694}
2023-01-04 01:33:07,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:07,579 INFO:     Epoch: 78
2023-01-04 01:33:09,205 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4018483693401019, 'Total loss': 0.4018483693401019} | train loss {'Reaction outcome loss': 0.1781365737035125, 'Total loss': 0.1781365737035125}
2023-01-04 01:33:09,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:09,206 INFO:     Epoch: 79
2023-01-04 01:33:10,809 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39789497752984365, 'Total loss': 0.39789497752984365} | train loss {'Reaction outcome loss': 0.18318302754145724, 'Total loss': 0.18318302754145724}
2023-01-04 01:33:10,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:10,809 INFO:     Epoch: 80
2023-01-04 01:33:12,381 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41514612634976705, 'Total loss': 0.41514612634976705} | train loss {'Reaction outcome loss': 0.17996384142695562, 'Total loss': 0.17996384142695562}
2023-01-04 01:33:12,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:12,382 INFO:     Epoch: 81
2023-01-04 01:33:13,980 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41687224606672924, 'Total loss': 0.41687224606672924} | train loss {'Reaction outcome loss': 0.180203469070282, 'Total loss': 0.180203469070282}
2023-01-04 01:33:13,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:13,980 INFO:     Epoch: 82
2023-01-04 01:33:15,577 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4150906880696615, 'Total loss': 0.4150906880696615} | train loss {'Reaction outcome loss': 0.17772060380388133, 'Total loss': 0.17772060380388133}
2023-01-04 01:33:15,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:15,577 INFO:     Epoch: 83
2023-01-04 01:33:17,174 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4075582683086395, 'Total loss': 0.4075582683086395} | train loss {'Reaction outcome loss': 0.17560783175302777, 'Total loss': 0.17560783175302777}
2023-01-04 01:33:17,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:17,174 INFO:     Epoch: 84
2023-01-04 01:33:18,772 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4198704719543457, 'Total loss': 0.4198704719543457} | train loss {'Reaction outcome loss': 0.17422408747834328, 'Total loss': 0.17422408747834328}
2023-01-04 01:33:18,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:18,773 INFO:     Epoch: 85
2023-01-04 01:33:20,336 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40517774571975074, 'Total loss': 0.40517774571975074} | train loss {'Reaction outcome loss': 0.177132749012199, 'Total loss': 0.177132749012199}
2023-01-04 01:33:20,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:20,336 INFO:     Epoch: 86
2023-01-04 01:33:21,957 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39730620086193086, 'Total loss': 0.39730620086193086} | train loss {'Reaction outcome loss': 0.18981471632867106, 'Total loss': 0.18981471632867106}
2023-01-04 01:33:21,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:21,957 INFO:     Epoch: 87
2023-01-04 01:33:23,579 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.431624170144399, 'Total loss': 0.431624170144399} | train loss {'Reaction outcome loss': 0.17268264000610373, 'Total loss': 0.17268264000610373}
2023-01-04 01:33:23,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:23,579 INFO:     Epoch: 88
2023-01-04 01:33:25,200 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4150913154085477, 'Total loss': 0.4150913154085477} | train loss {'Reaction outcome loss': 0.1741577772892028, 'Total loss': 0.1741577772892028}
2023-01-04 01:33:25,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:25,200 INFO:     Epoch: 89
2023-01-04 01:33:26,820 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3970322464903196, 'Total loss': 0.3970322464903196} | train loss {'Reaction outcome loss': 0.17131924748262964, 'Total loss': 0.17131924748262964}
2023-01-04 01:33:26,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:26,820 INFO:     Epoch: 90
2023-01-04 01:33:28,447 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4064554860194524, 'Total loss': 0.4064554860194524} | train loss {'Reaction outcome loss': 0.16831658770198651, 'Total loss': 0.16831658770198651}
2023-01-04 01:33:28,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:28,448 INFO:     Epoch: 91
2023-01-04 01:33:30,016 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40886810223261516, 'Total loss': 0.40886810223261516} | train loss {'Reaction outcome loss': 0.17210694385078346, 'Total loss': 0.17210694385078346}
2023-01-04 01:33:30,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:30,016 INFO:     Epoch: 92
2023-01-04 01:33:31,619 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41002345383167266, 'Total loss': 0.41002345383167266} | train loss {'Reaction outcome loss': 0.16871212070564862, 'Total loss': 0.16871212070564862}
2023-01-04 01:33:31,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:31,619 INFO:     Epoch: 93
2023-01-04 01:33:33,221 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3928140858809153, 'Total loss': 0.3928140858809153} | train loss {'Reaction outcome loss': 0.17222336574765074, 'Total loss': 0.17222336574765074}
2023-01-04 01:33:33,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:33,221 INFO:     Epoch: 94
2023-01-04 01:33:34,841 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37784206758563715, 'Total loss': 0.37784206758563715} | train loss {'Reaction outcome loss': 0.1671241992018253, 'Total loss': 0.1671241992018253}
2023-01-04 01:33:34,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:34,842 INFO:     Epoch: 95
2023-01-04 01:33:36,460 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4198474446932475, 'Total loss': 0.4198474446932475} | train loss {'Reaction outcome loss': 0.17098695613811657, 'Total loss': 0.17098695613811657}
2023-01-04 01:33:36,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:36,460 INFO:     Epoch: 96
2023-01-04 01:33:38,057 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41162039240201315, 'Total loss': 0.41162039240201315} | train loss {'Reaction outcome loss': 0.16736155676379816, 'Total loss': 0.16736155676379816}
2023-01-04 01:33:38,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:38,057 INFO:     Epoch: 97
2023-01-04 01:33:39,640 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3922871818145116, 'Total loss': 0.3922871818145116} | train loss {'Reaction outcome loss': 0.16860815290019146, 'Total loss': 0.16860815290019146}
2023-01-04 01:33:39,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:39,640 INFO:     Epoch: 98
2023-01-04 01:33:41,259 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4081546609600385, 'Total loss': 0.4081546609600385} | train loss {'Reaction outcome loss': 0.16601516270099598, 'Total loss': 0.16601516270099598}
2023-01-04 01:33:41,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:41,259 INFO:     Epoch: 99
2023-01-04 01:33:42,874 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42155714382727943, 'Total loss': 0.42155714382727943} | train loss {'Reaction outcome loss': 0.1665046287133642, 'Total loss': 0.1665046287133642}
2023-01-04 01:33:42,874 INFO:     Best model found after epoch 34 of 100.
2023-01-04 01:33:42,874 INFO:   Done with stage: TRAINING
2023-01-04 01:33:42,874 INFO:   Starting stage: EVALUATION
2023-01-04 01:33:43,002 INFO:   Done with stage: EVALUATION
2023-01-04 01:33:43,003 INFO:   Leaving out SEQ value Fold_9
2023-01-04 01:33:43,015 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:33:43,015 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:33:43,655 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:33:43,655 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:33:43,724 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:33:43,725 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:33:43,725 INFO:     No hyperparam tuning for this model
2023-01-04 01:33:43,725 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:33:43,725 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:33:43,725 INFO:     None feature selector for col prot
2023-01-04 01:33:43,726 INFO:     None feature selector for col prot
2023-01-04 01:33:43,726 INFO:     None feature selector for col prot
2023-01-04 01:33:43,726 INFO:     None feature selector for col chem
2023-01-04 01:33:43,726 INFO:     None feature selector for col chem
2023-01-04 01:33:43,726 INFO:     None feature selector for col chem
2023-01-04 01:33:43,726 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:33:43,726 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:33:43,727 INFO:     Number of params in model 70141
2023-01-04 01:33:43,731 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:33:43,731 INFO:   Starting stage: TRAINING
2023-01-04 01:33:43,774 INFO:     Val loss before train {'Reaction outcome loss': 1.0316184600194296, 'Total loss': 1.0316184600194296}
2023-01-04 01:33:43,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:43,775 INFO:     Epoch: 0
2023-01-04 01:33:45,399 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6489670197168986, 'Total loss': 0.6489670197168986} | train loss {'Reaction outcome loss': 0.8273724424720242, 'Total loss': 0.8273724424720242}
2023-01-04 01:33:45,400 INFO:     Found new best model at epoch 0
2023-01-04 01:33:45,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:45,400 INFO:     Epoch: 1
2023-01-04 01:33:46,966 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5864667137463887, 'Total loss': 0.5864667137463887} | train loss {'Reaction outcome loss': 0.5918668979319973, 'Total loss': 0.5918668979319973}
2023-01-04 01:33:46,967 INFO:     Found new best model at epoch 1
2023-01-04 01:33:46,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:46,967 INFO:     Epoch: 2
2023-01-04 01:33:48,574 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5480591972668966, 'Total loss': 0.5480591972668966} | train loss {'Reaction outcome loss': 0.5278471048003521, 'Total loss': 0.5278471048003521}
2023-01-04 01:33:48,574 INFO:     Found new best model at epoch 2
2023-01-04 01:33:48,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:48,576 INFO:     Epoch: 3
2023-01-04 01:33:50,192 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.505028514067332, 'Total loss': 0.505028514067332} | train loss {'Reaction outcome loss': 0.4914515985418921, 'Total loss': 0.4914515985418921}
2023-01-04 01:33:50,192 INFO:     Found new best model at epoch 3
2023-01-04 01:33:50,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:50,193 INFO:     Epoch: 4
2023-01-04 01:33:51,800 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48257017135620117, 'Total loss': 0.48257017135620117} | train loss {'Reaction outcome loss': 0.46020912907395384, 'Total loss': 0.46020912907395384}
2023-01-04 01:33:51,800 INFO:     Found new best model at epoch 4
2023-01-04 01:33:51,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:51,801 INFO:     Epoch: 5
2023-01-04 01:33:53,430 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4723827580610911, 'Total loss': 0.4723827580610911} | train loss {'Reaction outcome loss': 0.43888739895993384, 'Total loss': 0.43888739895993384}
2023-01-04 01:33:53,430 INFO:     Found new best model at epoch 5
2023-01-04 01:33:53,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:53,431 INFO:     Epoch: 6
2023-01-04 01:33:55,060 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4623394588629405, 'Total loss': 0.4623394588629405} | train loss {'Reaction outcome loss': 0.42291856421856, 'Total loss': 0.42291856421856}
2023-01-04 01:33:55,060 INFO:     Found new best model at epoch 6
2023-01-04 01:33:55,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:55,061 INFO:     Epoch: 7
2023-01-04 01:33:56,626 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44448179999987286, 'Total loss': 0.44448179999987286} | train loss {'Reaction outcome loss': 0.4055756179768123, 'Total loss': 0.4055756179768123}
2023-01-04 01:33:56,626 INFO:     Found new best model at epoch 7
2023-01-04 01:33:56,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:56,627 INFO:     Epoch: 8
2023-01-04 01:33:58,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4411686857541402, 'Total loss': 0.4411686857541402} | train loss {'Reaction outcome loss': 0.38944374499471346, 'Total loss': 0.38944374499471346}
2023-01-04 01:33:58,260 INFO:     Found new best model at epoch 8
2023-01-04 01:33:58,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:58,261 INFO:     Epoch: 9
2023-01-04 01:33:59,876 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4374934365351995, 'Total loss': 0.4374934365351995} | train loss {'Reaction outcome loss': 0.3783493503671733, 'Total loss': 0.3783493503671733}
2023-01-04 01:33:59,876 INFO:     Found new best model at epoch 9
2023-01-04 01:33:59,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:33:59,877 INFO:     Epoch: 10
2023-01-04 01:34:01,505 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45536282161871594, 'Total loss': 0.45536282161871594} | train loss {'Reaction outcome loss': 0.37470932272465335, 'Total loss': 0.37470932272465335}
2023-01-04 01:34:01,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:01,506 INFO:     Epoch: 11
2023-01-04 01:34:03,124 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4411313831806183, 'Total loss': 0.4411313831806183} | train loss {'Reaction outcome loss': 0.35956592624205624, 'Total loss': 0.35956592624205624}
2023-01-04 01:34:03,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:03,124 INFO:     Epoch: 12
2023-01-04 01:34:04,719 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43872052828470864, 'Total loss': 0.43872052828470864} | train loss {'Reaction outcome loss': 0.3475624111386529, 'Total loss': 0.3475624111386529}
2023-01-04 01:34:04,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:04,720 INFO:     Epoch: 13
2023-01-04 01:34:06,301 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42926358779271445, 'Total loss': 0.42926358779271445} | train loss {'Reaction outcome loss': 0.33744245570868364, 'Total loss': 0.33744245570868364}
2023-01-04 01:34:06,301 INFO:     Found new best model at epoch 13
2023-01-04 01:34:06,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:06,302 INFO:     Epoch: 14
2023-01-04 01:34:07,904 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43396349946657814, 'Total loss': 0.43396349946657814} | train loss {'Reaction outcome loss': 0.3287623839179118, 'Total loss': 0.3287623839179118}
2023-01-04 01:34:07,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:07,904 INFO:     Epoch: 15
2023-01-04 01:34:09,503 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4329539199670156, 'Total loss': 0.4329539199670156} | train loss {'Reaction outcome loss': 0.3231080860921107, 'Total loss': 0.3231080860921107}
2023-01-04 01:34:09,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:09,504 INFO:     Epoch: 16
2023-01-04 01:34:11,105 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43874029914538065, 'Total loss': 0.43874029914538065} | train loss {'Reaction outcome loss': 0.3150014307187951, 'Total loss': 0.3150014307187951}
2023-01-04 01:34:11,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:11,106 INFO:     Epoch: 17
2023-01-04 01:34:12,719 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4221211185057958, 'Total loss': 0.4221211185057958} | train loss {'Reaction outcome loss': 0.30890533458137803, 'Total loss': 0.30890533458137803}
2023-01-04 01:34:12,719 INFO:     Found new best model at epoch 17
2023-01-04 01:34:12,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:12,720 INFO:     Epoch: 18
2023-01-04 01:34:14,280 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.434500507513682, 'Total loss': 0.434500507513682} | train loss {'Reaction outcome loss': 0.3019228565035914, 'Total loss': 0.3019228565035914}
2023-01-04 01:34:14,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:14,280 INFO:     Epoch: 19
2023-01-04 01:34:15,881 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4508602678775787, 'Total loss': 0.4508602678775787} | train loss {'Reaction outcome loss': 0.2987657683678781, 'Total loss': 0.2987657683678781}
2023-01-04 01:34:15,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:15,881 INFO:     Epoch: 20
2023-01-04 01:34:17,481 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4204377084970474, 'Total loss': 0.4204377084970474} | train loss {'Reaction outcome loss': 0.29407718509732594, 'Total loss': 0.29407718509732594}
2023-01-04 01:34:17,481 INFO:     Found new best model at epoch 20
2023-01-04 01:34:17,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:17,482 INFO:     Epoch: 21
2023-01-04 01:34:19,080 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4356473882993062, 'Total loss': 0.4356473882993062} | train loss {'Reaction outcome loss': 0.2881342062517407, 'Total loss': 0.2881342062517407}
2023-01-04 01:34:19,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:19,081 INFO:     Epoch: 22
2023-01-04 01:34:20,680 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42507782379786174, 'Total loss': 0.42507782379786174} | train loss {'Reaction outcome loss': 0.2833971668009906, 'Total loss': 0.2833971668009906}
2023-01-04 01:34:20,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:20,680 INFO:     Epoch: 23
2023-01-04 01:34:22,274 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4236544420321782, 'Total loss': 0.4236544420321782} | train loss {'Reaction outcome loss': 0.2802787931986909, 'Total loss': 0.2802787931986909}
2023-01-04 01:34:22,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:22,274 INFO:     Epoch: 24
2023-01-04 01:34:23,857 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43988072872161865, 'Total loss': 0.43988072872161865} | train loss {'Reaction outcome loss': 0.2737461158978766, 'Total loss': 0.2737461158978766}
2023-01-04 01:34:23,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:23,858 INFO:     Epoch: 25
2023-01-04 01:34:25,476 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43551573654015857, 'Total loss': 0.43551573654015857} | train loss {'Reaction outcome loss': 0.2715244012736324, 'Total loss': 0.2715244012736324}
2023-01-04 01:34:25,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:25,476 INFO:     Epoch: 26
2023-01-04 01:34:27,094 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.419243390361468, 'Total loss': 0.419243390361468} | train loss {'Reaction outcome loss': 0.2671848776989846, 'Total loss': 0.2671848776989846}
2023-01-04 01:34:27,094 INFO:     Found new best model at epoch 26
2023-01-04 01:34:27,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:27,095 INFO:     Epoch: 27
2023-01-04 01:34:28,705 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4329112152258555, 'Total loss': 0.4329112152258555} | train loss {'Reaction outcome loss': 0.26110972072532657, 'Total loss': 0.26110972072532657}
2023-01-04 01:34:28,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:28,706 INFO:     Epoch: 28
2023-01-04 01:34:30,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4183995485305786, 'Total loss': 0.4183995485305786} | train loss {'Reaction outcome loss': 0.2700757783014273, 'Total loss': 0.2700757783014273}
2023-01-04 01:34:30,325 INFO:     Found new best model at epoch 28
2023-01-04 01:34:30,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:30,326 INFO:     Epoch: 29
2023-01-04 01:34:31,903 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44487564265727997, 'Total loss': 0.44487564265727997} | train loss {'Reaction outcome loss': 0.26835851354079077, 'Total loss': 0.26835851354079077}
2023-01-04 01:34:31,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:31,903 INFO:     Epoch: 30
2023-01-04 01:34:33,518 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4250116109848022, 'Total loss': 0.4250116109848022} | train loss {'Reaction outcome loss': 0.25264980411831883, 'Total loss': 0.25264980411831883}
2023-01-04 01:34:33,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:33,518 INFO:     Epoch: 31
2023-01-04 01:34:35,134 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4174022207657496, 'Total loss': 0.4174022207657496} | train loss {'Reaction outcome loss': 0.2546462968153798, 'Total loss': 0.2546462968153798}
2023-01-04 01:34:35,134 INFO:     Found new best model at epoch 31
2023-01-04 01:34:35,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:35,135 INFO:     Epoch: 32
2023-01-04 01:34:36,745 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4401803900798162, 'Total loss': 0.4401803900798162} | train loss {'Reaction outcome loss': 0.25793787707453186, 'Total loss': 0.25793787707453186}
2023-01-04 01:34:36,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:36,745 INFO:     Epoch: 33
2023-01-04 01:34:38,329 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42424389322598777, 'Total loss': 0.42424389322598777} | train loss {'Reaction outcome loss': 0.24903392367253918, 'Total loss': 0.24903392367253918}
2023-01-04 01:34:38,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:38,329 INFO:     Epoch: 34
2023-01-04 01:34:39,948 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42156026760737103, 'Total loss': 0.42156026760737103} | train loss {'Reaction outcome loss': 0.24102384684870165, 'Total loss': 0.24102384684870165}
2023-01-04 01:34:39,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:39,949 INFO:     Epoch: 35
2023-01-04 01:34:41,329 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42764948805173236, 'Total loss': 0.42764948805173236} | train loss {'Reaction outcome loss': 0.2370683595259122, 'Total loss': 0.2370683595259122}
2023-01-04 01:34:41,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:41,330 INFO:     Epoch: 36
2023-01-04 01:34:42,392 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41926372845967613, 'Total loss': 0.41926372845967613} | train loss {'Reaction outcome loss': 0.2353487959269947, 'Total loss': 0.2353487959269947}
2023-01-04 01:34:42,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:42,392 INFO:     Epoch: 37
2023-01-04 01:34:43,443 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4274837851524353, 'Total loss': 0.4274837851524353} | train loss {'Reaction outcome loss': 0.23324400608164622, 'Total loss': 0.23324400608164622}
2023-01-04 01:34:43,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:43,443 INFO:     Epoch: 38
2023-01-04 01:34:44,498 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41725601156552633, 'Total loss': 0.41725601156552633} | train loss {'Reaction outcome loss': 0.22994760507951825, 'Total loss': 0.22994760507951825}
2023-01-04 01:34:44,498 INFO:     Found new best model at epoch 38
2023-01-04 01:34:44,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:44,499 INFO:     Epoch: 39
2023-01-04 01:34:45,603 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40623223713288703, 'Total loss': 0.40623223713288703} | train loss {'Reaction outcome loss': 0.22980492545858675, 'Total loss': 0.22980492545858675}
2023-01-04 01:34:45,603 INFO:     Found new best model at epoch 39
2023-01-04 01:34:45,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:45,604 INFO:     Epoch: 40
2023-01-04 01:34:47,163 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42992507219314574, 'Total loss': 0.42992507219314574} | train loss {'Reaction outcome loss': 0.23204169408384495, 'Total loss': 0.23204169408384495}
2023-01-04 01:34:47,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:47,164 INFO:     Epoch: 41
2023-01-04 01:34:48,788 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41374137103557584, 'Total loss': 0.41374137103557584} | train loss {'Reaction outcome loss': 0.2352804901159328, 'Total loss': 0.2352804901159328}
2023-01-04 01:34:48,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:48,788 INFO:     Epoch: 42
2023-01-04 01:34:50,416 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4156978189945221, 'Total loss': 0.4156978189945221} | train loss {'Reaction outcome loss': 0.22599761142138985, 'Total loss': 0.22599761142138985}
2023-01-04 01:34:50,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:50,416 INFO:     Epoch: 43
2023-01-04 01:34:52,041 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4184946358203888, 'Total loss': 0.4184946358203888} | train loss {'Reaction outcome loss': 0.22139233935867314, 'Total loss': 0.22139233935867314}
2023-01-04 01:34:52,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:52,041 INFO:     Epoch: 44
2023-01-04 01:34:53,668 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4430573383967082, 'Total loss': 0.4430573383967082} | train loss {'Reaction outcome loss': 0.21901309282343456, 'Total loss': 0.21901309282343456}
2023-01-04 01:34:53,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:53,668 INFO:     Epoch: 45
2023-01-04 01:34:55,260 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43387470543384554, 'Total loss': 0.43387470543384554} | train loss {'Reaction outcome loss': 0.22130391132288976, 'Total loss': 0.22130391132288976}
2023-01-04 01:34:55,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:55,261 INFO:     Epoch: 46
2023-01-04 01:34:56,831 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43855396111806233, 'Total loss': 0.43855396111806233} | train loss {'Reaction outcome loss': 0.21401359789677477, 'Total loss': 0.21401359789677477}
2023-01-04 01:34:56,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:56,831 INFO:     Epoch: 47
2023-01-04 01:34:58,446 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42294853925704956, 'Total loss': 0.42294853925704956} | train loss {'Reaction outcome loss': 0.21189349003395982, 'Total loss': 0.21189349003395982}
2023-01-04 01:34:58,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:34:58,447 INFO:     Epoch: 48
2023-01-04 01:35:00,049 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4237747887770335, 'Total loss': 0.4237747887770335} | train loss {'Reaction outcome loss': 0.21371636891980533, 'Total loss': 0.21371636891980533}
2023-01-04 01:35:00,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:00,050 INFO:     Epoch: 49
2023-01-04 01:35:01,668 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44337379932403564, 'Total loss': 0.44337379932403564} | train loss {'Reaction outcome loss': 0.2099606687925584, 'Total loss': 0.2099606687925584}
2023-01-04 01:35:01,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:01,668 INFO:     Epoch: 50
2023-01-04 01:35:03,295 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4392340540885925, 'Total loss': 0.4392340540885925} | train loss {'Reaction outcome loss': 0.20805752176143552, 'Total loss': 0.20805752176143552}
2023-01-04 01:35:03,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:03,295 INFO:     Epoch: 51
2023-01-04 01:35:04,874 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41930803110202153, 'Total loss': 0.41930803110202153} | train loss {'Reaction outcome loss': 0.21147447684484508, 'Total loss': 0.21147447684484508}
2023-01-04 01:35:04,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:04,874 INFO:     Epoch: 52
2023-01-04 01:35:06,452 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4567955086628596, 'Total loss': 0.4567955086628596} | train loss {'Reaction outcome loss': 0.20404810871443022, 'Total loss': 0.20404810871443022}
2023-01-04 01:35:06,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:06,452 INFO:     Epoch: 53
2023-01-04 01:35:08,048 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4316076457500458, 'Total loss': 0.4316076457500458} | train loss {'Reaction outcome loss': 0.20383770788928657, 'Total loss': 0.20383770788928657}
2023-01-04 01:35:08,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:08,048 INFO:     Epoch: 54
2023-01-04 01:35:09,642 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43136179049809775, 'Total loss': 0.43136179049809775} | train loss {'Reaction outcome loss': 0.20298899779015261, 'Total loss': 0.20298899779015261}
2023-01-04 01:35:09,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:09,642 INFO:     Epoch: 55
2023-01-04 01:35:11,241 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4301405012607574, 'Total loss': 0.4301405012607574} | train loss {'Reaction outcome loss': 0.20260029756057032, 'Total loss': 0.20260029756057032}
2023-01-04 01:35:11,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:11,242 INFO:     Epoch: 56
2023-01-04 01:35:12,803 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4337700163324674, 'Total loss': 0.4337700163324674} | train loss {'Reaction outcome loss': 0.19984488542555165, 'Total loss': 0.19984488542555165}
2023-01-04 01:35:12,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:12,804 INFO:     Epoch: 57
2023-01-04 01:35:14,392 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44004922807216645, 'Total loss': 0.44004922807216645} | train loss {'Reaction outcome loss': 0.197342838038795, 'Total loss': 0.197342838038795}
2023-01-04 01:35:14,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:14,393 INFO:     Epoch: 58
2023-01-04 01:35:16,013 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4336089283227921, 'Total loss': 0.4336089283227921} | train loss {'Reaction outcome loss': 0.1961874704675919, 'Total loss': 0.1961874704675919}
2023-01-04 01:35:16,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:16,014 INFO:     Epoch: 59
2023-01-04 01:35:17,601 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4577522118886312, 'Total loss': 0.4577522118886312} | train loss {'Reaction outcome loss': 0.19739050232886296, 'Total loss': 0.19739050232886296}
2023-01-04 01:35:17,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:17,602 INFO:     Epoch: 60
2023-01-04 01:35:19,222 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4177518665790558, 'Total loss': 0.4177518665790558} | train loss {'Reaction outcome loss': 0.19337531260680407, 'Total loss': 0.19337531260680407}
2023-01-04 01:35:19,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:19,222 INFO:     Epoch: 61
2023-01-04 01:35:20,845 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43137066761652626, 'Total loss': 0.43137066761652626} | train loss {'Reaction outcome loss': 0.19248048176961965, 'Total loss': 0.19248048176961965}
2023-01-04 01:35:20,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:20,845 INFO:     Epoch: 62
2023-01-04 01:35:22,443 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41270895848671596, 'Total loss': 0.41270895848671596} | train loss {'Reaction outcome loss': 0.19302854938117284, 'Total loss': 0.19302854938117284}
2023-01-04 01:35:22,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:22,443 INFO:     Epoch: 63
2023-01-04 01:35:24,009 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4205056389172872, 'Total loss': 0.4205056389172872} | train loss {'Reaction outcome loss': 0.1909328694105236, 'Total loss': 0.1909328694105236}
2023-01-04 01:35:24,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:24,009 INFO:     Epoch: 64
2023-01-04 01:35:25,630 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43211276829242706, 'Total loss': 0.43211276829242706} | train loss {'Reaction outcome loss': 0.19072560888868623, 'Total loss': 0.19072560888868623}
2023-01-04 01:35:25,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:25,630 INFO:     Epoch: 65
2023-01-04 01:35:27,214 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43853172262509665, 'Total loss': 0.43853172262509665} | train loss {'Reaction outcome loss': 0.1874005935843224, 'Total loss': 0.1874005935843224}
2023-01-04 01:35:27,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:27,214 INFO:     Epoch: 66
2023-01-04 01:35:28,834 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4233225047588348, 'Total loss': 0.4233225047588348} | train loss {'Reaction outcome loss': 0.1906681575987866, 'Total loss': 0.1906681575987866}
2023-01-04 01:35:28,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:28,834 INFO:     Epoch: 67
2023-01-04 01:35:30,413 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42211605111757916, 'Total loss': 0.42211605111757916} | train loss {'Reaction outcome loss': 0.18630068705997604, 'Total loss': 0.18630068705997604}
2023-01-04 01:35:30,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:30,414 INFO:     Epoch: 68
2023-01-04 01:35:31,980 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4340197056531906, 'Total loss': 0.4340197056531906} | train loss {'Reaction outcome loss': 0.18575210338757894, 'Total loss': 0.18575210338757894}
2023-01-04 01:35:31,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:31,980 INFO:     Epoch: 69
2023-01-04 01:35:33,601 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4303824931383133, 'Total loss': 0.4303824931383133} | train loss {'Reaction outcome loss': 0.18763094475033923, 'Total loss': 0.18763094475033923}
2023-01-04 01:35:33,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:33,601 INFO:     Epoch: 70
2023-01-04 01:35:35,187 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4188878883918126, 'Total loss': 0.4188878883918126} | train loss {'Reaction outcome loss': 0.18475307174620853, 'Total loss': 0.18475307174620853}
2023-01-04 01:35:35,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:35,187 INFO:     Epoch: 71
2023-01-04 01:35:36,808 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4267236222823461, 'Total loss': 0.4267236222823461} | train loss {'Reaction outcome loss': 0.19372045777086844, 'Total loss': 0.19372045777086844}
2023-01-04 01:35:36,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:36,808 INFO:     Epoch: 72
2023-01-04 01:35:38,395 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4362891803185145, 'Total loss': 0.4362891803185145} | train loss {'Reaction outcome loss': 0.18388551066838799, 'Total loss': 0.18388551066838799}
2023-01-04 01:35:38,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:38,395 INFO:     Epoch: 73
2023-01-04 01:35:39,998 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42152408411105474, 'Total loss': 0.42152408411105474} | train loss {'Reaction outcome loss': 0.18060974495407814, 'Total loss': 0.18060974495407814}
2023-01-04 01:35:39,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:39,999 INFO:     Epoch: 74
2023-01-04 01:35:41,588 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4083527237176895, 'Total loss': 0.4083527237176895} | train loss {'Reaction outcome loss': 0.18094553114454923, 'Total loss': 0.18094553114454923}
2023-01-04 01:35:41,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:41,588 INFO:     Epoch: 75
2023-01-04 01:35:43,181 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4207272152105967, 'Total loss': 0.4207272152105967} | train loss {'Reaction outcome loss': 0.1794220852881562, 'Total loss': 0.1794220852881562}
2023-01-04 01:35:43,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:43,181 INFO:     Epoch: 76
2023-01-04 01:35:44,776 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4222931961218516, 'Total loss': 0.4222931961218516} | train loss {'Reaction outcome loss': 0.17717030369912853, 'Total loss': 0.17717030369912853}
2023-01-04 01:35:44,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:44,776 INFO:     Epoch: 77
2023-01-04 01:35:46,372 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4401088068882624, 'Total loss': 0.4401088068882624} | train loss {'Reaction outcome loss': 0.17602813610294793, 'Total loss': 0.17602813610294793}
2023-01-04 01:35:46,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:46,373 INFO:     Epoch: 78
2023-01-04 01:35:47,959 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4081713706875841, 'Total loss': 0.4081713706875841} | train loss {'Reaction outcome loss': 0.17646047930516626, 'Total loss': 0.17646047930516626}
2023-01-04 01:35:47,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:47,960 INFO:     Epoch: 79
2023-01-04 01:35:49,565 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43450103551149366, 'Total loss': 0.43450103551149366} | train loss {'Reaction outcome loss': 0.17621695597072307, 'Total loss': 0.17621695597072307}
2023-01-04 01:35:49,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:49,565 INFO:     Epoch: 80
2023-01-04 01:35:51,147 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4157442589600881, 'Total loss': 0.4157442589600881} | train loss {'Reaction outcome loss': 0.17362714948578048, 'Total loss': 0.17362714948578048}
2023-01-04 01:35:51,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:51,148 INFO:     Epoch: 81
2023-01-04 01:35:52,735 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4269257426261902, 'Total loss': 0.4269257426261902} | train loss {'Reaction outcome loss': 0.1752050185282512, 'Total loss': 0.1752050185282512}
2023-01-04 01:35:52,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:52,736 INFO:     Epoch: 82
2023-01-04 01:35:54,318 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43902867436409, 'Total loss': 0.43902867436409} | train loss {'Reaction outcome loss': 0.17341914233196987, 'Total loss': 0.17341914233196987}
2023-01-04 01:35:54,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:54,318 INFO:     Epoch: 83
2023-01-04 01:35:55,940 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41522709230581917, 'Total loss': 0.41522709230581917} | train loss {'Reaction outcome loss': 0.17253446720154159, 'Total loss': 0.17253446720154159}
2023-01-04 01:35:55,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:55,941 INFO:     Epoch: 84
2023-01-04 01:35:57,543 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4121178994576136, 'Total loss': 0.4121178994576136} | train loss {'Reaction outcome loss': 0.17182128688411624, 'Total loss': 0.17182128688411624}
2023-01-04 01:35:57,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:57,543 INFO:     Epoch: 85
2023-01-04 01:35:59,146 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42395732502142586, 'Total loss': 0.42395732502142586} | train loss {'Reaction outcome loss': 0.17090777326392118, 'Total loss': 0.17090777326392118}
2023-01-04 01:35:59,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:35:59,146 INFO:     Epoch: 86
2023-01-04 01:36:00,744 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4069117307662964, 'Total loss': 0.4069117307662964} | train loss {'Reaction outcome loss': 0.1692500897283342, 'Total loss': 0.1692500897283342}
2023-01-04 01:36:00,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:00,744 INFO:     Epoch: 87
2023-01-04 01:36:02,364 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4090777630607287, 'Total loss': 0.4090777630607287} | train loss {'Reaction outcome loss': 0.16849833191962968, 'Total loss': 0.16849833191962968}
2023-01-04 01:36:02,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:02,364 INFO:     Epoch: 88
2023-01-04 01:36:03,945 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4218868563572566, 'Total loss': 0.4218868563572566} | train loss {'Reaction outcome loss': 0.16828335692728127, 'Total loss': 0.16828335692728127}
2023-01-04 01:36:03,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:03,945 INFO:     Epoch: 89
2023-01-04 01:36:05,567 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4227801223595937, 'Total loss': 0.4227801223595937} | train loss {'Reaction outcome loss': 0.16704135226599107, 'Total loss': 0.16704135226599107}
2023-01-04 01:36:05,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:05,568 INFO:     Epoch: 90
2023-01-04 01:36:07,129 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4343596170345942, 'Total loss': 0.4343596170345942} | train loss {'Reaction outcome loss': 0.16772798637538328, 'Total loss': 0.16772798637538328}
2023-01-04 01:36:07,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:07,129 INFO:     Epoch: 91
2023-01-04 01:36:08,701 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43327078719933826, 'Total loss': 0.43327078719933826} | train loss {'Reaction outcome loss': 0.16651001831169066, 'Total loss': 0.16651001831169066}
2023-01-04 01:36:08,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:08,701 INFO:     Epoch: 92
2023-01-04 01:36:10,294 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4334290643533071, 'Total loss': 0.4334290643533071} | train loss {'Reaction outcome loss': 0.16571668372826948, 'Total loss': 0.16571668372826948}
2023-01-04 01:36:10,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:10,294 INFO:     Epoch: 93
2023-01-04 01:36:11,887 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4250690996646881, 'Total loss': 0.4250690996646881} | train loss {'Reaction outcome loss': 0.166876204083235, 'Total loss': 0.166876204083235}
2023-01-04 01:36:11,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:11,887 INFO:     Epoch: 94
2023-01-04 01:36:13,509 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42136614918708803, 'Total loss': 0.42136614918708803} | train loss {'Reaction outcome loss': 0.16388223417089792, 'Total loss': 0.16388223417089792}
2023-01-04 01:36:13,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:13,509 INFO:     Epoch: 95
2023-01-04 01:36:15,106 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4282974272966385, 'Total loss': 0.4282974272966385} | train loss {'Reaction outcome loss': 0.16275282628645282, 'Total loss': 0.16275282628645282}
2023-01-04 01:36:15,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:15,106 INFO:     Epoch: 96
2023-01-04 01:36:16,678 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4147996485233307, 'Total loss': 0.4147996485233307} | train loss {'Reaction outcome loss': 0.1644219346884368, 'Total loss': 0.1644219346884368}
2023-01-04 01:36:16,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:16,679 INFO:     Epoch: 97
2023-01-04 01:36:18,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4369195133447647, 'Total loss': 0.4369195133447647} | train loss {'Reaction outcome loss': 0.16178151605266106, 'Total loss': 0.16178151605266106}
2023-01-04 01:36:18,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:18,302 INFO:     Epoch: 98
2023-01-04 01:36:19,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4100864976644516, 'Total loss': 0.4100864976644516} | train loss {'Reaction outcome loss': 0.16283902277254964, 'Total loss': 0.16283902277254964}
2023-01-04 01:36:19,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:19,922 INFO:     Epoch: 99
2023-01-04 01:36:21,542 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44736753702163695, 'Total loss': 0.44736753702163695} | train loss {'Reaction outcome loss': 0.16023039431931227, 'Total loss': 0.16023039431931227}
2023-01-04 01:36:21,542 INFO:     Best model found after epoch 40 of 100.
2023-01-04 01:36:21,542 INFO:   Done with stage: TRAINING
2023-01-04 01:36:21,543 INFO:   Starting stage: EVALUATION
2023-01-04 01:36:21,671 INFO:   Done with stage: EVALUATION
2023-01-04 01:36:21,680 INFO:   Leaving out SEQ value Fold_0
2023-01-04 01:36:21,692 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:36:21,692 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:36:22,344 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:36:22,344 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:36:22,413 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:36:22,413 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:36:22,413 INFO:     No hyperparam tuning for this model
2023-01-04 01:36:22,413 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:36:22,413 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:36:22,414 INFO:     None feature selector for col prot
2023-01-04 01:36:22,414 INFO:     None feature selector for col prot
2023-01-04 01:36:22,414 INFO:     None feature selector for col prot
2023-01-04 01:36:22,414 INFO:     None feature selector for col chem
2023-01-04 01:36:22,415 INFO:     None feature selector for col chem
2023-01-04 01:36:22,415 INFO:     None feature selector for col chem
2023-01-04 01:36:22,415 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:36:22,415 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:36:22,416 INFO:     Number of params in model 70141
2023-01-04 01:36:22,419 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:36:22,419 INFO:   Starting stage: TRAINING
2023-01-04 01:36:22,462 INFO:     Val loss before train {'Reaction outcome loss': 1.0309925516446432, 'Total loss': 1.0309925516446432}
2023-01-04 01:36:22,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:22,462 INFO:     Epoch: 0
2023-01-04 01:36:24,063 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7329558432102203, 'Total loss': 0.7329558432102203} | train loss {'Reaction outcome loss': 0.8337488398360817, 'Total loss': 0.8337488398360817}
2023-01-04 01:36:24,064 INFO:     Found new best model at epoch 0
2023-01-04 01:36:24,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:24,065 INFO:     Epoch: 1
2023-01-04 01:36:25,641 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5603675564130147, 'Total loss': 0.5603675564130147} | train loss {'Reaction outcome loss': 0.6013887513671881, 'Total loss': 0.6013887513671881}
2023-01-04 01:36:25,641 INFO:     Found new best model at epoch 1
2023-01-04 01:36:25,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:25,642 INFO:     Epoch: 2
2023-01-04 01:36:27,237 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5105901539325715, 'Total loss': 0.5105901539325715} | train loss {'Reaction outcome loss': 0.5264516511621574, 'Total loss': 0.5264516511621574}
2023-01-04 01:36:27,237 INFO:     Found new best model at epoch 2
2023-01-04 01:36:27,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:27,238 INFO:     Epoch: 3
2023-01-04 01:36:28,832 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4782741685708364, 'Total loss': 0.4782741685708364} | train loss {'Reaction outcome loss': 0.4867818445723126, 'Total loss': 0.4867818445723126}
2023-01-04 01:36:28,832 INFO:     Found new best model at epoch 3
2023-01-04 01:36:28,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:28,833 INFO:     Epoch: 4
2023-01-04 01:36:30,428 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45535765488942465, 'Total loss': 0.45535765488942465} | train loss {'Reaction outcome loss': 0.46688365218216094, 'Total loss': 0.46688365218216094}
2023-01-04 01:36:30,428 INFO:     Found new best model at epoch 4
2023-01-04 01:36:30,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:30,429 INFO:     Epoch: 5
2023-01-04 01:36:32,022 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45038175185521445, 'Total loss': 0.45038175185521445} | train loss {'Reaction outcome loss': 0.44181342993871786, 'Total loss': 0.44181342993871786}
2023-01-04 01:36:32,022 INFO:     Found new best model at epoch 5
2023-01-04 01:36:32,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:32,023 INFO:     Epoch: 6
2023-01-04 01:36:33,596 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44623336593310037, 'Total loss': 0.44623336593310037} | train loss {'Reaction outcome loss': 0.4245223109137969, 'Total loss': 0.4245223109137969}
2023-01-04 01:36:33,596 INFO:     Found new best model at epoch 6
2023-01-04 01:36:33,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:33,597 INFO:     Epoch: 7
2023-01-04 01:36:35,189 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4240843206644058, 'Total loss': 0.4240843206644058} | train loss {'Reaction outcome loss': 0.4110468664061625, 'Total loss': 0.4110468664061625}
2023-01-04 01:36:35,190 INFO:     Found new best model at epoch 7
2023-01-04 01:36:35,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:35,190 INFO:     Epoch: 8
2023-01-04 01:36:36,764 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.404472937186559, 'Total loss': 0.404472937186559} | train loss {'Reaction outcome loss': 0.40365113847065665, 'Total loss': 0.40365113847065665}
2023-01-04 01:36:36,764 INFO:     Found new best model at epoch 8
2023-01-04 01:36:36,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:36,765 INFO:     Epoch: 9
2023-01-04 01:36:38,340 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4232672055562337, 'Total loss': 0.4232672055562337} | train loss {'Reaction outcome loss': 0.39177473685096786, 'Total loss': 0.39177473685096786}
2023-01-04 01:36:38,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:38,340 INFO:     Epoch: 10
2023-01-04 01:36:39,929 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41160597999890647, 'Total loss': 0.41160597999890647} | train loss {'Reaction outcome loss': 0.3845307367421059, 'Total loss': 0.3845307367421059}
2023-01-04 01:36:39,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:39,929 INFO:     Epoch: 11
2023-01-04 01:36:41,544 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41181671619415283, 'Total loss': 0.41181671619415283} | train loss {'Reaction outcome loss': 0.37813042252715945, 'Total loss': 0.37813042252715945}
2023-01-04 01:36:41,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:41,544 INFO:     Epoch: 12
2023-01-04 01:36:43,138 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4081747382879257, 'Total loss': 0.4081747382879257} | train loss {'Reaction outcome loss': 0.37377986004171165, 'Total loss': 0.37377986004171165}
2023-01-04 01:36:43,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:43,138 INFO:     Epoch: 13
2023-01-04 01:36:44,733 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4116158723831177, 'Total loss': 0.4116158723831177} | train loss {'Reaction outcome loss': 0.37124464315348776, 'Total loss': 0.37124464315348776}
2023-01-04 01:36:44,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:44,734 INFO:     Epoch: 14
2023-01-04 01:36:46,351 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39715503752231596, 'Total loss': 0.39715503752231596} | train loss {'Reaction outcome loss': 0.3587469434487107, 'Total loss': 0.3587469434487107}
2023-01-04 01:36:46,351 INFO:     Found new best model at epoch 14
2023-01-04 01:36:46,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:46,352 INFO:     Epoch: 15
2023-01-04 01:36:47,926 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4113697032133738, 'Total loss': 0.4113697032133738} | train loss {'Reaction outcome loss': 0.36871191837649414, 'Total loss': 0.36871191837649414}
2023-01-04 01:36:47,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:47,927 INFO:     Epoch: 16
2023-01-04 01:36:49,507 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40029411216576893, 'Total loss': 0.40029411216576893} | train loss {'Reaction outcome loss': 0.35272425774862803, 'Total loss': 0.35272425774862803}
2023-01-04 01:36:49,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:49,507 INFO:     Epoch: 17
2023-01-04 01:36:51,100 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.391589580476284, 'Total loss': 0.391589580476284} | train loss {'Reaction outcome loss': 0.3424231102276742, 'Total loss': 0.3424231102276742}
2023-01-04 01:36:51,100 INFO:     Found new best model at epoch 17
2023-01-04 01:36:51,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:51,101 INFO:     Epoch: 18
2023-01-04 01:36:52,675 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.396265106399854, 'Total loss': 0.396265106399854} | train loss {'Reaction outcome loss': 0.3334275928483702, 'Total loss': 0.3334275928483702}
2023-01-04 01:36:52,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:52,675 INFO:     Epoch: 19
2023-01-04 01:36:54,251 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3990403195222219, 'Total loss': 0.3990403195222219} | train loss {'Reaction outcome loss': 0.33009924913716054, 'Total loss': 0.33009924913716054}
2023-01-04 01:36:54,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:54,251 INFO:     Epoch: 20
2023-01-04 01:36:55,848 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40103503366311394, 'Total loss': 0.40103503366311394} | train loss {'Reaction outcome loss': 0.3452396667899861, 'Total loss': 0.3452396667899861}
2023-01-04 01:36:55,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:55,848 INFO:     Epoch: 21
2023-01-04 01:36:57,469 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39675243695576984, 'Total loss': 0.39675243695576984} | train loss {'Reaction outcome loss': 0.3209589711808856, 'Total loss': 0.3209589711808856}
2023-01-04 01:36:57,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:57,469 INFO:     Epoch: 22
2023-01-04 01:36:59,076 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38800957004229225, 'Total loss': 0.38800957004229225} | train loss {'Reaction outcome loss': 0.3219030361784541, 'Total loss': 0.3219030361784541}
2023-01-04 01:36:59,077 INFO:     Found new best model at epoch 22
2023-01-04 01:36:59,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:36:59,077 INFO:     Epoch: 23
2023-01-04 01:37:00,667 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38859523336092633, 'Total loss': 0.38859523336092633} | train loss {'Reaction outcome loss': 0.3144874401741486, 'Total loss': 0.3144874401741486}
2023-01-04 01:37:00,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:00,667 INFO:     Epoch: 24
2023-01-04 01:37:02,238 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38842081824938457, 'Total loss': 0.38842081824938457} | train loss {'Reaction outcome loss': 0.30588226720937056, 'Total loss': 0.30588226720937056}
2023-01-04 01:37:02,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:02,238 INFO:     Epoch: 25
2023-01-04 01:37:03,845 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3804944862922033, 'Total loss': 0.3804944862922033} | train loss {'Reaction outcome loss': 0.30773789963374537, 'Total loss': 0.30773789963374537}
2023-01-04 01:37:03,845 INFO:     Found new best model at epoch 25
2023-01-04 01:37:03,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:03,846 INFO:     Epoch: 26
2023-01-04 01:37:05,455 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4015780329704285, 'Total loss': 0.4015780329704285} | train loss {'Reaction outcome loss': 0.303668018369733, 'Total loss': 0.303668018369733}
2023-01-04 01:37:05,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:05,455 INFO:     Epoch: 27
2023-01-04 01:37:07,076 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39006780584653217, 'Total loss': 0.39006780584653217} | train loss {'Reaction outcome loss': 0.2957613493789973, 'Total loss': 0.2957613493789973}
2023-01-04 01:37:07,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:07,077 INFO:     Epoch: 28
2023-01-04 01:37:08,645 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39856690367062886, 'Total loss': 0.39856690367062886} | train loss {'Reaction outcome loss': 0.29041641657038225, 'Total loss': 0.29041641657038225}
2023-01-04 01:37:08,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:08,646 INFO:     Epoch: 29
2023-01-04 01:37:10,245 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3966403027375539, 'Total loss': 0.3966403027375539} | train loss {'Reaction outcome loss': 0.28710679151075624, 'Total loss': 0.28710679151075624}
2023-01-04 01:37:10,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:10,245 INFO:     Epoch: 30
2023-01-04 01:37:11,832 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40686267217000327, 'Total loss': 0.40686267217000327} | train loss {'Reaction outcome loss': 0.28274283715586207, 'Total loss': 0.28274283715586207}
2023-01-04 01:37:11,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:11,832 INFO:     Epoch: 31
2023-01-04 01:37:13,454 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3841515044371287, 'Total loss': 0.3841515044371287} | train loss {'Reaction outcome loss': 0.27917594029534415, 'Total loss': 0.27917594029534415}
2023-01-04 01:37:13,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:13,454 INFO:     Epoch: 32
2023-01-04 01:37:15,054 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39145649075508115, 'Total loss': 0.39145649075508115} | train loss {'Reaction outcome loss': 0.2787056978424147, 'Total loss': 0.2787056978424147}
2023-01-04 01:37:15,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:15,055 INFO:     Epoch: 33
2023-01-04 01:37:16,679 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39610797315835955, 'Total loss': 0.39610797315835955} | train loss {'Reaction outcome loss': 0.27309594834509815, 'Total loss': 0.27309594834509815}
2023-01-04 01:37:16,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:16,679 INFO:     Epoch: 34
2023-01-04 01:37:18,270 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3963255286216736, 'Total loss': 0.3963255286216736} | train loss {'Reaction outcome loss': 0.27029076055961027, 'Total loss': 0.27029076055961027}
2023-01-04 01:37:18,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:18,272 INFO:     Epoch: 35
2023-01-04 01:37:19,857 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3773352573315302, 'Total loss': 0.3773352573315302} | train loss {'Reaction outcome loss': 0.2680461724454105, 'Total loss': 0.2680461724454105}
2023-01-04 01:37:19,857 INFO:     Found new best model at epoch 35
2023-01-04 01:37:19,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:19,858 INFO:     Epoch: 36
2023-01-04 01:37:21,445 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3937201380729675, 'Total loss': 0.3937201380729675} | train loss {'Reaction outcome loss': 0.2616825781600631, 'Total loss': 0.2616825781600631}
2023-01-04 01:37:21,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:21,445 INFO:     Epoch: 37
2023-01-04 01:37:23,069 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37320122917493187, 'Total loss': 0.37320122917493187} | train loss {'Reaction outcome loss': 0.2602512240949748, 'Total loss': 0.2602512240949748}
2023-01-04 01:37:23,069 INFO:     Found new best model at epoch 37
2023-01-04 01:37:23,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:23,070 INFO:     Epoch: 38
2023-01-04 01:37:24,692 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38829473257064817, 'Total loss': 0.38829473257064817} | train loss {'Reaction outcome loss': 0.2601191877291295, 'Total loss': 0.2601191877291295}
2023-01-04 01:37:24,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:24,693 INFO:     Epoch: 39
2023-01-04 01:37:26,261 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3737968385219574, 'Total loss': 0.3737968385219574} | train loss {'Reaction outcome loss': 0.25499791109030123, 'Total loss': 0.25499791109030123}
2023-01-04 01:37:26,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:26,261 INFO:     Epoch: 40
2023-01-04 01:37:27,837 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39685721695423126, 'Total loss': 0.39685721695423126} | train loss {'Reaction outcome loss': 0.253028366620234, 'Total loss': 0.253028366620234}
2023-01-04 01:37:27,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:27,837 INFO:     Epoch: 41
2023-01-04 01:37:29,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3821672340234121, 'Total loss': 0.3821672340234121} | train loss {'Reaction outcome loss': 0.2602056309013911, 'Total loss': 0.2602056309013911}
2023-01-04 01:37:29,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:29,420 INFO:     Epoch: 42
2023-01-04 01:37:31,043 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37473010818163555, 'Total loss': 0.37473010818163555} | train loss {'Reaction outcome loss': 0.26404100440044387, 'Total loss': 0.26404100440044387}
2023-01-04 01:37:31,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:31,043 INFO:     Epoch: 43
2023-01-04 01:37:32,616 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3766872574885686, 'Total loss': 0.3766872574885686} | train loss {'Reaction outcome loss': 0.24511667845481366, 'Total loss': 0.24511667845481366}
2023-01-04 01:37:32,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:32,616 INFO:     Epoch: 44
2023-01-04 01:37:34,240 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3783951352039973, 'Total loss': 0.3783951352039973} | train loss {'Reaction outcome loss': 0.24071446388847687, 'Total loss': 0.24071446388847687}
2023-01-04 01:37:34,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:34,240 INFO:     Epoch: 45
2023-01-04 01:37:35,839 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39358995457490287, 'Total loss': 0.39358995457490287} | train loss {'Reaction outcome loss': 0.24049326624262377, 'Total loss': 0.24049326624262377}
2023-01-04 01:37:35,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:35,840 INFO:     Epoch: 46
2023-01-04 01:37:37,411 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3997358297308286, 'Total loss': 0.3997358297308286} | train loss {'Reaction outcome loss': 0.23806192455948263, 'Total loss': 0.23806192455948263}
2023-01-04 01:37:37,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:37,412 INFO:     Epoch: 47
2023-01-04 01:37:38,991 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3784772594769796, 'Total loss': 0.3784772594769796} | train loss {'Reaction outcome loss': 0.23725220341272518, 'Total loss': 0.23725220341272518}
2023-01-04 01:37:38,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:38,991 INFO:     Epoch: 48
2023-01-04 01:37:40,616 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3765731374422709, 'Total loss': 0.3765731374422709} | train loss {'Reaction outcome loss': 0.23690804461206216, 'Total loss': 0.23690804461206216}
2023-01-04 01:37:40,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:40,616 INFO:     Epoch: 49
2023-01-04 01:37:42,241 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3803582568963369, 'Total loss': 0.3803582568963369} | train loss {'Reaction outcome loss': 0.23840850702338462, 'Total loss': 0.23840850702338462}
2023-01-04 01:37:42,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:42,242 INFO:     Epoch: 50
2023-01-04 01:37:43,867 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3698027290403843, 'Total loss': 0.3698027290403843} | train loss {'Reaction outcome loss': 0.24539002110047833, 'Total loss': 0.24539002110047833}
2023-01-04 01:37:43,867 INFO:     Found new best model at epoch 50
2023-01-04 01:37:43,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:43,868 INFO:     Epoch: 51
2023-01-04 01:37:45,454 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3949439853429794, 'Total loss': 0.3949439853429794} | train loss {'Reaction outcome loss': 0.23919465579092503, 'Total loss': 0.23919465579092503}
2023-01-04 01:37:45,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:45,455 INFO:     Epoch: 52
2023-01-04 01:37:47,039 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36815495987733204, 'Total loss': 0.36815495987733204} | train loss {'Reaction outcome loss': 0.24086951630432968, 'Total loss': 0.24086951630432968}
2023-01-04 01:37:47,039 INFO:     Found new best model at epoch 52
2023-01-04 01:37:47,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:47,040 INFO:     Epoch: 53
2023-01-04 01:37:48,639 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38973858058452604, 'Total loss': 0.38973858058452604} | train loss {'Reaction outcome loss': 0.23372145377747391, 'Total loss': 0.23372145377747391}
2023-01-04 01:37:48,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:48,641 INFO:     Epoch: 54
2023-01-04 01:37:50,255 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3738430360953013, 'Total loss': 0.3738430360953013} | train loss {'Reaction outcome loss': 0.22573149201724702, 'Total loss': 0.22573149201724702}
2023-01-04 01:37:50,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:50,256 INFO:     Epoch: 55
2023-01-04 01:37:51,856 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37989271283149717, 'Total loss': 0.37989271283149717} | train loss {'Reaction outcome loss': 0.22175117484226392, 'Total loss': 0.22175117484226392}
2023-01-04 01:37:51,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:51,856 INFO:     Epoch: 56
2023-01-04 01:37:53,465 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3771991531054179, 'Total loss': 0.3771991531054179} | train loss {'Reaction outcome loss': 0.21949653029171884, 'Total loss': 0.21949653029171884}
2023-01-04 01:37:53,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:53,465 INFO:     Epoch: 57
2023-01-04 01:37:55,038 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37569741408030194, 'Total loss': 0.37569741408030194} | train loss {'Reaction outcome loss': 0.22019413141938654, 'Total loss': 0.22019413141938654}
2023-01-04 01:37:55,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:55,039 INFO:     Epoch: 58
2023-01-04 01:37:56,619 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3712718074520429, 'Total loss': 0.3712718074520429} | train loss {'Reaction outcome loss': 0.21597768004985352, 'Total loss': 0.21597768004985352}
2023-01-04 01:37:56,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:56,620 INFO:     Epoch: 59
2023-01-04 01:37:58,245 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3861258347829183, 'Total loss': 0.3861258347829183} | train loss {'Reaction outcome loss': 0.21457563307342134, 'Total loss': 0.21457563307342134}
2023-01-04 01:37:58,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:58,245 INFO:     Epoch: 60
2023-01-04 01:37:59,870 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3958964139223099, 'Total loss': 0.3958964139223099} | train loss {'Reaction outcome loss': 0.21440016729352268, 'Total loss': 0.21440016729352268}
2023-01-04 01:37:59,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:37:59,870 INFO:     Epoch: 61
2023-01-04 01:38:01,489 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3839923103650411, 'Total loss': 0.3839923103650411} | train loss {'Reaction outcome loss': 0.21375607474518524, 'Total loss': 0.21375607474518524}
2023-01-04 01:38:01,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:01,489 INFO:     Epoch: 62
2023-01-04 01:38:03,072 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3814773549636205, 'Total loss': 0.3814773549636205} | train loss {'Reaction outcome loss': 0.21232397844922135, 'Total loss': 0.21232397844922135}
2023-01-04 01:38:03,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:03,072 INFO:     Epoch: 63
2023-01-04 01:38:04,659 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39895709653695427, 'Total loss': 0.39895709653695427} | train loss {'Reaction outcome loss': 0.20889409201962095, 'Total loss': 0.20889409201962095}
2023-01-04 01:38:04,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:04,659 INFO:     Epoch: 64
2023-01-04 01:38:06,254 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3824339042107264, 'Total loss': 0.3824339042107264} | train loss {'Reaction outcome loss': 0.20903700361167718, 'Total loss': 0.20903700361167718}
2023-01-04 01:38:06,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:06,254 INFO:     Epoch: 65
2023-01-04 01:38:07,849 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3697411477565765, 'Total loss': 0.3697411477565765} | train loss {'Reaction outcome loss': 0.20749649702254142, 'Total loss': 0.20749649702254142}
2023-01-04 01:38:07,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:07,850 INFO:     Epoch: 66
2023-01-04 01:38:09,468 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3825539837280909, 'Total loss': 0.3825539837280909} | train loss {'Reaction outcome loss': 0.20515241980066765, 'Total loss': 0.20515241980066765}
2023-01-04 01:38:09,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:09,468 INFO:     Epoch: 67
2023-01-04 01:38:11,085 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3612959704051415, 'Total loss': 0.3612959704051415} | train loss {'Reaction outcome loss': 0.20470503257968012, 'Total loss': 0.20470503257968012}
2023-01-04 01:38:11,085 INFO:     Found new best model at epoch 67
2023-01-04 01:38:11,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:11,086 INFO:     Epoch: 68
2023-01-04 01:38:12,649 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3866934195160866, 'Total loss': 0.3866934195160866} | train loss {'Reaction outcome loss': 0.20290403303271518, 'Total loss': 0.20290403303271518}
2023-01-04 01:38:12,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:12,649 INFO:     Epoch: 69
2023-01-04 01:38:14,230 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3597360869248708, 'Total loss': 0.3597360869248708} | train loss {'Reaction outcome loss': 0.20232147005035717, 'Total loss': 0.20232147005035717}
2023-01-04 01:38:14,230 INFO:     Found new best model at epoch 69
2023-01-04 01:38:14,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:14,231 INFO:     Epoch: 70
2023-01-04 01:38:15,820 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37483775019645693, 'Total loss': 0.37483775019645693} | train loss {'Reaction outcome loss': 0.20293776696949414, 'Total loss': 0.20293776696949414}
2023-01-04 01:38:15,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:15,820 INFO:     Epoch: 71
2023-01-04 01:38:17,431 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39423549473285674, 'Total loss': 0.39423549473285674} | train loss {'Reaction outcome loss': 0.20205013281024614, 'Total loss': 0.20205013281024614}
2023-01-04 01:38:17,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:17,431 INFO:     Epoch: 72
2023-01-04 01:38:19,050 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40663929482301076, 'Total loss': 0.40663929482301076} | train loss {'Reaction outcome loss': 0.1974023517265079, 'Total loss': 0.1974023517265079}
2023-01-04 01:38:19,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:19,050 INFO:     Epoch: 73
2023-01-04 01:38:20,647 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37743103702863057, 'Total loss': 0.37743103702863057} | train loss {'Reaction outcome loss': 0.19745561709978443, 'Total loss': 0.19745561709978443}
2023-01-04 01:38:20,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:20,647 INFO:     Epoch: 74
2023-01-04 01:38:22,238 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3866970797379812, 'Total loss': 0.3866970797379812} | train loss {'Reaction outcome loss': 0.19883811959753867, 'Total loss': 0.19883811959753867}
2023-01-04 01:38:22,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:22,238 INFO:     Epoch: 75
2023-01-04 01:38:23,862 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38191477954387665, 'Total loss': 0.38191477954387665} | train loss {'Reaction outcome loss': 0.20642297239839166, 'Total loss': 0.20642297239839166}
2023-01-04 01:38:23,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:23,863 INFO:     Epoch: 76
2023-01-04 01:38:25,474 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.361076682806015, 'Total loss': 0.361076682806015} | train loss {'Reaction outcome loss': 0.19630083163687284, 'Total loss': 0.19630083163687284}
2023-01-04 01:38:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:25,475 INFO:     Epoch: 77
2023-01-04 01:38:27,052 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3701644062995911, 'Total loss': 0.3701644062995911} | train loss {'Reaction outcome loss': 0.20269420257138987, 'Total loss': 0.20269420257138987}
2023-01-04 01:38:27,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:27,052 INFO:     Epoch: 78
2023-01-04 01:38:28,651 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3795722713073095, 'Total loss': 0.3795722713073095} | train loss {'Reaction outcome loss': 0.19457051133750888, 'Total loss': 0.19457051133750888}
2023-01-04 01:38:28,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:28,652 INFO:     Epoch: 79
2023-01-04 01:38:30,237 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39408678114414214, 'Total loss': 0.39408678114414214} | train loss {'Reaction outcome loss': 0.19176323565931153, 'Total loss': 0.19176323565931153}
2023-01-04 01:38:30,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:30,238 INFO:     Epoch: 80
2023-01-04 01:38:31,819 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35847399731477103, 'Total loss': 0.35847399731477103} | train loss {'Reaction outcome loss': 0.18995005358685402, 'Total loss': 0.18995005358685402}
2023-01-04 01:38:31,820 INFO:     Found new best model at epoch 80
2023-01-04 01:38:31,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:31,821 INFO:     Epoch: 81
2023-01-04 01:38:33,417 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3720592180887858, 'Total loss': 0.3720592180887858} | train loss {'Reaction outcome loss': 0.19104985070685027, 'Total loss': 0.19104985070685027}
2023-01-04 01:38:33,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:33,417 INFO:     Epoch: 82
2023-01-04 01:38:35,015 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3738962839047114, 'Total loss': 0.3738962839047114} | train loss {'Reaction outcome loss': 0.1900228280616263, 'Total loss': 0.1900228280616263}
2023-01-04 01:38:35,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:35,015 INFO:     Epoch: 83
2023-01-04 01:38:36,614 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35913466215133666, 'Total loss': 0.35913466215133666} | train loss {'Reaction outcome loss': 0.21293685994232478, 'Total loss': 0.21293685994232478}
2023-01-04 01:38:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:36,614 INFO:     Epoch: 84
2023-01-04 01:38:38,198 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.388406632343928, 'Total loss': 0.388406632343928} | train loss {'Reaction outcome loss': 0.18706686679523546, 'Total loss': 0.18706686679523546}
2023-01-04 01:38:38,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:38,198 INFO:     Epoch: 85
2023-01-04 01:38:39,780 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35950838029384613, 'Total loss': 0.35950838029384613} | train loss {'Reaction outcome loss': 0.18657137466051726, 'Total loss': 0.18657137466051726}
2023-01-04 01:38:39,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:39,780 INFO:     Epoch: 86
2023-01-04 01:38:41,375 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3874107003211975, 'Total loss': 0.3874107003211975} | train loss {'Reaction outcome loss': 0.1833125118409162, 'Total loss': 0.1833125118409162}
2023-01-04 01:38:41,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:41,375 INFO:     Epoch: 87
2023-01-04 01:38:42,969 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3856545974810918, 'Total loss': 0.3856545974810918} | train loss {'Reaction outcome loss': 0.18563672097482503, 'Total loss': 0.18563672097482503}
2023-01-04 01:38:42,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:42,970 INFO:     Epoch: 88
2023-01-04 01:38:44,564 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38149651090304054, 'Total loss': 0.38149651090304054} | train loss {'Reaction outcome loss': 0.18213546837163766, 'Total loss': 0.18213546837163766}
2023-01-04 01:38:44,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:44,565 INFO:     Epoch: 89
2023-01-04 01:38:46,160 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3745974977811178, 'Total loss': 0.3745974977811178} | train loss {'Reaction outcome loss': 0.18256551891687012, 'Total loss': 0.18256551891687012}
2023-01-04 01:38:46,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:46,160 INFO:     Epoch: 90
2023-01-04 01:38:47,740 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3822701066732407, 'Total loss': 0.3822701066732407} | train loss {'Reaction outcome loss': 0.1822330550726358, 'Total loss': 0.1822330550726358}
2023-01-04 01:38:47,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:47,741 INFO:     Epoch: 91
2023-01-04 01:38:49,331 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39538128475348155, 'Total loss': 0.39538128475348155} | train loss {'Reaction outcome loss': 0.18382752170462324, 'Total loss': 0.18382752170462324}
2023-01-04 01:38:49,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:49,332 INFO:     Epoch: 92
2023-01-04 01:38:50,955 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3671237642566363, 'Total loss': 0.3671237642566363} | train loss {'Reaction outcome loss': 0.18520891845928153, 'Total loss': 0.18520891845928153}
2023-01-04 01:38:50,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:50,956 INFO:     Epoch: 93
2023-01-04 01:38:52,577 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3884511629740397, 'Total loss': 0.3884511629740397} | train loss {'Reaction outcome loss': 0.18522976589240675, 'Total loss': 0.18522976589240675}
2023-01-04 01:38:52,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:52,577 INFO:     Epoch: 94
2023-01-04 01:38:54,199 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3886678074796995, 'Total loss': 0.3886678074796995} | train loss {'Reaction outcome loss': 0.19071601676768152, 'Total loss': 0.19071601676768152}
2023-01-04 01:38:54,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:54,200 INFO:     Epoch: 95
2023-01-04 01:38:55,809 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37980837225914, 'Total loss': 0.37980837225914} | train loss {'Reaction outcome loss': 0.18457690496986776, 'Total loss': 0.18457690496986776}
2023-01-04 01:38:55,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:55,809 INFO:     Epoch: 96
2023-01-04 01:38:57,416 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37232911090056103, 'Total loss': 0.37232911090056103} | train loss {'Reaction outcome loss': 0.17632534363023614, 'Total loss': 0.17632534363023614}
2023-01-04 01:38:57,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:57,416 INFO:     Epoch: 97
2023-01-04 01:38:59,026 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3763323118289312, 'Total loss': 0.3763323118289312} | train loss {'Reaction outcome loss': 0.1771150629268221, 'Total loss': 0.1771150629268221}
2023-01-04 01:38:59,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:38:59,026 INFO:     Epoch: 98
2023-01-04 01:39:00,606 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3854069282611211, 'Total loss': 0.3854069282611211} | train loss {'Reaction outcome loss': 0.17497207468672507, 'Total loss': 0.17497207468672507}
2023-01-04 01:39:00,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:00,607 INFO:     Epoch: 99
2023-01-04 01:39:02,184 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3671909699837367, 'Total loss': 0.3671909699837367} | train loss {'Reaction outcome loss': 0.17427222010361298, 'Total loss': 0.17427222010361298}
2023-01-04 01:39:02,184 INFO:     Best model found after epoch 81 of 100.
2023-01-04 01:39:02,184 INFO:   Done with stage: TRAINING
2023-01-04 01:39:02,184 INFO:   Starting stage: EVALUATION
2023-01-04 01:39:02,313 INFO:   Done with stage: EVALUATION
2023-01-04 01:39:02,313 INFO:   Leaving out SEQ value Fold_1
2023-01-04 01:39:02,326 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:39:02,326 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:39:02,980 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:39:02,980 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:39:03,049 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:39:03,049 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:39:03,049 INFO:     No hyperparam tuning for this model
2023-01-04 01:39:03,049 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:39:03,049 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:39:03,050 INFO:     None feature selector for col prot
2023-01-04 01:39:03,050 INFO:     None feature selector for col prot
2023-01-04 01:39:03,050 INFO:     None feature selector for col prot
2023-01-04 01:39:03,051 INFO:     None feature selector for col chem
2023-01-04 01:39:03,051 INFO:     None feature selector for col chem
2023-01-04 01:39:03,051 INFO:     None feature selector for col chem
2023-01-04 01:39:03,051 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:39:03,051 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:39:03,052 INFO:     Number of params in model 70141
2023-01-04 01:39:03,055 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:39:03,055 INFO:   Starting stage: TRAINING
2023-01-04 01:39:03,098 INFO:     Val loss before train {'Reaction outcome loss': 1.0274620572725932, 'Total loss': 1.0274620572725932}
2023-01-04 01:39:03,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:03,098 INFO:     Epoch: 0
2023-01-04 01:39:04,663 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.679024088382721, 'Total loss': 0.679024088382721} | train loss {'Reaction outcome loss': 0.8408909700612666, 'Total loss': 0.8408909700612666}
2023-01-04 01:39:04,663 INFO:     Found new best model at epoch 0
2023-01-04 01:39:04,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:04,664 INFO:     Epoch: 1
2023-01-04 01:39:06,230 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5697066823641459, 'Total loss': 0.5697066823641459} | train loss {'Reaction outcome loss': 0.594761588651201, 'Total loss': 0.594761588651201}
2023-01-04 01:39:06,230 INFO:     Found new best model at epoch 1
2023-01-04 01:39:06,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:06,231 INFO:     Epoch: 2
2023-01-04 01:39:07,811 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5297448436419169, 'Total loss': 0.5297448436419169} | train loss {'Reaction outcome loss': 0.5180124322465365, 'Total loss': 0.5180124322465365}
2023-01-04 01:39:07,812 INFO:     Found new best model at epoch 2
2023-01-04 01:39:07,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:07,813 INFO:     Epoch: 3
2023-01-04 01:39:09,392 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5312693357467652, 'Total loss': 0.5312693357467652} | train loss {'Reaction outcome loss': 0.4842850920082866, 'Total loss': 0.4842850920082866}
2023-01-04 01:39:09,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:09,392 INFO:     Epoch: 4
2023-01-04 01:39:11,012 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49887228608131406, 'Total loss': 0.49887228608131406} | train loss {'Reaction outcome loss': 0.45838182149589923, 'Total loss': 0.45838182149589923}
2023-01-04 01:39:11,012 INFO:     Found new best model at epoch 4
2023-01-04 01:39:11,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:11,013 INFO:     Epoch: 5
2023-01-04 01:39:12,592 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47423381408055626, 'Total loss': 0.47423381408055626} | train loss {'Reaction outcome loss': 0.4397543290009101, 'Total loss': 0.4397543290009101}
2023-01-04 01:39:12,592 INFO:     Found new best model at epoch 5
2023-01-04 01:39:12,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:12,593 INFO:     Epoch: 6
2023-01-04 01:39:14,181 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.500921897093455, 'Total loss': 0.500921897093455} | train loss {'Reaction outcome loss': 0.42823548901124275, 'Total loss': 0.42823548901124275}
2023-01-04 01:39:14,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:14,181 INFO:     Epoch: 7
2023-01-04 01:39:15,753 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4860479434331258, 'Total loss': 0.4860479434331258} | train loss {'Reaction outcome loss': 0.41687098194075667, 'Total loss': 0.41687098194075667}
2023-01-04 01:39:15,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:15,753 INFO:     Epoch: 8
2023-01-04 01:39:17,344 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4722280999024709, 'Total loss': 0.4722280999024709} | train loss {'Reaction outcome loss': 0.4040220663747818, 'Total loss': 0.4040220663747818}
2023-01-04 01:39:17,344 INFO:     Found new best model at epoch 8
2023-01-04 01:39:17,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:17,345 INFO:     Epoch: 9
2023-01-04 01:39:18,934 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4590967694918315, 'Total loss': 0.4590967694918315} | train loss {'Reaction outcome loss': 0.3919100304120693, 'Total loss': 0.3919100304120693}
2023-01-04 01:39:18,934 INFO:     Found new best model at epoch 9
2023-01-04 01:39:18,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:18,935 INFO:     Epoch: 10
2023-01-04 01:39:20,524 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46351974209149677, 'Total loss': 0.46351974209149677} | train loss {'Reaction outcome loss': 0.3880398630744953, 'Total loss': 0.3880398630744953}
2023-01-04 01:39:20,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:20,525 INFO:     Epoch: 11
2023-01-04 01:39:22,133 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4520813326040904, 'Total loss': 0.4520813326040904} | train loss {'Reaction outcome loss': 0.37520031105942914, 'Total loss': 0.37520031105942914}
2023-01-04 01:39:22,133 INFO:     Found new best model at epoch 11
2023-01-04 01:39:22,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:22,134 INFO:     Epoch: 12
2023-01-04 01:39:23,735 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4594764510790507, 'Total loss': 0.4594764510790507} | train loss {'Reaction outcome loss': 0.3698407075489345, 'Total loss': 0.3698407075489345}
2023-01-04 01:39:23,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:23,735 INFO:     Epoch: 13
2023-01-04 01:39:25,344 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4488880495230357, 'Total loss': 0.4488880495230357} | train loss {'Reaction outcome loss': 0.36395355571057997, 'Total loss': 0.36395355571057997}
2023-01-04 01:39:25,344 INFO:     Found new best model at epoch 13
2023-01-04 01:39:25,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:25,345 INFO:     Epoch: 14
2023-01-04 01:39:26,986 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45604992111523945, 'Total loss': 0.45604992111523945} | train loss {'Reaction outcome loss': 0.3564327372966901, 'Total loss': 0.3564327372966901}
2023-01-04 01:39:26,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:26,987 INFO:     Epoch: 15
2023-01-04 01:39:28,636 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4595744719107946, 'Total loss': 0.4595744719107946} | train loss {'Reaction outcome loss': 0.3507140589931953, 'Total loss': 0.3507140589931953}
2023-01-04 01:39:28,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:28,636 INFO:     Epoch: 16
2023-01-04 01:39:30,255 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44259343842665355, 'Total loss': 0.44259343842665355} | train loss {'Reaction outcome loss': 0.3417579645216735, 'Total loss': 0.3417579645216735}
2023-01-04 01:39:30,255 INFO:     Found new best model at epoch 16
2023-01-04 01:39:30,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:30,256 INFO:     Epoch: 17
2023-01-04 01:39:31,820 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43496267596880595, 'Total loss': 0.43496267596880595} | train loss {'Reaction outcome loss': 0.33858192779218266, 'Total loss': 0.33858192779218266}
2023-01-04 01:39:31,821 INFO:     Found new best model at epoch 17
2023-01-04 01:39:31,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:31,822 INFO:     Epoch: 18
2023-01-04 01:39:33,394 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43882000843683877, 'Total loss': 0.43882000843683877} | train loss {'Reaction outcome loss': 0.33076626367435075, 'Total loss': 0.33076626367435075}
2023-01-04 01:39:33,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:33,394 INFO:     Epoch: 19
2023-01-04 01:39:34,982 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44784578879674275, 'Total loss': 0.44784578879674275} | train loss {'Reaction outcome loss': 0.3236752636701145, 'Total loss': 0.3236752636701145}
2023-01-04 01:39:34,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:34,983 INFO:     Epoch: 20
2023-01-04 01:39:36,573 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4382768968741099, 'Total loss': 0.4382768968741099} | train loss {'Reaction outcome loss': 0.3224286649484133, 'Total loss': 0.3224286649484133}
2023-01-04 01:39:36,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:36,573 INFO:     Epoch: 21
2023-01-04 01:39:38,162 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4441962440808614, 'Total loss': 0.4441962440808614} | train loss {'Reaction outcome loss': 0.3196840616941884, 'Total loss': 0.3196840616941884}
2023-01-04 01:39:38,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:38,163 INFO:     Epoch: 22
2023-01-04 01:39:39,753 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44221045076847076, 'Total loss': 0.44221045076847076} | train loss {'Reaction outcome loss': 0.3077567307332504, 'Total loss': 0.3077567307332504}
2023-01-04 01:39:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:39,753 INFO:     Epoch: 23
2023-01-04 01:39:41,327 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4339301913976669, 'Total loss': 0.4339301913976669} | train loss {'Reaction outcome loss': 0.30391396380930574, 'Total loss': 0.30391396380930574}
2023-01-04 01:39:41,327 INFO:     Found new best model at epoch 23
2023-01-04 01:39:41,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:41,328 INFO:     Epoch: 24
2023-01-04 01:39:42,952 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42758373022079466, 'Total loss': 0.42758373022079466} | train loss {'Reaction outcome loss': 0.299994862516937, 'Total loss': 0.299994862516937}
2023-01-04 01:39:42,952 INFO:     Found new best model at epoch 24
2023-01-04 01:39:42,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:42,954 INFO:     Epoch: 25
2023-01-04 01:39:44,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4396198014418284, 'Total loss': 0.4396198014418284} | train loss {'Reaction outcome loss': 0.29431230465543456, 'Total loss': 0.29431230465543456}
2023-01-04 01:39:44,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:44,616 INFO:     Epoch: 26
2023-01-04 01:39:46,278 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42233163913091026, 'Total loss': 0.42233163913091026} | train loss {'Reaction outcome loss': 0.28934697632465267, 'Total loss': 0.28934697632465267}
2023-01-04 01:39:46,278 INFO:     Found new best model at epoch 26
2023-01-04 01:39:46,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:46,279 INFO:     Epoch: 27
2023-01-04 01:39:47,907 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4226946512858073, 'Total loss': 0.4226946512858073} | train loss {'Reaction outcome loss': 0.2877320165718919, 'Total loss': 0.2877320165718919}
2023-01-04 01:39:47,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:47,907 INFO:     Epoch: 28
2023-01-04 01:39:49,519 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4152312368154526, 'Total loss': 0.4152312368154526} | train loss {'Reaction outcome loss': 0.2828319891612383, 'Total loss': 0.2828319891612383}
2023-01-04 01:39:49,519 INFO:     Found new best model at epoch 28
2023-01-04 01:39:49,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:49,520 INFO:     Epoch: 29
2023-01-04 01:39:51,120 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41405377388000486, 'Total loss': 0.41405377388000486} | train loss {'Reaction outcome loss': 0.27842351195041387, 'Total loss': 0.27842351195041387}
2023-01-04 01:39:51,120 INFO:     Found new best model at epoch 29
2023-01-04 01:39:51,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:51,121 INFO:     Epoch: 30
2023-01-04 01:39:52,752 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40286062359809877, 'Total loss': 0.40286062359809877} | train loss {'Reaction outcome loss': 0.2751994019212282, 'Total loss': 0.2751994019212282}
2023-01-04 01:39:52,752 INFO:     Found new best model at epoch 30
2023-01-04 01:39:52,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:52,753 INFO:     Epoch: 31
2023-01-04 01:39:54,388 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40717602769533795, 'Total loss': 0.40717602769533795} | train loss {'Reaction outcome loss': 0.273111805418486, 'Total loss': 0.273111805418486}
2023-01-04 01:39:54,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:54,388 INFO:     Epoch: 32
2023-01-04 01:39:56,006 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43743380904197693, 'Total loss': 0.43743380904197693} | train loss {'Reaction outcome loss': 0.264962693778005, 'Total loss': 0.264962693778005}
2023-01-04 01:39:56,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:56,006 INFO:     Epoch: 33
2023-01-04 01:39:57,639 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42207155128320056, 'Total loss': 0.42207155128320056} | train loss {'Reaction outcome loss': 0.2637062400467255, 'Total loss': 0.2637062400467255}
2023-01-04 01:39:57,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:57,639 INFO:     Epoch: 34
2023-01-04 01:39:59,215 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45196134050687153, 'Total loss': 0.45196134050687153} | train loss {'Reaction outcome loss': 0.2601272243782001, 'Total loss': 0.2601272243782001}
2023-01-04 01:39:59,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:39:59,215 INFO:     Epoch: 35
2023-01-04 01:40:00,789 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4018315523862839, 'Total loss': 0.4018315523862839} | train loss {'Reaction outcome loss': 0.25888037814529263, 'Total loss': 0.25888037814529263}
2023-01-04 01:40:00,790 INFO:     Found new best model at epoch 35
2023-01-04 01:40:00,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:00,790 INFO:     Epoch: 36
2023-01-04 01:40:02,384 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4025254120429357, 'Total loss': 0.4025254120429357} | train loss {'Reaction outcome loss': 0.2543806454316283, 'Total loss': 0.2543806454316283}
2023-01-04 01:40:02,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:02,384 INFO:     Epoch: 37
2023-01-04 01:40:03,976 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44050305684407554, 'Total loss': 0.44050305684407554} | train loss {'Reaction outcome loss': 0.250636576263207, 'Total loss': 0.250636576263207}
2023-01-04 01:40:03,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:03,976 INFO:     Epoch: 38
2023-01-04 01:40:05,568 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4236007610956828, 'Total loss': 0.4236007610956828} | train loss {'Reaction outcome loss': 0.2485426483196626, 'Total loss': 0.2485426483196626}
2023-01-04 01:40:05,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:05,568 INFO:     Epoch: 39
2023-01-04 01:40:07,161 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43078619440396626, 'Total loss': 0.43078619440396626} | train loss {'Reaction outcome loss': 0.24499345711260306, 'Total loss': 0.24499345711260306}
2023-01-04 01:40:07,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:07,163 INFO:     Epoch: 40
2023-01-04 01:40:08,761 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4305401384830475, 'Total loss': 0.4305401384830475} | train loss {'Reaction outcome loss': 0.24247788763740033, 'Total loss': 0.24247788763740033}
2023-01-04 01:40:08,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:08,761 INFO:     Epoch: 41
2023-01-04 01:40:09,893 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43501535852750145, 'Total loss': 0.43501535852750145} | train loss {'Reaction outcome loss': 0.23971508693732863, 'Total loss': 0.23971508693732863}
2023-01-04 01:40:09,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:09,894 INFO:     Epoch: 42
2023-01-04 01:40:10,953 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4220922440290451, 'Total loss': 0.4220922440290451} | train loss {'Reaction outcome loss': 0.2384320695207967, 'Total loss': 0.2384320695207967}
2023-01-04 01:40:10,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:10,953 INFO:     Epoch: 43
2023-01-04 01:40:12,009 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4173936645189921, 'Total loss': 0.4173936645189921} | train loss {'Reaction outcome loss': 0.23804844056080648, 'Total loss': 0.23804844056080648}
2023-01-04 01:40:12,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:12,010 INFO:     Epoch: 44
2023-01-04 01:40:13,065 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45631197293599446, 'Total loss': 0.45631197293599446} | train loss {'Reaction outcome loss': 0.23418696131293604, 'Total loss': 0.23418696131293604}
2023-01-04 01:40:13,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:13,065 INFO:     Epoch: 45
2023-01-04 01:40:14,627 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41563661595185597, 'Total loss': 0.41563661595185597} | train loss {'Reaction outcome loss': 0.23003603651633728, 'Total loss': 0.23003603651633728}
2023-01-04 01:40:14,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:14,628 INFO:     Epoch: 46
2023-01-04 01:40:16,212 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4355694482723872, 'Total loss': 0.4355694482723872} | train loss {'Reaction outcome loss': 0.2273126427097705, 'Total loss': 0.2273126427097705}
2023-01-04 01:40:16,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:16,212 INFO:     Epoch: 47
2023-01-04 01:40:17,836 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4186026235421499, 'Total loss': 0.4186026235421499} | train loss {'Reaction outcome loss': 0.22406835085480387, 'Total loss': 0.22406835085480387}
2023-01-04 01:40:17,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:17,836 INFO:     Epoch: 48
2023-01-04 01:40:19,461 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42238017320632937, 'Total loss': 0.42238017320632937} | train loss {'Reaction outcome loss': 0.2216147609981725, 'Total loss': 0.2216147609981725}
2023-01-04 01:40:19,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:19,461 INFO:     Epoch: 49
2023-01-04 01:40:21,076 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42179706593354543, 'Total loss': 0.42179706593354543} | train loss {'Reaction outcome loss': 0.21915305739241667, 'Total loss': 0.21915305739241667}
2023-01-04 01:40:21,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:21,076 INFO:     Epoch: 50
2023-01-04 01:40:22,689 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41802583932876586, 'Total loss': 0.41802583932876586} | train loss {'Reaction outcome loss': 0.22058444556550702, 'Total loss': 0.22058444556550702}
2023-01-04 01:40:22,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:22,689 INFO:     Epoch: 51
2023-01-04 01:40:24,292 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40963483502467474, 'Total loss': 0.40963483502467474} | train loss {'Reaction outcome loss': 0.21651106452254285, 'Total loss': 0.21651106452254285}
2023-01-04 01:40:24,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:24,292 INFO:     Epoch: 52
2023-01-04 01:40:25,912 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43329682350158694, 'Total loss': 0.43329682350158694} | train loss {'Reaction outcome loss': 0.21566181921987637, 'Total loss': 0.21566181921987637}
2023-01-04 01:40:25,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:25,913 INFO:     Epoch: 53
2023-01-04 01:40:27,534 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42999529242515566, 'Total loss': 0.42999529242515566} | train loss {'Reaction outcome loss': 0.21438004967142438, 'Total loss': 0.21438004967142438}
2023-01-04 01:40:27,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:27,535 INFO:     Epoch: 54
2023-01-04 01:40:29,158 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4240468064943949, 'Total loss': 0.4240468064943949} | train loss {'Reaction outcome loss': 0.21242744416214418, 'Total loss': 0.21242744416214418}
2023-01-04 01:40:29,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:29,158 INFO:     Epoch: 55
2023-01-04 01:40:30,784 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44040361742178596, 'Total loss': 0.44040361742178596} | train loss {'Reaction outcome loss': 0.21188952317337997, 'Total loss': 0.21188952317337997}
2023-01-04 01:40:30,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:30,784 INFO:     Epoch: 56
2023-01-04 01:40:32,376 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4088966657718023, 'Total loss': 0.4088966657718023} | train loss {'Reaction outcome loss': 0.2079769966489487, 'Total loss': 0.2079769966489487}
2023-01-04 01:40:32,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:32,377 INFO:     Epoch: 57
2023-01-04 01:40:34,002 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4337350130081177, 'Total loss': 0.4337350130081177} | train loss {'Reaction outcome loss': 0.20827440568667743, 'Total loss': 0.20827440568667743}
2023-01-04 01:40:34,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:34,002 INFO:     Epoch: 58
2023-01-04 01:40:35,623 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4145160287618637, 'Total loss': 0.4145160287618637} | train loss {'Reaction outcome loss': 0.2043398411290094, 'Total loss': 0.2043398411290094}
2023-01-04 01:40:35,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:35,623 INFO:     Epoch: 59
2023-01-04 01:40:37,252 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4310707151889801, 'Total loss': 0.4310707151889801} | train loss {'Reaction outcome loss': 0.20113415472071106, 'Total loss': 0.20113415472071106}
2023-01-04 01:40:37,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:37,253 INFO:     Epoch: 60
2023-01-04 01:40:38,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41040814320246377, 'Total loss': 0.41040814320246377} | train loss {'Reaction outcome loss': 0.2010941430111699, 'Total loss': 0.2010941430111699}
2023-01-04 01:40:38,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:38,843 INFO:     Epoch: 61
2023-01-04 01:40:40,421 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.429032626748085, 'Total loss': 0.429032626748085} | train loss {'Reaction outcome loss': 0.2004938874282137, 'Total loss': 0.2004938874282137}
2023-01-04 01:40:40,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:40,422 INFO:     Epoch: 62
2023-01-04 01:40:42,016 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43647086719671885, 'Total loss': 0.43647086719671885} | train loss {'Reaction outcome loss': 0.2003109739533207, 'Total loss': 0.2003109739533207}
2023-01-04 01:40:42,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:42,017 INFO:     Epoch: 63
2023-01-04 01:40:43,606 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4227401812871297, 'Total loss': 0.4227401812871297} | train loss {'Reaction outcome loss': 0.19533131358996575, 'Total loss': 0.19533131358996575}
2023-01-04 01:40:43,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:43,607 INFO:     Epoch: 64
2023-01-04 01:40:45,196 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.417484250664711, 'Total loss': 0.417484250664711} | train loss {'Reaction outcome loss': 0.196942473482852, 'Total loss': 0.196942473482852}
2023-01-04 01:40:45,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:45,197 INFO:     Epoch: 65
2023-01-04 01:40:46,786 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4436119462052981, 'Total loss': 0.4436119462052981} | train loss {'Reaction outcome loss': 0.19301057905012503, 'Total loss': 0.19301057905012503}
2023-01-04 01:40:46,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:46,786 INFO:     Epoch: 66
2023-01-04 01:40:48,404 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41691114405790963, 'Total loss': 0.41691114405790963} | train loss {'Reaction outcome loss': 0.19233487826178147, 'Total loss': 0.19233487826178147}
2023-01-04 01:40:48,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:48,404 INFO:     Epoch: 67
2023-01-04 01:40:50,002 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4369508961836497, 'Total loss': 0.4369508961836497} | train loss {'Reaction outcome loss': 0.1919487178063297, 'Total loss': 0.1919487178063297}
2023-01-04 01:40:50,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:50,002 INFO:     Epoch: 68
2023-01-04 01:40:51,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44760927160580954, 'Total loss': 0.44760927160580954} | train loss {'Reaction outcome loss': 0.19211551802375956, 'Total loss': 0.19211551802375956}
2023-01-04 01:40:51,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:51,576 INFO:     Epoch: 69
2023-01-04 01:40:53,163 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43915167848269143, 'Total loss': 0.43915167848269143} | train loss {'Reaction outcome loss': 0.18807054411086754, 'Total loss': 0.18807054411086754}
2023-01-04 01:40:53,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:53,163 INFO:     Epoch: 70
2023-01-04 01:40:54,783 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4424177239338557, 'Total loss': 0.4424177239338557} | train loss {'Reaction outcome loss': 0.18812821681395703, 'Total loss': 0.18812821681395703}
2023-01-04 01:40:54,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:54,783 INFO:     Epoch: 71
2023-01-04 01:40:56,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42150335063536964, 'Total loss': 0.42150335063536964} | train loss {'Reaction outcome loss': 0.18524120213797965, 'Total loss': 0.18524120213797965}
2023-01-04 01:40:56,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:56,368 INFO:     Epoch: 72
2023-01-04 01:40:57,986 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4353638013203939, 'Total loss': 0.4353638013203939} | train loss {'Reaction outcome loss': 0.1835266040946843, 'Total loss': 0.1835266040946843}
2023-01-04 01:40:57,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:57,987 INFO:     Epoch: 73
2023-01-04 01:40:59,560 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4130897869666417, 'Total loss': 0.4130897869666417} | train loss {'Reaction outcome loss': 0.18458724081637742, 'Total loss': 0.18458724081637742}
2023-01-04 01:40:59,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:40:59,560 INFO:     Epoch: 74
2023-01-04 01:41:01,149 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46107946236928304, 'Total loss': 0.46107946236928304} | train loss {'Reaction outcome loss': 0.18312618046732404, 'Total loss': 0.18312618046732404}
2023-01-04 01:41:01,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:01,149 INFO:     Epoch: 75
2023-01-04 01:41:02,766 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43072627584139506, 'Total loss': 0.43072627584139506} | train loss {'Reaction outcome loss': 0.18299451237122621, 'Total loss': 0.18299451237122621}
2023-01-04 01:41:02,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:02,766 INFO:     Epoch: 76
2023-01-04 01:41:04,373 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44107853968938193, 'Total loss': 0.44107853968938193} | train loss {'Reaction outcome loss': 0.18196250174230005, 'Total loss': 0.18196250174230005}
2023-01-04 01:41:04,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:04,373 INFO:     Epoch: 77
2023-01-04 01:41:05,963 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4246492991844813, 'Total loss': 0.4246492991844813} | train loss {'Reaction outcome loss': 0.1822859393474916, 'Total loss': 0.1822859393474916}
2023-01-04 01:41:05,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:05,964 INFO:     Epoch: 78
2023-01-04 01:41:07,544 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43183026611804964, 'Total loss': 0.43183026611804964} | train loss {'Reaction outcome loss': 0.17872987170197902, 'Total loss': 0.17872987170197902}
2023-01-04 01:41:07,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:07,545 INFO:     Epoch: 79
2023-01-04 01:41:09,115 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4320280214150747, 'Total loss': 0.4320280214150747} | train loss {'Reaction outcome loss': 0.18668048634477283, 'Total loss': 0.18668048634477283}
2023-01-04 01:41:09,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:09,115 INFO:     Epoch: 80
2023-01-04 01:41:10,700 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4834721565246582, 'Total loss': 0.4834721565246582} | train loss {'Reaction outcome loss': 0.19304466661086064, 'Total loss': 0.19304466661086064}
2023-01-04 01:41:10,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:10,701 INFO:     Epoch: 81
2023-01-04 01:41:12,286 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4288297176361084, 'Total loss': 0.4288297176361084} | train loss {'Reaction outcome loss': 0.17814846176955051, 'Total loss': 0.17814846176955051}
2023-01-04 01:41:12,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:12,287 INFO:     Epoch: 82
2023-01-04 01:41:13,872 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4336215873559316, 'Total loss': 0.4336215873559316} | train loss {'Reaction outcome loss': 0.1734505051458457, 'Total loss': 0.1734505051458457}
2023-01-04 01:41:13,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:13,873 INFO:     Epoch: 83
2023-01-04 01:41:15,457 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4614599168300629, 'Total loss': 0.4614599168300629} | train loss {'Reaction outcome loss': 0.17473078326008323, 'Total loss': 0.17473078326008323}
2023-01-04 01:41:15,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:15,457 INFO:     Epoch: 84
2023-01-04 01:41:17,019 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46887721021970113, 'Total loss': 0.46887721021970113} | train loss {'Reaction outcome loss': 0.181977111292814, 'Total loss': 0.181977111292814}
2023-01-04 01:41:17,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:17,019 INFO:     Epoch: 85
2023-01-04 01:41:18,601 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46893335282802584, 'Total loss': 0.46893335282802584} | train loss {'Reaction outcome loss': 0.18962525275360415, 'Total loss': 0.18962525275360415}
2023-01-04 01:41:18,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:18,601 INFO:     Epoch: 86
2023-01-04 01:41:20,189 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4568967888752619, 'Total loss': 0.4568967888752619} | train loss {'Reaction outcome loss': 0.18175419921349006, 'Total loss': 0.18175419921349006}
2023-01-04 01:41:20,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:20,190 INFO:     Epoch: 87
2023-01-04 01:41:21,776 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4569062660137812, 'Total loss': 0.4569062660137812} | train loss {'Reaction outcome loss': 0.16805691539965387, 'Total loss': 0.16805691539965387}
2023-01-04 01:41:21,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:21,776 INFO:     Epoch: 88
2023-01-04 01:41:23,364 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45173739542563757, 'Total loss': 0.45173739542563757} | train loss {'Reaction outcome loss': 0.1690429473950433, 'Total loss': 0.1690429473950433}
2023-01-04 01:41:23,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:23,364 INFO:     Epoch: 89
2023-01-04 01:41:24,938 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4490502327680588, 'Total loss': 0.4490502327680588} | train loss {'Reaction outcome loss': 0.16959551523751193, 'Total loss': 0.16959551523751193}
2023-01-04 01:41:24,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:24,939 INFO:     Epoch: 90
2023-01-04 01:41:26,528 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45581273635228475, 'Total loss': 0.45581273635228475} | train loss {'Reaction outcome loss': 0.17481211419014828, 'Total loss': 0.17481211419014828}
2023-01-04 01:41:26,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:26,528 INFO:     Epoch: 91
2023-01-04 01:41:28,147 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4379608323176702, 'Total loss': 0.4379608323176702} | train loss {'Reaction outcome loss': 0.1814989610144909, 'Total loss': 0.1814989610144909}
2023-01-04 01:41:28,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:28,147 INFO:     Epoch: 92
2023-01-04 01:41:29,734 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44858861168225606, 'Total loss': 0.44858861168225606} | train loss {'Reaction outcome loss': 0.1675902416734681, 'Total loss': 0.1675902416734681}
2023-01-04 01:41:29,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:29,735 INFO:     Epoch: 93
2023-01-04 01:41:31,355 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4363437672456106, 'Total loss': 0.4363437672456106} | train loss {'Reaction outcome loss': 0.16769012669101357, 'Total loss': 0.16769012669101357}
2023-01-04 01:41:31,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:31,356 INFO:     Epoch: 94
2023-01-04 01:41:32,941 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44649968643983207, 'Total loss': 0.44649968643983207} | train loss {'Reaction outcome loss': 0.1705117364660997, 'Total loss': 0.1705117364660997}
2023-01-04 01:41:32,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:32,942 INFO:     Epoch: 95
2023-01-04 01:41:34,531 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44215815762678784, 'Total loss': 0.44215815762678784} | train loss {'Reaction outcome loss': 0.16641139479158312, 'Total loss': 0.16641139479158312}
2023-01-04 01:41:34,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:34,531 INFO:     Epoch: 96
2023-01-04 01:41:36,112 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4255782812833786, 'Total loss': 0.4255782812833786} | train loss {'Reaction outcome loss': 0.16559847192568838, 'Total loss': 0.16559847192568838}
2023-01-04 01:41:36,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:36,113 INFO:     Epoch: 97
2023-01-04 01:41:37,735 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4475237299998601, 'Total loss': 0.4475237299998601} | train loss {'Reaction outcome loss': 0.1737024382269685, 'Total loss': 0.1737024382269685}
2023-01-04 01:41:37,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:37,736 INFO:     Epoch: 98
2023-01-04 01:41:39,324 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4452295775214831, 'Total loss': 0.4452295775214831} | train loss {'Reaction outcome loss': 0.182328290724452, 'Total loss': 0.182328290724452}
2023-01-04 01:41:39,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:39,324 INFO:     Epoch: 99
2023-01-04 01:41:40,948 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4342001885175705, 'Total loss': 0.4342001885175705} | train loss {'Reaction outcome loss': 0.1835975330862878, 'Total loss': 0.1835975330862878}
2023-01-04 01:41:40,948 INFO:     Best model found after epoch 36 of 100.
2023-01-04 01:41:40,949 INFO:   Done with stage: TRAINING
2023-01-04 01:41:40,949 INFO:   Starting stage: EVALUATION
2023-01-04 01:41:41,078 INFO:   Done with stage: EVALUATION
2023-01-04 01:41:41,078 INFO:   Leaving out SEQ value Fold_2
2023-01-04 01:41:41,091 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 01:41:41,091 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:41:41,737 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:41:41,738 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:41:41,806 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:41:41,806 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:41:41,807 INFO:     No hyperparam tuning for this model
2023-01-04 01:41:41,807 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:41:41,807 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:41:41,807 INFO:     None feature selector for col prot
2023-01-04 01:41:41,808 INFO:     None feature selector for col prot
2023-01-04 01:41:41,808 INFO:     None feature selector for col prot
2023-01-04 01:41:41,808 INFO:     None feature selector for col chem
2023-01-04 01:41:41,808 INFO:     None feature selector for col chem
2023-01-04 01:41:41,808 INFO:     None feature selector for col chem
2023-01-04 01:41:41,808 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:41:41,808 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:41:41,809 INFO:     Number of params in model 70141
2023-01-04 01:41:41,813 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:41:41,813 INFO:   Starting stage: TRAINING
2023-01-04 01:41:41,856 INFO:     Val loss before train {'Reaction outcome loss': 1.0455407579739888, 'Total loss': 1.0455407579739888}
2023-01-04 01:41:41,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:41,857 INFO:     Epoch: 0
2023-01-04 01:41:43,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7217515627543132, 'Total loss': 0.7217515627543132} | train loss {'Reaction outcome loss': 0.8267522269771213, 'Total loss': 0.8267522269771213}
2023-01-04 01:41:43,410 INFO:     Found new best model at epoch 0
2023-01-04 01:41:43,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:43,411 INFO:     Epoch: 1
2023-01-04 01:41:44,977 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6019200682640076, 'Total loss': 0.6019200682640076} | train loss {'Reaction outcome loss': 0.5995693384181886, 'Total loss': 0.5995693384181886}
2023-01-04 01:41:44,978 INFO:     Found new best model at epoch 1
2023-01-04 01:41:44,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:44,979 INFO:     Epoch: 2
2023-01-04 01:41:46,555 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5612907707691193, 'Total loss': 0.5612907707691193} | train loss {'Reaction outcome loss': 0.5220484843839219, 'Total loss': 0.5220484843839219}
2023-01-04 01:41:46,555 INFO:     Found new best model at epoch 2
2023-01-04 01:41:46,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:46,556 INFO:     Epoch: 3
2023-01-04 01:41:48,137 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5450937569141387, 'Total loss': 0.5450937569141387} | train loss {'Reaction outcome loss': 0.4837577297683164, 'Total loss': 0.4837577297683164}
2023-01-04 01:41:48,137 INFO:     Found new best model at epoch 3
2023-01-04 01:41:48,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:48,138 INFO:     Epoch: 4
2023-01-04 01:41:49,719 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5048682769139607, 'Total loss': 0.5048682769139607} | train loss {'Reaction outcome loss': 0.45255103423481896, 'Total loss': 0.45255103423481896}
2023-01-04 01:41:49,719 INFO:     Found new best model at epoch 4
2023-01-04 01:41:49,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:49,720 INFO:     Epoch: 5
2023-01-04 01:41:51,287 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49232536753018696, 'Total loss': 0.49232536753018696} | train loss {'Reaction outcome loss': 0.4344231951913554, 'Total loss': 0.4344231951913554}
2023-01-04 01:41:51,288 INFO:     Found new best model at epoch 5
2023-01-04 01:41:51,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:51,289 INFO:     Epoch: 6
2023-01-04 01:41:52,841 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4828384439150492, 'Total loss': 0.4828384439150492} | train loss {'Reaction outcome loss': 0.4198199360471069, 'Total loss': 0.4198199360471069}
2023-01-04 01:41:52,842 INFO:     Found new best model at epoch 6
2023-01-04 01:41:52,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:52,843 INFO:     Epoch: 7
2023-01-04 01:41:54,417 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4736611088116964, 'Total loss': 0.4736611088116964} | train loss {'Reaction outcome loss': 0.40793283414709697, 'Total loss': 0.40793283414709697}
2023-01-04 01:41:54,417 INFO:     Found new best model at epoch 7
2023-01-04 01:41:54,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:54,418 INFO:     Epoch: 8
2023-01-04 01:41:55,989 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4827284276485443, 'Total loss': 0.4827284276485443} | train loss {'Reaction outcome loss': 0.3969045800221709, 'Total loss': 0.3969045800221709}
2023-01-04 01:41:55,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:55,990 INFO:     Epoch: 9
2023-01-04 01:41:57,563 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47531675100326537, 'Total loss': 0.47531675100326537} | train loss {'Reaction outcome loss': 0.3882871934454956, 'Total loss': 0.3882871934454956}
2023-01-04 01:41:57,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:57,563 INFO:     Epoch: 10
2023-01-04 01:41:59,136 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45343882938226066, 'Total loss': 0.45343882938226066} | train loss {'Reaction outcome loss': 0.3794259445557555, 'Total loss': 0.3794259445557555}
2023-01-04 01:41:59,137 INFO:     Found new best model at epoch 10
2023-01-04 01:41:59,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:41:59,137 INFO:     Epoch: 11
2023-01-04 01:42:00,694 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45936472217241925, 'Total loss': 0.45936472217241925} | train loss {'Reaction outcome loss': 0.3703698063671807, 'Total loss': 0.3703698063671807}
2023-01-04 01:42:00,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:00,694 INFO:     Epoch: 12
2023-01-04 01:42:02,260 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4684085687001546, 'Total loss': 0.4684085687001546} | train loss {'Reaction outcome loss': 0.3617238690428463, 'Total loss': 0.3617238690428463}
2023-01-04 01:42:02,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:02,261 INFO:     Epoch: 13
2023-01-04 01:42:03,867 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4702718963225683, 'Total loss': 0.4702718963225683} | train loss {'Reaction outcome loss': 0.35884556084216296, 'Total loss': 0.35884556084216296}
2023-01-04 01:42:03,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:03,868 INFO:     Epoch: 14
2023-01-04 01:42:05,443 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45311211546262103, 'Total loss': 0.45311211546262103} | train loss {'Reaction outcome loss': 0.34999832404511316, 'Total loss': 0.34999832404511316}
2023-01-04 01:42:05,444 INFO:     Found new best model at epoch 14
2023-01-04 01:42:05,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:05,444 INFO:     Epoch: 15
2023-01-04 01:42:07,050 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46938063700993854, 'Total loss': 0.46938063700993854} | train loss {'Reaction outcome loss': 0.3434008836964548, 'Total loss': 0.3434008836964548}
2023-01-04 01:42:07,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:07,050 INFO:     Epoch: 16
2023-01-04 01:42:08,654 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45217660864194237, 'Total loss': 0.45217660864194237} | train loss {'Reaction outcome loss': 0.3404046173988681, 'Total loss': 0.3404046173988681}
2023-01-04 01:42:08,655 INFO:     Found new best model at epoch 16
2023-01-04 01:42:08,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:08,655 INFO:     Epoch: 17
2023-01-04 01:42:10,224 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45704223215579987, 'Total loss': 0.45704223215579987} | train loss {'Reaction outcome loss': 0.33425908704926244, 'Total loss': 0.33425908704926244}
2023-01-04 01:42:10,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:10,224 INFO:     Epoch: 18
2023-01-04 01:42:11,821 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43573556542396547, 'Total loss': 0.43573556542396547} | train loss {'Reaction outcome loss': 0.3274984987991633, 'Total loss': 0.3274984987991633}
2023-01-04 01:42:11,821 INFO:     Found new best model at epoch 18
2023-01-04 01:42:11,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:11,822 INFO:     Epoch: 19
2023-01-04 01:42:13,390 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4549699534972509, 'Total loss': 0.4549699534972509} | train loss {'Reaction outcome loss': 0.32447175984526727, 'Total loss': 0.32447175984526727}
2023-01-04 01:42:13,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:13,390 INFO:     Epoch: 20
2023-01-04 01:42:14,997 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4480300575494766, 'Total loss': 0.4480300575494766} | train loss {'Reaction outcome loss': 0.3178934589192107, 'Total loss': 0.3178934589192107}
2023-01-04 01:42:14,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:14,999 INFO:     Epoch: 21
2023-01-04 01:42:16,569 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47395448287328085, 'Total loss': 0.47395448287328085} | train loss {'Reaction outcome loss': 0.31660970341373273, 'Total loss': 0.31660970341373273}
2023-01-04 01:42:16,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:16,569 INFO:     Epoch: 22
2023-01-04 01:42:18,162 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4333500385284424, 'Total loss': 0.4333500385284424} | train loss {'Reaction outcome loss': 0.30772035129559344, 'Total loss': 0.30772035129559344}
2023-01-04 01:42:18,162 INFO:     Found new best model at epoch 22
2023-01-04 01:42:18,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:18,163 INFO:     Epoch: 23
2023-01-04 01:42:19,710 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45129819413026173, 'Total loss': 0.45129819413026173} | train loss {'Reaction outcome loss': 0.30386335648350665, 'Total loss': 0.30386335648350665}
2023-01-04 01:42:19,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:19,711 INFO:     Epoch: 24
2023-01-04 01:42:21,316 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43159762024879456, 'Total loss': 0.43159762024879456} | train loss {'Reaction outcome loss': 0.3027126418747308, 'Total loss': 0.3027126418747308}
2023-01-04 01:42:21,317 INFO:     Found new best model at epoch 24
2023-01-04 01:42:21,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:21,318 INFO:     Epoch: 25
2023-01-04 01:42:22,889 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45897826155026755, 'Total loss': 0.45897826155026755} | train loss {'Reaction outcome loss': 0.2976202292047141, 'Total loss': 0.2976202292047141}
2023-01-04 01:42:22,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:22,889 INFO:     Epoch: 26
2023-01-04 01:42:24,500 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.431528506676356, 'Total loss': 0.431528506676356} | train loss {'Reaction outcome loss': 0.29101070098497056, 'Total loss': 0.29101070098497056}
2023-01-04 01:42:24,500 INFO:     Found new best model at epoch 26
2023-01-04 01:42:24,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:24,501 INFO:     Epoch: 27
2023-01-04 01:42:26,108 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44594398538271585, 'Total loss': 0.44594398538271585} | train loss {'Reaction outcome loss': 0.28946191503669755, 'Total loss': 0.28946191503669755}
2023-01-04 01:42:26,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:26,108 INFO:     Epoch: 28
2023-01-04 01:42:27,671 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4201118399699529, 'Total loss': 0.4201118399699529} | train loss {'Reaction outcome loss': 0.28357984851568174, 'Total loss': 0.28357984851568174}
2023-01-04 01:42:27,671 INFO:     Found new best model at epoch 28
2023-01-04 01:42:27,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:27,672 INFO:     Epoch: 29
2023-01-04 01:42:29,232 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4283475170532862, 'Total loss': 0.4283475170532862} | train loss {'Reaction outcome loss': 0.28096200342907574, 'Total loss': 0.28096200342907574}
2023-01-04 01:42:29,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:29,232 INFO:     Epoch: 30
2023-01-04 01:42:30,835 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43711235125859577, 'Total loss': 0.43711235125859577} | train loss {'Reaction outcome loss': 0.27609293176468475, 'Total loss': 0.27609293176468475}
2023-01-04 01:42:30,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:30,835 INFO:     Epoch: 31
2023-01-04 01:42:32,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43443435430526733, 'Total loss': 0.43443435430526733} | train loss {'Reaction outcome loss': 0.27235021062823006, 'Total loss': 0.27235021062823006}
2023-01-04 01:42:32,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:32,402 INFO:     Epoch: 32
2023-01-04 01:42:34,003 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42881453037261963, 'Total loss': 0.42881453037261963} | train loss {'Reaction outcome loss': 0.27171196392822616, 'Total loss': 0.27171196392822616}
2023-01-04 01:42:34,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:34,004 INFO:     Epoch: 33
2023-01-04 01:42:35,573 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43578066130479176, 'Total loss': 0.43578066130479176} | train loss {'Reaction outcome loss': 0.26746894048028813, 'Total loss': 0.26746894048028813}
2023-01-04 01:42:35,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:35,573 INFO:     Epoch: 34
2023-01-04 01:42:37,120 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4193562964598338, 'Total loss': 0.4193562964598338} | train loss {'Reaction outcome loss': 0.26290883172999374, 'Total loss': 0.26290883172999374}
2023-01-04 01:42:37,120 INFO:     Found new best model at epoch 34
2023-01-04 01:42:37,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:37,121 INFO:     Epoch: 35
2023-01-04 01:42:38,686 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4346140682697296, 'Total loss': 0.4346140682697296} | train loss {'Reaction outcome loss': 0.2587391774787571, 'Total loss': 0.2587391774787571}
2023-01-04 01:42:38,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:38,686 INFO:     Epoch: 36
2023-01-04 01:42:40,260 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44059987664222716, 'Total loss': 0.44059987664222716} | train loss {'Reaction outcome loss': 0.2574618612126116, 'Total loss': 0.2574618612126116}
2023-01-04 01:42:40,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:40,261 INFO:     Epoch: 37
2023-01-04 01:42:41,833 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4308362603187561, 'Total loss': 0.4308362603187561} | train loss {'Reaction outcome loss': 0.25585157762626154, 'Total loss': 0.25585157762626154}
2023-01-04 01:42:41,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:41,833 INFO:     Epoch: 38
2023-01-04 01:42:43,407 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4501377602418264, 'Total loss': 0.4501377602418264} | train loss {'Reaction outcome loss': 0.25257872700036227, 'Total loss': 0.25257872700036227}
2023-01-04 01:42:43,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:43,408 INFO:     Epoch: 39
2023-01-04 01:42:44,968 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44784834384918215, 'Total loss': 0.44784834384918215} | train loss {'Reaction outcome loss': 0.24815560568929154, 'Total loss': 0.24815560568929154}
2023-01-04 01:42:44,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:44,968 INFO:     Epoch: 40
2023-01-04 01:42:46,533 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42753371795018513, 'Total loss': 0.42753371795018513} | train loss {'Reaction outcome loss': 0.24671692927896757, 'Total loss': 0.24671692927896757}
2023-01-04 01:42:46,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:46,534 INFO:     Epoch: 41
2023-01-04 01:42:48,109 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4387718011935552, 'Total loss': 0.4387718011935552} | train loss {'Reaction outcome loss': 0.24421959440479732, 'Total loss': 0.24421959440479732}
2023-01-04 01:42:48,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:48,109 INFO:     Epoch: 42
2023-01-04 01:42:49,685 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44558076858520507, 'Total loss': 0.44558076858520507} | train loss {'Reaction outcome loss': 0.239930578246508, 'Total loss': 0.239930578246508}
2023-01-04 01:42:49,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:49,685 INFO:     Epoch: 43
2023-01-04 01:42:51,260 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4469074269135793, 'Total loss': 0.4469074269135793} | train loss {'Reaction outcome loss': 0.23908872864185235, 'Total loss': 0.23908872864185235}
2023-01-04 01:42:51,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:51,260 INFO:     Epoch: 44
2023-01-04 01:42:52,835 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44164000848929086, 'Total loss': 0.44164000848929086} | train loss {'Reaction outcome loss': 0.23788600031545748, 'Total loss': 0.23788600031545748}
2023-01-04 01:42:52,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:52,836 INFO:     Epoch: 45
2023-01-04 01:42:54,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4269811064004898, 'Total loss': 0.4269811064004898} | train loss {'Reaction outcome loss': 0.23693461926319662, 'Total loss': 0.23693461926319662}
2023-01-04 01:42:54,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:54,397 INFO:     Epoch: 46
2023-01-04 01:42:55,984 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4550027390321096, 'Total loss': 0.4550027390321096} | train loss {'Reaction outcome loss': 0.23361043812154414, 'Total loss': 0.23361043812154414}
2023-01-04 01:42:55,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:55,984 INFO:     Epoch: 47
2023-01-04 01:42:57,578 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4438660095135371, 'Total loss': 0.4438660095135371} | train loss {'Reaction outcome loss': 0.23406613764144998, 'Total loss': 0.23406613764144998}
2023-01-04 01:42:57,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:57,578 INFO:     Epoch: 48
2023-01-04 01:42:59,164 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43462040623029075, 'Total loss': 0.43462040623029075} | train loss {'Reaction outcome loss': 0.2312218893333014, 'Total loss': 0.2312218893333014}
2023-01-04 01:42:59,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:42:59,164 INFO:     Epoch: 49
2023-01-04 01:43:00,771 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45685170888900756, 'Total loss': 0.45685170888900756} | train loss {'Reaction outcome loss': 0.2254024366319398, 'Total loss': 0.2254024366319398}
2023-01-04 01:43:00,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:00,771 INFO:     Epoch: 50
2023-01-04 01:43:02,375 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4422722895940145, 'Total loss': 0.4422722895940145} | train loss {'Reaction outcome loss': 0.2257637029766163, 'Total loss': 0.2257637029766163}
2023-01-04 01:43:02,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:02,376 INFO:     Epoch: 51
2023-01-04 01:43:03,927 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4505721256136894, 'Total loss': 0.4505721256136894} | train loss {'Reaction outcome loss': 0.22280340694955417, 'Total loss': 0.22280340694955417}
2023-01-04 01:43:03,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:03,927 INFO:     Epoch: 52
2023-01-04 01:43:05,515 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4654356181621552, 'Total loss': 0.4654356181621552} | train loss {'Reaction outcome loss': 0.22267945770911135, 'Total loss': 0.22267945770911135}
2023-01-04 01:43:05,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:05,516 INFO:     Epoch: 53
2023-01-04 01:43:07,120 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45146447817484536, 'Total loss': 0.45146447817484536} | train loss {'Reaction outcome loss': 0.22039136189571668, 'Total loss': 0.22039136189571668}
2023-01-04 01:43:07,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:07,120 INFO:     Epoch: 54
2023-01-04 01:43:08,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43566262821356455, 'Total loss': 0.43566262821356455} | train loss {'Reaction outcome loss': 0.21869458877669148, 'Total loss': 0.21869458877669148}
2023-01-04 01:43:08,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:08,725 INFO:     Epoch: 55
2023-01-04 01:43:10,299 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44061835010846456, 'Total loss': 0.44061835010846456} | train loss {'Reaction outcome loss': 0.21731331439572812, 'Total loss': 0.21731331439572812}
2023-01-04 01:43:10,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:10,299 INFO:     Epoch: 56
2023-01-04 01:43:11,889 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45558119714260104, 'Total loss': 0.45558119714260104} | train loss {'Reaction outcome loss': 0.21388793295256167, 'Total loss': 0.21388793295256167}
2023-01-04 01:43:11,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:11,889 INFO:     Epoch: 57
2023-01-04 01:43:13,444 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46047905683517454, 'Total loss': 0.46047905683517454} | train loss {'Reaction outcome loss': 0.21545169954171112, 'Total loss': 0.21545169954171112}
2023-01-04 01:43:13,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:13,444 INFO:     Epoch: 58
2023-01-04 01:43:15,023 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.458975346883138, 'Total loss': 0.458975346883138} | train loss {'Reaction outcome loss': 0.21238099719523948, 'Total loss': 0.21238099719523948}
2023-01-04 01:43:15,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:15,023 INFO:     Epoch: 59
2023-01-04 01:43:16,610 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47769989172617594, 'Total loss': 0.47769989172617594} | train loss {'Reaction outcome loss': 0.21285738246071906, 'Total loss': 0.21285738246071906}
2023-01-04 01:43:16,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:16,611 INFO:     Epoch: 60
2023-01-04 01:43:18,214 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45469409227371216, 'Total loss': 0.45469409227371216} | train loss {'Reaction outcome loss': 0.20944080384441346, 'Total loss': 0.20944080384441346}
2023-01-04 01:43:18,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:18,214 INFO:     Epoch: 61
2023-01-04 01:43:19,816 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4474670052528381, 'Total loss': 0.4474670052528381} | train loss {'Reaction outcome loss': 0.2107581808862887, 'Total loss': 0.2107581808862887}
2023-01-04 01:43:19,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:19,816 INFO:     Epoch: 62
2023-01-04 01:43:21,388 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45012048482894895, 'Total loss': 0.45012048482894895} | train loss {'Reaction outcome loss': 0.2072557758116897, 'Total loss': 0.2072557758116897}
2023-01-04 01:43:21,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:21,389 INFO:     Epoch: 63
2023-01-04 01:43:22,949 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4652413169542948, 'Total loss': 0.4652413169542948} | train loss {'Reaction outcome loss': 0.20784935606950586, 'Total loss': 0.20784935606950586}
2023-01-04 01:43:22,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:22,950 INFO:     Epoch: 64
2023-01-04 01:43:24,528 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4545730819304784, 'Total loss': 0.4545730819304784} | train loss {'Reaction outcome loss': 0.20654938383635146, 'Total loss': 0.20654938383635146}
2023-01-04 01:43:24,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:24,528 INFO:     Epoch: 65
2023-01-04 01:43:26,108 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45719399452209475, 'Total loss': 0.45719399452209475} | train loss {'Reaction outcome loss': 0.20286762155592442, 'Total loss': 0.20286762155592442}
2023-01-04 01:43:26,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:26,109 INFO:     Epoch: 66
2023-01-04 01:43:27,688 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4421525001525879, 'Total loss': 0.4421525001525879} | train loss {'Reaction outcome loss': 0.2032165316380424, 'Total loss': 0.2032165316380424}
2023-01-04 01:43:27,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:27,689 INFO:     Epoch: 67
2023-01-04 01:43:29,268 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45417887369791665, 'Total loss': 0.45417887369791665} | train loss {'Reaction outcome loss': 0.20289651221244326, 'Total loss': 0.20289651221244326}
2023-01-04 01:43:29,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:29,268 INFO:     Epoch: 68
2023-01-04 01:43:30,821 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4531442761421204, 'Total loss': 0.4531442761421204} | train loss {'Reaction outcome loss': 0.20113900503068616, 'Total loss': 0.20113900503068616}
2023-01-04 01:43:30,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:30,821 INFO:     Epoch: 69
2023-01-04 01:43:32,412 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4646741449832916, 'Total loss': 0.4646741449832916} | train loss {'Reaction outcome loss': 0.19777085079432843, 'Total loss': 0.19777085079432843}
2023-01-04 01:43:32,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:32,412 INFO:     Epoch: 70
2023-01-04 01:43:34,015 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45074688146511716, 'Total loss': 0.45074688146511716} | train loss {'Reaction outcome loss': 0.19721684087709193, 'Total loss': 0.19721684087709193}
2023-01-04 01:43:34,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:34,015 INFO:     Epoch: 71
2023-01-04 01:43:35,622 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4648736317952474, 'Total loss': 0.4648736317952474} | train loss {'Reaction outcome loss': 0.1942779185325453, 'Total loss': 0.1942779185325453}
2023-01-04 01:43:35,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:35,623 INFO:     Epoch: 72
2023-01-04 01:43:37,232 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.495669287443161, 'Total loss': 0.495669287443161} | train loss {'Reaction outcome loss': 0.1950547243076148, 'Total loss': 0.1950547243076148}
2023-01-04 01:43:37,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:37,232 INFO:     Epoch: 73
2023-01-04 01:43:38,833 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45272395412127175, 'Total loss': 0.45272395412127175} | train loss {'Reaction outcome loss': 0.1940880791035109, 'Total loss': 0.1940880791035109}
2023-01-04 01:43:38,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:38,833 INFO:     Epoch: 74
2023-01-04 01:43:40,400 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47810773849487304, 'Total loss': 0.47810773849487304} | train loss {'Reaction outcome loss': 0.19381383369802993, 'Total loss': 0.19381383369802993}
2023-01-04 01:43:40,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:40,401 INFO:     Epoch: 75
2023-01-04 01:43:41,976 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46855688790480293, 'Total loss': 0.46855688790480293} | train loss {'Reaction outcome loss': 0.19260388756027588, 'Total loss': 0.19260388756027588}
2023-01-04 01:43:41,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:41,976 INFO:     Epoch: 76
2023-01-04 01:43:43,556 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4482233613729477, 'Total loss': 0.4482233613729477} | train loss {'Reaction outcome loss': 0.19376116254513626, 'Total loss': 0.19376116254513626}
2023-01-04 01:43:43,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:43,556 INFO:     Epoch: 77
2023-01-04 01:43:45,134 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46688661773999535, 'Total loss': 0.46688661773999535} | train loss {'Reaction outcome loss': 0.1883328472137888, 'Total loss': 0.1883328472137888}
2023-01-04 01:43:45,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:45,134 INFO:     Epoch: 78
2023-01-04 01:43:46,717 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45641697148482, 'Total loss': 0.45641697148482} | train loss {'Reaction outcome loss': 0.1887138415598771, 'Total loss': 0.1887138415598771}
2023-01-04 01:43:46,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:46,717 INFO:     Epoch: 79
2023-01-04 01:43:48,273 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4484097639719645, 'Total loss': 0.4484097639719645} | train loss {'Reaction outcome loss': 0.18522172844235277, 'Total loss': 0.18522172844235277}
2023-01-04 01:43:48,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:48,273 INFO:     Epoch: 80
2023-01-04 01:43:49,847 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4983644366264343, 'Total loss': 0.4983644366264343} | train loss {'Reaction outcome loss': 0.18654775575158142, 'Total loss': 0.18654775575158142}
2023-01-04 01:43:49,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:49,847 INFO:     Epoch: 81
2023-01-04 01:43:51,466 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49395610590775807, 'Total loss': 0.49395610590775807} | train loss {'Reaction outcome loss': 0.1854596941394138, 'Total loss': 0.1854596941394138}
2023-01-04 01:43:51,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:51,466 INFO:     Epoch: 82
2023-01-04 01:43:53,087 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4797357479731242, 'Total loss': 0.4797357479731242} | train loss {'Reaction outcome loss': 0.18565110198389262, 'Total loss': 0.18565110198389262}
2023-01-04 01:43:53,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:53,087 INFO:     Epoch: 83
2023-01-04 01:43:54,690 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4555439005295436, 'Total loss': 0.4555439005295436} | train loss {'Reaction outcome loss': 0.18656805932740153, 'Total loss': 0.18656805932740153}
2023-01-04 01:43:54,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:54,691 INFO:     Epoch: 84
2023-01-04 01:43:56,295 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47463010052839916, 'Total loss': 0.47463010052839916} | train loss {'Reaction outcome loss': 0.18472236070113304, 'Total loss': 0.18472236070113304}
2023-01-04 01:43:56,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:56,296 INFO:     Epoch: 85
2023-01-04 01:43:57,872 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47950519770383837, 'Total loss': 0.47950519770383837} | train loss {'Reaction outcome loss': 0.18668073854808295, 'Total loss': 0.18668073854808295}
2023-01-04 01:43:57,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:57,873 INFO:     Epoch: 86
2023-01-04 01:43:59,430 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47044244507948557, 'Total loss': 0.47044244507948557} | train loss {'Reaction outcome loss': 0.18404347444082791, 'Total loss': 0.18404347444082791}
2023-01-04 01:43:59,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:43:59,430 INFO:     Epoch: 87
2023-01-04 01:44:01,034 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45940105666716896, 'Total loss': 0.45940105666716896} | train loss {'Reaction outcome loss': 0.18263676147157457, 'Total loss': 0.18263676147157457}
2023-01-04 01:44:01,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:01,034 INFO:     Epoch: 88
2023-01-04 01:44:02,647 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46650447050730387, 'Total loss': 0.46650447050730387} | train loss {'Reaction outcome loss': 0.18194601558585524, 'Total loss': 0.18194601558585524}
2023-01-04 01:44:02,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:02,647 INFO:     Epoch: 89
2023-01-04 01:44:04,259 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4670502175887426, 'Total loss': 0.4670502175887426} | train loss {'Reaction outcome loss': 0.1785243386573298, 'Total loss': 0.1785243386573298}
2023-01-04 01:44:04,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:04,260 INFO:     Epoch: 90
2023-01-04 01:44:05,858 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48459603687127434, 'Total loss': 0.48459603687127434} | train loss {'Reaction outcome loss': 0.17818263419579727, 'Total loss': 0.17818263419579727}
2023-01-04 01:44:05,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:05,858 INFO:     Epoch: 91
2023-01-04 01:44:07,437 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4913966496785482, 'Total loss': 0.4913966496785482} | train loss {'Reaction outcome loss': 0.18005665771035484, 'Total loss': 0.18005665771035484}
2023-01-04 01:44:07,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:07,437 INFO:     Epoch: 92
2023-01-04 01:44:09,047 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4627851148446401, 'Total loss': 0.4627851148446401} | train loss {'Reaction outcome loss': 0.17785019061831764, 'Total loss': 0.17785019061831764}
2023-01-04 01:44:09,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:09,048 INFO:     Epoch: 93
2023-01-04 01:44:10,659 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47744235893090564, 'Total loss': 0.47744235893090564} | train loss {'Reaction outcome loss': 0.17611726806686692, 'Total loss': 0.17611726806686692}
2023-01-04 01:44:10,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:10,659 INFO:     Epoch: 94
2023-01-04 01:44:12,268 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45407639344533285, 'Total loss': 0.45407639344533285} | train loss {'Reaction outcome loss': 0.17695462125466094, 'Total loss': 0.17695462125466094}
2023-01-04 01:44:12,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:12,268 INFO:     Epoch: 95
2023-01-04 01:44:13,871 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4477666000525157, 'Total loss': 0.4477666000525157} | train loss {'Reaction outcome loss': 0.1759250811045314, 'Total loss': 0.1759250811045314}
2023-01-04 01:44:13,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:13,871 INFO:     Epoch: 96
2023-01-04 01:44:15,421 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49319713513056435, 'Total loss': 0.49319713513056435} | train loss {'Reaction outcome loss': 0.17327061932765958, 'Total loss': 0.17327061932765958}
2023-01-04 01:44:15,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:15,421 INFO:     Epoch: 97
2023-01-04 01:44:17,008 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47292066415150963, 'Total loss': 0.47292066415150963} | train loss {'Reaction outcome loss': 0.17543001266899128, 'Total loss': 0.17543001266899128}
2023-01-04 01:44:17,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:17,009 INFO:     Epoch: 98
2023-01-04 01:44:18,605 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5040157794952392, 'Total loss': 0.5040157794952392} | train loss {'Reaction outcome loss': 0.17368743282098037, 'Total loss': 0.17368743282098037}
2023-01-04 01:44:18,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:18,605 INFO:     Epoch: 99
2023-01-04 01:44:20,203 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4949345509211222, 'Total loss': 0.4949345509211222} | train loss {'Reaction outcome loss': 0.1728858434503059, 'Total loss': 0.1728858434503059}
2023-01-04 01:44:20,203 INFO:     Best model found after epoch 35 of 100.
2023-01-04 01:44:20,203 INFO:   Done with stage: TRAINING
2023-01-04 01:44:20,203 INFO:   Starting stage: EVALUATION
2023-01-04 01:44:20,344 INFO:   Done with stage: EVALUATION
2023-01-04 01:44:20,344 INFO:   Leaving out SEQ value Fold_3
2023-01-04 01:44:20,357 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 01:44:20,357 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:44:21,002 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:44:21,002 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:44:21,071 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:44:21,072 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:44:21,072 INFO:     No hyperparam tuning for this model
2023-01-04 01:44:21,072 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:44:21,072 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:44:21,072 INFO:     None feature selector for col prot
2023-01-04 01:44:21,073 INFO:     None feature selector for col prot
2023-01-04 01:44:21,073 INFO:     None feature selector for col prot
2023-01-04 01:44:21,073 INFO:     None feature selector for col chem
2023-01-04 01:44:21,073 INFO:     None feature selector for col chem
2023-01-04 01:44:21,073 INFO:     None feature selector for col chem
2023-01-04 01:44:21,074 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:44:21,074 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:44:21,075 INFO:     Number of params in model 70141
2023-01-04 01:44:21,078 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:44:21,078 INFO:   Starting stage: TRAINING
2023-01-04 01:44:21,121 INFO:     Val loss before train {'Reaction outcome loss': 1.0145950754483541, 'Total loss': 1.0145950754483541}
2023-01-04 01:44:21,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:21,121 INFO:     Epoch: 0
2023-01-04 01:44:22,731 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.654470956325531, 'Total loss': 0.654470956325531} | train loss {'Reaction outcome loss': 0.830963218516677, 'Total loss': 0.830963218516677}
2023-01-04 01:44:22,731 INFO:     Found new best model at epoch 0
2023-01-04 01:44:22,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:22,732 INFO:     Epoch: 1
2023-01-04 01:44:24,316 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5708821515242258, 'Total loss': 0.5708821515242258} | train loss {'Reaction outcome loss': 0.6008658022993673, 'Total loss': 0.6008658022993673}
2023-01-04 01:44:24,316 INFO:     Found new best model at epoch 1
2023-01-04 01:44:24,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:24,317 INFO:     Epoch: 2
2023-01-04 01:44:25,897 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5223071833451589, 'Total loss': 0.5223071833451589} | train loss {'Reaction outcome loss': 0.5377388546501634, 'Total loss': 0.5377388546501634}
2023-01-04 01:44:25,897 INFO:     Found new best model at epoch 2
2023-01-04 01:44:25,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:25,898 INFO:     Epoch: 3
2023-01-04 01:44:27,512 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5131509125232696, 'Total loss': 0.5131509125232696} | train loss {'Reaction outcome loss': 0.5029477512966978, 'Total loss': 0.5029477512966978}
2023-01-04 01:44:27,512 INFO:     Found new best model at epoch 3
2023-01-04 01:44:27,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:27,513 INFO:     Epoch: 4
2023-01-04 01:44:29,112 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4832753578821818, 'Total loss': 0.4832753578821818} | train loss {'Reaction outcome loss': 0.477913962989828, 'Total loss': 0.477913962989828}
2023-01-04 01:44:29,113 INFO:     Found new best model at epoch 4
2023-01-04 01:44:29,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:29,114 INFO:     Epoch: 5
2023-01-04 01:44:30,716 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4594388087590536, 'Total loss': 0.4594388087590536} | train loss {'Reaction outcome loss': 0.4552295718097339, 'Total loss': 0.4552295718097339}
2023-01-04 01:44:30,716 INFO:     Found new best model at epoch 5
2023-01-04 01:44:30,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:30,717 INFO:     Epoch: 6
2023-01-04 01:44:32,330 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47166225910186765, 'Total loss': 0.47166225910186765} | train loss {'Reaction outcome loss': 0.4352410694815382, 'Total loss': 0.4352410694815382}
2023-01-04 01:44:32,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:32,330 INFO:     Epoch: 7
2023-01-04 01:44:33,885 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45482055346171063, 'Total loss': 0.45482055346171063} | train loss {'Reaction outcome loss': 0.4194484670123045, 'Total loss': 0.4194484670123045}
2023-01-04 01:44:33,886 INFO:     Found new best model at epoch 7
2023-01-04 01:44:33,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:33,886 INFO:     Epoch: 8
2023-01-04 01:44:35,475 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42550058563550314, 'Total loss': 0.42550058563550314} | train loss {'Reaction outcome loss': 0.4091386873356617, 'Total loss': 0.4091386873356617}
2023-01-04 01:44:35,476 INFO:     Found new best model at epoch 8
2023-01-04 01:44:35,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:35,477 INFO:     Epoch: 9
2023-01-04 01:44:37,064 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4262736757596334, 'Total loss': 0.4262736757596334} | train loss {'Reaction outcome loss': 0.3933973618558724, 'Total loss': 0.3933973618558724}
2023-01-04 01:44:37,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:37,065 INFO:     Epoch: 10
2023-01-04 01:44:38,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4439527322848638, 'Total loss': 0.4439527322848638} | train loss {'Reaction outcome loss': 0.382693775270107, 'Total loss': 0.382693775270107}
2023-01-04 01:44:38,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:38,653 INFO:     Epoch: 11
2023-01-04 01:44:40,241 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4187501092751821, 'Total loss': 0.4187501092751821} | train loss {'Reaction outcome loss': 0.37283873384016275, 'Total loss': 0.37283873384016275}
2023-01-04 01:44:40,241 INFO:     Found new best model at epoch 11
2023-01-04 01:44:40,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:40,242 INFO:     Epoch: 12
2023-01-04 01:44:41,811 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4614499847094218, 'Total loss': 0.4614499847094218} | train loss {'Reaction outcome loss': 0.36508679047335674, 'Total loss': 0.36508679047335674}
2023-01-04 01:44:41,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:41,811 INFO:     Epoch: 13
2023-01-04 01:44:43,405 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4315534601608912, 'Total loss': 0.4315534601608912} | train loss {'Reaction outcome loss': 0.35824578141208985, 'Total loss': 0.35824578141208985}
2023-01-04 01:44:43,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:43,405 INFO:     Epoch: 14
2023-01-04 01:44:45,012 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42195608019828795, 'Total loss': 0.42195608019828795} | train loss {'Reaction outcome loss': 0.35162851067572615, 'Total loss': 0.35162851067572615}
2023-01-04 01:44:45,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:45,012 INFO:     Epoch: 15
2023-01-04 01:44:46,630 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4212167461713155, 'Total loss': 0.4212167461713155} | train loss {'Reaction outcome loss': 0.34480434887274336, 'Total loss': 0.34480434887274336}
2023-01-04 01:44:46,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:46,630 INFO:     Epoch: 16
2023-01-04 01:44:48,244 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39682505453626316, 'Total loss': 0.39682505453626316} | train loss {'Reaction outcome loss': 0.33697519908203694, 'Total loss': 0.33697519908203694}
2023-01-04 01:44:48,245 INFO:     Found new best model at epoch 16
2023-01-04 01:44:48,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:48,246 INFO:     Epoch: 17
2023-01-04 01:44:49,851 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42981698910395305, 'Total loss': 0.42981698910395305} | train loss {'Reaction outcome loss': 0.3299156127728685, 'Total loss': 0.3299156127728685}
2023-01-04 01:44:49,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:49,851 INFO:     Epoch: 18
2023-01-04 01:44:51,428 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45664179722468057, 'Total loss': 0.45664179722468057} | train loss {'Reaction outcome loss': 0.3225722536716583, 'Total loss': 0.3225722536716583}
2023-01-04 01:44:51,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:51,428 INFO:     Epoch: 19
2023-01-04 01:44:53,001 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.412424698472023, 'Total loss': 0.412424698472023} | train loss {'Reaction outcome loss': 0.3207039943196043, 'Total loss': 0.3207039943196043}
2023-01-04 01:44:53,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:53,001 INFO:     Epoch: 20
2023-01-04 01:44:54,590 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4191352228323619, 'Total loss': 0.4191352228323619} | train loss {'Reaction outcome loss': 0.31403197747838757, 'Total loss': 0.31403197747838757}
2023-01-04 01:44:54,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:54,591 INFO:     Epoch: 21
2023-01-04 01:44:56,178 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39824613531430564, 'Total loss': 0.39824613531430564} | train loss {'Reaction outcome loss': 0.30921106396691644, 'Total loss': 0.30921106396691644}
2023-01-04 01:44:56,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:56,178 INFO:     Epoch: 22
2023-01-04 01:44:57,766 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4085402230421702, 'Total loss': 0.4085402230421702} | train loss {'Reaction outcome loss': 0.30524898083866947, 'Total loss': 0.30524898083866947}
2023-01-04 01:44:57,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:57,766 INFO:     Epoch: 23
2023-01-04 01:44:59,345 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3976708988348643, 'Total loss': 0.3976708988348643} | train loss {'Reaction outcome loss': 0.29855324803803956, 'Total loss': 0.29855324803803956}
2023-01-04 01:44:59,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:44:59,345 INFO:     Epoch: 24
2023-01-04 01:45:00,905 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40398512880007426, 'Total loss': 0.40398512880007426} | train loss {'Reaction outcome loss': 0.298512769441535, 'Total loss': 0.298512769441535}
2023-01-04 01:45:00,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:00,906 INFO:     Epoch: 25
2023-01-04 01:45:02,515 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40164107518891495, 'Total loss': 0.40164107518891495} | train loss {'Reaction outcome loss': 0.29084594289425514, 'Total loss': 0.29084594289425514}
2023-01-04 01:45:02,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:02,515 INFO:     Epoch: 26
2023-01-04 01:45:04,124 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.417704364657402, 'Total loss': 0.417704364657402} | train loss {'Reaction outcome loss': 0.2880559535085285, 'Total loss': 0.2880559535085285}
2023-01-04 01:45:04,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:04,125 INFO:     Epoch: 27
2023-01-04 01:45:05,695 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39925405383110046, 'Total loss': 0.39925405383110046} | train loss {'Reaction outcome loss': 0.28500140569832205, 'Total loss': 0.28500140569832205}
2023-01-04 01:45:05,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:05,695 INFO:     Epoch: 28
2023-01-04 01:45:07,297 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.409334272146225, 'Total loss': 0.409334272146225} | train loss {'Reaction outcome loss': 0.28260559985672473, 'Total loss': 0.28260559985672473}
2023-01-04 01:45:07,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:07,297 INFO:     Epoch: 29
2023-01-04 01:45:08,857 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43051756620407106, 'Total loss': 0.43051756620407106} | train loss {'Reaction outcome loss': 0.27698039461987733, 'Total loss': 0.27698039461987733}
2023-01-04 01:45:08,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:08,857 INFO:     Epoch: 30
2023-01-04 01:45:10,430 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4106282244126002, 'Total loss': 0.4106282244126002} | train loss {'Reaction outcome loss': 0.27570464135739053, 'Total loss': 0.27570464135739053}
2023-01-04 01:45:10,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:10,431 INFO:     Epoch: 31
2023-01-04 01:45:12,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4148916443188985, 'Total loss': 0.4148916443188985} | train loss {'Reaction outcome loss': 0.27311983563169073, 'Total loss': 0.27311983563169073}
2023-01-04 01:45:12,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:12,014 INFO:     Epoch: 32
2023-01-04 01:45:13,618 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.400612810254097, 'Total loss': 0.400612810254097} | train loss {'Reaction outcome loss': 0.27019257522629997, 'Total loss': 0.27019257522629997}
2023-01-04 01:45:13,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:13,619 INFO:     Epoch: 33
2023-01-04 01:45:15,233 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38715922037760414, 'Total loss': 0.38715922037760414} | train loss {'Reaction outcome loss': 0.26663077271876545, 'Total loss': 0.26663077271876545}
2023-01-04 01:45:15,233 INFO:     Found new best model at epoch 33
2023-01-04 01:45:15,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:15,234 INFO:     Epoch: 34
2023-01-04 01:45:16,831 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41812484661738075, 'Total loss': 0.41812484661738075} | train loss {'Reaction outcome loss': 0.2625655608564398, 'Total loss': 0.2625655608564398}
2023-01-04 01:45:16,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:16,832 INFO:     Epoch: 35
2023-01-04 01:45:18,415 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4023326168457667, 'Total loss': 0.4023326168457667} | train loss {'Reaction outcome loss': 0.25930687779710243, 'Total loss': 0.25930687779710243}
2023-01-04 01:45:18,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:18,416 INFO:     Epoch: 36
2023-01-04 01:45:19,985 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4073997259140015, 'Total loss': 0.4073997259140015} | train loss {'Reaction outcome loss': 0.25940321660498633, 'Total loss': 0.25940321660498633}
2023-01-04 01:45:19,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:19,985 INFO:     Epoch: 37
2023-01-04 01:45:21,585 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4066421662767728, 'Total loss': 0.4066421662767728} | train loss {'Reaction outcome loss': 0.25800766396152713, 'Total loss': 0.25800766396152713}
2023-01-04 01:45:21,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:21,586 INFO:     Epoch: 38
2023-01-04 01:45:23,176 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3857003688812256, 'Total loss': 0.3857003688812256} | train loss {'Reaction outcome loss': 0.2549271274249267, 'Total loss': 0.2549271274249267}
2023-01-04 01:45:23,177 INFO:     Found new best model at epoch 38
2023-01-04 01:45:23,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:23,178 INFO:     Epoch: 39
2023-01-04 01:45:24,773 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41062336365381874, 'Total loss': 0.41062336365381874} | train loss {'Reaction outcome loss': 0.25175607484513823, 'Total loss': 0.25175607484513823}
2023-01-04 01:45:24,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:24,773 INFO:     Epoch: 40
2023-01-04 01:45:26,374 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4048058569431305, 'Total loss': 0.4048058569431305} | train loss {'Reaction outcome loss': 0.24923236885645095, 'Total loss': 0.24923236885645095}
2023-01-04 01:45:26,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:26,374 INFO:     Epoch: 41
2023-01-04 01:45:27,923 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40481872856616974, 'Total loss': 0.40481872856616974} | train loss {'Reaction outcome loss': 0.24713722485912978, 'Total loss': 0.24713722485912978}
2023-01-04 01:45:27,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:27,924 INFO:     Epoch: 42
2023-01-04 01:45:29,529 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40200761556625364, 'Total loss': 0.40200761556625364} | train loss {'Reaction outcome loss': 0.2433496972913072, 'Total loss': 0.2433496972913072}
2023-01-04 01:45:29,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:29,529 INFO:     Epoch: 43
2023-01-04 01:45:31,136 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4056837111711502, 'Total loss': 0.4056837111711502} | train loss {'Reaction outcome loss': 0.24357715444843264, 'Total loss': 0.24357715444843264}
2023-01-04 01:45:31,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:31,136 INFO:     Epoch: 44
2023-01-04 01:45:32,741 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39897696872552235, 'Total loss': 0.39897696872552235} | train loss {'Reaction outcome loss': 0.24149107128164193, 'Total loss': 0.24149107128164193}
2023-01-04 01:45:32,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:32,742 INFO:     Epoch: 45
2023-01-04 01:45:34,317 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39494308829307556, 'Total loss': 0.39494308829307556} | train loss {'Reaction outcome loss': 0.237025660863758, 'Total loss': 0.237025660863758}
2023-01-04 01:45:34,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:34,317 INFO:     Epoch: 46
2023-01-04 01:45:35,896 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4100868463516235, 'Total loss': 0.4100868463516235} | train loss {'Reaction outcome loss': 0.2369568031825071, 'Total loss': 0.2369568031825071}
2023-01-04 01:45:35,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:35,897 INFO:     Epoch: 47
2023-01-04 01:45:37,477 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40416600505510963, 'Total loss': 0.40416600505510963} | train loss {'Reaction outcome loss': 0.23409411961036006, 'Total loss': 0.23409411961036006}
2023-01-04 01:45:37,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:37,477 INFO:     Epoch: 48
2023-01-04 01:45:39,074 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3837798615296682, 'Total loss': 0.3837798615296682} | train loss {'Reaction outcome loss': 0.23140863185055063, 'Total loss': 0.23140863185055063}
2023-01-04 01:45:39,075 INFO:     Found new best model at epoch 48
2023-01-04 01:45:39,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:39,075 INFO:     Epoch: 49
2023-01-04 01:45:40,681 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40706479450066885, 'Total loss': 0.40706479450066885} | train loss {'Reaction outcome loss': 0.2279463395557917, 'Total loss': 0.2279463395557917}
2023-01-04 01:45:40,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:40,681 INFO:     Epoch: 50
2023-01-04 01:45:42,277 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4115424354871114, 'Total loss': 0.4115424354871114} | train loss {'Reaction outcome loss': 0.22879381018289685, 'Total loss': 0.22879381018289685}
2023-01-04 01:45:42,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:42,278 INFO:     Epoch: 51
2023-01-04 01:45:43,889 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40959980686505637, 'Total loss': 0.40959980686505637} | train loss {'Reaction outcome loss': 0.22745922880831862, 'Total loss': 0.22745922880831862}
2023-01-04 01:45:43,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:43,890 INFO:     Epoch: 52
2023-01-04 01:45:45,473 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3894135862588882, 'Total loss': 0.3894135862588882} | train loss {'Reaction outcome loss': 0.2251338996672935, 'Total loss': 0.2251338996672935}
2023-01-04 01:45:45,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:45,473 INFO:     Epoch: 53
2023-01-04 01:45:47,046 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40555095275243125, 'Total loss': 0.40555095275243125} | train loss {'Reaction outcome loss': 0.2236128547194883, 'Total loss': 0.2236128547194883}
2023-01-04 01:45:47,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:47,046 INFO:     Epoch: 54
2023-01-04 01:45:48,627 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39386099614202974, 'Total loss': 0.39386099614202974} | train loss {'Reaction outcome loss': 0.2231625106090503, 'Total loss': 0.2231625106090503}
2023-01-04 01:45:48,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:48,627 INFO:     Epoch: 55
2023-01-04 01:45:50,210 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38173894832531613, 'Total loss': 0.38173894832531613} | train loss {'Reaction outcome loss': 0.2217887920483838, 'Total loss': 0.2217887920483838}
2023-01-04 01:45:50,210 INFO:     Found new best model at epoch 55
2023-01-04 01:45:50,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:50,211 INFO:     Epoch: 56
2023-01-04 01:45:51,796 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38132515698671343, 'Total loss': 0.38132515698671343} | train loss {'Reaction outcome loss': 0.2190453988112455, 'Total loss': 0.2190453988112455}
2023-01-04 01:45:51,796 INFO:     Found new best model at epoch 56
2023-01-04 01:45:51,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:51,797 INFO:     Epoch: 57
2023-01-04 01:45:53,371 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3891842822233836, 'Total loss': 0.3891842822233836} | train loss {'Reaction outcome loss': 0.21752228148716646, 'Total loss': 0.21752228148716646}
2023-01-04 01:45:53,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:53,371 INFO:     Epoch: 58
2023-01-04 01:45:54,946 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.425982411702474, 'Total loss': 0.425982411702474} | train loss {'Reaction outcome loss': 0.2163777516570187, 'Total loss': 0.2163777516570187}
2023-01-04 01:45:54,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:54,947 INFO:     Epoch: 59
2023-01-04 01:45:56,532 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40617892642815906, 'Total loss': 0.40617892642815906} | train loss {'Reaction outcome loss': 0.21576318393604163, 'Total loss': 0.21576318393604163}
2023-01-04 01:45:56,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:56,532 INFO:     Epoch: 60
2023-01-04 01:45:58,120 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4258401950200399, 'Total loss': 0.4258401950200399} | train loss {'Reaction outcome loss': 0.21470399672695756, 'Total loss': 0.21470399672695756}
2023-01-04 01:45:58,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:58,120 INFO:     Epoch: 61
2023-01-04 01:45:59,708 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3901128634810448, 'Total loss': 0.3901128634810448} | train loss {'Reaction outcome loss': 0.21093414969959834, 'Total loss': 0.21093414969959834}
2023-01-04 01:45:59,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:45:59,709 INFO:     Epoch: 62
2023-01-04 01:46:01,294 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.406978906194369, 'Total loss': 0.406978906194369} | train loss {'Reaction outcome loss': 0.2083726790835605, 'Total loss': 0.2083726790835605}
2023-01-04 01:46:01,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:01,294 INFO:     Epoch: 63
2023-01-04 01:46:02,866 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41447279751300814, 'Total loss': 0.41447279751300814} | train loss {'Reaction outcome loss': 0.20851640962064266, 'Total loss': 0.20851640962064266}
2023-01-04 01:46:02,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:02,866 INFO:     Epoch: 64
2023-01-04 01:46:04,432 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42016029755274453, 'Total loss': 0.42016029755274453} | train loss {'Reaction outcome loss': 0.211585437695421, 'Total loss': 0.211585437695421}
2023-01-04 01:46:04,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:04,432 INFO:     Epoch: 65
2023-01-04 01:46:06,052 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40862705012162526, 'Total loss': 0.40862705012162526} | train loss {'Reaction outcome loss': 0.2063466749242405, 'Total loss': 0.2063466749242405}
2023-01-04 01:46:06,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:06,053 INFO:     Epoch: 66
2023-01-04 01:46:07,674 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4074294994274775, 'Total loss': 0.4074294994274775} | train loss {'Reaction outcome loss': 0.2042585511005273, 'Total loss': 0.2042585511005273}
2023-01-04 01:46:07,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:07,675 INFO:     Epoch: 67
2023-01-04 01:46:09,294 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41216503183046976, 'Total loss': 0.41216503183046976} | train loss {'Reaction outcome loss': 0.20293733257338079, 'Total loss': 0.20293733257338079}
2023-01-04 01:46:09,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:09,294 INFO:     Epoch: 68
2023-01-04 01:46:10,903 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40699329574902854, 'Total loss': 0.40699329574902854} | train loss {'Reaction outcome loss': 0.20297093024599727, 'Total loss': 0.20297093024599727}
2023-01-04 01:46:10,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:10,904 INFO:     Epoch: 69
2023-01-04 01:46:12,453 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4083836764097214, 'Total loss': 0.4083836764097214} | train loss {'Reaction outcome loss': 0.20002491579792142, 'Total loss': 0.20002491579792142}
2023-01-04 01:46:12,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:12,454 INFO:     Epoch: 70
2023-01-04 01:46:14,036 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41217753489812214, 'Total loss': 0.41217753489812214} | train loss {'Reaction outcome loss': 0.20101258000290959, 'Total loss': 0.20101258000290959}
2023-01-04 01:46:14,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:14,036 INFO:     Epoch: 71
2023-01-04 01:46:15,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4157092879215876, 'Total loss': 0.4157092879215876} | train loss {'Reaction outcome loss': 0.1987127777610491, 'Total loss': 0.1987127777610491}
2023-01-04 01:46:15,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:15,625 INFO:     Epoch: 72
2023-01-04 01:46:17,213 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3899085561434428, 'Total loss': 0.3899085561434428} | train loss {'Reaction outcome loss': 0.19859465418288308, 'Total loss': 0.19859465418288308}
2023-01-04 01:46:17,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:17,214 INFO:     Epoch: 73
2023-01-04 01:46:18,802 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41149527033170064, 'Total loss': 0.41149527033170064} | train loss {'Reaction outcome loss': 0.1963151989463907, 'Total loss': 0.1963151989463907}
2023-01-04 01:46:18,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:18,802 INFO:     Epoch: 74
2023-01-04 01:46:20,377 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4187663396199544, 'Total loss': 0.4187663396199544} | train loss {'Reaction outcome loss': 0.19393396588300701, 'Total loss': 0.19393396588300701}
2023-01-04 01:46:20,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:20,377 INFO:     Epoch: 75
2023-01-04 01:46:21,953 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42485513190428414, 'Total loss': 0.42485513190428414} | train loss {'Reaction outcome loss': 0.19417849041004903, 'Total loss': 0.19417849041004903}
2023-01-04 01:46:21,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:21,953 INFO:     Epoch: 76
2023-01-04 01:46:23,563 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3969298938910166, 'Total loss': 0.3969298938910166} | train loss {'Reaction outcome loss': 0.19443254927377196, 'Total loss': 0.19443254927377196}
2023-01-04 01:46:23,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:23,563 INFO:     Epoch: 77
2023-01-04 01:46:25,168 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40762888789176943, 'Total loss': 0.40762888789176943} | train loss {'Reaction outcome loss': 0.19205644628862395, 'Total loss': 0.19205644628862395}
2023-01-04 01:46:25,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:25,169 INFO:     Epoch: 78
2023-01-04 01:46:26,776 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41854276061058043, 'Total loss': 0.41854276061058043} | train loss {'Reaction outcome loss': 0.1925623778960783, 'Total loss': 0.1925623778960783}
2023-01-04 01:46:26,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:26,777 INFO:     Epoch: 79
2023-01-04 01:46:28,373 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4124590675036112, 'Total loss': 0.4124590675036112} | train loss {'Reaction outcome loss': 0.19136104550566116, 'Total loss': 0.19136104550566116}
2023-01-04 01:46:28,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:28,374 INFO:     Epoch: 80
2023-01-04 01:46:29,944 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4471082826455434, 'Total loss': 0.4471082826455434} | train loss {'Reaction outcome loss': 0.1897418159638008, 'Total loss': 0.1897418159638008}
2023-01-04 01:46:29,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:29,945 INFO:     Epoch: 81
2023-01-04 01:46:31,511 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4132284983992577, 'Total loss': 0.4132284983992577} | train loss {'Reaction outcome loss': 0.1897656475295768, 'Total loss': 0.1897656475295768}
2023-01-04 01:46:31,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:31,511 INFO:     Epoch: 82
2023-01-04 01:46:33,098 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41501561403274534, 'Total loss': 0.41501561403274534} | train loss {'Reaction outcome loss': 0.18906734803569142, 'Total loss': 0.18906734803569142}
2023-01-04 01:46:33,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:33,098 INFO:     Epoch: 83
2023-01-04 01:46:34,686 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4286609629789988, 'Total loss': 0.4286609629789988} | train loss {'Reaction outcome loss': 0.18688082607313447, 'Total loss': 0.18688082607313447}
2023-01-04 01:46:34,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:34,686 INFO:     Epoch: 84
2023-01-04 01:46:36,272 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41617676615715027, 'Total loss': 0.41617676615715027} | train loss {'Reaction outcome loss': 0.18662803327787097, 'Total loss': 0.18662803327787097}
2023-01-04 01:46:36,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:36,273 INFO:     Epoch: 85
2023-01-04 01:46:37,858 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4326535592476527, 'Total loss': 0.4326535592476527} | train loss {'Reaction outcome loss': 0.18754920932416716, 'Total loss': 0.18754920932416716}
2023-01-04 01:46:37,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:37,859 INFO:     Epoch: 86
2023-01-04 01:46:39,415 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4237937351067861, 'Total loss': 0.4237937351067861} | train loss {'Reaction outcome loss': 0.1846332788249872, 'Total loss': 0.1846332788249872}
2023-01-04 01:46:39,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:39,415 INFO:     Epoch: 87
2023-01-04 01:46:41,000 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.412393985191981, 'Total loss': 0.412393985191981} | train loss {'Reaction outcome loss': 0.18322345061078124, 'Total loss': 0.18322345061078124}
2023-01-04 01:46:41,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:41,002 INFO:     Epoch: 88
2023-01-04 01:46:42,588 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42276673515637714, 'Total loss': 0.42276673515637714} | train loss {'Reaction outcome loss': 0.18197692525539086, 'Total loss': 0.18197692525539086}
2023-01-04 01:46:42,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:42,588 INFO:     Epoch: 89
2023-01-04 01:46:44,175 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4442135080695152, 'Total loss': 0.4442135080695152} | train loss {'Reaction outcome loss': 0.18271116235966448, 'Total loss': 0.18271116235966448}
2023-01-04 01:46:44,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:44,175 INFO:     Epoch: 90
2023-01-04 01:46:45,763 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4698460380236308, 'Total loss': 0.4698460380236308} | train loss {'Reaction outcome loss': 0.18125293160496403, 'Total loss': 0.18125293160496403}
2023-01-04 01:46:45,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:45,764 INFO:     Epoch: 91
2023-01-04 01:46:47,330 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4190583070119222, 'Total loss': 0.4190583070119222} | train loss {'Reaction outcome loss': 0.17880066805757092, 'Total loss': 0.17880066805757092}
2023-01-04 01:46:47,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:47,330 INFO:     Epoch: 92
2023-01-04 01:46:48,902 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46281541138887405, 'Total loss': 0.46281541138887405} | train loss {'Reaction outcome loss': 0.1810927824491132, 'Total loss': 0.1810927824491132}
2023-01-04 01:46:48,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:48,902 INFO:     Epoch: 93
2023-01-04 01:46:50,491 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4339764714241028, 'Total loss': 0.4339764714241028} | train loss {'Reaction outcome loss': 0.17966810432364688, 'Total loss': 0.17966810432364688}
2023-01-04 01:46:50,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:50,492 INFO:     Epoch: 94
2023-01-04 01:46:52,091 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.417340158422788, 'Total loss': 0.417340158422788} | train loss {'Reaction outcome loss': 0.18068181878350076, 'Total loss': 0.18068181878350076}
2023-01-04 01:46:52,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:52,092 INFO:     Epoch: 95
2023-01-04 01:46:53,702 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44159567753473916, 'Total loss': 0.44159567753473916} | train loss {'Reaction outcome loss': 0.17659337015101945, 'Total loss': 0.17659337015101945}
2023-01-04 01:46:53,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:53,703 INFO:     Epoch: 96
2023-01-04 01:46:55,310 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43765333741903306, 'Total loss': 0.43765333741903306} | train loss {'Reaction outcome loss': 0.17746338709155574, 'Total loss': 0.17746338709155574}
2023-01-04 01:46:55,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:55,310 INFO:     Epoch: 97
2023-01-04 01:46:56,900 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4176183263460795, 'Total loss': 0.4176183263460795} | train loss {'Reaction outcome loss': 0.17418495341319673, 'Total loss': 0.17418495341319673}
2023-01-04 01:46:56,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:56,900 INFO:     Epoch: 98
2023-01-04 01:46:58,466 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4054142584403356, 'Total loss': 0.4054142584403356} | train loss {'Reaction outcome loss': 0.17533339234748788, 'Total loss': 0.17533339234748788}
2023-01-04 01:46:58,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:46:58,466 INFO:     Epoch: 99
2023-01-04 01:47:00,071 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43085731168588004, 'Total loss': 0.43085731168588004} | train loss {'Reaction outcome loss': 0.17593773132203705, 'Total loss': 0.17593773132203705}
2023-01-04 01:47:00,072 INFO:     Best model found after epoch 57 of 100.
2023-01-04 01:47:00,072 INFO:   Done with stage: TRAINING
2023-01-04 01:47:00,072 INFO:   Starting stage: EVALUATION
2023-01-04 01:47:00,205 INFO:   Done with stage: EVALUATION
2023-01-04 01:47:00,205 INFO:   Leaving out SEQ value Fold_4
2023-01-04 01:47:00,218 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:47:00,218 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:47:00,858 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:47:00,859 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:47:00,927 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:47:00,927 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:47:00,927 INFO:     No hyperparam tuning for this model
2023-01-04 01:47:00,927 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:47:00,927 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:47:00,928 INFO:     None feature selector for col prot
2023-01-04 01:47:00,928 INFO:     None feature selector for col prot
2023-01-04 01:47:00,928 INFO:     None feature selector for col prot
2023-01-04 01:47:00,929 INFO:     None feature selector for col chem
2023-01-04 01:47:00,929 INFO:     None feature selector for col chem
2023-01-04 01:47:00,929 INFO:     None feature selector for col chem
2023-01-04 01:47:00,929 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:47:00,929 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:47:00,930 INFO:     Number of params in model 70141
2023-01-04 01:47:00,933 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:47:00,933 INFO:   Starting stage: TRAINING
2023-01-04 01:47:00,977 INFO:     Val loss before train {'Reaction outcome loss': 1.0708066383997599, 'Total loss': 1.0708066383997599}
2023-01-04 01:47:00,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:00,977 INFO:     Epoch: 0
2023-01-04 01:47:02,600 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6617187658945719, 'Total loss': 0.6617187658945719} | train loss {'Reaction outcome loss': 0.8457369198617728, 'Total loss': 0.8457369198617728}
2023-01-04 01:47:02,600 INFO:     Found new best model at epoch 0
2023-01-04 01:47:02,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:02,601 INFO:     Epoch: 1
2023-01-04 01:47:04,212 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5546245237191518, 'Total loss': 0.5546245237191518} | train loss {'Reaction outcome loss': 0.6109154091581054, 'Total loss': 0.6109154091581054}
2023-01-04 01:47:04,212 INFO:     Found new best model at epoch 1
2023-01-04 01:47:04,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:04,213 INFO:     Epoch: 2
2023-01-04 01:47:05,785 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49205496509869895, 'Total loss': 0.49205496509869895} | train loss {'Reaction outcome loss': 0.5438086189079921, 'Total loss': 0.5438086189079921}
2023-01-04 01:47:05,786 INFO:     Found new best model at epoch 2
2023-01-04 01:47:05,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:05,786 INFO:     Epoch: 3
2023-01-04 01:47:07,399 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4728345195452372, 'Total loss': 0.4728345195452372} | train loss {'Reaction outcome loss': 0.50778713501126, 'Total loss': 0.50778713501126}
2023-01-04 01:47:07,399 INFO:     Found new best model at epoch 3
2023-01-04 01:47:07,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:07,400 INFO:     Epoch: 4
2023-01-04 01:47:09,000 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4551014691591263, 'Total loss': 0.4551014691591263} | train loss {'Reaction outcome loss': 0.4778483936682913, 'Total loss': 0.4778483936682913}
2023-01-04 01:47:09,000 INFO:     Found new best model at epoch 4
2023-01-04 01:47:09,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:09,001 INFO:     Epoch: 5
2023-01-04 01:47:10,605 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4211350748936335, 'Total loss': 0.4211350748936335} | train loss {'Reaction outcome loss': 0.45454356168372306, 'Total loss': 0.45454356168372306}
2023-01-04 01:47:10,605 INFO:     Found new best model at epoch 5
2023-01-04 01:47:10,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:10,606 INFO:     Epoch: 6
2023-01-04 01:47:12,215 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4113973528146744, 'Total loss': 0.4113973528146744} | train loss {'Reaction outcome loss': 0.4391981099286805, 'Total loss': 0.4391981099286805}
2023-01-04 01:47:12,215 INFO:     Found new best model at epoch 6
2023-01-04 01:47:12,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:12,216 INFO:     Epoch: 7
2023-01-04 01:47:13,804 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4219344953695933, 'Total loss': 0.4219344953695933} | train loss {'Reaction outcome loss': 0.42374569734396494, 'Total loss': 0.42374569734396494}
2023-01-04 01:47:13,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:13,804 INFO:     Epoch: 8
2023-01-04 01:47:15,398 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4050104121367137, 'Total loss': 0.4050104121367137} | train loss {'Reaction outcome loss': 0.415739254998988, 'Total loss': 0.415739254998988}
2023-01-04 01:47:15,398 INFO:     Found new best model at epoch 8
2023-01-04 01:47:15,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:15,399 INFO:     Epoch: 9
2023-01-04 01:47:17,009 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3999183932940165, 'Total loss': 0.3999183932940165} | train loss {'Reaction outcome loss': 0.40568369398892357, 'Total loss': 0.40568369398892357}
2023-01-04 01:47:17,010 INFO:     Found new best model at epoch 9
2023-01-04 01:47:17,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:17,011 INFO:     Epoch: 10
2023-01-04 01:47:18,626 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40710660417874656, 'Total loss': 0.40710660417874656} | train loss {'Reaction outcome loss': 0.3906751158815957, 'Total loss': 0.3906751158815957}
2023-01-04 01:47:18,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:18,626 INFO:     Epoch: 11
2023-01-04 01:47:20,241 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4044093072414398, 'Total loss': 0.4044093072414398} | train loss {'Reaction outcome loss': 0.38165521707918926, 'Total loss': 0.38165521707918926}
2023-01-04 01:47:20,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:20,242 INFO:     Epoch: 12
2023-01-04 01:47:21,862 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39866417745749155, 'Total loss': 0.39866417745749155} | train loss {'Reaction outcome loss': 0.3740355563822432, 'Total loss': 0.3740355563822432}
2023-01-04 01:47:21,862 INFO:     Found new best model at epoch 12
2023-01-04 01:47:21,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:21,863 INFO:     Epoch: 13
2023-01-04 01:47:23,439 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39351858496665953, 'Total loss': 0.39351858496665953} | train loss {'Reaction outcome loss': 0.36682483698152374, 'Total loss': 0.36682483698152374}
2023-01-04 01:47:23,440 INFO:     Found new best model at epoch 13
2023-01-04 01:47:23,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:23,441 INFO:     Epoch: 14
2023-01-04 01:47:25,053 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3974714368581772, 'Total loss': 0.3974714368581772} | train loss {'Reaction outcome loss': 0.35947975346251676, 'Total loss': 0.35947975346251676}
2023-01-04 01:47:25,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:25,053 INFO:     Epoch: 15
2023-01-04 01:47:26,650 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39753226737181346, 'Total loss': 0.39753226737181346} | train loss {'Reaction outcome loss': 0.3565729187558527, 'Total loss': 0.3565729187558527}
2023-01-04 01:47:26,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:26,651 INFO:     Epoch: 16
2023-01-04 01:47:28,247 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39339254597822826, 'Total loss': 0.39339254597822826} | train loss {'Reaction outcome loss': 0.3543021371588111, 'Total loss': 0.3543021371588111}
2023-01-04 01:47:28,247 INFO:     Found new best model at epoch 16
2023-01-04 01:47:28,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:28,248 INFO:     Epoch: 17
2023-01-04 01:47:29,845 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39124392370382943, 'Total loss': 0.39124392370382943} | train loss {'Reaction outcome loss': 0.3384063638149055, 'Total loss': 0.3384063638149055}
2023-01-04 01:47:29,845 INFO:     Found new best model at epoch 17
2023-01-04 01:47:29,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:29,846 INFO:     Epoch: 18
2023-01-04 01:47:31,443 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4045420875151952, 'Total loss': 0.4045420875151952} | train loss {'Reaction outcome loss': 0.33379810377411323, 'Total loss': 0.33379810377411323}
2023-01-04 01:47:31,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:31,443 INFO:     Epoch: 19
2023-01-04 01:47:33,011 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4107008109490077, 'Total loss': 0.4107008109490077} | train loss {'Reaction outcome loss': 0.3263508974670675, 'Total loss': 0.3263508974670675}
2023-01-04 01:47:33,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:33,012 INFO:     Epoch: 20
2023-01-04 01:47:34,632 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4043375829855601, 'Total loss': 0.4043375829855601} | train loss {'Reaction outcome loss': 0.3212161090063012, 'Total loss': 0.3212161090063012}
2023-01-04 01:47:34,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:34,632 INFO:     Epoch: 21
2023-01-04 01:47:36,253 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3902184704939524, 'Total loss': 0.3902184704939524} | train loss {'Reaction outcome loss': 0.3164879452661557, 'Total loss': 0.3164879452661557}
2023-01-04 01:47:36,254 INFO:     Found new best model at epoch 21
2023-01-04 01:47:36,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:36,254 INFO:     Epoch: 22
2023-01-04 01:47:37,857 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3966222087542216, 'Total loss': 0.3966222087542216} | train loss {'Reaction outcome loss': 0.309034881995235, 'Total loss': 0.309034881995235}
2023-01-04 01:47:37,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:37,857 INFO:     Epoch: 23
2023-01-04 01:47:39,471 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40043170750141144, 'Total loss': 0.40043170750141144} | train loss {'Reaction outcome loss': 0.3048685370553015, 'Total loss': 0.3048685370553015}
2023-01-04 01:47:39,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:39,471 INFO:     Epoch: 24
2023-01-04 01:47:41,064 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38378859758377076, 'Total loss': 0.38378859758377076} | train loss {'Reaction outcome loss': 0.30353440407771565, 'Total loss': 0.30353440407771565}
2023-01-04 01:47:41,064 INFO:     Found new best model at epoch 24
2023-01-04 01:47:41,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:41,065 INFO:     Epoch: 25
2023-01-04 01:47:42,653 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38908260067303974, 'Total loss': 0.38908260067303974} | train loss {'Reaction outcome loss': 0.3002649626830194, 'Total loss': 0.3002649626830194}
2023-01-04 01:47:42,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:42,653 INFO:     Epoch: 26
2023-01-04 01:47:44,276 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39120923578739164, 'Total loss': 0.39120923578739164} | train loss {'Reaction outcome loss': 0.2927088001278985, 'Total loss': 0.2927088001278985}
2023-01-04 01:47:44,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:44,277 INFO:     Epoch: 27
2023-01-04 01:47:45,880 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3857661157846451, 'Total loss': 0.3857661157846451} | train loss {'Reaction outcome loss': 0.2931859153120414, 'Total loss': 0.2931859153120414}
2023-01-04 01:47:45,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:45,880 INFO:     Epoch: 28
2023-01-04 01:47:47,500 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3949298789103826, 'Total loss': 0.3949298789103826} | train loss {'Reaction outcome loss': 0.29214085552645713, 'Total loss': 0.29214085552645713}
2023-01-04 01:47:47,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:47,501 INFO:     Epoch: 29
2023-01-04 01:47:49,112 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3905291388432185, 'Total loss': 0.3905291388432185} | train loss {'Reaction outcome loss': 0.27928272042080987, 'Total loss': 0.27928272042080987}
2023-01-04 01:47:49,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:49,112 INFO:     Epoch: 30
2023-01-04 01:47:50,699 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3932795246442159, 'Total loss': 0.3932795246442159} | train loss {'Reaction outcome loss': 0.2790822567269746, 'Total loss': 0.2790822567269746}
2023-01-04 01:47:50,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:50,700 INFO:     Epoch: 31
2023-01-04 01:47:52,293 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4057750185330709, 'Total loss': 0.4057750185330709} | train loss {'Reaction outcome loss': 0.2727672556302159, 'Total loss': 0.2727672556302159}
2023-01-04 01:47:52,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:52,293 INFO:     Epoch: 32
2023-01-04 01:47:53,900 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40442614555358886, 'Total loss': 0.40442614555358886} | train loss {'Reaction outcome loss': 0.2714445157924775, 'Total loss': 0.2714445157924775}
2023-01-04 01:47:53,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:53,902 INFO:     Epoch: 33
2023-01-04 01:47:55,521 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39930835912624996, 'Total loss': 0.39930835912624996} | train loss {'Reaction outcome loss': 0.2687354852288094, 'Total loss': 0.2687354852288094}
2023-01-04 01:47:55,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:55,521 INFO:     Epoch: 34
2023-01-04 01:47:57,140 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3827582250038783, 'Total loss': 0.3827582250038783} | train loss {'Reaction outcome loss': 0.26532823268486105, 'Total loss': 0.26532823268486105}
2023-01-04 01:47:57,141 INFO:     Found new best model at epoch 34
2023-01-04 01:47:57,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:57,141 INFO:     Epoch: 35
2023-01-04 01:47:58,750 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42175089915593467, 'Total loss': 0.42175089915593467} | train loss {'Reaction outcome loss': 0.26185337474231823, 'Total loss': 0.26185337474231823}
2023-01-04 01:47:58,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:47:58,750 INFO:     Epoch: 36
2023-01-04 01:48:00,317 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3981679598490397, 'Total loss': 0.3981679598490397} | train loss {'Reaction outcome loss': 0.2596277343041763, 'Total loss': 0.2596277343041763}
2023-01-04 01:48:00,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:00,318 INFO:     Epoch: 37
2023-01-04 01:48:01,942 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40469946364561715, 'Total loss': 0.40469946364561715} | train loss {'Reaction outcome loss': 0.25491251478303206, 'Total loss': 0.25491251478303206}
2023-01-04 01:48:01,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:01,943 INFO:     Epoch: 38
2023-01-04 01:48:03,563 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3906513343254725, 'Total loss': 0.3906513343254725} | train loss {'Reaction outcome loss': 0.25423650362685346, 'Total loss': 0.25423650362685346}
2023-01-04 01:48:03,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:03,563 INFO:     Epoch: 39
2023-01-04 01:48:05,187 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3930736561616262, 'Total loss': 0.3930736561616262} | train loss {'Reaction outcome loss': 0.24920628548083504, 'Total loss': 0.24920628548083504}
2023-01-04 01:48:05,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:05,188 INFO:     Epoch: 40
2023-01-04 01:48:06,815 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40632229248682655, 'Total loss': 0.40632229248682655} | train loss {'Reaction outcome loss': 0.2568585623892537, 'Total loss': 0.2568585623892537}
2023-01-04 01:48:06,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:06,815 INFO:     Epoch: 41
2023-01-04 01:48:08,419 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38371774355570476, 'Total loss': 0.38371774355570476} | train loss {'Reaction outcome loss': 0.2563294378581904, 'Total loss': 0.2563294378581904}
2023-01-04 01:48:08,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:08,419 INFO:     Epoch: 42
2023-01-04 01:48:10,001 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38782995343208315, 'Total loss': 0.38782995343208315} | train loss {'Reaction outcome loss': 0.2450993768263446, 'Total loss': 0.2450993768263446}
2023-01-04 01:48:10,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:10,002 INFO:     Epoch: 43
2023-01-04 01:48:11,598 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3910581886768341, 'Total loss': 0.3910581886768341} | train loss {'Reaction outcome loss': 0.23986426115785117, 'Total loss': 0.23986426115785117}
2023-01-04 01:48:11,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:11,598 INFO:     Epoch: 44
2023-01-04 01:48:13,192 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3999154766400655, 'Total loss': 0.3999154766400655} | train loss {'Reaction outcome loss': 0.23668914203417313, 'Total loss': 0.23668914203417313}
2023-01-04 01:48:13,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:13,193 INFO:     Epoch: 45
2023-01-04 01:48:14,796 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4098659783601761, 'Total loss': 0.4098659783601761} | train loss {'Reaction outcome loss': 0.24718000587291908, 'Total loss': 0.24718000587291908}
2023-01-04 01:48:14,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:14,796 INFO:     Epoch: 46
2023-01-04 01:48:16,396 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4052155683437983, 'Total loss': 0.4052155683437983} | train loss {'Reaction outcome loss': 0.24959899928501766, 'Total loss': 0.24959899928501766}
2023-01-04 01:48:16,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:16,396 INFO:     Epoch: 47
2023-01-04 01:48:17,977 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3966311166683833, 'Total loss': 0.3966311166683833} | train loss {'Reaction outcome loss': 0.2343363705482604, 'Total loss': 0.2343363705482604}
2023-01-04 01:48:17,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:17,977 INFO:     Epoch: 48
2023-01-04 01:48:19,593 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42256200114885967, 'Total loss': 0.42256200114885967} | train loss {'Reaction outcome loss': 0.2305040223189913, 'Total loss': 0.2305040223189913}
2023-01-04 01:48:19,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:19,593 INFO:     Epoch: 49
2023-01-04 01:48:21,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40596910019715626, 'Total loss': 0.40596910019715626} | train loss {'Reaction outcome loss': 0.22753650761222927, 'Total loss': 0.22753650761222927}
2023-01-04 01:48:21,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:21,212 INFO:     Epoch: 50
2023-01-04 01:48:22,829 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4150903324286143, 'Total loss': 0.4150903324286143} | train loss {'Reaction outcome loss': 0.2265957617525693, 'Total loss': 0.2265957617525693}
2023-01-04 01:48:22,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:22,829 INFO:     Epoch: 51
2023-01-04 01:48:24,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39117031494776405, 'Total loss': 0.39117031494776405} | train loss {'Reaction outcome loss': 0.22359908351390387, 'Total loss': 0.22359908351390387}
2023-01-04 01:48:24,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:24,452 INFO:     Epoch: 52
2023-01-04 01:48:26,047 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4255142241716385, 'Total loss': 0.4255142241716385} | train loss {'Reaction outcome loss': 0.22079111712554406, 'Total loss': 0.22079111712554406}
2023-01-04 01:48:26,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:26,047 INFO:     Epoch: 53
2023-01-04 01:48:27,645 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4173477053642273, 'Total loss': 0.4173477053642273} | train loss {'Reaction outcome loss': 0.22180483262886613, 'Total loss': 0.22180483262886613}
2023-01-04 01:48:27,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:27,646 INFO:     Epoch: 54
2023-01-04 01:48:29,270 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4060825894276301, 'Total loss': 0.4060825894276301} | train loss {'Reaction outcome loss': 0.21945774769056184, 'Total loss': 0.21945774769056184}
2023-01-04 01:48:29,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:29,271 INFO:     Epoch: 55
2023-01-04 01:48:30,868 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42366140087445575, 'Total loss': 0.42366140087445575} | train loss {'Reaction outcome loss': 0.21681587933900132, 'Total loss': 0.21681587933900132}
2023-01-04 01:48:30,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:30,869 INFO:     Epoch: 56
2023-01-04 01:48:32,490 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3917156229416529, 'Total loss': 0.3917156229416529} | train loss {'Reaction outcome loss': 0.2233671664017374, 'Total loss': 0.2233671664017374}
2023-01-04 01:48:32,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:32,490 INFO:     Epoch: 57
2023-01-04 01:48:34,118 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3977882325649261, 'Total loss': 0.3977882325649261} | train loss {'Reaction outcome loss': 0.21544603581761307, 'Total loss': 0.21544603581761307}
2023-01-04 01:48:34,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:34,118 INFO:     Epoch: 58
2023-01-04 01:48:35,703 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4013478259245555, 'Total loss': 0.4013478259245555} | train loss {'Reaction outcome loss': 0.21228835668164497, 'Total loss': 0.21228835668164497}
2023-01-04 01:48:35,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:35,704 INFO:     Epoch: 59
2023-01-04 01:48:37,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4043282310167948, 'Total loss': 0.4043282310167948} | train loss {'Reaction outcome loss': 0.20996660239124784, 'Total loss': 0.20996660239124784}
2023-01-04 01:48:37,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:37,277 INFO:     Epoch: 60
2023-01-04 01:48:38,899 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40919447541236875, 'Total loss': 0.40919447541236875} | train loss {'Reaction outcome loss': 0.21228023869511875, 'Total loss': 0.21228023869511875}
2023-01-04 01:48:38,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:38,900 INFO:     Epoch: 61
2023-01-04 01:48:40,525 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4232158655921618, 'Total loss': 0.4232158655921618} | train loss {'Reaction outcome loss': 0.21107488425416482, 'Total loss': 0.21107488425416482}
2023-01-04 01:48:40,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:40,525 INFO:     Epoch: 62
2023-01-04 01:48:42,130 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4105231106281281, 'Total loss': 0.4105231106281281} | train loss {'Reaction outcome loss': 0.20592133863871256, 'Total loss': 0.20592133863871256}
2023-01-04 01:48:42,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:42,130 INFO:     Epoch: 63
2023-01-04 01:48:43,762 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4455318510532379, 'Total loss': 0.4455318510532379} | train loss {'Reaction outcome loss': 0.20375727904720933, 'Total loss': 0.20375727904720933}
2023-01-04 01:48:43,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:43,762 INFO:     Epoch: 64
2023-01-04 01:48:45,353 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4441009263197581, 'Total loss': 0.4441009263197581} | train loss {'Reaction outcome loss': 0.2029164798706909, 'Total loss': 0.2029164798706909}
2023-01-04 01:48:45,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:45,353 INFO:     Epoch: 65
2023-01-04 01:48:46,975 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42263838251431785, 'Total loss': 0.42263838251431785} | train loss {'Reaction outcome loss': 0.20283468974061628, 'Total loss': 0.20283468974061628}
2023-01-04 01:48:46,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:46,975 INFO:     Epoch: 66
2023-01-04 01:48:48,601 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43074325025081633, 'Total loss': 0.43074325025081633} | train loss {'Reaction outcome loss': 0.20545797440074925, 'Total loss': 0.20545797440074925}
2023-01-04 01:48:48,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:48,602 INFO:     Epoch: 67
2023-01-04 01:48:50,210 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43314358542362846, 'Total loss': 0.43314358542362846} | train loss {'Reaction outcome loss': 0.21710838588035625, 'Total loss': 0.21710838588035625}
2023-01-04 01:48:50,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:50,210 INFO:     Epoch: 68
2023-01-04 01:48:51,836 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42524630228678384, 'Total loss': 0.42524630228678384} | train loss {'Reaction outcome loss': 0.2333447079368668, 'Total loss': 0.2333447079368668}
2023-01-04 01:48:51,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:51,837 INFO:     Epoch: 69
2023-01-04 01:48:53,436 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4026814952492714, 'Total loss': 0.4026814952492714} | train loss {'Reaction outcome loss': 0.20707312373417444, 'Total loss': 0.20707312373417444}
2023-01-04 01:48:53,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:53,436 INFO:     Epoch: 70
2023-01-04 01:48:55,037 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41496294140815737, 'Total loss': 0.41496294140815737} | train loss {'Reaction outcome loss': 0.20996189981267072, 'Total loss': 0.20996189981267072}
2023-01-04 01:48:55,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:55,038 INFO:     Epoch: 71
2023-01-04 01:48:56,659 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3872735038399696, 'Total loss': 0.3872735038399696} | train loss {'Reaction outcome loss': 0.2106711403466761, 'Total loss': 0.2106711403466761}
2023-01-04 01:48:56,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:56,660 INFO:     Epoch: 72
2023-01-04 01:48:58,279 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4298277030388514, 'Total loss': 0.4298277030388514} | train loss {'Reaction outcome loss': 0.19580627628222472, 'Total loss': 0.19580627628222472}
2023-01-04 01:48:58,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:58,279 INFO:     Epoch: 73
2023-01-04 01:48:59,900 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4497724155584971, 'Total loss': 0.4497724155584971} | train loss {'Reaction outcome loss': 0.1949220233267018, 'Total loss': 0.1949220233267018}
2023-01-04 01:48:59,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:48:59,901 INFO:     Epoch: 74
2023-01-04 01:49:01,516 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45234050154685973, 'Total loss': 0.45234050154685973} | train loss {'Reaction outcome loss': 0.1916169800321399, 'Total loss': 0.1916169800321399}
2023-01-04 01:49:01,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:01,517 INFO:     Epoch: 75
2023-01-04 01:49:03,096 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42549378822247186, 'Total loss': 0.42549378822247186} | train loss {'Reaction outcome loss': 0.19382511172443628, 'Total loss': 0.19382511172443628}
2023-01-04 01:49:03,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:03,096 INFO:     Epoch: 76
2023-01-04 01:49:04,678 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42861112852891287, 'Total loss': 0.42861112852891287} | train loss {'Reaction outcome loss': 0.21738714640167123, 'Total loss': 0.21738714640167123}
2023-01-04 01:49:04,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:04,678 INFO:     Epoch: 77
2023-01-04 01:49:06,269 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4620822429656982, 'Total loss': 0.4620822429656982} | train loss {'Reaction outcome loss': 0.1883340667767882, 'Total loss': 0.1883340667767882}
2023-01-04 01:49:06,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:06,270 INFO:     Epoch: 78
2023-01-04 01:49:07,885 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.410998722910881, 'Total loss': 0.410998722910881} | train loss {'Reaction outcome loss': 0.18839811308535517, 'Total loss': 0.18839811308535517}
2023-01-04 01:49:07,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:07,886 INFO:     Epoch: 79
2023-01-04 01:49:09,508 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43126669675111773, 'Total loss': 0.43126669675111773} | train loss {'Reaction outcome loss': 0.18379434634782915, 'Total loss': 0.18379434634782915}
2023-01-04 01:49:09,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:09,509 INFO:     Epoch: 80
2023-01-04 01:49:11,115 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4486412346363068, 'Total loss': 0.4486412346363068} | train loss {'Reaction outcome loss': 0.1855538791598941, 'Total loss': 0.1855538791598941}
2023-01-04 01:49:11,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:11,115 INFO:     Epoch: 81
2023-01-04 01:49:12,706 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43214101791381837, 'Total loss': 0.43214101791381837} | train loss {'Reaction outcome loss': 0.18178270912418762, 'Total loss': 0.18178270912418762}
2023-01-04 01:49:12,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:12,706 INFO:     Epoch: 82
2023-01-04 01:49:14,298 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47328850825627644, 'Total loss': 0.47328850825627644} | train loss {'Reaction outcome loss': 0.1851042278401334, 'Total loss': 0.1851042278401334}
2023-01-04 01:49:14,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:14,298 INFO:     Epoch: 83
2023-01-04 01:49:15,891 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4319345812002818, 'Total loss': 0.4319345812002818} | train loss {'Reaction outcome loss': 0.18208027801829038, 'Total loss': 0.18208027801829038}
2023-01-04 01:49:15,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:15,891 INFO:     Epoch: 84
2023-01-04 01:49:17,509 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43484131594498954, 'Total loss': 0.43484131594498954} | train loss {'Reaction outcome loss': 0.18202448311831834, 'Total loss': 0.18202448311831834}
2023-01-04 01:49:17,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:17,509 INFO:     Epoch: 85
2023-01-04 01:49:19,129 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4504963258902232, 'Total loss': 0.4504963258902232} | train loss {'Reaction outcome loss': 0.18127817901499246, 'Total loss': 0.18127817901499246}
2023-01-04 01:49:19,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:19,130 INFO:     Epoch: 86
2023-01-04 01:49:20,724 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4550760249296824, 'Total loss': 0.4550760249296824} | train loss {'Reaction outcome loss': 0.1836040580301019, 'Total loss': 0.1836040580301019}
2023-01-04 01:49:20,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:20,725 INFO:     Epoch: 87
2023-01-04 01:49:22,325 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4484758943319321, 'Total loss': 0.4484758943319321} | train loss {'Reaction outcome loss': 0.1779438550988941, 'Total loss': 0.1779438550988941}
2023-01-04 01:49:22,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:22,325 INFO:     Epoch: 88
2023-01-04 01:49:23,946 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43252354562282563, 'Total loss': 0.43252354562282563} | train loss {'Reaction outcome loss': 0.1796727633574873, 'Total loss': 0.1796727633574873}
2023-01-04 01:49:23,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:23,946 INFO:     Epoch: 89
2023-01-04 01:49:25,563 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45526593575874963, 'Total loss': 0.45526593575874963} | train loss {'Reaction outcome loss': 0.17406167448341403, 'Total loss': 0.17406167448341403}
2023-01-04 01:49:25,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:25,563 INFO:     Epoch: 90
2023-01-04 01:49:27,189 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4257136734823386, 'Total loss': 0.4257136734823386} | train loss {'Reaction outcome loss': 0.17731311720492976, 'Total loss': 0.17731311720492976}
2023-01-04 01:49:27,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:27,190 INFO:     Epoch: 91
2023-01-04 01:49:28,797 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43915141820907594, 'Total loss': 0.43915141820907594} | train loss {'Reaction outcome loss': 0.17347546892630117, 'Total loss': 0.17347546892630117}
2023-01-04 01:49:28,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:28,797 INFO:     Epoch: 92
2023-01-04 01:49:30,382 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4542124480009079, 'Total loss': 0.4542124480009079} | train loss {'Reaction outcome loss': 0.17382505082071514, 'Total loss': 0.17382505082071514}
2023-01-04 01:49:30,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:30,384 INFO:     Epoch: 93
2023-01-04 01:49:32,010 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43589954475561776, 'Total loss': 0.43589954475561776} | train loss {'Reaction outcome loss': 0.1751861183173774, 'Total loss': 0.1751861183173774}
2023-01-04 01:49:32,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:32,010 INFO:     Epoch: 94
2023-01-04 01:49:33,631 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4538215776284536, 'Total loss': 0.4538215776284536} | train loss {'Reaction outcome loss': 0.17361379431668614, 'Total loss': 0.17361379431668614}
2023-01-04 01:49:33,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:33,631 INFO:     Epoch: 95
2023-01-04 01:49:35,253 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4286212161183357, 'Total loss': 0.4286212161183357} | train loss {'Reaction outcome loss': 0.17399873434012567, 'Total loss': 0.17399873434012567}
2023-01-04 01:49:35,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:35,253 INFO:     Epoch: 96
2023-01-04 01:49:36,871 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44661068320274355, 'Total loss': 0.44661068320274355} | train loss {'Reaction outcome loss': 0.171420927365324, 'Total loss': 0.171420927365324}
2023-01-04 01:49:36,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:36,872 INFO:     Epoch: 97
2023-01-04 01:49:38,454 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4551663726568222, 'Total loss': 0.4551663726568222} | train loss {'Reaction outcome loss': 0.17115261710358132, 'Total loss': 0.17115261710358132}
2023-01-04 01:49:38,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:38,454 INFO:     Epoch: 98
2023-01-04 01:49:39,792 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4183533231417338, 'Total loss': 0.4183533231417338} | train loss {'Reaction outcome loss': 0.16970725228821865, 'Total loss': 0.16970725228821865}
2023-01-04 01:49:39,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:39,792 INFO:     Epoch: 99
2023-01-04 01:49:40,864 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42654630343119304, 'Total loss': 0.42654630343119304} | train loss {'Reaction outcome loss': 0.16832055625897172, 'Total loss': 0.16832055625897172}
2023-01-04 01:49:40,865 INFO:     Best model found after epoch 35 of 100.
2023-01-04 01:49:40,865 INFO:   Done with stage: TRAINING
2023-01-04 01:49:40,865 INFO:   Starting stage: EVALUATION
2023-01-04 01:49:40,991 INFO:   Done with stage: EVALUATION
2023-01-04 01:49:40,991 INFO:   Leaving out SEQ value Fold_5
2023-01-04 01:49:41,004 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:49:41,004 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:49:41,660 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:49:41,660 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:49:41,730 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:49:41,731 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:49:41,731 INFO:     No hyperparam tuning for this model
2023-01-04 01:49:41,731 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:49:41,731 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:49:41,732 INFO:     None feature selector for col prot
2023-01-04 01:49:41,732 INFO:     None feature selector for col prot
2023-01-04 01:49:41,732 INFO:     None feature selector for col prot
2023-01-04 01:49:41,732 INFO:     None feature selector for col chem
2023-01-04 01:49:41,732 INFO:     None feature selector for col chem
2023-01-04 01:49:41,732 INFO:     None feature selector for col chem
2023-01-04 01:49:41,733 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:49:41,733 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:49:41,734 INFO:     Number of params in model 70141
2023-01-04 01:49:41,737 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:49:41,737 INFO:   Starting stage: TRAINING
2023-01-04 01:49:41,771 INFO:     Val loss before train {'Reaction outcome loss': 0.8177390853563945, 'Total loss': 0.8177390853563945}
2023-01-04 01:49:41,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:41,771 INFO:     Epoch: 0
2023-01-04 01:49:42,840 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6064751803874969, 'Total loss': 0.6064751803874969} | train loss {'Reaction outcome loss': 0.8403184224552196, 'Total loss': 0.8403184224552196}
2023-01-04 01:49:42,840 INFO:     Found new best model at epoch 0
2023-01-04 01:49:42,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:42,841 INFO:     Epoch: 1
2023-01-04 01:49:43,918 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5258938650290171, 'Total loss': 0.5258938650290171} | train loss {'Reaction outcome loss': 0.6215694502587783, 'Total loss': 0.6215694502587783}
2023-01-04 01:49:43,918 INFO:     Found new best model at epoch 1
2023-01-04 01:49:43,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:43,919 INFO:     Epoch: 2
2023-01-04 01:49:45,506 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.453558886051178, 'Total loss': 0.453558886051178} | train loss {'Reaction outcome loss': 0.5430999900674992, 'Total loss': 0.5430999900674992}
2023-01-04 01:49:45,506 INFO:     Found new best model at epoch 2
2023-01-04 01:49:45,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:45,507 INFO:     Epoch: 3
2023-01-04 01:49:47,129 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42889587779839833, 'Total loss': 0.42889587779839833} | train loss {'Reaction outcome loss': 0.49966375083269193, 'Total loss': 0.49966375083269193}
2023-01-04 01:49:47,130 INFO:     Found new best model at epoch 3
2023-01-04 01:49:47,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:47,130 INFO:     Epoch: 4
2023-01-04 01:49:48,754 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4312658021847407, 'Total loss': 0.4312658021847407} | train loss {'Reaction outcome loss': 0.46738340240308096, 'Total loss': 0.46738340240308096}
2023-01-04 01:49:48,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:48,754 INFO:     Epoch: 5
2023-01-04 01:49:50,361 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40205609997113545, 'Total loss': 0.40205609997113545} | train loss {'Reaction outcome loss': 0.4442522410666469, 'Total loss': 0.4442522410666469}
2023-01-04 01:49:50,362 INFO:     Found new best model at epoch 5
2023-01-04 01:49:50,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:50,363 INFO:     Epoch: 6
2023-01-04 01:49:51,987 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3926823496818542, 'Total loss': 0.3926823496818542} | train loss {'Reaction outcome loss': 0.4279522282014255, 'Total loss': 0.4279522282014255}
2023-01-04 01:49:51,987 INFO:     Found new best model at epoch 6
2023-01-04 01:49:51,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:51,988 INFO:     Epoch: 7
2023-01-04 01:49:53,568 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39113510549068453, 'Total loss': 0.39113510549068453} | train loss {'Reaction outcome loss': 0.4113857136629118, 'Total loss': 0.4113857136629118}
2023-01-04 01:49:53,568 INFO:     Found new best model at epoch 7
2023-01-04 01:49:53,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:53,569 INFO:     Epoch: 8
2023-01-04 01:49:55,181 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38052498996257783, 'Total loss': 0.38052498996257783} | train loss {'Reaction outcome loss': 0.39972294791726, 'Total loss': 0.39972294791726}
2023-01-04 01:49:55,181 INFO:     Found new best model at epoch 8
2023-01-04 01:49:55,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:55,182 INFO:     Epoch: 9
2023-01-04 01:49:56,808 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37872178057829536, 'Total loss': 0.37872178057829536} | train loss {'Reaction outcome loss': 0.3900249698854956, 'Total loss': 0.3900249698854956}
2023-01-04 01:49:56,808 INFO:     Found new best model at epoch 9
2023-01-04 01:49:56,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:56,809 INFO:     Epoch: 10
2023-01-04 01:49:58,433 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3823340872923533, 'Total loss': 0.3823340872923533} | train loss {'Reaction outcome loss': 0.37996529435422877, 'Total loss': 0.37996529435422877}
2023-01-04 01:49:58,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:49:58,433 INFO:     Epoch: 11
2023-01-04 01:50:00,060 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3590572843949, 'Total loss': 0.3590572843949} | train loss {'Reaction outcome loss': 0.37017447240516166, 'Total loss': 0.37017447240516166}
2023-01-04 01:50:00,060 INFO:     Found new best model at epoch 11
2023-01-04 01:50:00,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:00,061 INFO:     Epoch: 12
2023-01-04 01:50:01,667 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36613903641700746, 'Total loss': 0.36613903641700746} | train loss {'Reaction outcome loss': 0.3633540408813566, 'Total loss': 0.3633540408813566}
2023-01-04 01:50:01,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:01,669 INFO:     Epoch: 13
2023-01-04 01:50:03,237 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35791973272959393, 'Total loss': 0.35791973272959393} | train loss {'Reaction outcome loss': 0.35570481812265375, 'Total loss': 0.35570481812265375}
2023-01-04 01:50:03,237 INFO:     Found new best model at epoch 13
2023-01-04 01:50:03,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:03,238 INFO:     Epoch: 14
2023-01-04 01:50:04,834 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37445169140895207, 'Total loss': 0.37445169140895207} | train loss {'Reaction outcome loss': 0.3500216326504838, 'Total loss': 0.3500216326504838}
2023-01-04 01:50:04,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:04,834 INFO:     Epoch: 15
2023-01-04 01:50:06,430 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3602909843126933, 'Total loss': 0.3602909843126933} | train loss {'Reaction outcome loss': 0.3445191734641898, 'Total loss': 0.3445191734641898}
2023-01-04 01:50:06,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:06,430 INFO:     Epoch: 16
2023-01-04 01:50:08,027 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3632404039303462, 'Total loss': 0.3632404039303462} | train loss {'Reaction outcome loss': 0.33525916151298946, 'Total loss': 0.33525916151298946}
2023-01-04 01:50:08,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:08,028 INFO:     Epoch: 17
2023-01-04 01:50:09,635 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.361719411611557, 'Total loss': 0.361719411611557} | train loss {'Reaction outcome loss': 0.33171110678235544, 'Total loss': 0.33171110678235544}
2023-01-04 01:50:09,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:09,636 INFO:     Epoch: 18
2023-01-04 01:50:11,237 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38534164826075235, 'Total loss': 0.38534164826075235} | train loss {'Reaction outcome loss': 0.3240197416300808, 'Total loss': 0.3240197416300808}
2023-01-04 01:50:11,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:11,238 INFO:     Epoch: 19
2023-01-04 01:50:12,839 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36499204436937965, 'Total loss': 0.36499204436937965} | train loss {'Reaction outcome loss': 0.31996151377255305, 'Total loss': 0.31996151377255305}
2023-01-04 01:50:12,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:12,840 INFO:     Epoch: 20
2023-01-04 01:50:14,475 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3534577866395315, 'Total loss': 0.3534577866395315} | train loss {'Reaction outcome loss': 0.31499566468628737, 'Total loss': 0.31499566468628737}
2023-01-04 01:50:14,475 INFO:     Found new best model at epoch 20
2023-01-04 01:50:14,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:14,476 INFO:     Epoch: 21
2023-01-04 01:50:16,082 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3583662440379461, 'Total loss': 0.3583662440379461} | train loss {'Reaction outcome loss': 0.30755571725136105, 'Total loss': 0.30755571725136105}
2023-01-04 01:50:16,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:16,082 INFO:     Epoch: 22
2023-01-04 01:50:17,710 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3530373215675354, 'Total loss': 0.3530373215675354} | train loss {'Reaction outcome loss': 0.30142040679816307, 'Total loss': 0.30142040679816307}
2023-01-04 01:50:17,710 INFO:     Found new best model at epoch 22
2023-01-04 01:50:17,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:17,711 INFO:     Epoch: 23
2023-01-04 01:50:19,332 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3861916477481524, 'Total loss': 0.3861916477481524} | train loss {'Reaction outcome loss': 0.2969982157115041, 'Total loss': 0.2969982157115041}
2023-01-04 01:50:19,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:19,332 INFO:     Epoch: 24
2023-01-04 01:50:20,913 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35472113688786827, 'Total loss': 0.35472113688786827} | train loss {'Reaction outcome loss': 0.2948496000646254, 'Total loss': 0.2948496000646254}
2023-01-04 01:50:20,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:20,914 INFO:     Epoch: 25
2023-01-04 01:50:22,542 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3532476112246513, 'Total loss': 0.3532476112246513} | train loss {'Reaction outcome loss': 0.28848497203756324, 'Total loss': 0.28848497203756324}
2023-01-04 01:50:22,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:22,542 INFO:     Epoch: 26
2023-01-04 01:50:24,165 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3491676007707914, 'Total loss': 0.3491676007707914} | train loss {'Reaction outcome loss': 0.28682860390481535, 'Total loss': 0.28682860390481535}
2023-01-04 01:50:24,166 INFO:     Found new best model at epoch 26
2023-01-04 01:50:24,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:24,166 INFO:     Epoch: 27
2023-01-04 01:50:25,801 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37129781941572826, 'Total loss': 0.37129781941572826} | train loss {'Reaction outcome loss': 0.2782338774672269, 'Total loss': 0.2782338774672269}
2023-01-04 01:50:25,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:25,801 INFO:     Epoch: 28
2023-01-04 01:50:27,437 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.34880224366982776, 'Total loss': 0.34880224366982776} | train loss {'Reaction outcome loss': 0.27757276702228434, 'Total loss': 0.27757276702228434}
2023-01-04 01:50:27,437 INFO:     Found new best model at epoch 28
2023-01-04 01:50:27,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:27,438 INFO:     Epoch: 29
2023-01-04 01:50:29,050 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3652809619903564, 'Total loss': 0.3652809619903564} | train loss {'Reaction outcome loss': 0.27197337775938346, 'Total loss': 0.27197337775938346}
2023-01-04 01:50:29,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:29,050 INFO:     Epoch: 30
2023-01-04 01:50:30,642 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.361007629831632, 'Total loss': 0.361007629831632} | train loss {'Reaction outcome loss': 0.27009844618583845, 'Total loss': 0.27009844618583845}
2023-01-04 01:50:30,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:30,642 INFO:     Epoch: 31
2023-01-04 01:50:32,266 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3517225806911786, 'Total loss': 0.3517225806911786} | train loss {'Reaction outcome loss': 0.2668218583285486, 'Total loss': 0.2668218583285486}
2023-01-04 01:50:32,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:32,266 INFO:     Epoch: 32
2023-01-04 01:50:33,892 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35164769291877745, 'Total loss': 0.35164769291877745} | train loss {'Reaction outcome loss': 0.26180514378560577, 'Total loss': 0.26180514378560577}
2023-01-04 01:50:33,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:33,892 INFO:     Epoch: 33
2023-01-04 01:50:35,516 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34554996291796364, 'Total loss': 0.34554996291796364} | train loss {'Reaction outcome loss': 0.26040736015630545, 'Total loss': 0.26040736015630545}
2023-01-04 01:50:35,516 INFO:     Found new best model at epoch 33
2023-01-04 01:50:35,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:35,517 INFO:     Epoch: 34
2023-01-04 01:50:37,138 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3780919581651688, 'Total loss': 0.3780919581651688} | train loss {'Reaction outcome loss': 0.25493266005808696, 'Total loss': 0.25493266005808696}
2023-01-04 01:50:37,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:37,139 INFO:     Epoch: 35
2023-01-04 01:50:38,733 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3662872344255447, 'Total loss': 0.3662872344255447} | train loss {'Reaction outcome loss': 0.25421349238940527, 'Total loss': 0.25421349238940527}
2023-01-04 01:50:38,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:38,734 INFO:     Epoch: 36
2023-01-04 01:50:40,355 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37993890394767127, 'Total loss': 0.37993890394767127} | train loss {'Reaction outcome loss': 0.2503123418949141, 'Total loss': 0.2503123418949141}
2023-01-04 01:50:40,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:40,355 INFO:     Epoch: 37
2023-01-04 01:50:41,979 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3688218782345454, 'Total loss': 0.3688218782345454} | train loss {'Reaction outcome loss': 0.2467552464092251, 'Total loss': 0.2467552464092251}
2023-01-04 01:50:41,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:41,979 INFO:     Epoch: 38
2023-01-04 01:50:43,596 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3577701022227605, 'Total loss': 0.3577701022227605} | train loss {'Reaction outcome loss': 0.24666130242849085, 'Total loss': 0.24666130242849085}
2023-01-04 01:50:43,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:43,597 INFO:     Epoch: 39
2023-01-04 01:50:45,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3933846871058146, 'Total loss': 0.3933846871058146} | train loss {'Reaction outcome loss': 0.24112126158570554, 'Total loss': 0.24112126158570554}
2023-01-04 01:50:45,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:45,224 INFO:     Epoch: 40
2023-01-04 01:50:46,844 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37184070646762846, 'Total loss': 0.37184070646762846} | train loss {'Reaction outcome loss': 0.24104778457849896, 'Total loss': 0.24104778457849896}
2023-01-04 01:50:46,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:46,844 INFO:     Epoch: 41
2023-01-04 01:50:48,425 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38132285376389824, 'Total loss': 0.38132285376389824} | train loss {'Reaction outcome loss': 0.23731371390529057, 'Total loss': 0.23731371390529057}
2023-01-04 01:50:48,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:48,425 INFO:     Epoch: 42
2023-01-04 01:50:50,044 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38264881471792855, 'Total loss': 0.38264881471792855} | train loss {'Reaction outcome loss': 0.23046199568557396, 'Total loss': 0.23046199568557396}
2023-01-04 01:50:50,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:50,044 INFO:     Epoch: 43
2023-01-04 01:50:51,669 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37445793449878695, 'Total loss': 0.37445793449878695} | train loss {'Reaction outcome loss': 0.2330509116503306, 'Total loss': 0.2330509116503306}
2023-01-04 01:50:51,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:51,669 INFO:     Epoch: 44
2023-01-04 01:50:53,292 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36123043100039165, 'Total loss': 0.36123043100039165} | train loss {'Reaction outcome loss': 0.23218108394892636, 'Total loss': 0.23218108394892636}
2023-01-04 01:50:53,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:53,293 INFO:     Epoch: 45
2023-01-04 01:50:54,908 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35807398756345116, 'Total loss': 0.35807398756345116} | train loss {'Reaction outcome loss': 0.22548426477917696, 'Total loss': 0.22548426477917696}
2023-01-04 01:50:54,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:54,908 INFO:     Epoch: 46
2023-01-04 01:50:56,487 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.410767126083374, 'Total loss': 0.410767126083374} | train loss {'Reaction outcome loss': 0.22693403133120563, 'Total loss': 0.22693403133120563}
2023-01-04 01:50:56,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:56,488 INFO:     Epoch: 47
2023-01-04 01:50:58,074 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3775908996661504, 'Total loss': 0.3775908996661504} | train loss {'Reaction outcome loss': 0.22473792200538226, 'Total loss': 0.22473792200538226}
2023-01-04 01:50:58,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:58,074 INFO:     Epoch: 48
2023-01-04 01:50:59,675 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39357780367136, 'Total loss': 0.39357780367136} | train loss {'Reaction outcome loss': 0.2224328555099478, 'Total loss': 0.2224328555099478}
2023-01-04 01:50:59,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:50:59,675 INFO:     Epoch: 49
2023-01-04 01:51:01,293 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37310740252335867, 'Total loss': 0.37310740252335867} | train loss {'Reaction outcome loss': 0.22027628118380743, 'Total loss': 0.22027628118380743}
2023-01-04 01:51:01,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:01,293 INFO:     Epoch: 50
2023-01-04 01:51:02,923 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3769255513946215, 'Total loss': 0.3769255513946215} | train loss {'Reaction outcome loss': 0.21858722081791193, 'Total loss': 0.21858722081791193}
2023-01-04 01:51:02,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:02,923 INFO:     Epoch: 51
2023-01-04 01:51:04,549 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39381652474403384, 'Total loss': 0.39381652474403384} | train loss {'Reaction outcome loss': 0.21595616216371205, 'Total loss': 0.21595616216371205}
2023-01-04 01:51:04,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:04,549 INFO:     Epoch: 52
2023-01-04 01:51:06,125 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3603352750341097, 'Total loss': 0.3603352750341097} | train loss {'Reaction outcome loss': 0.21520915653032086, 'Total loss': 0.21520915653032086}
2023-01-04 01:51:06,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:06,125 INFO:     Epoch: 53
2023-01-04 01:51:07,721 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3671102553606033, 'Total loss': 0.3671102553606033} | train loss {'Reaction outcome loss': 0.21267976618576998, 'Total loss': 0.21267976618576998}
2023-01-04 01:51:07,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:07,722 INFO:     Epoch: 54
2023-01-04 01:51:09,317 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3788330271840096, 'Total loss': 0.3788330271840096} | train loss {'Reaction outcome loss': 0.20987124735697943, 'Total loss': 0.20987124735697943}
2023-01-04 01:51:09,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:09,317 INFO:     Epoch: 55
2023-01-04 01:51:10,913 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3846283694108327, 'Total loss': 0.3846283694108327} | train loss {'Reaction outcome loss': 0.2096562226326457, 'Total loss': 0.2096562226326457}
2023-01-04 01:51:10,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:10,914 INFO:     Epoch: 56
2023-01-04 01:51:12,517 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39221683144569397, 'Total loss': 0.39221683144569397} | train loss {'Reaction outcome loss': 0.20840418137045114, 'Total loss': 0.20840418137045114}
2023-01-04 01:51:12,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:12,517 INFO:     Epoch: 57
2023-01-04 01:51:14,137 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37862357397874197, 'Total loss': 0.37862357397874197} | train loss {'Reaction outcome loss': 0.20888514680929132, 'Total loss': 0.20888514680929132}
2023-01-04 01:51:14,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:14,137 INFO:     Epoch: 58
2023-01-04 01:51:15,734 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37291257282098134, 'Total loss': 0.37291257282098134} | train loss {'Reaction outcome loss': 0.20368662574715132, 'Total loss': 0.20368662574715132}
2023-01-04 01:51:15,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:15,735 INFO:     Epoch: 59
2023-01-04 01:51:17,332 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40794944763183594, 'Total loss': 0.40794944763183594} | train loss {'Reaction outcome loss': 0.2036037945898001, 'Total loss': 0.2036037945898001}
2023-01-04 01:51:17,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:17,332 INFO:     Epoch: 60
2023-01-04 01:51:18,927 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37564317335685093, 'Total loss': 0.37564317335685093} | train loss {'Reaction outcome loss': 0.2035127617149792, 'Total loss': 0.2035127617149792}
2023-01-04 01:51:18,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:18,927 INFO:     Epoch: 61
2023-01-04 01:51:20,547 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40575416882832843, 'Total loss': 0.40575416882832843} | train loss {'Reaction outcome loss': 0.20045620670360564, 'Total loss': 0.20045620670360564}
2023-01-04 01:51:20,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:20,548 INFO:     Epoch: 62
2023-01-04 01:51:22,180 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34877221484978993, 'Total loss': 0.34877221484978993} | train loss {'Reaction outcome loss': 0.2003931415062196, 'Total loss': 0.2003931415062196}
2023-01-04 01:51:22,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:22,180 INFO:     Epoch: 63
2023-01-04 01:51:23,760 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3653665520250797, 'Total loss': 0.3653665520250797} | train loss {'Reaction outcome loss': 0.1980802065252397, 'Total loss': 0.1980802065252397}
2023-01-04 01:51:23,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:23,761 INFO:     Epoch: 64
2023-01-04 01:51:25,363 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37936068028211595, 'Total loss': 0.37936068028211595} | train loss {'Reaction outcome loss': 0.19747603544797276, 'Total loss': 0.19747603544797276}
2023-01-04 01:51:25,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:25,363 INFO:     Epoch: 65
2023-01-04 01:51:26,986 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38145349820454916, 'Total loss': 0.38145349820454916} | train loss {'Reaction outcome loss': 0.19435951829171783, 'Total loss': 0.19435951829171783}
2023-01-04 01:51:26,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:26,987 INFO:     Epoch: 66
2023-01-04 01:51:28,617 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39200311303138735, 'Total loss': 0.39200311303138735} | train loss {'Reaction outcome loss': 0.19653832989102665, 'Total loss': 0.19653832989102665}
2023-01-04 01:51:28,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:28,617 INFO:     Epoch: 67
2023-01-04 01:51:30,249 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3856002296010653, 'Total loss': 0.3856002296010653} | train loss {'Reaction outcome loss': 0.19360968184116084, 'Total loss': 0.19360968184116084}
2023-01-04 01:51:30,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:30,249 INFO:     Epoch: 68
2023-01-04 01:51:31,837 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39677386383215585, 'Total loss': 0.39677386383215585} | train loss {'Reaction outcome loss': 0.1929487630267651, 'Total loss': 0.1929487630267651}
2023-01-04 01:51:31,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:31,837 INFO:     Epoch: 69
2023-01-04 01:51:33,405 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3940418943762779, 'Total loss': 0.3940418943762779} | train loss {'Reaction outcome loss': 0.19166532538105005, 'Total loss': 0.19166532538105005}
2023-01-04 01:51:33,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:33,405 INFO:     Epoch: 70
2023-01-04 01:51:35,013 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39242919310927393, 'Total loss': 0.39242919310927393} | train loss {'Reaction outcome loss': 0.19146024417266627, 'Total loss': 0.19146024417266627}
2023-01-04 01:51:35,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:35,013 INFO:     Epoch: 71
2023-01-04 01:51:36,618 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3506447369853655, 'Total loss': 0.3506447369853655} | train loss {'Reaction outcome loss': 0.18905096624840037, 'Total loss': 0.18905096624840037}
2023-01-04 01:51:36,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:36,618 INFO:     Epoch: 72
2023-01-04 01:51:38,249 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37805463671684264, 'Total loss': 0.37805463671684264} | train loss {'Reaction outcome loss': 0.187355130749489, 'Total loss': 0.187355130749489}
2023-01-04 01:51:38,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:38,250 INFO:     Epoch: 73
2023-01-04 01:51:39,870 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37159288028875986, 'Total loss': 0.37159288028875986} | train loss {'Reaction outcome loss': 0.18915373573099878, 'Total loss': 0.18915373573099878}
2023-01-04 01:51:39,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:39,871 INFO:     Epoch: 74
2023-01-04 01:51:41,473 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3707594096660614, 'Total loss': 0.3707594096660614} | train loss {'Reaction outcome loss': 0.1867909840365287, 'Total loss': 0.1867909840365287}
2023-01-04 01:51:41,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:41,474 INFO:     Epoch: 75
2023-01-04 01:51:43,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39974137643973034, 'Total loss': 0.39974137643973034} | train loss {'Reaction outcome loss': 0.18500661689263603, 'Total loss': 0.18500661689263603}
2023-01-04 01:51:43,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:43,084 INFO:     Epoch: 76
2023-01-04 01:51:44,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39483084877332053, 'Total loss': 0.39483084877332053} | train loss {'Reaction outcome loss': 0.18571714704540232, 'Total loss': 0.18571714704540232}
2023-01-04 01:51:44,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:44,702 INFO:     Epoch: 77
2023-01-04 01:51:46,303 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36571656763553617, 'Total loss': 0.36571656763553617} | train loss {'Reaction outcome loss': 0.1872816528546681, 'Total loss': 0.1872816528546681}
2023-01-04 01:51:46,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:46,303 INFO:     Epoch: 78
2023-01-04 01:51:47,932 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36482831090688705, 'Total loss': 0.36482831090688705} | train loss {'Reaction outcome loss': 0.18407100374517887, 'Total loss': 0.18407100374517887}
2023-01-04 01:51:47,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:47,933 INFO:     Epoch: 79
2023-01-04 01:51:49,540 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42171820203463234, 'Total loss': 0.42171820203463234} | train loss {'Reaction outcome loss': 0.18176733775044177, 'Total loss': 0.18176733775044177}
2023-01-04 01:51:49,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:49,540 INFO:     Epoch: 80
2023-01-04 01:51:51,116 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.386873867114385, 'Total loss': 0.386873867114385} | train loss {'Reaction outcome loss': 0.18276511284015023, 'Total loss': 0.18276511284015023}
2023-01-04 01:51:51,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:51,117 INFO:     Epoch: 81
2023-01-04 01:51:52,742 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39957048147916796, 'Total loss': 0.39957048147916796} | train loss {'Reaction outcome loss': 0.1815119021461221, 'Total loss': 0.1815119021461221}
2023-01-04 01:51:52,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:52,742 INFO:     Epoch: 82
2023-01-04 01:51:54,377 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36478228072325386, 'Total loss': 0.36478228072325386} | train loss {'Reaction outcome loss': 0.17990309976390984, 'Total loss': 0.17990309976390984}
2023-01-04 01:51:54,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:54,377 INFO:     Epoch: 83
2023-01-04 01:51:56,000 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3831044346094131, 'Total loss': 0.3831044346094131} | train loss {'Reaction outcome loss': 0.1814221849745738, 'Total loss': 0.1814221849745738}
2023-01-04 01:51:56,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:56,001 INFO:     Epoch: 84
2023-01-04 01:51:57,635 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37012032195925715, 'Total loss': 0.37012032195925715} | train loss {'Reaction outcome loss': 0.1788467388559765, 'Total loss': 0.1788467388559765}
2023-01-04 01:51:57,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:57,635 INFO:     Epoch: 85
2023-01-04 01:51:59,252 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37811631162961323, 'Total loss': 0.37811631162961323} | train loss {'Reaction outcome loss': 0.1787561736597481, 'Total loss': 0.1787561736597481}
2023-01-04 01:51:59,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:51:59,253 INFO:     Epoch: 86
2023-01-04 01:52:00,840 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37776235391696295, 'Total loss': 0.37776235391696295} | train loss {'Reaction outcome loss': 0.17661642759285248, 'Total loss': 0.17661642759285248}
2023-01-04 01:52:00,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:00,841 INFO:     Epoch: 87
2023-01-04 01:52:02,469 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3614074602723122, 'Total loss': 0.3614074602723122} | train loss {'Reaction outcome loss': 0.1744129233707805, 'Total loss': 0.1744129233707805}
2023-01-04 01:52:02,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:02,469 INFO:     Epoch: 88
2023-01-04 01:52:04,097 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37835880517959597, 'Total loss': 0.37835880517959597} | train loss {'Reaction outcome loss': 0.17435491945096948, 'Total loss': 0.17435491945096948}
2023-01-04 01:52:04,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:04,097 INFO:     Epoch: 89
2023-01-04 01:52:05,722 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.398528191447258, 'Total loss': 0.398528191447258} | train loss {'Reaction outcome loss': 0.17588181563716934, 'Total loss': 0.17588181563716934}
2023-01-04 01:52:05,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:05,722 INFO:     Epoch: 90
2023-01-04 01:52:07,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42412719627221424, 'Total loss': 0.42412719627221424} | train loss {'Reaction outcome loss': 0.17356791747364111, 'Total loss': 0.17356791747364111}
2023-01-04 01:52:07,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:07,346 INFO:     Epoch: 91
2023-01-04 01:52:08,939 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3801835497220357, 'Total loss': 0.3801835497220357} | train loss {'Reaction outcome loss': 0.1738132489542561, 'Total loss': 0.1738132489542561}
2023-01-04 01:52:08,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:08,940 INFO:     Epoch: 92
2023-01-04 01:52:10,560 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3923852334419886, 'Total loss': 0.3923852334419886} | train loss {'Reaction outcome loss': 0.17627906776453614, 'Total loss': 0.17627906776453614}
2023-01-04 01:52:10,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:10,560 INFO:     Epoch: 93
2023-01-04 01:52:12,188 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36552450036009154, 'Total loss': 0.36552450036009154} | train loss {'Reaction outcome loss': 0.17232613455141063, 'Total loss': 0.17232613455141063}
2023-01-04 01:52:12,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:12,188 INFO:     Epoch: 94
2023-01-04 01:52:13,817 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3808801181614399, 'Total loss': 0.3808801181614399} | train loss {'Reaction outcome loss': 0.1750139881140596, 'Total loss': 0.1750139881140596}
2023-01-04 01:52:13,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:13,817 INFO:     Epoch: 95
2023-01-04 01:52:15,427 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3907285302877426, 'Total loss': 0.3907285302877426} | train loss {'Reaction outcome loss': 0.1709053786908569, 'Total loss': 0.1709053786908569}
2023-01-04 01:52:15,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:15,428 INFO:     Epoch: 96
2023-01-04 01:52:17,042 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39851568043231966, 'Total loss': 0.39851568043231966} | train loss {'Reaction outcome loss': 0.17012517113870662, 'Total loss': 0.17012517113870662}
2023-01-04 01:52:17,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:17,042 INFO:     Epoch: 97
2023-01-04 01:52:18,619 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38357250491778055, 'Total loss': 0.38357250491778055} | train loss {'Reaction outcome loss': 0.17198096122928905, 'Total loss': 0.17198096122928905}
2023-01-04 01:52:18,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:18,620 INFO:     Epoch: 98
2023-01-04 01:52:20,227 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4020706355571747, 'Total loss': 0.4020706355571747} | train loss {'Reaction outcome loss': 0.17058003744251676, 'Total loss': 0.17058003744251676}
2023-01-04 01:52:20,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:20,228 INFO:     Epoch: 99
2023-01-04 01:52:21,834 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3887777497371038, 'Total loss': 0.3887777497371038} | train loss {'Reaction outcome loss': 0.17134377391275946, 'Total loss': 0.17134377391275946}
2023-01-04 01:52:21,834 INFO:     Best model found after epoch 34 of 100.
2023-01-04 01:52:21,834 INFO:   Done with stage: TRAINING
2023-01-04 01:52:21,835 INFO:   Starting stage: EVALUATION
2023-01-04 01:52:21,956 INFO:   Done with stage: EVALUATION
2023-01-04 01:52:21,956 INFO:   Leaving out SEQ value Fold_6
2023-01-04 01:52:21,969 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 01:52:21,969 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:52:22,617 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:52:22,617 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:52:22,686 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:52:22,687 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:52:22,687 INFO:     No hyperparam tuning for this model
2023-01-04 01:52:22,687 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:52:22,687 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:52:22,688 INFO:     None feature selector for col prot
2023-01-04 01:52:22,688 INFO:     None feature selector for col prot
2023-01-04 01:52:22,688 INFO:     None feature selector for col prot
2023-01-04 01:52:22,688 INFO:     None feature selector for col chem
2023-01-04 01:52:22,689 INFO:     None feature selector for col chem
2023-01-04 01:52:22,689 INFO:     None feature selector for col chem
2023-01-04 01:52:22,689 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:52:22,689 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:52:22,690 INFO:     Number of params in model 70141
2023-01-04 01:52:22,693 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:52:22,693 INFO:   Starting stage: TRAINING
2023-01-04 01:52:22,737 INFO:     Val loss before train {'Reaction outcome loss': 0.9386251290639241, 'Total loss': 0.9386251290639241}
2023-01-04 01:52:22,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:22,737 INFO:     Epoch: 0
2023-01-04 01:52:24,344 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6081665416558584, 'Total loss': 0.6081665416558584} | train loss {'Reaction outcome loss': 0.8452789325566188, 'Total loss': 0.8452789325566188}
2023-01-04 01:52:24,344 INFO:     Found new best model at epoch 0
2023-01-04 01:52:24,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:24,345 INFO:     Epoch: 1
2023-01-04 01:52:25,939 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5058642745018005, 'Total loss': 0.5058642745018005} | train loss {'Reaction outcome loss': 0.5992665669343767, 'Total loss': 0.5992665669343767}
2023-01-04 01:52:25,939 INFO:     Found new best model at epoch 1
2023-01-04 01:52:25,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:25,940 INFO:     Epoch: 2
2023-01-04 01:52:27,508 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46709177096684773, 'Total loss': 0.46709177096684773} | train loss {'Reaction outcome loss': 0.5217753142988595, 'Total loss': 0.5217753142988595}
2023-01-04 01:52:27,508 INFO:     Found new best model at epoch 2
2023-01-04 01:52:27,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:27,509 INFO:     Epoch: 3
2023-01-04 01:52:29,114 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45213407079378765, 'Total loss': 0.45213407079378765} | train loss {'Reaction outcome loss': 0.4798504059223363, 'Total loss': 0.4798504059223363}
2023-01-04 01:52:29,115 INFO:     Found new best model at epoch 3
2023-01-04 01:52:29,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:29,115 INFO:     Epoch: 4
2023-01-04 01:52:30,725 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4215637425581614, 'Total loss': 0.4215637425581614} | train loss {'Reaction outcome loss': 0.4519103771469889, 'Total loss': 0.4519103771469889}
2023-01-04 01:52:30,725 INFO:     Found new best model at epoch 4
2023-01-04 01:52:30,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:30,726 INFO:     Epoch: 5
2023-01-04 01:52:32,328 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4266504983107249, 'Total loss': 0.4266504983107249} | train loss {'Reaction outcome loss': 0.43017283016747804, 'Total loss': 0.43017283016747804}
2023-01-04 01:52:32,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:32,328 INFO:     Epoch: 6
2023-01-04 01:52:33,947 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4235145092010498, 'Total loss': 0.4235145092010498} | train loss {'Reaction outcome loss': 0.41391071791413925, 'Total loss': 0.41391071791413925}
2023-01-04 01:52:33,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:33,948 INFO:     Epoch: 7
2023-01-04 01:52:35,518 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4052803635597229, 'Total loss': 0.4052803635597229} | train loss {'Reaction outcome loss': 0.3975488587017477, 'Total loss': 0.3975488587017477}
2023-01-04 01:52:35,519 INFO:     Found new best model at epoch 7
2023-01-04 01:52:35,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:35,519 INFO:     Epoch: 8
2023-01-04 01:52:37,117 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4113377213478088, 'Total loss': 0.4113377213478088} | train loss {'Reaction outcome loss': 0.38757864597940095, 'Total loss': 0.38757864597940095}
2023-01-04 01:52:37,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:37,118 INFO:     Epoch: 9
2023-01-04 01:52:38,729 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38803406357765197, 'Total loss': 0.38803406357765197} | train loss {'Reaction outcome loss': 0.37716197192560147, 'Total loss': 0.37716197192560147}
2023-01-04 01:52:38,729 INFO:     Found new best model at epoch 9
2023-01-04 01:52:38,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:38,730 INFO:     Epoch: 10
2023-01-04 01:52:40,328 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37805572152137756, 'Total loss': 0.37805572152137756} | train loss {'Reaction outcome loss': 0.3691307114314859, 'Total loss': 0.3691307114314859}
2023-01-04 01:52:40,329 INFO:     Found new best model at epoch 10
2023-01-04 01:52:40,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:40,330 INFO:     Epoch: 11
2023-01-04 01:52:41,935 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3850190748771032, 'Total loss': 0.3850190748771032} | train loss {'Reaction outcome loss': 0.3592042815565628, 'Total loss': 0.3592042815565628}
2023-01-04 01:52:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:41,935 INFO:     Epoch: 12
2023-01-04 01:52:43,519 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37592617770036063, 'Total loss': 0.37592617770036063} | train loss {'Reaction outcome loss': 0.35280970913650345, 'Total loss': 0.35280970913650345}
2023-01-04 01:52:43,519 INFO:     Found new best model at epoch 12
2023-01-04 01:52:43,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:43,520 INFO:     Epoch: 13
2023-01-04 01:52:45,081 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36587245265642804, 'Total loss': 0.36587245265642804} | train loss {'Reaction outcome loss': 0.3440065537273449, 'Total loss': 0.3440065537273449}
2023-01-04 01:52:45,081 INFO:     Found new best model at epoch 13
2023-01-04 01:52:45,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:45,082 INFO:     Epoch: 14
2023-01-04 01:52:46,692 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3639307826757431, 'Total loss': 0.3639307826757431} | train loss {'Reaction outcome loss': 0.3375796894576863, 'Total loss': 0.3375796894576863}
2023-01-04 01:52:46,693 INFO:     Found new best model at epoch 14
2023-01-04 01:52:46,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:46,694 INFO:     Epoch: 15
2023-01-04 01:52:48,291 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3717790424823761, 'Total loss': 0.3717790424823761} | train loss {'Reaction outcome loss': 0.3277171014053543, 'Total loss': 0.3277171014053543}
2023-01-04 01:52:48,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:48,292 INFO:     Epoch: 16
2023-01-04 01:52:49,892 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3714895278215408, 'Total loss': 0.3714895278215408} | train loss {'Reaction outcome loss': 0.3254963062214155, 'Total loss': 0.3254963062214155}
2023-01-04 01:52:49,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:49,892 INFO:     Epoch: 17
2023-01-04 01:52:51,476 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3699912200371424, 'Total loss': 0.3699912200371424} | train loss {'Reaction outcome loss': 0.3172772604237943, 'Total loss': 0.3172772604237943}
2023-01-04 01:52:51,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:51,477 INFO:     Epoch: 18
2023-01-04 01:52:53,038 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35826168656349183, 'Total loss': 0.35826168656349183} | train loss {'Reaction outcome loss': 0.31130747385594965, 'Total loss': 0.31130747385594965}
2023-01-04 01:52:53,039 INFO:     Found new best model at epoch 18
2023-01-04 01:52:53,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:53,039 INFO:     Epoch: 19
2023-01-04 01:52:54,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35355828478932383, 'Total loss': 0.35355828478932383} | train loss {'Reaction outcome loss': 0.30856443563625763, 'Total loss': 0.30856443563625763}
2023-01-04 01:52:54,618 INFO:     Found new best model at epoch 19
2023-01-04 01:52:54,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:54,619 INFO:     Epoch: 20
2023-01-04 01:52:56,215 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.336911412080129, 'Total loss': 0.336911412080129} | train loss {'Reaction outcome loss': 0.30341457173119496, 'Total loss': 0.30341457173119496}
2023-01-04 01:52:56,215 INFO:     Found new best model at epoch 20
2023-01-04 01:52:56,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:56,216 INFO:     Epoch: 21
2023-01-04 01:52:57,790 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36849750876426696, 'Total loss': 0.36849750876426696} | train loss {'Reaction outcome loss': 0.2969217798570647, 'Total loss': 0.2969217798570647}
2023-01-04 01:52:57,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:57,790 INFO:     Epoch: 22
2023-01-04 01:52:59,399 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3748370160659154, 'Total loss': 0.3748370160659154} | train loss {'Reaction outcome loss': 0.29125017955572935, 'Total loss': 0.29125017955572935}
2023-01-04 01:52:59,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:52:59,400 INFO:     Epoch: 23
2023-01-04 01:53:01,052 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.35585290789604185, 'Total loss': 0.35585290789604185} | train loss {'Reaction outcome loss': 0.2884939534276941, 'Total loss': 0.2884939534276941}
2023-01-04 01:53:01,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:01,052 INFO:     Epoch: 24
2023-01-04 01:53:02,631 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3579653506477674, 'Total loss': 0.3579653506477674} | train loss {'Reaction outcome loss': 0.2867870641613964, 'Total loss': 0.2867870641613964}
2023-01-04 01:53:02,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:02,631 INFO:     Epoch: 25
2023-01-04 01:53:04,207 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36714332600434624, 'Total loss': 0.36714332600434624} | train loss {'Reaction outcome loss': 0.28169462922280725, 'Total loss': 0.28169462922280725}
2023-01-04 01:53:04,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:04,207 INFO:     Epoch: 26
2023-01-04 01:53:05,787 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3733943670988083, 'Total loss': 0.3733943670988083} | train loss {'Reaction outcome loss': 0.27698872096999716, 'Total loss': 0.27698872096999716}
2023-01-04 01:53:05,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:05,787 INFO:     Epoch: 27
2023-01-04 01:53:07,362 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.35115207781394325, 'Total loss': 0.35115207781394325} | train loss {'Reaction outcome loss': 0.2722007138722569, 'Total loss': 0.2722007138722569}
2023-01-04 01:53:07,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:07,362 INFO:     Epoch: 28
2023-01-04 01:53:08,967 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.33680141617854437, 'Total loss': 0.33680141617854437} | train loss {'Reaction outcome loss': 0.26984608951058703, 'Total loss': 0.26984608951058703}
2023-01-04 01:53:08,967 INFO:     Found new best model at epoch 28
2023-01-04 01:53:08,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:08,968 INFO:     Epoch: 29
2023-01-04 01:53:10,564 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3326237591604392, 'Total loss': 0.3326237591604392} | train loss {'Reaction outcome loss': 0.2669403151656589, 'Total loss': 0.2669403151656589}
2023-01-04 01:53:10,564 INFO:     Found new best model at epoch 29
2023-01-04 01:53:10,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:10,565 INFO:     Epoch: 30
2023-01-04 01:53:12,134 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3537133067846298, 'Total loss': 0.3537133067846298} | train loss {'Reaction outcome loss': 0.2626306708004788, 'Total loss': 0.2626306708004788}
2023-01-04 01:53:12,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:12,135 INFO:     Epoch: 31
2023-01-04 01:53:13,720 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3399341235558192, 'Total loss': 0.3399341235558192} | train loss {'Reaction outcome loss': 0.2592948967060686, 'Total loss': 0.2592948967060686}
2023-01-04 01:53:13,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:13,720 INFO:     Epoch: 32
2023-01-04 01:53:15,327 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.329738133152326, 'Total loss': 0.329738133152326} | train loss {'Reaction outcome loss': 0.257134787248869, 'Total loss': 0.257134787248869}
2023-01-04 01:53:15,329 INFO:     Found new best model at epoch 32
2023-01-04 01:53:15,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:15,330 INFO:     Epoch: 33
2023-01-04 01:53:16,927 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.352883646885554, 'Total loss': 0.352883646885554} | train loss {'Reaction outcome loss': 0.2563595690757689, 'Total loss': 0.2563595690757689}
2023-01-04 01:53:16,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:16,928 INFO:     Epoch: 34
2023-01-04 01:53:18,535 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3354902118444443, 'Total loss': 0.3354902118444443} | train loss {'Reaction outcome loss': 0.25030947611225346, 'Total loss': 0.25030947611225346}
2023-01-04 01:53:18,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:18,535 INFO:     Epoch: 35
2023-01-04 01:53:20,120 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35113674104213716, 'Total loss': 0.35113674104213716} | train loss {'Reaction outcome loss': 0.24715639816692275, 'Total loss': 0.24715639816692275}
2023-01-04 01:53:20,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:20,120 INFO:     Epoch: 36
2023-01-04 01:53:21,692 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33438699642817177, 'Total loss': 0.33438699642817177} | train loss {'Reaction outcome loss': 0.24755167585872387, 'Total loss': 0.24755167585872387}
2023-01-04 01:53:21,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:21,693 INFO:     Epoch: 37
2023-01-04 01:53:23,277 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.33509971499443053, 'Total loss': 0.33509971499443053} | train loss {'Reaction outcome loss': 0.2433275257910255, 'Total loss': 0.2433275257910255}
2023-01-04 01:53:23,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:23,277 INFO:     Epoch: 38
2023-01-04 01:53:24,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.33696096142133075, 'Total loss': 0.33696096142133075} | train loss {'Reaction outcome loss': 0.24113033204781312, 'Total loss': 0.24113033204781312}
2023-01-04 01:53:24,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:24,884 INFO:     Epoch: 39
2023-01-04 01:53:26,492 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.32865269780158995, 'Total loss': 0.32865269780158995} | train loss {'Reaction outcome loss': 0.23942224296612025, 'Total loss': 0.23942224296612025}
2023-01-04 01:53:26,492 INFO:     Found new best model at epoch 39
2023-01-04 01:53:26,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:26,493 INFO:     Epoch: 40
2023-01-04 01:53:28,069 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3418857981761297, 'Total loss': 0.3418857981761297} | train loss {'Reaction outcome loss': 0.23645015142137443, 'Total loss': 0.23645015142137443}
2023-01-04 01:53:28,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:28,069 INFO:     Epoch: 41
2023-01-04 01:53:29,631 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3480918417374293, 'Total loss': 0.3480918417374293} | train loss {'Reaction outcome loss': 0.23460067392592013, 'Total loss': 0.23460067392592013}
2023-01-04 01:53:29,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:29,631 INFO:     Epoch: 42
2023-01-04 01:53:31,238 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33641415486733117, 'Total loss': 0.33641415486733117} | train loss {'Reaction outcome loss': 0.23090865573145614, 'Total loss': 0.23090865573145614}
2023-01-04 01:53:31,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:31,238 INFO:     Epoch: 43
2023-01-04 01:53:32,808 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3581882337729136, 'Total loss': 0.3581882337729136} | train loss {'Reaction outcome loss': 0.22840621783296122, 'Total loss': 0.22840621783296122}
2023-01-04 01:53:32,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:32,809 INFO:     Epoch: 44
2023-01-04 01:53:34,412 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35187937219937643, 'Total loss': 0.35187937219937643} | train loss {'Reaction outcome loss': 0.228625460330696, 'Total loss': 0.228625460330696}
2023-01-04 01:53:34,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:34,413 INFO:     Epoch: 45
2023-01-04 01:53:36,010 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3459281255801519, 'Total loss': 0.3459281255801519} | train loss {'Reaction outcome loss': 0.2261414162297971, 'Total loss': 0.2261414162297971}
2023-01-04 01:53:36,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:36,010 INFO:     Epoch: 46
2023-01-04 01:53:37,609 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34202287048101426, 'Total loss': 0.34202287048101426} | train loss {'Reaction outcome loss': 0.22443262677993217, 'Total loss': 0.22443262677993217}
2023-01-04 01:53:37,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:37,609 INFO:     Epoch: 47
2023-01-04 01:53:39,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35083706577618917, 'Total loss': 0.35083706577618917} | train loss {'Reaction outcome loss': 0.2208531159961963, 'Total loss': 0.2208531159961963}
2023-01-04 01:53:39,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:39,148 INFO:     Epoch: 48
2023-01-04 01:53:40,730 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.361954935391744, 'Total loss': 0.361954935391744} | train loss {'Reaction outcome loss': 0.22061096217456092, 'Total loss': 0.22061096217456092}
2023-01-04 01:53:40,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:40,731 INFO:     Epoch: 49
2023-01-04 01:53:42,313 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35670287037889165, 'Total loss': 0.35670287037889165} | train loss {'Reaction outcome loss': 0.22085585797300739, 'Total loss': 0.22085585797300739}
2023-01-04 01:53:42,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:42,314 INFO:     Epoch: 50
2023-01-04 01:53:43,895 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37410220007101697, 'Total loss': 0.37410220007101697} | train loss {'Reaction outcome loss': 0.21800766291137594, 'Total loss': 0.21800766291137594}
2023-01-04 01:53:43,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:43,895 INFO:     Epoch: 51
2023-01-04 01:53:45,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36825004816055296, 'Total loss': 0.36825004816055296} | train loss {'Reaction outcome loss': 0.2148357580558662, 'Total loss': 0.2148357580558662}
2023-01-04 01:53:45,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:45,478 INFO:     Epoch: 52
2023-01-04 01:53:47,043 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3510799070199331, 'Total loss': 0.3510799070199331} | train loss {'Reaction outcome loss': 0.21251383673970717, 'Total loss': 0.21251383673970717}
2023-01-04 01:53:47,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:47,043 INFO:     Epoch: 53
2023-01-04 01:53:48,641 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36248070846001307, 'Total loss': 0.36248070846001307} | train loss {'Reaction outcome loss': 0.21234308740627156, 'Total loss': 0.21234308740627156}
2023-01-04 01:53:48,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:48,641 INFO:     Epoch: 54
2023-01-04 01:53:50,238 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37055612206459043, 'Total loss': 0.37055612206459043} | train loss {'Reaction outcome loss': 0.20970438951014603, 'Total loss': 0.20970438951014603}
2023-01-04 01:53:50,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:50,238 INFO:     Epoch: 55
2023-01-04 01:53:51,836 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34038954973220825, 'Total loss': 0.34038954973220825} | train loss {'Reaction outcome loss': 0.20936442513263573, 'Total loss': 0.20936442513263573}
2023-01-04 01:53:51,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:51,837 INFO:     Epoch: 56
2023-01-04 01:53:53,435 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3463111934872965, 'Total loss': 0.3463111934872965} | train loss {'Reaction outcome loss': 0.20959489464922978, 'Total loss': 0.20959489464922978}
2023-01-04 01:53:53,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:53,435 INFO:     Epoch: 57
2023-01-04 01:53:55,032 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.375149534145991, 'Total loss': 0.375149534145991} | train loss {'Reaction outcome loss': 0.20590699240429342, 'Total loss': 0.20590699240429342}
2023-01-04 01:53:55,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:55,032 INFO:     Epoch: 58
2023-01-04 01:53:56,590 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38661454419294994, 'Total loss': 0.38661454419294994} | train loss {'Reaction outcome loss': 0.203767359365512, 'Total loss': 0.203767359365512}
2023-01-04 01:53:56,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:56,590 INFO:     Epoch: 59
2023-01-04 01:53:58,196 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3586025396982829, 'Total loss': 0.3586025396982829} | train loss {'Reaction outcome loss': 0.20275540972114914, 'Total loss': 0.20275540972114914}
2023-01-04 01:53:58,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:58,196 INFO:     Epoch: 60
2023-01-04 01:53:59,800 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.355970295270284, 'Total loss': 0.355970295270284} | train loss {'Reaction outcome loss': 0.2022685153532202, 'Total loss': 0.2022685153532202}
2023-01-04 01:53:59,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:53:59,800 INFO:     Epoch: 61
2023-01-04 01:54:01,424 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36004941364129384, 'Total loss': 0.36004941364129384} | train loss {'Reaction outcome loss': 0.19810165808855618, 'Total loss': 0.19810165808855618}
2023-01-04 01:54:01,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:01,424 INFO:     Epoch: 62
2023-01-04 01:54:03,045 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36786463459332785, 'Total loss': 0.36786463459332785} | train loss {'Reaction outcome loss': 0.2000001440993952, 'Total loss': 0.2000001440993952}
2023-01-04 01:54:03,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:03,045 INFO:     Epoch: 63
2023-01-04 01:54:04,667 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36225931346416473, 'Total loss': 0.36225931346416473} | train loss {'Reaction outcome loss': 0.1972754152668436, 'Total loss': 0.1972754152668436}
2023-01-04 01:54:04,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:04,668 INFO:     Epoch: 64
2023-01-04 01:54:06,225 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35031179133802653, 'Total loss': 0.35031179133802653} | train loss {'Reaction outcome loss': 0.19844864433916815, 'Total loss': 0.19844864433916815}
2023-01-04 01:54:06,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:06,225 INFO:     Epoch: 65
2023-01-04 01:54:07,820 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33032663526634376, 'Total loss': 0.33032663526634376} | train loss {'Reaction outcome loss': 0.1962184832723689, 'Total loss': 0.1962184832723689}
2023-01-04 01:54:07,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:07,820 INFO:     Epoch: 66
2023-01-04 01:54:09,423 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35608100295066836, 'Total loss': 0.35608100295066836} | train loss {'Reaction outcome loss': 0.19546155386135308, 'Total loss': 0.19546155386135308}
2023-01-04 01:54:09,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:09,423 INFO:     Epoch: 67
2023-01-04 01:54:11,028 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35080861697594323, 'Total loss': 0.35080861697594323} | train loss {'Reaction outcome loss': 0.1946272306062662, 'Total loss': 0.1946272306062662}
2023-01-04 01:54:11,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:11,029 INFO:     Epoch: 68
2023-01-04 01:54:12,632 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3417874445517858, 'Total loss': 0.3417874445517858} | train loss {'Reaction outcome loss': 0.19693144002970117, 'Total loss': 0.19693144002970117}
2023-01-04 01:54:12,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:12,632 INFO:     Epoch: 69
2023-01-04 01:54:14,218 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36537120342254636, 'Total loss': 0.36537120342254636} | train loss {'Reaction outcome loss': 0.19371712285970902, 'Total loss': 0.19371712285970902}
2023-01-04 01:54:14,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:14,218 INFO:     Epoch: 70
2023-01-04 01:54:15,787 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34615806192159654, 'Total loss': 0.34615806192159654} | train loss {'Reaction outcome loss': 0.1924450856150828, 'Total loss': 0.1924450856150828}
2023-01-04 01:54:15,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:15,787 INFO:     Epoch: 71
2023-01-04 01:54:17,375 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37641172607739765, 'Total loss': 0.37641172607739765} | train loss {'Reaction outcome loss': 0.19024602195968593, 'Total loss': 0.19024602195968593}
2023-01-04 01:54:17,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:17,376 INFO:     Epoch: 72
2023-01-04 01:54:18,964 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.390562454238534, 'Total loss': 0.390562454238534} | train loss {'Reaction outcome loss': 0.18986092189693973, 'Total loss': 0.18986092189693973}
2023-01-04 01:54:18,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:18,965 INFO:     Epoch: 73
2023-01-04 01:54:20,575 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36787010033925377, 'Total loss': 0.36787010033925377} | train loss {'Reaction outcome loss': 0.18896079123237708, 'Total loss': 0.18896079123237708}
2023-01-04 01:54:20,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:20,575 INFO:     Epoch: 74
2023-01-04 01:54:22,183 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3788070986668269, 'Total loss': 0.3788070986668269} | train loss {'Reaction outcome loss': 0.18877913892595438, 'Total loss': 0.18877913892595438}
2023-01-04 01:54:22,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:22,185 INFO:     Epoch: 75
2023-01-04 01:54:23,749 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35184904498358566, 'Total loss': 0.35184904498358566} | train loss {'Reaction outcome loss': 0.18606902083150878, 'Total loss': 0.18606902083150878}
2023-01-04 01:54:23,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:23,749 INFO:     Epoch: 76
2023-01-04 01:54:25,357 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37268964101870855, 'Total loss': 0.37268964101870855} | train loss {'Reaction outcome loss': 0.18657996415765615, 'Total loss': 0.18657996415765615}
2023-01-04 01:54:25,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:25,357 INFO:     Epoch: 77
2023-01-04 01:54:26,962 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3694774051507314, 'Total loss': 0.3694774051507314} | train loss {'Reaction outcome loss': 0.1846306100759628, 'Total loss': 0.1846306100759628}
2023-01-04 01:54:26,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:26,963 INFO:     Epoch: 78
2023-01-04 01:54:28,531 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38764941195646924, 'Total loss': 0.38764941195646924} | train loss {'Reaction outcome loss': 0.18350879501306663, 'Total loss': 0.18350879501306663}
2023-01-04 01:54:28,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:28,532 INFO:     Epoch: 79
2023-01-04 01:54:30,099 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3846758306026459, 'Total loss': 0.3846758306026459} | train loss {'Reaction outcome loss': 0.18336747998684427, 'Total loss': 0.18336747998684427}
2023-01-04 01:54:30,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:30,099 INFO:     Epoch: 80
2023-01-04 01:54:31,670 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3610304296016693, 'Total loss': 0.3610304296016693} | train loss {'Reaction outcome loss': 0.18191377609206813, 'Total loss': 0.18191377609206813}
2023-01-04 01:54:31,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:31,670 INFO:     Epoch: 81
2023-01-04 01:54:33,223 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38880321284135183, 'Total loss': 0.38880321284135183} | train loss {'Reaction outcome loss': 0.17923976003743, 'Total loss': 0.17923976003743}
2023-01-04 01:54:33,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:33,224 INFO:     Epoch: 82
2023-01-04 01:54:34,804 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3613281801342964, 'Total loss': 0.3613281801342964} | train loss {'Reaction outcome loss': 0.18025518921169922, 'Total loss': 0.18025518921169922}
2023-01-04 01:54:34,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:34,805 INFO:     Epoch: 83
2023-01-04 01:54:36,385 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3668528477350871, 'Total loss': 0.3668528477350871} | train loss {'Reaction outcome loss': 0.1803336568571029, 'Total loss': 0.1803336568571029}
2023-01-04 01:54:36,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:36,385 INFO:     Epoch: 84
2023-01-04 01:54:37,963 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3948012868563334, 'Total loss': 0.3948012868563334} | train loss {'Reaction outcome loss': 0.17950605233301864, 'Total loss': 0.17950605233301864}
2023-01-04 01:54:37,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:37,964 INFO:     Epoch: 85
2023-01-04 01:54:39,544 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40222375293572743, 'Total loss': 0.40222375293572743} | train loss {'Reaction outcome loss': 0.17756768140642748, 'Total loss': 0.17756768140642748}
2023-01-04 01:54:39,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:39,545 INFO:     Epoch: 86
2023-01-04 01:54:41,118 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3688697208960851, 'Total loss': 0.3688697208960851} | train loss {'Reaction outcome loss': 0.17763027121877148, 'Total loss': 0.17763027121877148}
2023-01-04 01:54:41,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:41,119 INFO:     Epoch: 87
2023-01-04 01:54:42,697 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36951474646727245, 'Total loss': 0.36951474646727245} | train loss {'Reaction outcome loss': 0.17840451282197542, 'Total loss': 0.17840451282197542}
2023-01-04 01:54:42,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:42,697 INFO:     Epoch: 88
2023-01-04 01:54:44,301 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4007796128590902, 'Total loss': 0.4007796128590902} | train loss {'Reaction outcome loss': 0.17648425730910614, 'Total loss': 0.17648425730910614}
2023-01-04 01:54:44,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:44,301 INFO:     Epoch: 89
2023-01-04 01:54:45,907 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38422973453998566, 'Total loss': 0.38422973453998566} | train loss {'Reaction outcome loss': 0.17397611335355, 'Total loss': 0.17397611335355}
2023-01-04 01:54:45,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:45,907 INFO:     Epoch: 90
2023-01-04 01:54:47,508 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38545481065909065, 'Total loss': 0.38545481065909065} | train loss {'Reaction outcome loss': 0.1736607703849347, 'Total loss': 0.1736607703849347}
2023-01-04 01:54:47,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:47,508 INFO:     Epoch: 91
2023-01-04 01:54:49,103 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37776601513226826, 'Total loss': 0.37776601513226826} | train loss {'Reaction outcome loss': 0.17184934325951295, 'Total loss': 0.17184934325951295}
2023-01-04 01:54:49,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:49,103 INFO:     Epoch: 92
2023-01-04 01:54:50,657 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36269066433111824, 'Total loss': 0.36269066433111824} | train loss {'Reaction outcome loss': 0.17272498814837775, 'Total loss': 0.17272498814837775}
2023-01-04 01:54:50,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:50,658 INFO:     Epoch: 93
2023-01-04 01:54:52,273 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39434932271639506, 'Total loss': 0.39434932271639506} | train loss {'Reaction outcome loss': 0.1725757040736014, 'Total loss': 0.1725757040736014}
2023-01-04 01:54:52,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:52,273 INFO:     Epoch: 94
2023-01-04 01:54:53,878 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39284199674924214, 'Total loss': 0.39284199674924214} | train loss {'Reaction outcome loss': 0.1723933654096331, 'Total loss': 0.1723933654096331}
2023-01-04 01:54:53,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:53,880 INFO:     Epoch: 95
2023-01-04 01:54:55,453 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3665113985538483, 'Total loss': 0.3665113985538483} | train loss {'Reaction outcome loss': 0.17028971086426156, 'Total loss': 0.17028971086426156}
2023-01-04 01:54:55,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:55,453 INFO:     Epoch: 96
2023-01-04 01:54:57,059 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3953541080156962, 'Total loss': 0.3953541080156962} | train loss {'Reaction outcome loss': 0.17047254376820403, 'Total loss': 0.17047254376820403}
2023-01-04 01:54:57,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:57,059 INFO:     Epoch: 97
2023-01-04 01:54:58,629 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38414650907119113, 'Total loss': 0.38414650907119113} | train loss {'Reaction outcome loss': 0.17104847094275222, 'Total loss': 0.17104847094275222}
2023-01-04 01:54:58,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:54:58,629 INFO:     Epoch: 98
2023-01-04 01:55:00,184 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37665563623110454, 'Total loss': 0.37665563623110454} | train loss {'Reaction outcome loss': 0.17061032216832803, 'Total loss': 0.17061032216832803}
2023-01-04 01:55:00,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:00,185 INFO:     Epoch: 99
2023-01-04 01:55:01,767 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36801114430030185, 'Total loss': 0.36801114430030185} | train loss {'Reaction outcome loss': 0.1707433520197651, 'Total loss': 0.1707433520197651}
2023-01-04 01:55:01,768 INFO:     Best model found after epoch 40 of 100.
2023-01-04 01:55:01,768 INFO:   Done with stage: TRAINING
2023-01-04 01:55:01,768 INFO:   Starting stage: EVALUATION
2023-01-04 01:55:01,902 INFO:   Done with stage: EVALUATION
2023-01-04 01:55:01,902 INFO:   Leaving out SEQ value Fold_7
2023-01-04 01:55:01,914 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 01:55:01,914 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:55:02,558 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:55:02,558 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:55:02,627 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:55:02,627 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:55:02,627 INFO:     No hyperparam tuning for this model
2023-01-04 01:55:02,627 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:55:02,627 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:55:02,628 INFO:     None feature selector for col prot
2023-01-04 01:55:02,628 INFO:     None feature selector for col prot
2023-01-04 01:55:02,628 INFO:     None feature selector for col prot
2023-01-04 01:55:02,629 INFO:     None feature selector for col chem
2023-01-04 01:55:02,629 INFO:     None feature selector for col chem
2023-01-04 01:55:02,629 INFO:     None feature selector for col chem
2023-01-04 01:55:02,629 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:55:02,629 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:55:02,630 INFO:     Number of params in model 70141
2023-01-04 01:55:02,633 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:55:02,634 INFO:   Starting stage: TRAINING
2023-01-04 01:55:02,677 INFO:     Val loss before train {'Reaction outcome loss': 1.0619962056477865, 'Total loss': 1.0619962056477865}
2023-01-04 01:55:02,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:02,678 INFO:     Epoch: 0
2023-01-04 01:55:04,257 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6823759575684866, 'Total loss': 0.6823759575684866} | train loss {'Reaction outcome loss': 0.846778168512957, 'Total loss': 0.846778168512957}
2023-01-04 01:55:04,257 INFO:     Found new best model at epoch 0
2023-01-04 01:55:04,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:04,258 INFO:     Epoch: 1
2023-01-04 01:55:05,866 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5525510688622792, 'Total loss': 0.5525510688622792} | train loss {'Reaction outcome loss': 0.5971839542153978, 'Total loss': 0.5971839542153978}
2023-01-04 01:55:05,867 INFO:     Found new best model at epoch 1
2023-01-04 01:55:05,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:05,868 INFO:     Epoch: 2
2023-01-04 01:55:07,471 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5525085926055908, 'Total loss': 0.5525085926055908} | train loss {'Reaction outcome loss': 0.5269009134847752, 'Total loss': 0.5269009134847752}
2023-01-04 01:55:07,471 INFO:     Found new best model at epoch 2
2023-01-04 01:55:07,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:07,472 INFO:     Epoch: 3
2023-01-04 01:55:08,753 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5065684179464977, 'Total loss': 0.5065684179464977} | train loss {'Reaction outcome loss': 0.49019107179050025, 'Total loss': 0.49019107179050025}
2023-01-04 01:55:08,753 INFO:     Found new best model at epoch 3
2023-01-04 01:55:08,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:08,754 INFO:     Epoch: 4
2023-01-04 01:55:09,808 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48117679556210835, 'Total loss': 0.48117679556210835} | train loss {'Reaction outcome loss': 0.4631025357729327, 'Total loss': 0.4631025357729327}
2023-01-04 01:55:09,808 INFO:     Found new best model at epoch 4
2023-01-04 01:55:09,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:09,809 INFO:     Epoch: 5
2023-01-04 01:55:10,857 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.481462432940801, 'Total loss': 0.481462432940801} | train loss {'Reaction outcome loss': 0.44508838941798595, 'Total loss': 0.44508838941798595}
2023-01-04 01:55:10,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:10,857 INFO:     Epoch: 6
2023-01-04 01:55:11,909 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47411860823631286, 'Total loss': 0.47411860823631286} | train loss {'Reaction outcome loss': 0.4295817239441141, 'Total loss': 0.4295817239441141}
2023-01-04 01:55:11,909 INFO:     Found new best model at epoch 6
2023-01-04 01:55:11,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:11,910 INFO:     Epoch: 7
2023-01-04 01:55:13,290 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4502598981062571, 'Total loss': 0.4502598981062571} | train loss {'Reaction outcome loss': 0.41614317760741626, 'Total loss': 0.41614317760741626}
2023-01-04 01:55:13,290 INFO:     Found new best model at epoch 7
2023-01-04 01:55:13,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:13,291 INFO:     Epoch: 8
2023-01-04 01:55:14,853 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45131335655848187, 'Total loss': 0.45131335655848187} | train loss {'Reaction outcome loss': 0.40374020682851763, 'Total loss': 0.40374020682851763}
2023-01-04 01:55:14,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:14,854 INFO:     Epoch: 9
2023-01-04 01:55:16,459 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43693369527657827, 'Total loss': 0.43693369527657827} | train loss {'Reaction outcome loss': 0.39383497793417777, 'Total loss': 0.39383497793417777}
2023-01-04 01:55:16,459 INFO:     Found new best model at epoch 9
2023-01-04 01:55:16,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:16,460 INFO:     Epoch: 10
2023-01-04 01:55:18,042 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43427525758743285, 'Total loss': 0.43427525758743285} | train loss {'Reaction outcome loss': 0.38532338481749934, 'Total loss': 0.38532338481749934}
2023-01-04 01:55:18,043 INFO:     Found new best model at epoch 10
2023-01-04 01:55:18,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:18,043 INFO:     Epoch: 11
2023-01-04 01:55:19,650 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4286669373512268, 'Total loss': 0.4286669373512268} | train loss {'Reaction outcome loss': 0.3753284360044194, 'Total loss': 0.3753284360044194}
2023-01-04 01:55:19,650 INFO:     Found new best model at epoch 11
2023-01-04 01:55:19,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:19,651 INFO:     Epoch: 12
2023-01-04 01:55:21,260 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4420771420001984, 'Total loss': 0.4420771420001984} | train loss {'Reaction outcome loss': 0.36922123375600274, 'Total loss': 0.36922123375600274}
2023-01-04 01:55:21,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:21,260 INFO:     Epoch: 13
2023-01-04 01:55:22,851 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4207482029994329, 'Total loss': 0.4207482029994329} | train loss {'Reaction outcome loss': 0.3617037010725832, 'Total loss': 0.3617037010725832}
2023-01-04 01:55:22,851 INFO:     Found new best model at epoch 13
2023-01-04 01:55:22,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:22,852 INFO:     Epoch: 14
2023-01-04 01:55:24,447 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44168640971183776, 'Total loss': 0.44168640971183776} | train loss {'Reaction outcome loss': 0.3548336546242672, 'Total loss': 0.3548336546242672}
2023-01-04 01:55:24,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:24,448 INFO:     Epoch: 15
2023-01-04 01:55:26,058 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4265908042589823, 'Total loss': 0.4265908042589823} | train loss {'Reaction outcome loss': 0.3476434462044361, 'Total loss': 0.3476434462044361}
2023-01-04 01:55:26,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:26,058 INFO:     Epoch: 16
2023-01-04 01:55:27,670 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43217838207880654, 'Total loss': 0.43217838207880654} | train loss {'Reaction outcome loss': 0.34064480542701525, 'Total loss': 0.34064480542701525}
2023-01-04 01:55:27,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:27,670 INFO:     Epoch: 17
2023-01-04 01:55:29,288 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4229654947916667, 'Total loss': 0.4229654947916667} | train loss {'Reaction outcome loss': 0.33527058599530346, 'Total loss': 0.33527058599530346}
2023-01-04 01:55:29,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:29,289 INFO:     Epoch: 18
2023-01-04 01:55:30,885 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4167601784070333, 'Total loss': 0.4167601784070333} | train loss {'Reaction outcome loss': 0.3310784345669468, 'Total loss': 0.3310784345669468}
2023-01-04 01:55:30,885 INFO:     Found new best model at epoch 18
2023-01-04 01:55:30,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:30,886 INFO:     Epoch: 19
2023-01-04 01:55:32,482 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42828243374824526, 'Total loss': 0.42828243374824526} | train loss {'Reaction outcome loss': 0.32587626220209753, 'Total loss': 0.32587626220209753}
2023-01-04 01:55:32,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:32,482 INFO:     Epoch: 20
2023-01-04 01:55:34,066 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4262743721405665, 'Total loss': 0.4262743721405665} | train loss {'Reaction outcome loss': 0.31988316959273205, 'Total loss': 0.31988316959273205}
2023-01-04 01:55:34,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:34,067 INFO:     Epoch: 21
2023-01-04 01:55:35,680 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4162175804376602, 'Total loss': 0.4162175804376602} | train loss {'Reaction outcome loss': 0.3147624409383666, 'Total loss': 0.3147624409383666}
2023-01-04 01:55:35,681 INFO:     Found new best model at epoch 21
2023-01-04 01:55:35,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:35,682 INFO:     Epoch: 22
2023-01-04 01:55:37,272 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.426726637283961, 'Total loss': 0.426726637283961} | train loss {'Reaction outcome loss': 0.3104270056814608, 'Total loss': 0.3104270056814608}
2023-01-04 01:55:37,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:37,272 INFO:     Epoch: 23
2023-01-04 01:55:38,857 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40039119124412537, 'Total loss': 0.40039119124412537} | train loss {'Reaction outcome loss': 0.3053885833190305, 'Total loss': 0.3053885833190305}
2023-01-04 01:55:38,857 INFO:     Found new best model at epoch 23
2023-01-04 01:55:38,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:38,858 INFO:     Epoch: 24
2023-01-04 01:55:40,431 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41754883726437886, 'Total loss': 0.41754883726437886} | train loss {'Reaction outcome loss': 0.30102480126775966, 'Total loss': 0.30102480126775966}
2023-01-04 01:55:40,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:40,432 INFO:     Epoch: 25
2023-01-04 01:55:42,023 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4278846343358358, 'Total loss': 0.4278846343358358} | train loss {'Reaction outcome loss': 0.29695889726281166, 'Total loss': 0.29695889726281166}
2023-01-04 01:55:42,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:42,023 INFO:     Epoch: 26
2023-01-04 01:55:43,603 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43118908007939655, 'Total loss': 0.43118908007939655} | train loss {'Reaction outcome loss': 0.2926881640034653, 'Total loss': 0.2926881640034653}
2023-01-04 01:55:43,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:43,603 INFO:     Epoch: 27
2023-01-04 01:55:45,184 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4181285490592321, 'Total loss': 0.4181285490592321} | train loss {'Reaction outcome loss': 0.287280921137681, 'Total loss': 0.287280921137681}
2023-01-04 01:55:45,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:45,184 INFO:     Epoch: 28
2023-01-04 01:55:46,765 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4296462953090668, 'Total loss': 0.4296462953090668} | train loss {'Reaction outcome loss': 0.28511026224298197, 'Total loss': 0.28511026224298197}
2023-01-04 01:55:46,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:46,765 INFO:     Epoch: 29
2023-01-04 01:55:48,339 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41634192168712614, 'Total loss': 0.41634192168712614} | train loss {'Reaction outcome loss': 0.282457125284811, 'Total loss': 0.282457125284811}
2023-01-04 01:55:48,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:48,340 INFO:     Epoch: 30
2023-01-04 01:55:49,903 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4025493303934733, 'Total loss': 0.4025493303934733} | train loss {'Reaction outcome loss': 0.2797990687680941, 'Total loss': 0.2797990687680941}
2023-01-04 01:55:49,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:49,904 INFO:     Epoch: 31
2023-01-04 01:55:51,486 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4383295327425003, 'Total loss': 0.4383295327425003} | train loss {'Reaction outcome loss': 0.2729934668916203, 'Total loss': 0.2729934668916203}
2023-01-04 01:55:51,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:51,486 INFO:     Epoch: 32
2023-01-04 01:55:53,074 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4107786625623703, 'Total loss': 0.4107786625623703} | train loss {'Reaction outcome loss': 0.27054863221889, 'Total loss': 0.27054863221889}
2023-01-04 01:55:53,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:53,074 INFO:     Epoch: 33
2023-01-04 01:55:54,662 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4135550861557325, 'Total loss': 0.4135550861557325} | train loss {'Reaction outcome loss': 0.26699339119839843, 'Total loss': 0.26699339119839843}
2023-01-04 01:55:54,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:54,662 INFO:     Epoch: 34
2023-01-04 01:55:56,251 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4681048442920049, 'Total loss': 0.4681048442920049} | train loss {'Reaction outcome loss': 0.2650735003560999, 'Total loss': 0.2650735003560999}
2023-01-04 01:55:56,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:56,252 INFO:     Epoch: 35
2023-01-04 01:55:57,817 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4219381004571915, 'Total loss': 0.4219381004571915} | train loss {'Reaction outcome loss': 0.2626779670045324, 'Total loss': 0.2626779670045324}
2023-01-04 01:55:57,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:57,817 INFO:     Epoch: 36
2023-01-04 01:55:59,405 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41589097380638124, 'Total loss': 0.41589097380638124} | train loss {'Reaction outcome loss': 0.2578838637819255, 'Total loss': 0.2578838637819255}
2023-01-04 01:55:59,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:55:59,406 INFO:     Epoch: 37
2023-01-04 01:56:00,996 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42761936982472737, 'Total loss': 0.42761936982472737} | train loss {'Reaction outcome loss': 0.25562158096445736, 'Total loss': 0.25562158096445736}
2023-01-04 01:56:00,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:00,996 INFO:     Epoch: 38
2023-01-04 01:56:02,602 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40342462758223213, 'Total loss': 0.40342462758223213} | train loss {'Reaction outcome loss': 0.25397974309803795, 'Total loss': 0.25397974309803795}
2023-01-04 01:56:02,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:02,603 INFO:     Epoch: 39
2023-01-04 01:56:04,209 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41810151636600495, 'Total loss': 0.41810151636600495} | train loss {'Reaction outcome loss': 0.25391658447193405, 'Total loss': 0.25391658447193405}
2023-01-04 01:56:04,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:04,209 INFO:     Epoch: 40
2023-01-04 01:56:05,819 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4138892630736033, 'Total loss': 0.4138892630736033} | train loss {'Reaction outcome loss': 0.2494598999619484, 'Total loss': 0.2494598999619484}
2023-01-04 01:56:05,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:05,820 INFO:     Epoch: 41
2023-01-04 01:56:07,399 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43487765789031985, 'Total loss': 0.43487765789031985} | train loss {'Reaction outcome loss': 0.24328621340929157, 'Total loss': 0.24328621340929157}
2023-01-04 01:56:07,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:07,400 INFO:     Epoch: 42
2023-01-04 01:56:08,976 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4304555733998617, 'Total loss': 0.4304555733998617} | train loss {'Reaction outcome loss': 0.24226127284830504, 'Total loss': 0.24226127284830504}
2023-01-04 01:56:08,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:08,977 INFO:     Epoch: 43
2023-01-04 01:56:10,582 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.410244874159495, 'Total loss': 0.410244874159495} | train loss {'Reaction outcome loss': 0.2400119958350258, 'Total loss': 0.2400119958350258}
2023-01-04 01:56:10,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:10,582 INFO:     Epoch: 44
2023-01-04 01:56:12,193 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4424732565879822, 'Total loss': 0.4424732565879822} | train loss {'Reaction outcome loss': 0.23879239216011805, 'Total loss': 0.23879239216011805}
2023-01-04 01:56:12,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:12,193 INFO:     Epoch: 45
2023-01-04 01:56:13,805 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4403768956661224, 'Total loss': 0.4403768956661224} | train loss {'Reaction outcome loss': 0.23385684697949974, 'Total loss': 0.23385684697949974}
2023-01-04 01:56:13,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:13,805 INFO:     Epoch: 46
2023-01-04 01:56:15,402 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42854460775852204, 'Total loss': 0.42854460775852204} | train loss {'Reaction outcome loss': 0.2337300898847136, 'Total loss': 0.2337300898847136}
2023-01-04 01:56:15,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:15,402 INFO:     Epoch: 47
2023-01-04 01:56:16,988 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4230874180793762, 'Total loss': 0.4230874180793762} | train loss {'Reaction outcome loss': 0.2284466947163761, 'Total loss': 0.2284466947163761}
2023-01-04 01:56:16,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:16,989 INFO:     Epoch: 48
2023-01-04 01:56:18,561 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43744584619998933, 'Total loss': 0.43744584619998933} | train loss {'Reaction outcome loss': 0.2292668904538137, 'Total loss': 0.2292668904538137}
2023-01-04 01:56:18,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:18,561 INFO:     Epoch: 49
2023-01-04 01:56:20,147 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44142696062723796, 'Total loss': 0.44142696062723796} | train loss {'Reaction outcome loss': 0.22491729369618163, 'Total loss': 0.22491729369618163}
2023-01-04 01:56:20,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:20,148 INFO:     Epoch: 50
2023-01-04 01:56:21,767 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4012860536575317, 'Total loss': 0.4012860536575317} | train loss {'Reaction outcome loss': 0.22346175478322663, 'Total loss': 0.22346175478322663}
2023-01-04 01:56:21,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:21,768 INFO:     Epoch: 51
2023-01-04 01:56:23,361 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43226843973000845, 'Total loss': 0.43226843973000845} | train loss {'Reaction outcome loss': 0.2243867054935137, 'Total loss': 0.2243867054935137}
2023-01-04 01:56:23,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:23,361 INFO:     Epoch: 52
2023-01-04 01:56:24,954 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41716712415218354, 'Total loss': 0.41716712415218354} | train loss {'Reaction outcome loss': 0.22159457437857225, 'Total loss': 0.22159457437857225}
2023-01-04 01:56:24,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:24,954 INFO:     Epoch: 53
2023-01-04 01:56:26,551 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43216814398765563, 'Total loss': 0.43216814398765563} | train loss {'Reaction outcome loss': 0.2199586973981048, 'Total loss': 0.2199586973981048}
2023-01-04 01:56:26,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:26,551 INFO:     Epoch: 54
2023-01-04 01:56:28,165 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.438504562775294, 'Total loss': 0.438504562775294} | train loss {'Reaction outcome loss': 0.21546163849097533, 'Total loss': 0.21546163849097533}
2023-01-04 01:56:28,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:28,166 INFO:     Epoch: 55
2023-01-04 01:56:29,740 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42624571124712624, 'Total loss': 0.42624571124712624} | train loss {'Reaction outcome loss': 0.21815529547251053, 'Total loss': 0.21815529547251053}
2023-01-04 01:56:29,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:29,741 INFO:     Epoch: 56
2023-01-04 01:56:31,353 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4309593041737874, 'Total loss': 0.4309593041737874} | train loss {'Reaction outcome loss': 0.2128724233131774, 'Total loss': 0.2128724233131774}
2023-01-04 01:56:31,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:31,354 INFO:     Epoch: 57
2023-01-04 01:56:32,925 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4152231012781461, 'Total loss': 0.4152231012781461} | train loss {'Reaction outcome loss': 0.21310715899415258, 'Total loss': 0.21310715899415258}
2023-01-04 01:56:32,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:32,926 INFO:     Epoch: 58
2023-01-04 01:56:34,495 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4228884180386861, 'Total loss': 0.4228884180386861} | train loss {'Reaction outcome loss': 0.2079592265161502, 'Total loss': 0.2079592265161502}
2023-01-04 01:56:34,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:34,496 INFO:     Epoch: 59
2023-01-04 01:56:36,077 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4137053122123083, 'Total loss': 0.4137053122123083} | train loss {'Reaction outcome loss': 0.20867130910828166, 'Total loss': 0.20867130910828166}
2023-01-04 01:56:36,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:36,077 INFO:     Epoch: 60
2023-01-04 01:56:37,662 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42749538918336233, 'Total loss': 0.42749538918336233} | train loss {'Reaction outcome loss': 0.206973144444671, 'Total loss': 0.206973144444671}
2023-01-04 01:56:37,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:37,663 INFO:     Epoch: 61
2023-01-04 01:56:39,236 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.437141407529513, 'Total loss': 0.437141407529513} | train loss {'Reaction outcome loss': 0.20589869163495345, 'Total loss': 0.20589869163495345}
2023-01-04 01:56:39,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:39,237 INFO:     Epoch: 62
2023-01-04 01:56:40,828 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4369605044523875, 'Total loss': 0.4369605044523875} | train loss {'Reaction outcome loss': 0.20432369595896588, 'Total loss': 0.20432369595896588}
2023-01-04 01:56:40,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:40,828 INFO:     Epoch: 63
2023-01-04 01:56:42,412 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43911638905604683, 'Total loss': 0.43911638905604683} | train loss {'Reaction outcome loss': 0.20420852162107064, 'Total loss': 0.20420852162107064}
2023-01-04 01:56:42,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:42,412 INFO:     Epoch: 64
2023-01-04 01:56:44,026 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43661962846914926, 'Total loss': 0.43661962846914926} | train loss {'Reaction outcome loss': 0.20048203723110858, 'Total loss': 0.20048203723110858}
2023-01-04 01:56:44,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:44,026 INFO:     Epoch: 65
2023-01-04 01:56:45,604 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4373621890942256, 'Total loss': 0.4373621890942256} | train loss {'Reaction outcome loss': 0.20090319282871527, 'Total loss': 0.20090319282871527}
2023-01-04 01:56:45,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:45,604 INFO:     Epoch: 66
2023-01-04 01:56:47,202 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4310266306002935, 'Total loss': 0.4310266306002935} | train loss {'Reaction outcome loss': 0.19600229498923477, 'Total loss': 0.19600229498923477}
2023-01-04 01:56:47,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:47,202 INFO:     Epoch: 67
2023-01-04 01:56:48,812 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43363747000694275, 'Total loss': 0.43363747000694275} | train loss {'Reaction outcome loss': 0.1975662922962521, 'Total loss': 0.1975662922962521}
2023-01-04 01:56:48,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:48,812 INFO:     Epoch: 68
2023-01-04 01:56:50,426 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4326481640338898, 'Total loss': 0.4326481640338898} | train loss {'Reaction outcome loss': 0.1969863214958323, 'Total loss': 0.1969863214958323}
2023-01-04 01:56:50,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:50,427 INFO:     Epoch: 69
2023-01-04 01:56:52,015 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40553330034017565, 'Total loss': 0.40553330034017565} | train loss {'Reaction outcome loss': 0.19354817611131356, 'Total loss': 0.19354817611131356}
2023-01-04 01:56:52,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:52,015 INFO:     Epoch: 70
2023-01-04 01:56:53,602 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4223663568496704, 'Total loss': 0.4223663568496704} | train loss {'Reaction outcome loss': 0.19569542978883442, 'Total loss': 0.19569542978883442}
2023-01-04 01:56:53,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:53,603 INFO:     Epoch: 71
2023-01-04 01:56:55,219 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40135971109072366, 'Total loss': 0.40135971109072366} | train loss {'Reaction outcome loss': 0.1921268190889463, 'Total loss': 0.1921268190889463}
2023-01-04 01:56:55,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:55,219 INFO:     Epoch: 72
2023-01-04 01:56:56,832 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4396008501450221, 'Total loss': 0.4396008501450221} | train loss {'Reaction outcome loss': 0.19256027396360453, 'Total loss': 0.19256027396360453}
2023-01-04 01:56:56,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:56,832 INFO:     Epoch: 73
2023-01-04 01:56:58,436 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44552893241246544, 'Total loss': 0.44552893241246544} | train loss {'Reaction outcome loss': 0.19059092318979057, 'Total loss': 0.19059092318979057}
2023-01-04 01:56:58,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:56:58,437 INFO:     Epoch: 74
2023-01-04 01:57:00,020 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45336352785428363, 'Total loss': 0.45336352785428363} | train loss {'Reaction outcome loss': 0.1878860893040678, 'Total loss': 0.1878860893040678}
2023-01-04 01:57:00,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:00,020 INFO:     Epoch: 75
2023-01-04 01:57:01,599 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4448393702507019, 'Total loss': 0.4448393702507019} | train loss {'Reaction outcome loss': 0.1920278980634617, 'Total loss': 0.1920278980634617}
2023-01-04 01:57:01,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:01,600 INFO:     Epoch: 76
2023-01-04 01:57:03,162 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4062732790907224, 'Total loss': 0.4062732790907224} | train loss {'Reaction outcome loss': 0.187149636080339, 'Total loss': 0.187149636080339}
2023-01-04 01:57:03,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:03,163 INFO:     Epoch: 77
2023-01-04 01:57:04,765 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4576818565527598, 'Total loss': 0.4576818565527598} | train loss {'Reaction outcome loss': 0.18485027808614457, 'Total loss': 0.18485027808614457}
2023-01-04 01:57:04,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:04,766 INFO:     Epoch: 78
2023-01-04 01:57:06,365 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4450127770503362, 'Total loss': 0.4450127770503362} | train loss {'Reaction outcome loss': 0.18556651727289614, 'Total loss': 0.18556651727289614}
2023-01-04 01:57:06,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:06,366 INFO:     Epoch: 79
2023-01-04 01:57:07,987 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42749944726626077, 'Total loss': 0.42749944726626077} | train loss {'Reaction outcome loss': 0.18575566802445773, 'Total loss': 0.18575566802445773}
2023-01-04 01:57:07,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:07,988 INFO:     Epoch: 80
2023-01-04 01:57:09,574 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41898494561513266, 'Total loss': 0.41898494561513266} | train loss {'Reaction outcome loss': 0.18378472750340283, 'Total loss': 0.18378472750340283}
2023-01-04 01:57:09,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:09,575 INFO:     Epoch: 81
2023-01-04 01:57:11,192 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44363228380680086, 'Total loss': 0.44363228380680086} | train loss {'Reaction outcome loss': 0.1838211967562237, 'Total loss': 0.1838211967562237}
2023-01-04 01:57:11,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:11,192 INFO:     Epoch: 82
2023-01-04 01:57:12,757 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45359572817881905, 'Total loss': 0.45359572817881905} | train loss {'Reaction outcome loss': 0.18093072347016664, 'Total loss': 0.18093072347016664}
2023-01-04 01:57:12,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:12,758 INFO:     Epoch: 83
2023-01-04 01:57:14,368 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43659413953622184, 'Total loss': 0.43659413953622184} | train loss {'Reaction outcome loss': 0.18228813194173532, 'Total loss': 0.18228813194173532}
2023-01-04 01:57:14,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:14,368 INFO:     Epoch: 84
2023-01-04 01:57:15,981 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4336316932924092, 'Total loss': 0.4336316932924092} | train loss {'Reaction outcome loss': 0.18030010400353558, 'Total loss': 0.18030010400353558}
2023-01-04 01:57:15,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:15,981 INFO:     Epoch: 85
2023-01-04 01:57:17,593 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45770758589108784, 'Total loss': 0.45770758589108784} | train loss {'Reaction outcome loss': 0.18062175346715173, 'Total loss': 0.18062175346715173}
2023-01-04 01:57:17,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:17,593 INFO:     Epoch: 86
2023-01-04 01:57:19,180 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4518286873896917, 'Total loss': 0.4518286873896917} | train loss {'Reaction outcome loss': 0.17914585992150064, 'Total loss': 0.17914585992150064}
2023-01-04 01:57:19,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:19,180 INFO:     Epoch: 87
2023-01-04 01:57:20,768 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4364148139953613, 'Total loss': 0.4364148139953613} | train loss {'Reaction outcome loss': 0.1790097843393357, 'Total loss': 0.1790097843393357}
2023-01-04 01:57:20,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:20,768 INFO:     Epoch: 88
2023-01-04 01:57:22,379 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4373763471841812, 'Total loss': 0.4373763471841812} | train loss {'Reaction outcome loss': 0.17669363847396669, 'Total loss': 0.17669363847396669}
2023-01-04 01:57:22,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:22,379 INFO:     Epoch: 89
2023-01-04 01:57:23,977 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4572324752807617, 'Total loss': 0.4572324752807617} | train loss {'Reaction outcome loss': 0.17725359309247157, 'Total loss': 0.17725359309247157}
2023-01-04 01:57:23,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:23,977 INFO:     Epoch: 90
2023-01-04 01:57:25,565 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45917154600222904, 'Total loss': 0.45917154600222904} | train loss {'Reaction outcome loss': 0.1774205187757085, 'Total loss': 0.1774205187757085}
2023-01-04 01:57:25,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:25,566 INFO:     Epoch: 91
2023-01-04 01:57:27,166 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4614136238892873, 'Total loss': 0.4614136238892873} | train loss {'Reaction outcome loss': 0.17454545768181773, 'Total loss': 0.17454545768181773}
2023-01-04 01:57:27,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:27,167 INFO:     Epoch: 92
2023-01-04 01:57:28,740 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.450959915916125, 'Total loss': 0.450959915916125} | train loss {'Reaction outcome loss': 0.1731912394047436, 'Total loss': 0.1731912394047436}
2023-01-04 01:57:28,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:28,740 INFO:     Epoch: 93
2023-01-04 01:57:30,311 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46162383755048114, 'Total loss': 0.46162383755048114} | train loss {'Reaction outcome loss': 0.17341630467397234, 'Total loss': 0.17341630467397234}
2023-01-04 01:57:30,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:30,311 INFO:     Epoch: 94
2023-01-04 01:57:31,904 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4440363903840383, 'Total loss': 0.4440363903840383} | train loss {'Reaction outcome loss': 0.1704998935307682, 'Total loss': 0.1704998935307682}
2023-01-04 01:57:31,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:31,905 INFO:     Epoch: 95
2023-01-04 01:57:33,500 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44849346379439037, 'Total loss': 0.44849346379439037} | train loss {'Reaction outcome loss': 0.16997100368658774, 'Total loss': 0.16997100368658774}
2023-01-04 01:57:33,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:33,501 INFO:     Epoch: 96
2023-01-04 01:57:35,108 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43442625030875204, 'Total loss': 0.43442625030875204} | train loss {'Reaction outcome loss': 0.17132463951996207, 'Total loss': 0.17132463951996207}
2023-01-04 01:57:35,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:35,109 INFO:     Epoch: 97
2023-01-04 01:57:36,698 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4643386244773865, 'Total loss': 0.4643386244773865} | train loss {'Reaction outcome loss': 0.17188921668668733, 'Total loss': 0.17188921668668733}
2023-01-04 01:57:36,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:36,700 INFO:     Epoch: 98
2023-01-04 01:57:38,306 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44487935801347095, 'Total loss': 0.44487935801347095} | train loss {'Reaction outcome loss': 0.16977928576134418, 'Total loss': 0.16977928576134418}
2023-01-04 01:57:38,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:38,307 INFO:     Epoch: 99
2023-01-04 01:57:39,874 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4371433238188426, 'Total loss': 0.4371433238188426} | train loss {'Reaction outcome loss': 0.17153812414647018, 'Total loss': 0.17153812414647018}
2023-01-04 01:57:39,874 INFO:     Best model found after epoch 24 of 100.
2023-01-04 01:57:39,874 INFO:   Done with stage: TRAINING
2023-01-04 01:57:39,874 INFO:   Starting stage: EVALUATION
2023-01-04 01:57:40,008 INFO:   Done with stage: EVALUATION
2023-01-04 01:57:40,008 INFO:   Leaving out SEQ value Fold_8
2023-01-04 01:57:40,020 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:57:40,020 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:57:40,673 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:57:40,673 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:57:40,743 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:57:40,743 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:57:40,743 INFO:     No hyperparam tuning for this model
2023-01-04 01:57:40,743 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:57:40,743 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:57:40,744 INFO:     None feature selector for col prot
2023-01-04 01:57:40,744 INFO:     None feature selector for col prot
2023-01-04 01:57:40,744 INFO:     None feature selector for col prot
2023-01-04 01:57:40,745 INFO:     None feature selector for col chem
2023-01-04 01:57:40,745 INFO:     None feature selector for col chem
2023-01-04 01:57:40,745 INFO:     None feature selector for col chem
2023-01-04 01:57:40,745 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:57:40,745 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:57:40,746 INFO:     Number of params in model 70141
2023-01-04 01:57:40,749 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:57:40,749 INFO:   Starting stage: TRAINING
2023-01-04 01:57:40,792 INFO:     Val loss before train {'Reaction outcome loss': 0.8828525384267171, 'Total loss': 0.8828525384267171}
2023-01-04 01:57:40,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:40,792 INFO:     Epoch: 0
2023-01-04 01:57:42,408 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.607439661026001, 'Total loss': 0.607439661026001} | train loss {'Reaction outcome loss': 0.8910329460774948, 'Total loss': 0.8910329460774948}
2023-01-04 01:57:42,408 INFO:     Found new best model at epoch 0
2023-01-04 01:57:42,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:42,409 INFO:     Epoch: 1
2023-01-04 01:57:44,022 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5023419797420502, 'Total loss': 0.5023419797420502} | train loss {'Reaction outcome loss': 0.6301301563905034, 'Total loss': 0.6301301563905034}
2023-01-04 01:57:44,023 INFO:     Found new best model at epoch 1
2023-01-04 01:57:44,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:44,024 INFO:     Epoch: 2
2023-01-04 01:57:45,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4561096986134847, 'Total loss': 0.4561096986134847} | train loss {'Reaction outcome loss': 0.5453832762228453, 'Total loss': 0.5453832762228453}
2023-01-04 01:57:45,611 INFO:     Found new best model at epoch 2
2023-01-04 01:57:45,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:45,611 INFO:     Epoch: 3
2023-01-04 01:57:47,209 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43026331861813866, 'Total loss': 0.43026331861813866} | train loss {'Reaction outcome loss': 0.4989049452952099, 'Total loss': 0.4989049452952099}
2023-01-04 01:57:47,209 INFO:     Found new best model at epoch 3
2023-01-04 01:57:47,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:47,210 INFO:     Epoch: 4
2023-01-04 01:57:48,841 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43260264297326406, 'Total loss': 0.43260264297326406} | train loss {'Reaction outcome loss': 0.4696596411161044, 'Total loss': 0.4696596411161044}
2023-01-04 01:57:48,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:48,841 INFO:     Epoch: 5
2023-01-04 01:57:50,468 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.405912392338117, 'Total loss': 0.405912392338117} | train loss {'Reaction outcome loss': 0.44536482252261267, 'Total loss': 0.44536482252261267}
2023-01-04 01:57:50,468 INFO:     Found new best model at epoch 5
2023-01-04 01:57:50,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:50,469 INFO:     Epoch: 6
2023-01-04 01:57:52,079 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41129541397094727, 'Total loss': 0.41129541397094727} | train loss {'Reaction outcome loss': 0.42522031300119545, 'Total loss': 0.42522031300119545}
2023-01-04 01:57:52,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:52,080 INFO:     Epoch: 7
2023-01-04 01:57:53,710 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39748674432436626, 'Total loss': 0.39748674432436626} | train loss {'Reaction outcome loss': 0.4132306831569448, 'Total loss': 0.4132306831569448}
2023-01-04 01:57:53,710 INFO:     Found new best model at epoch 7
2023-01-04 01:57:53,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:53,711 INFO:     Epoch: 8
2023-01-04 01:57:55,319 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3804375638564428, 'Total loss': 0.3804375638564428} | train loss {'Reaction outcome loss': 0.39768677019255255, 'Total loss': 0.39768677019255255}
2023-01-04 01:57:55,319 INFO:     Found new best model at epoch 8
2023-01-04 01:57:55,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:55,320 INFO:     Epoch: 9
2023-01-04 01:57:56,902 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38637927373250325, 'Total loss': 0.38637927373250325} | train loss {'Reaction outcome loss': 0.38828946838310047, 'Total loss': 0.38828946838310047}
2023-01-04 01:57:56,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:56,903 INFO:     Epoch: 10
2023-01-04 01:57:58,505 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37401114304860433, 'Total loss': 0.37401114304860433} | train loss {'Reaction outcome loss': 0.3771719735398189, 'Total loss': 0.3771719735398189}
2023-01-04 01:57:58,506 INFO:     Found new best model at epoch 10
2023-01-04 01:57:58,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:57:58,506 INFO:     Epoch: 11
2023-01-04 01:58:00,108 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38491165041923525, 'Total loss': 0.38491165041923525} | train loss {'Reaction outcome loss': 0.3678975525961026, 'Total loss': 0.3678975525961026}
2023-01-04 01:58:00,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:00,108 INFO:     Epoch: 12
2023-01-04 01:58:01,713 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3783485323190689, 'Total loss': 0.3783485323190689} | train loss {'Reaction outcome loss': 0.3619007986805499, 'Total loss': 0.3619007986805499}
2023-01-04 01:58:01,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:01,713 INFO:     Epoch: 13
2023-01-04 01:58:03,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36933116416136424, 'Total loss': 0.36933116416136424} | train loss {'Reaction outcome loss': 0.3517305590077858, 'Total loss': 0.3517305590077858}
2023-01-04 01:58:03,295 INFO:     Found new best model at epoch 13
2023-01-04 01:58:03,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:03,296 INFO:     Epoch: 14
2023-01-04 01:58:04,930 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3648383269707362, 'Total loss': 0.3648383269707362} | train loss {'Reaction outcome loss': 0.34550655611693215, 'Total loss': 0.34550655611693215}
2023-01-04 01:58:04,930 INFO:     Found new best model at epoch 14
2023-01-04 01:58:04,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:04,931 INFO:     Epoch: 15
2023-01-04 01:58:06,511 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37108169694741566, 'Total loss': 0.37108169694741566} | train loss {'Reaction outcome loss': 0.34096086243107, 'Total loss': 0.34096086243107}
2023-01-04 01:58:06,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:06,511 INFO:     Epoch: 16
2023-01-04 01:58:08,112 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37494919896125795, 'Total loss': 0.37494919896125795} | train loss {'Reaction outcome loss': 0.33329627619861263, 'Total loss': 0.33329627619861263}
2023-01-04 01:58:08,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:08,113 INFO:     Epoch: 17
2023-01-04 01:58:09,714 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36087446262439093, 'Total loss': 0.36087446262439093} | train loss {'Reaction outcome loss': 0.3269244446167016, 'Total loss': 0.3269244446167016}
2023-01-04 01:58:09,714 INFO:     Found new best model at epoch 17
2023-01-04 01:58:09,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:09,715 INFO:     Epoch: 18
2023-01-04 01:58:11,316 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35925659239292146, 'Total loss': 0.35925659239292146} | train loss {'Reaction outcome loss': 0.32157558791796653, 'Total loss': 0.32157558791796653}
2023-01-04 01:58:11,316 INFO:     Found new best model at epoch 18
2023-01-04 01:58:11,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:11,317 INFO:     Epoch: 19
2023-01-04 01:58:12,927 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3485007146994273, 'Total loss': 0.3485007146994273} | train loss {'Reaction outcome loss': 0.31623836945648226, 'Total loss': 0.31623836945648226}
2023-01-04 01:58:12,927 INFO:     Found new best model at epoch 19
2023-01-04 01:58:12,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:12,928 INFO:     Epoch: 20
2023-01-04 01:58:14,555 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3599886146684488, 'Total loss': 0.3599886146684488} | train loss {'Reaction outcome loss': 0.3096603647358581, 'Total loss': 0.3096603647358581}
2023-01-04 01:58:14,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:14,556 INFO:     Epoch: 21
2023-01-04 01:58:16,196 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3560128450393677, 'Total loss': 0.3560128450393677} | train loss {'Reaction outcome loss': 0.3060704925860739, 'Total loss': 0.3060704925860739}
2023-01-04 01:58:16,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:16,196 INFO:     Epoch: 22
2023-01-04 01:58:17,831 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3470957706371943, 'Total loss': 0.3470957706371943} | train loss {'Reaction outcome loss': 0.30129497441789305, 'Total loss': 0.30129497441789305}
2023-01-04 01:58:17,831 INFO:     Found new best model at epoch 22
2023-01-04 01:58:17,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:17,832 INFO:     Epoch: 23
2023-01-04 01:58:19,441 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.351850966612498, 'Total loss': 0.351850966612498} | train loss {'Reaction outcome loss': 0.2970562114343316, 'Total loss': 0.2970562114343316}
2023-01-04 01:58:19,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:19,441 INFO:     Epoch: 24
2023-01-04 01:58:21,072 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3597041110197703, 'Total loss': 0.3597041110197703} | train loss {'Reaction outcome loss': 0.2931153233085729, 'Total loss': 0.2931153233085729}
2023-01-04 01:58:21,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:21,072 INFO:     Epoch: 25
2023-01-04 01:58:22,657 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3743577857812246, 'Total loss': 0.3743577857812246} | train loss {'Reaction outcome loss': 0.2884305763976238, 'Total loss': 0.2884305763976238}
2023-01-04 01:58:22,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:22,658 INFO:     Epoch: 26
2023-01-04 01:58:24,252 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.35960909227530163, 'Total loss': 0.35960909227530163} | train loss {'Reaction outcome loss': 0.28439428420596174, 'Total loss': 0.28439428420596174}
2023-01-04 01:58:24,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:24,253 INFO:     Epoch: 27
2023-01-04 01:58:25,883 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3522233575582504, 'Total loss': 0.3522233575582504} | train loss {'Reaction outcome loss': 0.27947988369189447, 'Total loss': 0.27947988369189447}
2023-01-04 01:58:25,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:25,884 INFO:     Epoch: 28
2023-01-04 01:58:27,503 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3564269691705704, 'Total loss': 0.3564269691705704} | train loss {'Reaction outcome loss': 0.2751129514097307, 'Total loss': 0.2751129514097307}
2023-01-04 01:58:27,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:27,504 INFO:     Epoch: 29
2023-01-04 01:58:29,091 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3777293632427851, 'Total loss': 0.3777293632427851} | train loss {'Reaction outcome loss': 0.27359008361393794, 'Total loss': 0.27359008361393794}
2023-01-04 01:58:29,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:29,091 INFO:     Epoch: 30
2023-01-04 01:58:30,698 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36425509651501975, 'Total loss': 0.36425509651501975} | train loss {'Reaction outcome loss': 0.27202385830750103, 'Total loss': 0.27202385830750103}
2023-01-04 01:58:30,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:30,698 INFO:     Epoch: 31
2023-01-04 01:58:32,271 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.369698673983415, 'Total loss': 0.369698673983415} | train loss {'Reaction outcome loss': 0.26819178023600837, 'Total loss': 0.26819178023600837}
2023-01-04 01:58:32,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:32,272 INFO:     Epoch: 32
2023-01-04 01:58:33,900 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3846791585286458, 'Total loss': 0.3846791585286458} | train loss {'Reaction outcome loss': 0.2659074276658817, 'Total loss': 0.2659074276658817}
2023-01-04 01:58:33,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:33,900 INFO:     Epoch: 33
2023-01-04 01:58:35,499 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3667814515531063, 'Total loss': 0.3667814515531063} | train loss {'Reaction outcome loss': 0.2609150266335329, 'Total loss': 0.2609150266335329}
2023-01-04 01:58:35,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:35,499 INFO:     Epoch: 34
2023-01-04 01:58:37,127 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38124226331710814, 'Total loss': 0.38124226331710814} | train loss {'Reaction outcome loss': 0.25706174380620034, 'Total loss': 0.25706174380620034}
2023-01-04 01:58:37,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:37,128 INFO:     Epoch: 35
2023-01-04 01:58:38,757 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37911768406629565, 'Total loss': 0.37911768406629565} | train loss {'Reaction outcome loss': 0.25594773009042876, 'Total loss': 0.25594773009042876}
2023-01-04 01:58:38,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:38,757 INFO:     Epoch: 36
2023-01-04 01:58:40,340 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39610903163750966, 'Total loss': 0.39610903163750966} | train loss {'Reaction outcome loss': 0.2528449704446947, 'Total loss': 0.2528449704446947}
2023-01-04 01:58:40,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:40,341 INFO:     Epoch: 37
2023-01-04 01:58:41,932 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38592624962329863, 'Total loss': 0.38592624962329863} | train loss {'Reaction outcome loss': 0.2515846309033542, 'Total loss': 0.2515846309033542}
2023-01-04 01:58:41,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:41,932 INFO:     Epoch: 38
2023-01-04 01:58:43,544 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3783871456980705, 'Total loss': 0.3783871456980705} | train loss {'Reaction outcome loss': 0.24714958339606813, 'Total loss': 0.24714958339606813}
2023-01-04 01:58:43,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:43,545 INFO:     Epoch: 39
2023-01-04 01:58:45,158 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36843874007463456, 'Total loss': 0.36843874007463456} | train loss {'Reaction outcome loss': 0.24317615065010875, 'Total loss': 0.24317615065010875}
2023-01-04 01:58:45,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:45,158 INFO:     Epoch: 40
2023-01-04 01:58:46,781 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3732850939035416, 'Total loss': 0.3732850939035416} | train loss {'Reaction outcome loss': 0.24032721063290263, 'Total loss': 0.24032721063290263}
2023-01-04 01:58:46,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:46,781 INFO:     Epoch: 41
2023-01-04 01:58:48,382 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38189351360003154, 'Total loss': 0.38189351360003154} | train loss {'Reaction outcome loss': 0.2397572557149381, 'Total loss': 0.2397572557149381}
2023-01-04 01:58:48,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:48,382 INFO:     Epoch: 42
2023-01-04 01:58:50,014 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3755430281162262, 'Total loss': 0.3755430281162262} | train loss {'Reaction outcome loss': 0.23643968751929728, 'Total loss': 0.23643968751929728}
2023-01-04 01:58:50,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:50,015 INFO:     Epoch: 43
2023-01-04 01:58:51,634 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38272681335608166, 'Total loss': 0.38272681335608166} | train loss {'Reaction outcome loss': 0.2353545394104095, 'Total loss': 0.2353545394104095}
2023-01-04 01:58:51,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:51,634 INFO:     Epoch: 44
2023-01-04 01:58:53,235 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40467502176761627, 'Total loss': 0.40467502176761627} | train loss {'Reaction outcome loss': 0.2335063652925543, 'Total loss': 0.2335063652925543}
2023-01-04 01:58:53,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:53,236 INFO:     Epoch: 45
2023-01-04 01:58:54,856 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4044345185160637, 'Total loss': 0.4044345185160637} | train loss {'Reaction outcome loss': 0.2327097070534522, 'Total loss': 0.2327097070534522}
2023-01-04 01:58:54,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:54,856 INFO:     Epoch: 46
2023-01-04 01:58:56,477 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3824555277824402, 'Total loss': 0.3824555277824402} | train loss {'Reaction outcome loss': 0.2295786569748975, 'Total loss': 0.2295786569748975}
2023-01-04 01:58:56,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:56,477 INFO:     Epoch: 47
2023-01-04 01:58:58,082 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3972142775853475, 'Total loss': 0.3972142775853475} | train loss {'Reaction outcome loss': 0.22762962274710624, 'Total loss': 0.22762962274710624}
2023-01-04 01:58:58,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:58,082 INFO:     Epoch: 48
2023-01-04 01:58:59,679 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38857723474502565, 'Total loss': 0.38857723474502565} | train loss {'Reaction outcome loss': 0.22485088311566126, 'Total loss': 0.22485088311566126}
2023-01-04 01:58:59,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:58:59,679 INFO:     Epoch: 49
2023-01-04 01:59:01,307 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3971034665902456, 'Total loss': 0.3971034665902456} | train loss {'Reaction outcome loss': 0.22331537941087454, 'Total loss': 0.22331537941087454}
2023-01-04 01:59:01,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:01,307 INFO:     Epoch: 50
2023-01-04 01:59:02,930 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38880338966846467, 'Total loss': 0.38880338966846467} | train loss {'Reaction outcome loss': 0.22148771407855977, 'Total loss': 0.22148771407855977}
2023-01-04 01:59:02,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:02,931 INFO:     Epoch: 51
2023-01-04 01:59:04,555 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39612375597159066, 'Total loss': 0.39612375597159066} | train loss {'Reaction outcome loss': 0.22202923140801248, 'Total loss': 0.22202923140801248}
2023-01-04 01:59:04,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:04,555 INFO:     Epoch: 52
2023-01-04 01:59:06,185 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3850729043285052, 'Total loss': 0.3850729043285052} | train loss {'Reaction outcome loss': 0.21692341676365168, 'Total loss': 0.21692341676365168}
2023-01-04 01:59:06,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:06,185 INFO:     Epoch: 53
2023-01-04 01:59:07,809 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39116823077201845, 'Total loss': 0.39116823077201845} | train loss {'Reaction outcome loss': 0.21614832349713314, 'Total loss': 0.21614832349713314}
2023-01-04 01:59:07,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:07,809 INFO:     Epoch: 54
2023-01-04 01:59:09,423 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3798832093675931, 'Total loss': 0.3798832093675931} | train loss {'Reaction outcome loss': 0.21497313736094034, 'Total loss': 0.21497313736094034}
2023-01-04 01:59:09,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:09,423 INFO:     Epoch: 55
2023-01-04 01:59:11,058 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37496525843938194, 'Total loss': 0.37496525843938194} | train loss {'Reaction outcome loss': 0.21447302714420569, 'Total loss': 0.21447302714420569}
2023-01-04 01:59:11,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:11,058 INFO:     Epoch: 56
2023-01-04 01:59:12,686 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4119109779596329, 'Total loss': 0.4119109779596329} | train loss {'Reaction outcome loss': 0.21112774446983198, 'Total loss': 0.21112774446983198}
2023-01-04 01:59:12,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:12,686 INFO:     Epoch: 57
2023-01-04 01:59:14,316 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40406715671221416, 'Total loss': 0.40406715671221416} | train loss {'Reaction outcome loss': 0.20952092915343035, 'Total loss': 0.20952092915343035}
2023-01-04 01:59:14,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:14,317 INFO:     Epoch: 58
2023-01-04 01:59:15,923 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3952270011107127, 'Total loss': 0.3952270011107127} | train loss {'Reaction outcome loss': 0.20806403364649964, 'Total loss': 0.20806403364649964}
2023-01-04 01:59:15,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:15,924 INFO:     Epoch: 59
2023-01-04 01:59:17,511 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.403815625111262, 'Total loss': 0.403815625111262} | train loss {'Reaction outcome loss': 0.20612016894488128, 'Total loss': 0.20612016894488128}
2023-01-04 01:59:17,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:17,511 INFO:     Epoch: 60
2023-01-04 01:59:19,115 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39951048195362093, 'Total loss': 0.39951048195362093} | train loss {'Reaction outcome loss': 0.2049595970082154, 'Total loss': 0.2049595970082154}
2023-01-04 01:59:19,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:19,115 INFO:     Epoch: 61
2023-01-04 01:59:20,719 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4129064400990804, 'Total loss': 0.4129064400990804} | train loss {'Reaction outcome loss': 0.2046413612064472, 'Total loss': 0.2046413612064472}
2023-01-04 01:59:20,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:20,720 INFO:     Epoch: 62
2023-01-04 01:59:22,324 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3939246289432049, 'Total loss': 0.3939246289432049} | train loss {'Reaction outcome loss': 0.20241107368700556, 'Total loss': 0.20241107368700556}
2023-01-04 01:59:22,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:22,324 INFO:     Epoch: 63
2023-01-04 01:59:23,929 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.388687821974357, 'Total loss': 0.388687821974357} | train loss {'Reaction outcome loss': 0.20124524405448016, 'Total loss': 0.20124524405448016}
2023-01-04 01:59:23,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:23,929 INFO:     Epoch: 64
2023-01-04 01:59:25,532 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4086577594280243, 'Total loss': 0.4086577594280243} | train loss {'Reaction outcome loss': 0.19989004160280907, 'Total loss': 0.19989004160280907}
2023-01-04 01:59:25,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:25,532 INFO:     Epoch: 65
2023-01-04 01:59:27,132 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4071410000324249, 'Total loss': 0.4071410000324249} | train loss {'Reaction outcome loss': 0.19948619496521106, 'Total loss': 0.19948619496521106}
2023-01-04 01:59:27,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:27,132 INFO:     Epoch: 66
2023-01-04 01:59:28,763 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41586742202440896, 'Total loss': 0.41586742202440896} | train loss {'Reaction outcome loss': 0.19681606109553296, 'Total loss': 0.19681606109553296}
2023-01-04 01:59:28,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:28,763 INFO:     Epoch: 67
2023-01-04 01:59:30,393 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.412024732430776, 'Total loss': 0.412024732430776} | train loss {'Reaction outcome loss': 0.19586364101847156, 'Total loss': 0.19586364101847156}
2023-01-04 01:59:30,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:30,393 INFO:     Epoch: 68
2023-01-04 01:59:32,006 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4143934806187948, 'Total loss': 0.4143934806187948} | train loss {'Reaction outcome loss': 0.19358663313386673, 'Total loss': 0.19358663313386673}
2023-01-04 01:59:32,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:32,007 INFO:     Epoch: 69
2023-01-04 01:59:33,608 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42352701524893444, 'Total loss': 0.42352701524893444} | train loss {'Reaction outcome loss': 0.19462191434543485, 'Total loss': 0.19462191434543485}
2023-01-04 01:59:33,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:33,609 INFO:     Epoch: 70
2023-01-04 01:59:35,223 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4128894383708636, 'Total loss': 0.4128894383708636} | train loss {'Reaction outcome loss': 0.19329071230513956, 'Total loss': 0.19329071230513956}
2023-01-04 01:59:35,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:35,223 INFO:     Epoch: 71
2023-01-04 01:59:36,819 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41436084111531574, 'Total loss': 0.41436084111531574} | train loss {'Reaction outcome loss': 0.19186842481904942, 'Total loss': 0.19186842481904942}
2023-01-04 01:59:36,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:36,819 INFO:     Epoch: 72
2023-01-04 01:59:38,424 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40277589013179144, 'Total loss': 0.40277589013179144} | train loss {'Reaction outcome loss': 0.1918911469111804, 'Total loss': 0.1918911469111804}
2023-01-04 01:59:38,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:38,424 INFO:     Epoch: 73
2023-01-04 01:59:40,029 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40545278787612915, 'Total loss': 0.40545278787612915} | train loss {'Reaction outcome loss': 0.18880785465079095, 'Total loss': 0.18880785465079095}
2023-01-04 01:59:40,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:40,029 INFO:     Epoch: 74
2023-01-04 01:59:41,658 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4227348158756892, 'Total loss': 0.4227348158756892} | train loss {'Reaction outcome loss': 0.18910986768747495, 'Total loss': 0.18910986768747495}
2023-01-04 01:59:41,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:41,659 INFO:     Epoch: 75
2023-01-04 01:59:43,270 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4167792975902557, 'Total loss': 0.4167792975902557} | train loss {'Reaction outcome loss': 0.18777278759634453, 'Total loss': 0.18777278759634453}
2023-01-04 01:59:43,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:43,270 INFO:     Epoch: 76
2023-01-04 01:59:44,870 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40105100770791374, 'Total loss': 0.40105100770791374} | train loss {'Reaction outcome loss': 0.186216330955928, 'Total loss': 0.186216330955928}
2023-01-04 01:59:44,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:44,871 INFO:     Epoch: 77
2023-01-04 01:59:46,468 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.441092911362648, 'Total loss': 0.441092911362648} | train loss {'Reaction outcome loss': 0.18645625535587004, 'Total loss': 0.18645625535587004}
2023-01-04 01:59:46,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:46,469 INFO:     Epoch: 78
2023-01-04 01:59:48,071 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4389914224545161, 'Total loss': 0.4389914224545161} | train loss {'Reaction outcome loss': 0.1842810416237757, 'Total loss': 0.1842810416237757}
2023-01-04 01:59:48,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:48,071 INFO:     Epoch: 79
2023-01-04 01:59:49,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4019395569960276, 'Total loss': 0.4019395569960276} | train loss {'Reaction outcome loss': 0.18221604661336874, 'Total loss': 0.18221604661336874}
2023-01-04 01:59:49,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:49,695 INFO:     Epoch: 80
2023-01-04 01:59:51,307 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4082557717959086, 'Total loss': 0.4082557717959086} | train loss {'Reaction outcome loss': 0.1804897203194213, 'Total loss': 0.1804897203194213}
2023-01-04 01:59:51,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:51,308 INFO:     Epoch: 81
2023-01-04 01:59:52,908 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4330108900864919, 'Total loss': 0.4330108900864919} | train loss {'Reaction outcome loss': 0.18493111984340294, 'Total loss': 0.18493111984340294}
2023-01-04 01:59:52,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:52,909 INFO:     Epoch: 82
2023-01-04 01:59:54,494 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4092208166917165, 'Total loss': 0.4092208166917165} | train loss {'Reaction outcome loss': 0.18113708812138235, 'Total loss': 0.18113708812138235}
2023-01-04 01:59:54,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:54,494 INFO:     Epoch: 83
2023-01-04 01:59:56,104 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4233884960412979, 'Total loss': 0.4233884960412979} | train loss {'Reaction outcome loss': 0.18387287074451197, 'Total loss': 0.18387287074451197}
2023-01-04 01:59:56,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:56,104 INFO:     Epoch: 84
2023-01-04 01:59:57,733 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43177043795585635, 'Total loss': 0.43177043795585635} | train loss {'Reaction outcome loss': 0.18095114164135087, 'Total loss': 0.18095114164135087}
2023-01-04 01:59:57,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:57,733 INFO:     Epoch: 85
2023-01-04 01:59:59,364 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.412691796819369, 'Total loss': 0.412691796819369} | train loss {'Reaction outcome loss': 0.18046405485794217, 'Total loss': 0.18046405485794217}
2023-01-04 01:59:59,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:59:59,365 INFO:     Epoch: 86
2023-01-04 02:00:00,971 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42477451761563617, 'Total loss': 0.42477451761563617} | train loss {'Reaction outcome loss': 0.17875973095559256, 'Total loss': 0.17875973095559256}
2023-01-04 02:00:00,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:00,971 INFO:     Epoch: 87
2023-01-04 02:00:02,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4358452578385671, 'Total loss': 0.4358452578385671} | train loss {'Reaction outcome loss': 0.1781989349260765, 'Total loss': 0.1781989349260765}
2023-01-04 02:00:02,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:02,566 INFO:     Epoch: 88
2023-01-04 02:00:04,168 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.402340026696523, 'Total loss': 0.402340026696523} | train loss {'Reaction outcome loss': 0.17827600268277236, 'Total loss': 0.17827600268277236}
2023-01-04 02:00:04,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:04,169 INFO:     Epoch: 89
2023-01-04 02:00:05,770 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43422280649344125, 'Total loss': 0.43422280649344125} | train loss {'Reaction outcome loss': 0.17679891871147208, 'Total loss': 0.17679891871147208}
2023-01-04 02:00:05,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:05,770 INFO:     Epoch: 90
2023-01-04 02:00:07,399 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4326100806395213, 'Total loss': 0.4326100806395213} | train loss {'Reaction outcome loss': 0.17620897962163717, 'Total loss': 0.17620897962163717}
2023-01-04 02:00:07,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:07,400 INFO:     Epoch: 91
2023-01-04 02:00:09,028 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4414910058180491, 'Total loss': 0.4414910058180491} | train loss {'Reaction outcome loss': 0.17614653235173613, 'Total loss': 0.17614653235173613}
2023-01-04 02:00:09,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:09,028 INFO:     Epoch: 92
2023-01-04 02:00:10,631 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4169350802898407, 'Total loss': 0.4169350802898407} | train loss {'Reaction outcome loss': 0.17606009689532892, 'Total loss': 0.17606009689532892}
2023-01-04 02:00:10,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:10,631 INFO:     Epoch: 93
2023-01-04 02:00:12,229 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42672364513079325, 'Total loss': 0.42672364513079325} | train loss {'Reaction outcome loss': 0.17682225754760234, 'Total loss': 0.17682225754760234}
2023-01-04 02:00:12,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:12,229 INFO:     Epoch: 94
2023-01-04 02:00:13,829 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4189585785071055, 'Total loss': 0.4189585785071055} | train loss {'Reaction outcome loss': 0.17514730355154307, 'Total loss': 0.17514730355154307}
2023-01-04 02:00:13,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:13,829 INFO:     Epoch: 95
2023-01-04 02:00:15,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4615234409769376, 'Total loss': 0.4615234409769376} | train loss {'Reaction outcome loss': 0.17206957917458746, 'Total loss': 0.17206957917458746}
2023-01-04 02:00:15,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:15,432 INFO:     Epoch: 96
2023-01-04 02:00:17,031 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41192912062009174, 'Total loss': 0.41192912062009174} | train loss {'Reaction outcome loss': 0.17365677067034943, 'Total loss': 0.17365677067034943}
2023-01-04 02:00:17,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:17,031 INFO:     Epoch: 97
2023-01-04 02:00:18,618 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4241531511147817, 'Total loss': 0.4241531511147817} | train loss {'Reaction outcome loss': 0.17408320011860196, 'Total loss': 0.17408320011860196}
2023-01-04 02:00:18,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:18,618 INFO:     Epoch: 98
2023-01-04 02:00:20,231 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4423880636692047, 'Total loss': 0.4423880636692047} | train loss {'Reaction outcome loss': 0.1749091584047148, 'Total loss': 0.1749091584047148}
2023-01-04 02:00:20,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:20,231 INFO:     Epoch: 99
2023-01-04 02:00:21,831 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4203146361435453, 'Total loss': 0.4203146361435453} | train loss {'Reaction outcome loss': 0.17060613531336888, 'Total loss': 0.17060613531336888}
2023-01-04 02:00:21,831 INFO:     Best model found after epoch 23 of 100.
2023-01-04 02:00:21,831 INFO:   Done with stage: TRAINING
2023-01-04 02:00:21,832 INFO:   Starting stage: EVALUATION
2023-01-04 02:00:21,955 INFO:   Done with stage: EVALUATION
2023-01-04 02:00:21,955 INFO:   Leaving out SEQ value Fold_9
2023-01-04 02:00:21,968 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:00:21,968 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:00:22,614 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:00:22,615 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:00:22,683 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:00:22,683 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:00:22,683 INFO:     No hyperparam tuning for this model
2023-01-04 02:00:22,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:00:22,683 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:00:22,684 INFO:     None feature selector for col prot
2023-01-04 02:00:22,684 INFO:     None feature selector for col prot
2023-01-04 02:00:22,684 INFO:     None feature selector for col prot
2023-01-04 02:00:22,685 INFO:     None feature selector for col chem
2023-01-04 02:00:22,685 INFO:     None feature selector for col chem
2023-01-04 02:00:22,685 INFO:     None feature selector for col chem
2023-01-04 02:00:22,685 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:00:22,685 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:00:22,686 INFO:     Number of params in model 70141
2023-01-04 02:00:22,689 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:00:22,689 INFO:   Starting stage: TRAINING
2023-01-04 02:00:22,732 INFO:     Val loss before train {'Reaction outcome loss': 0.9480123162269593, 'Total loss': 0.9480123162269593}
2023-01-04 02:00:22,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:22,732 INFO:     Epoch: 0
2023-01-04 02:00:24,339 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6658084293206533, 'Total loss': 0.6658084293206533} | train loss {'Reaction outcome loss': 0.8287524042555886, 'Total loss': 0.8287524042555886}
2023-01-04 02:00:24,339 INFO:     Found new best model at epoch 0
2023-01-04 02:00:24,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:24,340 INFO:     Epoch: 1
2023-01-04 02:00:25,938 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5963853259881338, 'Total loss': 0.5963853259881338} | train loss {'Reaction outcome loss': 0.5809200211924358, 'Total loss': 0.5809200211924358}
2023-01-04 02:00:25,938 INFO:     Found new best model at epoch 1
2023-01-04 02:00:25,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:25,939 INFO:     Epoch: 2
2023-01-04 02:00:27,513 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5536924203236898, 'Total loss': 0.5536924203236898} | train loss {'Reaction outcome loss': 0.5133904997449722, 'Total loss': 0.5133904997449722}
2023-01-04 02:00:27,513 INFO:     Found new best model at epoch 2
2023-01-04 02:00:27,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:27,514 INFO:     Epoch: 3
2023-01-04 02:00:29,098 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4852083841959635, 'Total loss': 0.4852083841959635} | train loss {'Reaction outcome loss': 0.4743473300859876, 'Total loss': 0.4743473300859876}
2023-01-04 02:00:29,099 INFO:     Found new best model at epoch 3
2023-01-04 02:00:29,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:29,099 INFO:     Epoch: 4
2023-01-04 02:00:30,706 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4755840251843135, 'Total loss': 0.4755840251843135} | train loss {'Reaction outcome loss': 0.44890321513814646, 'Total loss': 0.44890321513814646}
2023-01-04 02:00:30,706 INFO:     Found new best model at epoch 4
2023-01-04 02:00:30,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:30,707 INFO:     Epoch: 5
2023-01-04 02:00:32,295 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46505034267902373, 'Total loss': 0.46505034267902373} | train loss {'Reaction outcome loss': 0.4277079768315719, 'Total loss': 0.4277079768315719}
2023-01-04 02:00:32,295 INFO:     Found new best model at epoch 5
2023-01-04 02:00:32,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:32,296 INFO:     Epoch: 6
2023-01-04 02:00:33,896 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4547704795996348, 'Total loss': 0.4547704795996348} | train loss {'Reaction outcome loss': 0.41375337290937886, 'Total loss': 0.41375337290937886}
2023-01-04 02:00:33,897 INFO:     Found new best model at epoch 6
2023-01-04 02:00:33,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:33,898 INFO:     Epoch: 7
2023-01-04 02:00:35,504 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44464910626411436, 'Total loss': 0.44464910626411436} | train loss {'Reaction outcome loss': 0.4000314066227335, 'Total loss': 0.4000314066227335}
2023-01-04 02:00:35,504 INFO:     Found new best model at epoch 7
2023-01-04 02:00:35,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:35,505 INFO:     Epoch: 8
2023-01-04 02:00:37,093 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4328447252511978, 'Total loss': 0.4328447252511978} | train loss {'Reaction outcome loss': 0.3890192324880266, 'Total loss': 0.3890192324880266}
2023-01-04 02:00:37,094 INFO:     Found new best model at epoch 8
2023-01-04 02:00:37,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:37,094 INFO:     Epoch: 9
2023-01-04 02:00:38,667 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4193070868651072, 'Total loss': 0.4193070868651072} | train loss {'Reaction outcome loss': 0.37802231665292796, 'Total loss': 0.37802231665292796}
2023-01-04 02:00:38,667 INFO:     Found new best model at epoch 9
2023-01-04 02:00:38,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:38,668 INFO:     Epoch: 10
2023-01-04 02:00:40,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4287514626979828, 'Total loss': 0.4287514626979828} | train loss {'Reaction outcome loss': 0.3684752678403454, 'Total loss': 0.3684752678403454}
2023-01-04 02:00:40,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:40,248 INFO:     Epoch: 11
2023-01-04 02:00:41,830 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.429426775376002, 'Total loss': 0.429426775376002} | train loss {'Reaction outcome loss': 0.36167368415172085, 'Total loss': 0.36167368415172085}
2023-01-04 02:00:41,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:41,830 INFO:     Epoch: 12
2023-01-04 02:00:43,412 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43970403373241423, 'Total loss': 0.43970403373241423} | train loss {'Reaction outcome loss': 0.35101519288481586, 'Total loss': 0.35101519288481586}
2023-01-04 02:00:43,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:43,412 INFO:     Epoch: 13
2023-01-04 02:00:44,984 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42896727422873177, 'Total loss': 0.42896727422873177} | train loss {'Reaction outcome loss': 0.34436173070847553, 'Total loss': 0.34436173070847553}
2023-01-04 02:00:44,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:44,985 INFO:     Epoch: 14
2023-01-04 02:00:46,595 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42768601576487225, 'Total loss': 0.42768601576487225} | train loss {'Reaction outcome loss': 0.34043867048555915, 'Total loss': 0.34043867048555915}
2023-01-04 02:00:46,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:46,596 INFO:     Epoch: 15
2023-01-04 02:00:48,168 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4329091548919678, 'Total loss': 0.4329091548919678} | train loss {'Reaction outcome loss': 0.33255169934926243, 'Total loss': 0.33255169934926243}
2023-01-04 02:00:48,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:48,169 INFO:     Epoch: 16
2023-01-04 02:00:49,772 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41786694824695586, 'Total loss': 0.41786694824695586} | train loss {'Reaction outcome loss': 0.3237656098212639, 'Total loss': 0.3237656098212639}
2023-01-04 02:00:49,772 INFO:     Found new best model at epoch 16
2023-01-04 02:00:49,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:49,773 INFO:     Epoch: 17
2023-01-04 02:00:51,347 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4036608636379242, 'Total loss': 0.4036608636379242} | train loss {'Reaction outcome loss': 0.3187183327972889, 'Total loss': 0.3187183327972889}
2023-01-04 02:00:51,347 INFO:     Found new best model at epoch 17
2023-01-04 02:00:51,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:51,348 INFO:     Epoch: 18
2023-01-04 02:00:52,952 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42868010997772216, 'Total loss': 0.42868010997772216} | train loss {'Reaction outcome loss': 0.31238990334154915, 'Total loss': 0.31238990334154915}
2023-01-04 02:00:52,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:52,953 INFO:     Epoch: 19
2023-01-04 02:00:54,539 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4275506834189097, 'Total loss': 0.4275506834189097} | train loss {'Reaction outcome loss': 0.3070036265047362, 'Total loss': 0.3070036265047362}
2023-01-04 02:00:54,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:54,539 INFO:     Epoch: 20
2023-01-04 02:00:56,134 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41325795849164326, 'Total loss': 0.41325795849164326} | train loss {'Reaction outcome loss': 0.30410076917087947, 'Total loss': 0.30410076917087947}
2023-01-04 02:00:56,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:56,134 INFO:     Epoch: 21
2023-01-04 02:00:57,746 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42070799122254054, 'Total loss': 0.42070799122254054} | train loss {'Reaction outcome loss': 0.2991147483733014, 'Total loss': 0.2991147483733014}
2023-01-04 02:00:57,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:57,746 INFO:     Epoch: 22
2023-01-04 02:00:59,351 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4239723344643911, 'Total loss': 0.4239723344643911} | train loss {'Reaction outcome loss': 0.2919999870070576, 'Total loss': 0.2919999870070576}
2023-01-04 02:00:59,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:00:59,351 INFO:     Epoch: 23
2023-01-04 02:01:00,958 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4224102367957433, 'Total loss': 0.4224102367957433} | train loss {'Reaction outcome loss': 0.29350753106775074, 'Total loss': 0.29350753106775074}
2023-01-04 02:01:00,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:00,958 INFO:     Epoch: 24
2023-01-04 02:01:02,567 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4069195181131363, 'Total loss': 0.4069195181131363} | train loss {'Reaction outcome loss': 0.28614746121159434, 'Total loss': 0.28614746121159434}
2023-01-04 02:01:02,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:02,568 INFO:     Epoch: 25
2023-01-04 02:01:04,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41620146532853447, 'Total loss': 0.41620146532853447} | train loss {'Reaction outcome loss': 0.2834598786693855, 'Total loss': 0.2834598786693855}
2023-01-04 02:01:04,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:04,139 INFO:     Epoch: 26
2023-01-04 02:01:05,708 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40932347575823463, 'Total loss': 0.40932347575823463} | train loss {'Reaction outcome loss': 0.2750563003856988, 'Total loss': 0.2750563003856988}
2023-01-04 02:01:05,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:05,709 INFO:     Epoch: 27
2023-01-04 02:01:07,288 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4314849883317947, 'Total loss': 0.4314849883317947} | train loss {'Reaction outcome loss': 0.274113430784349, 'Total loss': 0.274113430784349}
2023-01-04 02:01:07,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:07,288 INFO:     Epoch: 28
2023-01-04 02:01:08,867 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41260254085063935, 'Total loss': 0.41260254085063935} | train loss {'Reaction outcome loss': 0.27159710440539964, 'Total loss': 0.27159710440539964}
2023-01-04 02:01:08,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:08,868 INFO:     Epoch: 29
2023-01-04 02:01:10,447 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4287349939346313, 'Total loss': 0.4287349939346313} | train loss {'Reaction outcome loss': 0.26758243684677313, 'Total loss': 0.26758243684677313}
2023-01-04 02:01:10,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:10,447 INFO:     Epoch: 30
2023-01-04 02:01:12,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42102529605229694, 'Total loss': 0.42102529605229694} | train loss {'Reaction outcome loss': 0.262558993332795, 'Total loss': 0.262558993332795}
2023-01-04 02:01:12,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:12,012 INFO:     Epoch: 31
2023-01-04 02:01:13,576 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39637303352355957, 'Total loss': 0.39637303352355957} | train loss {'Reaction outcome loss': 0.26023889628041835, 'Total loss': 0.26023889628041835}
2023-01-04 02:01:13,576 INFO:     Found new best model at epoch 31
2023-01-04 02:01:13,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:13,577 INFO:     Epoch: 32
2023-01-04 02:01:15,172 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4502108782529831, 'Total loss': 0.4502108782529831} | train loss {'Reaction outcome loss': 0.2570540710984573, 'Total loss': 0.2570540710984573}
2023-01-04 02:01:15,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:15,173 INFO:     Epoch: 33
2023-01-04 02:01:16,787 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.430669704079628, 'Total loss': 0.430669704079628} | train loss {'Reaction outcome loss': 0.2544508890731491, 'Total loss': 0.2544508890731491}
2023-01-04 02:01:16,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:16,788 INFO:     Epoch: 34
2023-01-04 02:01:18,401 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42411830425262453, 'Total loss': 0.42411830425262453} | train loss {'Reaction outcome loss': 0.24995865925711436, 'Total loss': 0.24995865925711436}
2023-01-04 02:01:18,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:18,401 INFO:     Epoch: 35
2023-01-04 02:01:19,977 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41318747103214265, 'Total loss': 0.41318747103214265} | train loss {'Reaction outcome loss': 0.24656649023620753, 'Total loss': 0.24656649023620753}
2023-01-04 02:01:19,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:19,977 INFO:     Epoch: 36
2023-01-04 02:01:21,565 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4242863724629084, 'Total loss': 0.4242863724629084} | train loss {'Reaction outcome loss': 0.24355039923676175, 'Total loss': 0.24355039923676175}
2023-01-04 02:01:21,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:21,565 INFO:     Epoch: 37
2023-01-04 02:01:23,141 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40373759468396503, 'Total loss': 0.40373759468396503} | train loss {'Reaction outcome loss': 0.24167603817190567, 'Total loss': 0.24167603817190567}
2023-01-04 02:01:23,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:23,142 INFO:     Epoch: 38
2023-01-04 02:01:24,749 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41417266527811686, 'Total loss': 0.41417266527811686} | train loss {'Reaction outcome loss': 0.23668189613270935, 'Total loss': 0.23668189613270935}
2023-01-04 02:01:24,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:24,749 INFO:     Epoch: 39
2023-01-04 02:01:26,359 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42229154258966445, 'Total loss': 0.42229154258966445} | train loss {'Reaction outcome loss': 0.23447570794799033, 'Total loss': 0.23447570794799033}
2023-01-04 02:01:26,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:26,360 INFO:     Epoch: 40
2023-01-04 02:01:27,972 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40459807763497035, 'Total loss': 0.40459807763497035} | train loss {'Reaction outcome loss': 0.2339742711072203, 'Total loss': 0.2339742711072203}
2023-01-04 02:01:27,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:27,972 INFO:     Epoch: 41
2023-01-04 02:01:29,568 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42372123102347053, 'Total loss': 0.42372123102347053} | train loss {'Reaction outcome loss': 0.23112310243457773, 'Total loss': 0.23112310243457773}
2023-01-04 02:01:29,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:29,568 INFO:     Epoch: 42
2023-01-04 02:01:31,142 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4334644615650177, 'Total loss': 0.4334644615650177} | train loss {'Reaction outcome loss': 0.22944793183981937, 'Total loss': 0.22944793183981937}
2023-01-04 02:01:31,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:31,142 INFO:     Epoch: 43
2023-01-04 02:01:32,704 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44793903827667236, 'Total loss': 0.44793903827667236} | train loss {'Reaction outcome loss': 0.226447385137588, 'Total loss': 0.226447385137588}
2023-01-04 02:01:32,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:32,704 INFO:     Epoch: 44
2023-01-04 02:01:34,307 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4077239026625951, 'Total loss': 0.4077239026625951} | train loss {'Reaction outcome loss': 0.22575519063992658, 'Total loss': 0.22575519063992658}
2023-01-04 02:01:34,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:34,307 INFO:     Epoch: 45
2023-01-04 02:01:35,928 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4076577126979828, 'Total loss': 0.4076577126979828} | train loss {'Reaction outcome loss': 0.22520903153956806, 'Total loss': 0.22520903153956806}
2023-01-04 02:01:35,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:35,929 INFO:     Epoch: 46
2023-01-04 02:01:37,546 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3993765791257223, 'Total loss': 0.3993765791257223} | train loss {'Reaction outcome loss': 0.22114292878902306, 'Total loss': 0.22114292878902306}
2023-01-04 02:01:37,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:37,547 INFO:     Epoch: 47
2023-01-04 02:01:39,136 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4057314842939377, 'Total loss': 0.4057314842939377} | train loss {'Reaction outcome loss': 0.21681625184596237, 'Total loss': 0.21681625184596237}
2023-01-04 02:01:39,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:39,136 INFO:     Epoch: 48
2023-01-04 02:01:40,705 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4196827401717504, 'Total loss': 0.4196827401717504} | train loss {'Reaction outcome loss': 0.21824606270767258, 'Total loss': 0.21824606270767258}
2023-01-04 02:01:40,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:40,706 INFO:     Epoch: 49
2023-01-04 02:01:42,297 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40452948162953056, 'Total loss': 0.40452948162953056} | train loss {'Reaction outcome loss': 0.21554313572871425, 'Total loss': 0.21554313572871425}
2023-01-04 02:01:42,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:42,297 INFO:     Epoch: 50
2023-01-04 02:01:43,884 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42296942869822185, 'Total loss': 0.42296942869822185} | train loss {'Reaction outcome loss': 0.21443396889652214, 'Total loss': 0.21443396889652214}
2023-01-04 02:01:43,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:43,884 INFO:     Epoch: 51
2023-01-04 02:01:45,473 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44436269303162895, 'Total loss': 0.44436269303162895} | train loss {'Reaction outcome loss': 0.21060031466186047, 'Total loss': 0.21060031466186047}
2023-01-04 02:01:45,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:45,473 INFO:     Epoch: 52
2023-01-04 02:01:47,081 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42194166680177053, 'Total loss': 0.42194166680177053} | train loss {'Reaction outcome loss': 0.20920461378175847, 'Total loss': 0.20920461378175847}
2023-01-04 02:01:47,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:47,081 INFO:     Epoch: 53
2023-01-04 02:01:48,652 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4251078526178996, 'Total loss': 0.4251078526178996} | train loss {'Reaction outcome loss': 0.20974267596365326, 'Total loss': 0.20974267596365326}
2023-01-04 02:01:48,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:48,653 INFO:     Epoch: 54
2023-01-04 02:01:50,225 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41257164378960925, 'Total loss': 0.41257164378960925} | train loss {'Reaction outcome loss': 0.20678803520481082, 'Total loss': 0.20678803520481082}
2023-01-04 02:01:50,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:50,225 INFO:     Epoch: 55
2023-01-04 02:01:51,795 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4010251839955648, 'Total loss': 0.4010251839955648} | train loss {'Reaction outcome loss': 0.20525356452830518, 'Total loss': 0.20525356452830518}
2023-01-04 02:01:51,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:51,795 INFO:     Epoch: 56
2023-01-04 02:01:53,438 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46555869877338407, 'Total loss': 0.46555869877338407} | train loss {'Reaction outcome loss': 0.20081092269724085, 'Total loss': 0.20081092269724085}
2023-01-04 02:01:53,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:53,438 INFO:     Epoch: 57
2023-01-04 02:01:55,060 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4227670179059108, 'Total loss': 0.4227670179059108} | train loss {'Reaction outcome loss': 0.2026179729940465, 'Total loss': 0.2026179729940465}
2023-01-04 02:01:55,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:55,061 INFO:     Epoch: 58
2023-01-04 02:01:56,644 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42849072615305583, 'Total loss': 0.42849072615305583} | train loss {'Reaction outcome loss': 0.20231618063293233, 'Total loss': 0.20231618063293233}
2023-01-04 02:01:56,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:56,645 INFO:     Epoch: 59
2023-01-04 02:01:58,228 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43310618003209433, 'Total loss': 0.43310618003209433} | train loss {'Reaction outcome loss': 0.19573225226443614, 'Total loss': 0.19573225226443614}
2023-01-04 02:01:58,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:58,228 INFO:     Epoch: 60
2023-01-04 02:01:59,812 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42890229721864065, 'Total loss': 0.42890229721864065} | train loss {'Reaction outcome loss': 0.1981952243967213, 'Total loss': 0.1981952243967213}
2023-01-04 02:01:59,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:01:59,812 INFO:     Epoch: 61
2023-01-04 02:02:01,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41874705304702126, 'Total loss': 0.41874705304702126} | train loss {'Reaction outcome loss': 0.1972044424500561, 'Total loss': 0.1972044424500561}
2023-01-04 02:02:01,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:01,398 INFO:     Epoch: 62
2023-01-04 02:02:02,982 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4297542467713356, 'Total loss': 0.4297542467713356} | train loss {'Reaction outcome loss': 0.1939129800107466, 'Total loss': 0.1939129800107466}
2023-01-04 02:02:02,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:02,983 INFO:     Epoch: 63
2023-01-04 02:02:04,586 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4341279665629069, 'Total loss': 0.4341279665629069} | train loss {'Reaction outcome loss': 0.19580275897126997, 'Total loss': 0.19580275897126997}
2023-01-04 02:02:04,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:04,586 INFO:     Epoch: 64
2023-01-04 02:02:06,163 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40709315141042074, 'Total loss': 0.40709315141042074} | train loss {'Reaction outcome loss': 0.1938326215765772, 'Total loss': 0.1938326215765772}
2023-01-04 02:02:06,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:06,163 INFO:     Epoch: 65
2023-01-04 02:02:07,755 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41610123217105865, 'Total loss': 0.41610123217105865} | train loss {'Reaction outcome loss': 0.19176470149770705, 'Total loss': 0.19176470149770705}
2023-01-04 02:02:07,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:07,756 INFO:     Epoch: 66
2023-01-04 02:02:09,338 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40196230113506315, 'Total loss': 0.40196230113506315} | train loss {'Reaction outcome loss': 0.1899807661241532, 'Total loss': 0.1899807661241532}
2023-01-04 02:02:09,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:09,338 INFO:     Epoch: 67
2023-01-04 02:02:10,921 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4115425318479538, 'Total loss': 0.4115425318479538} | train loss {'Reaction outcome loss': 0.18959833379073518, 'Total loss': 0.18959833379073518}
2023-01-04 02:02:10,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:10,921 INFO:     Epoch: 68
2023-01-04 02:02:12,503 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41906542479991915, 'Total loss': 0.41906542479991915} | train loss {'Reaction outcome loss': 0.18590538777465368, 'Total loss': 0.18590538777465368}
2023-01-04 02:02:12,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:12,503 INFO:     Epoch: 69
2023-01-04 02:02:14,086 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4033771852652232, 'Total loss': 0.4033771852652232} | train loss {'Reaction outcome loss': 0.18459699468782348, 'Total loss': 0.18459699468782348}
2023-01-04 02:02:14,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:14,086 INFO:     Epoch: 70
2023-01-04 02:02:15,654 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38956922640403113, 'Total loss': 0.38956922640403113} | train loss {'Reaction outcome loss': 0.18510059824036637, 'Total loss': 0.18510059824036637}
2023-01-04 02:02:15,654 INFO:     Found new best model at epoch 70
2023-01-04 02:02:15,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:15,655 INFO:     Epoch: 71
2023-01-04 02:02:17,227 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4128637373447418, 'Total loss': 0.4128637373447418} | train loss {'Reaction outcome loss': 0.18630734067002352, 'Total loss': 0.18630734067002352}
2023-01-04 02:02:17,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:17,227 INFO:     Epoch: 72
2023-01-04 02:02:18,810 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40559590260187783, 'Total loss': 0.40559590260187783} | train loss {'Reaction outcome loss': 0.18650508009196415, 'Total loss': 0.18650508009196415}
2023-01-04 02:02:18,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:18,811 INFO:     Epoch: 73
2023-01-04 02:02:20,402 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42235702176888784, 'Total loss': 0.42235702176888784} | train loss {'Reaction outcome loss': 0.1809462636817981, 'Total loss': 0.1809462636817981}
2023-01-04 02:02:20,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:20,403 INFO:     Epoch: 74
2023-01-04 02:02:21,999 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41743670652310055, 'Total loss': 0.41743670652310055} | train loss {'Reaction outcome loss': 0.18151869211536253, 'Total loss': 0.18151869211536253}
2023-01-04 02:02:21,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:22,000 INFO:     Epoch: 75
2023-01-04 02:02:23,562 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43236528610189756, 'Total loss': 0.43236528610189756} | train loss {'Reaction outcome loss': 0.18169954802541838, 'Total loss': 0.18169954802541838}
2023-01-04 02:02:23,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:23,563 INFO:     Epoch: 76
2023-01-04 02:02:25,144 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41328789790471393, 'Total loss': 0.41328789790471393} | train loss {'Reaction outcome loss': 0.1784783097691018, 'Total loss': 0.1784783097691018}
2023-01-04 02:02:25,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:25,144 INFO:     Epoch: 77
2023-01-04 02:02:26,712 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3973803475499153, 'Total loss': 0.3973803475499153} | train loss {'Reaction outcome loss': 0.1799365922020082, 'Total loss': 0.1799365922020082}
2023-01-04 02:02:26,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:26,712 INFO:     Epoch: 78
2023-01-04 02:02:28,319 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4147102544705073, 'Total loss': 0.4147102544705073} | train loss {'Reaction outcome loss': 0.17463612818859353, 'Total loss': 0.17463612818859353}
2023-01-04 02:02:28,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:28,319 INFO:     Epoch: 79
2023-01-04 02:02:29,926 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.421599680185318, 'Total loss': 0.421599680185318} | train loss {'Reaction outcome loss': 0.17625726134020048, 'Total loss': 0.17625726134020048}
2023-01-04 02:02:29,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:29,927 INFO:     Epoch: 80
2023-01-04 02:02:31,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4368543341755867, 'Total loss': 0.4368543341755867} | train loss {'Reaction outcome loss': 0.17479929942501723, 'Total loss': 0.17479929942501723}
2023-01-04 02:02:31,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:31,490 INFO:     Epoch: 81
2023-01-04 02:02:33,061 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42332777579625447, 'Total loss': 0.42332777579625447} | train loss {'Reaction outcome loss': 0.17401835902247334, 'Total loss': 0.17401835902247334}
2023-01-04 02:02:33,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:33,062 INFO:     Epoch: 82
2023-01-04 02:02:34,651 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41541885733604433, 'Total loss': 0.41541885733604433} | train loss {'Reaction outcome loss': 0.1736592292636089, 'Total loss': 0.1736592292636089}
2023-01-04 02:02:34,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:34,652 INFO:     Epoch: 83
2023-01-04 02:02:36,233 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40709460377693174, 'Total loss': 0.40709460377693174} | train loss {'Reaction outcome loss': 0.17526328789382956, 'Total loss': 0.17526328789382956}
2023-01-04 02:02:36,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:36,233 INFO:     Epoch: 84
2023-01-04 02:02:37,814 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.414792533715566, 'Total loss': 0.414792533715566} | train loss {'Reaction outcome loss': 0.171132063931602, 'Total loss': 0.171132063931602}
2023-01-04 02:02:37,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:37,815 INFO:     Epoch: 85
2023-01-04 02:02:39,393 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4231228480736415, 'Total loss': 0.4231228480736415} | train loss {'Reaction outcome loss': 0.17485373303375756, 'Total loss': 0.17485373303375756}
2023-01-04 02:02:39,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:39,393 INFO:     Epoch: 86
2023-01-04 02:02:40,963 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4159367799758911, 'Total loss': 0.4159367799758911} | train loss {'Reaction outcome loss': 0.1735532431434976, 'Total loss': 0.1735532431434976}
2023-01-04 02:02:40,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:40,964 INFO:     Epoch: 87
2023-01-04 02:02:42,556 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40313636263211566, 'Total loss': 0.40313636263211566} | train loss {'Reaction outcome loss': 0.16946375207554032, 'Total loss': 0.16946375207554032}
2023-01-04 02:02:42,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:42,557 INFO:     Epoch: 88
2023-01-04 02:02:44,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41459176143010457, 'Total loss': 0.41459176143010457} | train loss {'Reaction outcome loss': 0.17220334528544307, 'Total loss': 0.17220334528544307}
2023-01-04 02:02:44,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:44,131 INFO:     Epoch: 89
2023-01-04 02:02:45,699 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43797995646794635, 'Total loss': 0.43797995646794635} | train loss {'Reaction outcome loss': 0.16731308138229117, 'Total loss': 0.16731308138229117}
2023-01-04 02:02:45,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:45,700 INFO:     Epoch: 90
2023-01-04 02:02:47,307 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3986176470915476, 'Total loss': 0.3986176470915476} | train loss {'Reaction outcome loss': 0.1656449693153157, 'Total loss': 0.1656449693153157}
2023-01-04 02:02:47,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:47,307 INFO:     Epoch: 91
2023-01-04 02:02:48,915 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41305480202039085, 'Total loss': 0.41305480202039085} | train loss {'Reaction outcome loss': 0.16737733907100275, 'Total loss': 0.16737733907100275}
2023-01-04 02:02:48,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:48,916 INFO:     Epoch: 92
2023-01-04 02:02:50,465 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4032419592142105, 'Total loss': 0.4032419592142105} | train loss {'Reaction outcome loss': 0.16575992328325545, 'Total loss': 0.16575992328325545}
2023-01-04 02:02:50,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:50,465 INFO:     Epoch: 93
2023-01-04 02:02:52,073 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4293060431877772, 'Total loss': 0.4293060431877772} | train loss {'Reaction outcome loss': 0.1654785140791405, 'Total loss': 0.1654785140791405}
2023-01-04 02:02:52,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:52,073 INFO:     Epoch: 94
2023-01-04 02:02:53,642 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40356881767511366, 'Total loss': 0.40356881767511366} | train loss {'Reaction outcome loss': 0.1668192203204236, 'Total loss': 0.1668192203204236}
2023-01-04 02:02:53,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:53,642 INFO:     Epoch: 95
2023-01-04 02:02:55,223 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4182329873243968, 'Total loss': 0.4182329873243968} | train loss {'Reaction outcome loss': 0.16409890405004368, 'Total loss': 0.16409890405004368}
2023-01-04 02:02:55,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:55,224 INFO:     Epoch: 96
2023-01-04 02:02:56,805 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4356343944867452, 'Total loss': 0.4356343944867452} | train loss {'Reaction outcome loss': 0.16376016855946857, 'Total loss': 0.16376016855946857}
2023-01-04 02:02:56,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:56,805 INFO:     Epoch: 97
2023-01-04 02:02:58,383 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42565143754084905, 'Total loss': 0.42565143754084905} | train loss {'Reaction outcome loss': 0.16394303700492385, 'Total loss': 0.16394303700492385}
2023-01-04 02:02:58,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:58,383 INFO:     Epoch: 98
2023-01-04 02:02:59,958 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40467871030171715, 'Total loss': 0.40467871030171715} | train loss {'Reaction outcome loss': 0.16106603145055529, 'Total loss': 0.16106603145055529}
2023-01-04 02:02:59,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:02:59,958 INFO:     Epoch: 99
2023-01-04 02:03:01,547 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4084060142437617, 'Total loss': 0.4084060142437617} | train loss {'Reaction outcome loss': 0.1605770701719244, 'Total loss': 0.1605770701719244}
2023-01-04 02:03:01,547 INFO:     Best model found after epoch 71 of 100.
2023-01-04 02:03:01,548 INFO:   Done with stage: TRAINING
2023-01-04 02:03:01,548 INFO:   Starting stage: EVALUATION
2023-01-04 02:03:01,682 INFO:   Done with stage: EVALUATION
2023-01-04 02:03:01,690 INFO:   Leaving out SEQ value Fold_0
2023-01-04 02:03:01,702 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 02:03:01,702 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:03:02,339 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:03:02,339 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:03:02,407 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:03:02,407 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:03:02,407 INFO:     No hyperparam tuning for this model
2023-01-04 02:03:02,407 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:03:02,407 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:03:02,408 INFO:     None feature selector for col prot
2023-01-04 02:03:02,408 INFO:     None feature selector for col prot
2023-01-04 02:03:02,408 INFO:     None feature selector for col prot
2023-01-04 02:03:02,409 INFO:     None feature selector for col chem
2023-01-04 02:03:02,409 INFO:     None feature selector for col chem
2023-01-04 02:03:02,409 INFO:     None feature selector for col chem
2023-01-04 02:03:02,409 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:03:02,409 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:03:02,410 INFO:     Number of params in model 70141
2023-01-04 02:03:02,413 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:03:02,413 INFO:   Starting stage: TRAINING
2023-01-04 02:03:02,459 INFO:     Val loss before train {'Reaction outcome loss': 1.047658916314443, 'Total loss': 1.047658916314443}
2023-01-04 02:03:02,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:02,459 INFO:     Epoch: 0
2023-01-04 02:03:04,034 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7184454639752705, 'Total loss': 0.7184454639752705} | train loss {'Reaction outcome loss': 0.8234067253577404, 'Total loss': 0.8234067253577404}
2023-01-04 02:03:04,034 INFO:     Found new best model at epoch 0
2023-01-04 02:03:04,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:04,035 INFO:     Epoch: 1
2023-01-04 02:03:05,607 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5887003938357035, 'Total loss': 0.5887003938357035} | train loss {'Reaction outcome loss': 0.582126972657857, 'Total loss': 0.582126972657857}
2023-01-04 02:03:05,607 INFO:     Found new best model at epoch 1
2023-01-04 02:03:05,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:05,608 INFO:     Epoch: 2
2023-01-04 02:03:07,194 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5679970482985178, 'Total loss': 0.5679970482985178} | train loss {'Reaction outcome loss': 0.5173564078934464, 'Total loss': 0.5173564078934464}
2023-01-04 02:03:07,194 INFO:     Found new best model at epoch 2
2023-01-04 02:03:07,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:07,195 INFO:     Epoch: 3
2023-01-04 02:03:08,815 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5275277475516001, 'Total loss': 0.5275277475516001} | train loss {'Reaction outcome loss': 0.48222684347149214, 'Total loss': 0.48222684347149214}
2023-01-04 02:03:08,815 INFO:     Found new best model at epoch 3
2023-01-04 02:03:08,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:08,816 INFO:     Epoch: 4
2023-01-04 02:03:10,427 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49325965841611225, 'Total loss': 0.49325965841611225} | train loss {'Reaction outcome loss': 0.45582973149233247, 'Total loss': 0.45582973149233247}
2023-01-04 02:03:10,427 INFO:     Found new best model at epoch 4
2023-01-04 02:03:10,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:10,428 INFO:     Epoch: 5
2023-01-04 02:03:12,048 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4808378487825394, 'Total loss': 0.4808378487825394} | train loss {'Reaction outcome loss': 0.4362329777889636, 'Total loss': 0.4362329777889636}
2023-01-04 02:03:12,048 INFO:     Found new best model at epoch 5
2023-01-04 02:03:12,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:12,049 INFO:     Epoch: 6
2023-01-04 02:03:13,680 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46056943337122597, 'Total loss': 0.46056943337122597} | train loss {'Reaction outcome loss': 0.4245685868429177, 'Total loss': 0.4245685868429177}
2023-01-04 02:03:13,681 INFO:     Found new best model at epoch 6
2023-01-04 02:03:13,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:13,681 INFO:     Epoch: 7
2023-01-04 02:03:15,315 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46175472835699716, 'Total loss': 0.46175472835699716} | train loss {'Reaction outcome loss': 0.4081543147727683, 'Total loss': 0.4081543147727683}
2023-01-04 02:03:15,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:15,315 INFO:     Epoch: 8
2023-01-04 02:03:16,920 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4506162305672963, 'Total loss': 0.4506162305672963} | train loss {'Reaction outcome loss': 0.39352795476223523, 'Total loss': 0.39352795476223523}
2023-01-04 02:03:16,920 INFO:     Found new best model at epoch 8
2023-01-04 02:03:16,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:16,921 INFO:     Epoch: 9
2023-01-04 02:03:18,513 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4680485000212987, 'Total loss': 0.4680485000212987} | train loss {'Reaction outcome loss': 0.3850384517794564, 'Total loss': 0.3850384517794564}
2023-01-04 02:03:18,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:18,514 INFO:     Epoch: 10
2023-01-04 02:03:20,104 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4413679083188375, 'Total loss': 0.4413679083188375} | train loss {'Reaction outcome loss': 0.3758589669843733, 'Total loss': 0.3758589669843733}
2023-01-04 02:03:20,105 INFO:     Found new best model at epoch 10
2023-01-04 02:03:20,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:20,105 INFO:     Epoch: 11
2023-01-04 02:03:21,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4469069222609202, 'Total loss': 0.4469069222609202} | train loss {'Reaction outcome loss': 0.37046212940425666, 'Total loss': 0.37046212940425666}
2023-01-04 02:03:21,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:21,716 INFO:     Epoch: 12
2023-01-04 02:03:23,319 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44067535996437074, 'Total loss': 0.44067535996437074} | train loss {'Reaction outcome loss': 0.3619310763620195, 'Total loss': 0.3619310763620195}
2023-01-04 02:03:23,319 INFO:     Found new best model at epoch 12
2023-01-04 02:03:23,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:23,320 INFO:     Epoch: 13
2023-01-04 02:03:24,919 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4570419987042745, 'Total loss': 0.4570419987042745} | train loss {'Reaction outcome loss': 0.355305968364189, 'Total loss': 0.355305968364189}
2023-01-04 02:03:24,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:24,919 INFO:     Epoch: 14
2023-01-04 02:03:26,501 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4422819177309672, 'Total loss': 0.4422819177309672} | train loss {'Reaction outcome loss': 0.3475008665860354, 'Total loss': 0.3475008665860354}
2023-01-04 02:03:26,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:26,501 INFO:     Epoch: 15
2023-01-04 02:03:28,104 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4338027318318685, 'Total loss': 0.4338027318318685} | train loss {'Reaction outcome loss': 0.34118178737905874, 'Total loss': 0.34118178737905874}
2023-01-04 02:03:28,104 INFO:     Found new best model at epoch 15
2023-01-04 02:03:28,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:28,105 INFO:     Epoch: 16
2023-01-04 02:03:29,681 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42181103030840555, 'Total loss': 0.42181103030840555} | train loss {'Reaction outcome loss': 0.3370867779021298, 'Total loss': 0.3370867779021298}
2023-01-04 02:03:29,682 INFO:     Found new best model at epoch 16
2023-01-04 02:03:29,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:29,683 INFO:     Epoch: 17
2023-01-04 02:03:31,288 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4589932292699814, 'Total loss': 0.4589932292699814} | train loss {'Reaction outcome loss': 0.330248056941635, 'Total loss': 0.330248056941635}
2023-01-04 02:03:31,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:31,288 INFO:     Epoch: 18
2023-01-04 02:03:32,890 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4158863931894302, 'Total loss': 0.4158863931894302} | train loss {'Reaction outcome loss': 0.3276183789138829, 'Total loss': 0.3276183789138829}
2023-01-04 02:03:32,890 INFO:     Found new best model at epoch 18
2023-01-04 02:03:32,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:32,891 INFO:     Epoch: 19
2023-01-04 02:03:34,488 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43595967690149945, 'Total loss': 0.43595967690149945} | train loss {'Reaction outcome loss': 0.32005652962695985, 'Total loss': 0.32005652962695985}
2023-01-04 02:03:34,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:34,488 INFO:     Epoch: 20
2023-01-04 02:03:36,062 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4339354852835337, 'Total loss': 0.4339354852835337} | train loss {'Reaction outcome loss': 0.3151750312674613, 'Total loss': 0.3151750312674613}
2023-01-04 02:03:36,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:36,063 INFO:     Epoch: 21
2023-01-04 02:03:37,631 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4262553870677948, 'Total loss': 0.4262553870677948} | train loss {'Reaction outcome loss': 0.310675248449102, 'Total loss': 0.310675248449102}
2023-01-04 02:03:37,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:37,632 INFO:     Epoch: 22
2023-01-04 02:03:39,233 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4485363225142161, 'Total loss': 0.4485363225142161} | train loss {'Reaction outcome loss': 0.30353019970568107, 'Total loss': 0.30353019970568107}
2023-01-04 02:03:39,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:39,234 INFO:     Epoch: 23
2023-01-04 02:03:40,840 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41586099565029144, 'Total loss': 0.41586099565029144} | train loss {'Reaction outcome loss': 0.2984914944913143, 'Total loss': 0.2984914944913143}
2023-01-04 02:03:40,840 INFO:     Found new best model at epoch 23
2023-01-04 02:03:40,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:40,841 INFO:     Epoch: 24
2023-01-04 02:03:42,443 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4222586880127589, 'Total loss': 0.4222586880127589} | train loss {'Reaction outcome loss': 0.2938221818170486, 'Total loss': 0.2938221818170486}
2023-01-04 02:03:42,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:42,443 INFO:     Epoch: 25
2023-01-04 02:03:44,039 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4319747984409332, 'Total loss': 0.4319747984409332} | train loss {'Reaction outcome loss': 0.29047978966882376, 'Total loss': 0.29047978966882376}
2023-01-04 02:03:44,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:44,039 INFO:     Epoch: 26
2023-01-04 02:03:45,627 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42335513134797415, 'Total loss': 0.42335513134797415} | train loss {'Reaction outcome loss': 0.2858353465004063, 'Total loss': 0.2858353465004063}
2023-01-04 02:03:45,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:45,627 INFO:     Epoch: 27
2023-01-04 02:03:47,200 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4081550478935242, 'Total loss': 0.4081550478935242} | train loss {'Reaction outcome loss': 0.2816715798043943, 'Total loss': 0.2816715798043943}
2023-01-04 02:03:47,200 INFO:     Found new best model at epoch 27
2023-01-04 02:03:47,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:47,201 INFO:     Epoch: 28
2023-01-04 02:03:48,804 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4022775153319041, 'Total loss': 0.4022775153319041} | train loss {'Reaction outcome loss': 0.279065103102953, 'Total loss': 0.279065103102953}
2023-01-04 02:03:48,805 INFO:     Found new best model at epoch 28
2023-01-04 02:03:48,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:48,806 INFO:     Epoch: 29
2023-01-04 02:03:50,401 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4214390436808268, 'Total loss': 0.4214390436808268} | train loss {'Reaction outcome loss': 0.27564346303160375, 'Total loss': 0.27564346303160375}
2023-01-04 02:03:50,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:50,402 INFO:     Epoch: 30
2023-01-04 02:03:52,002 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4162220964829127, 'Total loss': 0.4162220964829127} | train loss {'Reaction outcome loss': 0.26987156230997256, 'Total loss': 0.26987156230997256}
2023-01-04 02:03:52,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:52,003 INFO:     Epoch: 31
2023-01-04 02:03:53,578 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4070141543944677, 'Total loss': 0.4070141543944677} | train loss {'Reaction outcome loss': 0.2679255090844937, 'Total loss': 0.2679255090844937}
2023-01-04 02:03:53,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:53,578 INFO:     Epoch: 32
2023-01-04 02:03:55,219 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4181898484627406, 'Total loss': 0.4181898484627406} | train loss {'Reaction outcome loss': 0.26468715768976087, 'Total loss': 0.26468715768976087}
2023-01-04 02:03:55,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:55,219 INFO:     Epoch: 33
2023-01-04 02:03:56,817 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39980809191862743, 'Total loss': 0.39980809191862743} | train loss {'Reaction outcome loss': 0.2645017637328787, 'Total loss': 0.2645017637328787}
2023-01-04 02:03:56,818 INFO:     Found new best model at epoch 33
2023-01-04 02:03:56,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:56,818 INFO:     Epoch: 34
2023-01-04 02:03:58,423 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4290473977724711, 'Total loss': 0.4290473977724711} | train loss {'Reaction outcome loss': 0.2594880185775704, 'Total loss': 0.2594880185775704}
2023-01-04 02:03:58,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:03:58,423 INFO:     Epoch: 35
2023-01-04 02:04:00,004 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40931627750396726, 'Total loss': 0.40931627750396726} | train loss {'Reaction outcome loss': 0.2584552316220252, 'Total loss': 0.2584552316220252}
2023-01-04 02:04:00,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:00,005 INFO:     Epoch: 36
2023-01-04 02:04:01,582 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4362579802672068, 'Total loss': 0.4362579802672068} | train loss {'Reaction outcome loss': 0.252909544729133, 'Total loss': 0.252909544729133}
2023-01-04 02:04:01,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:01,582 INFO:     Epoch: 37
2023-01-04 02:04:03,210 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4015224099159241, 'Total loss': 0.4015224099159241} | train loss {'Reaction outcome loss': 0.24912507814310847, 'Total loss': 0.24912507814310847}
2023-01-04 02:04:03,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:03,210 INFO:     Epoch: 38
2023-01-04 02:04:04,831 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4187249968449275, 'Total loss': 0.4187249968449275} | train loss {'Reaction outcome loss': 0.24482027291159927, 'Total loss': 0.24482027291159927}
2023-01-04 02:04:04,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:04,832 INFO:     Epoch: 39
2023-01-04 02:04:06,407 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.422791247566541, 'Total loss': 0.422791247566541} | train loss {'Reaction outcome loss': 0.24502524913667323, 'Total loss': 0.24502524913667323}
2023-01-04 02:04:06,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:06,409 INFO:     Epoch: 40
2023-01-04 02:04:07,983 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4058108121156693, 'Total loss': 0.4058108121156693} | train loss {'Reaction outcome loss': 0.2446535234322478, 'Total loss': 0.2446535234322478}
2023-01-04 02:04:07,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:07,983 INFO:     Epoch: 41
2023-01-04 02:04:09,587 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4194085121154785, 'Total loss': 0.4194085121154785} | train loss {'Reaction outcome loss': 0.2407509405097682, 'Total loss': 0.2407509405097682}
2023-01-04 02:04:09,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:09,587 INFO:     Epoch: 42
2023-01-04 02:04:11,169 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4210251341263453, 'Total loss': 0.4210251341263453} | train loss {'Reaction outcome loss': 0.23644575441167467, 'Total loss': 0.23644575441167467}
2023-01-04 02:04:11,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:11,169 INFO:     Epoch: 43
2023-01-04 02:04:12,743 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3972827504078547, 'Total loss': 0.3972827504078547} | train loss {'Reaction outcome loss': 0.23675408117445834, 'Total loss': 0.23675408117445834}
2023-01-04 02:04:12,744 INFO:     Found new best model at epoch 43
2023-01-04 02:04:12,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:12,745 INFO:     Epoch: 44
2023-01-04 02:04:14,320 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4010524978240331, 'Total loss': 0.4010524978240331} | train loss {'Reaction outcome loss': 0.23233701845446786, 'Total loss': 0.23233701845446786}
2023-01-04 02:04:14,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:14,321 INFO:     Epoch: 45
2023-01-04 02:04:15,916 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4057656188805898, 'Total loss': 0.4057656188805898} | train loss {'Reaction outcome loss': 0.2324023193819619, 'Total loss': 0.2324023193819619}
2023-01-04 02:04:15,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:15,916 INFO:     Epoch: 46
2023-01-04 02:04:17,493 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40009756485621134, 'Total loss': 0.40009756485621134} | train loss {'Reaction outcome loss': 0.22836806634679818, 'Total loss': 0.22836806634679818}
2023-01-04 02:04:17,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:17,494 INFO:     Epoch: 47
2023-01-04 02:04:19,108 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40538599093755084, 'Total loss': 0.40538599093755084} | train loss {'Reaction outcome loss': 0.22540338943292806, 'Total loss': 0.22540338943292806}
2023-01-04 02:04:19,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:19,108 INFO:     Epoch: 48
2023-01-04 02:04:20,702 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4091489394505819, 'Total loss': 0.4091489394505819} | train loss {'Reaction outcome loss': 0.22244082080138908, 'Total loss': 0.22244082080138908}
2023-01-04 02:04:20,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:20,702 INFO:     Epoch: 49
2023-01-04 02:04:22,274 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40894232044617335, 'Total loss': 0.40894232044617335} | train loss {'Reaction outcome loss': 0.22192795830522918, 'Total loss': 0.22192795830522918}
2023-01-04 02:04:22,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:22,275 INFO:     Epoch: 50
2023-01-04 02:04:23,843 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39959982633590696, 'Total loss': 0.39959982633590696} | train loss {'Reaction outcome loss': 0.2204746383177492, 'Total loss': 0.2204746383177492}
2023-01-04 02:04:23,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:23,843 INFO:     Epoch: 51
2023-01-04 02:04:25,439 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3768569419781367, 'Total loss': 0.3768569419781367} | train loss {'Reaction outcome loss': 0.21802142937923527, 'Total loss': 0.21802142937923527}
2023-01-04 02:04:25,439 INFO:     Found new best model at epoch 51
2023-01-04 02:04:25,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:25,440 INFO:     Epoch: 52
2023-01-04 02:04:27,024 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40571073492368065, 'Total loss': 0.40571073492368065} | train loss {'Reaction outcome loss': 0.21401597572756664, 'Total loss': 0.21401597572756664}
2023-01-04 02:04:27,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:27,024 INFO:     Epoch: 53
2023-01-04 02:04:28,615 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40290767351786294, 'Total loss': 0.40290767351786294} | train loss {'Reaction outcome loss': 0.21285966297973208, 'Total loss': 0.21285966297973208}
2023-01-04 02:04:28,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:28,615 INFO:     Epoch: 54
2023-01-04 02:04:30,200 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3725341329971949, 'Total loss': 0.3725341329971949} | train loss {'Reaction outcome loss': 0.21136716507620865, 'Total loss': 0.21136716507620865}
2023-01-04 02:04:30,201 INFO:     Found new best model at epoch 54
2023-01-04 02:04:30,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:30,201 INFO:     Epoch: 55
2023-01-04 02:04:31,790 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4260683168967565, 'Total loss': 0.4260683168967565} | train loss {'Reaction outcome loss': 0.2109204584889578, 'Total loss': 0.2109204584889578}
2023-01-04 02:04:31,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:31,790 INFO:     Epoch: 56
2023-01-04 02:04:33,385 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4205299993356069, 'Total loss': 0.4205299993356069} | train loss {'Reaction outcome loss': 0.21071801507238286, 'Total loss': 0.21071801507238286}
2023-01-04 02:04:33,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:33,385 INFO:     Epoch: 57
2023-01-04 02:04:34,980 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38224133253097536, 'Total loss': 0.38224133253097536} | train loss {'Reaction outcome loss': 0.20523922892556878, 'Total loss': 0.20523922892556878}
2023-01-04 02:04:34,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:34,980 INFO:     Epoch: 58
2023-01-04 02:04:36,586 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38607359627882637, 'Total loss': 0.38607359627882637} | train loss {'Reaction outcome loss': 0.20511140009804524, 'Total loss': 0.20511140009804524}
2023-01-04 02:04:36,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:36,586 INFO:     Epoch: 59
2023-01-04 02:04:38,191 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4059126302599907, 'Total loss': 0.4059126302599907} | train loss {'Reaction outcome loss': 0.20310540892688672, 'Total loss': 0.20310540892688672}
2023-01-04 02:04:38,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:38,191 INFO:     Epoch: 60
2023-01-04 02:04:39,777 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3962260693311691, 'Total loss': 0.3962260693311691} | train loss {'Reaction outcome loss': 0.20422668355916226, 'Total loss': 0.20422668355916226}
2023-01-04 02:04:39,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:39,777 INFO:     Epoch: 61
2023-01-04 02:04:41,116 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3771930992603302, 'Total loss': 0.3771930992603302} | train loss {'Reaction outcome loss': 0.20127688104034344, 'Total loss': 0.20127688104034344}
2023-01-04 02:04:41,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:41,116 INFO:     Epoch: 62
2023-01-04 02:04:42,179 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38415097296237943, 'Total loss': 0.38415097296237943} | train loss {'Reaction outcome loss': 0.19866458802814885, 'Total loss': 0.19866458802814885}
2023-01-04 02:04:42,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:42,180 INFO:     Epoch: 63
2023-01-04 02:04:43,228 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4052133361498515, 'Total loss': 0.4052133361498515} | train loss {'Reaction outcome loss': 0.19717146660927887, 'Total loss': 0.19717146660927887}
2023-01-04 02:04:43,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:43,229 INFO:     Epoch: 64
2023-01-04 02:04:44,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37993696331977844, 'Total loss': 0.37993696331977844} | train loss {'Reaction outcome loss': 0.19803106159120185, 'Total loss': 0.19803106159120185}
2023-01-04 02:04:44,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:44,269 INFO:     Epoch: 65
2023-01-04 02:04:45,376 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39021439452966056, 'Total loss': 0.39021439452966056} | train loss {'Reaction outcome loss': 0.19326984709053685, 'Total loss': 0.19326984709053685}
2023-01-04 02:04:45,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:45,376 INFO:     Epoch: 66
2023-01-04 02:04:46,947 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.397563906510671, 'Total loss': 0.397563906510671} | train loss {'Reaction outcome loss': 0.19131479220487854, 'Total loss': 0.19131479220487854}
2023-01-04 02:04:46,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:46,947 INFO:     Epoch: 67
2023-01-04 02:04:48,547 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40405281335115434, 'Total loss': 0.40405281335115434} | train loss {'Reaction outcome loss': 0.19026220976050956, 'Total loss': 0.19026220976050956}
2023-01-04 02:04:48,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:48,548 INFO:     Epoch: 68
2023-01-04 02:04:50,143 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40655669073263806, 'Total loss': 0.40655669073263806} | train loss {'Reaction outcome loss': 0.19370122157692254, 'Total loss': 0.19370122157692254}
2023-01-04 02:04:50,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:50,143 INFO:     Epoch: 69
2023-01-04 02:04:51,743 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42092993557453157, 'Total loss': 0.42092993557453157} | train loss {'Reaction outcome loss': 0.1925451455999425, 'Total loss': 0.1925451455999425}
2023-01-04 02:04:51,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:51,743 INFO:     Epoch: 70
2023-01-04 02:04:53,343 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3943171550830205, 'Total loss': 0.3943171550830205} | train loss {'Reaction outcome loss': 0.19117511596680778, 'Total loss': 0.19117511596680778}
2023-01-04 02:04:53,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:53,344 INFO:     Epoch: 71
2023-01-04 02:04:54,906 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3935438245534897, 'Total loss': 0.3935438245534897} | train loss {'Reaction outcome loss': 0.19152756002578106, 'Total loss': 0.19152756002578106}
2023-01-04 02:04:54,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:54,906 INFO:     Epoch: 72
2023-01-04 02:04:56,507 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3931433781981468, 'Total loss': 0.3931433781981468} | train loss {'Reaction outcome loss': 0.18504931330135016, 'Total loss': 0.18504931330135016}
2023-01-04 02:04:56,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:56,508 INFO:     Epoch: 73
2023-01-04 02:04:58,098 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.405437367161115, 'Total loss': 0.405437367161115} | train loss {'Reaction outcome loss': 0.18983058363281108, 'Total loss': 0.18983058363281108}
2023-01-04 02:04:58,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:58,098 INFO:     Epoch: 74
2023-01-04 02:04:59,684 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40583444635073346, 'Total loss': 0.40583444635073346} | train loss {'Reaction outcome loss': 0.18814990932169634, 'Total loss': 0.18814990932169634}
2023-01-04 02:04:59,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:04:59,684 INFO:     Epoch: 75
2023-01-04 02:05:01,284 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3832157035668691, 'Total loss': 0.3832157035668691} | train loss {'Reaction outcome loss': 0.184120298851104, 'Total loss': 0.184120298851104}
2023-01-04 02:05:01,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:01,285 INFO:     Epoch: 76
2023-01-04 02:05:02,881 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40001123944918315, 'Total loss': 0.40001123944918315} | train loss {'Reaction outcome loss': 0.1821587761956175, 'Total loss': 0.1821587761956175}
2023-01-04 02:05:02,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:02,882 INFO:     Epoch: 77
2023-01-04 02:05:04,447 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37616783479849497, 'Total loss': 0.37616783479849497} | train loss {'Reaction outcome loss': 0.18167173923863159, 'Total loss': 0.18167173923863159}
2023-01-04 02:05:04,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:04,447 INFO:     Epoch: 78
2023-01-04 02:05:06,043 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41030392746130623, 'Total loss': 0.41030392746130623} | train loss {'Reaction outcome loss': 0.18269452939130665, 'Total loss': 0.18269452939130665}
2023-01-04 02:05:06,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:06,044 INFO:     Epoch: 79
2023-01-04 02:05:07,633 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40793693164984385, 'Total loss': 0.40793693164984385} | train loss {'Reaction outcome loss': 0.18180560591483946, 'Total loss': 0.18180560591483946}
2023-01-04 02:05:07,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:07,634 INFO:     Epoch: 80
2023-01-04 02:05:09,237 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4220366065700849, 'Total loss': 0.4220366065700849} | train loss {'Reaction outcome loss': 0.18218167456064796, 'Total loss': 0.18218167456064796}
2023-01-04 02:05:09,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:09,237 INFO:     Epoch: 81
2023-01-04 02:05:10,834 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38214809050162635, 'Total loss': 0.38214809050162635} | train loss {'Reaction outcome loss': 0.17824958476336886, 'Total loss': 0.17824958476336886}
2023-01-04 02:05:10,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:10,835 INFO:     Epoch: 82
2023-01-04 02:05:12,405 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4248692909876505, 'Total loss': 0.4248692909876505} | train loss {'Reaction outcome loss': 0.17589857557536046, 'Total loss': 0.17589857557536046}
2023-01-04 02:05:12,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:12,406 INFO:     Epoch: 83
2023-01-04 02:05:13,972 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3989732185999552, 'Total loss': 0.3989732185999552} | train loss {'Reaction outcome loss': 0.17555312554423624, 'Total loss': 0.17555312554423624}
2023-01-04 02:05:13,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:13,972 INFO:     Epoch: 84
2023-01-04 02:05:15,576 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37367364168167116, 'Total loss': 0.37367364168167116} | train loss {'Reaction outcome loss': 0.17586846787468854, 'Total loss': 0.17586846787468854}
2023-01-04 02:05:15,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:15,577 INFO:     Epoch: 85
2023-01-04 02:05:17,178 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4264835735162099, 'Total loss': 0.4264835735162099} | train loss {'Reaction outcome loss': 0.17733189244259953, 'Total loss': 0.17733189244259953}
2023-01-04 02:05:17,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:17,179 INFO:     Epoch: 86
2023-01-04 02:05:18,760 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4091447591781616, 'Total loss': 0.4091447591781616} | train loss {'Reaction outcome loss': 0.1760528971073934, 'Total loss': 0.1760528971073934}
2023-01-04 02:05:18,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:18,760 INFO:     Epoch: 87
2023-01-04 02:05:20,367 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41005326906840006, 'Total loss': 0.41005326906840006} | train loss {'Reaction outcome loss': 0.17467617850082043, 'Total loss': 0.17467617850082043}
2023-01-04 02:05:20,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:20,367 INFO:     Epoch: 88
2023-01-04 02:05:21,918 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39948439598083496, 'Total loss': 0.39948439598083496} | train loss {'Reaction outcome loss': 0.17350383225279167, 'Total loss': 0.17350383225279167}
2023-01-04 02:05:21,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:21,918 INFO:     Epoch: 89
2023-01-04 02:05:23,520 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39136789987484616, 'Total loss': 0.39136789987484616} | train loss {'Reaction outcome loss': 0.17367344961634704, 'Total loss': 0.17367344961634704}
2023-01-04 02:05:23,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:23,521 INFO:     Epoch: 90
2023-01-04 02:05:25,123 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43437071740627287, 'Total loss': 0.43437071740627287} | train loss {'Reaction outcome loss': 0.17335860093461944, 'Total loss': 0.17335860093461944}
2023-01-04 02:05:25,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:25,123 INFO:     Epoch: 91
2023-01-04 02:05:26,732 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3965636824568113, 'Total loss': 0.3965636824568113} | train loss {'Reaction outcome loss': 0.17180399516181194, 'Total loss': 0.17180399516181194}
2023-01-04 02:05:26,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:26,732 INFO:     Epoch: 92
2023-01-04 02:05:28,303 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39544191559155784, 'Total loss': 0.39544191559155784} | train loss {'Reaction outcome loss': 0.1709441212534686, 'Total loss': 0.1709441212534686}
2023-01-04 02:05:28,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:28,303 INFO:     Epoch: 93
2023-01-04 02:05:29,904 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41444812615712484, 'Total loss': 0.41444812615712484} | train loss {'Reaction outcome loss': 0.17016795227788525, 'Total loss': 0.17016795227788525}
2023-01-04 02:05:29,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:29,904 INFO:     Epoch: 94
2023-01-04 02:05:31,449 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.417822136481603, 'Total loss': 0.417822136481603} | train loss {'Reaction outcome loss': 0.16758754399124082, 'Total loss': 0.16758754399124082}
2023-01-04 02:05:31,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:31,449 INFO:     Epoch: 95
2023-01-04 02:05:33,024 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38848732858896257, 'Total loss': 0.38848732858896257} | train loss {'Reaction outcome loss': 0.17253054763043757, 'Total loss': 0.17253054763043757}
2023-01-04 02:05:33,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:33,024 INFO:     Epoch: 96
2023-01-04 02:05:34,599 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44726616342862446, 'Total loss': 0.44726616342862446} | train loss {'Reaction outcome loss': 0.17048973046352356, 'Total loss': 0.17048973046352356}
2023-01-04 02:05:34,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:34,599 INFO:     Epoch: 97
2023-01-04 02:05:36,174 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41457254191239673, 'Total loss': 0.41457254191239673} | train loss {'Reaction outcome loss': 0.17254819928398935, 'Total loss': 0.17254819928398935}
2023-01-04 02:05:36,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:36,174 INFO:     Epoch: 98
2023-01-04 02:05:37,748 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3969281494617462, 'Total loss': 0.3969281494617462} | train loss {'Reaction outcome loss': 0.1685203632455824, 'Total loss': 0.1685203632455824}
2023-01-04 02:05:37,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:37,748 INFO:     Epoch: 99
2023-01-04 02:05:39,297 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41476017236709595, 'Total loss': 0.41476017236709595} | train loss {'Reaction outcome loss': 0.164197940526073, 'Total loss': 0.164197940526073}
2023-01-04 02:05:39,297 INFO:     Best model found after epoch 55 of 100.
2023-01-04 02:05:39,297 INFO:   Done with stage: TRAINING
2023-01-04 02:05:39,297 INFO:   Starting stage: EVALUATION
2023-01-04 02:05:39,437 INFO:   Done with stage: EVALUATION
2023-01-04 02:05:39,437 INFO:   Leaving out SEQ value Fold_1
2023-01-04 02:05:39,450 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:05:39,450 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:05:40,094 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:05:40,094 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:05:40,164 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:05:40,164 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:05:40,164 INFO:     No hyperparam tuning for this model
2023-01-04 02:05:40,164 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:05:40,164 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:05:40,165 INFO:     None feature selector for col prot
2023-01-04 02:05:40,165 INFO:     None feature selector for col prot
2023-01-04 02:05:40,165 INFO:     None feature selector for col prot
2023-01-04 02:05:40,165 INFO:     None feature selector for col chem
2023-01-04 02:05:40,166 INFO:     None feature selector for col chem
2023-01-04 02:05:40,166 INFO:     None feature selector for col chem
2023-01-04 02:05:40,166 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:05:40,166 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:05:40,167 INFO:     Number of params in model 70141
2023-01-04 02:05:40,170 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:05:40,170 INFO:   Starting stage: TRAINING
2023-01-04 02:05:40,214 INFO:     Val loss before train {'Reaction outcome loss': 1.0769025643666585, 'Total loss': 1.0769025643666585}
2023-01-04 02:05:40,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:40,214 INFO:     Epoch: 0
2023-01-04 02:05:41,825 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.769967516263326, 'Total loss': 0.769967516263326} | train loss {'Reaction outcome loss': 0.8509144316407016, 'Total loss': 0.8509144316407016}
2023-01-04 02:05:41,826 INFO:     Found new best model at epoch 0
2023-01-04 02:05:41,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:41,826 INFO:     Epoch: 1
2023-01-04 02:05:43,440 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6239465117454529, 'Total loss': 0.6239465117454529} | train loss {'Reaction outcome loss': 0.6086121063380345, 'Total loss': 0.6086121063380345}
2023-01-04 02:05:43,441 INFO:     Found new best model at epoch 1
2023-01-04 02:05:43,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:43,442 INFO:     Epoch: 2
2023-01-04 02:05:45,055 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5670323550701142, 'Total loss': 0.5670323550701142} | train loss {'Reaction outcome loss': 0.5337374208726152, 'Total loss': 0.5337374208726152}
2023-01-04 02:05:45,055 INFO:     Found new best model at epoch 2
2023-01-04 02:05:45,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:45,056 INFO:     Epoch: 3
2023-01-04 02:05:46,666 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5366312742233277, 'Total loss': 0.5366312742233277} | train loss {'Reaction outcome loss': 0.49399348212419636, 'Total loss': 0.49399348212419636}
2023-01-04 02:05:46,666 INFO:     Found new best model at epoch 3
2023-01-04 02:05:46,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:46,667 INFO:     Epoch: 4
2023-01-04 02:05:48,225 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5022517025470734, 'Total loss': 0.5022517025470734} | train loss {'Reaction outcome loss': 0.4629661357098252, 'Total loss': 0.4629661357098252}
2023-01-04 02:05:48,225 INFO:     Found new best model at epoch 4
2023-01-04 02:05:48,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:48,226 INFO:     Epoch: 5
2023-01-04 02:05:49,794 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5168898423512777, 'Total loss': 0.5168898423512777} | train loss {'Reaction outcome loss': 0.44518445029746007, 'Total loss': 0.44518445029746007}
2023-01-04 02:05:49,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:49,794 INFO:     Epoch: 6
2023-01-04 02:05:51,403 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5070677657922109, 'Total loss': 0.5070677657922109} | train loss {'Reaction outcome loss': 0.4254486816425393, 'Total loss': 0.4254486816425393}
2023-01-04 02:05:51,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:51,403 INFO:     Epoch: 7
2023-01-04 02:05:52,971 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4722553531328837, 'Total loss': 0.4722553531328837} | train loss {'Reaction outcome loss': 0.411834174916692, 'Total loss': 0.411834174916692}
2023-01-04 02:05:52,972 INFO:     Found new best model at epoch 7
2023-01-04 02:05:52,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:52,972 INFO:     Epoch: 8
2023-01-04 02:05:54,541 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47084638277689617, 'Total loss': 0.47084638277689617} | train loss {'Reaction outcome loss': 0.39890661036228614, 'Total loss': 0.39890661036228614}
2023-01-04 02:05:54,542 INFO:     Found new best model at epoch 8
2023-01-04 02:05:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:54,543 INFO:     Epoch: 9
2023-01-04 02:05:56,112 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48151235580444335, 'Total loss': 0.48151235580444335} | train loss {'Reaction outcome loss': 0.38679637885006674, 'Total loss': 0.38679637885006674}
2023-01-04 02:05:56,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:56,112 INFO:     Epoch: 10
2023-01-04 02:05:57,677 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4557210147380829, 'Total loss': 0.4557210147380829} | train loss {'Reaction outcome loss': 0.37677985345468906, 'Total loss': 0.37677985345468906}
2023-01-04 02:05:57,677 INFO:     Found new best model at epoch 10
2023-01-04 02:05:57,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:57,678 INFO:     Epoch: 11
2023-01-04 02:05:59,260 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4724748174349467, 'Total loss': 0.4724748174349467} | train loss {'Reaction outcome loss': 0.36793673536094434, 'Total loss': 0.36793673536094434}
2023-01-04 02:05:59,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:05:59,260 INFO:     Epoch: 12
2023-01-04 02:06:00,845 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46696066757043203, 'Total loss': 0.46696066757043203} | train loss {'Reaction outcome loss': 0.35818140428975553, 'Total loss': 0.35818140428975553}
2023-01-04 02:06:00,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:00,846 INFO:     Epoch: 13
2023-01-04 02:06:02,429 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46531779766082765, 'Total loss': 0.46531779766082765} | train loss {'Reaction outcome loss': 0.3506397017597282, 'Total loss': 0.3506397017597282}
2023-01-04 02:06:02,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:02,429 INFO:     Epoch: 14
2023-01-04 02:06:04,012 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4563360730806986, 'Total loss': 0.4563360730806986} | train loss {'Reaction outcome loss': 0.34596275825080647, 'Total loss': 0.34596275825080647}
2023-01-04 02:06:04,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:04,013 INFO:     Epoch: 15
2023-01-04 02:06:05,573 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4662485251824061, 'Total loss': 0.4662485251824061} | train loss {'Reaction outcome loss': 0.33898595133184517, 'Total loss': 0.33898595133184517}
2023-01-04 02:06:05,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:05,574 INFO:     Epoch: 16
2023-01-04 02:06:07,138 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4650466740131378, 'Total loss': 0.4650466740131378} | train loss {'Reaction outcome loss': 0.3303402768597551, 'Total loss': 0.3303402768597551}
2023-01-04 02:06:07,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:07,138 INFO:     Epoch: 17
2023-01-04 02:06:08,723 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4451531926790873, 'Total loss': 0.4451531926790873} | train loss {'Reaction outcome loss': 0.32158605379127236, 'Total loss': 0.32158605379127236}
2023-01-04 02:06:08,723 INFO:     Found new best model at epoch 17
2023-01-04 02:06:08,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:08,724 INFO:     Epoch: 18
2023-01-04 02:06:10,306 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4771540343761444, 'Total loss': 0.4771540343761444} | train loss {'Reaction outcome loss': 0.3168789806646587, 'Total loss': 0.3168789806646587}
2023-01-04 02:06:10,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:10,307 INFO:     Epoch: 19
2023-01-04 02:06:11,891 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4333160907030106, 'Total loss': 0.4333160907030106} | train loss {'Reaction outcome loss': 0.31325648113215054, 'Total loss': 0.31325648113215054}
2023-01-04 02:06:11,891 INFO:     Found new best model at epoch 19
2023-01-04 02:06:11,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:11,892 INFO:     Epoch: 20
2023-01-04 02:06:13,474 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4500844836235046, 'Total loss': 0.4500844836235046} | train loss {'Reaction outcome loss': 0.3079938143015887, 'Total loss': 0.3079938143015887}
2023-01-04 02:06:13,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:13,476 INFO:     Epoch: 21
2023-01-04 02:06:15,024 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4564448118209839, 'Total loss': 0.4564448118209839} | train loss {'Reaction outcome loss': 0.3021402598569428, 'Total loss': 0.3021402598569428}
2023-01-04 02:06:15,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:15,024 INFO:     Epoch: 22
2023-01-04 02:06:16,608 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46613370180130004, 'Total loss': 0.46613370180130004} | train loss {'Reaction outcome loss': 0.29883495753590206, 'Total loss': 0.29883495753590206}
2023-01-04 02:06:16,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:16,608 INFO:     Epoch: 23
2023-01-04 02:06:18,190 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45593360463778176, 'Total loss': 0.45593360463778176} | train loss {'Reaction outcome loss': 0.2932463507745823, 'Total loss': 0.2932463507745823}
2023-01-04 02:06:18,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:18,191 INFO:     Epoch: 24
2023-01-04 02:06:19,775 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44967679182688397, 'Total loss': 0.44967679182688397} | train loss {'Reaction outcome loss': 0.29002752171380675, 'Total loss': 0.29002752171380675}
2023-01-04 02:06:19,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:19,776 INFO:     Epoch: 25
2023-01-04 02:06:21,359 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46204856832822166, 'Total loss': 0.46204856832822166} | train loss {'Reaction outcome loss': 0.2846609747893836, 'Total loss': 0.2846609747893836}
2023-01-04 02:06:21,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:21,359 INFO:     Epoch: 26
2023-01-04 02:06:22,943 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4462413966655731, 'Total loss': 0.4462413966655731} | train loss {'Reaction outcome loss': 0.27951318854941937, 'Total loss': 0.27951318854941937}
2023-01-04 02:06:22,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:22,943 INFO:     Epoch: 27
2023-01-04 02:06:24,494 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.469592355688413, 'Total loss': 0.469592355688413} | train loss {'Reaction outcome loss': 0.2776622073384967, 'Total loss': 0.2776622073384967}
2023-01-04 02:06:24,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:24,494 INFO:     Epoch: 28
2023-01-04 02:06:26,078 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47322603861490886, 'Total loss': 0.47322603861490886} | train loss {'Reaction outcome loss': 0.27304786152757, 'Total loss': 0.27304786152757}
2023-01-04 02:06:26,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:26,079 INFO:     Epoch: 29
2023-01-04 02:06:27,689 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46503360867500304, 'Total loss': 0.46503360867500304} | train loss {'Reaction outcome loss': 0.26770877563496576, 'Total loss': 0.26770877563496576}
2023-01-04 02:06:27,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:27,689 INFO:     Epoch: 30
2023-01-04 02:06:29,311 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4795529743035634, 'Total loss': 0.4795529743035634} | train loss {'Reaction outcome loss': 0.26629924904691044, 'Total loss': 0.26629924904691044}
2023-01-04 02:06:29,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:29,312 INFO:     Epoch: 31
2023-01-04 02:06:30,930 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.472933167219162, 'Total loss': 0.472933167219162} | train loss {'Reaction outcome loss': 0.26545613400474954, 'Total loss': 0.26545613400474954}
2023-01-04 02:06:30,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:30,930 INFO:     Epoch: 32
2023-01-04 02:06:32,484 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47904273867607117, 'Total loss': 0.47904273867607117} | train loss {'Reaction outcome loss': 0.25783516956071784, 'Total loss': 0.25783516956071784}
2023-01-04 02:06:32,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:32,485 INFO:     Epoch: 33
2023-01-04 02:06:34,058 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4482104957103729, 'Total loss': 0.4482104957103729} | train loss {'Reaction outcome loss': 0.2575290301937039, 'Total loss': 0.2575290301937039}
2023-01-04 02:06:34,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:34,058 INFO:     Epoch: 34
2023-01-04 02:06:35,643 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4643348256746928, 'Total loss': 0.4643348256746928} | train loss {'Reaction outcome loss': 0.2540028546087063, 'Total loss': 0.2540028546087063}
2023-01-04 02:06:35,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:35,643 INFO:     Epoch: 35
2023-01-04 02:06:37,235 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4575150817632675, 'Total loss': 0.4575150817632675} | train loss {'Reaction outcome loss': 0.2544854952117605, 'Total loss': 0.2544854952117605}
2023-01-04 02:06:37,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:37,235 INFO:     Epoch: 36
2023-01-04 02:06:38,850 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45846235752105713, 'Total loss': 0.45846235752105713} | train loss {'Reaction outcome loss': 0.25205448046870477, 'Total loss': 0.25205448046870477}
2023-01-04 02:06:38,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:38,850 INFO:     Epoch: 37
2023-01-04 02:06:40,433 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4697287003199259, 'Total loss': 0.4697287003199259} | train loss {'Reaction outcome loss': 0.24635548133702173, 'Total loss': 0.24635548133702173}
2023-01-04 02:06:40,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:40,433 INFO:     Epoch: 38
2023-01-04 02:06:42,002 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4490135371685028, 'Total loss': 0.4490135371685028} | train loss {'Reaction outcome loss': 0.24427142979944275, 'Total loss': 0.24427142979944275}
2023-01-04 02:06:42,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:42,002 INFO:     Epoch: 39
2023-01-04 02:06:43,585 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.461511371533076, 'Total loss': 0.461511371533076} | train loss {'Reaction outcome loss': 0.24244536630754923, 'Total loss': 0.24244536630754923}
2023-01-04 02:06:43,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:43,585 INFO:     Epoch: 40
2023-01-04 02:06:45,170 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4716773231824239, 'Total loss': 0.4716773231824239} | train loss {'Reaction outcome loss': 0.2412415845251649, 'Total loss': 0.2412415845251649}
2023-01-04 02:06:45,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:45,170 INFO:     Epoch: 41
2023-01-04 02:06:46,749 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45397839744885765, 'Total loss': 0.45397839744885765} | train loss {'Reaction outcome loss': 0.23948065823719014, 'Total loss': 0.23948065823719014}
2023-01-04 02:06:46,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:46,749 INFO:     Epoch: 42
2023-01-04 02:06:48,359 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4899563322464625, 'Total loss': 0.4899563322464625} | train loss {'Reaction outcome loss': 0.238463704018806, 'Total loss': 0.238463704018806}
2023-01-04 02:06:48,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:48,360 INFO:     Epoch: 43
2023-01-04 02:06:49,967 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4828573574622472, 'Total loss': 0.4828573574622472} | train loss {'Reaction outcome loss': 0.23309334840652715, 'Total loss': 0.23309334840652715}
2023-01-04 02:06:49,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:49,967 INFO:     Epoch: 44
2023-01-04 02:06:51,499 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48794872164726255, 'Total loss': 0.48794872164726255} | train loss {'Reaction outcome loss': 0.2336730857780815, 'Total loss': 0.2336730857780815}
2023-01-04 02:06:51,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:51,499 INFO:     Epoch: 45
2023-01-04 02:06:53,067 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46885202527046205, 'Total loss': 0.46885202527046205} | train loss {'Reaction outcome loss': 0.22920981655917028, 'Total loss': 0.22920981655917028}
2023-01-04 02:06:53,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:53,067 INFO:     Epoch: 46
2023-01-04 02:06:54,676 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.466691263516744, 'Total loss': 0.466691263516744} | train loss {'Reaction outcome loss': 0.22808851500170946, 'Total loss': 0.22808851500170946}
2023-01-04 02:06:54,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:54,676 INFO:     Epoch: 47
2023-01-04 02:06:56,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47281347711881, 'Total loss': 0.47281347711881} | train loss {'Reaction outcome loss': 0.226764259193718, 'Total loss': 0.226764259193718}
2023-01-04 02:06:56,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:56,287 INFO:     Epoch: 48
2023-01-04 02:06:57,905 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49411361515522, 'Total loss': 0.49411361515522} | train loss {'Reaction outcome loss': 0.22352364595408422, 'Total loss': 0.22352364595408422}
2023-01-04 02:06:57,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:57,905 INFO:     Epoch: 49
2023-01-04 02:06:59,446 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4872004727522532, 'Total loss': 0.4872004727522532} | train loss {'Reaction outcome loss': 0.22334963296723626, 'Total loss': 0.22334963296723626}
2023-01-04 02:06:59,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:06:59,447 INFO:     Epoch: 50
2023-01-04 02:07:01,047 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49756860931714375, 'Total loss': 0.49756860931714375} | train loss {'Reaction outcome loss': 0.2203538670700832, 'Total loss': 0.2203538670700832}
2023-01-04 02:07:01,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:01,048 INFO:     Epoch: 51
2023-01-04 02:07:02,614 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4799586941798528, 'Total loss': 0.4799586941798528} | train loss {'Reaction outcome loss': 0.21934441228254434, 'Total loss': 0.21934441228254434}
2023-01-04 02:07:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:02,614 INFO:     Epoch: 52
2023-01-04 02:07:04,222 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4886193772157033, 'Total loss': 0.4886193772157033} | train loss {'Reaction outcome loss': 0.21867625354143388, 'Total loss': 0.21867625354143388}
2023-01-04 02:07:04,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:04,222 INFO:     Epoch: 53
2023-01-04 02:07:05,826 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5083602786064148, 'Total loss': 0.5083602786064148} | train loss {'Reaction outcome loss': 0.21791611947663073, 'Total loss': 0.21791611947663073}
2023-01-04 02:07:05,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:05,827 INFO:     Epoch: 54
2023-01-04 02:07:07,403 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4895874887704849, 'Total loss': 0.4895874887704849} | train loss {'Reaction outcome loss': 0.21244995509457848, 'Total loss': 0.21244995509457848}
2023-01-04 02:07:07,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:07,404 INFO:     Epoch: 55
2023-01-04 02:07:08,966 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4730624382694562, 'Total loss': 0.4730624382694562} | train loss {'Reaction outcome loss': 0.2135212675661501, 'Total loss': 0.2135212675661501}
2023-01-04 02:07:08,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:08,966 INFO:     Epoch: 56
2023-01-04 02:07:10,582 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.480125367641449, 'Total loss': 0.480125367641449} | train loss {'Reaction outcome loss': 0.21204626852524106, 'Total loss': 0.21204626852524106}
2023-01-04 02:07:10,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:10,582 INFO:     Epoch: 57
2023-01-04 02:07:12,174 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5015060663223266, 'Total loss': 0.5015060663223266} | train loss {'Reaction outcome loss': 0.20833968595486052, 'Total loss': 0.20833968595486052}
2023-01-04 02:07:12,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:12,174 INFO:     Epoch: 58
2023-01-04 02:07:13,800 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.485785851875941, 'Total loss': 0.485785851875941} | train loss {'Reaction outcome loss': 0.21105651454116306, 'Total loss': 0.21105651454116306}
2023-01-04 02:07:13,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:13,800 INFO:     Epoch: 59
2023-01-04 02:07:15,416 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5252144575119019, 'Total loss': 0.5252144575119019} | train loss {'Reaction outcome loss': 0.2056150802132422, 'Total loss': 0.2056150802132422}
2023-01-04 02:07:15,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:15,417 INFO:     Epoch: 60
2023-01-04 02:07:16,988 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49238289693991344, 'Total loss': 0.49238289693991344} | train loss {'Reaction outcome loss': 0.20548351525063932, 'Total loss': 0.20548351525063932}
2023-01-04 02:07:16,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:16,989 INFO:     Epoch: 61
2023-01-04 02:07:18,561 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.505083171526591, 'Total loss': 0.505083171526591} | train loss {'Reaction outcome loss': 0.20588174730838432, 'Total loss': 0.20588174730838432}
2023-01-04 02:07:18,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:18,562 INFO:     Epoch: 62
2023-01-04 02:07:20,159 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47353579600652057, 'Total loss': 0.47353579600652057} | train loss {'Reaction outcome loss': 0.2043491136418642, 'Total loss': 0.2043491136418642}
2023-01-04 02:07:20,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:20,160 INFO:     Epoch: 63
2023-01-04 02:07:21,723 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48953828612963357, 'Total loss': 0.48953828612963357} | train loss {'Reaction outcome loss': 0.20060347498523712, 'Total loss': 0.20060347498523712}
2023-01-04 02:07:21,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:21,723 INFO:     Epoch: 64
2023-01-04 02:07:23,334 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49886151154836017, 'Total loss': 0.49886151154836017} | train loss {'Reaction outcome loss': 0.20434006514286038, 'Total loss': 0.20434006514286038}
2023-01-04 02:07:23,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:23,334 INFO:     Epoch: 65
2023-01-04 02:07:24,933 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5389886041482289, 'Total loss': 0.5389886041482289} | train loss {'Reaction outcome loss': 0.19931653989003087, 'Total loss': 0.19931653989003087}
2023-01-04 02:07:24,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:24,933 INFO:     Epoch: 66
2023-01-04 02:07:26,486 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49395920485258105, 'Total loss': 0.49395920485258105} | train loss {'Reaction outcome loss': 0.19751277073782725, 'Total loss': 0.19751277073782725}
2023-01-04 02:07:26,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:26,486 INFO:     Epoch: 67
2023-01-04 02:07:28,070 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4892046461502711, 'Total loss': 0.4892046461502711} | train loss {'Reaction outcome loss': 0.19575837332021145, 'Total loss': 0.19575837332021145}
2023-01-04 02:07:28,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:28,070 INFO:     Epoch: 68
2023-01-04 02:07:29,653 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4911242663860321, 'Total loss': 0.4911242663860321} | train loss {'Reaction outcome loss': 0.1956629638159036, 'Total loss': 0.1956629638159036}
2023-01-04 02:07:29,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:29,653 INFO:     Epoch: 69
2023-01-04 02:07:31,236 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5191761940717697, 'Total loss': 0.5191761940717697} | train loss {'Reaction outcome loss': 0.19528355855957, 'Total loss': 0.19528355855957}
2023-01-04 02:07:31,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:31,236 INFO:     Epoch: 70
2023-01-04 02:07:32,820 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5012358069419861, 'Total loss': 0.5012358069419861} | train loss {'Reaction outcome loss': 0.192571120010349, 'Total loss': 0.192571120010349}
2023-01-04 02:07:32,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:32,820 INFO:     Epoch: 71
2023-01-04 02:07:34,405 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5015912771224975, 'Total loss': 0.5015912771224975} | train loss {'Reaction outcome loss': 0.18952524133135368, 'Total loss': 0.18952524133135368}
2023-01-04 02:07:34,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:34,405 INFO:     Epoch: 72
2023-01-04 02:07:35,956 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4883352098365625, 'Total loss': 0.4883352098365625} | train loss {'Reaction outcome loss': 0.19093799364012087, 'Total loss': 0.19093799364012087}
2023-01-04 02:07:35,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:35,957 INFO:     Epoch: 73
2023-01-04 02:07:37,556 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5107536286115646, 'Total loss': 0.5107536286115646} | train loss {'Reaction outcome loss': 0.19183402314075154, 'Total loss': 0.19183402314075154}
2023-01-04 02:07:37,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:37,557 INFO:     Epoch: 74
2023-01-04 02:07:39,169 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5273012816905975, 'Total loss': 0.5273012816905975} | train loss {'Reaction outcome loss': 0.19011613452657514, 'Total loss': 0.19011613452657514}
2023-01-04 02:07:39,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:39,169 INFO:     Epoch: 75
2023-01-04 02:07:40,780 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5182419319947561, 'Total loss': 0.5182419319947561} | train loss {'Reaction outcome loss': 0.1892965599812948, 'Total loss': 0.1892965599812948}
2023-01-04 02:07:40,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:40,780 INFO:     Epoch: 76
2023-01-04 02:07:42,392 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5203527381022771, 'Total loss': 0.5203527381022771} | train loss {'Reaction outcome loss': 0.18718581291826536, 'Total loss': 0.18718581291826536}
2023-01-04 02:07:42,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:42,392 INFO:     Epoch: 77
2023-01-04 02:07:43,989 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.504028594493866, 'Total loss': 0.504028594493866} | train loss {'Reaction outcome loss': 0.18701435414136108, 'Total loss': 0.18701435414136108}
2023-01-04 02:07:43,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:43,989 INFO:     Epoch: 78
2023-01-04 02:07:45,577 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5027579595645268, 'Total loss': 0.5027579595645268} | train loss {'Reaction outcome loss': 0.1858703935736396, 'Total loss': 0.1858703935736396}
2023-01-04 02:07:45,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:45,577 INFO:     Epoch: 79
2023-01-04 02:07:47,142 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5227722942829132, 'Total loss': 0.5227722942829132} | train loss {'Reaction outcome loss': 0.18476299595522838, 'Total loss': 0.18476299595522838}
2023-01-04 02:07:47,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:47,142 INFO:     Epoch: 80
2023-01-04 02:07:48,750 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5221320688724518, 'Total loss': 0.5221320688724518} | train loss {'Reaction outcome loss': 0.1846348723654982, 'Total loss': 0.1846348723654982}
2023-01-04 02:07:48,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:48,750 INFO:     Epoch: 81
2023-01-04 02:07:50,362 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4978922625382741, 'Total loss': 0.4978922625382741} | train loss {'Reaction outcome loss': 0.18596831987183676, 'Total loss': 0.18596831987183676}
2023-01-04 02:07:50,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:50,363 INFO:     Epoch: 82
2023-01-04 02:07:51,973 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5085636427005132, 'Total loss': 0.5085636427005132} | train loss {'Reaction outcome loss': 0.18349300491467227, 'Total loss': 0.18349300491467227}
2023-01-04 02:07:51,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:51,974 INFO:     Epoch: 83
2023-01-04 02:07:53,516 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4997824420531591, 'Total loss': 0.4997824420531591} | train loss {'Reaction outcome loss': 0.17896124973458094, 'Total loss': 0.17896124973458094}
2023-01-04 02:07:53,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:53,517 INFO:     Epoch: 84
2023-01-04 02:07:55,125 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5107373694578806, 'Total loss': 0.5107373694578806} | train loss {'Reaction outcome loss': 0.18082660532481695, 'Total loss': 0.18082660532481695}
2023-01-04 02:07:55,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:55,125 INFO:     Epoch: 85
2023-01-04 02:07:56,687 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5163452496131261, 'Total loss': 0.5163452496131261} | train loss {'Reaction outcome loss': 0.17903326152667512, 'Total loss': 0.17903326152667512}
2023-01-04 02:07:56,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:56,687 INFO:     Epoch: 86
2023-01-04 02:07:58,295 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5233373721440633, 'Total loss': 0.5233373721440633} | train loss {'Reaction outcome loss': 0.17858182277231321, 'Total loss': 0.17858182277231321}
2023-01-04 02:07:58,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:58,296 INFO:     Epoch: 87
2023-01-04 02:07:59,903 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5311630606651306, 'Total loss': 0.5311630606651306} | train loss {'Reaction outcome loss': 0.17881235502062054, 'Total loss': 0.17881235502062054}
2023-01-04 02:07:59,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:07:59,903 INFO:     Epoch: 88
2023-01-04 02:08:01,509 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5252395202716191, 'Total loss': 0.5252395202716191} | train loss {'Reaction outcome loss': 0.17759235026518794, 'Total loss': 0.17759235026518794}
2023-01-04 02:08:01,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:01,510 INFO:     Epoch: 89
2023-01-04 02:08:03,068 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.527213724454244, 'Total loss': 0.527213724454244} | train loss {'Reaction outcome loss': 0.17673254564377297, 'Total loss': 0.17673254564377297}
2023-01-04 02:08:03,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:03,068 INFO:     Epoch: 90
2023-01-04 02:08:04,646 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5332793335119883, 'Total loss': 0.5332793335119883} | train loss {'Reaction outcome loss': 0.17879965186227847, 'Total loss': 0.17879965186227847}
2023-01-04 02:08:04,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:04,646 INFO:     Epoch: 91
2023-01-04 02:08:06,221 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5423804084459941, 'Total loss': 0.5423804084459941} | train loss {'Reaction outcome loss': 0.17536688091600464, 'Total loss': 0.17536688091600464}
2023-01-04 02:08:06,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:06,222 INFO:     Epoch: 92
2023-01-04 02:08:07,792 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5304051756858825, 'Total loss': 0.5304051756858825} | train loss {'Reaction outcome loss': 0.17288128879383532, 'Total loss': 0.17288128879383532}
2023-01-04 02:08:07,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:07,792 INFO:     Epoch: 93
2023-01-04 02:08:09,365 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5130392293135325, 'Total loss': 0.5130392293135325} | train loss {'Reaction outcome loss': 0.17344043931386766, 'Total loss': 0.17344043931386766}
2023-01-04 02:08:09,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:09,365 INFO:     Epoch: 94
2023-01-04 02:08:10,919 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49046353499094647, 'Total loss': 0.49046353499094647} | train loss {'Reaction outcome loss': 0.176209332693341, 'Total loss': 0.176209332693341}
2023-01-04 02:08:10,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:10,920 INFO:     Epoch: 95
2023-01-04 02:08:12,478 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5139896959066391, 'Total loss': 0.5139896959066391} | train loss {'Reaction outcome loss': 0.17255234314523038, 'Total loss': 0.17255234314523038}
2023-01-04 02:08:12,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:12,479 INFO:     Epoch: 96
2023-01-04 02:08:14,086 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5465570489565531, 'Total loss': 0.5465570489565531} | train loss {'Reaction outcome loss': 0.17277490056670494, 'Total loss': 0.17277490056670494}
2023-01-04 02:08:14,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:14,086 INFO:     Epoch: 97
2023-01-04 02:08:15,659 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5146398425102234, 'Total loss': 0.5146398425102234} | train loss {'Reaction outcome loss': 0.17133749495974204, 'Total loss': 0.17133749495974204}
2023-01-04 02:08:15,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:15,659 INFO:     Epoch: 98
2023-01-04 02:08:17,230 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5212335367997487, 'Total loss': 0.5212335367997487} | train loss {'Reaction outcome loss': 0.17059435067276885, 'Total loss': 0.17059435067276885}
2023-01-04 02:08:17,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:17,230 INFO:     Epoch: 99
2023-01-04 02:08:18,839 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5086074908574422, 'Total loss': 0.5086074908574422} | train loss {'Reaction outcome loss': 0.17238772577558556, 'Total loss': 0.17238772577558556}
2023-01-04 02:08:18,839 INFO:     Best model found after epoch 20 of 100.
2023-01-04 02:08:18,839 INFO:   Done with stage: TRAINING
2023-01-04 02:08:18,839 INFO:   Starting stage: EVALUATION
2023-01-04 02:08:18,973 INFO:   Done with stage: EVALUATION
2023-01-04 02:08:18,973 INFO:   Leaving out SEQ value Fold_2
2023-01-04 02:08:18,985 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 02:08:18,986 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:08:19,631 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:08:19,631 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:08:19,700 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:08:19,700 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:08:19,700 INFO:     No hyperparam tuning for this model
2023-01-04 02:08:19,700 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:08:19,700 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:08:19,701 INFO:     None feature selector for col prot
2023-01-04 02:08:19,701 INFO:     None feature selector for col prot
2023-01-04 02:08:19,701 INFO:     None feature selector for col prot
2023-01-04 02:08:19,702 INFO:     None feature selector for col chem
2023-01-04 02:08:19,702 INFO:     None feature selector for col chem
2023-01-04 02:08:19,702 INFO:     None feature selector for col chem
2023-01-04 02:08:19,702 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:08:19,702 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:08:19,703 INFO:     Number of params in model 70141
2023-01-04 02:08:19,706 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:08:19,706 INFO:   Starting stage: TRAINING
2023-01-04 02:08:19,750 INFO:     Val loss before train {'Reaction outcome loss': 0.9952837785085042, 'Total loss': 0.9952837785085042}
2023-01-04 02:08:19,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:19,750 INFO:     Epoch: 0
2023-01-04 02:08:21,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6522067646185558, 'Total loss': 0.6522067646185558} | train loss {'Reaction outcome loss': 0.8332319247635293, 'Total loss': 0.8332319247635293}
2023-01-04 02:08:21,325 INFO:     Found new best model at epoch 0
2023-01-04 02:08:21,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:21,325 INFO:     Epoch: 1
2023-01-04 02:08:22,900 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.537818972269694, 'Total loss': 0.537818972269694} | train loss {'Reaction outcome loss': 0.5949718288449577, 'Total loss': 0.5949718288449577}
2023-01-04 02:08:22,900 INFO:     Found new best model at epoch 1
2023-01-04 02:08:22,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:22,901 INFO:     Epoch: 2
2023-01-04 02:08:24,476 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5226395010948182, 'Total loss': 0.5226395010948182} | train loss {'Reaction outcome loss': 0.5188331231747791, 'Total loss': 0.5188331231747791}
2023-01-04 02:08:24,476 INFO:     Found new best model at epoch 2
2023-01-04 02:08:24,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:24,477 INFO:     Epoch: 3
2023-01-04 02:08:26,050 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4749090939760208, 'Total loss': 0.4749090939760208} | train loss {'Reaction outcome loss': 0.47254390921784845, 'Total loss': 0.47254390921784845}
2023-01-04 02:08:26,051 INFO:     Found new best model at epoch 3
2023-01-04 02:08:26,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:26,052 INFO:     Epoch: 4
2023-01-04 02:08:27,649 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4537944515546163, 'Total loss': 0.4537944515546163} | train loss {'Reaction outcome loss': 0.44485247364410985, 'Total loss': 0.44485247364410985}
2023-01-04 02:08:27,649 INFO:     Found new best model at epoch 4
2023-01-04 02:08:27,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:27,650 INFO:     Epoch: 5
2023-01-04 02:08:29,190 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4494445562362671, 'Total loss': 0.4494445562362671} | train loss {'Reaction outcome loss': 0.42379992447056614, 'Total loss': 0.42379992447056614}
2023-01-04 02:08:29,190 INFO:     Found new best model at epoch 5
2023-01-04 02:08:29,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:29,191 INFO:     Epoch: 6
2023-01-04 02:08:30,765 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44163490533828736, 'Total loss': 0.44163490533828736} | train loss {'Reaction outcome loss': 0.40720250689503035, 'Total loss': 0.40720250689503035}
2023-01-04 02:08:30,765 INFO:     Found new best model at epoch 6
2023-01-04 02:08:30,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:30,766 INFO:     Epoch: 7
2023-01-04 02:08:32,341 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44367683827877047, 'Total loss': 0.44367683827877047} | train loss {'Reaction outcome loss': 0.39309232239867303, 'Total loss': 0.39309232239867303}
2023-01-04 02:08:32,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:32,341 INFO:     Epoch: 8
2023-01-04 02:08:33,915 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4595849057038625, 'Total loss': 0.4595849057038625} | train loss {'Reaction outcome loss': 0.3797332010480947, 'Total loss': 0.3797332010480947}
2023-01-04 02:08:33,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:33,915 INFO:     Epoch: 9
2023-01-04 02:08:35,490 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45072328945000967, 'Total loss': 0.45072328945000967} | train loss {'Reaction outcome loss': 0.3754554292112043, 'Total loss': 0.3754554292112043}
2023-01-04 02:08:35,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:35,491 INFO:     Epoch: 10
2023-01-04 02:08:37,062 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42897295753161113, 'Total loss': 0.42897295753161113} | train loss {'Reaction outcome loss': 0.3662490126960007, 'Total loss': 0.3662490126960007}
2023-01-04 02:08:37,062 INFO:     Found new best model at epoch 10
2023-01-04 02:08:37,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:37,063 INFO:     Epoch: 11
2023-01-04 02:08:38,603 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4481225887934367, 'Total loss': 0.4481225887934367} | train loss {'Reaction outcome loss': 0.3598861283871717, 'Total loss': 0.3598861283871717}
2023-01-04 02:08:38,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:38,603 INFO:     Epoch: 12
2023-01-04 02:08:40,208 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4353582839171092, 'Total loss': 0.4353582839171092} | train loss {'Reaction outcome loss': 0.35017361077087705, 'Total loss': 0.35017361077087705}
2023-01-04 02:08:40,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:40,208 INFO:     Epoch: 13
2023-01-04 02:08:41,810 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.445433767636617, 'Total loss': 0.445433767636617} | train loss {'Reaction outcome loss': 0.3435788212460039, 'Total loss': 0.3435788212460039}
2023-01-04 02:08:41,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:41,811 INFO:     Epoch: 14
2023-01-04 02:08:43,413 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41741362810134885, 'Total loss': 0.41741362810134885} | train loss {'Reaction outcome loss': 0.33696575124403494, 'Total loss': 0.33696575124403494}
2023-01-04 02:08:43,414 INFO:     Found new best model at epoch 14
2023-01-04 02:08:43,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:43,415 INFO:     Epoch: 15
2023-01-04 02:08:45,018 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4462577690680822, 'Total loss': 0.4462577690680822} | train loss {'Reaction outcome loss': 0.3298862245984567, 'Total loss': 0.3298862245984567}
2023-01-04 02:08:45,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:45,018 INFO:     Epoch: 16
2023-01-04 02:08:46,583 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43505289951960247, 'Total loss': 0.43505289951960247} | train loss {'Reaction outcome loss': 0.32298840820830277, 'Total loss': 0.32298840820830277}
2023-01-04 02:08:46,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:46,583 INFO:     Epoch: 17
2023-01-04 02:08:48,157 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41709558566411337, 'Total loss': 0.41709558566411337} | train loss {'Reaction outcome loss': 0.31640808786446356, 'Total loss': 0.31640808786446356}
2023-01-04 02:08:48,157 INFO:     Found new best model at epoch 17
2023-01-04 02:08:48,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:48,158 INFO:     Epoch: 18
2023-01-04 02:08:49,733 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4170684556166331, 'Total loss': 0.4170684556166331} | train loss {'Reaction outcome loss': 0.3133889450913384, 'Total loss': 0.3133889450913384}
2023-01-04 02:08:49,734 INFO:     Found new best model at epoch 18
2023-01-04 02:08:49,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:49,735 INFO:     Epoch: 19
2023-01-04 02:08:51,309 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42968058784802754, 'Total loss': 0.42968058784802754} | train loss {'Reaction outcome loss': 0.30804219465334337, 'Total loss': 0.30804219465334337}
2023-01-04 02:08:51,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:51,309 INFO:     Epoch: 20
2023-01-04 02:08:52,884 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43569695750872295, 'Total loss': 0.43569695750872295} | train loss {'Reaction outcome loss': 0.30214184328859106, 'Total loss': 0.30214184328859106}
2023-01-04 02:08:52,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:52,884 INFO:     Epoch: 21
2023-01-04 02:08:54,459 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4213966886202494, 'Total loss': 0.4213966886202494} | train loss {'Reaction outcome loss': 0.2980106505855318, 'Total loss': 0.2980106505855318}
2023-01-04 02:08:54,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:54,460 INFO:     Epoch: 22
2023-01-04 02:08:56,006 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43473437825838723, 'Total loss': 0.43473437825838723} | train loss {'Reaction outcome loss': 0.29265755313984204, 'Total loss': 0.29265755313984204}
2023-01-04 02:08:56,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:56,007 INFO:     Epoch: 23
2023-01-04 02:08:57,581 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4300554722547531, 'Total loss': 0.4300554722547531} | train loss {'Reaction outcome loss': 0.2865533026296905, 'Total loss': 0.2865533026296905}
2023-01-04 02:08:57,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:57,581 INFO:     Epoch: 24
2023-01-04 02:08:59,155 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42187892844279606, 'Total loss': 0.42187892844279606} | train loss {'Reaction outcome loss': 0.2824091960440625, 'Total loss': 0.2824091960440625}
2023-01-04 02:08:59,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:08:59,155 INFO:     Epoch: 25
2023-01-04 02:09:00,730 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43641013503074644, 'Total loss': 0.43641013503074644} | train loss {'Reaction outcome loss': 0.2792904373435747, 'Total loss': 0.2792904373435747}
2023-01-04 02:09:00,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:00,730 INFO:     Epoch: 26
2023-01-04 02:09:02,296 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41865161856015526, 'Total loss': 0.41865161856015526} | train loss {'Reaction outcome loss': 0.2753231955535246, 'Total loss': 0.2753231955535246}
2023-01-04 02:09:02,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:02,297 INFO:     Epoch: 27
2023-01-04 02:09:03,860 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41287788301706313, 'Total loss': 0.41287788301706313} | train loss {'Reaction outcome loss': 0.2726015982664985, 'Total loss': 0.2726015982664985}
2023-01-04 02:09:03,860 INFO:     Found new best model at epoch 27
2023-01-04 02:09:03,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:03,861 INFO:     Epoch: 28
2023-01-04 02:09:05,413 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42142816781997683, 'Total loss': 0.42142816781997683} | train loss {'Reaction outcome loss': 0.2693763445694368, 'Total loss': 0.2693763445694368}
2023-01-04 02:09:05,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:05,413 INFO:     Epoch: 29
2023-01-04 02:09:06,984 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4503878176212311, 'Total loss': 0.4503878176212311} | train loss {'Reaction outcome loss': 0.2638831913962469, 'Total loss': 0.2638831913962469}
2023-01-04 02:09:06,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:06,984 INFO:     Epoch: 30
2023-01-04 02:09:08,562 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4393959894776344, 'Total loss': 0.4393959894776344} | train loss {'Reaction outcome loss': 0.2656442806288436, 'Total loss': 0.2656442806288436}
2023-01-04 02:09:08,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:08,562 INFO:     Epoch: 31
2023-01-04 02:09:10,130 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38735774407784146, 'Total loss': 0.38735774407784146} | train loss {'Reaction outcome loss': 0.2563097324126806, 'Total loss': 0.2563097324126806}
2023-01-04 02:09:10,130 INFO:     Found new best model at epoch 31
2023-01-04 02:09:10,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:10,131 INFO:     Epoch: 32
2023-01-04 02:09:11,703 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41650493095318475, 'Total loss': 0.41650493095318475} | train loss {'Reaction outcome loss': 0.2560009438640032, 'Total loss': 0.2560009438640032}
2023-01-04 02:09:11,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:11,703 INFO:     Epoch: 33
2023-01-04 02:09:13,251 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42816014885902404, 'Total loss': 0.42816014885902404} | train loss {'Reaction outcome loss': 0.25071065253390495, 'Total loss': 0.25071065253390495}
2023-01-04 02:09:13,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:13,251 INFO:     Epoch: 34
2023-01-04 02:09:14,853 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4414363165696462, 'Total loss': 0.4414363165696462} | train loss {'Reaction outcome loss': 0.24833807682161366, 'Total loss': 0.24833807682161366}
2023-01-04 02:09:14,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:14,853 INFO:     Epoch: 35
2023-01-04 02:09:16,417 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42907265623410545, 'Total loss': 0.42907265623410545} | train loss {'Reaction outcome loss': 0.2462730260886552, 'Total loss': 0.2462730260886552}
2023-01-04 02:09:16,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:16,417 INFO:     Epoch: 36
2023-01-04 02:09:18,019 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4504346211751302, 'Total loss': 0.4504346211751302} | train loss {'Reaction outcome loss': 0.24290587422830281, 'Total loss': 0.24290587422830281}
2023-01-04 02:09:18,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:18,020 INFO:     Epoch: 37
2023-01-04 02:09:19,585 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4101496487855911, 'Total loss': 0.4101496487855911} | train loss {'Reaction outcome loss': 0.23889710534459505, 'Total loss': 0.23889710534459505}
2023-01-04 02:09:19,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:19,585 INFO:     Epoch: 38
2023-01-04 02:09:21,188 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4139345253507296, 'Total loss': 0.4139345253507296} | train loss {'Reaction outcome loss': 0.2379687421788008, 'Total loss': 0.2379687421788008}
2023-01-04 02:09:21,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:21,188 INFO:     Epoch: 39
2023-01-04 02:09:22,733 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4171423723300298, 'Total loss': 0.4171423723300298} | train loss {'Reaction outcome loss': 0.2328931138519839, 'Total loss': 0.2328931138519839}
2023-01-04 02:09:22,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:22,734 INFO:     Epoch: 40
2023-01-04 02:09:24,337 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44539959331353507, 'Total loss': 0.44539959331353507} | train loss {'Reaction outcome loss': 0.23188993566747987, 'Total loss': 0.23188993566747987}
2023-01-04 02:09:24,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:24,338 INFO:     Epoch: 41
2023-01-04 02:09:25,897 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4247240503629049, 'Total loss': 0.4247240503629049} | train loss {'Reaction outcome loss': 0.23151772014878608, 'Total loss': 0.23151772014878608}
2023-01-04 02:09:25,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:25,897 INFO:     Epoch: 42
2023-01-04 02:09:27,499 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43942630489667256, 'Total loss': 0.43942630489667256} | train loss {'Reaction outcome loss': 0.22663367104344753, 'Total loss': 0.22663367104344753}
2023-01-04 02:09:27,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:27,500 INFO:     Epoch: 43
2023-01-04 02:09:29,100 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42731965283552803, 'Total loss': 0.42731965283552803} | train loss {'Reaction outcome loss': 0.22567905974830246, 'Total loss': 0.22567905974830246}
2023-01-04 02:09:29,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:29,101 INFO:     Epoch: 44
2023-01-04 02:09:30,659 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4270526746908824, 'Total loss': 0.4270526746908824} | train loss {'Reaction outcome loss': 0.2215559286979665, 'Total loss': 0.2215559286979665}
2023-01-04 02:09:30,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:30,659 INFO:     Epoch: 45
2023-01-04 02:09:32,205 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42468057324488956, 'Total loss': 0.42468057324488956} | train loss {'Reaction outcome loss': 0.22164055369384997, 'Total loss': 0.22164055369384997}
2023-01-04 02:09:32,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:32,206 INFO:     Epoch: 46
2023-01-04 02:09:33,809 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41957271297772725, 'Total loss': 0.41957271297772725} | train loss {'Reaction outcome loss': 0.219788375436823, 'Total loss': 0.219788375436823}
2023-01-04 02:09:33,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:33,809 INFO:     Epoch: 47
2023-01-04 02:09:35,413 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4130522350470225, 'Total loss': 0.4130522350470225} | train loss {'Reaction outcome loss': 0.21511546194880873, 'Total loss': 0.21511546194880873}
2023-01-04 02:09:35,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:35,413 INFO:     Epoch: 48
2023-01-04 02:09:37,016 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4252954085667928, 'Total loss': 0.4252954085667928} | train loss {'Reaction outcome loss': 0.21397143886202857, 'Total loss': 0.21397143886202857}
2023-01-04 02:09:37,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:37,017 INFO:     Epoch: 49
2023-01-04 02:09:38,621 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4337264796098073, 'Total loss': 0.4337264796098073} | train loss {'Reaction outcome loss': 0.21402739921768943, 'Total loss': 0.21402739921768943}
2023-01-04 02:09:38,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:38,621 INFO:     Epoch: 50
2023-01-04 02:09:40,186 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.448366508881251, 'Total loss': 0.448366508881251} | train loss {'Reaction outcome loss': 0.21097126858302087, 'Total loss': 0.21097126858302087}
2023-01-04 02:09:40,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:40,187 INFO:     Epoch: 51
2023-01-04 02:09:41,759 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4630080203215281, 'Total loss': 0.4630080203215281} | train loss {'Reaction outcome loss': 0.20961194915267137, 'Total loss': 0.20961194915267137}
2023-01-04 02:09:41,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:41,759 INFO:     Epoch: 52
2023-01-04 02:09:43,331 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43979687690734864, 'Total loss': 0.43979687690734864} | train loss {'Reaction outcome loss': 0.20885423755771293, 'Total loss': 0.20885423755771293}
2023-01-04 02:09:43,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:43,331 INFO:     Epoch: 53
2023-01-04 02:09:44,903 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4301624983549118, 'Total loss': 0.4301624983549118} | train loss {'Reaction outcome loss': 0.20594141973462296, 'Total loss': 0.20594141973462296}
2023-01-04 02:09:44,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:44,903 INFO:     Epoch: 54
2023-01-04 02:09:46,475 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.409049898882707, 'Total loss': 0.409049898882707} | train loss {'Reaction outcome loss': 0.20479969219082877, 'Total loss': 0.20479969219082877}
2023-01-04 02:09:46,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:46,475 INFO:     Epoch: 55
2023-01-04 02:09:48,049 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4588714877764384, 'Total loss': 0.4588714877764384} | train loss {'Reaction outcome loss': 0.20514365181244992, 'Total loss': 0.20514365181244992}
2023-01-04 02:09:48,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:48,049 INFO:     Epoch: 56
2023-01-04 02:09:49,591 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43150274554888407, 'Total loss': 0.43150274554888407} | train loss {'Reaction outcome loss': 0.20307572691568307, 'Total loss': 0.20307572691568307}
2023-01-04 02:09:49,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:49,592 INFO:     Epoch: 57
2023-01-04 02:09:51,183 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42911300460497537, 'Total loss': 0.42911300460497537} | train loss {'Reaction outcome loss': 0.19887995921866797, 'Total loss': 0.19887995921866797}
2023-01-04 02:09:51,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:51,183 INFO:     Epoch: 58
2023-01-04 02:09:52,792 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45257613162199656, 'Total loss': 0.45257613162199656} | train loss {'Reaction outcome loss': 0.19937556755862065, 'Total loss': 0.19937556755862065}
2023-01-04 02:09:52,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:52,792 INFO:     Epoch: 59
2023-01-04 02:09:54,365 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46332357625166576, 'Total loss': 0.46332357625166576} | train loss {'Reaction outcome loss': 0.1978322525846434, 'Total loss': 0.1978322525846434}
2023-01-04 02:09:54,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:54,365 INFO:     Epoch: 60
2023-01-04 02:09:55,972 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47218454082806904, 'Total loss': 0.47218454082806904} | train loss {'Reaction outcome loss': 0.19773272456321525, 'Total loss': 0.19773272456321525}
2023-01-04 02:09:55,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:55,973 INFO:     Epoch: 61
2023-01-04 02:09:57,532 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4634731163581212, 'Total loss': 0.4634731163581212} | train loss {'Reaction outcome loss': 0.19681377294081034, 'Total loss': 0.19681377294081034}
2023-01-04 02:09:57,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:57,533 INFO:     Epoch: 62
2023-01-04 02:09:59,085 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4434318999449412, 'Total loss': 0.4434318999449412} | train loss {'Reaction outcome loss': 0.19482231378937379, 'Total loss': 0.19482231378937379}
2023-01-04 02:09:59,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:09:59,085 INFO:     Epoch: 63
2023-01-04 02:10:00,658 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4526897797981898, 'Total loss': 0.4526897797981898} | train loss {'Reaction outcome loss': 0.19263216443342795, 'Total loss': 0.19263216443342795}
2023-01-04 02:10:00,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:00,659 INFO:     Epoch: 64
2023-01-04 02:10:02,233 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4540308237075806, 'Total loss': 0.4540308237075806} | train loss {'Reaction outcome loss': 0.19122884339301577, 'Total loss': 0.19122884339301577}
2023-01-04 02:10:02,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:02,233 INFO:     Epoch: 65
2023-01-04 02:10:03,805 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4829296261072159, 'Total loss': 0.4829296261072159} | train loss {'Reaction outcome loss': 0.1902047567642652, 'Total loss': 0.1902047567642652}
2023-01-04 02:10:03,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:03,805 INFO:     Epoch: 66
2023-01-04 02:10:05,379 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.431851585706075, 'Total loss': 0.431851585706075} | train loss {'Reaction outcome loss': 0.18789180550355833, 'Total loss': 0.18789180550355833}
2023-01-04 02:10:05,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:05,379 INFO:     Epoch: 67
2023-01-04 02:10:06,832 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4710460404555003, 'Total loss': 0.4710460404555003} | train loss {'Reaction outcome loss': 0.18940981043564095, 'Total loss': 0.18940981043564095}
2023-01-04 02:10:06,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:06,833 INFO:     Epoch: 68
2023-01-04 02:10:07,882 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43859256903330485, 'Total loss': 0.43859256903330485} | train loss {'Reaction outcome loss': 0.1895041905425407, 'Total loss': 0.1895041905425407}
2023-01-04 02:10:07,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:07,883 INFO:     Epoch: 69
2023-01-04 02:10:08,925 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4648133784532547, 'Total loss': 0.4648133784532547} | train loss {'Reaction outcome loss': 0.18718069962365724, 'Total loss': 0.18718069962365724}
2023-01-04 02:10:08,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:08,926 INFO:     Epoch: 70
2023-01-04 02:10:09,965 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4657016654809316, 'Total loss': 0.4657016654809316} | train loss {'Reaction outcome loss': 0.18379060168078531, 'Total loss': 0.18379060168078531}
2023-01-04 02:10:09,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:09,966 INFO:     Epoch: 71
2023-01-04 02:10:11,149 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5021443923314413, 'Total loss': 0.5021443923314413} | train loss {'Reaction outcome loss': 0.18326026492584974, 'Total loss': 0.18326026492584974}
2023-01-04 02:10:11,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:11,149 INFO:     Epoch: 72
2023-01-04 02:10:12,714 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45974992712338764, 'Total loss': 0.45974992712338764} | train loss {'Reaction outcome loss': 0.18330601812937322, 'Total loss': 0.18330601812937322}
2023-01-04 02:10:12,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:12,714 INFO:     Epoch: 73
2023-01-04 02:10:14,287 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4363534040749073, 'Total loss': 0.4363534040749073} | train loss {'Reaction outcome loss': 0.18412217486226734, 'Total loss': 0.18412217486226734}
2023-01-04 02:10:14,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:14,287 INFO:     Epoch: 74
2023-01-04 02:10:15,877 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4439893774688244, 'Total loss': 0.4439893774688244} | train loss {'Reaction outcome loss': 0.18219678513296358, 'Total loss': 0.18219678513296358}
2023-01-04 02:10:15,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:15,877 INFO:     Epoch: 75
2023-01-04 02:10:17,468 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4408780266841253, 'Total loss': 0.4408780266841253} | train loss {'Reaction outcome loss': 0.17863678007690242, 'Total loss': 0.17863678007690242}
2023-01-04 02:10:17,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:17,468 INFO:     Epoch: 76
2023-01-04 02:10:19,075 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42810023923714957, 'Total loss': 0.42810023923714957} | train loss {'Reaction outcome loss': 0.17870830606682833, 'Total loss': 0.17870830606682833}
2023-01-04 02:10:19,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:19,075 INFO:     Epoch: 77
2023-01-04 02:10:20,661 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43395305971304576, 'Total loss': 0.43395305971304576} | train loss {'Reaction outcome loss': 0.17939720186831315, 'Total loss': 0.17939720186831315}
2023-01-04 02:10:20,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:20,661 INFO:     Epoch: 78
2023-01-04 02:10:22,269 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4650603363911311, 'Total loss': 0.4650603363911311} | train loss {'Reaction outcome loss': 0.1789035456384713, 'Total loss': 0.1789035456384713}
2023-01-04 02:10:22,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:22,269 INFO:     Epoch: 79
2023-01-04 02:10:23,826 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4461763143539429, 'Total loss': 0.4461763143539429} | train loss {'Reaction outcome loss': 0.17657681386713142, 'Total loss': 0.17657681386713142}
2023-01-04 02:10:23,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:23,827 INFO:     Epoch: 80
2023-01-04 02:10:25,403 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4378876030445099, 'Total loss': 0.4378876030445099} | train loss {'Reaction outcome loss': 0.17635106678792845, 'Total loss': 0.17635106678792845}
2023-01-04 02:10:25,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:25,404 INFO:     Epoch: 81
2023-01-04 02:10:26,983 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4781355659166972, 'Total loss': 0.4781355659166972} | train loss {'Reaction outcome loss': 0.1771096718043853, 'Total loss': 0.1771096718043853}
2023-01-04 02:10:26,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:26,983 INFO:     Epoch: 82
2023-01-04 02:10:28,561 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4351955115795135, 'Total loss': 0.4351955115795135} | train loss {'Reaction outcome loss': 0.17799722972315746, 'Total loss': 0.17799722972315746}
2023-01-04 02:10:28,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:28,562 INFO:     Epoch: 83
2023-01-04 02:10:30,140 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4379874567190806, 'Total loss': 0.4379874567190806} | train loss {'Reaction outcome loss': 0.1750888767764791, 'Total loss': 0.1750888767764791}
2023-01-04 02:10:30,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:30,140 INFO:     Epoch: 84
2023-01-04 02:10:31,688 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46609675188859306, 'Total loss': 0.46609675188859306} | train loss {'Reaction outcome loss': 0.17283558154874396, 'Total loss': 0.17283558154874396}
2023-01-04 02:10:31,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:31,689 INFO:     Epoch: 85
2023-01-04 02:10:33,292 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49411852955818175, 'Total loss': 0.49411852955818175} | train loss {'Reaction outcome loss': 0.17362155761542447, 'Total loss': 0.17362155761542447}
2023-01-04 02:10:33,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:33,292 INFO:     Epoch: 86
2023-01-04 02:10:34,896 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43524868686993917, 'Total loss': 0.43524868686993917} | train loss {'Reaction outcome loss': 0.1715866103427205, 'Total loss': 0.1715866103427205}
2023-01-04 02:10:34,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:34,896 INFO:     Epoch: 87
2023-01-04 02:10:36,498 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47840964496135713, 'Total loss': 0.47840964496135713} | train loss {'Reaction outcome loss': 0.17167051644115658, 'Total loss': 0.17167051644115658}
2023-01-04 02:10:36,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:36,498 INFO:     Epoch: 88
2023-01-04 02:10:38,085 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4365077624718348, 'Total loss': 0.4365077624718348} | train loss {'Reaction outcome loss': 0.17081210364488672, 'Total loss': 0.17081210364488672}
2023-01-04 02:10:38,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:38,085 INFO:     Epoch: 89
2023-01-04 02:10:39,688 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42874213854471843, 'Total loss': 0.42874213854471843} | train loss {'Reaction outcome loss': 0.1709030819135708, 'Total loss': 0.1709030819135708}
2023-01-04 02:10:39,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:39,689 INFO:     Epoch: 90
2023-01-04 02:10:41,251 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4483655651410421, 'Total loss': 0.4483655651410421} | train loss {'Reaction outcome loss': 0.1713198325613807, 'Total loss': 0.1713198325613807}
2023-01-04 02:10:41,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:41,251 INFO:     Epoch: 91
2023-01-04 02:10:42,862 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46431814233462015, 'Total loss': 0.46431814233462015} | train loss {'Reaction outcome loss': 0.17093052661844663, 'Total loss': 0.17093052661844663}
2023-01-04 02:10:42,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:42,863 INFO:     Epoch: 92
2023-01-04 02:10:44,435 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4652067502339681, 'Total loss': 0.4652067502339681} | train loss {'Reaction outcome loss': 0.16665182090722597, 'Total loss': 0.16665182090722597}
2023-01-04 02:10:44,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:44,436 INFO:     Epoch: 93
2023-01-04 02:10:46,026 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4490493476390839, 'Total loss': 0.4490493476390839} | train loss {'Reaction outcome loss': 0.16933873194123145, 'Total loss': 0.16933873194123145}
2023-01-04 02:10:46,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:46,026 INFO:     Epoch: 94
2023-01-04 02:10:47,589 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43184351523717246, 'Total loss': 0.43184351523717246} | train loss {'Reaction outcome loss': 0.16570334623298255, 'Total loss': 0.16570334623298255}
2023-01-04 02:10:47,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:47,589 INFO:     Epoch: 95
2023-01-04 02:10:49,177 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46284151474634805, 'Total loss': 0.46284151474634805} | train loss {'Reaction outcome loss': 0.16725965407796395, 'Total loss': 0.16725965407796395}
2023-01-04 02:10:49,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:49,178 INFO:     Epoch: 96
2023-01-04 02:10:50,742 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5017501980066299, 'Total loss': 0.5017501980066299} | train loss {'Reaction outcome loss': 0.16866558944403906, 'Total loss': 0.16866558944403906}
2023-01-04 02:10:50,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:50,742 INFO:     Epoch: 97
2023-01-04 02:10:52,327 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4502851963043213, 'Total loss': 0.4502851963043213} | train loss {'Reaction outcome loss': 0.1668112533637783, 'Total loss': 0.1668112533637783}
2023-01-04 02:10:52,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:52,328 INFO:     Epoch: 98
2023-01-04 02:10:53,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47247464855511984, 'Total loss': 0.47247464855511984} | train loss {'Reaction outcome loss': 0.1653316191946849, 'Total loss': 0.1653316191946849}
2023-01-04 02:10:53,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:53,922 INFO:     Epoch: 99
2023-01-04 02:10:55,531 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46246302326520283, 'Total loss': 0.46246302326520283} | train loss {'Reaction outcome loss': 0.16544330121451245, 'Total loss': 0.16544330121451245}
2023-01-04 02:10:55,531 INFO:     Best model found after epoch 32 of 100.
2023-01-04 02:10:55,531 INFO:   Done with stage: TRAINING
2023-01-04 02:10:55,531 INFO:   Starting stage: EVALUATION
2023-01-04 02:10:55,670 INFO:   Done with stage: EVALUATION
2023-01-04 02:10:55,670 INFO:   Leaving out SEQ value Fold_3
2023-01-04 02:10:55,683 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:10:55,683 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:10:56,327 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:10:56,327 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:10:56,397 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:10:56,397 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:10:56,397 INFO:     No hyperparam tuning for this model
2023-01-04 02:10:56,397 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:10:56,397 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:10:56,398 INFO:     None feature selector for col prot
2023-01-04 02:10:56,398 INFO:     None feature selector for col prot
2023-01-04 02:10:56,398 INFO:     None feature selector for col prot
2023-01-04 02:10:56,399 INFO:     None feature selector for col chem
2023-01-04 02:10:56,399 INFO:     None feature selector for col chem
2023-01-04 02:10:56,399 INFO:     None feature selector for col chem
2023-01-04 02:10:56,399 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:10:56,399 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:10:56,400 INFO:     Number of params in model 70141
2023-01-04 02:10:56,403 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:10:56,403 INFO:   Starting stage: TRAINING
2023-01-04 02:10:56,447 INFO:     Val loss before train {'Reaction outcome loss': 1.089960010846456, 'Total loss': 1.089960010846456}
2023-01-04 02:10:56,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:56,447 INFO:     Epoch: 0
2023-01-04 02:10:58,033 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7383357683817545, 'Total loss': 0.7383357683817545} | train loss {'Reaction outcome loss': 0.8431740350966906, 'Total loss': 0.8431740350966906}
2023-01-04 02:10:58,033 INFO:     Found new best model at epoch 0
2023-01-04 02:10:58,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:58,034 INFO:     Epoch: 1
2023-01-04 02:10:59,600 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5900715728600819, 'Total loss': 0.5900715728600819} | train loss {'Reaction outcome loss': 0.6147015306310062, 'Total loss': 0.6147015306310062}
2023-01-04 02:10:59,600 INFO:     Found new best model at epoch 1
2023-01-04 02:10:59,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:10:59,601 INFO:     Epoch: 2
2023-01-04 02:11:01,181 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5416777809460958, 'Total loss': 0.5416777809460958} | train loss {'Reaction outcome loss': 0.533614927291, 'Total loss': 0.533614927291}
2023-01-04 02:11:01,183 INFO:     Found new best model at epoch 2
2023-01-04 02:11:01,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:01,183 INFO:     Epoch: 3
2023-01-04 02:11:02,769 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49770159522692364, 'Total loss': 0.49770159522692364} | train loss {'Reaction outcome loss': 0.4894435649370625, 'Total loss': 0.4894435649370625}
2023-01-04 02:11:02,769 INFO:     Found new best model at epoch 3
2023-01-04 02:11:02,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:02,770 INFO:     Epoch: 4
2023-01-04 02:11:04,360 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4900351226329803, 'Total loss': 0.4900351226329803} | train loss {'Reaction outcome loss': 0.45856279556224816, 'Total loss': 0.45856279556224816}
2023-01-04 02:11:04,360 INFO:     Found new best model at epoch 4
2023-01-04 02:11:04,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:04,361 INFO:     Epoch: 5
2023-01-04 02:11:05,947 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4533309469620387, 'Total loss': 0.4533309469620387} | train loss {'Reaction outcome loss': 0.43584780253633093, 'Total loss': 0.43584780253633093}
2023-01-04 02:11:05,947 INFO:     Found new best model at epoch 5
2023-01-04 02:11:05,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:05,948 INFO:     Epoch: 6
2023-01-04 02:11:07,528 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4470425933599472, 'Total loss': 0.4470425933599472} | train loss {'Reaction outcome loss': 0.4177568473574454, 'Total loss': 0.4177568473574454}
2023-01-04 02:11:07,529 INFO:     Found new best model at epoch 6
2023-01-04 02:11:07,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:07,530 INFO:     Epoch: 7
2023-01-04 02:11:09,106 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4437486261129379, 'Total loss': 0.4437486261129379} | train loss {'Reaction outcome loss': 0.40483353064008004, 'Total loss': 0.40483353064008004}
2023-01-04 02:11:09,106 INFO:     Found new best model at epoch 7
2023-01-04 02:11:09,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:09,107 INFO:     Epoch: 8
2023-01-04 02:11:10,684 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4212363839149475, 'Total loss': 0.4212363839149475} | train loss {'Reaction outcome loss': 0.3903694642830069, 'Total loss': 0.3903694642830069}
2023-01-04 02:11:10,684 INFO:     Found new best model at epoch 8
2023-01-04 02:11:10,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:10,685 INFO:     Epoch: 9
2023-01-04 02:11:12,270 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44038034081459043, 'Total loss': 0.44038034081459043} | train loss {'Reaction outcome loss': 0.37666185926238116, 'Total loss': 0.37666185926238116}
2023-01-04 02:11:12,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:12,270 INFO:     Epoch: 10
2023-01-04 02:11:13,854 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41395777066548667, 'Total loss': 0.41395777066548667} | train loss {'Reaction outcome loss': 0.3678611258085627, 'Total loss': 0.3678611258085627}
2023-01-04 02:11:13,854 INFO:     Found new best model at epoch 10
2023-01-04 02:11:13,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:13,855 INFO:     Epoch: 11
2023-01-04 02:11:15,451 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42952126264572144, 'Total loss': 0.42952126264572144} | train loss {'Reaction outcome loss': 0.35688869002526696, 'Total loss': 0.35688869002526696}
2023-01-04 02:11:15,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:15,451 INFO:     Epoch: 12
2023-01-04 02:11:17,040 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4382454107205073, 'Total loss': 0.4382454107205073} | train loss {'Reaction outcome loss': 0.3514779732718955, 'Total loss': 0.3514779732718955}
2023-01-04 02:11:17,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:17,040 INFO:     Epoch: 13
2023-01-04 02:11:18,650 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4271923820177714, 'Total loss': 0.4271923820177714} | train loss {'Reaction outcome loss': 0.3415190598444782, 'Total loss': 0.3415190598444782}
2023-01-04 02:11:18,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:18,651 INFO:     Epoch: 14
2023-01-04 02:11:20,264 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4186478475729624, 'Total loss': 0.4186478475729624} | train loss {'Reaction outcome loss': 0.3337725280736485, 'Total loss': 0.3337725280736485}
2023-01-04 02:11:20,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:20,265 INFO:     Epoch: 15
2023-01-04 02:11:21,876 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4210373600323995, 'Total loss': 0.4210373600323995} | train loss {'Reaction outcome loss': 0.32562320562501024, 'Total loss': 0.32562320562501024}
2023-01-04 02:11:21,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:21,877 INFO:     Epoch: 16
2023-01-04 02:11:23,448 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4045460085074107, 'Total loss': 0.4045460085074107} | train loss {'Reaction outcome loss': 0.32138310568611117, 'Total loss': 0.32138310568611117}
2023-01-04 02:11:23,448 INFO:     Found new best model at epoch 16
2023-01-04 02:11:23,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:23,449 INFO:     Epoch: 17
2023-01-04 02:11:25,023 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40714879234631857, 'Total loss': 0.40714879234631857} | train loss {'Reaction outcome loss': 0.3160366293342009, 'Total loss': 0.3160366293342009}
2023-01-04 02:11:25,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:25,024 INFO:     Epoch: 18
2023-01-04 02:11:26,596 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4072619765996933, 'Total loss': 0.4072619765996933} | train loss {'Reaction outcome loss': 0.3083872339368737, 'Total loss': 0.3083872339368737}
2023-01-04 02:11:26,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:26,596 INFO:     Epoch: 19
2023-01-04 02:11:28,181 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.408081982533137, 'Total loss': 0.408081982533137} | train loss {'Reaction outcome loss': 0.30375096933358775, 'Total loss': 0.30375096933358775}
2023-01-04 02:11:28,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:28,181 INFO:     Epoch: 20
2023-01-04 02:11:29,764 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4321969817082087, 'Total loss': 0.4321969817082087} | train loss {'Reaction outcome loss': 0.2979337110517234, 'Total loss': 0.2979337110517234}
2023-01-04 02:11:29,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:29,765 INFO:     Epoch: 21
2023-01-04 02:11:31,333 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4257836898167928, 'Total loss': 0.4257836898167928} | train loss {'Reaction outcome loss': 0.29188859922281146, 'Total loss': 0.29188859922281146}
2023-01-04 02:11:31,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:31,334 INFO:     Epoch: 22
2023-01-04 02:11:32,913 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.416320006052653, 'Total loss': 0.416320006052653} | train loss {'Reaction outcome loss': 0.28774908320964687, 'Total loss': 0.28774908320964687}
2023-01-04 02:11:32,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:32,914 INFO:     Epoch: 23
2023-01-04 02:11:34,481 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42319835821787516, 'Total loss': 0.42319835821787516} | train loss {'Reaction outcome loss': 0.2835212150982914, 'Total loss': 0.2835212150982914}
2023-01-04 02:11:34,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:34,481 INFO:     Epoch: 24
2023-01-04 02:11:36,064 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40757001340389254, 'Total loss': 0.40757001340389254} | train loss {'Reaction outcome loss': 0.280312849086349, 'Total loss': 0.280312849086349}
2023-01-04 02:11:36,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:36,065 INFO:     Epoch: 25
2023-01-04 02:11:37,676 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4108595192432404, 'Total loss': 0.4108595192432404} | train loss {'Reaction outcome loss': 0.2776753539695357, 'Total loss': 0.2776753539695357}
2023-01-04 02:11:37,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:37,677 INFO:     Epoch: 26
2023-01-04 02:11:39,278 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4123525122801463, 'Total loss': 0.4123525122801463} | train loss {'Reaction outcome loss': 0.2714393869939729, 'Total loss': 0.2714393869939729}
2023-01-04 02:11:39,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:39,278 INFO:     Epoch: 27
2023-01-04 02:11:40,855 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4083154539267222, 'Total loss': 0.4083154539267222} | train loss {'Reaction outcome loss': 0.26984305921806034, 'Total loss': 0.26984305921806034}
2023-01-04 02:11:40,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:40,855 INFO:     Epoch: 28
2023-01-04 02:11:42,470 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42359066208203633, 'Total loss': 0.42359066208203633} | train loss {'Reaction outcome loss': 0.2678265950649324, 'Total loss': 0.2678265950649324}
2023-01-04 02:11:42,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:42,471 INFO:     Epoch: 29
2023-01-04 02:11:44,041 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43235655725002287, 'Total loss': 0.43235655725002287} | train loss {'Reaction outcome loss': 0.2621227892210884, 'Total loss': 0.2621227892210884}
2023-01-04 02:11:44,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:44,041 INFO:     Epoch: 30
2023-01-04 02:11:45,624 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4135426104068756, 'Total loss': 0.4135426104068756} | train loss {'Reaction outcome loss': 0.26137084201195815, 'Total loss': 0.26137084201195815}
2023-01-04 02:11:45,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:45,625 INFO:     Epoch: 31
2023-01-04 02:11:47,239 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41177207231521606, 'Total loss': 0.41177207231521606} | train loss {'Reaction outcome loss': 0.25468246928368604, 'Total loss': 0.25468246928368604}
2023-01-04 02:11:47,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:47,239 INFO:     Epoch: 32
2023-01-04 02:11:48,844 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4206348607937495, 'Total loss': 0.4206348607937495} | train loss {'Reaction outcome loss': 0.25361507156197605, 'Total loss': 0.25361507156197605}
2023-01-04 02:11:48,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:48,844 INFO:     Epoch: 33
2023-01-04 02:11:50,417 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40528486371040345, 'Total loss': 0.40528486371040345} | train loss {'Reaction outcome loss': 0.24827772979862497, 'Total loss': 0.24827772979862497}
2023-01-04 02:11:50,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:50,418 INFO:     Epoch: 34
2023-01-04 02:11:52,005 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41866110588113464, 'Total loss': 0.41866110588113464} | train loss {'Reaction outcome loss': 0.24741867535414486, 'Total loss': 0.24741867535414486}
2023-01-04 02:11:52,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:52,006 INFO:     Epoch: 35
2023-01-04 02:11:53,582 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3987574328978856, 'Total loss': 0.3987574328978856} | train loss {'Reaction outcome loss': 0.2451666242232288, 'Total loss': 0.2451666242232288}
2023-01-04 02:11:53,582 INFO:     Found new best model at epoch 35
2023-01-04 02:11:53,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:53,583 INFO:     Epoch: 36
2023-01-04 02:11:55,166 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42533898651599883, 'Total loss': 0.42533898651599883} | train loss {'Reaction outcome loss': 0.2418430533776753, 'Total loss': 0.2418430533776753}
2023-01-04 02:11:55,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:55,167 INFO:     Epoch: 37
2023-01-04 02:11:56,749 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43193575243155163, 'Total loss': 0.43193575243155163} | train loss {'Reaction outcome loss': 0.23922413072283685, 'Total loss': 0.23922413072283685}
2023-01-04 02:11:56,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:56,749 INFO:     Epoch: 38
2023-01-04 02:11:58,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4454389239350955, 'Total loss': 0.4454389239350955} | train loss {'Reaction outcome loss': 0.23863068367116644, 'Total loss': 0.23863068367116644}
2023-01-04 02:11:58,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:58,324 INFO:     Epoch: 39
2023-01-04 02:11:59,905 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41726863582928975, 'Total loss': 0.41726863582928975} | train loss {'Reaction outcome loss': 0.2349875741468294, 'Total loss': 0.2349875741468294}
2023-01-04 02:11:59,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:11:59,905 INFO:     Epoch: 40
2023-01-04 02:12:01,468 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4081774681806564, 'Total loss': 0.4081774681806564} | train loss {'Reaction outcome loss': 0.23129290413029874, 'Total loss': 0.23129290413029874}
2023-01-04 02:12:01,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:01,468 INFO:     Epoch: 41
2023-01-04 02:12:03,072 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.425614932179451, 'Total loss': 0.425614932179451} | train loss {'Reaction outcome loss': 0.23375043381739707, 'Total loss': 0.23375043381739707}
2023-01-04 02:12:03,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:03,073 INFO:     Epoch: 42
2023-01-04 02:12:04,677 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40374328891436256, 'Total loss': 0.40374328891436256} | train loss {'Reaction outcome loss': 0.23088937044062102, 'Total loss': 0.23088937044062102}
2023-01-04 02:12:04,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:04,677 INFO:     Epoch: 43
2023-01-04 02:12:06,273 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3932117929061254, 'Total loss': 0.3932117929061254} | train loss {'Reaction outcome loss': 0.22736119185268444, 'Total loss': 0.22736119185268444}
2023-01-04 02:12:06,273 INFO:     Found new best model at epoch 43
2023-01-04 02:12:06,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:06,274 INFO:     Epoch: 44
2023-01-04 02:12:07,865 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41272662580013275, 'Total loss': 0.41272662580013275} | train loss {'Reaction outcome loss': 0.22639303398828436, 'Total loss': 0.22639303398828436}
2023-01-04 02:12:07,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:07,865 INFO:     Epoch: 45
2023-01-04 02:12:09,481 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4391597578922907, 'Total loss': 0.4391597578922907} | train loss {'Reaction outcome loss': 0.22429614970936393, 'Total loss': 0.22429614970936393}
2023-01-04 02:12:09,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:09,481 INFO:     Epoch: 46
2023-01-04 02:12:11,067 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4312815209229787, 'Total loss': 0.4312815209229787} | train loss {'Reaction outcome loss': 0.219020921097946, 'Total loss': 0.219020921097946}
2023-01-04 02:12:11,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:11,067 INFO:     Epoch: 47
2023-01-04 02:12:12,672 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42596326569716136, 'Total loss': 0.42596326569716136} | train loss {'Reaction outcome loss': 0.21958815140554505, 'Total loss': 0.21958815140554505}
2023-01-04 02:12:12,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:12,673 INFO:     Epoch: 48
2023-01-04 02:12:14,278 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41735939780871073, 'Total loss': 0.41735939780871073} | train loss {'Reaction outcome loss': 0.21873225172451377, 'Total loss': 0.21873225172451377}
2023-01-04 02:12:14,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:14,279 INFO:     Epoch: 49
2023-01-04 02:12:15,882 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4293252935012182, 'Total loss': 0.4293252935012182} | train loss {'Reaction outcome loss': 0.21454743622210773, 'Total loss': 0.21454743622210773}
2023-01-04 02:12:15,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:15,883 INFO:     Epoch: 50
2023-01-04 02:12:17,465 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.425974078476429, 'Total loss': 0.425974078476429} | train loss {'Reaction outcome loss': 0.2151761889648046, 'Total loss': 0.2151761889648046}
2023-01-04 02:12:17,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:17,465 INFO:     Epoch: 51
2023-01-04 02:12:19,046 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41895721753438314, 'Total loss': 0.41895721753438314} | train loss {'Reaction outcome loss': 0.2130395485101825, 'Total loss': 0.2130395485101825}
2023-01-04 02:12:19,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:19,047 INFO:     Epoch: 52
2023-01-04 02:12:20,631 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4205110063155492, 'Total loss': 0.4205110063155492} | train loss {'Reaction outcome loss': 0.21228088395003855, 'Total loss': 0.21228088395003855}
2023-01-04 02:12:20,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:20,631 INFO:     Epoch: 53
2023-01-04 02:12:22,216 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4385454485813777, 'Total loss': 0.4385454485813777} | train loss {'Reaction outcome loss': 0.2093259977571068, 'Total loss': 0.2093259977571068}
2023-01-04 02:12:22,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:22,216 INFO:     Epoch: 54
2023-01-04 02:12:23,800 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45242256224155425, 'Total loss': 0.45242256224155425} | train loss {'Reaction outcome loss': 0.20953444815682667, 'Total loss': 0.20953444815682667}
2023-01-04 02:12:23,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:23,800 INFO:     Epoch: 55
2023-01-04 02:12:25,365 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44683508773644764, 'Total loss': 0.44683508773644764} | train loss {'Reaction outcome loss': 0.2067684619313609, 'Total loss': 0.2067684619313609}
2023-01-04 02:12:25,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:25,366 INFO:     Epoch: 56
2023-01-04 02:12:26,952 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4220939556757609, 'Total loss': 0.4220939556757609} | train loss {'Reaction outcome loss': 0.20455152054663991, 'Total loss': 0.20455152054663991}
2023-01-04 02:12:26,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:26,953 INFO:     Epoch: 57
2023-01-04 02:12:28,519 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4230471566319466, 'Total loss': 0.4230471566319466} | train loss {'Reaction outcome loss': 0.20393538534858802, 'Total loss': 0.20393538534858802}
2023-01-04 02:12:28,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:28,520 INFO:     Epoch: 58
2023-01-04 02:12:30,130 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4421359712878863, 'Total loss': 0.4421359712878863} | train loss {'Reaction outcome loss': 0.20542454440826483, 'Total loss': 0.20542454440826483}
2023-01-04 02:12:30,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:30,130 INFO:     Epoch: 59
2023-01-04 02:12:31,745 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42265504548947014, 'Total loss': 0.42265504548947014} | train loss {'Reaction outcome loss': 0.2024327967941326, 'Total loss': 0.2024327967941326}
2023-01-04 02:12:31,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:31,746 INFO:     Epoch: 60
2023-01-04 02:12:33,348 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43774223923683164, 'Total loss': 0.43774223923683164} | train loss {'Reaction outcome loss': 0.19877552449104996, 'Total loss': 0.19877552449104996}
2023-01-04 02:12:33,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:33,349 INFO:     Epoch: 61
2023-01-04 02:12:34,929 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4405053814252218, 'Total loss': 0.4405053814252218} | train loss {'Reaction outcome loss': 0.19835224046106756, 'Total loss': 0.19835224046106756}
2023-01-04 02:12:34,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:34,930 INFO:     Epoch: 62
2023-01-04 02:12:36,520 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42087205350399015, 'Total loss': 0.42087205350399015} | train loss {'Reaction outcome loss': 0.19742837082594633, 'Total loss': 0.19742837082594633}
2023-01-04 02:12:36,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:36,520 INFO:     Epoch: 63
2023-01-04 02:12:38,104 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43951162497202556, 'Total loss': 0.43951162497202556} | train loss {'Reaction outcome loss': 0.19760969224093605, 'Total loss': 0.19760969224093605}
2023-01-04 02:12:38,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:38,105 INFO:     Epoch: 64
2023-01-04 02:12:39,681 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4518375704685847, 'Total loss': 0.4518375704685847} | train loss {'Reaction outcome loss': 0.1948715643753318, 'Total loss': 0.1948715643753318}
2023-01-04 02:12:39,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:39,681 INFO:     Epoch: 65
2023-01-04 02:12:41,288 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4472787857055664, 'Total loss': 0.4472787857055664} | train loss {'Reaction outcome loss': 0.19377054106851999, 'Total loss': 0.19377054106851999}
2023-01-04 02:12:41,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:41,288 INFO:     Epoch: 66
2023-01-04 02:12:42,894 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4446719378232956, 'Total loss': 0.4446719378232956} | train loss {'Reaction outcome loss': 0.19547556713223457, 'Total loss': 0.19547556713223457}
2023-01-04 02:12:42,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:42,895 INFO:     Epoch: 67
2023-01-04 02:12:44,483 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44311961630980173, 'Total loss': 0.44311961630980173} | train loss {'Reaction outcome loss': 0.19047639985317297, 'Total loss': 0.19047639985317297}
2023-01-04 02:12:44,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:44,483 INFO:     Epoch: 68
2023-01-04 02:12:46,068 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4380016247431437, 'Total loss': 0.4380016247431437} | train loss {'Reaction outcome loss': 0.1897242718994835, 'Total loss': 0.1897242718994835}
2023-01-04 02:12:46,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:46,068 INFO:     Epoch: 69
2023-01-04 02:12:47,657 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4382400979598363, 'Total loss': 0.4382400979598363} | train loss {'Reaction outcome loss': 0.1895093319081042, 'Total loss': 0.1895093319081042}
2023-01-04 02:12:47,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:47,657 INFO:     Epoch: 70
2023-01-04 02:12:49,246 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4377762764692307, 'Total loss': 0.4377762764692307} | train loss {'Reaction outcome loss': 0.19022638745007725, 'Total loss': 0.19022638745007725}
2023-01-04 02:12:49,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:49,247 INFO:     Epoch: 71
2023-01-04 02:12:50,834 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4457096676031748, 'Total loss': 0.4457096676031748} | train loss {'Reaction outcome loss': 0.18796195402523896, 'Total loss': 0.18796195402523896}
2023-01-04 02:12:50,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:50,834 INFO:     Epoch: 72
2023-01-04 02:12:52,400 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45891743699709575, 'Total loss': 0.45891743699709575} | train loss {'Reaction outcome loss': 0.18644929560322832, 'Total loss': 0.18644929560322832}
2023-01-04 02:12:52,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:52,400 INFO:     Epoch: 73
2023-01-04 02:12:54,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4438158969084422, 'Total loss': 0.4438158969084422} | train loss {'Reaction outcome loss': 0.18434440108002537, 'Total loss': 0.18434440108002537}
2023-01-04 02:12:54,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:54,013 INFO:     Epoch: 74
2023-01-04 02:12:55,591 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4554142355918884, 'Total loss': 0.4554142355918884} | train loss {'Reaction outcome loss': 0.18362864883222285, 'Total loss': 0.18362864883222285}
2023-01-04 02:12:55,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:55,591 INFO:     Epoch: 75
2023-01-04 02:12:57,183 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4571433206399282, 'Total loss': 0.4571433206399282} | train loss {'Reaction outcome loss': 0.18392351965154827, 'Total loss': 0.18392351965154827}
2023-01-04 02:12:57,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:57,183 INFO:     Epoch: 76
2023-01-04 02:12:58,775 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4375955030322075, 'Total loss': 0.4375955030322075} | train loss {'Reaction outcome loss': 0.184737749853219, 'Total loss': 0.184737749853219}
2023-01-04 02:12:58,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:12:58,775 INFO:     Epoch: 77
2023-01-04 02:13:00,368 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4615290919939677, 'Total loss': 0.4615290919939677} | train loss {'Reaction outcome loss': 0.18194952809734502, 'Total loss': 0.18194952809734502}
2023-01-04 02:13:00,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:00,368 INFO:     Epoch: 78
2023-01-04 02:13:01,954 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4572188973426819, 'Total loss': 0.4572188973426819} | train loss {'Reaction outcome loss': 0.1809857272046761, 'Total loss': 0.1809857272046761}
2023-01-04 02:13:01,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:01,955 INFO:     Epoch: 79
2023-01-04 02:13:03,535 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48915878534317014, 'Total loss': 0.48915878534317014} | train loss {'Reaction outcome loss': 0.1785954269886452, 'Total loss': 0.1785954269886452}
2023-01-04 02:13:03,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:03,535 INFO:     Epoch: 80
2023-01-04 02:13:05,119 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4630385140577952, 'Total loss': 0.4630385140577952} | train loss {'Reaction outcome loss': 0.17986937855662655, 'Total loss': 0.17986937855662655}
2023-01-04 02:13:05,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:05,120 INFO:     Epoch: 81
2023-01-04 02:13:06,733 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46081394453843433, 'Total loss': 0.46081394453843433} | train loss {'Reaction outcome loss': 0.17690170184457607, 'Total loss': 0.17690170184457607}
2023-01-04 02:13:06,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:06,733 INFO:     Epoch: 82
2023-01-04 02:13:08,347 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4479204997420311, 'Total loss': 0.4479204997420311} | train loss {'Reaction outcome loss': 0.17614316209525305, 'Total loss': 0.17614316209525305}
2023-01-04 02:13:08,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:08,347 INFO:     Epoch: 83
2023-01-04 02:13:09,952 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44205658783515295, 'Total loss': 0.44205658783515295} | train loss {'Reaction outcome loss': 0.17721582077661135, 'Total loss': 0.17721582077661135}
2023-01-04 02:13:09,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:09,952 INFO:     Epoch: 84
2023-01-04 02:13:11,531 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49024783372879027, 'Total loss': 0.49024783372879027} | train loss {'Reaction outcome loss': 0.1767502367890773, 'Total loss': 0.1767502367890773}
2023-01-04 02:13:11,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:11,531 INFO:     Epoch: 85
2023-01-04 02:13:13,109 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44674097895622256, 'Total loss': 0.44674097895622256} | train loss {'Reaction outcome loss': 0.17661101796603115, 'Total loss': 0.17661101796603115}
2023-01-04 02:13:13,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:13,109 INFO:     Epoch: 86
2023-01-04 02:13:14,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48506584763526917, 'Total loss': 0.48506584763526917} | train loss {'Reaction outcome loss': 0.17352862680589196, 'Total loss': 0.17352862680589196}
2023-01-04 02:13:14,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:14,729 INFO:     Epoch: 87
2023-01-04 02:13:16,332 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4785369465748469, 'Total loss': 0.4785369465748469} | train loss {'Reaction outcome loss': 0.1752159477748575, 'Total loss': 0.1752159477748575}
2023-01-04 02:13:16,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:16,332 INFO:     Epoch: 88
2023-01-04 02:13:17,940 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4768509795268377, 'Total loss': 0.4768509795268377} | train loss {'Reaction outcome loss': 0.17207238596123065, 'Total loss': 0.17207238596123065}
2023-01-04 02:13:17,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:17,940 INFO:     Epoch: 89
2023-01-04 02:13:19,529 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4424591839313507, 'Total loss': 0.4424591839313507} | train loss {'Reaction outcome loss': 0.17167435441655618, 'Total loss': 0.17167435441655618}
2023-01-04 02:13:19,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:19,529 INFO:     Epoch: 90
2023-01-04 02:13:21,145 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4494163155555725, 'Total loss': 0.4494163155555725} | train loss {'Reaction outcome loss': 0.17335877334359137, 'Total loss': 0.17335877334359137}
2023-01-04 02:13:21,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:21,146 INFO:     Epoch: 91
2023-01-04 02:13:22,709 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4747418741385142, 'Total loss': 0.4747418741385142} | train loss {'Reaction outcome loss': 0.17098384406961445, 'Total loss': 0.17098384406961445}
2023-01-04 02:13:22,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:22,710 INFO:     Epoch: 92
2023-01-04 02:13:24,319 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4479042867819468, 'Total loss': 0.4479042867819468} | train loss {'Reaction outcome loss': 0.17315077611048074, 'Total loss': 0.17315077611048074}
2023-01-04 02:13:24,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:24,319 INFO:     Epoch: 93
2023-01-04 02:13:25,929 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4783737301826477, 'Total loss': 0.4783737301826477} | train loss {'Reaction outcome loss': 0.170608800686352, 'Total loss': 0.170608800686352}
2023-01-04 02:13:25,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:25,929 INFO:     Epoch: 94
2023-01-04 02:13:27,538 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4793699324131012, 'Total loss': 0.4793699324131012} | train loss {'Reaction outcome loss': 0.16938341627182968, 'Total loss': 0.16938341627182968}
2023-01-04 02:13:27,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:27,538 INFO:     Epoch: 95
2023-01-04 02:13:29,111 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4727482795715332, 'Total loss': 0.4727482795715332} | train loss {'Reaction outcome loss': 0.1712492875870399, 'Total loss': 0.1712492875870399}
2023-01-04 02:13:29,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:29,111 INFO:     Epoch: 96
2023-01-04 02:13:30,694 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4514222244421641, 'Total loss': 0.4514222244421641} | train loss {'Reaction outcome loss': 0.1696313136889443, 'Total loss': 0.1696313136889443}
2023-01-04 02:13:30,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:30,694 INFO:     Epoch: 97
2023-01-04 02:13:32,272 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4513524405658245, 'Total loss': 0.4513524405658245} | train loss {'Reaction outcome loss': 0.16731394867473928, 'Total loss': 0.16731394867473928}
2023-01-04 02:13:32,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:32,272 INFO:     Epoch: 98
2023-01-04 02:13:33,880 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44321103890736896, 'Total loss': 0.44321103890736896} | train loss {'Reaction outcome loss': 0.16648028111833074, 'Total loss': 0.16648028111833074}
2023-01-04 02:13:33,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:33,881 INFO:     Epoch: 99
2023-01-04 02:13:35,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44798268874486286, 'Total loss': 0.44798268874486286} | train loss {'Reaction outcome loss': 0.16708863829772402, 'Total loss': 0.16708863829772402}
2023-01-04 02:13:35,455 INFO:     Best model found after epoch 44 of 100.
2023-01-04 02:13:35,455 INFO:   Done with stage: TRAINING
2023-01-04 02:13:35,455 INFO:   Starting stage: EVALUATION
2023-01-04 02:13:35,589 INFO:   Done with stage: EVALUATION
2023-01-04 02:13:35,589 INFO:   Leaving out SEQ value Fold_4
2023-01-04 02:13:35,602 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:13:35,602 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:13:36,253 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:13:36,253 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:13:36,322 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:13:36,322 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:13:36,322 INFO:     No hyperparam tuning for this model
2023-01-04 02:13:36,322 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:13:36,322 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:13:36,323 INFO:     None feature selector for col prot
2023-01-04 02:13:36,323 INFO:     None feature selector for col prot
2023-01-04 02:13:36,323 INFO:     None feature selector for col prot
2023-01-04 02:13:36,324 INFO:     None feature selector for col chem
2023-01-04 02:13:36,324 INFO:     None feature selector for col chem
2023-01-04 02:13:36,324 INFO:     None feature selector for col chem
2023-01-04 02:13:36,324 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:13:36,324 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:13:36,325 INFO:     Number of params in model 70141
2023-01-04 02:13:36,329 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:13:36,329 INFO:   Starting stage: TRAINING
2023-01-04 02:13:36,373 INFO:     Val loss before train {'Reaction outcome loss': 0.9505464335282644, 'Total loss': 0.9505464335282644}
2023-01-04 02:13:36,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:36,373 INFO:     Epoch: 0
2023-01-04 02:13:37,977 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6803950289885203, 'Total loss': 0.6803950289885203} | train loss {'Reaction outcome loss': 0.8588060545802548, 'Total loss': 0.8588060545802548}
2023-01-04 02:13:37,977 INFO:     Found new best model at epoch 0
2023-01-04 02:13:37,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:37,978 INFO:     Epoch: 1
2023-01-04 02:13:39,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5278347790241241, 'Total loss': 0.5278347790241241} | train loss {'Reaction outcome loss': 0.6383416093346002, 'Total loss': 0.6383416093346002}
2023-01-04 02:13:39,590 INFO:     Found new best model at epoch 1
2023-01-04 02:13:39,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:39,591 INFO:     Epoch: 2
2023-01-04 02:13:41,190 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49206868012746174, 'Total loss': 0.49206868012746174} | train loss {'Reaction outcome loss': 0.5433172610034978, 'Total loss': 0.5433172610034978}
2023-01-04 02:13:41,190 INFO:     Found new best model at epoch 2
2023-01-04 02:13:41,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:41,191 INFO:     Epoch: 3
2023-01-04 02:13:42,791 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4710773954788844, 'Total loss': 0.4710773954788844} | train loss {'Reaction outcome loss': 0.49680364909379376, 'Total loss': 0.49680364909379376}
2023-01-04 02:13:42,791 INFO:     Found new best model at epoch 3
2023-01-04 02:13:42,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:42,792 INFO:     Epoch: 4
2023-01-04 02:13:44,387 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43939912021160127, 'Total loss': 0.43939912021160127} | train loss {'Reaction outcome loss': 0.4706051618238722, 'Total loss': 0.4706051618238722}
2023-01-04 02:13:44,387 INFO:     Found new best model at epoch 4
2023-01-04 02:13:44,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:44,388 INFO:     Epoch: 5
2023-01-04 02:13:45,964 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45251054962476095, 'Total loss': 0.45251054962476095} | train loss {'Reaction outcome loss': 0.45061836480770423, 'Total loss': 0.45061836480770423}
2023-01-04 02:13:45,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:45,965 INFO:     Epoch: 6
2023-01-04 02:13:47,556 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42829364240169526, 'Total loss': 0.42829364240169526} | train loss {'Reaction outcome loss': 0.440103429923023, 'Total loss': 0.440103429923023}
2023-01-04 02:13:47,556 INFO:     Found new best model at epoch 6
2023-01-04 02:13:47,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:47,557 INFO:     Epoch: 7
2023-01-04 02:13:49,139 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4262975831826528, 'Total loss': 0.4262975831826528} | train loss {'Reaction outcome loss': 0.42256724834779574, 'Total loss': 0.42256724834779574}
2023-01-04 02:13:49,139 INFO:     Found new best model at epoch 7
2023-01-04 02:13:49,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:49,140 INFO:     Epoch: 8
2023-01-04 02:13:50,731 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4174283643563588, 'Total loss': 0.4174283643563588} | train loss {'Reaction outcome loss': 0.4125004260669179, 'Total loss': 0.4125004260669179}
2023-01-04 02:13:50,732 INFO:     Found new best model at epoch 8
2023-01-04 02:13:50,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:50,733 INFO:     Epoch: 9
2023-01-04 02:13:52,323 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4289235313733419, 'Total loss': 0.4289235313733419} | train loss {'Reaction outcome loss': 0.40247019264253153, 'Total loss': 0.40247019264253153}
2023-01-04 02:13:52,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:52,323 INFO:     Epoch: 10
2023-01-04 02:13:53,917 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41139273941516874, 'Total loss': 0.41139273941516874} | train loss {'Reaction outcome loss': 0.39475436616907, 'Total loss': 0.39475436616907}
2023-01-04 02:13:53,917 INFO:     Found new best model at epoch 10
2023-01-04 02:13:53,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:53,918 INFO:     Epoch: 11
2023-01-04 02:13:55,511 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41924300690491995, 'Total loss': 0.41924300690491995} | train loss {'Reaction outcome loss': 0.38451381298870296, 'Total loss': 0.38451381298870296}
2023-01-04 02:13:55,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:55,511 INFO:     Epoch: 12
2023-01-04 02:13:57,133 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39748428761959076, 'Total loss': 0.39748428761959076} | train loss {'Reaction outcome loss': 0.3802216159368771, 'Total loss': 0.3802216159368771}
2023-01-04 02:13:57,134 INFO:     Found new best model at epoch 12
2023-01-04 02:13:57,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:57,135 INFO:     Epoch: 13
2023-01-04 02:13:58,707 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3939597139755885, 'Total loss': 0.3939597139755885} | train loss {'Reaction outcome loss': 0.37730543050861015, 'Total loss': 0.37730543050861015}
2023-01-04 02:13:58,707 INFO:     Found new best model at epoch 13
2023-01-04 02:13:58,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:13:58,708 INFO:     Epoch: 14
2023-01-04 02:14:00,298 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.384407835205396, 'Total loss': 0.384407835205396} | train loss {'Reaction outcome loss': 0.3621095770875505, 'Total loss': 0.3621095770875505}
2023-01-04 02:14:00,299 INFO:     Found new best model at epoch 14
2023-01-04 02:14:00,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:00,299 INFO:     Epoch: 15
2023-01-04 02:14:01,892 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39589955310026803, 'Total loss': 0.39589955310026803} | train loss {'Reaction outcome loss': 0.3544832009592674, 'Total loss': 0.3544832009592674}
2023-01-04 02:14:01,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:01,892 INFO:     Epoch: 16
2023-01-04 02:14:03,475 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38526954551537834, 'Total loss': 0.38526954551537834} | train loss {'Reaction outcome loss': 0.3474313146552827, 'Total loss': 0.3474313146552827}
2023-01-04 02:14:03,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:03,475 INFO:     Epoch: 17
2023-01-04 02:14:05,074 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.378759961326917, 'Total loss': 0.378759961326917} | train loss {'Reaction outcome loss': 0.341843112102757, 'Total loss': 0.341843112102757}
2023-01-04 02:14:05,074 INFO:     Found new best model at epoch 17
2023-01-04 02:14:05,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:05,075 INFO:     Epoch: 18
2023-01-04 02:14:06,671 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37363776862621306, 'Total loss': 0.37363776862621306} | train loss {'Reaction outcome loss': 0.3346491197581349, 'Total loss': 0.3346491197581349}
2023-01-04 02:14:06,671 INFO:     Found new best model at epoch 18
2023-01-04 02:14:06,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:06,672 INFO:     Epoch: 19
2023-01-04 02:14:08,297 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39255862633387245, 'Total loss': 0.39255862633387245} | train loss {'Reaction outcome loss': 0.3301644859670162, 'Total loss': 0.3301644859670162}
2023-01-04 02:14:08,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:08,297 INFO:     Epoch: 20
2023-01-04 02:14:09,918 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37118634084860486, 'Total loss': 0.37118634084860486} | train loss {'Reaction outcome loss': 0.3236601276254749, 'Total loss': 0.3236601276254749}
2023-01-04 02:14:09,919 INFO:     Found new best model at epoch 20
2023-01-04 02:14:09,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:09,920 INFO:     Epoch: 21
2023-01-04 02:14:11,543 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38269963264465334, 'Total loss': 0.38269963264465334} | train loss {'Reaction outcome loss': 0.3224023574207356, 'Total loss': 0.3224023574207356}
2023-01-04 02:14:11,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:11,543 INFO:     Epoch: 22
2023-01-04 02:14:13,141 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36862762173016866, 'Total loss': 0.36862762173016866} | train loss {'Reaction outcome loss': 0.3135428815285854, 'Total loss': 0.3135428815285854}
2023-01-04 02:14:13,141 INFO:     Found new best model at epoch 22
2023-01-04 02:14:13,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:13,142 INFO:     Epoch: 23
2023-01-04 02:14:14,746 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.372674556573232, 'Total loss': 0.372674556573232} | train loss {'Reaction outcome loss': 0.31012267175306013, 'Total loss': 0.31012267175306013}
2023-01-04 02:14:14,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:14,747 INFO:     Epoch: 24
2023-01-04 02:14:16,339 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3628894587357839, 'Total loss': 0.3628894587357839} | train loss {'Reaction outcome loss': 0.30345377186988143, 'Total loss': 0.30345377186988143}
2023-01-04 02:14:16,339 INFO:     Found new best model at epoch 24
2023-01-04 02:14:16,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:16,340 INFO:     Epoch: 25
2023-01-04 02:14:17,931 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3842016567786535, 'Total loss': 0.3842016567786535} | train loss {'Reaction outcome loss': 0.30233818397897744, 'Total loss': 0.30233818397897744}
2023-01-04 02:14:17,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:17,931 INFO:     Epoch: 26
2023-01-04 02:14:19,527 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39318805038928983, 'Total loss': 0.39318805038928983} | train loss {'Reaction outcome loss': 0.30480367933278496, 'Total loss': 0.30480367933278496}
2023-01-04 02:14:19,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:19,527 INFO:     Epoch: 27
2023-01-04 02:14:21,122 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3901008665561676, 'Total loss': 0.3901008665561676} | train loss {'Reaction outcome loss': 0.3030714336850181, 'Total loss': 0.3030714336850181}
2023-01-04 02:14:21,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:21,122 INFO:     Epoch: 28
2023-01-04 02:14:22,720 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38954925338427226, 'Total loss': 0.38954925338427226} | train loss {'Reaction outcome loss': 0.2868904781365848, 'Total loss': 0.2868904781365848}
2023-01-04 02:14:22,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:22,721 INFO:     Epoch: 29
2023-01-04 02:14:24,311 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38740621705849965, 'Total loss': 0.38740621705849965} | train loss {'Reaction outcome loss': 0.28472516892234917, 'Total loss': 0.28472516892234917}
2023-01-04 02:14:24,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:24,311 INFO:     Epoch: 30
2023-01-04 02:14:25,929 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3760136246681213, 'Total loss': 0.3760136246681213} | train loss {'Reaction outcome loss': 0.2825278794069005, 'Total loss': 0.2825278794069005}
2023-01-04 02:14:25,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:25,931 INFO:     Epoch: 31
2023-01-04 02:14:27,552 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39368441502253215, 'Total loss': 0.39368441502253215} | train loss {'Reaction outcome loss': 0.276165214434698, 'Total loss': 0.276165214434698}
2023-01-04 02:14:27,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:27,552 INFO:     Epoch: 32
2023-01-04 02:14:29,172 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3825823962688446, 'Total loss': 0.3825823962688446} | train loss {'Reaction outcome loss': 0.2831109596308375, 'Total loss': 0.2831109596308375}
2023-01-04 02:14:29,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:29,172 INFO:     Epoch: 33
2023-01-04 02:14:30,776 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39927444557348885, 'Total loss': 0.39927444557348885} | train loss {'Reaction outcome loss': 0.2889303715167351, 'Total loss': 0.2889303715167351}
2023-01-04 02:14:30,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:30,776 INFO:     Epoch: 34
2023-01-04 02:14:32,371 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3803924103577932, 'Total loss': 0.3803924103577932} | train loss {'Reaction outcome loss': 0.26836779297909874, 'Total loss': 0.26836779297909874}
2023-01-04 02:14:32,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:32,372 INFO:     Epoch: 35
2023-01-04 02:14:33,958 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3789661010106405, 'Total loss': 0.3789661010106405} | train loss {'Reaction outcome loss': 0.2631348606209149, 'Total loss': 0.2631348606209149}
2023-01-04 02:14:33,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:33,958 INFO:     Epoch: 36
2023-01-04 02:14:35,560 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37870029906431835, 'Total loss': 0.37870029906431835} | train loss {'Reaction outcome loss': 0.2607888938670141, 'Total loss': 0.2607888938670141}
2023-01-04 02:14:35,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:35,560 INFO:     Epoch: 37
2023-01-04 02:14:37,181 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39112768073876697, 'Total loss': 0.39112768073876697} | train loss {'Reaction outcome loss': 0.2581455637512267, 'Total loss': 0.2581455637512267}
2023-01-04 02:14:37,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:37,181 INFO:     Epoch: 38
2023-01-04 02:14:38,792 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38970315059026084, 'Total loss': 0.38970315059026084} | train loss {'Reaction outcome loss': 0.2786143823675271, 'Total loss': 0.2786143823675271}
2023-01-04 02:14:38,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:38,792 INFO:     Epoch: 39
2023-01-04 02:14:40,388 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3959667901198069, 'Total loss': 0.3959667901198069} | train loss {'Reaction outcome loss': 0.25272927967075637, 'Total loss': 0.25272927967075637}
2023-01-04 02:14:40,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:40,388 INFO:     Epoch: 40
2023-01-04 02:14:41,982 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40717140436172483, 'Total loss': 0.40717140436172483} | train loss {'Reaction outcome loss': 0.24905927880019485, 'Total loss': 0.24905927880019485}
2023-01-04 02:14:41,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:41,982 INFO:     Epoch: 41
2023-01-04 02:14:43,571 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.397136793533961, 'Total loss': 0.397136793533961} | train loss {'Reaction outcome loss': 0.24909686267146489, 'Total loss': 0.24909686267146489}
2023-01-04 02:14:43,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:43,572 INFO:     Epoch: 42
2023-01-04 02:14:45,177 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40347993572553, 'Total loss': 0.40347993572553} | train loss {'Reaction outcome loss': 0.24621493345045525, 'Total loss': 0.24621493345045525}
2023-01-04 02:14:45,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:45,178 INFO:     Epoch: 43
2023-01-04 02:14:46,757 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39471701780955, 'Total loss': 0.39471701780955} | train loss {'Reaction outcome loss': 0.24483235195900002, 'Total loss': 0.24483235195900002}
2023-01-04 02:14:46,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:46,757 INFO:     Epoch: 44
2023-01-04 02:14:48,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39645856122175854, 'Total loss': 0.39645856122175854} | train loss {'Reaction outcome loss': 0.2416208987975235, 'Total loss': 0.2416208987975235}
2023-01-04 02:14:48,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:48,372 INFO:     Epoch: 45
2023-01-04 02:14:49,958 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.386197770635287, 'Total loss': 0.386197770635287} | train loss {'Reaction outcome loss': 0.23969510636474614, 'Total loss': 0.23969510636474614}
2023-01-04 02:14:49,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:49,958 INFO:     Epoch: 46
2023-01-04 02:14:51,534 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39107418606678646, 'Total loss': 0.39107418606678646} | train loss {'Reaction outcome loss': 0.23819946894840593, 'Total loss': 0.23819946894840593}
2023-01-04 02:14:51,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:51,534 INFO:     Epoch: 47
2023-01-04 02:14:53,152 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3918514897425969, 'Total loss': 0.3918514897425969} | train loss {'Reaction outcome loss': 0.23500791087871473, 'Total loss': 0.23500791087871473}
2023-01-04 02:14:53,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:53,152 INFO:     Epoch: 48
2023-01-04 02:14:54,769 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4094050278266271, 'Total loss': 0.4094050278266271} | train loss {'Reaction outcome loss': 0.2342611505012372, 'Total loss': 0.2342611505012372}
2023-01-04 02:14:54,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:54,769 INFO:     Epoch: 49
2023-01-04 02:14:56,389 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3975507696469625, 'Total loss': 0.3975507696469625} | train loss {'Reaction outcome loss': 0.23239409400696825, 'Total loss': 0.23239409400696825}
2023-01-04 02:14:56,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:56,389 INFO:     Epoch: 50
2023-01-04 02:14:57,989 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.403324360648791, 'Total loss': 0.403324360648791} | train loss {'Reaction outcome loss': 0.2279853503746183, 'Total loss': 0.2279853503746183}
2023-01-04 02:14:57,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:57,989 INFO:     Epoch: 51
2023-01-04 02:14:59,607 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3911867752671242, 'Total loss': 0.3911867752671242} | train loss {'Reaction outcome loss': 0.22717167609384953, 'Total loss': 0.22717167609384953}
2023-01-04 02:14:59,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:14:59,607 INFO:     Epoch: 52
2023-01-04 02:15:01,208 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40489039619763695, 'Total loss': 0.40489039619763695} | train loss {'Reaction outcome loss': 0.22578868305013663, 'Total loss': 0.22578868305013663}
2023-01-04 02:15:01,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:01,210 INFO:     Epoch: 53
2023-01-04 02:15:02,802 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4049254685640335, 'Total loss': 0.4049254685640335} | train loss {'Reaction outcome loss': 0.2251109693982247, 'Total loss': 0.2251109693982247}
2023-01-04 02:15:02,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:02,802 INFO:     Epoch: 54
2023-01-04 02:15:04,414 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3975099265575409, 'Total loss': 0.3975099265575409} | train loss {'Reaction outcome loss': 0.22461218886293363, 'Total loss': 0.22461218886293363}
2023-01-04 02:15:04,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:04,414 INFO:     Epoch: 55
2023-01-04 02:15:06,031 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40264073610305784, 'Total loss': 0.40264073610305784} | train loss {'Reaction outcome loss': 0.2204819918623653, 'Total loss': 0.2204819918623653}
2023-01-04 02:15:06,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:06,032 INFO:     Epoch: 56
2023-01-04 02:15:07,624 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4190811008214951, 'Total loss': 0.4190811008214951} | train loss {'Reaction outcome loss': 0.21876797340202914, 'Total loss': 0.21876797340202914}
2023-01-04 02:15:07,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:07,625 INFO:     Epoch: 57
2023-01-04 02:15:09,199 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3945899076759815, 'Total loss': 0.3945899076759815} | train loss {'Reaction outcome loss': 0.21632069492277325, 'Total loss': 0.21632069492277325}
2023-01-04 02:15:09,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:09,200 INFO:     Epoch: 58
2023-01-04 02:15:10,807 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4088622689247131, 'Total loss': 0.4088622689247131} | train loss {'Reaction outcome loss': 0.2209020823078311, 'Total loss': 0.2209020823078311}
2023-01-04 02:15:10,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:10,807 INFO:     Epoch: 59
2023-01-04 02:15:12,434 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3974349483847618, 'Total loss': 0.3974349483847618} | train loss {'Reaction outcome loss': 0.2355367825096608, 'Total loss': 0.2355367825096608}
2023-01-04 02:15:12,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:12,434 INFO:     Epoch: 60
2023-01-04 02:15:14,063 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41634989778200787, 'Total loss': 0.41634989778200787} | train loss {'Reaction outcome loss': 0.23260650224588258, 'Total loss': 0.23260650224588258}
2023-01-04 02:15:14,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:14,063 INFO:     Epoch: 61
2023-01-04 02:15:15,644 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4207695146401723, 'Total loss': 0.4207695146401723} | train loss {'Reaction outcome loss': 0.21328429828492412, 'Total loss': 0.21328429828492412}
2023-01-04 02:15:15,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:15,645 INFO:     Epoch: 62
2023-01-04 02:15:17,271 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44580807760357855, 'Total loss': 0.44580807760357855} | train loss {'Reaction outcome loss': 0.2113137548347341, 'Total loss': 0.2113137548347341}
2023-01-04 02:15:17,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:17,272 INFO:     Epoch: 63
2023-01-04 02:15:18,870 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42040543754895526, 'Total loss': 0.42040543754895526} | train loss {'Reaction outcome loss': 0.2090551757618137, 'Total loss': 0.2090551757618137}
2023-01-04 02:15:18,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:18,870 INFO:     Epoch: 64
2023-01-04 02:15:20,468 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4217288762331009, 'Total loss': 0.4217288762331009} | train loss {'Reaction outcome loss': 0.2150887359875133, 'Total loss': 0.2150887359875133}
2023-01-04 02:15:20,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:20,469 INFO:     Epoch: 65
2023-01-04 02:15:22,090 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4421329508225123, 'Total loss': 0.4421329508225123} | train loss {'Reaction outcome loss': 0.20850750598449097, 'Total loss': 0.20850750598449097}
2023-01-04 02:15:22,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:22,091 INFO:     Epoch: 66
2023-01-04 02:15:23,709 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4010559281955163, 'Total loss': 0.4010559281955163} | train loss {'Reaction outcome loss': 0.20502216922476943, 'Total loss': 0.20502216922476943}
2023-01-04 02:15:23,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:23,709 INFO:     Epoch: 67
2023-01-04 02:15:25,314 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42618342489004135, 'Total loss': 0.42618342489004135} | train loss {'Reaction outcome loss': 0.20432865570899963, 'Total loss': 0.20432865570899963}
2023-01-04 02:15:25,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:25,314 INFO:     Epoch: 68
2023-01-04 02:15:26,918 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4291912337144216, 'Total loss': 0.4291912337144216} | train loss {'Reaction outcome loss': 0.20270682859594724, 'Total loss': 0.20270682859594724}
2023-01-04 02:15:26,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:26,918 INFO:     Epoch: 69
2023-01-04 02:15:28,516 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42781744251648585, 'Total loss': 0.42781744251648585} | train loss {'Reaction outcome loss': 0.2028974244620759, 'Total loss': 0.2028974244620759}
2023-01-04 02:15:28,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:28,516 INFO:     Epoch: 70
2023-01-04 02:15:30,127 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4405377854903539, 'Total loss': 0.4405377854903539} | train loss {'Reaction outcome loss': 0.20067074348891922, 'Total loss': 0.20067074348891922}
2023-01-04 02:15:30,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:30,127 INFO:     Epoch: 71
2023-01-04 02:15:31,756 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4270485699176788, 'Total loss': 0.4270485699176788} | train loss {'Reaction outcome loss': 0.19937793678178897, 'Total loss': 0.19937793678178897}
2023-01-04 02:15:31,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:31,757 INFO:     Epoch: 72
2023-01-04 02:15:33,387 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42491158843040466, 'Total loss': 0.42491158843040466} | train loss {'Reaction outcome loss': 0.1974221201621665, 'Total loss': 0.1974221201621665}
2023-01-04 02:15:33,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:33,388 INFO:     Epoch: 73
2023-01-04 02:15:34,964 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4381936490535736, 'Total loss': 0.4381936490535736} | train loss {'Reaction outcome loss': 0.19881336319435766, 'Total loss': 0.19881336319435766}
2023-01-04 02:15:34,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:34,964 INFO:     Epoch: 74
2023-01-04 02:15:36,546 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4493319034576416, 'Total loss': 0.4493319034576416} | train loss {'Reaction outcome loss': 0.2039261086155539, 'Total loss': 0.2039261086155539}
2023-01-04 02:15:36,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:36,546 INFO:     Epoch: 75
2023-01-04 02:15:38,141 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4228619307279587, 'Total loss': 0.4228619307279587} | train loss {'Reaction outcome loss': 0.21052686014361138, 'Total loss': 0.21052686014361138}
2023-01-04 02:15:38,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:38,142 INFO:     Epoch: 76
2023-01-04 02:15:39,743 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43880112171173097, 'Total loss': 0.43880112171173097} | train loss {'Reaction outcome loss': 0.19032106130876142, 'Total loss': 0.19032106130876142}
2023-01-04 02:15:39,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:39,743 INFO:     Epoch: 77
2023-01-04 02:15:41,345 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42471087475617725, 'Total loss': 0.42471087475617725} | train loss {'Reaction outcome loss': 0.19147925212857206, 'Total loss': 0.19147925212857206}
2023-01-04 02:15:41,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:41,345 INFO:     Epoch: 78
2023-01-04 02:15:42,949 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42557872434457145, 'Total loss': 0.42557872434457145} | train loss {'Reaction outcome loss': 0.19218204235253128, 'Total loss': 0.19218204235253128}
2023-01-04 02:15:42,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:42,949 INFO:     Epoch: 79
2023-01-04 02:15:44,575 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4125234494606654, 'Total loss': 0.4125234494606654} | train loss {'Reaction outcome loss': 0.19094882319694845, 'Total loss': 0.19094882319694845}
2023-01-04 02:15:44,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:44,575 INFO:     Epoch: 80
2023-01-04 02:15:46,160 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.437756406267484, 'Total loss': 0.437756406267484} | train loss {'Reaction outcome loss': 0.1883887913486367, 'Total loss': 0.1883887913486367}
2023-01-04 02:15:46,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:46,160 INFO:     Epoch: 81
2023-01-04 02:15:47,783 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4390448515613874, 'Total loss': 0.4390448515613874} | train loss {'Reaction outcome loss': 0.18913228809074295, 'Total loss': 0.18913228809074295}
2023-01-04 02:15:47,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:47,783 INFO:     Epoch: 82
2023-01-04 02:15:49,365 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43126370906829836, 'Total loss': 0.43126370906829836} | train loss {'Reaction outcome loss': 0.18884916974744503, 'Total loss': 0.18884916974744503}
2023-01-04 02:15:49,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:49,365 INFO:     Epoch: 83
2023-01-04 02:15:50,984 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4337187106410662, 'Total loss': 0.4337187106410662} | train loss {'Reaction outcome loss': 0.1910203223157188, 'Total loss': 0.1910203223157188}
2023-01-04 02:15:50,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:50,985 INFO:     Epoch: 84
2023-01-04 02:15:52,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4405210594336192, 'Total loss': 0.4405210594336192} | train loss {'Reaction outcome loss': 0.2055542698950455, 'Total loss': 0.2055542698950455}
2023-01-04 02:15:52,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:52,562 INFO:     Epoch: 85
2023-01-04 02:15:54,143 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44681410292784374, 'Total loss': 0.44681410292784374} | train loss {'Reaction outcome loss': 0.18656967014041306, 'Total loss': 0.18656967014041306}
2023-01-04 02:15:54,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:54,143 INFO:     Epoch: 86
2023-01-04 02:15:55,716 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45756381551424663, 'Total loss': 0.45756381551424663} | train loss {'Reaction outcome loss': 0.18377401224890913, 'Total loss': 0.18377401224890913}
2023-01-04 02:15:55,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:55,716 INFO:     Epoch: 87
2023-01-04 02:15:57,337 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4596470316251119, 'Total loss': 0.4596470316251119} | train loss {'Reaction outcome loss': 0.18640129515172346, 'Total loss': 0.18640129515172346}
2023-01-04 02:15:57,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:57,337 INFO:     Epoch: 88
2023-01-04 02:15:58,955 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42593038429816565, 'Total loss': 0.42593038429816565} | train loss {'Reaction outcome loss': 0.18565663609626717, 'Total loss': 0.18565663609626717}
2023-01-04 02:15:58,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:15:58,956 INFO:     Epoch: 89
2023-01-04 02:16:00,550 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4462898731231689, 'Total loss': 0.4462898731231689} | train loss {'Reaction outcome loss': 0.18330792278436053, 'Total loss': 0.18330792278436053}
2023-01-04 02:16:00,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:00,551 INFO:     Epoch: 90
2023-01-04 02:16:02,179 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4536725322405497, 'Total loss': 0.4536725322405497} | train loss {'Reaction outcome loss': 0.18145621183287838, 'Total loss': 0.18145621183287838}
2023-01-04 02:16:02,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:02,180 INFO:     Epoch: 91
2023-01-04 02:16:03,764 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4430870403846105, 'Total loss': 0.4430870403846105} | train loss {'Reaction outcome loss': 0.18301468478191807, 'Total loss': 0.18301468478191807}
2023-01-04 02:16:03,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:03,765 INFO:     Epoch: 92
2023-01-04 02:16:05,384 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4476855476697286, 'Total loss': 0.4476855476697286} | train loss {'Reaction outcome loss': 0.17900043388869127, 'Total loss': 0.17900043388869127}
2023-01-04 02:16:05,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:05,384 INFO:     Epoch: 93
2023-01-04 02:16:07,003 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4336789419253667, 'Total loss': 0.4336789419253667} | train loss {'Reaction outcome loss': 0.17875759730864904, 'Total loss': 0.17875759730864904}
2023-01-04 02:16:07,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:07,003 INFO:     Epoch: 94
2023-01-04 02:16:08,616 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4335130880276362, 'Total loss': 0.4335130880276362} | train loss {'Reaction outcome loss': 0.1792271992451498, 'Total loss': 0.1792271992451498}
2023-01-04 02:16:08,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:08,617 INFO:     Epoch: 95
2023-01-04 02:16:10,193 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42316819727420807, 'Total loss': 0.42316819727420807} | train loss {'Reaction outcome loss': 0.17942645556657857, 'Total loss': 0.17942645556657857}
2023-01-04 02:16:10,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:10,193 INFO:     Epoch: 96
2023-01-04 02:16:11,790 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44989805221557616, 'Total loss': 0.44989805221557616} | train loss {'Reaction outcome loss': 0.18057823384288643, 'Total loss': 0.18057823384288643}
2023-01-04 02:16:11,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:11,790 INFO:     Epoch: 97
2023-01-04 02:16:13,384 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4482130527496338, 'Total loss': 0.4482130527496338} | train loss {'Reaction outcome loss': 0.1832390763202979, 'Total loss': 0.1832390763202979}
2023-01-04 02:16:13,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:13,385 INFO:     Epoch: 98
2023-01-04 02:16:14,983 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47190953691800436, 'Total loss': 0.47190953691800436} | train loss {'Reaction outcome loss': 0.19502249715235626, 'Total loss': 0.19502249715235626}
2023-01-04 02:16:14,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:14,984 INFO:     Epoch: 99
2023-01-04 02:16:16,608 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44082178076108297, 'Total loss': 0.44082178076108297} | train loss {'Reaction outcome loss': 0.18235705504206556, 'Total loss': 0.18235705504206556}
2023-01-04 02:16:16,608 INFO:     Best model found after epoch 25 of 100.
2023-01-04 02:16:16,608 INFO:   Done with stage: TRAINING
2023-01-04 02:16:16,608 INFO:   Starting stage: EVALUATION
2023-01-04 02:16:16,737 INFO:   Done with stage: EVALUATION
2023-01-04 02:16:16,737 INFO:   Leaving out SEQ value Fold_5
2023-01-04 02:16:16,750 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:16:16,750 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:16:17,400 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:16:17,401 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:16:17,471 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:16:17,471 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:16:17,471 INFO:     No hyperparam tuning for this model
2023-01-04 02:16:17,471 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:16:17,471 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:16:17,472 INFO:     None feature selector for col prot
2023-01-04 02:16:17,472 INFO:     None feature selector for col prot
2023-01-04 02:16:17,472 INFO:     None feature selector for col prot
2023-01-04 02:16:17,473 INFO:     None feature selector for col chem
2023-01-04 02:16:17,473 INFO:     None feature selector for col chem
2023-01-04 02:16:17,473 INFO:     None feature selector for col chem
2023-01-04 02:16:17,473 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:16:17,473 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:16:17,474 INFO:     Number of params in model 70141
2023-01-04 02:16:17,477 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:16:17,477 INFO:   Starting stage: TRAINING
2023-01-04 02:16:17,521 INFO:     Val loss before train {'Reaction outcome loss': 1.014351987838745, 'Total loss': 1.014351987838745}
2023-01-04 02:16:17,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:17,521 INFO:     Epoch: 0
2023-01-04 02:16:19,108 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6692843635876974, 'Total loss': 0.6692843635876974} | train loss {'Reaction outcome loss': 0.8400703458709345, 'Total loss': 0.8400703458709345}
2023-01-04 02:16:19,108 INFO:     Found new best model at epoch 0
2023-01-04 02:16:19,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:19,109 INFO:     Epoch: 1
2023-01-04 02:16:20,706 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5618929326534271, 'Total loss': 0.5618929326534271} | train loss {'Reaction outcome loss': 0.5887288422040318, 'Total loss': 0.5887288422040318}
2023-01-04 02:16:20,706 INFO:     Found new best model at epoch 1
2023-01-04 02:16:20,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:20,707 INFO:     Epoch: 2
2023-01-04 02:16:22,316 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.537346363067627, 'Total loss': 0.537346363067627} | train loss {'Reaction outcome loss': 0.5089532777235128, 'Total loss': 0.5089532777235128}
2023-01-04 02:16:22,316 INFO:     Found new best model at epoch 2
2023-01-04 02:16:22,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:22,317 INFO:     Epoch: 3
2023-01-04 02:16:23,928 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5152500212192536, 'Total loss': 0.5152500212192536} | train loss {'Reaction outcome loss': 0.4714352508347382, 'Total loss': 0.4714352508347382}
2023-01-04 02:16:23,928 INFO:     Found new best model at epoch 3
2023-01-04 02:16:23,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:23,929 INFO:     Epoch: 4
2023-01-04 02:16:25,537 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5031425873438518, 'Total loss': 0.5031425873438518} | train loss {'Reaction outcome loss': 0.4545298435765764, 'Total loss': 0.4545298435765764}
2023-01-04 02:16:25,537 INFO:     Found new best model at epoch 4
2023-01-04 02:16:25,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:25,538 INFO:     Epoch: 5
2023-01-04 02:16:27,099 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5120386362075806, 'Total loss': 0.5120386362075806} | train loss {'Reaction outcome loss': 0.433042648990733, 'Total loss': 0.433042648990733}
2023-01-04 02:16:27,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:27,100 INFO:     Epoch: 6
2023-01-04 02:16:28,687 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48484614888827005, 'Total loss': 0.48484614888827005} | train loss {'Reaction outcome loss': 0.4144640735256067, 'Total loss': 0.4144640735256067}
2023-01-04 02:16:28,687 INFO:     Found new best model at epoch 6
2023-01-04 02:16:28,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:28,688 INFO:     Epoch: 7
2023-01-04 02:16:30,273 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4984000245730082, 'Total loss': 0.4984000245730082} | train loss {'Reaction outcome loss': 0.39887090351270593, 'Total loss': 0.39887090351270593}
2023-01-04 02:16:30,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:30,273 INFO:     Epoch: 8
2023-01-04 02:16:31,867 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48035075267155963, 'Total loss': 0.48035075267155963} | train loss {'Reaction outcome loss': 0.3876106649218802, 'Total loss': 0.3876106649218802}
2023-01-04 02:16:31,867 INFO:     Found new best model at epoch 8
2023-01-04 02:16:31,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:31,868 INFO:     Epoch: 9
2023-01-04 02:16:33,460 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47036653260389966, 'Total loss': 0.47036653260389966} | train loss {'Reaction outcome loss': 0.37758744113228243, 'Total loss': 0.37758744113228243}
2023-01-04 02:16:33,460 INFO:     Found new best model at epoch 9
2023-01-04 02:16:33,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:33,461 INFO:     Epoch: 10
2023-01-04 02:16:35,055 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46931542654832203, 'Total loss': 0.46931542654832203} | train loss {'Reaction outcome loss': 0.3701224070906207, 'Total loss': 0.3701224070906207}
2023-01-04 02:16:35,055 INFO:     Found new best model at epoch 10
2023-01-04 02:16:35,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:35,056 INFO:     Epoch: 11
2023-01-04 02:16:36,632 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.467405433456103, 'Total loss': 0.467405433456103} | train loss {'Reaction outcome loss': 0.3638544974281736, 'Total loss': 0.3638544974281736}
2023-01-04 02:16:36,632 INFO:     Found new best model at epoch 11
2023-01-04 02:16:36,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:36,633 INFO:     Epoch: 12
2023-01-04 02:16:38,246 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46529521147410074, 'Total loss': 0.46529521147410074} | train loss {'Reaction outcome loss': 0.35295428289606684, 'Total loss': 0.35295428289606684}
2023-01-04 02:16:38,246 INFO:     Found new best model at epoch 12
2023-01-04 02:16:38,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:38,247 INFO:     Epoch: 13
2023-01-04 02:16:39,839 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46867827475070956, 'Total loss': 0.46867827475070956} | train loss {'Reaction outcome loss': 0.34378787968307734, 'Total loss': 0.34378787968307734}
2023-01-04 02:16:39,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:39,840 INFO:     Epoch: 14
2023-01-04 02:16:41,427 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47410015066464745, 'Total loss': 0.47410015066464745} | train loss {'Reaction outcome loss': 0.33676050418728043, 'Total loss': 0.33676050418728043}
2023-01-04 02:16:41,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:41,428 INFO:     Epoch: 15
2023-01-04 02:16:43,012 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45417168041070305, 'Total loss': 0.45417168041070305} | train loss {'Reaction outcome loss': 0.3320763137084398, 'Total loss': 0.3320763137084398}
2023-01-04 02:16:43,012 INFO:     Found new best model at epoch 15
2023-01-04 02:16:43,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:43,013 INFO:     Epoch: 16
2023-01-04 02:16:44,596 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44013503988583885, 'Total loss': 0.44013503988583885} | train loss {'Reaction outcome loss': 0.3252127621950501, 'Total loss': 0.3252127621950501}
2023-01-04 02:16:44,597 INFO:     Found new best model at epoch 16
2023-01-04 02:16:44,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:44,598 INFO:     Epoch: 17
2023-01-04 02:16:46,209 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4462447722752889, 'Total loss': 0.4462447722752889} | train loss {'Reaction outcome loss': 0.32197455386968626, 'Total loss': 0.32197455386968626}
2023-01-04 02:16:46,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:46,209 INFO:     Epoch: 18
2023-01-04 02:16:47,804 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43811217645804085, 'Total loss': 0.43811217645804085} | train loss {'Reaction outcome loss': 0.31465540617110505, 'Total loss': 0.31465540617110505}
2023-01-04 02:16:47,804 INFO:     Found new best model at epoch 18
2023-01-04 02:16:47,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:47,805 INFO:     Epoch: 19
2023-01-04 02:16:49,421 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4651955823103587, 'Total loss': 0.4651955823103587} | train loss {'Reaction outcome loss': 0.31021535466762556, 'Total loss': 0.31021535466762556}
2023-01-04 02:16:49,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:49,422 INFO:     Epoch: 20
2023-01-04 02:16:51,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45152397553126017, 'Total loss': 0.45152397553126017} | train loss {'Reaction outcome loss': 0.3050838442682963, 'Total loss': 0.3050838442682963}
2023-01-04 02:16:51,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:51,045 INFO:     Epoch: 21
2023-01-04 02:16:52,624 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4511339604854584, 'Total loss': 0.4511339604854584} | train loss {'Reaction outcome loss': 0.2979777584690094, 'Total loss': 0.2979777584690094}
2023-01-04 02:16:52,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:52,625 INFO:     Epoch: 22
2023-01-04 02:16:54,217 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44110785524050394, 'Total loss': 0.44110785524050394} | train loss {'Reaction outcome loss': 0.29422814151410526, 'Total loss': 0.29422814151410526}
2023-01-04 02:16:54,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:54,218 INFO:     Epoch: 23
2023-01-04 02:16:55,842 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44898215134938557, 'Total loss': 0.44898215134938557} | train loss {'Reaction outcome loss': 0.28922248657867045, 'Total loss': 0.28922248657867045}
2023-01-04 02:16:55,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:55,842 INFO:     Epoch: 24
2023-01-04 02:16:57,444 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44732372562090555, 'Total loss': 0.44732372562090555} | train loss {'Reaction outcome loss': 0.28788805977387383, 'Total loss': 0.28788805977387383}
2023-01-04 02:16:57,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:57,444 INFO:     Epoch: 25
2023-01-04 02:16:59,056 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4527621408303579, 'Total loss': 0.4527621408303579} | train loss {'Reaction outcome loss': 0.28306012607409037, 'Total loss': 0.28306012607409037}
2023-01-04 02:16:59,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:16:59,057 INFO:     Epoch: 26
2023-01-04 02:17:00,684 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46320224603017174, 'Total loss': 0.46320224603017174} | train loss {'Reaction outcome loss': 0.2793875525341086, 'Total loss': 0.2793875525341086}
2023-01-04 02:17:00,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:00,684 INFO:     Epoch: 27
2023-01-04 02:17:02,313 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43574030001958214, 'Total loss': 0.43574030001958214} | train loss {'Reaction outcome loss': 0.27721937820382847, 'Total loss': 0.27721937820382847}
2023-01-04 02:17:02,313 INFO:     Found new best model at epoch 27
2023-01-04 02:17:02,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:02,314 INFO:     Epoch: 28
2023-01-04 02:17:03,887 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4340106676022212, 'Total loss': 0.4340106676022212} | train loss {'Reaction outcome loss': 0.2707895143244389, 'Total loss': 0.2707895143244389}
2023-01-04 02:17:03,888 INFO:     Found new best model at epoch 28
2023-01-04 02:17:03,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:03,889 INFO:     Epoch: 29
2023-01-04 02:17:05,464 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4472340762615204, 'Total loss': 0.4472340762615204} | train loss {'Reaction outcome loss': 0.2688471257173713, 'Total loss': 0.2688471257173713}
2023-01-04 02:17:05,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:05,464 INFO:     Epoch: 30
2023-01-04 02:17:07,075 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4388150235017141, 'Total loss': 0.4388150235017141} | train loss {'Reaction outcome loss': 0.26660132585970714, 'Total loss': 0.26660132585970714}
2023-01-04 02:17:07,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:07,075 INFO:     Epoch: 31
2023-01-04 02:17:08,705 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4265729248523712, 'Total loss': 0.4265729248523712} | train loss {'Reaction outcome loss': 0.25984440334592573, 'Total loss': 0.25984440334592573}
2023-01-04 02:17:08,706 INFO:     Found new best model at epoch 31
2023-01-04 02:17:08,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:08,707 INFO:     Epoch: 32
2023-01-04 02:17:10,293 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.430245969692866, 'Total loss': 0.430245969692866} | train loss {'Reaction outcome loss': 0.25805431679970975, 'Total loss': 0.25805431679970975}
2023-01-04 02:17:10,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:10,293 INFO:     Epoch: 33
2023-01-04 02:17:11,898 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4352749913930893, 'Total loss': 0.4352749913930893} | train loss {'Reaction outcome loss': 0.2545804611046164, 'Total loss': 0.2545804611046164}
2023-01-04 02:17:11,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:11,898 INFO:     Epoch: 34
2023-01-04 02:17:13,524 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42917076249917346, 'Total loss': 0.42917076249917346} | train loss {'Reaction outcome loss': 0.25416972851920605, 'Total loss': 0.25416972851920605}
2023-01-04 02:17:13,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:13,524 INFO:     Epoch: 35
2023-01-04 02:17:15,104 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44810168743133544, 'Total loss': 0.44810168743133544} | train loss {'Reaction outcome loss': 0.2517419989107757, 'Total loss': 0.2517419989107757}
2023-01-04 02:17:15,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:15,105 INFO:     Epoch: 36
2023-01-04 02:17:16,725 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4357627362012863, 'Total loss': 0.4357627362012863} | train loss {'Reaction outcome loss': 0.24977566617662492, 'Total loss': 0.24977566617662492}
2023-01-04 02:17:16,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:16,726 INFO:     Epoch: 37
2023-01-04 02:17:18,323 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42838701605796814, 'Total loss': 0.42838701605796814} | train loss {'Reaction outcome loss': 0.24848968732555438, 'Total loss': 0.24848968732555438}
2023-01-04 02:17:18,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:18,323 INFO:     Epoch: 38
2023-01-04 02:17:19,923 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4617279986540476, 'Total loss': 0.4617279986540476} | train loss {'Reaction outcome loss': 0.24275080494935272, 'Total loss': 0.24275080494935272}
2023-01-04 02:17:19,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:19,924 INFO:     Epoch: 39
2023-01-04 02:17:21,510 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4608124891916911, 'Total loss': 0.4608124891916911} | train loss {'Reaction outcome loss': 0.24044840367834852, 'Total loss': 0.24044840367834852}
2023-01-04 02:17:21,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:21,510 INFO:     Epoch: 40
2023-01-04 02:17:23,137 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43747564951578777, 'Total loss': 0.43747564951578777} | train loss {'Reaction outcome loss': 0.23905690391615464, 'Total loss': 0.23905690391615464}
2023-01-04 02:17:23,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:23,137 INFO:     Epoch: 41
2023-01-04 02:17:24,738 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44212976296742756, 'Total loss': 0.44212976296742756} | train loss {'Reaction outcome loss': 0.2369574585835031, 'Total loss': 0.2369574585835031}
2023-01-04 02:17:24,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:24,738 INFO:     Epoch: 42
2023-01-04 02:17:26,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4526761740446091, 'Total loss': 0.4526761740446091} | train loss {'Reaction outcome loss': 0.2365055337575251, 'Total loss': 0.2365055337575251}
2023-01-04 02:17:26,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:26,361 INFO:     Epoch: 43
2023-01-04 02:17:27,991 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.438543027639389, 'Total loss': 0.438543027639389} | train loss {'Reaction outcome loss': 0.23177275322677157, 'Total loss': 0.23177275322677157}
2023-01-04 02:17:27,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:27,992 INFO:     Epoch: 44
2023-01-04 02:17:29,612 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.433562866350015, 'Total loss': 0.433562866350015} | train loss {'Reaction outcome loss': 0.2316389727913201, 'Total loss': 0.2316389727913201}
2023-01-04 02:17:29,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:29,613 INFO:     Epoch: 45
2023-01-04 02:17:31,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43020317057768503, 'Total loss': 0.43020317057768503} | train loss {'Reaction outcome loss': 0.2303662993343366, 'Total loss': 0.2303662993343366}
2023-01-04 02:17:31,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:31,212 INFO:     Epoch: 46
2023-01-04 02:17:32,820 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45491992831230166, 'Total loss': 0.45491992831230166} | train loss {'Reaction outcome loss': 0.22517537706217822, 'Total loss': 0.22517537706217822}
2023-01-04 02:17:32,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:32,820 INFO:     Epoch: 47
2023-01-04 02:17:34,443 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.434855263431867, 'Total loss': 0.434855263431867} | train loss {'Reaction outcome loss': 0.2271856205205541, 'Total loss': 0.2271856205205541}
2023-01-04 02:17:34,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:34,443 INFO:     Epoch: 48
2023-01-04 02:17:36,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4512646396954854, 'Total loss': 0.4512646396954854} | train loss {'Reaction outcome loss': 0.22512312723404687, 'Total loss': 0.22512312723404687}
2023-01-04 02:17:36,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:36,076 INFO:     Epoch: 49
2023-01-04 02:17:37,728 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4573583702246348, 'Total loss': 0.4573583702246348} | train loss {'Reaction outcome loss': 0.22052752365572445, 'Total loss': 0.22052752365572445}
2023-01-04 02:17:37,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:37,728 INFO:     Epoch: 50
2023-01-04 02:17:39,336 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46391626000404357, 'Total loss': 0.46391626000404357} | train loss {'Reaction outcome loss': 0.21955199438430692, 'Total loss': 0.21955199438430692}
2023-01-04 02:17:39,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:39,337 INFO:     Epoch: 51
2023-01-04 02:17:40,935 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46014487445354463, 'Total loss': 0.46014487445354463} | train loss {'Reaction outcome loss': 0.21980379594829108, 'Total loss': 0.21980379594829108}
2023-01-04 02:17:40,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:40,935 INFO:     Epoch: 52
2023-01-04 02:17:42,517 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4452712853749593, 'Total loss': 0.4452712853749593} | train loss {'Reaction outcome loss': 0.21695893227049542, 'Total loss': 0.21695893227049542}
2023-01-04 02:17:42,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:42,517 INFO:     Epoch: 53
2023-01-04 02:17:44,116 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45498296519120535, 'Total loss': 0.45498296519120535} | train loss {'Reaction outcome loss': 0.21339096387922493, 'Total loss': 0.21339096387922493}
2023-01-04 02:17:44,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:44,116 INFO:     Epoch: 54
2023-01-04 02:17:45,715 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4485850691795349, 'Total loss': 0.4485850691795349} | train loss {'Reaction outcome loss': 0.21390958363865165, 'Total loss': 0.21390958363865165}
2023-01-04 02:17:45,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:45,715 INFO:     Epoch: 55
2023-01-04 02:17:47,316 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4722784583767255, 'Total loss': 0.4722784583767255} | train loss {'Reaction outcome loss': 0.21280140503264536, 'Total loss': 0.21280140503264536}
2023-01-04 02:17:47,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:47,316 INFO:     Epoch: 56
2023-01-04 02:17:48,909 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45877162118752796, 'Total loss': 0.45877162118752796} | train loss {'Reaction outcome loss': 0.20885603421913032, 'Total loss': 0.20885603421913032}
2023-01-04 02:17:48,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:48,909 INFO:     Epoch: 57
2023-01-04 02:17:50,530 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.456756047407786, 'Total loss': 0.456756047407786} | train loss {'Reaction outcome loss': 0.21137885105512713, 'Total loss': 0.21137885105512713}
2023-01-04 02:17:50,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:50,531 INFO:     Epoch: 58
2023-01-04 02:17:52,114 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4645402004321416, 'Total loss': 0.4645402004321416} | train loss {'Reaction outcome loss': 0.2177241727445305, 'Total loss': 0.2177241727445305}
2023-01-04 02:17:52,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:52,114 INFO:     Epoch: 59
2023-01-04 02:17:53,727 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4657441973686218, 'Total loss': 0.4657441973686218} | train loss {'Reaction outcome loss': 0.20679901777718138, 'Total loss': 0.20679901777718138}
2023-01-04 02:17:53,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:53,727 INFO:     Epoch: 60
2023-01-04 02:17:55,352 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45029467244942983, 'Total loss': 0.45029467244942983} | train loss {'Reaction outcome loss': 0.20536898048189672, 'Total loss': 0.20536898048189672}
2023-01-04 02:17:55,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:55,352 INFO:     Epoch: 61
2023-01-04 02:17:56,965 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46675255000591276, 'Total loss': 0.46675255000591276} | train loss {'Reaction outcome loss': 0.20327225323737788, 'Total loss': 0.20327225323737788}
2023-01-04 02:17:56,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:56,966 INFO:     Epoch: 62
2023-01-04 02:17:58,552 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44085802634557086, 'Total loss': 0.44085802634557086} | train loss {'Reaction outcome loss': 0.20212839871090552, 'Total loss': 0.20212839871090552}
2023-01-04 02:17:58,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:17:58,552 INFO:     Epoch: 63
2023-01-04 02:18:00,144 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.449203360080719, 'Total loss': 0.449203360080719} | train loss {'Reaction outcome loss': 0.2094861979636809, 'Total loss': 0.2094861979636809}
2023-01-04 02:18:00,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:00,145 INFO:     Epoch: 64
2023-01-04 02:18:01,737 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4358029921849569, 'Total loss': 0.4358029921849569} | train loss {'Reaction outcome loss': 0.2121527848931441, 'Total loss': 0.2121527848931441}
2023-01-04 02:18:01,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:01,737 INFO:     Epoch: 65
2023-01-04 02:18:03,329 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47251483996709187, 'Total loss': 0.47251483996709187} | train loss {'Reaction outcome loss': 0.19888074717322446, 'Total loss': 0.19888074717322446}
2023-01-04 02:18:03,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:03,330 INFO:     Epoch: 66
2023-01-04 02:18:04,916 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45330708622932436, 'Total loss': 0.45330708622932436} | train loss {'Reaction outcome loss': 0.19818352839312234, 'Total loss': 0.19818352839312234}
2023-01-04 02:18:04,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:04,916 INFO:     Epoch: 67
2023-01-04 02:18:06,518 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45760782609383266, 'Total loss': 0.45760782609383266} | train loss {'Reaction outcome loss': 0.1980283783505792, 'Total loss': 0.1980283783505792}
2023-01-04 02:18:06,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:06,519 INFO:     Epoch: 68
2023-01-04 02:18:08,129 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4730390340089798, 'Total loss': 0.4730390340089798} | train loss {'Reaction outcome loss': 0.2000082167999252, 'Total loss': 0.2000082167999252}
2023-01-04 02:18:08,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:08,130 INFO:     Epoch: 69
2023-01-04 02:18:09,748 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4565842847029368, 'Total loss': 0.4565842847029368} | train loss {'Reaction outcome loss': 0.2028608021277435, 'Total loss': 0.2028608021277435}
2023-01-04 02:18:09,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:09,749 INFO:     Epoch: 70
2023-01-04 02:18:11,390 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46317317883173625, 'Total loss': 0.46317317883173625} | train loss {'Reaction outcome loss': 0.19371635045689656, 'Total loss': 0.19371635045689656}
2023-01-04 02:18:11,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:11,390 INFO:     Epoch: 71
2023-01-04 02:18:13,005 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4760270953178406, 'Total loss': 0.4760270953178406} | train loss {'Reaction outcome loss': 0.19674280576029982, 'Total loss': 0.19674280576029982}
2023-01-04 02:18:13,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:13,005 INFO:     Epoch: 72
2023-01-04 02:18:14,630 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4772789855798086, 'Total loss': 0.4772789855798086} | train loss {'Reaction outcome loss': 0.2155009008711204, 'Total loss': 0.2155009008711204}
2023-01-04 02:18:14,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:14,630 INFO:     Epoch: 73
2023-01-04 02:18:16,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4796668469905853, 'Total loss': 0.4796668469905853} | train loss {'Reaction outcome loss': 0.19119529792721773, 'Total loss': 0.19119529792721773}
2023-01-04 02:18:16,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:16,229 INFO:     Epoch: 74
2023-01-04 02:18:17,827 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4518738796313604, 'Total loss': 0.4518738796313604} | train loss {'Reaction outcome loss': 0.18743368999254756, 'Total loss': 0.18743368999254756}
2023-01-04 02:18:17,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:17,827 INFO:     Epoch: 75
2023-01-04 02:18:19,447 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.485565115014712, 'Total loss': 0.485565115014712} | train loss {'Reaction outcome loss': 0.1876573088693608, 'Total loss': 0.1876573088693608}
2023-01-04 02:18:19,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:19,447 INFO:     Epoch: 76
2023-01-04 02:18:21,067 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4567866345246633, 'Total loss': 0.4567866345246633} | train loss {'Reaction outcome loss': 0.18682660231022147, 'Total loss': 0.18682660231022147}
2023-01-04 02:18:21,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:21,068 INFO:     Epoch: 77
2023-01-04 02:18:22,690 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4553229073683421, 'Total loss': 0.4553229073683421} | train loss {'Reaction outcome loss': 0.1862478296805394, 'Total loss': 0.1862478296805394}
2023-01-04 02:18:22,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:22,691 INFO:     Epoch: 78
2023-01-04 02:18:24,297 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47375559707482656, 'Total loss': 0.47375559707482656} | train loss {'Reaction outcome loss': 0.18679134188678817, 'Total loss': 0.18679134188678817}
2023-01-04 02:18:24,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:24,297 INFO:     Epoch: 79
2023-01-04 02:18:25,927 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47533766825993856, 'Total loss': 0.47533766825993856} | train loss {'Reaction outcome loss': 0.1897521879369194, 'Total loss': 0.1897521879369194}
2023-01-04 02:18:25,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:25,927 INFO:     Epoch: 80
2023-01-04 02:18:27,527 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.482063090801239, 'Total loss': 0.482063090801239} | train loss {'Reaction outcome loss': 0.18496911948465783, 'Total loss': 0.18496911948465783}
2023-01-04 02:18:27,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:27,528 INFO:     Epoch: 81
2023-01-04 02:18:29,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4688752869764964, 'Total loss': 0.4688752869764964} | train loss {'Reaction outcome loss': 0.18300138300887542, 'Total loss': 0.18300138300887542}
2023-01-04 02:18:29,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:29,139 INFO:     Epoch: 82
2023-01-04 02:18:30,752 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4598710109790166, 'Total loss': 0.4598710109790166} | train loss {'Reaction outcome loss': 0.18310812262975756, 'Total loss': 0.18310812262975756}
2023-01-04 02:18:30,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:30,752 INFO:     Epoch: 83
2023-01-04 02:18:32,386 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47771860361099244, 'Total loss': 0.47771860361099244} | train loss {'Reaction outcome loss': 0.182272304965211, 'Total loss': 0.182272304965211}
2023-01-04 02:18:32,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:32,386 INFO:     Epoch: 84
2023-01-04 02:18:33,982 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47155375679334005, 'Total loss': 0.47155375679334005} | train loss {'Reaction outcome loss': 0.18162373401115436, 'Total loss': 0.18162373401115436}
2023-01-04 02:18:33,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:33,982 INFO:     Epoch: 85
2023-01-04 02:18:35,603 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46088518351316454, 'Total loss': 0.46088518351316454} | train loss {'Reaction outcome loss': 0.18201515481843566, 'Total loss': 0.18201515481843566}
2023-01-04 02:18:35,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:35,603 INFO:     Epoch: 86
2023-01-04 02:18:37,195 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46293068726857506, 'Total loss': 0.46293068726857506} | train loss {'Reaction outcome loss': 0.17971412416385568, 'Total loss': 0.17971412416385568}
2023-01-04 02:18:37,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:37,195 INFO:     Epoch: 87
2023-01-04 02:18:38,818 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48781805833180747, 'Total loss': 0.48781805833180747} | train loss {'Reaction outcome loss': 0.179713356360098, 'Total loss': 0.179713356360098}
2023-01-04 02:18:38,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:38,819 INFO:     Epoch: 88
2023-01-04 02:18:40,437 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5006798774003982, 'Total loss': 0.5006798774003982} | train loss {'Reaction outcome loss': 0.17889608504871526, 'Total loss': 0.17889608504871526}
2023-01-04 02:18:40,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:40,438 INFO:     Epoch: 89
2023-01-04 02:18:42,054 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4939275324344635, 'Total loss': 0.4939275324344635} | train loss {'Reaction outcome loss': 0.18082800405882418, 'Total loss': 0.18082800405882418}
2023-01-04 02:18:42,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:42,054 INFO:     Epoch: 90
2023-01-04 02:18:43,655 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.447946764032046, 'Total loss': 0.447946764032046} | train loss {'Reaction outcome loss': 0.1764723256481744, 'Total loss': 0.1764723256481744}
2023-01-04 02:18:43,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:43,655 INFO:     Epoch: 91
2023-01-04 02:18:45,250 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4805516799290975, 'Total loss': 0.4805516799290975} | train loss {'Reaction outcome loss': 0.1768034481184272, 'Total loss': 0.1768034481184272}
2023-01-04 02:18:45,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:45,250 INFO:     Epoch: 92
2023-01-04 02:18:46,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48340047200520836, 'Total loss': 0.48340047200520836} | train loss {'Reaction outcome loss': 0.17762921861891048, 'Total loss': 0.17762921861891048}
2023-01-04 02:18:46,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:46,863 INFO:     Epoch: 93
2023-01-04 02:18:48,470 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47436402440071107, 'Total loss': 0.47436402440071107} | train loss {'Reaction outcome loss': 0.17516257948530742, 'Total loss': 0.17516257948530742}
2023-01-04 02:18:48,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:48,471 INFO:     Epoch: 94
2023-01-04 02:18:50,080 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4660124838352203, 'Total loss': 0.4660124838352203} | train loss {'Reaction outcome loss': 0.17597558678708214, 'Total loss': 0.17597558678708214}
2023-01-04 02:18:50,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:50,081 INFO:     Epoch: 95
2023-01-04 02:18:51,676 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4732181052366892, 'Total loss': 0.4732181052366892} | train loss {'Reaction outcome loss': 0.1751134028404806, 'Total loss': 0.1751134028404806}
2023-01-04 02:18:51,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:51,677 INFO:     Epoch: 96
2023-01-04 02:18:53,295 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5345626950263977, 'Total loss': 0.5345626950263977} | train loss {'Reaction outcome loss': 0.17643138363759583, 'Total loss': 0.17643138363759583}
2023-01-04 02:18:53,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:53,296 INFO:     Epoch: 97
2023-01-04 02:18:54,893 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4835371603568395, 'Total loss': 0.4835371603568395} | train loss {'Reaction outcome loss': 0.1741076875815465, 'Total loss': 0.1741076875815465}
2023-01-04 02:18:54,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:54,893 INFO:     Epoch: 98
2023-01-04 02:18:56,515 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5156490067640941, 'Total loss': 0.5156490067640941} | train loss {'Reaction outcome loss': 0.17250841368134032, 'Total loss': 0.17250841368134032}
2023-01-04 02:18:56,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:56,515 INFO:     Epoch: 99
2023-01-04 02:18:58,135 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47961404323577883, 'Total loss': 0.47961404323577883} | train loss {'Reaction outcome loss': 0.17132895682479485, 'Total loss': 0.17132895682479485}
2023-01-04 02:18:58,135 INFO:     Best model found after epoch 32 of 100.
2023-01-04 02:18:58,136 INFO:   Done with stage: TRAINING
2023-01-04 02:18:58,136 INFO:   Starting stage: EVALUATION
2023-01-04 02:18:58,263 INFO:   Done with stage: EVALUATION
2023-01-04 02:18:58,263 INFO:   Leaving out SEQ value Fold_6
2023-01-04 02:18:58,276 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 02:18:58,276 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:18:58,927 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:18:58,927 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:18:58,996 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:18:58,996 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:18:58,996 INFO:     No hyperparam tuning for this model
2023-01-04 02:18:58,996 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:18:58,996 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:18:58,997 INFO:     None feature selector for col prot
2023-01-04 02:18:58,997 INFO:     None feature selector for col prot
2023-01-04 02:18:58,997 INFO:     None feature selector for col prot
2023-01-04 02:18:58,998 INFO:     None feature selector for col chem
2023-01-04 02:18:58,998 INFO:     None feature selector for col chem
2023-01-04 02:18:58,998 INFO:     None feature selector for col chem
2023-01-04 02:18:58,998 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:18:58,998 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:18:58,999 INFO:     Number of params in model 70141
2023-01-04 02:18:59,002 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:18:59,002 INFO:   Starting stage: TRAINING
2023-01-04 02:18:59,045 INFO:     Val loss before train {'Reaction outcome loss': 0.9475262403488159, 'Total loss': 0.9475262403488159}
2023-01-04 02:18:59,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:18:59,046 INFO:     Epoch: 0
2023-01-04 02:19:00,652 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.720577355225881, 'Total loss': 0.720577355225881} | train loss {'Reaction outcome loss': 0.8682848932725858, 'Total loss': 0.8682848932725858}
2023-01-04 02:19:00,652 INFO:     Found new best model at epoch 0
2023-01-04 02:19:00,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:00,653 INFO:     Epoch: 1
2023-01-04 02:19:02,280 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5753420134385426, 'Total loss': 0.5753420134385426} | train loss {'Reaction outcome loss': 0.6214382801245266, 'Total loss': 0.6214382801245266}
2023-01-04 02:19:02,281 INFO:     Found new best model at epoch 1
2023-01-04 02:19:02,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:02,281 INFO:     Epoch: 2
2023-01-04 02:19:03,867 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5197270929813385, 'Total loss': 0.5197270929813385} | train loss {'Reaction outcome loss': 0.534349416137172, 'Total loss': 0.534349416137172}
2023-01-04 02:19:03,868 INFO:     Found new best model at epoch 2
2023-01-04 02:19:03,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:03,868 INFO:     Epoch: 3
2023-01-04 02:19:05,491 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4850274215141932, 'Total loss': 0.4850274215141932} | train loss {'Reaction outcome loss': 0.4908036035535998, 'Total loss': 0.4908036035535998}
2023-01-04 02:19:05,491 INFO:     Found new best model at epoch 3
2023-01-04 02:19:05,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:05,492 INFO:     Epoch: 4
2023-01-04 02:19:07,098 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4812143425146739, 'Total loss': 0.4812143425146739} | train loss {'Reaction outcome loss': 0.4633085260752736, 'Total loss': 0.4633085260752736}
2023-01-04 02:19:07,098 INFO:     Found new best model at epoch 4
2023-01-04 02:19:07,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:07,099 INFO:     Epoch: 5
2023-01-04 02:19:08,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4665921946366628, 'Total loss': 0.4665921946366628} | train loss {'Reaction outcome loss': 0.444218061191941, 'Total loss': 0.444218061191941}
2023-01-04 02:19:08,699 INFO:     Found new best model at epoch 5
2023-01-04 02:19:08,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:08,700 INFO:     Epoch: 6
2023-01-04 02:19:10,321 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45840259989102683, 'Total loss': 0.45840259989102683} | train loss {'Reaction outcome loss': 0.4264235336212475, 'Total loss': 0.4264235336212475}
2023-01-04 02:19:10,322 INFO:     Found new best model at epoch 6
2023-01-04 02:19:10,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:10,323 INFO:     Epoch: 7
2023-01-04 02:19:11,911 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45296260714530945, 'Total loss': 0.45296260714530945} | train loss {'Reaction outcome loss': 0.41296635272270504, 'Total loss': 0.41296635272270504}
2023-01-04 02:19:11,911 INFO:     Found new best model at epoch 7
2023-01-04 02:19:11,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:11,912 INFO:     Epoch: 8
2023-01-04 02:19:13,512 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4598514258861542, 'Total loss': 0.4598514258861542} | train loss {'Reaction outcome loss': 0.4001632252378584, 'Total loss': 0.4001632252378584}
2023-01-04 02:19:13,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:13,513 INFO:     Epoch: 9
2023-01-04 02:19:15,115 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4340240975220998, 'Total loss': 0.4340240975220998} | train loss {'Reaction outcome loss': 0.39056898852548017, 'Total loss': 0.39056898852548017}
2023-01-04 02:19:15,115 INFO:     Found new best model at epoch 9
2023-01-04 02:19:15,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:15,116 INFO:     Epoch: 10
2023-01-04 02:19:16,718 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43096161584059395, 'Total loss': 0.43096161584059395} | train loss {'Reaction outcome loss': 0.38029383467207745, 'Total loss': 0.38029383467207745}
2023-01-04 02:19:16,718 INFO:     Found new best model at epoch 10
2023-01-04 02:19:16,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:16,719 INFO:     Epoch: 11
2023-01-04 02:19:18,309 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41464559932549794, 'Total loss': 0.41464559932549794} | train loss {'Reaction outcome loss': 0.3717491228657939, 'Total loss': 0.3717491228657939}
2023-01-04 02:19:18,309 INFO:     Found new best model at epoch 11
2023-01-04 02:19:18,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:18,310 INFO:     Epoch: 12
2023-01-04 02:19:19,945 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.433007276058197, 'Total loss': 0.433007276058197} | train loss {'Reaction outcome loss': 0.36461992884586003, 'Total loss': 0.36461992884586003}
2023-01-04 02:19:19,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:19,945 INFO:     Epoch: 13
2023-01-04 02:19:21,540 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41836118598779043, 'Total loss': 0.41836118598779043} | train loss {'Reaction outcome loss': 0.35763884674663576, 'Total loss': 0.35763884674663576}
2023-01-04 02:19:21,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:21,540 INFO:     Epoch: 14
2023-01-04 02:19:23,173 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43155023256937664, 'Total loss': 0.43155023256937664} | train loss {'Reaction outcome loss': 0.34826871755428696, 'Total loss': 0.34826871755428696}
2023-01-04 02:19:23,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:23,174 INFO:     Epoch: 15
2023-01-04 02:19:24,804 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4261162459850311, 'Total loss': 0.4261162459850311} | train loss {'Reaction outcome loss': 0.34342154405930414, 'Total loss': 0.34342154405930414}
2023-01-04 02:19:24,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:24,804 INFO:     Epoch: 16
2023-01-04 02:19:26,433 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4184540728727976, 'Total loss': 0.4184540728727976} | train loss {'Reaction outcome loss': 0.33555995334033933, 'Total loss': 0.33555995334033933}
2023-01-04 02:19:26,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:26,433 INFO:     Epoch: 17
2023-01-04 02:19:28,014 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41402640342712405, 'Total loss': 0.41402640342712405} | train loss {'Reaction outcome loss': 0.33066592432746816, 'Total loss': 0.33066592432746816}
2023-01-04 02:19:28,014 INFO:     Found new best model at epoch 17
2023-01-04 02:19:28,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:28,015 INFO:     Epoch: 18
2023-01-04 02:19:29,613 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41054365237553914, 'Total loss': 0.41054365237553914} | train loss {'Reaction outcome loss': 0.32584224708566595, 'Total loss': 0.32584224708566595}
2023-01-04 02:19:29,614 INFO:     Found new best model at epoch 18
2023-01-04 02:19:29,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:29,615 INFO:     Epoch: 19
2023-01-04 02:19:31,244 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40799562633037567, 'Total loss': 0.40799562633037567} | train loss {'Reaction outcome loss': 0.3209655752627428, 'Total loss': 0.3209655752627428}
2023-01-04 02:19:31,244 INFO:     Found new best model at epoch 19
2023-01-04 02:19:31,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:31,245 INFO:     Epoch: 20
2023-01-04 02:19:32,852 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4046544353167216, 'Total loss': 0.4046544353167216} | train loss {'Reaction outcome loss': 0.3149204568850004, 'Total loss': 0.3149204568850004}
2023-01-04 02:19:32,853 INFO:     Found new best model at epoch 20
2023-01-04 02:19:32,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:32,854 INFO:     Epoch: 21
2023-01-04 02:19:34,450 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4098921060562134, 'Total loss': 0.4098921060562134} | train loss {'Reaction outcome loss': 0.3112859929834462, 'Total loss': 0.3112859929834462}
2023-01-04 02:19:34,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:34,450 INFO:     Epoch: 22
2023-01-04 02:19:36,030 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40334968864917753, 'Total loss': 0.40334968864917753} | train loss {'Reaction outcome loss': 0.3079635570572171, 'Total loss': 0.3079635570572171}
2023-01-04 02:19:36,030 INFO:     Found new best model at epoch 22
2023-01-04 02:19:36,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:36,031 INFO:     Epoch: 23
2023-01-04 02:19:37,657 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4109533250331879, 'Total loss': 0.4109533250331879} | train loss {'Reaction outcome loss': 0.29984518519807807, 'Total loss': 0.29984518519807807}
2023-01-04 02:19:37,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:37,657 INFO:     Epoch: 24
2023-01-04 02:19:39,023 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4098731855551402, 'Total loss': 0.4098731855551402} | train loss {'Reaction outcome loss': 0.29776861279234557, 'Total loss': 0.29776861279234557}
2023-01-04 02:19:39,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:39,023 INFO:     Epoch: 25
2023-01-04 02:19:40,102 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41000145276387534, 'Total loss': 0.41000145276387534} | train loss {'Reaction outcome loss': 0.29182950095256743, 'Total loss': 0.29182950095256743}
2023-01-04 02:19:40,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:40,102 INFO:     Epoch: 26
2023-01-04 02:19:41,175 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4114795724550883, 'Total loss': 0.4114795724550883} | train loss {'Reaction outcome loss': 0.28957939543341044, 'Total loss': 0.28957939543341044}
2023-01-04 02:19:41,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:41,175 INFO:     Epoch: 27
2023-01-04 02:19:42,249 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39806845784187317, 'Total loss': 0.39806845784187317} | train loss {'Reaction outcome loss': 0.28644568343993126, 'Total loss': 0.28644568343993126}
2023-01-04 02:19:42,250 INFO:     Found new best model at epoch 27
2023-01-04 02:19:42,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:42,250 INFO:     Epoch: 28
2023-01-04 02:19:43,345 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4215912640094757, 'Total loss': 0.4215912640094757} | train loss {'Reaction outcome loss': 0.27995124979731406, 'Total loss': 0.27995124979731406}
2023-01-04 02:19:43,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:43,345 INFO:     Epoch: 29
2023-01-04 02:19:44,938 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41002268592516583, 'Total loss': 0.41002268592516583} | train loss {'Reaction outcome loss': 0.277434881655533, 'Total loss': 0.277434881655533}
2023-01-04 02:19:44,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:44,938 INFO:     Epoch: 30
2023-01-04 02:19:46,553 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40864467322826387, 'Total loss': 0.40864467322826387} | train loss {'Reaction outcome loss': 0.27257132636457143, 'Total loss': 0.27257132636457143}
2023-01-04 02:19:46,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:46,554 INFO:     Epoch: 31
2023-01-04 02:19:48,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4124900698661804, 'Total loss': 0.4124900698661804} | train loss {'Reaction outcome loss': 0.27061067934447247, 'Total loss': 0.27061067934447247}
2023-01-04 02:19:48,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:48,159 INFO:     Epoch: 32
2023-01-04 02:19:49,781 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4202028294404348, 'Total loss': 0.4202028294404348} | train loss {'Reaction outcome loss': 0.26753886143545813, 'Total loss': 0.26753886143545813}
2023-01-04 02:19:49,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:49,781 INFO:     Epoch: 33
2023-01-04 02:19:51,396 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.415243915716807, 'Total loss': 0.415243915716807} | train loss {'Reaction outcome loss': 0.2653297732453054, 'Total loss': 0.2653297732453054}
2023-01-04 02:19:51,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:51,396 INFO:     Epoch: 34
2023-01-04 02:19:52,990 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39711918532848356, 'Total loss': 0.39711918532848356} | train loss {'Reaction outcome loss': 0.26502456541579983, 'Total loss': 0.26502456541579983}
2023-01-04 02:19:52,990 INFO:     Found new best model at epoch 34
2023-01-04 02:19:52,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:52,991 INFO:     Epoch: 35
2023-01-04 02:19:54,590 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.402307207385699, 'Total loss': 0.402307207385699} | train loss {'Reaction outcome loss': 0.25776119909454337, 'Total loss': 0.25776119909454337}
2023-01-04 02:19:54,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:54,590 INFO:     Epoch: 36
2023-01-04 02:19:56,220 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4143633415301641, 'Total loss': 0.4143633415301641} | train loss {'Reaction outcome loss': 0.25656772020276275, 'Total loss': 0.25656772020276275}
2023-01-04 02:19:56,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:56,220 INFO:     Epoch: 37
2023-01-04 02:19:57,849 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41710962653160094, 'Total loss': 0.41710962653160094} | train loss {'Reaction outcome loss': 0.25344972836949764, 'Total loss': 0.25344972836949764}
2023-01-04 02:19:57,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:57,850 INFO:     Epoch: 38
2023-01-04 02:19:59,456 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4305153210957845, 'Total loss': 0.4305153210957845} | train loss {'Reaction outcome loss': 0.2511806596299156, 'Total loss': 0.2511806596299156}
2023-01-04 02:19:59,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:19:59,456 INFO:     Epoch: 39
2023-01-04 02:20:01,063 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.421389361222585, 'Total loss': 0.421389361222585} | train loss {'Reaction outcome loss': 0.2484083981370883, 'Total loss': 0.2484083981370883}
2023-01-04 02:20:01,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:01,063 INFO:     Epoch: 40
2023-01-04 02:20:02,657 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4111328254143397, 'Total loss': 0.4111328254143397} | train loss {'Reaction outcome loss': 0.2454518756765321, 'Total loss': 0.2454518756765321}
2023-01-04 02:20:02,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:02,657 INFO:     Epoch: 41
2023-01-04 02:20:04,258 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4000192095836004, 'Total loss': 0.4000192095836004} | train loss {'Reaction outcome loss': 0.24319334804258622, 'Total loss': 0.24319334804258622}
2023-01-04 02:20:04,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:04,259 INFO:     Epoch: 42
2023-01-04 02:20:05,858 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4151609073082606, 'Total loss': 0.4151609073082606} | train loss {'Reaction outcome loss': 0.24190335129034649, 'Total loss': 0.24190335129034649}
2023-01-04 02:20:05,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:05,859 INFO:     Epoch: 43
2023-01-04 02:20:07,458 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41888544460137683, 'Total loss': 0.41888544460137683} | train loss {'Reaction outcome loss': 0.23916159942746162, 'Total loss': 0.23916159942746162}
2023-01-04 02:20:07,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:07,459 INFO:     Epoch: 44
2023-01-04 02:20:09,058 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.424862003326416, 'Total loss': 0.424862003326416} | train loss {'Reaction outcome loss': 0.2377511303374268, 'Total loss': 0.2377511303374268}
2023-01-04 02:20:09,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:09,058 INFO:     Epoch: 45
2023-01-04 02:20:10,648 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42581773797671, 'Total loss': 0.42581773797671} | train loss {'Reaction outcome loss': 0.23600416231080082, 'Total loss': 0.23600416231080082}
2023-01-04 02:20:10,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:10,648 INFO:     Epoch: 46
2023-01-04 02:20:12,242 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4325200622280439, 'Total loss': 0.4325200622280439} | train loss {'Reaction outcome loss': 0.23469626157803442, 'Total loss': 0.23469626157803442}
2023-01-04 02:20:12,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:12,242 INFO:     Epoch: 47
2023-01-04 02:20:13,865 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.423135773340861, 'Total loss': 0.423135773340861} | train loss {'Reaction outcome loss': 0.23009258539614263, 'Total loss': 0.23009258539614263}
2023-01-04 02:20:13,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:13,866 INFO:     Epoch: 48
2023-01-04 02:20:15,492 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4412387192249298, 'Total loss': 0.4412387192249298} | train loss {'Reaction outcome loss': 0.22913262083965089, 'Total loss': 0.22913262083965089}
2023-01-04 02:20:15,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:15,492 INFO:     Epoch: 49
2023-01-04 02:20:17,123 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4280039290587107, 'Total loss': 0.4280039290587107} | train loss {'Reaction outcome loss': 0.2277036585613063, 'Total loss': 0.2277036585613063}
2023-01-04 02:20:17,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:17,124 INFO:     Epoch: 50
2023-01-04 02:20:18,732 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4504291752974192, 'Total loss': 0.4504291752974192} | train loss {'Reaction outcome loss': 0.22781171957669705, 'Total loss': 0.22781171957669705}
2023-01-04 02:20:18,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:18,733 INFO:     Epoch: 51
2023-01-04 02:20:20,332 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4151051436861356, 'Total loss': 0.4151051436861356} | train loss {'Reaction outcome loss': 0.22287598429819308, 'Total loss': 0.22287598429819308}
2023-01-04 02:20:20,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:20,333 INFO:     Epoch: 52
2023-01-04 02:20:21,936 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4218048016230265, 'Total loss': 0.4218048016230265} | train loss {'Reaction outcome loss': 0.22183408788556658, 'Total loss': 0.22183408788556658}
2023-01-04 02:20:21,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:21,936 INFO:     Epoch: 53
2023-01-04 02:20:23,539 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4207954476277033, 'Total loss': 0.4207954476277033} | train loss {'Reaction outcome loss': 0.22044239837393864, 'Total loss': 0.22044239837393864}
2023-01-04 02:20:23,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:23,540 INFO:     Epoch: 54
2023-01-04 02:20:25,143 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43031765669584277, 'Total loss': 0.43031765669584277} | train loss {'Reaction outcome loss': 0.2188846672269842, 'Total loss': 0.2188846672269842}
2023-01-04 02:20:25,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:25,144 INFO:     Epoch: 55
2023-01-04 02:20:26,748 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.429109517733256, 'Total loss': 0.429109517733256} | train loss {'Reaction outcome loss': 0.21800355981726077, 'Total loss': 0.21800355981726077}
2023-01-04 02:20:26,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:26,749 INFO:     Epoch: 56
2023-01-04 02:20:28,323 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4308091878890991, 'Total loss': 0.4308091878890991} | train loss {'Reaction outcome loss': 0.21627776591033282, 'Total loss': 0.21627776591033282}
2023-01-04 02:20:28,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:28,324 INFO:     Epoch: 57
2023-01-04 02:20:29,910 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4466066390275955, 'Total loss': 0.4466066390275955} | train loss {'Reaction outcome loss': 0.214948022179978, 'Total loss': 0.214948022179978}
2023-01-04 02:20:29,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:29,910 INFO:     Epoch: 58
2023-01-04 02:20:31,539 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4401489496231079, 'Total loss': 0.4401489496231079} | train loss {'Reaction outcome loss': 0.21253608050167777, 'Total loss': 0.21253608050167777}
2023-01-04 02:20:31,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:31,539 INFO:     Epoch: 59
2023-01-04 02:20:33,137 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42402951618035634, 'Total loss': 0.42402951618035634} | train loss {'Reaction outcome loss': 0.21336916302892275, 'Total loss': 0.21336916302892275}
2023-01-04 02:20:33,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:33,138 INFO:     Epoch: 60
2023-01-04 02:20:34,766 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41820560495058695, 'Total loss': 0.41820560495058695} | train loss {'Reaction outcome loss': 0.21012311434164804, 'Total loss': 0.21012311434164804}
2023-01-04 02:20:34,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:34,768 INFO:     Epoch: 61
2023-01-04 02:20:36,340 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4157863974571228, 'Total loss': 0.4157863974571228} | train loss {'Reaction outcome loss': 0.2089920077163605, 'Total loss': 0.2089920077163605}
2023-01-04 02:20:36,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:36,340 INFO:     Epoch: 62
2023-01-04 02:20:37,944 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4299591640631358, 'Total loss': 0.4299591640631358} | train loss {'Reaction outcome loss': 0.2056937907227325, 'Total loss': 0.2056937907227325}
2023-01-04 02:20:37,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:37,944 INFO:     Epoch: 63
2023-01-04 02:20:39,549 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44360330551862714, 'Total loss': 0.44360330551862714} | train loss {'Reaction outcome loss': 0.20526921930000025, 'Total loss': 0.20526921930000025}
2023-01-04 02:20:39,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:39,550 INFO:     Epoch: 64
2023-01-04 02:20:41,156 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44343563814957937, 'Total loss': 0.44343563814957937} | train loss {'Reaction outcome loss': 0.20429950184609055, 'Total loss': 0.20429950184609055}
2023-01-04 02:20:41,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:41,157 INFO:     Epoch: 65
2023-01-04 02:20:42,754 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4397402803103129, 'Total loss': 0.4397402803103129} | train loss {'Reaction outcome loss': 0.20121800310452492, 'Total loss': 0.20121800310452492}
2023-01-04 02:20:42,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:42,754 INFO:     Epoch: 66
2023-01-04 02:20:44,384 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4239505569140116, 'Total loss': 0.4239505569140116} | train loss {'Reaction outcome loss': 0.20365844553988763, 'Total loss': 0.20365844553988763}
2023-01-04 02:20:44,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:44,384 INFO:     Epoch: 67
2023-01-04 02:20:45,991 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4271600609024366, 'Total loss': 0.4271600609024366} | train loss {'Reaction outcome loss': 0.19957157556599658, 'Total loss': 0.19957157556599658}
2023-01-04 02:20:45,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:45,991 INFO:     Epoch: 68
2023-01-04 02:20:47,604 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4492159595092138, 'Total loss': 0.4492159595092138} | train loss {'Reaction outcome loss': 0.20030356447350248, 'Total loss': 0.20030356447350248}
2023-01-04 02:20:47,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:47,605 INFO:     Epoch: 69
2023-01-04 02:20:49,227 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.427224330107371, 'Total loss': 0.427224330107371} | train loss {'Reaction outcome loss': 0.20022026780279964, 'Total loss': 0.20022026780279964}
2023-01-04 02:20:49,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:49,227 INFO:     Epoch: 70
2023-01-04 02:20:50,856 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41558840771516165, 'Total loss': 0.41558840771516165} | train loss {'Reaction outcome loss': 0.19936459782509813, 'Total loss': 0.19936459782509813}
2023-01-04 02:20:50,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:50,856 INFO:     Epoch: 71
2023-01-04 02:20:52,487 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.411149674654007, 'Total loss': 0.411149674654007} | train loss {'Reaction outcome loss': 0.1963954467850902, 'Total loss': 0.1963954467850902}
2023-01-04 02:20:52,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:52,487 INFO:     Epoch: 72
2023-01-04 02:20:54,118 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4270401736100515, 'Total loss': 0.4270401736100515} | train loss {'Reaction outcome loss': 0.19681504534201072, 'Total loss': 0.19681504534201072}
2023-01-04 02:20:54,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:54,119 INFO:     Epoch: 73
2023-01-04 02:20:55,696 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42790023585160575, 'Total loss': 0.42790023585160575} | train loss {'Reaction outcome loss': 0.1934084947143651, 'Total loss': 0.1934084947143651}
2023-01-04 02:20:55,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:55,697 INFO:     Epoch: 74
2023-01-04 02:20:57,324 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4160434861977895, 'Total loss': 0.4160434861977895} | train loss {'Reaction outcome loss': 0.1959409086766656, 'Total loss': 0.1959409086766656}
2023-01-04 02:20:57,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:57,325 INFO:     Epoch: 75
2023-01-04 02:20:58,931 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41492044577995935, 'Total loss': 0.41492044577995935} | train loss {'Reaction outcome loss': 0.1912680757551417, 'Total loss': 0.1912680757551417}
2023-01-04 02:20:58,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:20:58,931 INFO:     Epoch: 76
2023-01-04 02:21:00,540 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4233861496051153, 'Total loss': 0.4233861496051153} | train loss {'Reaction outcome loss': 0.19042824520746293, 'Total loss': 0.19042824520746293}
2023-01-04 02:21:00,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:00,540 INFO:     Epoch: 77
2023-01-04 02:21:02,147 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44111836353937783, 'Total loss': 0.44111836353937783} | train loss {'Reaction outcome loss': 0.1891683734792019, 'Total loss': 0.1891683734792019}
2023-01-04 02:21:02,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:02,148 INFO:     Epoch: 78
2023-01-04 02:21:03,734 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4266363928715388, 'Total loss': 0.4266363928715388} | train loss {'Reaction outcome loss': 0.19194765932293145, 'Total loss': 0.19194765932293145}
2023-01-04 02:21:03,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:03,734 INFO:     Epoch: 79
2023-01-04 02:21:05,335 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42682470083236695, 'Total loss': 0.42682470083236695} | train loss {'Reaction outcome loss': 0.1906580680759375, 'Total loss': 0.1906580680759375}
2023-01-04 02:21:05,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:05,335 INFO:     Epoch: 80
2023-01-04 02:21:06,967 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44387561778227486, 'Total loss': 0.44387561778227486} | train loss {'Reaction outcome loss': 0.18716960517346642, 'Total loss': 0.18716960517346642}
2023-01-04 02:21:06,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:06,967 INFO:     Epoch: 81
2023-01-04 02:21:08,599 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.428042999903361, 'Total loss': 0.428042999903361} | train loss {'Reaction outcome loss': 0.19169259501708544, 'Total loss': 0.19169259501708544}
2023-01-04 02:21:08,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:08,600 INFO:     Epoch: 82
2023-01-04 02:21:10,230 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43312137524286903, 'Total loss': 0.43312137524286903} | train loss {'Reaction outcome loss': 0.18712277780371023, 'Total loss': 0.18712277780371023}
2023-01-04 02:21:10,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:10,231 INFO:     Epoch: 83
2023-01-04 02:21:11,843 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42026220758756, 'Total loss': 0.42026220758756} | train loss {'Reaction outcome loss': 0.18729580626806197, 'Total loss': 0.18729580626806197}
2023-01-04 02:21:11,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:11,843 INFO:     Epoch: 84
2023-01-04 02:21:13,441 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4242552479108175, 'Total loss': 0.4242552479108175} | train loss {'Reaction outcome loss': 0.18457496153452982, 'Total loss': 0.18457496153452982}
2023-01-04 02:21:13,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:13,442 INFO:     Epoch: 85
2023-01-04 02:21:15,043 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42006922165552774, 'Total loss': 0.42006922165552774} | train loss {'Reaction outcome loss': 0.1844211407409248, 'Total loss': 0.1844211407409248}
2023-01-04 02:21:15,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:15,043 INFO:     Epoch: 86
2023-01-04 02:21:16,664 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42531939297914506, 'Total loss': 0.42531939297914506} | train loss {'Reaction outcome loss': 0.18271008966362864, 'Total loss': 0.18271008966362864}
2023-01-04 02:21:16,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:16,665 INFO:     Epoch: 87
2023-01-04 02:21:18,281 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43457770844300586, 'Total loss': 0.43457770844300586} | train loss {'Reaction outcome loss': 0.18232606114006, 'Total loss': 0.18232606114006}
2023-01-04 02:21:18,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:18,281 INFO:     Epoch: 88
2023-01-04 02:21:19,903 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43268859485785166, 'Total loss': 0.43268859485785166} | train loss {'Reaction outcome loss': 0.18272667632367637, 'Total loss': 0.18272667632367637}
2023-01-04 02:21:19,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:19,904 INFO:     Epoch: 89
2023-01-04 02:21:21,512 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4231193254391352, 'Total loss': 0.4231193254391352} | train loss {'Reaction outcome loss': 0.1839755533888452, 'Total loss': 0.1839755533888452}
2023-01-04 02:21:21,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:21,512 INFO:     Epoch: 90
2023-01-04 02:21:23,109 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4267405440409978, 'Total loss': 0.4267405440409978} | train loss {'Reaction outcome loss': 0.18166154994888212, 'Total loss': 0.18166154994888212}
2023-01-04 02:21:23,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:23,109 INFO:     Epoch: 91
2023-01-04 02:21:24,708 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4195997416973114, 'Total loss': 0.4195997416973114} | train loss {'Reaction outcome loss': 0.17769163571271224, 'Total loss': 0.17769163571271224}
2023-01-04 02:21:24,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:24,708 INFO:     Epoch: 92
2023-01-04 02:21:26,307 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44345643917719524, 'Total loss': 0.44345643917719524} | train loss {'Reaction outcome loss': 0.18298250941781577, 'Total loss': 0.18298250941781577}
2023-01-04 02:21:26,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:26,308 INFO:     Epoch: 93
2023-01-04 02:21:27,905 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44077938894430796, 'Total loss': 0.44077938894430796} | train loss {'Reaction outcome loss': 0.1797654953405315, 'Total loss': 0.1797654953405315}
2023-01-04 02:21:27,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:27,905 INFO:     Epoch: 94
2023-01-04 02:21:29,500 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43138291835784914, 'Total loss': 0.43138291835784914} | train loss {'Reaction outcome loss': 0.1788000136022103, 'Total loss': 0.1788000136022103}
2023-01-04 02:21:29,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:29,501 INFO:     Epoch: 95
2023-01-04 02:21:31,082 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4414690633614858, 'Total loss': 0.4414690633614858} | train loss {'Reaction outcome loss': 0.17634859426948998, 'Total loss': 0.17634859426948998}
2023-01-04 02:21:31,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:31,083 INFO:     Epoch: 96
2023-01-04 02:21:32,661 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4382864753405253, 'Total loss': 0.4382864753405253} | train loss {'Reaction outcome loss': 0.1757393819935593, 'Total loss': 0.1757393819935593}
2023-01-04 02:21:32,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:32,661 INFO:     Epoch: 97
2023-01-04 02:21:34,285 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42423059741655983, 'Total loss': 0.42423059741655983} | train loss {'Reaction outcome loss': 0.17587658978111045, 'Total loss': 0.17587658978111045}
2023-01-04 02:21:34,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:34,285 INFO:     Epoch: 98
2023-01-04 02:21:35,909 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45544853111108147, 'Total loss': 0.45544853111108147} | train loss {'Reaction outcome loss': 0.17636852019503443, 'Total loss': 0.17636852019503443}
2023-01-04 02:21:35,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:35,909 INFO:     Epoch: 99
2023-01-04 02:21:37,531 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4320610632499059, 'Total loss': 0.4320610632499059} | train loss {'Reaction outcome loss': 0.1767707326607476, 'Total loss': 0.1767707326607476}
2023-01-04 02:21:37,532 INFO:     Best model found after epoch 35 of 100.
2023-01-04 02:21:37,532 INFO:   Done with stage: TRAINING
2023-01-04 02:21:37,532 INFO:   Starting stage: EVALUATION
2023-01-04 02:21:37,653 INFO:   Done with stage: EVALUATION
2023-01-04 02:21:37,653 INFO:   Leaving out SEQ value Fold_7
2023-01-04 02:21:37,666 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 02:21:37,666 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:21:38,306 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:21:38,306 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:21:38,374 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:21:38,374 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:21:38,374 INFO:     No hyperparam tuning for this model
2023-01-04 02:21:38,375 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:21:38,375 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:21:38,375 INFO:     None feature selector for col prot
2023-01-04 02:21:38,375 INFO:     None feature selector for col prot
2023-01-04 02:21:38,376 INFO:     None feature selector for col prot
2023-01-04 02:21:38,376 INFO:     None feature selector for col chem
2023-01-04 02:21:38,376 INFO:     None feature selector for col chem
2023-01-04 02:21:38,376 INFO:     None feature selector for col chem
2023-01-04 02:21:38,376 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:21:38,376 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:21:38,377 INFO:     Number of params in model 70141
2023-01-04 02:21:38,381 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:21:38,381 INFO:   Starting stage: TRAINING
2023-01-04 02:21:38,424 INFO:     Val loss before train {'Reaction outcome loss': 1.0271367311477662, 'Total loss': 1.0271367311477662}
2023-01-04 02:21:38,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:38,424 INFO:     Epoch: 0
2023-01-04 02:21:39,988 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7294190446535747, 'Total loss': 0.7294190446535747} | train loss {'Reaction outcome loss': 0.8703888915075723, 'Total loss': 0.8703888915075723}
2023-01-04 02:21:39,988 INFO:     Found new best model at epoch 0
2023-01-04 02:21:39,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:39,989 INFO:     Epoch: 1
2023-01-04 02:21:41,584 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6114748736222585, 'Total loss': 0.6114748736222585} | train loss {'Reaction outcome loss': 0.6056869975711464, 'Total loss': 0.6056869975711464}
2023-01-04 02:21:41,585 INFO:     Found new best model at epoch 1
2023-01-04 02:21:41,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:41,586 INFO:     Epoch: 2
2023-01-04 02:21:43,180 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5644628445307414, 'Total loss': 0.5644628445307414} | train loss {'Reaction outcome loss': 0.5248890118908796, 'Total loss': 0.5248890118908796}
2023-01-04 02:21:43,180 INFO:     Found new best model at epoch 2
2023-01-04 02:21:43,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:43,181 INFO:     Epoch: 3
2023-01-04 02:21:44,791 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5466131885846456, 'Total loss': 0.5466131885846456} | train loss {'Reaction outcome loss': 0.4901693076002899, 'Total loss': 0.4901693076002899}
2023-01-04 02:21:44,791 INFO:     Found new best model at epoch 3
2023-01-04 02:21:44,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:44,792 INFO:     Epoch: 4
2023-01-04 02:21:46,415 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5251613140106202, 'Total loss': 0.5251613140106202} | train loss {'Reaction outcome loss': 0.46377721918403886, 'Total loss': 0.46377721918403886}
2023-01-04 02:21:46,415 INFO:     Found new best model at epoch 4
2023-01-04 02:21:46,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:46,416 INFO:     Epoch: 5
2023-01-04 02:21:48,016 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5185554285844167, 'Total loss': 0.5185554285844167} | train loss {'Reaction outcome loss': 0.44291701428726693, 'Total loss': 0.44291701428726693}
2023-01-04 02:21:48,017 INFO:     Found new best model at epoch 5
2023-01-04 02:21:48,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:48,018 INFO:     Epoch: 6
2023-01-04 02:21:49,602 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5156571288903554, 'Total loss': 0.5156571288903554} | train loss {'Reaction outcome loss': 0.42368022339008343, 'Total loss': 0.42368022339008343}
2023-01-04 02:21:49,602 INFO:     Found new best model at epoch 6
2023-01-04 02:21:49,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:49,603 INFO:     Epoch: 7
2023-01-04 02:21:51,204 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49907673796017965, 'Total loss': 0.49907673796017965} | train loss {'Reaction outcome loss': 0.4134501056335463, 'Total loss': 0.4134501056335463}
2023-01-04 02:21:51,204 INFO:     Found new best model at epoch 7
2023-01-04 02:21:51,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:51,205 INFO:     Epoch: 8
2023-01-04 02:21:52,804 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49978669683138527, 'Total loss': 0.49978669683138527} | train loss {'Reaction outcome loss': 0.4013178620205029, 'Total loss': 0.4013178620205029}
2023-01-04 02:21:52,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:52,804 INFO:     Epoch: 9
2023-01-04 02:21:54,420 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.492092498143514, 'Total loss': 0.492092498143514} | train loss {'Reaction outcome loss': 0.39098521456498964, 'Total loss': 0.39098521456498964}
2023-01-04 02:21:54,420 INFO:     Found new best model at epoch 9
2023-01-04 02:21:54,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:54,421 INFO:     Epoch: 10
2023-01-04 02:21:56,022 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48340710798899333, 'Total loss': 0.48340710798899333} | train loss {'Reaction outcome loss': 0.38600820480486114, 'Total loss': 0.38600820480486114}
2023-01-04 02:21:56,022 INFO:     Found new best model at epoch 10
2023-01-04 02:21:56,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:56,023 INFO:     Epoch: 11
2023-01-04 02:21:57,600 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4790486335754395, 'Total loss': 0.4790486335754395} | train loss {'Reaction outcome loss': 0.372143288274104, 'Total loss': 0.372143288274104}
2023-01-04 02:21:57,600 INFO:     Found new best model at epoch 11
2023-01-04 02:21:57,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:57,601 INFO:     Epoch: 12
2023-01-04 02:21:59,186 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4752363324165344, 'Total loss': 0.4752363324165344} | train loss {'Reaction outcome loss': 0.36571485745562543, 'Total loss': 0.36571485745562543}
2023-01-04 02:21:59,186 INFO:     Found new best model at epoch 12
2023-01-04 02:21:59,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:21:59,187 INFO:     Epoch: 13
2023-01-04 02:22:00,780 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4656083305676778, 'Total loss': 0.4656083305676778} | train loss {'Reaction outcome loss': 0.35846168316551064, 'Total loss': 0.35846168316551064}
2023-01-04 02:22:00,781 INFO:     Found new best model at epoch 13
2023-01-04 02:22:00,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:00,782 INFO:     Epoch: 14
2023-01-04 02:22:02,373 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47193206747372946, 'Total loss': 0.47193206747372946} | train loss {'Reaction outcome loss': 0.3517628702661191, 'Total loss': 0.3517628702661191}
2023-01-04 02:22:02,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:02,373 INFO:     Epoch: 15
2023-01-04 02:22:03,999 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4594806710879008, 'Total loss': 0.4594806710879008} | train loss {'Reaction outcome loss': 0.34546610328372207, 'Total loss': 0.34546610328372207}
2023-01-04 02:22:03,999 INFO:     Found new best model at epoch 15
2023-01-04 02:22:03,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:04,000 INFO:     Epoch: 16
2023-01-04 02:22:05,587 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4720600207646688, 'Total loss': 0.4720600207646688} | train loss {'Reaction outcome loss': 0.3346154463312686, 'Total loss': 0.3346154463312686}
2023-01-04 02:22:05,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:05,587 INFO:     Epoch: 17
2023-01-04 02:22:07,163 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4606858243544896, 'Total loss': 0.4606858243544896} | train loss {'Reaction outcome loss': 0.33070402568212914, 'Total loss': 0.33070402568212914}
2023-01-04 02:22:07,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:07,163 INFO:     Epoch: 18
2023-01-04 02:22:08,764 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46210482319196067, 'Total loss': 0.46210482319196067} | train loss {'Reaction outcome loss': 0.3268198394334273, 'Total loss': 0.3268198394334273}
2023-01-04 02:22:08,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:08,764 INFO:     Epoch: 19
2023-01-04 02:22:10,398 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4712916235129038, 'Total loss': 0.4712916235129038} | train loss {'Reaction outcome loss': 0.32063768467855797, 'Total loss': 0.32063768467855797}
2023-01-04 02:22:10,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:10,399 INFO:     Epoch: 20
2023-01-04 02:22:12,029 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45825663904349007, 'Total loss': 0.45825663904349007} | train loss {'Reaction outcome loss': 0.3154059040498002, 'Total loss': 0.3154059040498002}
2023-01-04 02:22:12,030 INFO:     Found new best model at epoch 20
2023-01-04 02:22:12,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:12,031 INFO:     Epoch: 21
2023-01-04 02:22:13,651 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4616937518119812, 'Total loss': 0.4616937518119812} | train loss {'Reaction outcome loss': 0.310785611936762, 'Total loss': 0.310785611936762}
2023-01-04 02:22:13,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:13,652 INFO:     Epoch: 22
2023-01-04 02:22:15,268 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45018808444341024, 'Total loss': 0.45018808444341024} | train loss {'Reaction outcome loss': 0.3052949220587631, 'Total loss': 0.3052949220587631}
2023-01-04 02:22:15,268 INFO:     Found new best model at epoch 22
2023-01-04 02:22:15,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:15,269 INFO:     Epoch: 23
2023-01-04 02:22:16,854 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4444035589694977, 'Total loss': 0.4444035589694977} | train loss {'Reaction outcome loss': 0.30305210094804796, 'Total loss': 0.30305210094804796}
2023-01-04 02:22:16,854 INFO:     Found new best model at epoch 23
2023-01-04 02:22:16,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:16,855 INFO:     Epoch: 24
2023-01-04 02:22:18,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4529250999291738, 'Total loss': 0.4529250999291738} | train loss {'Reaction outcome loss': 0.2965915032027, 'Total loss': 0.2965915032027}
2023-01-04 02:22:18,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:18,478 INFO:     Epoch: 25
2023-01-04 02:22:20,102 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45609919528166454, 'Total loss': 0.45609919528166454} | train loss {'Reaction outcome loss': 0.28921307004746116, 'Total loss': 0.28921307004746116}
2023-01-04 02:22:20,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:20,102 INFO:     Epoch: 26
2023-01-04 02:22:21,734 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45688440601030983, 'Total loss': 0.45688440601030983} | train loss {'Reaction outcome loss': 0.28884247104075844, 'Total loss': 0.28884247104075844}
2023-01-04 02:22:21,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:21,734 INFO:     Epoch: 27
2023-01-04 02:22:23,368 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44698622624079387, 'Total loss': 0.44698622624079387} | train loss {'Reaction outcome loss': 0.28373403029536515, 'Total loss': 0.28373403029536515}
2023-01-04 02:22:23,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:23,368 INFO:     Epoch: 28
2023-01-04 02:22:24,952 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44314828018347424, 'Total loss': 0.44314828018347424} | train loss {'Reaction outcome loss': 0.2789715899941293, 'Total loss': 0.2789715899941293}
2023-01-04 02:22:24,952 INFO:     Found new best model at epoch 28
2023-01-04 02:22:24,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:24,953 INFO:     Epoch: 29
2023-01-04 02:22:26,554 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44544538855552673, 'Total loss': 0.44544538855552673} | train loss {'Reaction outcome loss': 0.27746233976167034, 'Total loss': 0.27746233976167034}
2023-01-04 02:22:26,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:26,554 INFO:     Epoch: 30
2023-01-04 02:22:28,178 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44626191953818, 'Total loss': 0.44626191953818} | train loss {'Reaction outcome loss': 0.2738960452835052, 'Total loss': 0.2738960452835052}
2023-01-04 02:22:28,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:28,179 INFO:     Epoch: 31
2023-01-04 02:22:29,813 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4293416142463684, 'Total loss': 0.4293416142463684} | train loss {'Reaction outcome loss': 0.27077301723432023, 'Total loss': 0.27077301723432023}
2023-01-04 02:22:29,813 INFO:     Found new best model at epoch 31
2023-01-04 02:22:29,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:29,814 INFO:     Epoch: 32
2023-01-04 02:22:31,408 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44899366597334545, 'Total loss': 0.44899366597334545} | train loss {'Reaction outcome loss': 0.2660342685958969, 'Total loss': 0.2660342685958969}
2023-01-04 02:22:31,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:31,409 INFO:     Epoch: 33
2023-01-04 02:22:32,987 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43101343711217244, 'Total loss': 0.43101343711217244} | train loss {'Reaction outcome loss': 0.2631742359014625, 'Total loss': 0.2631742359014625}
2023-01-04 02:22:32,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:32,988 INFO:     Epoch: 34
2023-01-04 02:22:34,585 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44860156178474425, 'Total loss': 0.44860156178474425} | train loss {'Reaction outcome loss': 0.26090838273294564, 'Total loss': 0.26090838273294564}
2023-01-04 02:22:34,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:34,586 INFO:     Epoch: 35
2023-01-04 02:22:36,210 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4436235914627711, 'Total loss': 0.4436235914627711} | train loss {'Reaction outcome loss': 0.2579013283502324, 'Total loss': 0.2579013283502324}
2023-01-04 02:22:36,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:36,210 INFO:     Epoch: 36
2023-01-04 02:22:37,836 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4552890807390213, 'Total loss': 0.4552890807390213} | train loss {'Reaction outcome loss': 0.2547277258003016, 'Total loss': 0.2547277258003016}
2023-01-04 02:22:37,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:37,836 INFO:     Epoch: 37
2023-01-04 02:22:39,433 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44227193196614584, 'Total loss': 0.44227193196614584} | train loss {'Reaction outcome loss': 0.24946260438821807, 'Total loss': 0.24946260438821807}
2023-01-04 02:22:39,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:39,433 INFO:     Epoch: 38
2023-01-04 02:22:41,058 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4506094505389531, 'Total loss': 0.4506094505389531} | train loss {'Reaction outcome loss': 0.25047961709893135, 'Total loss': 0.25047961709893135}
2023-01-04 02:22:41,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:41,058 INFO:     Epoch: 39
2023-01-04 02:22:42,652 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4337620437145233, 'Total loss': 0.4337620437145233} | train loss {'Reaction outcome loss': 0.24604372411213196, 'Total loss': 0.24604372411213196}
2023-01-04 02:22:42,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:42,652 INFO:     Epoch: 40
2023-01-04 02:22:44,259 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43494948620597523, 'Total loss': 0.43494948620597523} | train loss {'Reaction outcome loss': 0.24564868400028037, 'Total loss': 0.24564868400028037}
2023-01-04 02:22:44,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:44,259 INFO:     Epoch: 41
2023-01-04 02:22:45,863 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4460190773010254, 'Total loss': 0.4460190773010254} | train loss {'Reaction outcome loss': 0.24146350330609276, 'Total loss': 0.24146350330609276}
2023-01-04 02:22:45,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:45,863 INFO:     Epoch: 42
2023-01-04 02:22:47,463 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4688065985838572, 'Total loss': 0.4688065985838572} | train loss {'Reaction outcome loss': 0.2427791869301443, 'Total loss': 0.2427791869301443}
2023-01-04 02:22:47,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:47,464 INFO:     Epoch: 43
2023-01-04 02:22:49,056 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43945551514625547, 'Total loss': 0.43945551514625547} | train loss {'Reaction outcome loss': 0.23679226867531827, 'Total loss': 0.23679226867531827}
2023-01-04 02:22:49,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:49,056 INFO:     Epoch: 44
2023-01-04 02:22:50,658 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.452462116877238, 'Total loss': 0.452462116877238} | train loss {'Reaction outcome loss': 0.23506262833891362, 'Total loss': 0.23506262833891362}
2023-01-04 02:22:50,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:50,658 INFO:     Epoch: 45
2023-01-04 02:22:52,249 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45048409700393677, 'Total loss': 0.45048409700393677} | train loss {'Reaction outcome loss': 0.23231701979191724, 'Total loss': 0.23231701979191724}
2023-01-04 02:22:52,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:52,249 INFO:     Epoch: 46
2023-01-04 02:22:53,878 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44899981121222177, 'Total loss': 0.44899981121222177} | train loss {'Reaction outcome loss': 0.23120910055693306, 'Total loss': 0.23120910055693306}
2023-01-04 02:22:53,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:53,879 INFO:     Epoch: 47
2023-01-04 02:22:55,484 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4641912400722504, 'Total loss': 0.4641912400722504} | train loss {'Reaction outcome loss': 0.2302611104955742, 'Total loss': 0.2302611104955742}
2023-01-04 02:22:55,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:55,485 INFO:     Epoch: 48
2023-01-04 02:22:57,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45675644675890603, 'Total loss': 0.45675644675890603} | train loss {'Reaction outcome loss': 0.22752193635874277, 'Total loss': 0.22752193635874277}
2023-01-04 02:22:57,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:57,113 INFO:     Epoch: 49
2023-01-04 02:22:58,704 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4573955516020457, 'Total loss': 0.4573955516020457} | train loss {'Reaction outcome loss': 0.22756759464633164, 'Total loss': 0.22756759464633164}
2023-01-04 02:22:58,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:22:58,705 INFO:     Epoch: 50
2023-01-04 02:23:00,317 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4641234318415324, 'Total loss': 0.4641234318415324} | train loss {'Reaction outcome loss': 0.22511990306502214, 'Total loss': 0.22511990306502214}
2023-01-04 02:23:00,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:00,317 INFO:     Epoch: 51
2023-01-04 02:23:01,907 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4503937502702077, 'Total loss': 0.4503937502702077} | train loss {'Reaction outcome loss': 0.22141549997166177, 'Total loss': 0.22141549997166177}
2023-01-04 02:23:01,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:01,908 INFO:     Epoch: 52
2023-01-04 02:23:03,539 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4350495477517446, 'Total loss': 0.4350495477517446} | train loss {'Reaction outcome loss': 0.2222225306965814, 'Total loss': 0.2222225306965814}
2023-01-04 02:23:03,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:03,539 INFO:     Epoch: 53
2023-01-04 02:23:05,165 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4554637869199117, 'Total loss': 0.4554637869199117} | train loss {'Reaction outcome loss': 0.2190072696239079, 'Total loss': 0.2190072696239079}
2023-01-04 02:23:05,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:05,165 INFO:     Epoch: 54
2023-01-04 02:23:06,782 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4509819527467092, 'Total loss': 0.4509819527467092} | train loss {'Reaction outcome loss': 0.21788340555470342, 'Total loss': 0.21788340555470342}
2023-01-04 02:23:06,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:06,783 INFO:     Epoch: 55
2023-01-04 02:23:08,398 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4513287236293157, 'Total loss': 0.4513287236293157} | train loss {'Reaction outcome loss': 0.21548201622515378, 'Total loss': 0.21548201622515378}
2023-01-04 02:23:08,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:08,399 INFO:     Epoch: 56
2023-01-04 02:23:09,980 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4941737453142802, 'Total loss': 0.4941737453142802} | train loss {'Reaction outcome loss': 0.2170409538954604, 'Total loss': 0.2170409538954604}
2023-01-04 02:23:09,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:09,980 INFO:     Epoch: 57
2023-01-04 02:23:11,609 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4527156124512354, 'Total loss': 0.4527156124512354} | train loss {'Reaction outcome loss': 0.21341830067040687, 'Total loss': 0.21341830067040687}
2023-01-04 02:23:11,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:11,609 INFO:     Epoch: 58
2023-01-04 02:23:13,220 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44261527359485625, 'Total loss': 0.44261527359485625} | train loss {'Reaction outcome loss': 0.21145936038466137, 'Total loss': 0.21145936038466137}
2023-01-04 02:23:13,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:13,221 INFO:     Epoch: 59
2023-01-04 02:23:14,814 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47777698636054994, 'Total loss': 0.47777698636054994} | train loss {'Reaction outcome loss': 0.20968854530892647, 'Total loss': 0.20968854530892647}
2023-01-04 02:23:14,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:14,814 INFO:     Epoch: 60
2023-01-04 02:23:16,442 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47079448103904725, 'Total loss': 0.47079448103904725} | train loss {'Reaction outcome loss': 0.2078019895654723, 'Total loss': 0.2078019895654723}
2023-01-04 02:23:16,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:16,442 INFO:     Epoch: 61
2023-01-04 02:23:18,045 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.448678058385849, 'Total loss': 0.448678058385849} | train loss {'Reaction outcome loss': 0.2089287529326303, 'Total loss': 0.2089287529326303}
2023-01-04 02:23:18,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:18,047 INFO:     Epoch: 62
2023-01-04 02:23:19,644 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4600350836912791, 'Total loss': 0.4600350836912791} | train loss {'Reaction outcome loss': 0.20948807682694082, 'Total loss': 0.20948807682694082}
2023-01-04 02:23:19,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:19,645 INFO:     Epoch: 63
2023-01-04 02:23:21,275 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46703308721383413, 'Total loss': 0.46703308721383413} | train loss {'Reaction outcome loss': 0.20758040972887823, 'Total loss': 0.20758040972887823}
2023-01-04 02:23:21,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:21,276 INFO:     Epoch: 64
2023-01-04 02:23:22,910 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4659776657819748, 'Total loss': 0.4659776657819748} | train loss {'Reaction outcome loss': 0.20307841997876064, 'Total loss': 0.20307841997876064}
2023-01-04 02:23:22,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:22,910 INFO:     Epoch: 65
2023-01-04 02:23:24,548 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.467258882522583, 'Total loss': 0.467258882522583} | train loss {'Reaction outcome loss': 0.20674817746215995, 'Total loss': 0.20674817746215995}
2023-01-04 02:23:24,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:24,549 INFO:     Epoch: 66
2023-01-04 02:23:26,167 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46878064672152203, 'Total loss': 0.46878064672152203} | train loss {'Reaction outcome loss': 0.20348227705927532, 'Total loss': 0.20348227705927532}
2023-01-04 02:23:26,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:26,168 INFO:     Epoch: 67
2023-01-04 02:23:27,735 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4594464242458344, 'Total loss': 0.4594464242458344} | train loss {'Reaction outcome loss': 0.20189599414433382, 'Total loss': 0.20189599414433382}
2023-01-04 02:23:27,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:27,735 INFO:     Epoch: 68
2023-01-04 02:23:29,377 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47601768175760906, 'Total loss': 0.47601768175760906} | train loss {'Reaction outcome loss': 0.19797185187090174, 'Total loss': 0.19797185187090174}
2023-01-04 02:23:29,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:29,377 INFO:     Epoch: 69
2023-01-04 02:23:30,998 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.457855823636055, 'Total loss': 0.457855823636055} | train loss {'Reaction outcome loss': 0.19911404169208305, 'Total loss': 0.19911404169208305}
2023-01-04 02:23:30,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:30,998 INFO:     Epoch: 70
2023-01-04 02:23:32,626 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48233021795749664, 'Total loss': 0.48233021795749664} | train loss {'Reaction outcome loss': 0.1986228599202977, 'Total loss': 0.1986228599202977}
2023-01-04 02:23:32,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:32,627 INFO:     Epoch: 71
2023-01-04 02:23:34,255 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46500463684399923, 'Total loss': 0.46500463684399923} | train loss {'Reaction outcome loss': 0.19980553126749365, 'Total loss': 0.19980553126749365}
2023-01-04 02:23:34,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:34,255 INFO:     Epoch: 72
2023-01-04 02:23:35,841 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4607217609882355, 'Total loss': 0.4607217609882355} | train loss {'Reaction outcome loss': 0.19517499109602363, 'Total loss': 0.19517499109602363}
2023-01-04 02:23:35,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:35,841 INFO:     Epoch: 73
2023-01-04 02:23:37,435 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47962648967901866, 'Total loss': 0.47962648967901866} | train loss {'Reaction outcome loss': 0.19576375934863563, 'Total loss': 0.19576375934863563}
2023-01-04 02:23:37,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:37,435 INFO:     Epoch: 74
2023-01-04 02:23:39,042 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46489647726217903, 'Total loss': 0.46489647726217903} | train loss {'Reaction outcome loss': 0.1930287367519704, 'Total loss': 0.1930287367519704}
2023-01-04 02:23:39,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:39,042 INFO:     Epoch: 75
2023-01-04 02:23:40,648 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44382839898268384, 'Total loss': 0.44382839898268384} | train loss {'Reaction outcome loss': 0.19232580373030062, 'Total loss': 0.19232580373030062}
2023-01-04 02:23:40,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:40,648 INFO:     Epoch: 76
2023-01-04 02:23:42,255 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4744832674662272, 'Total loss': 0.4744832674662272} | train loss {'Reaction outcome loss': 0.1912152147330747, 'Total loss': 0.1912152147330747}
2023-01-04 02:23:42,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:42,255 INFO:     Epoch: 77
2023-01-04 02:23:43,863 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4748653252919515, 'Total loss': 0.4748653252919515} | train loss {'Reaction outcome loss': 0.193271794917889, 'Total loss': 0.193271794917889}
2023-01-04 02:23:43,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:43,863 INFO:     Epoch: 78
2023-01-04 02:23:45,448 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48500412007172905, 'Total loss': 0.48500412007172905} | train loss {'Reaction outcome loss': 0.19082496163270535, 'Total loss': 0.19082496163270535}
2023-01-04 02:23:45,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:45,448 INFO:     Epoch: 79
2023-01-04 02:23:47,020 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4728186388810476, 'Total loss': 0.4728186388810476} | train loss {'Reaction outcome loss': 0.1891760079304449, 'Total loss': 0.1891760079304449}
2023-01-04 02:23:47,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:47,021 INFO:     Epoch: 80
2023-01-04 02:23:48,657 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4814857691526413, 'Total loss': 0.4814857691526413} | train loss {'Reaction outcome loss': 0.1886757070043995, 'Total loss': 0.1886757070043995}
2023-01-04 02:23:48,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:48,658 INFO:     Epoch: 81
2023-01-04 02:23:50,293 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46207178036371865, 'Total loss': 0.46207178036371865} | train loss {'Reaction outcome loss': 0.18981619343322967, 'Total loss': 0.18981619343322967}
2023-01-04 02:23:50,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:50,293 INFO:     Epoch: 82
2023-01-04 02:23:51,937 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46669730395078657, 'Total loss': 0.46669730395078657} | train loss {'Reaction outcome loss': 0.18759922528578918, 'Total loss': 0.18759922528578918}
2023-01-04 02:23:51,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:51,938 INFO:     Epoch: 83
2023-01-04 02:23:53,528 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46845186352729795, 'Total loss': 0.46845186352729795} | train loss {'Reaction outcome loss': 0.18566676855947997, 'Total loss': 0.18566676855947997}
2023-01-04 02:23:53,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:53,528 INFO:     Epoch: 84
2023-01-04 02:23:55,117 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5051130414009094, 'Total loss': 0.5051130414009094} | train loss {'Reaction outcome loss': 0.18756522002229836, 'Total loss': 0.18756522002229836}
2023-01-04 02:23:55,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:55,117 INFO:     Epoch: 85
2023-01-04 02:23:56,713 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4934643050034841, 'Total loss': 0.4934643050034841} | train loss {'Reaction outcome loss': 0.1830466639062235, 'Total loss': 0.1830466639062235}
2023-01-04 02:23:56,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:56,713 INFO:     Epoch: 86
2023-01-04 02:23:58,343 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48143260379632313, 'Total loss': 0.48143260379632313} | train loss {'Reaction outcome loss': 0.18543673449259804, 'Total loss': 0.18543673449259804}
2023-01-04 02:23:58,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:58,343 INFO:     Epoch: 87
2023-01-04 02:23:59,977 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46718982557455696, 'Total loss': 0.46718982557455696} | train loss {'Reaction outcome loss': 0.1830348139460659, 'Total loss': 0.1830348139460659}
2023-01-04 02:23:59,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:23:59,978 INFO:     Epoch: 88
2023-01-04 02:24:01,605 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4839038848876953, 'Total loss': 0.4839038848876953} | train loss {'Reaction outcome loss': 0.1829799005714672, 'Total loss': 0.1829799005714672}
2023-01-04 02:24:01,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:01,605 INFO:     Epoch: 89
2023-01-04 02:24:03,204 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47064583698908485, 'Total loss': 0.47064583698908485} | train loss {'Reaction outcome loss': 0.1820385867077521, 'Total loss': 0.1820385867077521}
2023-01-04 02:24:03,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:03,204 INFO:     Epoch: 90
2023-01-04 02:24:04,794 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4859072466691335, 'Total loss': 0.4859072466691335} | train loss {'Reaction outcome loss': 0.1820699522534002, 'Total loss': 0.1820699522534002}
2023-01-04 02:24:04,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:04,794 INFO:     Epoch: 91
2023-01-04 02:24:06,400 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48502270579338075, 'Total loss': 0.48502270579338075} | train loss {'Reaction outcome loss': 0.18118678103285146, 'Total loss': 0.18118678103285146}
2023-01-04 02:24:06,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:06,400 INFO:     Epoch: 92
2023-01-04 02:24:08,001 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47005818486213685, 'Total loss': 0.47005818486213685} | train loss {'Reaction outcome loss': 0.17927545929051908, 'Total loss': 0.17927545929051908}
2023-01-04 02:24:08,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:08,002 INFO:     Epoch: 93
2023-01-04 02:24:09,599 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49782781104246776, 'Total loss': 0.49782781104246776} | train loss {'Reaction outcome loss': 0.17801964998460418, 'Total loss': 0.17801964998460418}
2023-01-04 02:24:09,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:09,599 INFO:     Epoch: 94
2023-01-04 02:24:11,232 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.475508193174998, 'Total loss': 0.475508193174998} | train loss {'Reaction outcome loss': 0.17848077222758682, 'Total loss': 0.17848077222758682}
2023-01-04 02:24:11,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:11,232 INFO:     Epoch: 95
2023-01-04 02:24:12,820 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4811268756786982, 'Total loss': 0.4811268756786982} | train loss {'Reaction outcome loss': 0.17865345602189375, 'Total loss': 0.17865345602189375}
2023-01-04 02:24:12,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:12,820 INFO:     Epoch: 96
2023-01-04 02:24:14,417 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49265087246894834, 'Total loss': 0.49265087246894834} | train loss {'Reaction outcome loss': 0.17974179901774395, 'Total loss': 0.17974179901774395}
2023-01-04 02:24:14,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:14,418 INFO:     Epoch: 97
2023-01-04 02:24:16,035 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49315271377563474, 'Total loss': 0.49315271377563474} | train loss {'Reaction outcome loss': 0.17586656914021995, 'Total loss': 0.17586656914021995}
2023-01-04 02:24:16,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:16,036 INFO:     Epoch: 98
2023-01-04 02:24:17,632 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48313105007012686, 'Total loss': 0.48313105007012686} | train loss {'Reaction outcome loss': 0.17487008953029928, 'Total loss': 0.17487008953029928}
2023-01-04 02:24:17,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:17,633 INFO:     Epoch: 99
2023-01-04 02:24:19,258 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47363756895065307, 'Total loss': 0.47363756895065307} | train loss {'Reaction outcome loss': 0.1743419347162819, 'Total loss': 0.1743419347162819}
2023-01-04 02:24:19,259 INFO:     Best model found after epoch 32 of 100.
2023-01-04 02:24:19,259 INFO:   Done with stage: TRAINING
2023-01-04 02:24:19,259 INFO:   Starting stage: EVALUATION
2023-01-04 02:24:19,382 INFO:   Done with stage: EVALUATION
2023-01-04 02:24:19,382 INFO:   Leaving out SEQ value Fold_8
2023-01-04 02:24:19,394 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 02:24:19,395 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:24:20,043 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:24:20,044 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:24:20,112 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:24:20,113 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:24:20,113 INFO:     No hyperparam tuning for this model
2023-01-04 02:24:20,113 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:24:20,113 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:24:20,113 INFO:     None feature selector for col prot
2023-01-04 02:24:20,114 INFO:     None feature selector for col prot
2023-01-04 02:24:20,114 INFO:     None feature selector for col prot
2023-01-04 02:24:20,114 INFO:     None feature selector for col chem
2023-01-04 02:24:20,114 INFO:     None feature selector for col chem
2023-01-04 02:24:20,114 INFO:     None feature selector for col chem
2023-01-04 02:24:20,114 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:24:20,114 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:24:20,116 INFO:     Number of params in model 70141
2023-01-04 02:24:20,119 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:24:20,119 INFO:   Starting stage: TRAINING
2023-01-04 02:24:20,161 INFO:     Val loss before train {'Reaction outcome loss': 0.9547449707984924, 'Total loss': 0.9547449707984924}
2023-01-04 02:24:20,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:20,161 INFO:     Epoch: 0
2023-01-04 02:24:21,739 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6475040872891744, 'Total loss': 0.6475040872891744} | train loss {'Reaction outcome loss': 0.8361259090986493, 'Total loss': 0.8361259090986493}
2023-01-04 02:24:21,739 INFO:     Found new best model at epoch 0
2023-01-04 02:24:21,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:21,740 INFO:     Epoch: 1
2023-01-04 02:24:23,349 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5653226683537166, 'Total loss': 0.5653226683537166} | train loss {'Reaction outcome loss': 0.5840812425535938, 'Total loss': 0.5840812425535938}
2023-01-04 02:24:23,350 INFO:     Found new best model at epoch 1
2023-01-04 02:24:23,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:23,351 INFO:     Epoch: 2
2023-01-04 02:24:24,945 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5230902433395386, 'Total loss': 0.5230902433395386} | train loss {'Reaction outcome loss': 0.5128824983047664, 'Total loss': 0.5128824983047664}
2023-01-04 02:24:24,945 INFO:     Found new best model at epoch 2
2023-01-04 02:24:24,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:24,946 INFO:     Epoch: 3
2023-01-04 02:24:26,559 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4932744900385539, 'Total loss': 0.4932744900385539} | train loss {'Reaction outcome loss': 0.4774909216359204, 'Total loss': 0.4774909216359204}
2023-01-04 02:24:26,559 INFO:     Found new best model at epoch 3
2023-01-04 02:24:26,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:26,560 INFO:     Epoch: 4
2023-01-04 02:24:28,161 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4834074954191844, 'Total loss': 0.4834074954191844} | train loss {'Reaction outcome loss': 0.4510209818071407, 'Total loss': 0.4510209818071407}
2023-01-04 02:24:28,161 INFO:     Found new best model at epoch 4
2023-01-04 02:24:28,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:28,162 INFO:     Epoch: 5
2023-01-04 02:24:29,762 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47627885043621065, 'Total loss': 0.47627885043621065} | train loss {'Reaction outcome loss': 0.43281733688464663, 'Total loss': 0.43281733688464663}
2023-01-04 02:24:29,762 INFO:     Found new best model at epoch 5
2023-01-04 02:24:29,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:29,763 INFO:     Epoch: 6
2023-01-04 02:24:31,357 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4702948490778605, 'Total loss': 0.4702948490778605} | train loss {'Reaction outcome loss': 0.4158430083348863, 'Total loss': 0.4158430083348863}
2023-01-04 02:24:31,357 INFO:     Found new best model at epoch 6
2023-01-04 02:24:31,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:31,358 INFO:     Epoch: 7
2023-01-04 02:24:32,952 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45459388494491576, 'Total loss': 0.45459388494491576} | train loss {'Reaction outcome loss': 0.40410302595541364, 'Total loss': 0.40410302595541364}
2023-01-04 02:24:32,952 INFO:     Found new best model at epoch 7
2023-01-04 02:24:32,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:32,953 INFO:     Epoch: 8
2023-01-04 02:24:34,571 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44357428352038064, 'Total loss': 0.44357428352038064} | train loss {'Reaction outcome loss': 0.39030927457318837, 'Total loss': 0.39030927457318837}
2023-01-04 02:24:34,571 INFO:     Found new best model at epoch 8
2023-01-04 02:24:34,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:34,572 INFO:     Epoch: 9
2023-01-04 02:24:36,166 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4312198559443156, 'Total loss': 0.4312198559443156} | train loss {'Reaction outcome loss': 0.37994520398468745, 'Total loss': 0.37994520398468745}
2023-01-04 02:24:36,166 INFO:     Found new best model at epoch 9
2023-01-04 02:24:36,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:36,167 INFO:     Epoch: 10
2023-01-04 02:24:37,762 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4507532020409902, 'Total loss': 0.4507532020409902} | train loss {'Reaction outcome loss': 0.37030254221027076, 'Total loss': 0.37030254221027076}
2023-01-04 02:24:37,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:37,762 INFO:     Epoch: 11
2023-01-04 02:24:39,348 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.442092764377594, 'Total loss': 0.442092764377594} | train loss {'Reaction outcome loss': 0.36165339456676143, 'Total loss': 0.36165339456676143}
2023-01-04 02:24:39,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:39,349 INFO:     Epoch: 12
2023-01-04 02:24:40,962 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4451973537604014, 'Total loss': 0.4451973537604014} | train loss {'Reaction outcome loss': 0.3552035280513419, 'Total loss': 0.3552035280513419}
2023-01-04 02:24:40,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:40,962 INFO:     Epoch: 13
2023-01-04 02:24:42,559 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4192284882068634, 'Total loss': 0.4192284882068634} | train loss {'Reaction outcome loss': 0.34494462380663155, 'Total loss': 0.34494462380663155}
2023-01-04 02:24:42,559 INFO:     Found new best model at epoch 13
2023-01-04 02:24:42,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:42,560 INFO:     Epoch: 14
2023-01-04 02:24:44,157 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4175613780816396, 'Total loss': 0.4175613780816396} | train loss {'Reaction outcome loss': 0.33715859808646387, 'Total loss': 0.33715859808646387}
2023-01-04 02:24:44,157 INFO:     Found new best model at epoch 14
2023-01-04 02:24:44,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:44,158 INFO:     Epoch: 15
2023-01-04 02:24:45,762 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3993210673332214, 'Total loss': 0.3993210673332214} | train loss {'Reaction outcome loss': 0.32944010042111366, 'Total loss': 0.32944010042111366}
2023-01-04 02:24:45,762 INFO:     Found new best model at epoch 15
2023-01-04 02:24:45,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:45,763 INFO:     Epoch: 16
2023-01-04 02:24:47,346 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4161642253398895, 'Total loss': 0.4161642253398895} | train loss {'Reaction outcome loss': 0.3233738847426559, 'Total loss': 0.3233738847426559}
2023-01-04 02:24:47,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:47,346 INFO:     Epoch: 17
2023-01-04 02:24:48,938 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41206168035666146, 'Total loss': 0.41206168035666146} | train loss {'Reaction outcome loss': 0.3174141889928911, 'Total loss': 0.3174141889928911}
2023-01-04 02:24:48,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:48,938 INFO:     Epoch: 18
2023-01-04 02:24:50,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41088396608829497, 'Total loss': 0.41088396608829497} | train loss {'Reaction outcome loss': 0.31079917687532704, 'Total loss': 0.31079917687532704}
2023-01-04 02:24:50,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:50,568 INFO:     Epoch: 19
2023-01-04 02:24:52,169 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39689106941223146, 'Total loss': 0.39689106941223146} | train loss {'Reaction outcome loss': 0.305626270922728, 'Total loss': 0.305626270922728}
2023-01-04 02:24:52,169 INFO:     Found new best model at epoch 19
2023-01-04 02:24:52,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:52,170 INFO:     Epoch: 20
2023-01-04 02:24:53,767 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4005171298980713, 'Total loss': 0.4005171298980713} | train loss {'Reaction outcome loss': 0.30507803958460744, 'Total loss': 0.30507803958460744}
2023-01-04 02:24:53,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:53,767 INFO:     Epoch: 21
2023-01-04 02:24:55,400 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40224483609199524, 'Total loss': 0.40224483609199524} | train loss {'Reaction outcome loss': 0.2980877309499665, 'Total loss': 0.2980877309499665}
2023-01-04 02:24:55,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:55,400 INFO:     Epoch: 22
2023-01-04 02:24:56,999 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3919899433851242, 'Total loss': 0.3919899433851242} | train loss {'Reaction outcome loss': 0.294664379706882, 'Total loss': 0.294664379706882}
2023-01-04 02:24:56,999 INFO:     Found new best model at epoch 22
2023-01-04 02:24:57,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:57,000 INFO:     Epoch: 23
2023-01-04 02:24:58,589 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4040075957775116, 'Total loss': 0.4040075957775116} | train loss {'Reaction outcome loss': 0.28812741677845, 'Total loss': 0.28812741677845}
2023-01-04 02:24:58,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:24:58,589 INFO:     Epoch: 24
2023-01-04 02:25:00,193 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3969886124134064, 'Total loss': 0.3969886124134064} | train loss {'Reaction outcome loss': 0.28221490829914053, 'Total loss': 0.28221490829914053}
2023-01-04 02:25:00,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:00,193 INFO:     Epoch: 25
2023-01-04 02:25:01,794 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39804929892222085, 'Total loss': 0.39804929892222085} | train loss {'Reaction outcome loss': 0.28077815272021595, 'Total loss': 0.28077815272021595}
2023-01-04 02:25:01,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:01,794 INFO:     Epoch: 26
2023-01-04 02:25:03,397 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4013997654120127, 'Total loss': 0.4013997654120127} | train loss {'Reaction outcome loss': 0.27756343018061846, 'Total loss': 0.27756343018061846}
2023-01-04 02:25:03,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:03,397 INFO:     Epoch: 27
2023-01-04 02:25:04,986 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4014178971449534, 'Total loss': 0.4014178971449534} | train loss {'Reaction outcome loss': 0.27333299347639944, 'Total loss': 0.27333299347639944}
2023-01-04 02:25:04,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:04,987 INFO:     Epoch: 28
2023-01-04 02:25:06,086 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40701090296109516, 'Total loss': 0.40701090296109516} | train loss {'Reaction outcome loss': 0.2682792270280394, 'Total loss': 0.2682792270280394}
2023-01-04 02:25:06,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:06,086 INFO:     Epoch: 29
2023-01-04 02:25:07,177 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4082978069782257, 'Total loss': 0.4082978069782257} | train loss {'Reaction outcome loss': 0.2622395428939847, 'Total loss': 0.2622395428939847}
2023-01-04 02:25:07,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:07,177 INFO:     Epoch: 30
2023-01-04 02:25:08,265 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.395391047000885, 'Total loss': 0.395391047000885} | train loss {'Reaction outcome loss': 0.26269304989047, 'Total loss': 0.26269304989047}
2023-01-04 02:25:08,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:08,265 INFO:     Epoch: 31
2023-01-04 02:25:09,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3928973029057185, 'Total loss': 0.3928973029057185} | train loss {'Reaction outcome loss': 0.25966290059072444, 'Total loss': 0.25966290059072444}
2023-01-04 02:25:09,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:09,467 INFO:     Epoch: 32
2023-01-04 02:25:11,066 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3930737912654877, 'Total loss': 0.3930737912654877} | train loss {'Reaction outcome loss': 0.2562863642504499, 'Total loss': 0.2562863642504499}
2023-01-04 02:25:11,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:11,067 INFO:     Epoch: 33
2023-01-04 02:25:12,670 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3900750418504079, 'Total loss': 0.3900750418504079} | train loss {'Reaction outcome loss': 0.25256137813471713, 'Total loss': 0.25256137813471713}
2023-01-04 02:25:12,670 INFO:     Found new best model at epoch 33
2023-01-04 02:25:12,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:12,671 INFO:     Epoch: 34
2023-01-04 02:25:14,272 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37805304328600564, 'Total loss': 0.37805304328600564} | train loss {'Reaction outcome loss': 0.2513773297413592, 'Total loss': 0.2513773297413592}
2023-01-04 02:25:14,272 INFO:     Found new best model at epoch 34
2023-01-04 02:25:14,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:14,273 INFO:     Epoch: 35
2023-01-04 02:25:15,870 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38760679761568706, 'Total loss': 0.38760679761568706} | train loss {'Reaction outcome loss': 0.24768234186869667, 'Total loss': 0.24768234186869667}
2023-01-04 02:25:15,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:15,870 INFO:     Epoch: 36
2023-01-04 02:25:17,488 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39816608230272926, 'Total loss': 0.39816608230272926} | train loss {'Reaction outcome loss': 0.2464094854326455, 'Total loss': 0.2464094854326455}
2023-01-04 02:25:17,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:17,488 INFO:     Epoch: 37
2023-01-04 02:25:19,076 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39613869190216067, 'Total loss': 0.39613869190216067} | train loss {'Reaction outcome loss': 0.24285038937192532, 'Total loss': 0.24285038937192532}
2023-01-04 02:25:19,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:19,076 INFO:     Epoch: 38
2023-01-04 02:25:20,686 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39485793709754946, 'Total loss': 0.39485793709754946} | train loss {'Reaction outcome loss': 0.24051422697058222, 'Total loss': 0.24051422697058222}
2023-01-04 02:25:20,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:20,687 INFO:     Epoch: 39
2023-01-04 02:25:22,285 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3859684298435847, 'Total loss': 0.3859684298435847} | train loss {'Reaction outcome loss': 0.23930550111114762, 'Total loss': 0.23930550111114762}
2023-01-04 02:25:22,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:22,285 INFO:     Epoch: 40
2023-01-04 02:25:23,914 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39622489909331005, 'Total loss': 0.39622489909331005} | train loss {'Reaction outcome loss': 0.23632163083725458, 'Total loss': 0.23632163083725458}
2023-01-04 02:25:23,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:23,914 INFO:     Epoch: 41
2023-01-04 02:25:25,513 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39965447584788005, 'Total loss': 0.39965447584788005} | train loss {'Reaction outcome loss': 0.23344700273112914, 'Total loss': 0.23344700273112914}
2023-01-04 02:25:25,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:25,513 INFO:     Epoch: 42
2023-01-04 02:25:27,136 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3851434608300527, 'Total loss': 0.3851434608300527} | train loss {'Reaction outcome loss': 0.2309733819256836, 'Total loss': 0.2309733819256836}
2023-01-04 02:25:27,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:27,137 INFO:     Epoch: 43
2023-01-04 02:25:28,732 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39517582456270856, 'Total loss': 0.39517582456270856} | train loss {'Reaction outcome loss': 0.22773705686472814, 'Total loss': 0.22773705686472814}
2023-01-04 02:25:28,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:28,732 INFO:     Epoch: 44
2023-01-04 02:25:30,329 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3809587796529134, 'Total loss': 0.3809587796529134} | train loss {'Reaction outcome loss': 0.2257289753332465, 'Total loss': 0.2257289753332465}
2023-01-04 02:25:30,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:30,329 INFO:     Epoch: 45
2023-01-04 02:25:31,910 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40901280542214713, 'Total loss': 0.40901280542214713} | train loss {'Reaction outcome loss': 0.22475421507355323, 'Total loss': 0.22475421507355323}
2023-01-04 02:25:31,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:31,910 INFO:     Epoch: 46
2023-01-04 02:25:33,530 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3991506298383077, 'Total loss': 0.3991506298383077} | train loss {'Reaction outcome loss': 0.22405735551235048, 'Total loss': 0.22405735551235048}
2023-01-04 02:25:33,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:33,531 INFO:     Epoch: 47
2023-01-04 02:25:35,147 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38470013489325844, 'Total loss': 0.38470013489325844} | train loss {'Reaction outcome loss': 0.22074897638404412, 'Total loss': 0.22074897638404412}
2023-01-04 02:25:35,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:35,147 INFO:     Epoch: 48
2023-01-04 02:25:36,745 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.410084996620814, 'Total loss': 0.410084996620814} | train loss {'Reaction outcome loss': 0.21997626924665395, 'Total loss': 0.21997626924665395}
2023-01-04 02:25:36,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:36,745 INFO:     Epoch: 49
2023-01-04 02:25:38,367 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4018325130144755, 'Total loss': 0.4018325130144755} | train loss {'Reaction outcome loss': 0.21878480739111505, 'Total loss': 0.21878480739111505}
2023-01-04 02:25:38,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:38,368 INFO:     Epoch: 50
2023-01-04 02:25:39,973 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4006613383690516, 'Total loss': 0.4006613383690516} | train loss {'Reaction outcome loss': 0.21382995985367667, 'Total loss': 0.21382995985367667}
2023-01-04 02:25:39,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:39,974 INFO:     Epoch: 51
2023-01-04 02:25:41,560 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3995949844519297, 'Total loss': 0.3995949844519297} | train loss {'Reaction outcome loss': 0.2131919498935288, 'Total loss': 0.2131919498935288}
2023-01-04 02:25:41,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:41,561 INFO:     Epoch: 52
2023-01-04 02:25:43,182 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39866872131824493, 'Total loss': 0.39866872131824493} | train loss {'Reaction outcome loss': 0.21134279845854007, 'Total loss': 0.21134279845854007}
2023-01-04 02:25:43,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:43,182 INFO:     Epoch: 53
2023-01-04 02:25:44,800 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40075020094712577, 'Total loss': 0.40075020094712577} | train loss {'Reaction outcome loss': 0.21131588315544145, 'Total loss': 0.21131588315544145}
2023-01-04 02:25:44,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:44,800 INFO:     Epoch: 54
2023-01-04 02:25:46,409 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3931427349646886, 'Total loss': 0.3931427349646886} | train loss {'Reaction outcome loss': 0.209973287711505, 'Total loss': 0.209973287711505}
2023-01-04 02:25:46,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:46,409 INFO:     Epoch: 55
2023-01-04 02:25:48,034 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39355359772841136, 'Total loss': 0.39355359772841136} | train loss {'Reaction outcome loss': 0.20839772975939705, 'Total loss': 0.20839772975939705}
2023-01-04 02:25:48,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:48,035 INFO:     Epoch: 56
2023-01-04 02:25:49,634 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3938415691256523, 'Total loss': 0.3938415691256523} | train loss {'Reaction outcome loss': 0.20553746227753292, 'Total loss': 0.20553746227753292}
2023-01-04 02:25:49,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:49,634 INFO:     Epoch: 57
2023-01-04 02:25:51,256 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.396277446548144, 'Total loss': 0.396277446548144} | train loss {'Reaction outcome loss': 0.20597467411457415, 'Total loss': 0.20597467411457415}
2023-01-04 02:25:51,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:51,257 INFO:     Epoch: 58
2023-01-04 02:25:52,845 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39880667328834535, 'Total loss': 0.39880667328834535} | train loss {'Reaction outcome loss': 0.2040169535588056, 'Total loss': 0.2040169535588056}
2023-01-04 02:25:52,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:52,846 INFO:     Epoch: 59
2023-01-04 02:25:54,448 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3943764189879099, 'Total loss': 0.3943764189879099} | train loss {'Reaction outcome loss': 0.2017532806130738, 'Total loss': 0.2017532806130738}
2023-01-04 02:25:54,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:54,448 INFO:     Epoch: 60
2023-01-04 02:25:56,067 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40082973341147105, 'Total loss': 0.40082973341147105} | train loss {'Reaction outcome loss': 0.200747607686029, 'Total loss': 0.200747607686029}
2023-01-04 02:25:56,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:56,067 INFO:     Epoch: 61
2023-01-04 02:25:57,692 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4073186973730723, 'Total loss': 0.4073186973730723} | train loss {'Reaction outcome loss': 0.19958305722001657, 'Total loss': 0.19958305722001657}
2023-01-04 02:25:57,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:57,693 INFO:     Epoch: 62
2023-01-04 02:25:59,272 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3992929905653, 'Total loss': 0.3992929905653} | train loss {'Reaction outcome loss': 0.19916041717202224, 'Total loss': 0.19916041717202224}
2023-01-04 02:25:59,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:25:59,273 INFO:     Epoch: 63
2023-01-04 02:26:00,869 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40009461939334867, 'Total loss': 0.40009461939334867} | train loss {'Reaction outcome loss': 0.19659381510441054, 'Total loss': 0.19659381510441054}
2023-01-04 02:26:00,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:00,869 INFO:     Epoch: 64
2023-01-04 02:26:02,467 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3932930827140808, 'Total loss': 0.3932930827140808} | train loss {'Reaction outcome loss': 0.19667844836758147, 'Total loss': 0.19667844836758147}
2023-01-04 02:26:02,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:02,467 INFO:     Epoch: 65
2023-01-04 02:26:04,068 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41346543431282046, 'Total loss': 0.41346543431282046} | train loss {'Reaction outcome loss': 0.1951882715676558, 'Total loss': 0.1951882715676558}
2023-01-04 02:26:04,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:04,068 INFO:     Epoch: 66
2023-01-04 02:26:05,655 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4073398381471634, 'Total loss': 0.4073398381471634} | train loss {'Reaction outcome loss': 0.19428535319515083, 'Total loss': 0.19428535319515083}
2023-01-04 02:26:05,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:05,656 INFO:     Epoch: 67
2023-01-04 02:26:07,256 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.400113183259964, 'Total loss': 0.400113183259964} | train loss {'Reaction outcome loss': 0.1908636538964101, 'Total loss': 0.1908636538964101}
2023-01-04 02:26:07,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:07,256 INFO:     Epoch: 68
2023-01-04 02:26:08,854 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4011559307575226, 'Total loss': 0.4011559307575226} | train loss {'Reaction outcome loss': 0.19148511424768272, 'Total loss': 0.19148511424768272}
2023-01-04 02:26:08,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:08,854 INFO:     Epoch: 69
2023-01-04 02:26:10,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4027105967203776, 'Total loss': 0.4027105967203776} | train loss {'Reaction outcome loss': 0.18926780157140877, 'Total loss': 0.18926780157140877}
2023-01-04 02:26:10,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:10,450 INFO:     Epoch: 70
2023-01-04 02:26:12,054 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4212643881638845, 'Total loss': 0.4212643881638845} | train loss {'Reaction outcome loss': 0.18944720301898163, 'Total loss': 0.18944720301898163}
2023-01-04 02:26:12,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:12,055 INFO:     Epoch: 71
2023-01-04 02:26:13,649 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41104839195807774, 'Total loss': 0.41104839195807774} | train loss {'Reaction outcome loss': 0.18952640929403933, 'Total loss': 0.18952640929403933}
2023-01-04 02:26:13,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:13,649 INFO:     Epoch: 72
2023-01-04 02:26:15,246 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.412062668800354, 'Total loss': 0.412062668800354} | train loss {'Reaction outcome loss': 0.18935794923252794, 'Total loss': 0.18935794923252794}
2023-01-04 02:26:15,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:15,246 INFO:     Epoch: 73
2023-01-04 02:26:16,837 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4118236536780993, 'Total loss': 0.4118236536780993} | train loss {'Reaction outcome loss': 0.1862292965665621, 'Total loss': 0.1862292965665621}
2023-01-04 02:26:16,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:16,838 INFO:     Epoch: 74
2023-01-04 02:26:18,460 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41692714194456737, 'Total loss': 0.41692714194456737} | train loss {'Reaction outcome loss': 0.18743472284761792, 'Total loss': 0.18743472284761792}
2023-01-04 02:26:18,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:18,460 INFO:     Epoch: 75
2023-01-04 02:26:20,085 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4360375170906385, 'Total loss': 0.4360375170906385} | train loss {'Reaction outcome loss': 0.1841999849553358, 'Total loss': 0.1841999849553358}
2023-01-04 02:26:20,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:20,085 INFO:     Epoch: 76
2023-01-04 02:26:21,677 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41465331117312115, 'Total loss': 0.41465331117312115} | train loss {'Reaction outcome loss': 0.18205701547678196, 'Total loss': 0.18205701547678196}
2023-01-04 02:26:21,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:21,677 INFO:     Epoch: 77
2023-01-04 02:26:23,302 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4030983090400696, 'Total loss': 0.4030983090400696} | train loss {'Reaction outcome loss': 0.18392217779256376, 'Total loss': 0.18392217779256376}
2023-01-04 02:26:23,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:23,302 INFO:     Epoch: 78
2023-01-04 02:26:24,896 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4092162976662318, 'Total loss': 0.4092162976662318} | train loss {'Reaction outcome loss': 0.18157634962793937, 'Total loss': 0.18157634962793937}
2023-01-04 02:26:24,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:24,897 INFO:     Epoch: 79
2023-01-04 02:26:26,518 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41045863926410675, 'Total loss': 0.41045863926410675} | train loss {'Reaction outcome loss': 0.1812422949457642, 'Total loss': 0.1812422949457642}
2023-01-04 02:26:26,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:26,519 INFO:     Epoch: 80
2023-01-04 02:26:28,132 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40631251931190493, 'Total loss': 0.40631251931190493} | train loss {'Reaction outcome loss': 0.18087928075114743, 'Total loss': 0.18087928075114743}
2023-01-04 02:26:28,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:28,134 INFO:     Epoch: 81
2023-01-04 02:26:29,716 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4249864012002945, 'Total loss': 0.4249864012002945} | train loss {'Reaction outcome loss': 0.18118038314935964, 'Total loss': 0.18118038314935964}
2023-01-04 02:26:29,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:29,716 INFO:     Epoch: 82
2023-01-04 02:26:31,329 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4481378674507141, 'Total loss': 0.4481378674507141} | train loss {'Reaction outcome loss': 0.17831069450247158, 'Total loss': 0.17831069450247158}
2023-01-04 02:26:31,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:31,329 INFO:     Epoch: 83
2023-01-04 02:26:32,960 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4119482984145482, 'Total loss': 0.4119482984145482} | train loss {'Reaction outcome loss': 0.17978016104186054, 'Total loss': 0.17978016104186054}
2023-01-04 02:26:32,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:32,960 INFO:     Epoch: 84
2023-01-04 02:26:34,554 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41853137612342833, 'Total loss': 0.41853137612342833} | train loss {'Reaction outcome loss': 0.17921205671900878, 'Total loss': 0.17921205671900878}
2023-01-04 02:26:34,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:34,555 INFO:     Epoch: 85
2023-01-04 02:26:36,159 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4031870037317276, 'Total loss': 0.4031870037317276} | train loss {'Reaction outcome loss': 0.17586356583673385, 'Total loss': 0.17586356583673385}
2023-01-04 02:26:36,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:36,159 INFO:     Epoch: 86
2023-01-04 02:26:37,771 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43427663544813794, 'Total loss': 0.43427663544813794} | train loss {'Reaction outcome loss': 0.17751408297070959, 'Total loss': 0.17751408297070959}
2023-01-04 02:26:37,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:37,771 INFO:     Epoch: 87
2023-01-04 02:26:39,359 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4149311274290085, 'Total loss': 0.4149311274290085} | train loss {'Reaction outcome loss': 0.17487036614991483, 'Total loss': 0.17487036614991483}
2023-01-04 02:26:39,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:39,360 INFO:     Epoch: 88
2023-01-04 02:26:40,984 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40708999733130136, 'Total loss': 0.40708999733130136} | train loss {'Reaction outcome loss': 0.17484288937697987, 'Total loss': 0.17484288937697987}
2023-01-04 02:26:40,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:40,984 INFO:     Epoch: 89
2023-01-04 02:26:42,606 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4118763084212939, 'Total loss': 0.4118763084212939} | train loss {'Reaction outcome loss': 0.17402651068495606, 'Total loss': 0.17402651068495606}
2023-01-04 02:26:42,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:42,606 INFO:     Epoch: 90
2023-01-04 02:26:44,199 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41011641422907513, 'Total loss': 0.41011641422907513} | train loss {'Reaction outcome loss': 0.17384313556301786, 'Total loss': 0.17384313556301786}
2023-01-04 02:26:44,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:44,200 INFO:     Epoch: 91
2023-01-04 02:26:45,801 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41932931542396545, 'Total loss': 0.41932931542396545} | train loss {'Reaction outcome loss': 0.17233389523888967, 'Total loss': 0.17233389523888967}
2023-01-04 02:26:45,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:45,801 INFO:     Epoch: 92
2023-01-04 02:26:47,426 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40288475155830383, 'Total loss': 0.40288475155830383} | train loss {'Reaction outcome loss': 0.17390413656292839, 'Total loss': 0.17390413656292839}
2023-01-04 02:26:47,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:47,427 INFO:     Epoch: 93
2023-01-04 02:26:49,019 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4215128312508265, 'Total loss': 0.4215128312508265} | train loss {'Reaction outcome loss': 0.17012469832271016, 'Total loss': 0.17012469832271016}
2023-01-04 02:26:49,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:49,019 INFO:     Epoch: 94
2023-01-04 02:26:50,644 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40399574438730873, 'Total loss': 0.40399574438730873} | train loss {'Reaction outcome loss': 0.1727951298524972, 'Total loss': 0.1727951298524972}
2023-01-04 02:26:50,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:50,645 INFO:     Epoch: 95
2023-01-04 02:26:52,223 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41204418341318766, 'Total loss': 0.41204418341318766} | train loss {'Reaction outcome loss': 0.17056570775699315, 'Total loss': 0.17056570775699315}
2023-01-04 02:26:52,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:52,223 INFO:     Epoch: 96
2023-01-04 02:26:53,825 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4136215567588806, 'Total loss': 0.4136215567588806} | train loss {'Reaction outcome loss': 0.1710624389000748, 'Total loss': 0.1710624389000748}
2023-01-04 02:26:53,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:53,825 INFO:     Epoch: 97
2023-01-04 02:26:55,428 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4105605791012446, 'Total loss': 0.4105605791012446} | train loss {'Reaction outcome loss': 0.17011673669145855, 'Total loss': 0.17011673669145855}
2023-01-04 02:26:55,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:55,428 INFO:     Epoch: 98
2023-01-04 02:26:57,011 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4265233079592387, 'Total loss': 0.4265233079592387} | train loss {'Reaction outcome loss': 0.16855957623678747, 'Total loss': 0.16855957623678747}
2023-01-04 02:26:57,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:57,011 INFO:     Epoch: 99
2023-01-04 02:26:58,611 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.421396670738856, 'Total loss': 0.421396670738856} | train loss {'Reaction outcome loss': 0.16817200079640973, 'Total loss': 0.16817200079640973}
2023-01-04 02:26:58,612 INFO:     Best model found after epoch 35 of 100.
2023-01-04 02:26:58,612 INFO:   Done with stage: TRAINING
2023-01-04 02:26:58,612 INFO:   Starting stage: EVALUATION
2023-01-04 02:26:58,733 INFO:   Done with stage: EVALUATION
2023-01-04 02:26:58,733 INFO:   Leaving out SEQ value Fold_9
2023-01-04 02:26:58,746 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:26:58,746 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:26:59,392 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:26:59,392 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:26:59,462 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:26:59,463 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:26:59,463 INFO:     No hyperparam tuning for this model
2023-01-04 02:26:59,463 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:26:59,463 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:26:59,463 INFO:     None feature selector for col prot
2023-01-04 02:26:59,464 INFO:     None feature selector for col prot
2023-01-04 02:26:59,464 INFO:     None feature selector for col prot
2023-01-04 02:26:59,464 INFO:     None feature selector for col chem
2023-01-04 02:26:59,464 INFO:     None feature selector for col chem
2023-01-04 02:26:59,464 INFO:     None feature selector for col chem
2023-01-04 02:26:59,464 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:26:59,464 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:26:59,466 INFO:     Number of params in model 70141
2023-01-04 02:26:59,469 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:26:59,469 INFO:   Starting stage: TRAINING
2023-01-04 02:26:59,513 INFO:     Val loss before train {'Reaction outcome loss': 1.0341041962305704, 'Total loss': 1.0341041962305704}
2023-01-04 02:26:59,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:26:59,513 INFO:     Epoch: 0
2023-01-04 02:27:01,098 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6078243503967921, 'Total loss': 0.6078243503967921} | train loss {'Reaction outcome loss': 0.856364151857195, 'Total loss': 0.856364151857195}
2023-01-04 02:27:01,098 INFO:     Found new best model at epoch 0
2023-01-04 02:27:01,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:01,100 INFO:     Epoch: 1
2023-01-04 02:27:02,688 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5357791483402252, 'Total loss': 0.5357791483402252} | train loss {'Reaction outcome loss': 0.6073735739192824, 'Total loss': 0.6073735739192824}
2023-01-04 02:27:02,688 INFO:     Found new best model at epoch 1
2023-01-04 02:27:02,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:02,689 INFO:     Epoch: 2
2023-01-04 02:27:04,271 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.528486967086792, 'Total loss': 0.528486967086792} | train loss {'Reaction outcome loss': 0.5314610529228718, 'Total loss': 0.5314610529228718}
2023-01-04 02:27:04,272 INFO:     Found new best model at epoch 2
2023-01-04 02:27:04,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:04,273 INFO:     Epoch: 3
2023-01-04 02:27:05,840 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5183828542629878, 'Total loss': 0.5183828542629878} | train loss {'Reaction outcome loss': 0.4885135209799683, 'Total loss': 0.4885135209799683}
2023-01-04 02:27:05,840 INFO:     Found new best model at epoch 3
2023-01-04 02:27:05,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:05,841 INFO:     Epoch: 4
2023-01-04 02:27:07,422 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4570565660794576, 'Total loss': 0.4570565660794576} | train loss {'Reaction outcome loss': 0.46421978889155563, 'Total loss': 0.46421978889155563}
2023-01-04 02:27:07,422 INFO:     Found new best model at epoch 4
2023-01-04 02:27:07,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:07,423 INFO:     Epoch: 5
2023-01-04 02:27:09,007 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4464574734369914, 'Total loss': 0.4464574734369914} | train loss {'Reaction outcome loss': 0.43837343624038416, 'Total loss': 0.43837343624038416}
2023-01-04 02:27:09,007 INFO:     Found new best model at epoch 5
2023-01-04 02:27:09,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:09,008 INFO:     Epoch: 6
2023-01-04 02:27:10,574 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.440125181277593, 'Total loss': 0.440125181277593} | train loss {'Reaction outcome loss': 0.42201065631025897, 'Total loss': 0.42201065631025897}
2023-01-04 02:27:10,575 INFO:     Found new best model at epoch 6
2023-01-04 02:27:10,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:10,576 INFO:     Epoch: 7
2023-01-04 02:27:12,156 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4323339452346166, 'Total loss': 0.4323339452346166} | train loss {'Reaction outcome loss': 0.40883806010667423, 'Total loss': 0.40883806010667423}
2023-01-04 02:27:12,156 INFO:     Found new best model at epoch 7
2023-01-04 02:27:12,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:12,157 INFO:     Epoch: 8
2023-01-04 02:27:13,766 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4393573835492134, 'Total loss': 0.4393573835492134} | train loss {'Reaction outcome loss': 0.39410051950899355, 'Total loss': 0.39410051950899355}
2023-01-04 02:27:13,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:13,767 INFO:     Epoch: 9
2023-01-04 02:27:15,340 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43864457805951435, 'Total loss': 0.43864457805951435} | train loss {'Reaction outcome loss': 0.38450057774673413, 'Total loss': 0.38450057774673413}
2023-01-04 02:27:15,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:15,340 INFO:     Epoch: 10
2023-01-04 02:27:16,921 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40457447692751886, 'Total loss': 0.40457447692751886} | train loss {'Reaction outcome loss': 0.37414534349184836, 'Total loss': 0.37414534349184836}
2023-01-04 02:27:16,921 INFO:     Found new best model at epoch 10
2023-01-04 02:27:16,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:16,922 INFO:     Epoch: 11
2023-01-04 02:27:18,482 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4267949322859446, 'Total loss': 0.4267949322859446} | train loss {'Reaction outcome loss': 0.365628564091277, 'Total loss': 0.365628564091277}
2023-01-04 02:27:18,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:18,482 INFO:     Epoch: 12
2023-01-04 02:27:20,088 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44735084772109984, 'Total loss': 0.44735084772109984} | train loss {'Reaction outcome loss': 0.35343533324716736, 'Total loss': 0.35343533324716736}
2023-01-04 02:27:20,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:20,088 INFO:     Epoch: 13
2023-01-04 02:27:21,694 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41443260610103605, 'Total loss': 0.41443260610103605} | train loss {'Reaction outcome loss': 0.34968604400318903, 'Total loss': 0.34968604400318903}
2023-01-04 02:27:21,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:21,694 INFO:     Epoch: 14
2023-01-04 02:27:23,305 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4150804231564204, 'Total loss': 0.4150804231564204} | train loss {'Reaction outcome loss': 0.34245918185388957, 'Total loss': 0.34245918185388957}
2023-01-04 02:27:23,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:23,306 INFO:     Epoch: 15
2023-01-04 02:27:24,889 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44026806553204856, 'Total loss': 0.44026806553204856} | train loss {'Reaction outcome loss': 0.3323293502313377, 'Total loss': 0.3323293502313377}
2023-01-04 02:27:24,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:24,889 INFO:     Epoch: 16
2023-01-04 02:27:26,506 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4096750388542811, 'Total loss': 0.4096750388542811} | train loss {'Reaction outcome loss': 0.32577459361866445, 'Total loss': 0.32577459361866445}
2023-01-04 02:27:26,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:26,506 INFO:     Epoch: 17
2023-01-04 02:27:28,077 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41933061679204303, 'Total loss': 0.41933061679204303} | train loss {'Reaction outcome loss': 0.3225977487698959, 'Total loss': 0.3225977487698959}
2023-01-04 02:27:28,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:28,077 INFO:     Epoch: 18
2023-01-04 02:27:29,682 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41323707103729246, 'Total loss': 0.41323707103729246} | train loss {'Reaction outcome loss': 0.3146860541327156, 'Total loss': 0.3146860541327156}
2023-01-04 02:27:29,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:29,682 INFO:     Epoch: 19
2023-01-04 02:27:31,288 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4031694769859314, 'Total loss': 0.4031694769859314} | train loss {'Reaction outcome loss': 0.3098841554546443, 'Total loss': 0.3098841554546443}
2023-01-04 02:27:31,288 INFO:     Found new best model at epoch 19
2023-01-04 02:27:31,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:31,289 INFO:     Epoch: 20
2023-01-04 02:27:32,867 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.405545515815417, 'Total loss': 0.405545515815417} | train loss {'Reaction outcome loss': 0.3049326593423412, 'Total loss': 0.3049326593423412}
2023-01-04 02:27:32,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:32,867 INFO:     Epoch: 21
2023-01-04 02:27:34,481 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4131614108880361, 'Total loss': 0.4131614108880361} | train loss {'Reaction outcome loss': 0.29804347053061436, 'Total loss': 0.29804347053061436}
2023-01-04 02:27:34,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:34,482 INFO:     Epoch: 22
2023-01-04 02:27:36,097 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3955400069554647, 'Total loss': 0.3955400069554647} | train loss {'Reaction outcome loss': 0.2932506509288384, 'Total loss': 0.2932506509288384}
2023-01-04 02:27:36,097 INFO:     Found new best model at epoch 22
2023-01-04 02:27:36,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:36,098 INFO:     Epoch: 23
2023-01-04 02:27:37,655 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43882667322953545, 'Total loss': 0.43882667322953545} | train loss {'Reaction outcome loss': 0.2871018921426178, 'Total loss': 0.2871018921426178}
2023-01-04 02:27:37,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:37,656 INFO:     Epoch: 24
2023-01-04 02:27:39,260 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4150624940792719, 'Total loss': 0.4150624940792719} | train loss {'Reaction outcome loss': 0.2846780921855982, 'Total loss': 0.2846780921855982}
2023-01-04 02:27:39,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:39,261 INFO:     Epoch: 25
2023-01-04 02:27:40,847 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4083949029445648, 'Total loss': 0.4083949029445648} | train loss {'Reaction outcome loss': 0.280926796913582, 'Total loss': 0.280926796913582}
2023-01-04 02:27:40,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:40,847 INFO:     Epoch: 26
2023-01-04 02:27:42,431 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39385294417540234, 'Total loss': 0.39385294417540234} | train loss {'Reaction outcome loss': 0.27555530287162233, 'Total loss': 0.27555530287162233}
2023-01-04 02:27:42,432 INFO:     Found new best model at epoch 26
2023-01-04 02:27:42,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:42,432 INFO:     Epoch: 27
2023-01-04 02:27:44,028 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3968273957570394, 'Total loss': 0.3968273957570394} | train loss {'Reaction outcome loss': 0.27025679148135395, 'Total loss': 0.27025679148135395}
2023-01-04 02:27:44,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:44,029 INFO:     Epoch: 28
2023-01-04 02:27:45,616 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4214129428068797, 'Total loss': 0.4214129428068797} | train loss {'Reaction outcome loss': 0.2695446657764651, 'Total loss': 0.2695446657764651}
2023-01-04 02:27:45,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:45,616 INFO:     Epoch: 29
2023-01-04 02:27:47,193 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42378459572792054, 'Total loss': 0.42378459572792054} | train loss {'Reaction outcome loss': 0.2625964937908371, 'Total loss': 0.2625964937908371}
2023-01-04 02:27:47,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:47,194 INFO:     Epoch: 30
2023-01-04 02:27:48,770 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3968401129047076, 'Total loss': 0.3968401129047076} | train loss {'Reaction outcome loss': 0.2590115019630124, 'Total loss': 0.2590115019630124}
2023-01-04 02:27:48,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:48,770 INFO:     Epoch: 31
2023-01-04 02:27:50,344 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4120169053475062, 'Total loss': 0.4120169053475062} | train loss {'Reaction outcome loss': 0.25891960340205333, 'Total loss': 0.25891960340205333}
2023-01-04 02:27:50,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:50,344 INFO:     Epoch: 32
2023-01-04 02:27:51,904 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.419124769171079, 'Total loss': 0.419124769171079} | train loss {'Reaction outcome loss': 0.2537644301697503, 'Total loss': 0.2537644301697503}
2023-01-04 02:27:51,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:51,904 INFO:     Epoch: 33
2023-01-04 02:27:53,483 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41024684607982637, 'Total loss': 0.41024684607982637} | train loss {'Reaction outcome loss': 0.2492421248207127, 'Total loss': 0.2492421248207127}
2023-01-04 02:27:53,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:53,483 INFO:     Epoch: 34
2023-01-04 02:27:55,048 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3833015918731689, 'Total loss': 0.3833015918731689} | train loss {'Reaction outcome loss': 0.24729553204927132, 'Total loss': 0.24729553204927132}
2023-01-04 02:27:55,048 INFO:     Found new best model at epoch 34
2023-01-04 02:27:55,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:55,049 INFO:     Epoch: 35
2023-01-04 02:27:56,652 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.433345897992452, 'Total loss': 0.433345897992452} | train loss {'Reaction outcome loss': 0.2418931945070733, 'Total loss': 0.2418931945070733}
2023-01-04 02:27:56,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:56,652 INFO:     Epoch: 36
2023-01-04 02:27:58,291 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4036838839451472, 'Total loss': 0.4036838839451472} | train loss {'Reaction outcome loss': 0.24261863620775023, 'Total loss': 0.24261863620775023}
2023-01-04 02:27:58,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:58,292 INFO:     Epoch: 37
2023-01-04 02:27:59,908 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4128266781568527, 'Total loss': 0.4128266781568527} | train loss {'Reaction outcome loss': 0.23911329453987798, 'Total loss': 0.23911329453987798}
2023-01-04 02:27:59,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:27:59,908 INFO:     Epoch: 38
2023-01-04 02:28:01,556 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4004225636521975, 'Total loss': 0.4004225636521975} | train loss {'Reaction outcome loss': 0.23696114220758424, 'Total loss': 0.23696114220758424}
2023-01-04 02:28:01,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:01,556 INFO:     Epoch: 39
2023-01-04 02:28:03,167 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4142637779315313, 'Total loss': 0.4142637779315313} | train loss {'Reaction outcome loss': 0.23291457841431137, 'Total loss': 0.23291457841431137}
2023-01-04 02:28:03,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:03,167 INFO:     Epoch: 40
2023-01-04 02:28:04,781 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39945828119913734, 'Total loss': 0.39945828119913734} | train loss {'Reaction outcome loss': 0.2307679426523238, 'Total loss': 0.2307679426523238}
2023-01-04 02:28:04,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:04,782 INFO:     Epoch: 41
2023-01-04 02:28:06,357 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40692674020926156, 'Total loss': 0.40692674020926156} | train loss {'Reaction outcome loss': 0.22783768200145585, 'Total loss': 0.22783768200145585}
2023-01-04 02:28:06,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:06,357 INFO:     Epoch: 42
2023-01-04 02:28:07,968 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39637179374694825, 'Total loss': 0.39637179374694825} | train loss {'Reaction outcome loss': 0.2265545116995808, 'Total loss': 0.2265545116995808}
2023-01-04 02:28:07,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:07,968 INFO:     Epoch: 43
2023-01-04 02:28:09,549 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41331397990385693, 'Total loss': 0.41331397990385693} | train loss {'Reaction outcome loss': 0.22591080671570596, 'Total loss': 0.22591080671570596}
2023-01-04 02:28:09,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:09,551 INFO:     Epoch: 44
2023-01-04 02:28:11,121 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40698551138242084, 'Total loss': 0.40698551138242084} | train loss {'Reaction outcome loss': 0.22065848484635353, 'Total loss': 0.22065848484635353}
2023-01-04 02:28:11,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:11,122 INFO:     Epoch: 45
2023-01-04 02:28:12,751 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41852239867051444, 'Total loss': 0.41852239867051444} | train loss {'Reaction outcome loss': 0.2211133342059533, 'Total loss': 0.2211133342059533}
2023-01-04 02:28:12,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:12,751 INFO:     Epoch: 46
2023-01-04 02:28:14,369 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39025248686472574, 'Total loss': 0.39025248686472574} | train loss {'Reaction outcome loss': 0.2178481576461209, 'Total loss': 0.2178481576461209}
2023-01-04 02:28:14,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:14,369 INFO:     Epoch: 47
2023-01-04 02:28:15,974 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41152487248182296, 'Total loss': 0.41152487248182296} | train loss {'Reaction outcome loss': 0.21575920542117452, 'Total loss': 0.21575920542117452}
2023-01-04 02:28:15,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:15,975 INFO:     Epoch: 48
2023-01-04 02:28:17,574 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3990142822265625, 'Total loss': 0.3990142822265625} | train loss {'Reaction outcome loss': 0.21287341675564755, 'Total loss': 0.21287341675564755}
2023-01-04 02:28:17,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:17,574 INFO:     Epoch: 49
2023-01-04 02:28:19,167 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3939538558324178, 'Total loss': 0.3939538558324178} | train loss {'Reaction outcome loss': 0.21441125561122912, 'Total loss': 0.21441125561122912}
2023-01-04 02:28:19,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:19,168 INFO:     Epoch: 50
2023-01-04 02:28:20,771 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4264074623584747, 'Total loss': 0.4264074623584747} | train loss {'Reaction outcome loss': 0.21093266300286037, 'Total loss': 0.21093266300286037}
2023-01-04 02:28:20,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:20,771 INFO:     Epoch: 51
2023-01-04 02:28:22,340 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3991683930158615, 'Total loss': 0.3991683930158615} | train loss {'Reaction outcome loss': 0.20879011801070105, 'Total loss': 0.20879011801070105}
2023-01-04 02:28:22,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:22,341 INFO:     Epoch: 52
2023-01-04 02:28:23,925 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40580573280652366, 'Total loss': 0.40580573280652366} | train loss {'Reaction outcome loss': 0.20592924983777705, 'Total loss': 0.20592924983777705}
2023-01-04 02:28:23,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:23,925 INFO:     Epoch: 53
2023-01-04 02:28:25,536 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42563481082518895, 'Total loss': 0.42563481082518895} | train loss {'Reaction outcome loss': 0.20604471874552488, 'Total loss': 0.20604471874552488}
2023-01-04 02:28:25,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:25,536 INFO:     Epoch: 54
2023-01-04 02:28:27,108 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41900473535060884, 'Total loss': 0.41900473535060884} | train loss {'Reaction outcome loss': 0.2044112257469092, 'Total loss': 0.2044112257469092}
2023-01-04 02:28:27,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:27,108 INFO:     Epoch: 55
2023-01-04 02:28:28,686 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43218008875846864, 'Total loss': 0.43218008875846864} | train loss {'Reaction outcome loss': 0.2017587456226784, 'Total loss': 0.2017587456226784}
2023-01-04 02:28:28,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:28,687 INFO:     Epoch: 56
2023-01-04 02:28:30,277 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42394920786221824, 'Total loss': 0.42394920786221824} | train loss {'Reaction outcome loss': 0.2012048430781621, 'Total loss': 0.2012048430781621}
2023-01-04 02:28:30,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:30,277 INFO:     Epoch: 57
2023-01-04 02:28:31,878 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4035636126995087, 'Total loss': 0.4035636126995087} | train loss {'Reaction outcome loss': 0.2000896795822756, 'Total loss': 0.2000896795822756}
2023-01-04 02:28:31,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:31,878 INFO:     Epoch: 58
2023-01-04 02:28:33,450 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42659661968549095, 'Total loss': 0.42659661968549095} | train loss {'Reaction outcome loss': 0.19817002176096404, 'Total loss': 0.19817002176096404}
2023-01-04 02:28:33,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:33,450 INFO:     Epoch: 59
2023-01-04 02:28:35,058 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4270102639993032, 'Total loss': 0.4270102639993032} | train loss {'Reaction outcome loss': 0.1981592814771146, 'Total loss': 0.1981592814771146}
2023-01-04 02:28:35,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:35,058 INFO:     Epoch: 60
2023-01-04 02:28:36,627 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4378329704205195, 'Total loss': 0.4378329704205195} | train loss {'Reaction outcome loss': 0.19659733080923775, 'Total loss': 0.19659733080923775}
2023-01-04 02:28:36,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:36,627 INFO:     Epoch: 61
2023-01-04 02:28:38,210 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3894617632031441, 'Total loss': 0.3894617632031441} | train loss {'Reaction outcome loss': 0.19644936072184657, 'Total loss': 0.19644936072184657}
2023-01-04 02:28:38,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:38,210 INFO:     Epoch: 62
2023-01-04 02:28:39,803 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4198925753434499, 'Total loss': 0.4198925753434499} | train loss {'Reaction outcome loss': 0.19573622313837935, 'Total loss': 0.19573622313837935}
2023-01-04 02:28:39,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:39,804 INFO:     Epoch: 63
2023-01-04 02:28:41,405 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42019157310326893, 'Total loss': 0.42019157310326893} | train loss {'Reaction outcome loss': 0.19165119462150293, 'Total loss': 0.19165119462150293}
2023-01-04 02:28:41,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:41,406 INFO:     Epoch: 64
2023-01-04 02:28:43,004 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4098430971304576, 'Total loss': 0.4098430971304576} | train loss {'Reaction outcome loss': 0.18940122770893314, 'Total loss': 0.18940122770893314}
2023-01-04 02:28:43,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:43,004 INFO:     Epoch: 65
2023-01-04 02:28:44,587 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4344817936420441, 'Total loss': 0.4344817936420441} | train loss {'Reaction outcome loss': 0.190056929759083, 'Total loss': 0.190056929759083}
2023-01-04 02:28:44,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:44,587 INFO:     Epoch: 66
2023-01-04 02:28:46,186 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4377495457728704, 'Total loss': 0.4377495457728704} | train loss {'Reaction outcome loss': 0.18815199825504836, 'Total loss': 0.18815199825504836}
2023-01-04 02:28:46,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:46,187 INFO:     Epoch: 67
2023-01-04 02:28:47,780 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4033127894004186, 'Total loss': 0.4033127894004186} | train loss {'Reaction outcome loss': 0.18719562016645053, 'Total loss': 0.18719562016645053}
2023-01-04 02:28:47,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:47,781 INFO:     Epoch: 68
2023-01-04 02:28:49,390 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4164541959762573, 'Total loss': 0.4164541959762573} | train loss {'Reaction outcome loss': 0.18782005217062295, 'Total loss': 0.18782005217062295}
2023-01-04 02:28:49,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:49,390 INFO:     Epoch: 69
2023-01-04 02:28:51,009 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43675099313259125, 'Total loss': 0.43675099313259125} | train loss {'Reaction outcome loss': 0.18403125090361402, 'Total loss': 0.18403125090361402}
2023-01-04 02:28:51,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:51,009 INFO:     Epoch: 70
2023-01-04 02:28:52,618 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4124588449796041, 'Total loss': 0.4124588449796041} | train loss {'Reaction outcome loss': 0.1829227948778846, 'Total loss': 0.1829227948778846}
2023-01-04 02:28:52,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:52,619 INFO:     Epoch: 71
2023-01-04 02:28:54,196 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4486699322859446, 'Total loss': 0.4486699322859446} | train loss {'Reaction outcome loss': 0.18368685917153846, 'Total loss': 0.18368685917153846}
2023-01-04 02:28:54,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:54,196 INFO:     Epoch: 72
2023-01-04 02:28:55,796 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40694110294183095, 'Total loss': 0.40694110294183095} | train loss {'Reaction outcome loss': 0.1821944304218475, 'Total loss': 0.1821944304218475}
2023-01-04 02:28:55,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:55,796 INFO:     Epoch: 73
2023-01-04 02:28:57,397 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42411518494288125, 'Total loss': 0.42411518494288125} | train loss {'Reaction outcome loss': 0.18085452609688696, 'Total loss': 0.18085452609688696}
2023-01-04 02:28:57,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:57,397 INFO:     Epoch: 74
2023-01-04 02:28:58,967 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4005104472239812, 'Total loss': 0.4005104472239812} | train loss {'Reaction outcome loss': 0.18021576593963118, 'Total loss': 0.18021576593963118}
2023-01-04 02:28:58,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:28:58,967 INFO:     Epoch: 75
2023-01-04 02:29:00,549 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4154309352238973, 'Total loss': 0.4154309352238973} | train loss {'Reaction outcome loss': 0.1766782546973359, 'Total loss': 0.1766782546973359}
2023-01-04 02:29:00,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:00,550 INFO:     Epoch: 76
2023-01-04 02:29:02,129 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4325622797012329, 'Total loss': 0.4325622797012329} | train loss {'Reaction outcome loss': 0.17803780132238448, 'Total loss': 0.17803780132238448}
2023-01-04 02:29:02,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:02,130 INFO:     Epoch: 77
2023-01-04 02:29:03,701 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41687380770842236, 'Total loss': 0.41687380770842236} | train loss {'Reaction outcome loss': 0.17759562515565297, 'Total loss': 0.17759562515565297}
2023-01-04 02:29:03,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:03,701 INFO:     Epoch: 78
2023-01-04 02:29:05,312 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41592808862527214, 'Total loss': 0.41592808862527214} | train loss {'Reaction outcome loss': 0.17719559036331237, 'Total loss': 0.17719559036331237}
2023-01-04 02:29:05,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:05,312 INFO:     Epoch: 79
2023-01-04 02:29:06,891 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42154496113459267, 'Total loss': 0.42154496113459267} | train loss {'Reaction outcome loss': 0.17433282114347837, 'Total loss': 0.17433282114347837}
2023-01-04 02:29:06,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:06,891 INFO:     Epoch: 80
2023-01-04 02:29:08,494 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41880764563878375, 'Total loss': 0.41880764563878375} | train loss {'Reaction outcome loss': 0.17424765487548208, 'Total loss': 0.17424765487548208}
2023-01-04 02:29:08,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:08,495 INFO:     Epoch: 81
2023-01-04 02:29:10,103 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4630290100971858, 'Total loss': 0.4630290100971858} | train loss {'Reaction outcome loss': 0.17318249752160406, 'Total loss': 0.17318249752160406}
2023-01-04 02:29:10,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:10,104 INFO:     Epoch: 82
2023-01-04 02:29:11,694 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48975715736548103, 'Total loss': 0.48975715736548103} | train loss {'Reaction outcome loss': 0.17414040341429468, 'Total loss': 0.17414040341429468}
2023-01-04 02:29:11,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:11,694 INFO:     Epoch: 83
2023-01-04 02:29:13,270 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41578955004612606, 'Total loss': 0.41578955004612606} | train loss {'Reaction outcome loss': 0.17222782257047012, 'Total loss': 0.17222782257047012}
2023-01-04 02:29:13,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:13,270 INFO:     Epoch: 84
2023-01-04 02:29:14,847 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4433357402682304, 'Total loss': 0.4433357402682304} | train loss {'Reaction outcome loss': 0.17353124045053103, 'Total loss': 0.17353124045053103}
2023-01-04 02:29:14,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:14,847 INFO:     Epoch: 85
2023-01-04 02:29:16,431 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4255123406648636, 'Total loss': 0.4255123406648636} | train loss {'Reaction outcome loss': 0.16961477114309143, 'Total loss': 0.16961477114309143}
2023-01-04 02:29:16,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:16,433 INFO:     Epoch: 86
2023-01-04 02:29:18,028 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45660536686579384, 'Total loss': 0.45660536686579384} | train loss {'Reaction outcome loss': 0.1684212052079774, 'Total loss': 0.1684212052079774}
2023-01-04 02:29:18,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:18,028 INFO:     Epoch: 87
2023-01-04 02:29:19,604 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45383717815081276, 'Total loss': 0.45383717815081276} | train loss {'Reaction outcome loss': 0.1697552459464021, 'Total loss': 0.1697552459464021}
2023-01-04 02:29:19,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:19,604 INFO:     Epoch: 88
2023-01-04 02:29:21,187 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.459915018081665, 'Total loss': 0.459915018081665} | train loss {'Reaction outcome loss': 0.16708935598713637, 'Total loss': 0.16708935598713637}
2023-01-04 02:29:21,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:21,187 INFO:     Epoch: 89
2023-01-04 02:29:22,763 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42339852352937063, 'Total loss': 0.42339852352937063} | train loss {'Reaction outcome loss': 0.16653284204131277, 'Total loss': 0.16653284204131277}
2023-01-04 02:29:22,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:22,764 INFO:     Epoch: 90
2023-01-04 02:29:24,366 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45308609008789064, 'Total loss': 0.45308609008789064} | train loss {'Reaction outcome loss': 0.16620465090335176, 'Total loss': 0.16620465090335176}
2023-01-04 02:29:24,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:24,366 INFO:     Epoch: 91
2023-01-04 02:29:25,964 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4438294529914856, 'Total loss': 0.4438294529914856} | train loss {'Reaction outcome loss': 0.1665403203304558, 'Total loss': 0.1665403203304558}
2023-01-04 02:29:25,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:25,965 INFO:     Epoch: 92
2023-01-04 02:29:27,578 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.438948259751002, 'Total loss': 0.438948259751002} | train loss {'Reaction outcome loss': 0.16663977646534026, 'Total loss': 0.16663977646534026}
2023-01-04 02:29:27,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:27,579 INFO:     Epoch: 93
2023-01-04 02:29:29,185 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44532771905263263, 'Total loss': 0.44532771905263263} | train loss {'Reaction outcome loss': 0.16524453292920316, 'Total loss': 0.16524453292920316}
2023-01-04 02:29:29,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:29,185 INFO:     Epoch: 94
2023-01-04 02:29:30,771 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4768430491288503, 'Total loss': 0.4768430491288503} | train loss {'Reaction outcome loss': 0.16432452337122963, 'Total loss': 0.16432452337122963}
2023-01-04 02:29:30,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:30,772 INFO:     Epoch: 95
2023-01-04 02:29:32,354 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42415193319320676, 'Total loss': 0.42415193319320676} | train loss {'Reaction outcome loss': 0.16339525426771953, 'Total loss': 0.16339525426771953}
2023-01-04 02:29:32,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:32,354 INFO:     Epoch: 96
2023-01-04 02:29:33,938 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4428410922487577, 'Total loss': 0.4428410922487577} | train loss {'Reaction outcome loss': 0.16304647488125268, 'Total loss': 0.16304647488125268}
2023-01-04 02:29:33,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:33,938 INFO:     Epoch: 97
2023-01-04 02:29:35,547 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4362827703356743, 'Total loss': 0.4362827703356743} | train loss {'Reaction outcome loss': 0.1626993072266779, 'Total loss': 0.1626993072266779}
2023-01-04 02:29:35,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:35,547 INFO:     Epoch: 98
2023-01-04 02:29:37,150 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45191198388735454, 'Total loss': 0.45191198388735454} | train loss {'Reaction outcome loss': 0.16032292427372757, 'Total loss': 0.16032292427372757}
2023-01-04 02:29:37,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:37,150 INFO:     Epoch: 99
2023-01-04 02:29:38,733 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4618772029876709, 'Total loss': 0.4618772029876709} | train loss {'Reaction outcome loss': 0.15975840932886748, 'Total loss': 0.15975840932886748}
2023-01-04 02:29:38,733 INFO:     Best model found after epoch 35 of 100.
2023-01-04 02:29:38,733 INFO:   Done with stage: TRAINING
2023-01-04 02:29:38,733 INFO:   Starting stage: EVALUATION
2023-01-04 02:29:38,868 INFO:   Done with stage: EVALUATION
2023-01-04 02:29:38,877 INFO:   Leaving out SEQ value Fold_0
2023-01-04 02:29:38,889 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:29:38,889 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:29:39,537 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:29:39,537 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:29:39,606 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:29:39,606 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:29:39,606 INFO:     No hyperparam tuning for this model
2023-01-04 02:29:39,606 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:29:39,606 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:29:39,607 INFO:     None feature selector for col prot
2023-01-04 02:29:39,607 INFO:     None feature selector for col prot
2023-01-04 02:29:39,607 INFO:     None feature selector for col prot
2023-01-04 02:29:39,608 INFO:     None feature selector for col chem
2023-01-04 02:29:39,608 INFO:     None feature selector for col chem
2023-01-04 02:29:39,608 INFO:     None feature selector for col chem
2023-01-04 02:29:39,608 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:29:39,608 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:29:39,609 INFO:     Number of params in model 70141
2023-01-04 02:29:39,612 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:29:39,612 INFO:   Starting stage: TRAINING
2023-01-04 02:29:39,656 INFO:     Val loss before train {'Reaction outcome loss': 1.0658934434254965, 'Total loss': 1.0658934434254965}
2023-01-04 02:29:39,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:39,656 INFO:     Epoch: 0
2023-01-04 02:29:41,258 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7066351413726807, 'Total loss': 0.7066351413726807} | train loss {'Reaction outcome loss': 0.8231083021981873, 'Total loss': 0.8231083021981873}
2023-01-04 02:29:41,258 INFO:     Found new best model at epoch 0
2023-01-04 02:29:41,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:41,259 INFO:     Epoch: 1
2023-01-04 02:29:42,825 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6017325282096863, 'Total loss': 0.6017325282096863} | train loss {'Reaction outcome loss': 0.5839467737143927, 'Total loss': 0.5839467737143927}
2023-01-04 02:29:42,825 INFO:     Found new best model at epoch 1
2023-01-04 02:29:42,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:42,826 INFO:     Epoch: 2
2023-01-04 02:29:44,410 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5654594898223877, 'Total loss': 0.5654594898223877} | train loss {'Reaction outcome loss': 0.513499605666547, 'Total loss': 0.513499605666547}
2023-01-04 02:29:44,410 INFO:     Found new best model at epoch 2
2023-01-04 02:29:44,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:44,411 INFO:     Epoch: 3
2023-01-04 02:29:45,988 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5584584891796112, 'Total loss': 0.5584584891796112} | train loss {'Reaction outcome loss': 0.47281450071256526, 'Total loss': 0.47281450071256526}
2023-01-04 02:29:45,988 INFO:     Found new best model at epoch 3
2023-01-04 02:29:45,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:45,989 INFO:     Epoch: 4
2023-01-04 02:29:47,566 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5134828527768452, 'Total loss': 0.5134828527768452} | train loss {'Reaction outcome loss': 0.44826595746252657, 'Total loss': 0.44826595746252657}
2023-01-04 02:29:47,567 INFO:     Found new best model at epoch 4
2023-01-04 02:29:47,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:47,568 INFO:     Epoch: 5
2023-01-04 02:29:49,171 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5267089128494262, 'Total loss': 0.5267089128494262} | train loss {'Reaction outcome loss': 0.4277866937111329, 'Total loss': 0.4277866937111329}
2023-01-04 02:29:49,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:49,172 INFO:     Epoch: 6
2023-01-04 02:29:50,781 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4956934839487076, 'Total loss': 0.4956934839487076} | train loss {'Reaction outcome loss': 0.4104279312611061, 'Total loss': 0.4104279312611061}
2023-01-04 02:29:50,782 INFO:     Found new best model at epoch 6
2023-01-04 02:29:50,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:50,783 INFO:     Epoch: 7
2023-01-04 02:29:52,371 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5065109630425771, 'Total loss': 0.5065109630425771} | train loss {'Reaction outcome loss': 0.39633529616968477, 'Total loss': 0.39633529616968477}
2023-01-04 02:29:52,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:52,371 INFO:     Epoch: 8
2023-01-04 02:29:53,982 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4990089734395345, 'Total loss': 0.4990089734395345} | train loss {'Reaction outcome loss': 0.3861592065570128, 'Total loss': 0.3861592065570128}
2023-01-04 02:29:53,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:53,983 INFO:     Epoch: 9
2023-01-04 02:29:55,589 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4873670736948649, 'Total loss': 0.4873670736948649} | train loss {'Reaction outcome loss': 0.3754140492120798, 'Total loss': 0.3754140492120798}
2023-01-04 02:29:55,590 INFO:     Found new best model at epoch 9
2023-01-04 02:29:55,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:55,591 INFO:     Epoch: 10
2023-01-04 02:29:57,175 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4940032164255778, 'Total loss': 0.4940032164255778} | train loss {'Reaction outcome loss': 0.36599111271491885, 'Total loss': 0.36599111271491885}
2023-01-04 02:29:57,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:57,176 INFO:     Epoch: 11
2023-01-04 02:29:58,770 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4816699584325155, 'Total loss': 0.4816699584325155} | train loss {'Reaction outcome loss': 0.3588131363265706, 'Total loss': 0.3588131363265706}
2023-01-04 02:29:58,771 INFO:     Found new best model at epoch 11
2023-01-04 02:29:58,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:29:58,771 INFO:     Epoch: 12
2023-01-04 02:30:00,356 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47669660250345863, 'Total loss': 0.47669660250345863} | train loss {'Reaction outcome loss': 0.35133062305785445, 'Total loss': 0.35133062305785445}
2023-01-04 02:30:00,356 INFO:     Found new best model at epoch 12
2023-01-04 02:30:00,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:00,357 INFO:     Epoch: 13
2023-01-04 02:30:01,938 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47890452345212303, 'Total loss': 0.47890452345212303} | train loss {'Reaction outcome loss': 0.3413062014610228, 'Total loss': 0.3413062014610228}
2023-01-04 02:30:01,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:01,939 INFO:     Epoch: 14
2023-01-04 02:30:03,521 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4746099372704824, 'Total loss': 0.4746099372704824} | train loss {'Reaction outcome loss': 0.3344384966975581, 'Total loss': 0.3344384966975581}
2023-01-04 02:30:03,521 INFO:     Found new best model at epoch 14
2023-01-04 02:30:03,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:03,522 INFO:     Epoch: 15
2023-01-04 02:30:05,093 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4836250861485799, 'Total loss': 0.4836250861485799} | train loss {'Reaction outcome loss': 0.329844790028177, 'Total loss': 0.329844790028177}
2023-01-04 02:30:05,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:05,093 INFO:     Epoch: 16
2023-01-04 02:30:06,670 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4786172568798065, 'Total loss': 0.4786172568798065} | train loss {'Reaction outcome loss': 0.3233154875219521, 'Total loss': 0.3233154875219521}
2023-01-04 02:30:06,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:06,671 INFO:     Epoch: 17
2023-01-04 02:30:08,252 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4907002985477448, 'Total loss': 0.4907002985477448} | train loss {'Reaction outcome loss': 0.3165311838642959, 'Total loss': 0.3165311838642959}
2023-01-04 02:30:08,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:08,252 INFO:     Epoch: 18
2023-01-04 02:30:09,812 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4790040820837021, 'Total loss': 0.4790040820837021} | train loss {'Reaction outcome loss': 0.3130800051301935, 'Total loss': 0.3130800051301935}
2023-01-04 02:30:09,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:09,812 INFO:     Epoch: 19
2023-01-04 02:30:11,426 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48600609302520753, 'Total loss': 0.48600609302520753} | train loss {'Reaction outcome loss': 0.3055800155457789, 'Total loss': 0.3055800155457789}
2023-01-04 02:30:11,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:11,426 INFO:     Epoch: 20
2023-01-04 02:30:13,039 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45787354608376823, 'Total loss': 0.45787354608376823} | train loss {'Reaction outcome loss': 0.30146020335437607, 'Total loss': 0.30146020335437607}
2023-01-04 02:30:13,039 INFO:     Found new best model at epoch 20
2023-01-04 02:30:13,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:13,040 INFO:     Epoch: 21
2023-01-04 02:30:14,594 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4861127108335495, 'Total loss': 0.4861127108335495} | train loss {'Reaction outcome loss': 0.29549209341189286, 'Total loss': 0.29549209341189286}
2023-01-04 02:30:14,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:14,594 INFO:     Epoch: 22
2023-01-04 02:30:16,204 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4875176707903544, 'Total loss': 0.4875176707903544} | train loss {'Reaction outcome loss': 0.29155488072955693, 'Total loss': 0.29155488072955693}
2023-01-04 02:30:16,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:16,204 INFO:     Epoch: 23
2023-01-04 02:30:17,763 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4625755469004313, 'Total loss': 0.4625755469004313} | train loss {'Reaction outcome loss': 0.28612131437789784, 'Total loss': 0.28612131437789784}
2023-01-04 02:30:17,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:17,763 INFO:     Epoch: 24
2023-01-04 02:30:19,333 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48005043069521586, 'Total loss': 0.48005043069521586} | train loss {'Reaction outcome loss': 0.2818456491197113, 'Total loss': 0.2818456491197113}
2023-01-04 02:30:19,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:19,333 INFO:     Epoch: 25
2023-01-04 02:30:20,909 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4677518526713053, 'Total loss': 0.4677518526713053} | train loss {'Reaction outcome loss': 0.2792471495259852, 'Total loss': 0.2792471495259852}
2023-01-04 02:30:20,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:20,910 INFO:     Epoch: 26
2023-01-04 02:30:22,518 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45584988097349805, 'Total loss': 0.45584988097349805} | train loss {'Reaction outcome loss': 0.27357545845808773, 'Total loss': 0.27357545845808773}
2023-01-04 02:30:22,519 INFO:     Found new best model at epoch 26
2023-01-04 02:30:22,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:22,520 INFO:     Epoch: 27
2023-01-04 02:30:24,095 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46724242170651753, 'Total loss': 0.46724242170651753} | train loss {'Reaction outcome loss': 0.2695954171192907, 'Total loss': 0.2695954171192907}
2023-01-04 02:30:24,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:24,096 INFO:     Epoch: 28
2023-01-04 02:30:25,674 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5079433639844259, 'Total loss': 0.5079433639844259} | train loss {'Reaction outcome loss': 0.26806462129210906, 'Total loss': 0.26806462129210906}
2023-01-04 02:30:25,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:25,674 INFO:     Epoch: 29
2023-01-04 02:30:27,241 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4913827419281006, 'Total loss': 0.4913827419281006} | train loss {'Reaction outcome loss': 0.2643975386001768, 'Total loss': 0.2643975386001768}
2023-01-04 02:30:27,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:27,241 INFO:     Epoch: 30
2023-01-04 02:30:28,822 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5019294420878092, 'Total loss': 0.5019294420878092} | train loss {'Reaction outcome loss': 0.260837166848844, 'Total loss': 0.260837166848844}
2023-01-04 02:30:28,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:28,823 INFO:     Epoch: 31
2023-01-04 02:30:30,403 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5160956919193268, 'Total loss': 0.5160956919193268} | train loss {'Reaction outcome loss': 0.2557360307333896, 'Total loss': 0.2557360307333896}
2023-01-04 02:30:30,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:30,403 INFO:     Epoch: 32
2023-01-04 02:30:31,972 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47479466497898104, 'Total loss': 0.47479466497898104} | train loss {'Reaction outcome loss': 0.2548304275086109, 'Total loss': 0.2548304275086109}
2023-01-04 02:30:31,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:31,972 INFO:     Epoch: 33
2023-01-04 02:30:33,573 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5064814428488413, 'Total loss': 0.5064814428488413} | train loss {'Reaction outcome loss': 0.2499555512637335, 'Total loss': 0.2499555512637335}
2023-01-04 02:30:33,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:33,574 INFO:     Epoch: 34
2023-01-04 02:30:35,182 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5072579423586527, 'Total loss': 0.5072579423586527} | train loss {'Reaction outcome loss': 0.2512943295721155, 'Total loss': 0.2512943295721155}
2023-01-04 02:30:35,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:35,183 INFO:     Epoch: 35
2023-01-04 02:30:36,740 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48424930274486544, 'Total loss': 0.48424930274486544} | train loss {'Reaction outcome loss': 0.2480984726635209, 'Total loss': 0.2480984726635209}
2023-01-04 02:30:36,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:36,740 INFO:     Epoch: 36
2023-01-04 02:30:38,312 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.484865407148997, 'Total loss': 0.484865407148997} | train loss {'Reaction outcome loss': 0.24567330916867638, 'Total loss': 0.24567330916867638}
2023-01-04 02:30:38,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:38,312 INFO:     Epoch: 37
2023-01-04 02:30:39,905 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5123084763685862, 'Total loss': 0.5123084763685862} | train loss {'Reaction outcome loss': 0.2397372488639433, 'Total loss': 0.2397372488639433}
2023-01-04 02:30:39,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:39,905 INFO:     Epoch: 38
2023-01-04 02:30:41,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.520096230506897, 'Total loss': 0.520096230506897} | train loss {'Reaction outcome loss': 0.2382420448001719, 'Total loss': 0.2382420448001719}
2023-01-04 02:30:41,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:41,500 INFO:     Epoch: 39
2023-01-04 02:30:43,063 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.508664216597875, 'Total loss': 0.508664216597875} | train loss {'Reaction outcome loss': 0.23607863453182862, 'Total loss': 0.23607863453182862}
2023-01-04 02:30:43,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:43,063 INFO:     Epoch: 40
2023-01-04 02:30:44,665 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5007202893495559, 'Total loss': 0.5007202893495559} | train loss {'Reaction outcome loss': 0.23266783813490485, 'Total loss': 0.23266783813490485}
2023-01-04 02:30:44,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:44,665 INFO:     Epoch: 41
2023-01-04 02:30:46,245 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46492401758829754, 'Total loss': 0.46492401758829754} | train loss {'Reaction outcome loss': 0.23196489804417547, 'Total loss': 0.23196489804417547}
2023-01-04 02:30:46,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:46,245 INFO:     Epoch: 42
2023-01-04 02:30:47,816 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48926466703414917, 'Total loss': 0.48926466703414917} | train loss {'Reaction outcome loss': 0.2310587283305443, 'Total loss': 0.2310587283305443}
2023-01-04 02:30:47,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:47,816 INFO:     Epoch: 43
2023-01-04 02:30:49,424 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47139504651228586, 'Total loss': 0.47139504651228586} | train loss {'Reaction outcome loss': 0.2274847703911092, 'Total loss': 0.2274847703911092}
2023-01-04 02:30:49,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:49,424 INFO:     Epoch: 44
2023-01-04 02:30:51,010 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.505148446559906, 'Total loss': 0.505148446559906} | train loss {'Reaction outcome loss': 0.22502643504880204, 'Total loss': 0.22502643504880204}
2023-01-04 02:30:51,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:51,011 INFO:     Epoch: 45
2023-01-04 02:30:52,620 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4965290665626526, 'Total loss': 0.4965290665626526} | train loss {'Reaction outcome loss': 0.2209390658803665, 'Total loss': 0.2209390658803665}
2023-01-04 02:30:52,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:52,620 INFO:     Epoch: 46
2023-01-04 02:30:54,203 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5069188872973124, 'Total loss': 0.5069188872973124} | train loss {'Reaction outcome loss': 0.2241166071816735, 'Total loss': 0.2241166071816735}
2023-01-04 02:30:54,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:54,204 INFO:     Epoch: 47
2023-01-04 02:30:55,813 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5009654919306438, 'Total loss': 0.5009654919306438} | train loss {'Reaction outcome loss': 0.2234513848802469, 'Total loss': 0.2234513848802469}
2023-01-04 02:30:55,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:55,813 INFO:     Epoch: 48
2023-01-04 02:30:57,422 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4969573676586151, 'Total loss': 0.4969573676586151} | train loss {'Reaction outcome loss': 0.2156940862590814, 'Total loss': 0.2156940862590814}
2023-01-04 02:30:57,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:57,422 INFO:     Epoch: 49
2023-01-04 02:30:59,000 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5089979906876881, 'Total loss': 0.5089979906876881} | train loss {'Reaction outcome loss': 0.21518171945736356, 'Total loss': 0.21518171945736356}
2023-01-04 02:30:59,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:30:59,001 INFO:     Epoch: 50
2023-01-04 02:31:00,611 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.501611198981603, 'Total loss': 0.501611198981603} | train loss {'Reaction outcome loss': 0.2152010207846217, 'Total loss': 0.2152010207846217}
2023-01-04 02:31:00,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:00,611 INFO:     Epoch: 51
2023-01-04 02:31:02,200 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5104688823223114, 'Total loss': 0.5104688823223114} | train loss {'Reaction outcome loss': 0.2104446311229772, 'Total loss': 0.2104446311229772}
2023-01-04 02:31:02,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:02,200 INFO:     Epoch: 52
2023-01-04 02:31:03,767 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5056856522957484, 'Total loss': 0.5056856522957484} | train loss {'Reaction outcome loss': 0.21057961229914732, 'Total loss': 0.21057961229914732}
2023-01-04 02:31:03,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:03,767 INFO:     Epoch: 53
2023-01-04 02:31:05,376 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5238257646560669, 'Total loss': 0.5238257646560669} | train loss {'Reaction outcome loss': 0.2092768746856464, 'Total loss': 0.2092768746856464}
2023-01-04 02:31:05,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:05,377 INFO:     Epoch: 54
2023-01-04 02:31:06,958 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5167551179726918, 'Total loss': 0.5167551179726918} | train loss {'Reaction outcome loss': 0.20697693269781386, 'Total loss': 0.20697693269781386}
2023-01-04 02:31:06,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:06,958 INFO:     Epoch: 55
2023-01-04 02:31:08,548 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5339568932851155, 'Total loss': 0.5339568932851155} | train loss {'Reaction outcome loss': 0.2051735801799019, 'Total loss': 0.2051735801799019}
2023-01-04 02:31:08,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:08,548 INFO:     Epoch: 56
2023-01-04 02:31:10,115 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5036574165026347, 'Total loss': 0.5036574165026347} | train loss {'Reaction outcome loss': 0.20333314742077224, 'Total loss': 0.20333314742077224}
2023-01-04 02:31:10,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:10,115 INFO:     Epoch: 57
2023-01-04 02:31:11,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5237258474032084, 'Total loss': 0.5237258474032084} | train loss {'Reaction outcome loss': 0.20408727314295996, 'Total loss': 0.20408727314295996}
2023-01-04 02:31:11,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:11,710 INFO:     Epoch: 58
2023-01-04 02:31:13,290 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5298819422721863, 'Total loss': 0.5298819422721863} | train loss {'Reaction outcome loss': 0.20197404468309704, 'Total loss': 0.20197404468309704}
2023-01-04 02:31:13,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:13,291 INFO:     Epoch: 59
2023-01-04 02:31:14,873 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.524755307038625, 'Total loss': 0.524755307038625} | train loss {'Reaction outcome loss': 0.1989481129486413, 'Total loss': 0.1989481129486413}
2023-01-04 02:31:14,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:14,873 INFO:     Epoch: 60
2023-01-04 02:31:16,456 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5358731160561244, 'Total loss': 0.5358731160561244} | train loss {'Reaction outcome loss': 0.20111594268929783, 'Total loss': 0.20111594268929783}
2023-01-04 02:31:16,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:16,456 INFO:     Epoch: 61
2023-01-04 02:31:18,015 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5560871422290802, 'Total loss': 0.5560871422290802} | train loss {'Reaction outcome loss': 0.19680252479538865, 'Total loss': 0.19680252479538865}
2023-01-04 02:31:18,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:18,016 INFO:     Epoch: 62
2023-01-04 02:31:19,588 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5156696602702141, 'Total loss': 0.5156696602702141} | train loss {'Reaction outcome loss': 0.19561429234072022, 'Total loss': 0.19561429234072022}
2023-01-04 02:31:19,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:19,588 INFO:     Epoch: 63
2023-01-04 02:31:21,165 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5181218236684799, 'Total loss': 0.5181218236684799} | train loss {'Reaction outcome loss': 0.19518127591505538, 'Total loss': 0.19518127591505538}
2023-01-04 02:31:21,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:21,166 INFO:     Epoch: 64
2023-01-04 02:31:22,775 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5047211850682894, 'Total loss': 0.5047211850682894} | train loss {'Reaction outcome loss': 0.19511056620709216, 'Total loss': 0.19511056620709216}
2023-01-04 02:31:22,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:22,775 INFO:     Epoch: 65
2023-01-04 02:31:24,339 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5408812284469604, 'Total loss': 0.5408812284469604} | train loss {'Reaction outcome loss': 0.19100295700622302, 'Total loss': 0.19100295700622302}
2023-01-04 02:31:24,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:24,339 INFO:     Epoch: 66
2023-01-04 02:31:25,928 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5375162561734518, 'Total loss': 0.5375162561734518} | train loss {'Reaction outcome loss': 0.19280770288127727, 'Total loss': 0.19280770288127727}
2023-01-04 02:31:25,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:25,928 INFO:     Epoch: 67
2023-01-04 02:31:27,499 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5401760836442312, 'Total loss': 0.5401760836442312} | train loss {'Reaction outcome loss': 0.18813106058722864, 'Total loss': 0.18813106058722864}
2023-01-04 02:31:27,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:27,500 INFO:     Epoch: 68
2023-01-04 02:31:29,070 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5520999968051911, 'Total loss': 0.5520999968051911} | train loss {'Reaction outcome loss': 0.18741060564987852, 'Total loss': 0.18741060564987852}
2023-01-04 02:31:29,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:29,071 INFO:     Epoch: 69
2023-01-04 02:31:30,619 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5110564281543096, 'Total loss': 0.5110564281543096} | train loss {'Reaction outcome loss': 0.18896868986750606, 'Total loss': 0.18896868986750606}
2023-01-04 02:31:30,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:30,620 INFO:     Epoch: 70
2023-01-04 02:31:32,228 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5409577508767446, 'Total loss': 0.5409577508767446} | train loss {'Reaction outcome loss': 0.1872793245503176, 'Total loss': 0.1872793245503176}
2023-01-04 02:31:32,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:32,228 INFO:     Epoch: 71
2023-01-04 02:31:33,836 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5340769022703171, 'Total loss': 0.5340769022703171} | train loss {'Reaction outcome loss': 0.1860285716770339, 'Total loss': 0.1860285716770339}
2023-01-04 02:31:33,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:33,837 INFO:     Epoch: 72
2023-01-04 02:31:35,415 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5235912104447683, 'Total loss': 0.5235912104447683} | train loss {'Reaction outcome loss': 0.18379860329883593, 'Total loss': 0.18379860329883593}
2023-01-04 02:31:35,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:35,416 INFO:     Epoch: 73
2023-01-04 02:31:36,990 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5410550057888031, 'Total loss': 0.5410550057888031} | train loss {'Reaction outcome loss': 0.18126215006693872, 'Total loss': 0.18126215006693872}
2023-01-04 02:31:36,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:36,990 INFO:     Epoch: 74
2023-01-04 02:31:38,543 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5363988916079203, 'Total loss': 0.5363988916079203} | train loss {'Reaction outcome loss': 0.18166200393797272, 'Total loss': 0.18166200393797272}
2023-01-04 02:31:38,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:38,543 INFO:     Epoch: 75
2023-01-04 02:31:40,123 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5409971217314402, 'Total loss': 0.5409971217314402} | train loss {'Reaction outcome loss': 0.17969721383381174, 'Total loss': 0.17969721383381174}
2023-01-04 02:31:40,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:40,124 INFO:     Epoch: 76
2023-01-04 02:31:41,703 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5568677961826325, 'Total loss': 0.5568677961826325} | train loss {'Reaction outcome loss': 0.17911742423681448, 'Total loss': 0.17911742423681448}
2023-01-04 02:31:41,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:41,703 INFO:     Epoch: 77
2023-01-04 02:31:43,276 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5184708595275879, 'Total loss': 0.5184708595275879} | train loss {'Reaction outcome loss': 0.1777285998959067, 'Total loss': 0.1777285998959067}
2023-01-04 02:31:43,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:43,277 INFO:     Epoch: 78
2023-01-04 02:31:44,837 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5563087860743204, 'Total loss': 0.5563087860743204} | train loss {'Reaction outcome loss': 0.1773705322662518, 'Total loss': 0.1773705322662518}
2023-01-04 02:31:44,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:44,838 INFO:     Epoch: 79
2023-01-04 02:31:46,444 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5462424496809641, 'Total loss': 0.5462424496809641} | train loss {'Reaction outcome loss': 0.17778228018024977, 'Total loss': 0.17778228018024977}
2023-01-04 02:31:46,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:46,444 INFO:     Epoch: 80
2023-01-04 02:31:47,995 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5061437676350276, 'Total loss': 0.5061437676350276} | train loss {'Reaction outcome loss': 0.17799936203680333, 'Total loss': 0.17799936203680333}
2023-01-04 02:31:47,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:47,996 INFO:     Epoch: 81
2023-01-04 02:31:49,557 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5346544106801351, 'Total loss': 0.5346544106801351} | train loss {'Reaction outcome loss': 0.17427452251886147, 'Total loss': 0.17427452251886147}
2023-01-04 02:31:49,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:49,557 INFO:     Epoch: 82
2023-01-04 02:31:51,166 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5304349794983864, 'Total loss': 0.5304349794983864} | train loss {'Reaction outcome loss': 0.17566090057107764, 'Total loss': 0.17566090057107764}
2023-01-04 02:31:51,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:51,166 INFO:     Epoch: 83
2023-01-04 02:31:52,740 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5290370513995488, 'Total loss': 0.5290370513995488} | train loss {'Reaction outcome loss': 0.173387775238413, 'Total loss': 0.173387775238413}
2023-01-04 02:31:52,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:52,741 INFO:     Epoch: 84
2023-01-04 02:31:54,301 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5536673625310262, 'Total loss': 0.5536673625310262} | train loss {'Reaction outcome loss': 0.17513141499655524, 'Total loss': 0.17513141499655524}
2023-01-04 02:31:54,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:54,301 INFO:     Epoch: 85
2023-01-04 02:31:55,909 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5707836031913758, 'Total loss': 0.5707836031913758} | train loss {'Reaction outcome loss': 0.17151805850928717, 'Total loss': 0.17151805850928717}
2023-01-04 02:31:55,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:55,910 INFO:     Epoch: 86
2023-01-04 02:31:57,461 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.547435466448466, 'Total loss': 0.547435466448466} | train loss {'Reaction outcome loss': 0.17314663958348278, 'Total loss': 0.17314663958348278}
2023-01-04 02:31:57,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:57,461 INFO:     Epoch: 87
2023-01-04 02:31:59,070 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5190544982751211, 'Total loss': 0.5190544982751211} | train loss {'Reaction outcome loss': 0.1715670381230812, 'Total loss': 0.1715670381230812}
2023-01-04 02:31:59,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:31:59,070 INFO:     Epoch: 88
2023-01-04 02:32:00,672 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5721091945966085, 'Total loss': 0.5721091945966085} | train loss {'Reaction outcome loss': 0.16770370023828135, 'Total loss': 0.16770370023828135}
2023-01-04 02:32:00,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:00,672 INFO:     Epoch: 89
2023-01-04 02:32:02,240 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5693594137827556, 'Total loss': 0.5693594137827556} | train loss {'Reaction outcome loss': 0.167879661123683, 'Total loss': 0.167879661123683}
2023-01-04 02:32:02,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:02,240 INFO:     Epoch: 90
2023-01-04 02:32:03,820 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5603703677654266, 'Total loss': 0.5603703677654266} | train loss {'Reaction outcome loss': 0.16842493033512448, 'Total loss': 0.16842493033512448}
2023-01-04 02:32:03,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:03,820 INFO:     Epoch: 91
2023-01-04 02:32:05,386 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5701604266961415, 'Total loss': 0.5701604266961415} | train loss {'Reaction outcome loss': 0.1669517909346597, 'Total loss': 0.1669517909346597}
2023-01-04 02:32:05,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:05,387 INFO:     Epoch: 92
2023-01-04 02:32:06,964 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5257567207018534, 'Total loss': 0.5257567207018534} | train loss {'Reaction outcome loss': 0.16674135119593056, 'Total loss': 0.16674135119593056}
2023-01-04 02:32:06,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:06,965 INFO:     Epoch: 93
2023-01-04 02:32:08,543 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5498371084531148, 'Total loss': 0.5498371084531148} | train loss {'Reaction outcome loss': 0.1655587892517121, 'Total loss': 0.1655587892517121}
2023-01-04 02:32:08,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:08,543 INFO:     Epoch: 94
2023-01-04 02:32:10,112 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5405674089988073, 'Total loss': 0.5405674089988073} | train loss {'Reaction outcome loss': 0.1645715548350972, 'Total loss': 0.1645715548350972}
2023-01-04 02:32:10,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:10,112 INFO:     Epoch: 95
2023-01-04 02:32:11,717 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5466669057806333, 'Total loss': 0.5466669057806333} | train loss {'Reaction outcome loss': 0.16434521572052563, 'Total loss': 0.16434521572052563}
2023-01-04 02:32:11,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:11,718 INFO:     Epoch: 96
2023-01-04 02:32:13,288 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.51576875547568, 'Total loss': 0.51576875547568} | train loss {'Reaction outcome loss': 0.16666985089707115, 'Total loss': 0.16666985089707115}
2023-01-04 02:32:13,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:13,288 INFO:     Epoch: 97
2023-01-04 02:32:14,877 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5254732737938563, 'Total loss': 0.5254732737938563} | train loss {'Reaction outcome loss': 0.1634867119324142, 'Total loss': 0.1634867119324142}
2023-01-04 02:32:14,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:14,878 INFO:     Epoch: 98
2023-01-04 02:32:16,487 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5488705058892568, 'Total loss': 0.5488705058892568} | train loss {'Reaction outcome loss': 0.1621392078316995, 'Total loss': 0.1621392078316995}
2023-01-04 02:32:16,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:16,487 INFO:     Epoch: 99
2023-01-04 02:32:18,094 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5440089285373688, 'Total loss': 0.5440089285373688} | train loss {'Reaction outcome loss': 0.15962393745698417, 'Total loss': 0.15962393745698417}
2023-01-04 02:32:18,094 INFO:     Best model found after epoch 27 of 100.
2023-01-04 02:32:18,094 INFO:   Done with stage: TRAINING
2023-01-04 02:32:18,094 INFO:   Starting stage: EVALUATION
2023-01-04 02:32:18,229 INFO:   Done with stage: EVALUATION
2023-01-04 02:32:18,229 INFO:   Leaving out SEQ value Fold_1
2023-01-04 02:32:18,241 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:32:18,242 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:32:18,908 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:32:18,908 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:32:18,977 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:32:18,977 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:32:18,977 INFO:     No hyperparam tuning for this model
2023-01-04 02:32:18,977 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:32:18,977 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:32:18,978 INFO:     None feature selector for col prot
2023-01-04 02:32:18,978 INFO:     None feature selector for col prot
2023-01-04 02:32:18,978 INFO:     None feature selector for col prot
2023-01-04 02:32:18,979 INFO:     None feature selector for col chem
2023-01-04 02:32:18,979 INFO:     None feature selector for col chem
2023-01-04 02:32:18,979 INFO:     None feature selector for col chem
2023-01-04 02:32:18,979 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:32:18,979 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:32:18,980 INFO:     Number of params in model 70141
2023-01-04 02:32:18,983 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:32:18,984 INFO:   Starting stage: TRAINING
2023-01-04 02:32:19,028 INFO:     Val loss before train {'Reaction outcome loss': 1.0039549152056375, 'Total loss': 1.0039549152056375}
2023-01-04 02:32:19,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:19,029 INFO:     Epoch: 0
2023-01-04 02:32:20,618 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6923290967941285, 'Total loss': 0.6923290967941285} | train loss {'Reaction outcome loss': 0.8590641275480173, 'Total loss': 0.8590641275480173}
2023-01-04 02:32:20,618 INFO:     Found new best model at epoch 0
2023-01-04 02:32:20,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:20,619 INFO:     Epoch: 1
2023-01-04 02:32:22,207 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5387112855911255, 'Total loss': 0.5387112855911255} | train loss {'Reaction outcome loss': 0.6017995690273128, 'Total loss': 0.6017995690273128}
2023-01-04 02:32:22,208 INFO:     Found new best model at epoch 1
2023-01-04 02:32:22,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:22,208 INFO:     Epoch: 2
2023-01-04 02:32:23,806 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48570433457692463, 'Total loss': 0.48570433457692463} | train loss {'Reaction outcome loss': 0.5341218808206959, 'Total loss': 0.5341218808206959}
2023-01-04 02:32:23,807 INFO:     Found new best model at epoch 2
2023-01-04 02:32:23,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:23,808 INFO:     Epoch: 3
2023-01-04 02:32:25,386 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4685008585453033, 'Total loss': 0.4685008585453033} | train loss {'Reaction outcome loss': 0.4876091927289963, 'Total loss': 0.4876091927289963}
2023-01-04 02:32:25,386 INFO:     Found new best model at epoch 3
2023-01-04 02:32:25,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:25,387 INFO:     Epoch: 4
2023-01-04 02:32:26,961 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4478971908489863, 'Total loss': 0.4478971908489863} | train loss {'Reaction outcome loss': 0.4614640695618236, 'Total loss': 0.4614640695618236}
2023-01-04 02:32:26,961 INFO:     Found new best model at epoch 4
2023-01-04 02:32:26,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:26,962 INFO:     Epoch: 5
2023-01-04 02:32:28,534 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43697588245073954, 'Total loss': 0.43697588245073954} | train loss {'Reaction outcome loss': 0.4453032675968564, 'Total loss': 0.4453032675968564}
2023-01-04 02:32:28,534 INFO:     Found new best model at epoch 5
2023-01-04 02:32:28,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:28,535 INFO:     Epoch: 6
2023-01-04 02:32:30,124 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.427202041943868, 'Total loss': 0.427202041943868} | train loss {'Reaction outcome loss': 0.43122860456924833, 'Total loss': 0.43122860456924833}
2023-01-04 02:32:30,125 INFO:     Found new best model at epoch 6
2023-01-04 02:32:30,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:30,125 INFO:     Epoch: 7
2023-01-04 02:32:31,700 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4184142510096232, 'Total loss': 0.4184142510096232} | train loss {'Reaction outcome loss': 0.41898299634888553, 'Total loss': 0.41898299634888553}
2023-01-04 02:32:31,700 INFO:     Found new best model at epoch 7
2023-01-04 02:32:31,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:31,701 INFO:     Epoch: 8
2023-01-04 02:32:33,288 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.402619602282842, 'Total loss': 0.402619602282842} | train loss {'Reaction outcome loss': 0.4086196940338266, 'Total loss': 0.4086196940338266}
2023-01-04 02:32:33,288 INFO:     Found new best model at epoch 8
2023-01-04 02:32:33,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:33,289 INFO:     Epoch: 9
2023-01-04 02:32:34,880 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41039088169733684, 'Total loss': 0.41039088169733684} | train loss {'Reaction outcome loss': 0.4046709189272445, 'Total loss': 0.4046709189272445}
2023-01-04 02:32:34,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:34,880 INFO:     Epoch: 10
2023-01-04 02:32:36,467 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4078433612982432, 'Total loss': 0.4078433612982432} | train loss {'Reaction outcome loss': 0.3907539973312152, 'Total loss': 0.3907539973312152}
2023-01-04 02:32:36,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:36,468 INFO:     Epoch: 11
2023-01-04 02:32:38,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39369046688079834, 'Total loss': 0.39369046688079834} | train loss {'Reaction outcome loss': 0.38105831549003505, 'Total loss': 0.38105831549003505}
2023-01-04 02:32:38,050 INFO:     Found new best model at epoch 11
2023-01-04 02:32:38,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:38,051 INFO:     Epoch: 12
2023-01-04 02:32:39,641 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38347209692001344, 'Total loss': 0.38347209692001344} | train loss {'Reaction outcome loss': 0.3729647862610232, 'Total loss': 0.3729647862610232}
2023-01-04 02:32:39,641 INFO:     Found new best model at epoch 12
2023-01-04 02:32:39,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:39,642 INFO:     Epoch: 13
2023-01-04 02:32:41,212 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3916111628214518, 'Total loss': 0.3916111628214518} | train loss {'Reaction outcome loss': 0.3684334266066983, 'Total loss': 0.3684334266066983}
2023-01-04 02:32:41,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:41,213 INFO:     Epoch: 14
2023-01-04 02:32:42,835 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40162325104077656, 'Total loss': 0.40162325104077656} | train loss {'Reaction outcome loss': 0.3612339884562391, 'Total loss': 0.3612339884562391}
2023-01-04 02:32:42,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:42,836 INFO:     Epoch: 15
2023-01-04 02:32:44,419 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38092184662818906, 'Total loss': 0.38092184662818906} | train loss {'Reaction outcome loss': 0.352450996028062, 'Total loss': 0.352450996028062}
2023-01-04 02:32:44,419 INFO:     Found new best model at epoch 15
2023-01-04 02:32:44,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:44,420 INFO:     Epoch: 16
2023-01-04 02:32:45,996 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37391598522663116, 'Total loss': 0.37391598522663116} | train loss {'Reaction outcome loss': 0.3457588619247595, 'Total loss': 0.3457588619247595}
2023-01-04 02:32:45,996 INFO:     Found new best model at epoch 16
2023-01-04 02:32:45,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:45,997 INFO:     Epoch: 17
2023-01-04 02:32:47,581 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38414397835731506, 'Total loss': 0.38414397835731506} | train loss {'Reaction outcome loss': 0.3400120064485447, 'Total loss': 0.3400120064485447}
2023-01-04 02:32:47,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:47,582 INFO:     Epoch: 18
2023-01-04 02:32:49,199 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37415430347124734, 'Total loss': 0.37415430347124734} | train loss {'Reaction outcome loss': 0.3348488336980707, 'Total loss': 0.3348488336980707}
2023-01-04 02:32:49,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:49,200 INFO:     Epoch: 19
2023-01-04 02:32:50,777 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37140037715435026, 'Total loss': 0.37140037715435026} | train loss {'Reaction outcome loss': 0.3278625060034835, 'Total loss': 0.3278625060034835}
2023-01-04 02:32:50,777 INFO:     Found new best model at epoch 19
2023-01-04 02:32:50,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:50,778 INFO:     Epoch: 20
2023-01-04 02:32:52,370 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.373699751496315, 'Total loss': 0.373699751496315} | train loss {'Reaction outcome loss': 0.32555010973685083, 'Total loss': 0.32555010973685083}
2023-01-04 02:32:52,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:52,370 INFO:     Epoch: 21
2023-01-04 02:32:53,964 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3674669136603673, 'Total loss': 0.3674669136603673} | train loss {'Reaction outcome loss': 0.3200782083676777, 'Total loss': 0.3200782083676777}
2023-01-04 02:32:53,964 INFO:     Found new best model at epoch 21
2023-01-04 02:32:53,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:53,965 INFO:     Epoch: 22
2023-01-04 02:32:55,563 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38540334105491636, 'Total loss': 0.38540334105491636} | train loss {'Reaction outcome loss': 0.32217947444946005, 'Total loss': 0.32217947444946005}
2023-01-04 02:32:55,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:55,564 INFO:     Epoch: 23
2023-01-04 02:32:57,173 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3752639884750048, 'Total loss': 0.3752639884750048} | train loss {'Reaction outcome loss': 0.3203636416161527, 'Total loss': 0.3203636416161527}
2023-01-04 02:32:57,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:57,173 INFO:     Epoch: 24
2023-01-04 02:32:58,770 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3640015348792076, 'Total loss': 0.3640015348792076} | train loss {'Reaction outcome loss': 0.3042551586467712, 'Total loss': 0.3042551586467712}
2023-01-04 02:32:58,770 INFO:     Found new best model at epoch 24
2023-01-04 02:32:58,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:32:58,771 INFO:     Epoch: 25
2023-01-04 02:33:00,365 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3713251481453578, 'Total loss': 0.3713251481453578} | train loss {'Reaction outcome loss': 0.2996024738809944, 'Total loss': 0.2996024738809944}
2023-01-04 02:33:00,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:00,365 INFO:     Epoch: 26
2023-01-04 02:33:01,974 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3709034909804662, 'Total loss': 0.3709034909804662} | train loss {'Reaction outcome loss': 0.29465553585433174, 'Total loss': 0.29465553585433174}
2023-01-04 02:33:01,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:01,974 INFO:     Epoch: 27
2023-01-04 02:33:03,572 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.388641686240832, 'Total loss': 0.388641686240832} | train loss {'Reaction outcome loss': 0.2916835769202157, 'Total loss': 0.2916835769202157}
2023-01-04 02:33:03,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:03,572 INFO:     Epoch: 28
2023-01-04 02:33:05,209 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3593548655509949, 'Total loss': 0.3593548655509949} | train loss {'Reaction outcome loss': 0.28884388199556904, 'Total loss': 0.28884388199556904}
2023-01-04 02:33:05,210 INFO:     Found new best model at epoch 28
2023-01-04 02:33:05,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:05,210 INFO:     Epoch: 29
2023-01-04 02:33:06,838 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35748635828495023, 'Total loss': 0.35748635828495023} | train loss {'Reaction outcome loss': 0.2916909841199716, 'Total loss': 0.2916909841199716}
2023-01-04 02:33:06,838 INFO:     Found new best model at epoch 29
2023-01-04 02:33:06,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:06,839 INFO:     Epoch: 30
2023-01-04 02:33:08,455 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3806675444046656, 'Total loss': 0.3806675444046656} | train loss {'Reaction outcome loss': 0.29156639587059885, 'Total loss': 0.29156639587059885}
2023-01-04 02:33:08,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:08,455 INFO:     Epoch: 31
2023-01-04 02:33:10,112 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3680865188439687, 'Total loss': 0.3680865188439687} | train loss {'Reaction outcome loss': 0.28012828133300965, 'Total loss': 0.28012828133300965}
2023-01-04 02:33:10,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:10,112 INFO:     Epoch: 32
2023-01-04 02:33:11,721 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39079146782557167, 'Total loss': 0.39079146782557167} | train loss {'Reaction outcome loss': 0.2724503473415836, 'Total loss': 0.2724503473415836}
2023-01-04 02:33:11,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:11,722 INFO:     Epoch: 33
2023-01-04 02:33:13,352 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37961672643820443, 'Total loss': 0.37961672643820443} | train loss {'Reaction outcome loss': 0.2795385002711977, 'Total loss': 0.2795385002711977}
2023-01-04 02:33:13,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:13,352 INFO:     Epoch: 34
2023-01-04 02:33:15,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38373844722906747, 'Total loss': 0.38373844722906747} | train loss {'Reaction outcome loss': 0.28383608751144074, 'Total loss': 0.28383608751144074}
2023-01-04 02:33:15,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:15,008 INFO:     Epoch: 35
2023-01-04 02:33:16,644 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3783791879812876, 'Total loss': 0.3783791879812876} | train loss {'Reaction outcome loss': 0.2661260512043331, 'Total loss': 0.2661260512043331}
2023-01-04 02:33:16,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:16,645 INFO:     Epoch: 36
2023-01-04 02:33:18,293 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3904849926630656, 'Total loss': 0.3904849926630656} | train loss {'Reaction outcome loss': 0.2612931873662856, 'Total loss': 0.2612931873662856}
2023-01-04 02:33:18,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:18,294 INFO:     Epoch: 37
2023-01-04 02:33:19,921 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3847234348456065, 'Total loss': 0.3847234348456065} | train loss {'Reaction outcome loss': 0.26098421078337275, 'Total loss': 0.26098421078337275}
2023-01-04 02:33:19,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:19,921 INFO:     Epoch: 38
2023-01-04 02:33:21,505 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3862079163392385, 'Total loss': 0.3862079163392385} | train loss {'Reaction outcome loss': 0.25968036455088767, 'Total loss': 0.25968036455088767}
2023-01-04 02:33:21,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:21,505 INFO:     Epoch: 39
2023-01-04 02:33:23,088 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.374427526195844, 'Total loss': 0.374427526195844} | train loss {'Reaction outcome loss': 0.2530995966930725, 'Total loss': 0.2530995966930725}
2023-01-04 02:33:23,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:23,088 INFO:     Epoch: 40
2023-01-04 02:33:24,685 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36790255407492317, 'Total loss': 0.36790255407492317} | train loss {'Reaction outcome loss': 0.25123918559267255, 'Total loss': 0.25123918559267255}
2023-01-04 02:33:24,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:24,685 INFO:     Epoch: 41
2023-01-04 02:33:26,297 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3998511602481206, 'Total loss': 0.3998511602481206} | train loss {'Reaction outcome loss': 0.25195322434107464, 'Total loss': 0.25195322434107464}
2023-01-04 02:33:26,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:26,297 INFO:     Epoch: 42
2023-01-04 02:33:27,937 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3899822433789571, 'Total loss': 0.3899822433789571} | train loss {'Reaction outcome loss': 0.24903599377991498, 'Total loss': 0.24903599377991498}
2023-01-04 02:33:27,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:27,937 INFO:     Epoch: 43
2023-01-04 02:33:29,589 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37506628533204395, 'Total loss': 0.37506628533204395} | train loss {'Reaction outcome loss': 0.2463168128226138, 'Total loss': 0.2463168128226138}
2023-01-04 02:33:29,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:29,589 INFO:     Epoch: 44
2023-01-04 02:33:31,217 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41042040983835854, 'Total loss': 0.41042040983835854} | train loss {'Reaction outcome loss': 0.24555197478258523, 'Total loss': 0.24555197478258523}
2023-01-04 02:33:31,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:31,218 INFO:     Epoch: 45
2023-01-04 02:33:32,853 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3869795143604279, 'Total loss': 0.3869795143604279} | train loss {'Reaction outcome loss': 0.2452970230023957, 'Total loss': 0.2452970230023957}
2023-01-04 02:33:32,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:32,854 INFO:     Epoch: 46
2023-01-04 02:33:34,483 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3698396493991216, 'Total loss': 0.3698396493991216} | train loss {'Reaction outcome loss': 0.2386651878984159, 'Total loss': 0.2386651878984159}
2023-01-04 02:33:34,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:34,484 INFO:     Epoch: 47
2023-01-04 02:33:36,071 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39168996214866636, 'Total loss': 0.39168996214866636} | train loss {'Reaction outcome loss': 0.23817675276591943, 'Total loss': 0.23817675276591943}
2023-01-04 02:33:36,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:36,072 INFO:     Epoch: 48
2023-01-04 02:33:37,666 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3692032883564631, 'Total loss': 0.3692032883564631} | train loss {'Reaction outcome loss': 0.2345586470201733, 'Total loss': 0.2345586470201733}
2023-01-04 02:33:37,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:37,667 INFO:     Epoch: 49
2023-01-04 02:33:39,291 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3787517299254735, 'Total loss': 0.3787517299254735} | train loss {'Reaction outcome loss': 0.23328275465578568, 'Total loss': 0.23328275465578568}
2023-01-04 02:33:39,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:39,291 INFO:     Epoch: 50
2023-01-04 02:33:40,896 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38425657550493875, 'Total loss': 0.38425657550493875} | train loss {'Reaction outcome loss': 0.25430975036452647, 'Total loss': 0.25430975036452647}
2023-01-04 02:33:40,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:40,897 INFO:     Epoch: 51
2023-01-04 02:33:42,515 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39031051794687904, 'Total loss': 0.39031051794687904} | train loss {'Reaction outcome loss': 0.2294936813177892, 'Total loss': 0.2294936813177892}
2023-01-04 02:33:42,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:42,516 INFO:     Epoch: 52
2023-01-04 02:33:44,108 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3711231251557668, 'Total loss': 0.3711231251557668} | train loss {'Reaction outcome loss': 0.22742210934276058, 'Total loss': 0.22742210934276058}
2023-01-04 02:33:44,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:44,108 INFO:     Epoch: 53
2023-01-04 02:33:45,703 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36992439726988474, 'Total loss': 0.36992439726988474} | train loss {'Reaction outcome loss': 0.22245904683992537, 'Total loss': 0.22245904683992537}
2023-01-04 02:33:45,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:45,703 INFO:     Epoch: 54
2023-01-04 02:33:47,291 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3973661532004674, 'Total loss': 0.3973661532004674} | train loss {'Reaction outcome loss': 0.22382555430184753, 'Total loss': 0.22382555430184753}
2023-01-04 02:33:47,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:47,291 INFO:     Epoch: 55
2023-01-04 02:33:48,861 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38564347525437676, 'Total loss': 0.38564347525437676} | train loss {'Reaction outcome loss': 0.22853092612374737, 'Total loss': 0.22853092612374737}
2023-01-04 02:33:48,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:48,862 INFO:     Epoch: 56
2023-01-04 02:33:50,447 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4131847451130549, 'Total loss': 0.4131847451130549} | train loss {'Reaction outcome loss': 0.2349756859450439, 'Total loss': 0.2349756859450439}
2023-01-04 02:33:50,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:50,447 INFO:     Epoch: 57
2023-01-04 02:33:52,054 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3920374612013499, 'Total loss': 0.3920374612013499} | train loss {'Reaction outcome loss': 0.219033753917809, 'Total loss': 0.219033753917809}
2023-01-04 02:33:52,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:52,054 INFO:     Epoch: 58
2023-01-04 02:33:53,644 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3959720194339752, 'Total loss': 0.3959720194339752} | train loss {'Reaction outcome loss': 0.21992358016660032, 'Total loss': 0.21992358016660032}
2023-01-04 02:33:53,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:53,644 INFO:     Epoch: 59
2023-01-04 02:33:55,232 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3965190629164378, 'Total loss': 0.3965190629164378} | train loss {'Reaction outcome loss': 0.21126109469733437, 'Total loss': 0.21126109469733437}
2023-01-04 02:33:55,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:55,233 INFO:     Epoch: 60
2023-01-04 02:33:56,861 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3996139422059059, 'Total loss': 0.3996139422059059} | train loss {'Reaction outcome loss': 0.21044584579797537, 'Total loss': 0.21044584579797537}
2023-01-04 02:33:56,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:56,861 INFO:     Epoch: 61
2023-01-04 02:33:58,449 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41209002236525216, 'Total loss': 0.41209002236525216} | train loss {'Reaction outcome loss': 0.2115325403055581, 'Total loss': 0.2115325403055581}
2023-01-04 02:33:58,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:33:58,450 INFO:     Epoch: 62
2023-01-04 02:34:00,072 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3895372251669566, 'Total loss': 0.3895372251669566} | train loss {'Reaction outcome loss': 0.20974782273254317, 'Total loss': 0.20974782273254317}
2023-01-04 02:34:00,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:00,073 INFO:     Epoch: 63
2023-01-04 02:34:01,650 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40663018872340523, 'Total loss': 0.40663018872340523} | train loss {'Reaction outcome loss': 0.2089433967236234, 'Total loss': 0.2089433967236234}
2023-01-04 02:34:01,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:01,651 INFO:     Epoch: 64
2023-01-04 02:34:03,282 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3981162925561269, 'Total loss': 0.3981162925561269} | train loss {'Reaction outcome loss': 0.20648361206026428, 'Total loss': 0.20648361206026428}
2023-01-04 02:34:03,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:03,282 INFO:     Epoch: 65
2023-01-04 02:34:04,906 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41482570866743723, 'Total loss': 0.41482570866743723} | train loss {'Reaction outcome loss': 0.20613771875562542, 'Total loss': 0.20613771875562542}
2023-01-04 02:34:04,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:04,906 INFO:     Epoch: 66
2023-01-04 02:34:06,529 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4134816398223241, 'Total loss': 0.4134816398223241} | train loss {'Reaction outcome loss': 0.20340841379088553, 'Total loss': 0.20340841379088553}
2023-01-04 02:34:06,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:06,529 INFO:     Epoch: 67
2023-01-04 02:34:08,104 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4100332389275233, 'Total loss': 0.4100332389275233} | train loss {'Reaction outcome loss': 0.20438648395888184, 'Total loss': 0.20438648395888184}
2023-01-04 02:34:08,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:08,104 INFO:     Epoch: 68
2023-01-04 02:34:09,690 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40381811956564584, 'Total loss': 0.40381811956564584} | train loss {'Reaction outcome loss': 0.20586824162012857, 'Total loss': 0.20586824162012857}
2023-01-04 02:34:09,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:09,690 INFO:     Epoch: 69
2023-01-04 02:34:11,283 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4025825331608454, 'Total loss': 0.4025825331608454} | train loss {'Reaction outcome loss': 0.2096906731620539, 'Total loss': 0.2096906731620539}
2023-01-04 02:34:11,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:11,283 INFO:     Epoch: 70
2023-01-04 02:34:12,870 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4019407987594604, 'Total loss': 0.4019407987594604} | train loss {'Reaction outcome loss': 0.20030824391279314, 'Total loss': 0.20030824391279314}
2023-01-04 02:34:12,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:12,872 INFO:     Epoch: 71
2023-01-04 02:34:14,455 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41259603997071587, 'Total loss': 0.41259603997071587} | train loss {'Reaction outcome loss': 0.19659164018567948, 'Total loss': 0.19659164018567948}
2023-01-04 02:34:14,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:14,456 INFO:     Epoch: 72
2023-01-04 02:34:16,035 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4163402706384659, 'Total loss': 0.4163402706384659} | train loss {'Reaction outcome loss': 0.19516488092826415, 'Total loss': 0.19516488092826415}
2023-01-04 02:34:16,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:16,035 INFO:     Epoch: 73
2023-01-04 02:34:17,637 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.418380630761385, 'Total loss': 0.418380630761385} | train loss {'Reaction outcome loss': 0.19258815935410128, 'Total loss': 0.19258815935410128}
2023-01-04 02:34:17,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:17,637 INFO:     Epoch: 74
2023-01-04 02:34:19,261 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4281237234671911, 'Total loss': 0.4281237234671911} | train loss {'Reaction outcome loss': 0.19231766214479518, 'Total loss': 0.19231766214479518}
2023-01-04 02:34:19,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:19,261 INFO:     Epoch: 75
2023-01-04 02:34:20,839 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4104009807109833, 'Total loss': 0.4104009807109833} | train loss {'Reaction outcome loss': 0.19114461822644682, 'Total loss': 0.19114461822644682}
2023-01-04 02:34:20,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:20,839 INFO:     Epoch: 76
2023-01-04 02:34:22,451 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4097117910782496, 'Total loss': 0.4097117910782496} | train loss {'Reaction outcome loss': 0.19122344544468986, 'Total loss': 0.19122344544468986}
2023-01-04 02:34:22,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:22,451 INFO:     Epoch: 77
2023-01-04 02:34:24,060 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41222748458385466, 'Total loss': 0.41222748458385466} | train loss {'Reaction outcome loss': 0.19059482658939078, 'Total loss': 0.19059482658939078}
2023-01-04 02:34:24,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:24,060 INFO:     Epoch: 78
2023-01-04 02:34:25,632 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40376415054003395, 'Total loss': 0.40376415054003395} | train loss {'Reaction outcome loss': 0.18921767337751985, 'Total loss': 0.18921767337751985}
2023-01-04 02:34:25,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:25,632 INFO:     Epoch: 79
2023-01-04 02:34:27,250 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40639905333518983, 'Total loss': 0.40639905333518983} | train loss {'Reaction outcome loss': 0.18897883538021773, 'Total loss': 0.18897883538021773}
2023-01-04 02:34:27,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:27,250 INFO:     Epoch: 80
2023-01-04 02:34:28,850 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40331481794516244, 'Total loss': 0.40331481794516244} | train loss {'Reaction outcome loss': 0.18746074146179456, 'Total loss': 0.18746074146179456}
2023-01-04 02:34:28,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:28,850 INFO:     Epoch: 81
2023-01-04 02:34:30,445 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4205581575632095, 'Total loss': 0.4205581575632095} | train loss {'Reaction outcome loss': 0.18429637361319545, 'Total loss': 0.18429637361319545}
2023-01-04 02:34:30,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:30,445 INFO:     Epoch: 82
2023-01-04 02:34:32,039 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4365022818247477, 'Total loss': 0.4365022818247477} | train loss {'Reaction outcome loss': 0.18540920823326576, 'Total loss': 0.18540920823326576}
2023-01-04 02:34:32,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:32,040 INFO:     Epoch: 83
2023-01-04 02:34:33,616 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40064895451068877, 'Total loss': 0.40064895451068877} | train loss {'Reaction outcome loss': 0.18426975283419084, 'Total loss': 0.18426975283419084}
2023-01-04 02:34:33,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:33,616 INFO:     Epoch: 84
2023-01-04 02:34:35,192 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4057324260473251, 'Total loss': 0.4057324260473251} | train loss {'Reaction outcome loss': 0.18418902390218084, 'Total loss': 0.18418902390218084}
2023-01-04 02:34:35,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:35,193 INFO:     Epoch: 85
2023-01-04 02:34:36,816 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.456005917986234, 'Total loss': 0.456005917986234} | train loss {'Reaction outcome loss': 0.18139321055356789, 'Total loss': 0.18139321055356789}
2023-01-04 02:34:36,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:36,816 INFO:     Epoch: 86
2023-01-04 02:34:38,098 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4123873621225357, 'Total loss': 0.4123873621225357} | train loss {'Reaction outcome loss': 0.18274250800216882, 'Total loss': 0.18274250800216882}
2023-01-04 02:34:38,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:38,099 INFO:     Epoch: 87
2023-01-04 02:34:39,172 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4114685465892156, 'Total loss': 0.4114685465892156} | train loss {'Reaction outcome loss': 0.17632186986536355, 'Total loss': 0.17632186986536355}
2023-01-04 02:34:39,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:39,172 INFO:     Epoch: 88
2023-01-04 02:34:40,244 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42300374309221905, 'Total loss': 0.42300374309221905} | train loss {'Reaction outcome loss': 0.17726336010218802, 'Total loss': 0.17726336010218802}
2023-01-04 02:34:40,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:40,245 INFO:     Epoch: 89
2023-01-04 02:34:41,314 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4290490448474884, 'Total loss': 0.4290490448474884} | train loss {'Reaction outcome loss': 0.18124111409575772, 'Total loss': 0.18124111409575772}
2023-01-04 02:34:41,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:41,314 INFO:     Epoch: 90
2023-01-04 02:34:42,583 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42643162111441296, 'Total loss': 0.42643162111441296} | train loss {'Reaction outcome loss': 0.17738843000531063, 'Total loss': 0.17738843000531063}
2023-01-04 02:34:42,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:42,583 INFO:     Epoch: 91
2023-01-04 02:34:44,205 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41679222087065376, 'Total loss': 0.41679222087065376} | train loss {'Reaction outcome loss': 0.17618268695018807, 'Total loss': 0.17618268695018807}
2023-01-04 02:34:44,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:44,205 INFO:     Epoch: 92
2023-01-04 02:34:45,843 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4246031314134598, 'Total loss': 0.4246031314134598} | train loss {'Reaction outcome loss': 0.17616385619862576, 'Total loss': 0.17616385619862576}
2023-01-04 02:34:45,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:45,843 INFO:     Epoch: 93
2023-01-04 02:34:47,494 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43187456478675207, 'Total loss': 0.43187456478675207} | train loss {'Reaction outcome loss': 0.17318744925474358, 'Total loss': 0.17318744925474358}
2023-01-04 02:34:47,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:47,494 INFO:     Epoch: 94
2023-01-04 02:34:49,142 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4374290039141973, 'Total loss': 0.4374290039141973} | train loss {'Reaction outcome loss': 0.18747944213395965, 'Total loss': 0.18747944213395965}
2023-01-04 02:34:49,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:49,143 INFO:     Epoch: 95
2023-01-04 02:34:50,773 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44553911288579306, 'Total loss': 0.44553911288579306} | train loss {'Reaction outcome loss': 0.2023436423337114, 'Total loss': 0.2023436423337114}
2023-01-04 02:34:50,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:50,774 INFO:     Epoch: 96
2023-01-04 02:34:52,395 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4053763469060262, 'Total loss': 0.4053763469060262} | train loss {'Reaction outcome loss': 0.18308867448437618, 'Total loss': 0.18308867448437618}
2023-01-04 02:34:52,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:52,395 INFO:     Epoch: 97
2023-01-04 02:34:54,045 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4216961274544398, 'Total loss': 0.4216961274544398} | train loss {'Reaction outcome loss': 0.17027770427378436, 'Total loss': 0.17027770427378436}
2023-01-04 02:34:54,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:54,046 INFO:     Epoch: 98
2023-01-04 02:34:55,696 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40531041423479713, 'Total loss': 0.40531041423479713} | train loss {'Reaction outcome loss': 0.1725870833345824, 'Total loss': 0.1725870833345824}
2023-01-04 02:34:55,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:55,697 INFO:     Epoch: 99
2023-01-04 02:34:57,343 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4189558158318202, 'Total loss': 0.4189558158318202} | train loss {'Reaction outcome loss': 0.16858598467223457, 'Total loss': 0.16858598467223457}
2023-01-04 02:34:57,344 INFO:     Best model found after epoch 30 of 100.
2023-01-04 02:34:57,344 INFO:   Done with stage: TRAINING
2023-01-04 02:34:57,344 INFO:   Starting stage: EVALUATION
2023-01-04 02:34:57,472 INFO:   Done with stage: EVALUATION
2023-01-04 02:34:57,472 INFO:   Leaving out SEQ value Fold_2
2023-01-04 02:34:57,485 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 02:34:57,485 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:34:58,132 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:34:58,132 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:34:58,201 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:34:58,201 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:34:58,201 INFO:     No hyperparam tuning for this model
2023-01-04 02:34:58,201 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:34:58,201 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:34:58,202 INFO:     None feature selector for col prot
2023-01-04 02:34:58,202 INFO:     None feature selector for col prot
2023-01-04 02:34:58,202 INFO:     None feature selector for col prot
2023-01-04 02:34:58,203 INFO:     None feature selector for col chem
2023-01-04 02:34:58,203 INFO:     None feature selector for col chem
2023-01-04 02:34:58,203 INFO:     None feature selector for col chem
2023-01-04 02:34:58,203 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:34:58,203 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:34:58,204 INFO:     Number of params in model 70141
2023-01-04 02:34:58,207 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:34:58,208 INFO:   Starting stage: TRAINING
2023-01-04 02:34:58,253 INFO:     Val loss before train {'Reaction outcome loss': 0.9603532512982687, 'Total loss': 0.9603532512982687}
2023-01-04 02:34:58,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:58,253 INFO:     Epoch: 0
2023-01-04 02:34:59,870 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6181159516175588, 'Total loss': 0.6181159516175588} | train loss {'Reaction outcome loss': 0.8486831823404688, 'Total loss': 0.8486831823404688}
2023-01-04 02:34:59,870 INFO:     Found new best model at epoch 0
2023-01-04 02:34:59,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:34:59,871 INFO:     Epoch: 1
2023-01-04 02:35:01,473 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5067844768365224, 'Total loss': 0.5067844768365224} | train loss {'Reaction outcome loss': 0.6071991617553425, 'Total loss': 0.6071991617553425}
2023-01-04 02:35:01,473 INFO:     Found new best model at epoch 1
2023-01-04 02:35:01,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:01,474 INFO:     Epoch: 2
2023-01-04 02:35:03,107 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4522185206413269, 'Total loss': 0.4522185206413269} | train loss {'Reaction outcome loss': 0.5313808622151396, 'Total loss': 0.5313808622151396}
2023-01-04 02:35:03,107 INFO:     Found new best model at epoch 2
2023-01-04 02:35:03,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:03,108 INFO:     Epoch: 3
2023-01-04 02:35:04,741 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4284576833248138, 'Total loss': 0.4284576833248138} | train loss {'Reaction outcome loss': 0.49321097266064945, 'Total loss': 0.49321097266064945}
2023-01-04 02:35:04,741 INFO:     Found new best model at epoch 3
2023-01-04 02:35:04,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:04,742 INFO:     Epoch: 4
2023-01-04 02:35:06,392 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4067061881224314, 'Total loss': 0.4067061881224314} | train loss {'Reaction outcome loss': 0.466768244866037, 'Total loss': 0.466768244866037}
2023-01-04 02:35:06,392 INFO:     Found new best model at epoch 4
2023-01-04 02:35:06,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:06,393 INFO:     Epoch: 5
2023-01-04 02:35:08,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3989924371242523, 'Total loss': 0.3989924371242523} | train loss {'Reaction outcome loss': 0.44548335377752346, 'Total loss': 0.44548335377752346}
2023-01-04 02:35:08,002 INFO:     Found new best model at epoch 5
2023-01-04 02:35:08,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:08,002 INFO:     Epoch: 6
2023-01-04 02:35:09,627 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3904775559902191, 'Total loss': 0.3904775559902191} | train loss {'Reaction outcome loss': 0.43318864365998844, 'Total loss': 0.43318864365998844}
2023-01-04 02:35:09,627 INFO:     Found new best model at epoch 6
2023-01-04 02:35:09,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:09,628 INFO:     Epoch: 7
2023-01-04 02:35:11,194 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3736653357744217, 'Total loss': 0.3736653357744217} | train loss {'Reaction outcome loss': 0.416683249610619, 'Total loss': 0.416683249610619}
2023-01-04 02:35:11,194 INFO:     Found new best model at epoch 7
2023-01-04 02:35:11,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:11,195 INFO:     Epoch: 8
2023-01-04 02:35:12,798 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.385873144865036, 'Total loss': 0.385873144865036} | train loss {'Reaction outcome loss': 0.40271742095368623, 'Total loss': 0.40271742095368623}
2023-01-04 02:35:12,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:12,798 INFO:     Epoch: 9
2023-01-04 02:35:14,371 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38556263943513236, 'Total loss': 0.38556263943513236} | train loss {'Reaction outcome loss': 0.3924336987037728, 'Total loss': 0.3924336987037728}
2023-01-04 02:35:14,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:14,371 INFO:     Epoch: 10
2023-01-04 02:35:15,981 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3808444072802862, 'Total loss': 0.3808444072802862} | train loss {'Reaction outcome loss': 0.38417669983893415, 'Total loss': 0.38417669983893415}
2023-01-04 02:35:15,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:15,981 INFO:     Epoch: 11
2023-01-04 02:35:17,571 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36620682179927827, 'Total loss': 0.36620682179927827} | train loss {'Reaction outcome loss': 0.37704727673617594, 'Total loss': 0.37704727673617594}
2023-01-04 02:35:17,572 INFO:     Found new best model at epoch 11
2023-01-04 02:35:17,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:17,572 INFO:     Epoch: 12
2023-01-04 02:35:19,154 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35608022212982177, 'Total loss': 0.35608022212982177} | train loss {'Reaction outcome loss': 0.3664645191254842, 'Total loss': 0.3664645191254842}
2023-01-04 02:35:19,154 INFO:     Found new best model at epoch 12
2023-01-04 02:35:19,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:19,155 INFO:     Epoch: 13
2023-01-04 02:35:20,727 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3597168783346812, 'Total loss': 0.3597168783346812} | train loss {'Reaction outcome loss': 0.3587884466796026, 'Total loss': 0.3587884466796026}
2023-01-04 02:35:20,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:20,728 INFO:     Epoch: 14
2023-01-04 02:35:22,299 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3663663516441981, 'Total loss': 0.3663663516441981} | train loss {'Reaction outcome loss': 0.35335961468245863, 'Total loss': 0.35335961468245863}
2023-01-04 02:35:22,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:22,299 INFO:     Epoch: 15
2023-01-04 02:35:23,895 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.34714398384094236, 'Total loss': 0.34714398384094236} | train loss {'Reaction outcome loss': 0.34293196092013023, 'Total loss': 0.34293196092013023}
2023-01-04 02:35:23,895 INFO:     Found new best model at epoch 15
2023-01-04 02:35:23,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:23,896 INFO:     Epoch: 16
2023-01-04 02:35:25,479 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3691725075244904, 'Total loss': 0.3691725075244904} | train loss {'Reaction outcome loss': 0.3399910770193504, 'Total loss': 0.3399910770193504}
2023-01-04 02:35:25,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:25,479 INFO:     Epoch: 17
2023-01-04 02:35:27,047 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36562825441360475, 'Total loss': 0.36562825441360475} | train loss {'Reaction outcome loss': 0.3333552128152691, 'Total loss': 0.3333552128152691}
2023-01-04 02:35:27,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:27,048 INFO:     Epoch: 18
2023-01-04 02:35:28,620 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3643592099348704, 'Total loss': 0.3643592099348704} | train loss {'Reaction outcome loss': 0.32873999186023306, 'Total loss': 0.32873999186023306}
2023-01-04 02:35:28,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:28,620 INFO:     Epoch: 19
2023-01-04 02:35:30,217 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.349952091773351, 'Total loss': 0.349952091773351} | train loss {'Reaction outcome loss': 0.3205701680242145, 'Total loss': 0.3205701680242145}
2023-01-04 02:35:30,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:30,218 INFO:     Epoch: 20
2023-01-04 02:35:31,828 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3377837151288986, 'Total loss': 0.3377837151288986} | train loss {'Reaction outcome loss': 0.3148523193043079, 'Total loss': 0.3148523193043079}
2023-01-04 02:35:31,828 INFO:     Found new best model at epoch 20
2023-01-04 02:35:31,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:31,829 INFO:     Epoch: 21
2023-01-04 02:35:33,405 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.33460633456707, 'Total loss': 0.33460633456707} | train loss {'Reaction outcome loss': 0.3108082017759337, 'Total loss': 0.3108082017759337}
2023-01-04 02:35:33,405 INFO:     Found new best model at epoch 21
2023-01-04 02:35:33,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:33,406 INFO:     Epoch: 22
2023-01-04 02:35:34,980 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34388378659884133, 'Total loss': 0.34388378659884133} | train loss {'Reaction outcome loss': 0.306884732178963, 'Total loss': 0.306884732178963}
2023-01-04 02:35:34,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:34,980 INFO:     Epoch: 23
2023-01-04 02:35:36,593 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3433737059434255, 'Total loss': 0.3433737059434255} | train loss {'Reaction outcome loss': 0.2998753818717316, 'Total loss': 0.2998753818717316}
2023-01-04 02:35:36,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:36,594 INFO:     Epoch: 24
2023-01-04 02:35:38,165 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3436960856119792, 'Total loss': 0.3436960856119792} | train loss {'Reaction outcome loss': 0.29578696883344735, 'Total loss': 0.29578696883344735}
2023-01-04 02:35:38,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:38,165 INFO:     Epoch: 25
2023-01-04 02:35:39,749 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3614076733589172, 'Total loss': 0.3614076733589172} | train loss {'Reaction outcome loss': 0.2915746541081989, 'Total loss': 0.2915746541081989}
2023-01-04 02:35:39,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:39,750 INFO:     Epoch: 26
2023-01-04 02:35:41,332 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.35232156415780386, 'Total loss': 0.35232156415780386} | train loss {'Reaction outcome loss': 0.2873396632281968, 'Total loss': 0.2873396632281968}
2023-01-04 02:35:41,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:41,332 INFO:     Epoch: 27
2023-01-04 02:35:42,916 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3422856311003367, 'Total loss': 0.3422856311003367} | train loss {'Reaction outcome loss': 0.28295018203067085, 'Total loss': 0.28295018203067085}
2023-01-04 02:35:42,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:42,917 INFO:     Epoch: 28
2023-01-04 02:35:44,490 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3453604300816854, 'Total loss': 0.3453604300816854} | train loss {'Reaction outcome loss': 0.2782474409951998, 'Total loss': 0.2782474409951998}
2023-01-04 02:35:44,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:44,490 INFO:     Epoch: 29
2023-01-04 02:35:46,081 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35037696758906045, 'Total loss': 0.35037696758906045} | train loss {'Reaction outcome loss': 0.27714531686510485, 'Total loss': 0.27714531686510485}
2023-01-04 02:35:46,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:46,081 INFO:     Epoch: 30
2023-01-04 02:35:47,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34261709650357564, 'Total loss': 0.34261709650357564} | train loss {'Reaction outcome loss': 0.2699216264469998, 'Total loss': 0.2699216264469998}
2023-01-04 02:35:47,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:47,692 INFO:     Epoch: 31
2023-01-04 02:35:49,286 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3393161356449127, 'Total loss': 0.3393161356449127} | train loss {'Reaction outcome loss': 0.2682411438601948, 'Total loss': 0.2682411438601948}
2023-01-04 02:35:49,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:49,286 INFO:     Epoch: 32
2023-01-04 02:35:50,896 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.33188187976678213, 'Total loss': 0.33188187976678213} | train loss {'Reaction outcome loss': 0.2645636850247418, 'Total loss': 0.2645636850247418}
2023-01-04 02:35:50,896 INFO:     Found new best model at epoch 32
2023-01-04 02:35:50,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:50,897 INFO:     Epoch: 33
2023-01-04 02:35:52,480 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37431080639362335, 'Total loss': 0.37431080639362335} | train loss {'Reaction outcome loss': 0.26048880524552653, 'Total loss': 0.26048880524552653}
2023-01-04 02:35:52,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:52,481 INFO:     Epoch: 34
2023-01-04 02:35:54,068 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3410681366920471, 'Total loss': 0.3410681366920471} | train loss {'Reaction outcome loss': 0.25820064376087953, 'Total loss': 0.25820064376087953}
2023-01-04 02:35:54,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:54,068 INFO:     Epoch: 35
2023-01-04 02:35:55,648 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3473696351051331, 'Total loss': 0.3473696351051331} | train loss {'Reaction outcome loss': 0.25420939394809905, 'Total loss': 0.25420939394809905}
2023-01-04 02:35:55,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:55,649 INFO:     Epoch: 36
2023-01-04 02:35:57,231 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3478824774424235, 'Total loss': 0.3478824774424235} | train loss {'Reaction outcome loss': 0.2515277602322345, 'Total loss': 0.2515277602322345}
2023-01-04 02:35:57,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:57,232 INFO:     Epoch: 37
2023-01-04 02:35:58,816 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.32405897478262585, 'Total loss': 0.32405897478262585} | train loss {'Reaction outcome loss': 0.24666397779309837, 'Total loss': 0.24666397779309837}
2023-01-04 02:35:58,816 INFO:     Found new best model at epoch 37
2023-01-04 02:35:58,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:35:58,817 INFO:     Epoch: 38
2023-01-04 02:36:00,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34018604159355165, 'Total loss': 0.34018604159355165} | train loss {'Reaction outcome loss': 0.243503610691885, 'Total loss': 0.243503610691885}
2023-01-04 02:36:00,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:00,401 INFO:     Epoch: 39
2023-01-04 02:36:01,968 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3394177337487539, 'Total loss': 0.3394177337487539} | train loss {'Reaction outcome loss': 0.24148419007223887, 'Total loss': 0.24148419007223887}
2023-01-04 02:36:01,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:01,969 INFO:     Epoch: 40
2023-01-04 02:36:03,552 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3359535266955694, 'Total loss': 0.3359535266955694} | train loss {'Reaction outcome loss': 0.23893483146263736, 'Total loss': 0.23893483146263736}
2023-01-04 02:36:03,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:03,552 INFO:     Epoch: 41
2023-01-04 02:36:05,121 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34400550921758016, 'Total loss': 0.34400550921758016} | train loss {'Reaction outcome loss': 0.23666273212454614, 'Total loss': 0.23666273212454614}
2023-01-04 02:36:05,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:05,121 INFO:     Epoch: 42
2023-01-04 02:36:06,705 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37200933893521626, 'Total loss': 0.37200933893521626} | train loss {'Reaction outcome loss': 0.23266495622857644, 'Total loss': 0.23266495622857644}
2023-01-04 02:36:06,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:06,705 INFO:     Epoch: 43
2023-01-04 02:36:08,289 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3347021400928497, 'Total loss': 0.3347021400928497} | train loss {'Reaction outcome loss': 0.22983746284986065, 'Total loss': 0.22983746284986065}
2023-01-04 02:36:08,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:08,289 INFO:     Epoch: 44
2023-01-04 02:36:09,879 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36847364604473115, 'Total loss': 0.36847364604473115} | train loss {'Reaction outcome loss': 0.2285476365283023, 'Total loss': 0.2285476365283023}
2023-01-04 02:36:09,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:09,879 INFO:     Epoch: 45
2023-01-04 02:36:11,458 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.34626190066337587, 'Total loss': 0.34626190066337587} | train loss {'Reaction outcome loss': 0.22529824477803967, 'Total loss': 0.22529824477803967}
2023-01-04 02:36:11,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:11,458 INFO:     Epoch: 46
2023-01-04 02:36:13,039 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3227344922721386, 'Total loss': 0.3227344922721386} | train loss {'Reaction outcome loss': 0.22364965833750736, 'Total loss': 0.22364965833750736}
2023-01-04 02:36:13,039 INFO:     Found new best model at epoch 46
2023-01-04 02:36:13,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:13,040 INFO:     Epoch: 47
2023-01-04 02:36:14,648 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3334744170308113, 'Total loss': 0.3334744170308113} | train loss {'Reaction outcome loss': 0.2220060937242569, 'Total loss': 0.2220060937242569}
2023-01-04 02:36:14,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:14,649 INFO:     Epoch: 48
2023-01-04 02:36:16,255 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3246925125519435, 'Total loss': 0.3246925125519435} | train loss {'Reaction outcome loss': 0.22236150762841214, 'Total loss': 0.22236150762841214}
2023-01-04 02:36:16,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:16,256 INFO:     Epoch: 49
2023-01-04 02:36:17,863 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34367999037106833, 'Total loss': 0.34367999037106833} | train loss {'Reaction outcome loss': 0.21678956080037748, 'Total loss': 0.21678956080037748}
2023-01-04 02:36:17,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:17,863 INFO:     Epoch: 50
2023-01-04 02:36:19,460 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34928878098726274, 'Total loss': 0.34928878098726274} | train loss {'Reaction outcome loss': 0.21472982280500177, 'Total loss': 0.21472982280500177}
2023-01-04 02:36:19,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:19,460 INFO:     Epoch: 51
2023-01-04 02:36:21,028 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35176827510197956, 'Total loss': 0.35176827510197956} | train loss {'Reaction outcome loss': 0.21322725206124085, 'Total loss': 0.21322725206124085}
2023-01-04 02:36:21,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:21,028 INFO:     Epoch: 52
2023-01-04 02:36:22,589 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3297414700190226, 'Total loss': 0.3297414700190226} | train loss {'Reaction outcome loss': 0.21266112116294622, 'Total loss': 0.21266112116294622}
2023-01-04 02:36:22,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:22,589 INFO:     Epoch: 53
2023-01-04 02:36:24,187 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3396024703979492, 'Total loss': 0.3396024703979492} | train loss {'Reaction outcome loss': 0.20950710381904658, 'Total loss': 0.20950710381904658}
2023-01-04 02:36:24,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:24,188 INFO:     Epoch: 54
2023-01-04 02:36:25,796 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34370701014995575, 'Total loss': 0.34370701014995575} | train loss {'Reaction outcome loss': 0.2082777190205716, 'Total loss': 0.2082777190205716}
2023-01-04 02:36:25,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:25,796 INFO:     Epoch: 55
2023-01-04 02:36:27,375 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3295362710952759, 'Total loss': 0.3295362710952759} | train loss {'Reaction outcome loss': 0.20542354491559695, 'Total loss': 0.20542354491559695}
2023-01-04 02:36:27,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:27,376 INFO:     Epoch: 56
2023-01-04 02:36:28,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32200313558181126, 'Total loss': 0.32200313558181126} | train loss {'Reaction outcome loss': 0.20519748021488207, 'Total loss': 0.20519748021488207}
2023-01-04 02:36:28,959 INFO:     Found new best model at epoch 56
2023-01-04 02:36:28,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:28,960 INFO:     Epoch: 57
2023-01-04 02:36:30,573 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3351595774292946, 'Total loss': 0.3351595774292946} | train loss {'Reaction outcome loss': 0.2027602770304593, 'Total loss': 0.2027602770304593}
2023-01-04 02:36:30,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:30,573 INFO:     Epoch: 58
2023-01-04 02:36:32,167 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3308863118290901, 'Total loss': 0.3308863118290901} | train loss {'Reaction outcome loss': 0.2002780177650878, 'Total loss': 0.2002780177650878}
2023-01-04 02:36:32,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:32,167 INFO:     Epoch: 59
2023-01-04 02:36:33,781 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3388127570350965, 'Total loss': 0.3388127570350965} | train loss {'Reaction outcome loss': 0.2012296461085551, 'Total loss': 0.2012296461085551}
2023-01-04 02:36:33,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:33,782 INFO:     Epoch: 60
2023-01-04 02:36:35,396 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3383351395527522, 'Total loss': 0.3383351395527522} | train loss {'Reaction outcome loss': 0.19755004078530483, 'Total loss': 0.19755004078530483}
2023-01-04 02:36:35,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:35,396 INFO:     Epoch: 61
2023-01-04 02:36:37,013 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3379599556326866, 'Total loss': 0.3379599556326866} | train loss {'Reaction outcome loss': 0.1985715716315882, 'Total loss': 0.1985715716315882}
2023-01-04 02:36:37,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:37,013 INFO:     Epoch: 62
2023-01-04 02:36:38,585 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3395916680494944, 'Total loss': 0.3395916680494944} | train loss {'Reaction outcome loss': 0.19731475605908103, 'Total loss': 0.19731475605908103}
2023-01-04 02:36:38,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:38,585 INFO:     Epoch: 63
2023-01-04 02:36:40,177 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3258792773510019, 'Total loss': 0.3258792773510019} | train loss {'Reaction outcome loss': 0.19426048927036296, 'Total loss': 0.19426048927036296}
2023-01-04 02:36:40,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:40,177 INFO:     Epoch: 64
2023-01-04 02:36:41,756 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34602707376082736, 'Total loss': 0.34602707376082736} | train loss {'Reaction outcome loss': 0.19517865157720163, 'Total loss': 0.19517865157720163}
2023-01-04 02:36:41,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:41,756 INFO:     Epoch: 65
2023-01-04 02:36:43,365 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35933632453282677, 'Total loss': 0.35933632453282677} | train loss {'Reaction outcome loss': 0.19321913594366424, 'Total loss': 0.19321913594366424}
2023-01-04 02:36:43,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:43,366 INFO:     Epoch: 66
2023-01-04 02:36:44,982 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33654269377390544, 'Total loss': 0.33654269377390544} | train loss {'Reaction outcome loss': 0.19364569940515897, 'Total loss': 0.19364569940515897}
2023-01-04 02:36:44,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:44,982 INFO:     Epoch: 67
2023-01-04 02:36:46,596 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35641391277313234, 'Total loss': 0.35641391277313234} | train loss {'Reaction outcome loss': 0.19094049760623136, 'Total loss': 0.19094049760623136}
2023-01-04 02:36:46,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:46,597 INFO:     Epoch: 68
2023-01-04 02:36:48,186 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3724659820397695, 'Total loss': 0.3724659820397695} | train loss {'Reaction outcome loss': 0.1888249656661366, 'Total loss': 0.1888249656661366}
2023-01-04 02:36:48,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:48,186 INFO:     Epoch: 69
2023-01-04 02:36:49,761 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35813478330771126, 'Total loss': 0.35813478330771126} | train loss {'Reaction outcome loss': 0.18861665255831975, 'Total loss': 0.18861665255831975}
2023-01-04 02:36:49,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:49,761 INFO:     Epoch: 70
2023-01-04 02:36:51,367 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3275736083587011, 'Total loss': 0.3275736083587011} | train loss {'Reaction outcome loss': 0.188972358476289, 'Total loss': 0.188972358476289}
2023-01-04 02:36:51,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:51,367 INFO:     Epoch: 71
2023-01-04 02:36:52,963 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33325898001591364, 'Total loss': 0.33325898001591364} | train loss {'Reaction outcome loss': 0.18600308582404235, 'Total loss': 0.18600308582404235}
2023-01-04 02:36:52,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:52,964 INFO:     Epoch: 72
2023-01-04 02:36:54,576 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3461433539787928, 'Total loss': 0.3461433539787928} | train loss {'Reaction outcome loss': 0.1857283248287374, 'Total loss': 0.1857283248287374}
2023-01-04 02:36:54,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:54,576 INFO:     Epoch: 73
2023-01-04 02:36:56,170 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3478912537296613, 'Total loss': 0.3478912537296613} | train loss {'Reaction outcome loss': 0.1866515915650521, 'Total loss': 0.1866515915650521}
2023-01-04 02:36:56,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:56,170 INFO:     Epoch: 74
2023-01-04 02:36:57,744 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3404020220041275, 'Total loss': 0.3404020220041275} | train loss {'Reaction outcome loss': 0.18452797518077776, 'Total loss': 0.18452797518077776}
2023-01-04 02:36:57,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:57,744 INFO:     Epoch: 75
2023-01-04 02:36:59,319 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36257806022961936, 'Total loss': 0.36257806022961936} | train loss {'Reaction outcome loss': 0.18084533936785954, 'Total loss': 0.18084533936785954}
2023-01-04 02:36:59,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:36:59,320 INFO:     Epoch: 76
2023-01-04 02:37:00,907 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3345227936903636, 'Total loss': 0.3345227936903636} | train loss {'Reaction outcome loss': 0.18243229870487304, 'Total loss': 0.18243229870487304}
2023-01-04 02:37:00,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:00,907 INFO:     Epoch: 77
2023-01-04 02:37:02,494 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3666855792204539, 'Total loss': 0.3666855792204539} | train loss {'Reaction outcome loss': 0.18297152111755452, 'Total loss': 0.18297152111755452}
2023-01-04 02:37:02,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:02,495 INFO:     Epoch: 78
2023-01-04 02:37:04,090 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35230693916479744, 'Total loss': 0.35230693916479744} | train loss {'Reaction outcome loss': 0.18061561981066518, 'Total loss': 0.18061561981066518}
2023-01-04 02:37:04,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:04,090 INFO:     Epoch: 79
2023-01-04 02:37:05,675 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3616444518168767, 'Total loss': 0.3616444518168767} | train loss {'Reaction outcome loss': 0.17836729898015513, 'Total loss': 0.17836729898015513}
2023-01-04 02:37:05,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:05,675 INFO:     Epoch: 80
2023-01-04 02:37:07,252 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33783637881278994, 'Total loss': 0.33783637881278994} | train loss {'Reaction outcome loss': 0.17838964310141592, 'Total loss': 0.17838964310141592}
2023-01-04 02:37:07,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:07,252 INFO:     Epoch: 81
2023-01-04 02:37:08,839 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36503053704897565, 'Total loss': 0.36503053704897565} | train loss {'Reaction outcome loss': 0.17507324929954143, 'Total loss': 0.17507324929954143}
2023-01-04 02:37:08,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:08,840 INFO:     Epoch: 82
2023-01-04 02:37:10,444 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39006133874257404, 'Total loss': 0.39006133874257404} | train loss {'Reaction outcome loss': 0.17699828772826026, 'Total loss': 0.17699828772826026}
2023-01-04 02:37:10,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:10,444 INFO:     Epoch: 83
2023-01-04 02:37:12,032 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34390142261981965, 'Total loss': 0.34390142261981965} | train loss {'Reaction outcome loss': 0.1788514583595913, 'Total loss': 0.1788514583595913}
2023-01-04 02:37:12,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:12,032 INFO:     Epoch: 84
2023-01-04 02:37:13,635 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3753946403662364, 'Total loss': 0.3753946403662364} | train loss {'Reaction outcome loss': 0.1766562491356239, 'Total loss': 0.1766562491356239}
2023-01-04 02:37:13,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:13,636 INFO:     Epoch: 85
2023-01-04 02:37:15,235 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3547009607156118, 'Total loss': 0.3547009607156118} | train loss {'Reaction outcome loss': 0.17647312241640403, 'Total loss': 0.17647312241640403}
2023-01-04 02:37:15,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:15,235 INFO:     Epoch: 86
2023-01-04 02:37:16,815 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3470233331123988, 'Total loss': 0.3470233331123988} | train loss {'Reaction outcome loss': 0.1746453388872808, 'Total loss': 0.1746453388872808}
2023-01-04 02:37:16,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:16,815 INFO:     Epoch: 87
2023-01-04 02:37:18,403 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3565775007009506, 'Total loss': 0.3565775007009506} | train loss {'Reaction outcome loss': 0.17373032415163342, 'Total loss': 0.17373032415163342}
2023-01-04 02:37:18,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:18,403 INFO:     Epoch: 88
2023-01-04 02:37:19,991 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3486503928899765, 'Total loss': 0.3486503928899765} | train loss {'Reaction outcome loss': 0.17289587217688995, 'Total loss': 0.17289587217688995}
2023-01-04 02:37:19,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:19,991 INFO:     Epoch: 89
2023-01-04 02:37:21,577 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3526525964339574, 'Total loss': 0.3526525964339574} | train loss {'Reaction outcome loss': 0.17196374111910806, 'Total loss': 0.17196374111910806}
2023-01-04 02:37:21,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:21,578 INFO:     Epoch: 90
2023-01-04 02:37:23,150 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3891532113154729, 'Total loss': 0.3891532113154729} | train loss {'Reaction outcome loss': 0.17121435400016988, 'Total loss': 0.17121435400016988}
2023-01-04 02:37:23,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:23,150 INFO:     Epoch: 91
2023-01-04 02:37:24,714 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.369597535332044, 'Total loss': 0.369597535332044} | train loss {'Reaction outcome loss': 0.17111724256163965, 'Total loss': 0.17111724256163965}
2023-01-04 02:37:24,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:24,714 INFO:     Epoch: 92
2023-01-04 02:37:26,296 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3349482536315918, 'Total loss': 0.3349482536315918} | train loss {'Reaction outcome loss': 0.1704854328171724, 'Total loss': 0.1704854328171724}
2023-01-04 02:37:26,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:26,297 INFO:     Epoch: 93
2023-01-04 02:37:27,877 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3695513983567556, 'Total loss': 0.3695513983567556} | train loss {'Reaction outcome loss': 0.17324789724292328, 'Total loss': 0.17324789724292328}
2023-01-04 02:37:27,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:27,877 INFO:     Epoch: 94
2023-01-04 02:37:29,485 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35081618453065555, 'Total loss': 0.35081618453065555} | train loss {'Reaction outcome loss': 0.16930934344928195, 'Total loss': 0.16930934344928195}
2023-01-04 02:37:29,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:29,486 INFO:     Epoch: 95
2023-01-04 02:37:31,098 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36413356810808184, 'Total loss': 0.36413356810808184} | train loss {'Reaction outcome loss': 0.16756859055998988, 'Total loss': 0.16756859055998988}
2023-01-04 02:37:31,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:31,098 INFO:     Epoch: 96
2023-01-04 02:37:32,691 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.377268726627032, 'Total loss': 0.377268726627032} | train loss {'Reaction outcome loss': 0.17059796588345819, 'Total loss': 0.17059796588345819}
2023-01-04 02:37:32,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:32,692 INFO:     Epoch: 97
2023-01-04 02:37:34,280 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3559538498520851, 'Total loss': 0.3559538498520851} | train loss {'Reaction outcome loss': 0.16847996661154024, 'Total loss': 0.16847996661154024}
2023-01-04 02:37:34,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:34,280 INFO:     Epoch: 98
2023-01-04 02:37:35,888 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3533438483874003, 'Total loss': 0.3533438483874003} | train loss {'Reaction outcome loss': 0.16993144817351208, 'Total loss': 0.16993144817351208}
2023-01-04 02:37:35,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:35,888 INFO:     Epoch: 99
2023-01-04 02:37:37,466 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3532346040010452, 'Total loss': 0.3532346040010452} | train loss {'Reaction outcome loss': 0.16831845989328448, 'Total loss': 0.16831845989328448}
2023-01-04 02:37:37,466 INFO:     Best model found after epoch 57 of 100.
2023-01-04 02:37:37,466 INFO:   Done with stage: TRAINING
2023-01-04 02:37:37,466 INFO:   Starting stage: EVALUATION
2023-01-04 02:37:37,600 INFO:   Done with stage: EVALUATION
2023-01-04 02:37:37,600 INFO:   Leaving out SEQ value Fold_3
2023-01-04 02:37:37,613 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 02:37:37,613 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:37:38,258 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:37:38,258 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:37:38,326 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:37:38,327 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:37:38,327 INFO:     No hyperparam tuning for this model
2023-01-04 02:37:38,327 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:37:38,327 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:37:38,328 INFO:     None feature selector for col prot
2023-01-04 02:37:38,328 INFO:     None feature selector for col prot
2023-01-04 02:37:38,328 INFO:     None feature selector for col prot
2023-01-04 02:37:38,328 INFO:     None feature selector for col chem
2023-01-04 02:37:38,328 INFO:     None feature selector for col chem
2023-01-04 02:37:38,328 INFO:     None feature selector for col chem
2023-01-04 02:37:38,328 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:37:38,329 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:37:38,330 INFO:     Number of params in model 70141
2023-01-04 02:37:38,333 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:37:38,333 INFO:   Starting stage: TRAINING
2023-01-04 02:37:38,376 INFO:     Val loss before train {'Reaction outcome loss': 1.0461981097857158, 'Total loss': 1.0461981097857158}
2023-01-04 02:37:38,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:38,376 INFO:     Epoch: 0
2023-01-04 02:37:39,949 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6837840557098389, 'Total loss': 0.6837840557098389} | train loss {'Reaction outcome loss': 0.8316005421427143, 'Total loss': 0.8316005421427143}
2023-01-04 02:37:39,950 INFO:     Found new best model at epoch 0
2023-01-04 02:37:39,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:39,950 INFO:     Epoch: 1
2023-01-04 02:37:41,533 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.573207684357961, 'Total loss': 0.573207684357961} | train loss {'Reaction outcome loss': 0.591578680844534, 'Total loss': 0.591578680844534}
2023-01-04 02:37:41,533 INFO:     Found new best model at epoch 1
2023-01-04 02:37:41,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:41,534 INFO:     Epoch: 2
2023-01-04 02:37:43,089 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5258379856745402, 'Total loss': 0.5258379856745402} | train loss {'Reaction outcome loss': 0.5173068447754934, 'Total loss': 0.5173068447754934}
2023-01-04 02:37:43,089 INFO:     Found new best model at epoch 2
2023-01-04 02:37:43,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:43,090 INFO:     Epoch: 3
2023-01-04 02:37:44,666 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.51541574994723, 'Total loss': 0.51541574994723} | train loss {'Reaction outcome loss': 0.4803524158703975, 'Total loss': 0.4803524158703975}
2023-01-04 02:37:44,666 INFO:     Found new best model at epoch 3
2023-01-04 02:37:44,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:44,667 INFO:     Epoch: 4
2023-01-04 02:37:46,256 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49243888556957244, 'Total loss': 0.49243888556957244} | train loss {'Reaction outcome loss': 0.4572063661265723, 'Total loss': 0.4572063661265723}
2023-01-04 02:37:46,256 INFO:     Found new best model at epoch 4
2023-01-04 02:37:46,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:46,257 INFO:     Epoch: 5
2023-01-04 02:37:47,860 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4774921069542567, 'Total loss': 0.4774921069542567} | train loss {'Reaction outcome loss': 0.44011974116384767, 'Total loss': 0.44011974116384767}
2023-01-04 02:37:47,860 INFO:     Found new best model at epoch 5
2023-01-04 02:37:47,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:47,861 INFO:     Epoch: 6
2023-01-04 02:37:49,444 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47154511213302613, 'Total loss': 0.47154511213302613} | train loss {'Reaction outcome loss': 0.4260055322350163, 'Total loss': 0.4260055322350163}
2023-01-04 02:37:49,444 INFO:     Found new best model at epoch 6
2023-01-04 02:37:49,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:49,445 INFO:     Epoch: 7
2023-01-04 02:37:51,052 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4535621682802836, 'Total loss': 0.4535621682802836} | train loss {'Reaction outcome loss': 0.41194565269427424, 'Total loss': 0.41194565269427424}
2023-01-04 02:37:51,052 INFO:     Found new best model at epoch 7
2023-01-04 02:37:51,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:51,053 INFO:     Epoch: 8
2023-01-04 02:37:52,617 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43660962382952373, 'Total loss': 0.43660962382952373} | train loss {'Reaction outcome loss': 0.39941715806613476, 'Total loss': 0.39941715806613476}
2023-01-04 02:37:52,618 INFO:     Found new best model at epoch 8
2023-01-04 02:37:52,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:52,619 INFO:     Epoch: 9
2023-01-04 02:37:54,195 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4964958518743515, 'Total loss': 0.4964958518743515} | train loss {'Reaction outcome loss': 0.3899229307532747, 'Total loss': 0.3899229307532747}
2023-01-04 02:37:54,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:54,195 INFO:     Epoch: 10
2023-01-04 02:37:55,773 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4490993122259776, 'Total loss': 0.4490993122259776} | train loss {'Reaction outcome loss': 0.38201686911858046, 'Total loss': 0.38201686911858046}
2023-01-04 02:37:55,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:55,773 INFO:     Epoch: 11
2023-01-04 02:37:57,351 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4436768511931101, 'Total loss': 0.4436768511931101} | train loss {'Reaction outcome loss': 0.3687970587240034, 'Total loss': 0.3687970587240034}
2023-01-04 02:37:57,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:57,351 INFO:     Epoch: 12
2023-01-04 02:37:58,916 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4380531976620356, 'Total loss': 0.4380531976620356} | train loss {'Reaction outcome loss': 0.36563057070359206, 'Total loss': 0.36563057070359206}
2023-01-04 02:37:58,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:37:58,916 INFO:     Epoch: 13
2023-01-04 02:38:00,478 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43397965331872307, 'Total loss': 0.43397965331872307} | train loss {'Reaction outcome loss': 0.3560340030889808, 'Total loss': 0.3560340030889808}
2023-01-04 02:38:00,478 INFO:     Found new best model at epoch 13
2023-01-04 02:38:00,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:00,479 INFO:     Epoch: 14
2023-01-04 02:38:02,050 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4408361792564392, 'Total loss': 0.4408361792564392} | train loss {'Reaction outcome loss': 0.3472883077986511, 'Total loss': 0.3472883077986511}
2023-01-04 02:38:02,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:02,050 INFO:     Epoch: 15
2023-01-04 02:38:03,650 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4280887871980667, 'Total loss': 0.4280887871980667} | train loss {'Reaction outcome loss': 0.33910335398419, 'Total loss': 0.33910335398419}
2023-01-04 02:38:03,650 INFO:     Found new best model at epoch 15
2023-01-04 02:38:03,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:03,651 INFO:     Epoch: 16
2023-01-04 02:38:05,223 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42005016952753066, 'Total loss': 0.42005016952753066} | train loss {'Reaction outcome loss': 0.3334049355688986, 'Total loss': 0.3334049355688986}
2023-01-04 02:38:05,223 INFO:     Found new best model at epoch 16
2023-01-04 02:38:05,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:05,224 INFO:     Epoch: 17
2023-01-04 02:38:06,794 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43759127060572306, 'Total loss': 0.43759127060572306} | train loss {'Reaction outcome loss': 0.32961404883053713, 'Total loss': 0.32961404883053713}
2023-01-04 02:38:06,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:06,794 INFO:     Epoch: 18
2023-01-04 02:38:08,383 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4380177696545919, 'Total loss': 0.4380177696545919} | train loss {'Reaction outcome loss': 0.3233286794343274, 'Total loss': 0.3233286794343274}
2023-01-04 02:38:08,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:08,385 INFO:     Epoch: 19
2023-01-04 02:38:09,956 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4169873644908269, 'Total loss': 0.4169873644908269} | train loss {'Reaction outcome loss': 0.3195482863611354, 'Total loss': 0.3195482863611354}
2023-01-04 02:38:09,956 INFO:     Found new best model at epoch 19
2023-01-04 02:38:09,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:09,957 INFO:     Epoch: 20
2023-01-04 02:38:11,526 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4277101973692576, 'Total loss': 0.4277101973692576} | train loss {'Reaction outcome loss': 0.31347758524911307, 'Total loss': 0.31347758524911307}
2023-01-04 02:38:11,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:11,527 INFO:     Epoch: 21
2023-01-04 02:38:13,125 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.436680602033933, 'Total loss': 0.436680602033933} | train loss {'Reaction outcome loss': 0.3095251019129823, 'Total loss': 0.3095251019129823}
2023-01-04 02:38:13,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:13,125 INFO:     Epoch: 22
2023-01-04 02:38:14,735 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.447934494415919, 'Total loss': 0.447934494415919} | train loss {'Reaction outcome loss': 0.30504176566452335, 'Total loss': 0.30504176566452335}
2023-01-04 02:38:14,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:14,736 INFO:     Epoch: 23
2023-01-04 02:38:16,295 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40645441512266794, 'Total loss': 0.40645441512266794} | train loss {'Reaction outcome loss': 0.2990101058131609, 'Total loss': 0.2990101058131609}
2023-01-04 02:38:16,295 INFO:     Found new best model at epoch 23
2023-01-04 02:38:16,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:16,296 INFO:     Epoch: 24
2023-01-04 02:38:17,902 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4128313978513082, 'Total loss': 0.4128313978513082} | train loss {'Reaction outcome loss': 0.29385342266096737, 'Total loss': 0.29385342266096737}
2023-01-04 02:38:17,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:17,902 INFO:     Epoch: 25
2023-01-04 02:38:19,467 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42899683564901353, 'Total loss': 0.42899683564901353} | train loss {'Reaction outcome loss': 0.288500057826767, 'Total loss': 0.288500057826767}
2023-01-04 02:38:19,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:19,467 INFO:     Epoch: 26
2023-01-04 02:38:21,045 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4278191427389781, 'Total loss': 0.4278191427389781} | train loss {'Reaction outcome loss': 0.28851120479595965, 'Total loss': 0.28851120479595965}
2023-01-04 02:38:21,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:21,045 INFO:     Epoch: 27
2023-01-04 02:38:22,622 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42826836109161376, 'Total loss': 0.42826836109161376} | train loss {'Reaction outcome loss': 0.28181744568159073, 'Total loss': 0.28181744568159073}
2023-01-04 02:38:22,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:22,623 INFO:     Epoch: 28
2023-01-04 02:38:24,200 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4013795773188273, 'Total loss': 0.4013795773188273} | train loss {'Reaction outcome loss': 0.2798214999365283, 'Total loss': 0.2798214999365283}
2023-01-04 02:38:24,200 INFO:     Found new best model at epoch 28
2023-01-04 02:38:24,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:24,201 INFO:     Epoch: 29
2023-01-04 02:38:25,762 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40253155728181206, 'Total loss': 0.40253155728181206} | train loss {'Reaction outcome loss': 0.27783824806357477, 'Total loss': 0.27783824806357477}
2023-01-04 02:38:25,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:25,762 INFO:     Epoch: 30
2023-01-04 02:38:27,325 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4358369499444962, 'Total loss': 0.4358369499444962} | train loss {'Reaction outcome loss': 0.2766499360238676, 'Total loss': 0.2766499360238676}
2023-01-04 02:38:27,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:27,326 INFO:     Epoch: 31
2023-01-04 02:38:28,894 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43059411148230237, 'Total loss': 0.43059411148230237} | train loss {'Reaction outcome loss': 0.2715225185066352, 'Total loss': 0.2715225185066352}
2023-01-04 02:38:28,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:28,894 INFO:     Epoch: 32
2023-01-04 02:38:30,495 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4142217129468918, 'Total loss': 0.4142217129468918} | train loss {'Reaction outcome loss': 0.26430242020131905, 'Total loss': 0.26430242020131905}
2023-01-04 02:38:30,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:30,495 INFO:     Epoch: 33
2023-01-04 02:38:32,063 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42270771066347756, 'Total loss': 0.42270771066347756} | train loss {'Reaction outcome loss': 0.26313141673366663, 'Total loss': 0.26313141673366663}
2023-01-04 02:38:32,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:32,063 INFO:     Epoch: 34
2023-01-04 02:38:33,663 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3941752461095651, 'Total loss': 0.3941752461095651} | train loss {'Reaction outcome loss': 0.2626018651621246, 'Total loss': 0.2626018651621246}
2023-01-04 02:38:33,663 INFO:     Found new best model at epoch 34
2023-01-04 02:38:33,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:33,664 INFO:     Epoch: 35
2023-01-04 02:38:35,244 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4207359274228414, 'Total loss': 0.4207359274228414} | train loss {'Reaction outcome loss': 0.2569354125247388, 'Total loss': 0.2569354125247388}
2023-01-04 02:38:35,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:35,244 INFO:     Epoch: 36
2023-01-04 02:38:36,818 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4258291224638621, 'Total loss': 0.4258291224638621} | train loss {'Reaction outcome loss': 0.25306998588990814, 'Total loss': 0.25306998588990814}
2023-01-04 02:38:36,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:36,819 INFO:     Epoch: 37
2023-01-04 02:38:38,394 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39242413292328515, 'Total loss': 0.39242413292328515} | train loss {'Reaction outcome loss': 0.25259708364804584, 'Total loss': 0.25259708364804584}
2023-01-04 02:38:38,394 INFO:     Found new best model at epoch 37
2023-01-04 02:38:38,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:38,395 INFO:     Epoch: 38
2023-01-04 02:38:39,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4111396352450053, 'Total loss': 0.4111396352450053} | train loss {'Reaction outcome loss': 0.25202130335263717, 'Total loss': 0.25202130335263717}
2023-01-04 02:38:39,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:39,972 INFO:     Epoch: 39
2023-01-04 02:38:41,550 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42505357712507247, 'Total loss': 0.42505357712507247} | train loss {'Reaction outcome loss': 0.24769941593209902, 'Total loss': 0.24769941593209902}
2023-01-04 02:38:41,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:41,550 INFO:     Epoch: 40
2023-01-04 02:38:43,107 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41627275149027504, 'Total loss': 0.41627275149027504} | train loss {'Reaction outcome loss': 0.24614885321139415, 'Total loss': 0.24614885321139415}
2023-01-04 02:38:43,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:43,107 INFO:     Epoch: 41
2023-01-04 02:38:44,706 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45178241829077403, 'Total loss': 0.45178241829077403} | train loss {'Reaction outcome loss': 0.24180961508071902, 'Total loss': 0.24180961508071902}
2023-01-04 02:38:44,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:44,708 INFO:     Epoch: 42
2023-01-04 02:38:46,287 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4219548091292381, 'Total loss': 0.4219548091292381} | train loss {'Reaction outcome loss': 0.24078207228319112, 'Total loss': 0.24078207228319112}
2023-01-04 02:38:46,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:46,287 INFO:     Epoch: 43
2023-01-04 02:38:47,886 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42954110304514564, 'Total loss': 0.42954110304514564} | train loss {'Reaction outcome loss': 0.2368112033157995, 'Total loss': 0.2368112033157995}
2023-01-04 02:38:47,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:47,886 INFO:     Epoch: 44
2023-01-04 02:38:49,459 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4056920200586319, 'Total loss': 0.4056920200586319} | train loss {'Reaction outcome loss': 0.23562422175055894, 'Total loss': 0.23562422175055894}
2023-01-04 02:38:49,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:49,459 INFO:     Epoch: 45
2023-01-04 02:38:51,063 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40677756890654565, 'Total loss': 0.40677756890654565} | train loss {'Reaction outcome loss': 0.2349448921807083, 'Total loss': 0.2349448921807083}
2023-01-04 02:38:51,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:51,064 INFO:     Epoch: 46
2023-01-04 02:38:52,633 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4175862312316895, 'Total loss': 0.4175862312316895} | train loss {'Reaction outcome loss': 0.23607107382881773, 'Total loss': 0.23607107382881773}
2023-01-04 02:38:52,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:52,633 INFO:     Epoch: 47
2023-01-04 02:38:54,197 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4052856902281443, 'Total loss': 0.4052856902281443} | train loss {'Reaction outcome loss': 0.2294904218079188, 'Total loss': 0.2294904218079188}
2023-01-04 02:38:54,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:54,197 INFO:     Epoch: 48
2023-01-04 02:38:55,797 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43083976904551186, 'Total loss': 0.43083976904551186} | train loss {'Reaction outcome loss': 0.2291564453707073, 'Total loss': 0.2291564453707073}
2023-01-04 02:38:55,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:55,797 INFO:     Epoch: 49
2023-01-04 02:38:57,373 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4090926965077718, 'Total loss': 0.4090926965077718} | train loss {'Reaction outcome loss': 0.2251016738323065, 'Total loss': 0.2251016738323065}
2023-01-04 02:38:57,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:57,373 INFO:     Epoch: 50
2023-01-04 02:38:58,951 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42870495319366453, 'Total loss': 0.42870495319366453} | train loss {'Reaction outcome loss': 0.2223920648151688, 'Total loss': 0.2223920648151688}
2023-01-04 02:38:58,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:38:58,951 INFO:     Epoch: 51
2023-01-04 02:39:00,553 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4169724543889364, 'Total loss': 0.4169724543889364} | train loss {'Reaction outcome loss': 0.2241275914340884, 'Total loss': 0.2241275914340884}
2023-01-04 02:39:00,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:00,553 INFO:     Epoch: 52
2023-01-04 02:39:02,122 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42646626035372415, 'Total loss': 0.42646626035372415} | train loss {'Reaction outcome loss': 0.2215525889189252, 'Total loss': 0.2215525889189252}
2023-01-04 02:39:02,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:02,122 INFO:     Epoch: 53
2023-01-04 02:39:03,683 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4533634752035141, 'Total loss': 0.4533634752035141} | train loss {'Reaction outcome loss': 0.21856780221938213, 'Total loss': 0.21856780221938213}
2023-01-04 02:39:03,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:03,684 INFO:     Epoch: 54
2023-01-04 02:39:05,271 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42561905334393185, 'Total loss': 0.42561905334393185} | train loss {'Reaction outcome loss': 0.21892105438661225, 'Total loss': 0.21892105438661225}
2023-01-04 02:39:05,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:05,271 INFO:     Epoch: 55
2023-01-04 02:39:06,878 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4285232702891032, 'Total loss': 0.4285232702891032} | train loss {'Reaction outcome loss': 0.21577735030989506, 'Total loss': 0.21577735030989506}
2023-01-04 02:39:06,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:06,878 INFO:     Epoch: 56
2023-01-04 02:39:08,482 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4290222406387329, 'Total loss': 0.4290222406387329} | train loss {'Reaction outcome loss': 0.21640852366611635, 'Total loss': 0.21640852366611635}
2023-01-04 02:39:08,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:08,482 INFO:     Epoch: 57
2023-01-04 02:39:10,065 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42593324184417725, 'Total loss': 0.42593324184417725} | train loss {'Reaction outcome loss': 0.21033615046504872, 'Total loss': 0.21033615046504872}
2023-01-04 02:39:10,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:10,065 INFO:     Epoch: 58
2023-01-04 02:39:11,639 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43478637337684634, 'Total loss': 0.43478637337684634} | train loss {'Reaction outcome loss': 0.2108262159175925, 'Total loss': 0.2108262159175925}
2023-01-04 02:39:11,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:11,640 INFO:     Epoch: 59
2023-01-04 02:39:13,227 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41657888690630596, 'Total loss': 0.41657888690630596} | train loss {'Reaction outcome loss': 0.20853988191747402, 'Total loss': 0.20853988191747402}
2023-01-04 02:39:13,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:13,228 INFO:     Epoch: 60
2023-01-04 02:39:14,834 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44775213102499645, 'Total loss': 0.44775213102499645} | train loss {'Reaction outcome loss': 0.20797214468756875, 'Total loss': 0.20797214468756875}
2023-01-04 02:39:14,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:14,834 INFO:     Epoch: 61
2023-01-04 02:39:16,446 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47581806977589924, 'Total loss': 0.47581806977589924} | train loss {'Reaction outcome loss': 0.2053456692222929, 'Total loss': 0.2053456692222929}
2023-01-04 02:39:16,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:16,447 INFO:     Epoch: 62
2023-01-04 02:39:18,052 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4510941460728645, 'Total loss': 0.4510941460728645} | train loss {'Reaction outcome loss': 0.20664616657809898, 'Total loss': 0.20664616657809898}
2023-01-04 02:39:18,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:18,052 INFO:     Epoch: 63
2023-01-04 02:39:19,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41959422330061596, 'Total loss': 0.41959422330061596} | train loss {'Reaction outcome loss': 0.2030827756629977, 'Total loss': 0.2030827756629977}
2023-01-04 02:39:19,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:19,646 INFO:     Epoch: 64
2023-01-04 02:39:21,230 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4409765323003133, 'Total loss': 0.4409765323003133} | train loss {'Reaction outcome loss': 0.20341687200543207, 'Total loss': 0.20341687200543207}
2023-01-04 02:39:21,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:21,231 INFO:     Epoch: 65
2023-01-04 02:39:22,836 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4314052015542984, 'Total loss': 0.4314052015542984} | train loss {'Reaction outcome loss': 0.1992916675496014, 'Total loss': 0.1992916675496014}
2023-01-04 02:39:22,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:22,837 INFO:     Epoch: 66
2023-01-04 02:39:24,409 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43926884134610494, 'Total loss': 0.43926884134610494} | train loss {'Reaction outcome loss': 0.19773692742071963, 'Total loss': 0.19773692742071963}
2023-01-04 02:39:24,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:24,409 INFO:     Epoch: 67
2023-01-04 02:39:26,015 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4505880663792292, 'Total loss': 0.4505880663792292} | train loss {'Reaction outcome loss': 0.19593311243114017, 'Total loss': 0.19593311243114017}
2023-01-04 02:39:26,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:26,015 INFO:     Epoch: 68
2023-01-04 02:39:27,626 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4280593683322271, 'Total loss': 0.4280593683322271} | train loss {'Reaction outcome loss': 0.19361084086254185, 'Total loss': 0.19361084086254185}
2023-01-04 02:39:27,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:27,627 INFO:     Epoch: 69
2023-01-04 02:39:29,212 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4264572819073995, 'Total loss': 0.4264572819073995} | train loss {'Reaction outcome loss': 0.19361907516643678, 'Total loss': 0.19361907516643678}
2023-01-04 02:39:29,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:29,212 INFO:     Epoch: 70
2023-01-04 02:39:30,786 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4323276768128077, 'Total loss': 0.4323276768128077} | train loss {'Reaction outcome loss': 0.1931203730786458, 'Total loss': 0.1931203730786458}
2023-01-04 02:39:30,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:30,786 INFO:     Epoch: 71
2023-01-04 02:39:32,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4372218668460846, 'Total loss': 0.4372218668460846} | train loss {'Reaction outcome loss': 0.19287200654846626, 'Total loss': 0.19287200654846626}
2023-01-04 02:39:32,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:32,391 INFO:     Epoch: 72
2023-01-04 02:39:33,996 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4426934033632278, 'Total loss': 0.4426934033632278} | train loss {'Reaction outcome loss': 0.1924272990707076, 'Total loss': 0.1924272990707076}
2023-01-04 02:39:33,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:33,996 INFO:     Epoch: 73
2023-01-04 02:39:35,603 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42959254955252013, 'Total loss': 0.42959254955252013} | train loss {'Reaction outcome loss': 0.19254569720899883, 'Total loss': 0.19254569720899883}
2023-01-04 02:39:35,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:35,604 INFO:     Epoch: 74
2023-01-04 02:39:37,160 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4489265620708466, 'Total loss': 0.4489265620708466} | train loss {'Reaction outcome loss': 0.18764953361653583, 'Total loss': 0.18764953361653583}
2023-01-04 02:39:37,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:37,160 INFO:     Epoch: 75
2023-01-04 02:39:38,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4444171796242396, 'Total loss': 0.4444171796242396} | train loss {'Reaction outcome loss': 0.18582840844470283, 'Total loss': 0.18582840844470283}
2023-01-04 02:39:38,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:38,753 INFO:     Epoch: 76
2023-01-04 02:39:40,317 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43346922248601916, 'Total loss': 0.43346922248601916} | train loss {'Reaction outcome loss': 0.1877110467288957, 'Total loss': 0.1877110467288957}
2023-01-04 02:39:40,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:40,317 INFO:     Epoch: 77
2023-01-04 02:39:41,893 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44943268795808156, 'Total loss': 0.44943268795808156} | train loss {'Reaction outcome loss': 0.18399325085483192, 'Total loss': 0.18399325085483192}
2023-01-04 02:39:41,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:41,893 INFO:     Epoch: 78
2023-01-04 02:39:43,475 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4447363873322805, 'Total loss': 0.4447363873322805} | train loss {'Reaction outcome loss': 0.18403750606863709, 'Total loss': 0.18403750606863709}
2023-01-04 02:39:43,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:43,475 INFO:     Epoch: 79
2023-01-04 02:39:45,083 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43042976160844165, 'Total loss': 0.43042976160844165} | train loss {'Reaction outcome loss': 0.18323477131788765, 'Total loss': 0.18323477131788765}
2023-01-04 02:39:45,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:45,083 INFO:     Epoch: 80
2023-01-04 02:39:46,664 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45482500791549685, 'Total loss': 0.45482500791549685} | train loss {'Reaction outcome loss': 0.18124052839892688, 'Total loss': 0.18124052839892688}
2023-01-04 02:39:46,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:46,664 INFO:     Epoch: 81
2023-01-04 02:39:48,241 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.471931288142999, 'Total loss': 0.471931288142999} | train loss {'Reaction outcome loss': 0.1795113551201838, 'Total loss': 0.1795113551201838}
2023-01-04 02:39:48,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:48,241 INFO:     Epoch: 82
2023-01-04 02:39:49,845 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.458946959177653, 'Total loss': 0.458946959177653} | train loss {'Reaction outcome loss': 0.17718592914496803, 'Total loss': 0.17718592914496803}
2023-01-04 02:39:49,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:49,845 INFO:     Epoch: 83
2023-01-04 02:39:51,437 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46123385379711784, 'Total loss': 0.46123385379711784} | train loss {'Reaction outcome loss': 0.17703786089798032, 'Total loss': 0.17703786089798032}
2023-01-04 02:39:51,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:51,438 INFO:     Epoch: 84
2023-01-04 02:39:53,036 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47013410727183025, 'Total loss': 0.47013410727183025} | train loss {'Reaction outcome loss': 0.17925208987115504, 'Total loss': 0.17925208987115504}
2023-01-04 02:39:53,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:53,037 INFO:     Epoch: 85
2023-01-04 02:39:54,648 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48385932445526125, 'Total loss': 0.48385932445526125} | train loss {'Reaction outcome loss': 0.17731201526582677, 'Total loss': 0.17731201526582677}
2023-01-04 02:39:54,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:54,648 INFO:     Epoch: 86
2023-01-04 02:39:56,237 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45890064239501954, 'Total loss': 0.45890064239501954} | train loss {'Reaction outcome loss': 0.17338498732272958, 'Total loss': 0.17338498732272958}
2023-01-04 02:39:56,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:56,237 INFO:     Epoch: 87
2023-01-04 02:39:57,809 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45400023261706035, 'Total loss': 0.45400023261706035} | train loss {'Reaction outcome loss': 0.17529291181309975, 'Total loss': 0.17529291181309975}
2023-01-04 02:39:57,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:57,810 INFO:     Epoch: 88
2023-01-04 02:39:59,401 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4725926707188288, 'Total loss': 0.4725926707188288} | train loss {'Reaction outcome loss': 0.1721191710209126, 'Total loss': 0.1721191710209126}
2023-01-04 02:39:59,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:39:59,401 INFO:     Epoch: 89
2023-01-04 02:40:01,012 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4679778019587199, 'Total loss': 0.4679778019587199} | train loss {'Reaction outcome loss': 0.1736122371540183, 'Total loss': 0.1736122371540183}
2023-01-04 02:40:01,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:01,013 INFO:     Epoch: 90
2023-01-04 02:40:02,589 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4803944448630015, 'Total loss': 0.4803944448630015} | train loss {'Reaction outcome loss': 0.17120854015506448, 'Total loss': 0.17120854015506448}
2023-01-04 02:40:02,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:02,590 INFO:     Epoch: 91
2023-01-04 02:40:04,115 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4791600197553635, 'Total loss': 0.4791600197553635} | train loss {'Reaction outcome loss': 0.17129712572983113, 'Total loss': 0.17129712572983113}
2023-01-04 02:40:04,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:04,115 INFO:     Epoch: 92
2023-01-04 02:40:05,174 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5394624998172124, 'Total loss': 0.5394624998172124} | train loss {'Reaction outcome loss': 0.17043772885650943, 'Total loss': 0.17043772885650943}
2023-01-04 02:40:05,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:05,174 INFO:     Epoch: 93
2023-01-04 02:40:06,247 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44432222060859206, 'Total loss': 0.44432222060859206} | train loss {'Reaction outcome loss': 0.1702769044172633, 'Total loss': 0.1702769044172633}
2023-01-04 02:40:06,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:06,248 INFO:     Epoch: 94
2023-01-04 02:40:07,310 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47562794089317323, 'Total loss': 0.47562794089317323} | train loss {'Reaction outcome loss': 0.17068576566438318, 'Total loss': 0.17068576566438318}
2023-01-04 02:40:07,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:07,310 INFO:     Epoch: 95
2023-01-04 02:40:08,448 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44142619357444346, 'Total loss': 0.44142619357444346} | train loss {'Reaction outcome loss': 0.16948669890262485, 'Total loss': 0.16948669890262485}
2023-01-04 02:40:08,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:08,448 INFO:     Epoch: 96
2023-01-04 02:40:10,023 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4516057846446832, 'Total loss': 0.4516057846446832} | train loss {'Reaction outcome loss': 0.1694439500092696, 'Total loss': 0.1694439500092696}
2023-01-04 02:40:10,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:10,024 INFO:     Epoch: 97
2023-01-04 02:40:11,599 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4569125659763813, 'Total loss': 0.4569125659763813} | train loss {'Reaction outcome loss': 0.17039257577269068, 'Total loss': 0.17039257577269068}
2023-01-04 02:40:11,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:11,599 INFO:     Epoch: 98
2023-01-04 02:40:13,172 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4554667005936305, 'Total loss': 0.4554667005936305} | train loss {'Reaction outcome loss': 0.16444376031202929, 'Total loss': 0.16444376031202929}
2023-01-04 02:40:13,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:13,173 INFO:     Epoch: 99
2023-01-04 02:40:14,757 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4745541900396347, 'Total loss': 0.4745541900396347} | train loss {'Reaction outcome loss': 0.1623949982607976, 'Total loss': 0.1623949982607976}
2023-01-04 02:40:14,757 INFO:     Best model found after epoch 38 of 100.
2023-01-04 02:40:14,757 INFO:   Done with stage: TRAINING
2023-01-04 02:40:14,757 INFO:   Starting stage: EVALUATION
2023-01-04 02:40:14,899 INFO:   Done with stage: EVALUATION
2023-01-04 02:40:14,900 INFO:   Leaving out SEQ value Fold_4
2023-01-04 02:40:14,912 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:40:14,912 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:40:15,574 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:40:15,574 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:40:15,645 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:40:15,645 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:40:15,645 INFO:     No hyperparam tuning for this model
2023-01-04 02:40:15,645 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:40:15,645 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:40:15,646 INFO:     None feature selector for col prot
2023-01-04 02:40:15,646 INFO:     None feature selector for col prot
2023-01-04 02:40:15,646 INFO:     None feature selector for col prot
2023-01-04 02:40:15,646 INFO:     None feature selector for col chem
2023-01-04 02:40:15,646 INFO:     None feature selector for col chem
2023-01-04 02:40:15,647 INFO:     None feature selector for col chem
2023-01-04 02:40:15,647 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:40:15,647 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:40:15,648 INFO:     Number of params in model 70141
2023-01-04 02:40:15,651 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:40:15,651 INFO:   Starting stage: TRAINING
2023-01-04 02:40:15,696 INFO:     Val loss before train {'Reaction outcome loss': 1.0661391377449037, 'Total loss': 1.0661391377449037}
2023-01-04 02:40:15,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:15,697 INFO:     Epoch: 0
2023-01-04 02:40:17,283 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7089464406172434, 'Total loss': 0.7089464406172434} | train loss {'Reaction outcome loss': 0.8419147006681432, 'Total loss': 0.8419147006681432}
2023-01-04 02:40:17,283 INFO:     Found new best model at epoch 0
2023-01-04 02:40:17,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:17,284 INFO:     Epoch: 1
2023-01-04 02:40:18,888 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5469602028528849, 'Total loss': 0.5469602028528849} | train loss {'Reaction outcome loss': 0.6007674899006236, 'Total loss': 0.6007674899006236}
2023-01-04 02:40:18,888 INFO:     Found new best model at epoch 1
2023-01-04 02:40:18,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:18,889 INFO:     Epoch: 2
2023-01-04 02:40:20,476 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5027641534805298, 'Total loss': 0.5027641534805298} | train loss {'Reaction outcome loss': 0.5255657657862817, 'Total loss': 0.5255657657862817}
2023-01-04 02:40:20,477 INFO:     Found new best model at epoch 2
2023-01-04 02:40:20,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:20,477 INFO:     Epoch: 3
2023-01-04 02:40:22,057 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47919182578722636, 'Total loss': 0.47919182578722636} | train loss {'Reaction outcome loss': 0.48803923789840326, 'Total loss': 0.48803923789840326}
2023-01-04 02:40:22,058 INFO:     Found new best model at epoch 3
2023-01-04 02:40:22,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:22,059 INFO:     Epoch: 4
2023-01-04 02:40:23,674 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43603367656469344, 'Total loss': 0.43603367656469344} | train loss {'Reaction outcome loss': 0.4590507534103117, 'Total loss': 0.4590507534103117}
2023-01-04 02:40:23,674 INFO:     Found new best model at epoch 4
2023-01-04 02:40:23,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:23,675 INFO:     Epoch: 5
2023-01-04 02:40:25,269 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4315830181042353, 'Total loss': 0.4315830181042353} | train loss {'Reaction outcome loss': 0.4375327779520033, 'Total loss': 0.4375327779520033}
2023-01-04 02:40:25,269 INFO:     Found new best model at epoch 5
2023-01-04 02:40:25,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:25,270 INFO:     Epoch: 6
2023-01-04 02:40:26,861 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4367194682359695, 'Total loss': 0.4367194682359695} | train loss {'Reaction outcome loss': 0.4205935443447822, 'Total loss': 0.4205935443447822}
2023-01-04 02:40:26,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:26,861 INFO:     Epoch: 7
2023-01-04 02:40:28,447 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4045118530591329, 'Total loss': 0.4045118530591329} | train loss {'Reaction outcome loss': 0.4085727419866168, 'Total loss': 0.4085727419866168}
2023-01-04 02:40:28,448 INFO:     Found new best model at epoch 7
2023-01-04 02:40:28,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:28,449 INFO:     Epoch: 8
2023-01-04 02:40:30,064 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41661560734113057, 'Total loss': 0.41661560734113057} | train loss {'Reaction outcome loss': 0.39638055808356276, 'Total loss': 0.39638055808356276}
2023-01-04 02:40:30,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:30,064 INFO:     Epoch: 9
2023-01-04 02:40:31,654 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40737907191117606, 'Total loss': 0.40737907191117606} | train loss {'Reaction outcome loss': 0.3938077277895333, 'Total loss': 0.3938077277895333}
2023-01-04 02:40:31,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:31,655 INFO:     Epoch: 10
2023-01-04 02:40:33,282 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3841743419567744, 'Total loss': 0.3841743419567744} | train loss {'Reaction outcome loss': 0.3803449384007684, 'Total loss': 0.3803449384007684}
2023-01-04 02:40:33,283 INFO:     Found new best model at epoch 10
2023-01-04 02:40:33,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:33,283 INFO:     Epoch: 11
2023-01-04 02:40:34,863 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4031742413838704, 'Total loss': 0.4031742413838704} | train loss {'Reaction outcome loss': 0.36656290803111385, 'Total loss': 0.36656290803111385}
2023-01-04 02:40:34,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:34,863 INFO:     Epoch: 12
2023-01-04 02:40:36,455 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3883924822012583, 'Total loss': 0.3883924822012583} | train loss {'Reaction outcome loss': 0.3588864034568162, 'Total loss': 0.3588864034568162}
2023-01-04 02:40:36,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:36,455 INFO:     Epoch: 13
2023-01-04 02:40:38,088 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3987934947013855, 'Total loss': 0.3987934947013855} | train loss {'Reaction outcome loss': 0.3521851028005282, 'Total loss': 0.3521851028005282}
2023-01-04 02:40:38,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:38,088 INFO:     Epoch: 14
2023-01-04 02:40:39,689 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38982558945814766, 'Total loss': 0.38982558945814766} | train loss {'Reaction outcome loss': 0.346922028593827, 'Total loss': 0.346922028593827}
2023-01-04 02:40:39,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:39,689 INFO:     Epoch: 15
2023-01-04 02:40:41,321 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3814026792844137, 'Total loss': 0.3814026792844137} | train loss {'Reaction outcome loss': 0.34086516256565635, 'Total loss': 0.34086516256565635}
2023-01-04 02:40:41,322 INFO:     Found new best model at epoch 15
2023-01-04 02:40:41,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:41,323 INFO:     Epoch: 16
2023-01-04 02:40:42,919 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38433002630869545, 'Total loss': 0.38433002630869545} | train loss {'Reaction outcome loss': 0.34238912197558774, 'Total loss': 0.34238912197558774}
2023-01-04 02:40:42,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:42,919 INFO:     Epoch: 17
2023-01-04 02:40:44,506 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3755659878253937, 'Total loss': 0.3755659878253937} | train loss {'Reaction outcome loss': 0.3362249963903341, 'Total loss': 0.3362249963903341}
2023-01-04 02:40:44,506 INFO:     Found new best model at epoch 17
2023-01-04 02:40:44,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:44,507 INFO:     Epoch: 18
2023-01-04 02:40:46,093 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39919668634732564, 'Total loss': 0.39919668634732564} | train loss {'Reaction outcome loss': 0.32968928022192034, 'Total loss': 0.32968928022192034}
2023-01-04 02:40:46,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:46,093 INFO:     Epoch: 19
2023-01-04 02:40:47,723 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.370835742354393, 'Total loss': 0.370835742354393} | train loss {'Reaction outcome loss': 0.31527956116242684, 'Total loss': 0.31527956116242684}
2023-01-04 02:40:47,723 INFO:     Found new best model at epoch 19
2023-01-04 02:40:47,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:47,724 INFO:     Epoch: 20
2023-01-04 02:40:49,297 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38891395727793376, 'Total loss': 0.38891395727793376} | train loss {'Reaction outcome loss': 0.3109169473561675, 'Total loss': 0.3109169473561675}
2023-01-04 02:40:49,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:49,297 INFO:     Epoch: 21
2023-01-04 02:40:50,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3633882462978363, 'Total loss': 0.3633882462978363} | train loss {'Reaction outcome loss': 0.3091176806863033, 'Total loss': 0.3091176806863033}
2023-01-04 02:40:50,910 INFO:     Found new best model at epoch 21
2023-01-04 02:40:50,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:50,911 INFO:     Epoch: 22
2023-01-04 02:40:52,538 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.377202308177948, 'Total loss': 0.377202308177948} | train loss {'Reaction outcome loss': 0.2999624770735323, 'Total loss': 0.2999624770735323}
2023-01-04 02:40:52,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:52,539 INFO:     Epoch: 23
2023-01-04 02:40:54,127 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3679700324932734, 'Total loss': 0.3679700324932734} | train loss {'Reaction outcome loss': 0.2970144963769269, 'Total loss': 0.2970144963769269}
2023-01-04 02:40:54,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:54,128 INFO:     Epoch: 24
2023-01-04 02:40:55,746 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3627499848604202, 'Total loss': 0.3627499848604202} | train loss {'Reaction outcome loss': 0.2932621744744804, 'Total loss': 0.2932621744744804}
2023-01-04 02:40:55,746 INFO:     Found new best model at epoch 24
2023-01-04 02:40:55,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:55,747 INFO:     Epoch: 25
2023-01-04 02:40:57,315 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38208623925844826, 'Total loss': 0.38208623925844826} | train loss {'Reaction outcome loss': 0.28837057927866344, 'Total loss': 0.28837057927866344}
2023-01-04 02:40:57,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:57,315 INFO:     Epoch: 26
2023-01-04 02:40:58,905 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3961068570613861, 'Total loss': 0.3961068570613861} | train loss {'Reaction outcome loss': 0.2837332682819038, 'Total loss': 0.2837332682819038}
2023-01-04 02:40:58,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:40:58,906 INFO:     Epoch: 27
2023-01-04 02:41:00,500 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.369826532403628, 'Total loss': 0.369826532403628} | train loss {'Reaction outcome loss': 0.28114796099860384, 'Total loss': 0.28114796099860384}
2023-01-04 02:41:00,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:00,500 INFO:     Epoch: 28
2023-01-04 02:41:02,103 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3814757168292999, 'Total loss': 0.3814757168292999} | train loss {'Reaction outcome loss': 0.275857271761566, 'Total loss': 0.275857271761566}
2023-01-04 02:41:02,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:02,103 INFO:     Epoch: 29
2023-01-04 02:41:03,734 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38214260737101235, 'Total loss': 0.38214260737101235} | train loss {'Reaction outcome loss': 0.27767757958605527, 'Total loss': 0.27767757958605527}
2023-01-04 02:41:03,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:03,734 INFO:     Epoch: 30
2023-01-04 02:41:05,338 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36655795673529307, 'Total loss': 0.36655795673529307} | train loss {'Reaction outcome loss': 0.26850830546269816, 'Total loss': 0.26850830546269816}
2023-01-04 02:41:05,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:05,338 INFO:     Epoch: 31
2023-01-04 02:41:06,915 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3741132746140162, 'Total loss': 0.3741132746140162} | train loss {'Reaction outcome loss': 0.2659228323209918, 'Total loss': 0.2659228323209918}
2023-01-04 02:41:06,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:06,916 INFO:     Epoch: 32
2023-01-04 02:41:08,513 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3889243414004644, 'Total loss': 0.3889243414004644} | train loss {'Reaction outcome loss': 0.2645825153432678, 'Total loss': 0.2645825153432678}
2023-01-04 02:41:08,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:08,513 INFO:     Epoch: 33
2023-01-04 02:41:10,142 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3812907616297404, 'Total loss': 0.3812907616297404} | train loss {'Reaction outcome loss': 0.25842175633390096, 'Total loss': 0.25842175633390096}
2023-01-04 02:41:10,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:10,143 INFO:     Epoch: 34
2023-01-04 02:41:11,735 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3821756213903427, 'Total loss': 0.3821756213903427} | train loss {'Reaction outcome loss': 0.2575417490893612, 'Total loss': 0.2575417490893612}
2023-01-04 02:41:11,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:11,736 INFO:     Epoch: 35
2023-01-04 02:41:13,349 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37186416884263357, 'Total loss': 0.37186416884263357} | train loss {'Reaction outcome loss': 0.25329389515251893, 'Total loss': 0.25329389515251893}
2023-01-04 02:41:13,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:13,349 INFO:     Epoch: 36
2023-01-04 02:41:14,970 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39770158429940544, 'Total loss': 0.39770158429940544} | train loss {'Reaction outcome loss': 0.25270220839782903, 'Total loss': 0.25270220839782903}
2023-01-04 02:41:14,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:14,970 INFO:     Epoch: 37
2023-01-04 02:41:16,554 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4110465238491694, 'Total loss': 0.4110465238491694} | train loss {'Reaction outcome loss': 0.2529054753570075, 'Total loss': 0.2529054753570075}
2023-01-04 02:41:16,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:16,554 INFO:     Epoch: 38
2023-01-04 02:41:18,191 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39790006577968595, 'Total loss': 0.39790006577968595} | train loss {'Reaction outcome loss': 0.24532107387494761, 'Total loss': 0.24532107387494761}
2023-01-04 02:41:18,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:18,191 INFO:     Epoch: 39
2023-01-04 02:41:19,818 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3825282206137975, 'Total loss': 0.3825282206137975} | train loss {'Reaction outcome loss': 0.24138348733802137, 'Total loss': 0.24138348733802137}
2023-01-04 02:41:19,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:19,818 INFO:     Epoch: 40
2023-01-04 02:41:21,427 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37431551814079284, 'Total loss': 0.37431551814079284} | train loss {'Reaction outcome loss': 0.24043239262613023, 'Total loss': 0.24043239262613023}
2023-01-04 02:41:21,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:21,428 INFO:     Epoch: 41
2023-01-04 02:41:23,055 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3924607545137405, 'Total loss': 0.3924607545137405} | train loss {'Reaction outcome loss': 0.238406535912899, 'Total loss': 0.238406535912899}
2023-01-04 02:41:23,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:23,056 INFO:     Epoch: 42
2023-01-04 02:41:24,657 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.385838316877683, 'Total loss': 0.385838316877683} | train loss {'Reaction outcome loss': 0.24049270860310915, 'Total loss': 0.24049270860310915}
2023-01-04 02:41:24,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:24,658 INFO:     Epoch: 43
2023-01-04 02:41:26,274 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3930786639451981, 'Total loss': 0.3930786639451981} | train loss {'Reaction outcome loss': 0.2333039446574981, 'Total loss': 0.2333039446574981}
2023-01-04 02:41:26,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:26,274 INFO:     Epoch: 44
2023-01-04 02:41:27,903 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37733696699142455, 'Total loss': 0.37733696699142455} | train loss {'Reaction outcome loss': 0.23067682704793802, 'Total loss': 0.23067682704793802}
2023-01-04 02:41:27,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:27,903 INFO:     Epoch: 45
2023-01-04 02:41:29,473 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38892231583595277, 'Total loss': 0.38892231583595277} | train loss {'Reaction outcome loss': 0.22821548758783256, 'Total loss': 0.22821548758783256}
2023-01-04 02:41:29,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:29,474 INFO:     Epoch: 46
2023-01-04 02:41:31,088 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4080373386542002, 'Total loss': 0.4080373386542002} | train loss {'Reaction outcome loss': 0.22860061933921394, 'Total loss': 0.22860061933921394}
2023-01-04 02:41:31,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:31,088 INFO:     Epoch: 47
2023-01-04 02:41:32,716 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.387995013097922, 'Total loss': 0.387995013097922} | train loss {'Reaction outcome loss': 0.22605366956123688, 'Total loss': 0.22605366956123688}
2023-01-04 02:41:32,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:32,717 INFO:     Epoch: 48
2023-01-04 02:41:34,303 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38852670465906464, 'Total loss': 0.38852670465906464} | train loss {'Reaction outcome loss': 0.22250431930550132, 'Total loss': 0.22250431930550132}
2023-01-04 02:41:34,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:34,303 INFO:     Epoch: 49
2023-01-04 02:41:35,896 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40808433294296265, 'Total loss': 0.40808433294296265} | train loss {'Reaction outcome loss': 0.2217210449415016, 'Total loss': 0.2217210449415016}
2023-01-04 02:41:35,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:35,896 INFO:     Epoch: 50
2023-01-04 02:41:37,490 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41325996816158295, 'Total loss': 0.41325996816158295} | train loss {'Reaction outcome loss': 0.21924358160332844, 'Total loss': 0.21924358160332844}
2023-01-04 02:41:37,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:37,490 INFO:     Epoch: 51
2023-01-04 02:41:39,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4024687031904856, 'Total loss': 0.4024687031904856} | train loss {'Reaction outcome loss': 0.21746278560781124, 'Total loss': 0.21746278560781124}
2023-01-04 02:41:39,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:39,063 INFO:     Epoch: 52
2023-01-04 02:41:40,655 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3820001035928726, 'Total loss': 0.3820001035928726} | train loss {'Reaction outcome loss': 0.21651243498142678, 'Total loss': 0.21651243498142678}
2023-01-04 02:41:40,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:40,655 INFO:     Epoch: 53
2023-01-04 02:41:42,237 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3842211519678434, 'Total loss': 0.3842211519678434} | train loss {'Reaction outcome loss': 0.21427859571986776, 'Total loss': 0.21427859571986776}
2023-01-04 02:41:42,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:42,238 INFO:     Epoch: 54
2023-01-04 02:41:43,854 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41477832198143005, 'Total loss': 0.41477832198143005} | train loss {'Reaction outcome loss': 0.2147413967396605, 'Total loss': 0.2147413967396605}
2023-01-04 02:41:43,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:43,854 INFO:     Epoch: 55
2023-01-04 02:41:45,471 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39790836175282795, 'Total loss': 0.39790836175282795} | train loss {'Reaction outcome loss': 0.21058571227974648, 'Total loss': 0.21058571227974648}
2023-01-04 02:41:45,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:45,471 INFO:     Epoch: 56
2023-01-04 02:41:47,072 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40975359330574673, 'Total loss': 0.40975359330574673} | train loss {'Reaction outcome loss': 0.20882356110487835, 'Total loss': 0.20882356110487835}
2023-01-04 02:41:47,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:47,073 INFO:     Epoch: 57
2023-01-04 02:41:48,703 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42511515418688456, 'Total loss': 0.42511515418688456} | train loss {'Reaction outcome loss': 0.20657579346974989, 'Total loss': 0.20657579346974989}
2023-01-04 02:41:48,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:48,703 INFO:     Epoch: 58
2023-01-04 02:41:50,322 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4091360668341319, 'Total loss': 0.4091360668341319} | train loss {'Reaction outcome loss': 0.2080458714829191, 'Total loss': 0.2080458714829191}
2023-01-04 02:41:50,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:50,322 INFO:     Epoch: 59
2023-01-04 02:41:51,899 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4231959730386734, 'Total loss': 0.4231959730386734} | train loss {'Reaction outcome loss': 0.21060103070667516, 'Total loss': 0.21060103070667516}
2023-01-04 02:41:51,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:51,900 INFO:     Epoch: 60
2023-01-04 02:41:53,491 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39339005450407666, 'Total loss': 0.39339005450407666} | train loss {'Reaction outcome loss': 0.22000115555778577, 'Total loss': 0.22000115555778577}
2023-01-04 02:41:53,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:53,491 INFO:     Epoch: 61
2023-01-04 02:41:55,124 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41356826623280846, 'Total loss': 0.41356826623280846} | train loss {'Reaction outcome loss': 0.21452837719487539, 'Total loss': 0.21452837719487539}
2023-01-04 02:41:55,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:55,124 INFO:     Epoch: 62
2023-01-04 02:41:56,720 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42643454869588215, 'Total loss': 0.42643454869588215} | train loss {'Reaction outcome loss': 0.2019296922965934, 'Total loss': 0.2019296922965934}
2023-01-04 02:41:56,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:56,721 INFO:     Epoch: 63
2023-01-04 02:41:58,333 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4028538088003794, 'Total loss': 0.4028538088003794} | train loss {'Reaction outcome loss': 0.19845600114322093, 'Total loss': 0.19845600114322093}
2023-01-04 02:41:58,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:58,333 INFO:     Epoch: 64
2023-01-04 02:41:59,952 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41115612387657163, 'Total loss': 0.41115612387657163} | train loss {'Reaction outcome loss': 0.19762307349246575, 'Total loss': 0.19762307349246575}
2023-01-04 02:41:59,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:41:59,954 INFO:     Epoch: 65
2023-01-04 02:42:01,532 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3831028482566277, 'Total loss': 0.3831028482566277} | train loss {'Reaction outcome loss': 0.194301831480529, 'Total loss': 0.194301831480529}
2023-01-04 02:42:01,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:01,533 INFO:     Epoch: 66
2023-01-04 02:42:03,131 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40316561559836067, 'Total loss': 0.40316561559836067} | train loss {'Reaction outcome loss': 0.19343286921683603, 'Total loss': 0.19343286921683603}
2023-01-04 02:42:03,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:03,131 INFO:     Epoch: 67
2023-01-04 02:42:04,724 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4141972998778025, 'Total loss': 0.4141972998778025} | train loss {'Reaction outcome loss': 0.195236224366902, 'Total loss': 0.195236224366902}
2023-01-04 02:42:04,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:04,724 INFO:     Epoch: 68
2023-01-04 02:42:06,321 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44309330185254414, 'Total loss': 0.44309330185254414} | train loss {'Reaction outcome loss': 0.19279337572882377, 'Total loss': 0.19279337572882377}
2023-01-04 02:42:06,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:06,322 INFO:     Epoch: 69
2023-01-04 02:42:07,932 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4311419124404589, 'Total loss': 0.4311419124404589} | train loss {'Reaction outcome loss': 0.19307104677663764, 'Total loss': 0.19307104677663764}
2023-01-04 02:42:07,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:07,932 INFO:     Epoch: 70
2023-01-04 02:42:09,536 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4282320300738017, 'Total loss': 0.4282320300738017} | train loss {'Reaction outcome loss': 0.19537846469472203, 'Total loss': 0.19537846469472203}
2023-01-04 02:42:09,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:09,536 INFO:     Epoch: 71
2023-01-04 02:42:11,132 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43177868326505026, 'Total loss': 0.43177868326505026} | train loss {'Reaction outcome loss': 0.19076639738826393, 'Total loss': 0.19076639738826393}
2023-01-04 02:42:11,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:11,132 INFO:     Epoch: 72
2023-01-04 02:42:12,721 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4257398297389348, 'Total loss': 0.4257398297389348} | train loss {'Reaction outcome loss': 0.18816692225743242, 'Total loss': 0.18816692225743242}
2023-01-04 02:42:12,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:12,722 INFO:     Epoch: 73
2023-01-04 02:42:14,299 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42481897473335267, 'Total loss': 0.42481897473335267} | train loss {'Reaction outcome loss': 0.18803128801688296, 'Total loss': 0.18803128801688296}
2023-01-04 02:42:14,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:14,299 INFO:     Epoch: 74
2023-01-04 02:42:15,922 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41884458661079405, 'Total loss': 0.41884458661079405} | train loss {'Reaction outcome loss': 0.18846654462580825, 'Total loss': 0.18846654462580825}
2023-01-04 02:42:15,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:15,922 INFO:     Epoch: 75
2023-01-04 02:42:17,546 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4497445752223333, 'Total loss': 0.4497445752223333} | train loss {'Reaction outcome loss': 0.18374047964217438, 'Total loss': 0.18374047964217438}
2023-01-04 02:42:17,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:17,546 INFO:     Epoch: 76
2023-01-04 02:42:19,136 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4636232336362203, 'Total loss': 0.4636232336362203} | train loss {'Reaction outcome loss': 0.18505804726442296, 'Total loss': 0.18505804726442296}
2023-01-04 02:42:19,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:19,137 INFO:     Epoch: 77
2023-01-04 02:42:20,729 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44789336423079174, 'Total loss': 0.44789336423079174} | train loss {'Reaction outcome loss': 0.1842838180207342, 'Total loss': 0.1842838180207342}
2023-01-04 02:42:20,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:20,730 INFO:     Epoch: 78
2023-01-04 02:42:22,321 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44672249754269916, 'Total loss': 0.44672249754269916} | train loss {'Reaction outcome loss': 0.18349416684862302, 'Total loss': 0.18349416684862302}
2023-01-04 02:42:22,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:22,321 INFO:     Epoch: 79
2023-01-04 02:42:23,910 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4285842299461365, 'Total loss': 0.4285842299461365} | train loss {'Reaction outcome loss': 0.1843440841977903, 'Total loss': 0.1843440841977903}
2023-01-04 02:42:23,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:23,910 INFO:     Epoch: 80
2023-01-04 02:42:25,538 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44335997303326924, 'Total loss': 0.44335997303326924} | train loss {'Reaction outcome loss': 0.1812020000677718, 'Total loss': 0.1812020000677718}
2023-01-04 02:42:25,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:25,538 INFO:     Epoch: 81
2023-01-04 02:42:27,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45595113734404247, 'Total loss': 0.45595113734404247} | train loss {'Reaction outcome loss': 0.18056258205172565, 'Total loss': 0.18056258205172565}
2023-01-04 02:42:27,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:27,139 INFO:     Epoch: 82
2023-01-04 02:42:28,723 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4368429536620776, 'Total loss': 0.4368429536620776} | train loss {'Reaction outcome loss': 0.17997616076963427, 'Total loss': 0.17997616076963427}
2023-01-04 02:42:28,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:28,723 INFO:     Epoch: 83
2023-01-04 02:42:30,315 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42541133711735407, 'Total loss': 0.42541133711735407} | train loss {'Reaction outcome loss': 0.1781514150525386, 'Total loss': 0.1781514150525386}
2023-01-04 02:42:30,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:30,316 INFO:     Epoch: 84
2023-01-04 02:42:31,897 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44082292119661964, 'Total loss': 0.44082292119661964} | train loss {'Reaction outcome loss': 0.17713662469843944, 'Total loss': 0.17713662469843944}
2023-01-04 02:42:31,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:31,898 INFO:     Epoch: 85
2023-01-04 02:42:33,526 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45363665123780567, 'Total loss': 0.45363665123780567} | train loss {'Reaction outcome loss': 0.18734829289757687, 'Total loss': 0.18734829289757687}
2023-01-04 02:42:33,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:33,527 INFO:     Epoch: 86
2023-01-04 02:42:35,153 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42705260614554086, 'Total loss': 0.42705260614554086} | train loss {'Reaction outcome loss': 0.19796112980828554, 'Total loss': 0.19796112980828554}
2023-01-04 02:42:35,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:35,155 INFO:     Epoch: 87
2023-01-04 02:42:36,737 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4357063929239909, 'Total loss': 0.4357063929239909} | train loss {'Reaction outcome loss': 0.17535677133549843, 'Total loss': 0.17535677133549843}
2023-01-04 02:42:36,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:36,738 INFO:     Epoch: 88
2023-01-04 02:42:38,364 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4356363818049431, 'Total loss': 0.4356363818049431} | train loss {'Reaction outcome loss': 0.17407248812294024, 'Total loss': 0.17407248812294024}
2023-01-04 02:42:38,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:38,364 INFO:     Epoch: 89
2023-01-04 02:42:39,991 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4451585590839386, 'Total loss': 0.4451585590839386} | train loss {'Reaction outcome loss': 0.1720163509303743, 'Total loss': 0.1720163509303743}
2023-01-04 02:42:39,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:39,991 INFO:     Epoch: 90
2023-01-04 02:42:41,608 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42781410614649457, 'Total loss': 0.42781410614649457} | train loss {'Reaction outcome loss': 0.179191453308137, 'Total loss': 0.179191453308137}
2023-01-04 02:42:41,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:41,609 INFO:     Epoch: 91
2023-01-04 02:42:43,197 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4676326404015223, 'Total loss': 0.4676326404015223} | train loss {'Reaction outcome loss': 0.18427286572599164, 'Total loss': 0.18427286572599164}
2023-01-04 02:42:43,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:43,197 INFO:     Epoch: 92
2023-01-04 02:42:44,834 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42412384748458865, 'Total loss': 0.42412384748458865} | train loss {'Reaction outcome loss': 0.1727610035585172, 'Total loss': 0.1727610035585172}
2023-01-04 02:42:44,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:44,834 INFO:     Epoch: 93
2023-01-04 02:42:46,451 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4530243754386902, 'Total loss': 0.4530243754386902} | train loss {'Reaction outcome loss': 0.17427991432081055, 'Total loss': 0.17427991432081055}
2023-01-04 02:42:46,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:46,451 INFO:     Epoch: 94
2023-01-04 02:42:48,087 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45401678085327146, 'Total loss': 0.45401678085327146} | train loss {'Reaction outcome loss': 0.1726962500859214, 'Total loss': 0.1726962500859214}
2023-01-04 02:42:48,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:48,087 INFO:     Epoch: 95
2023-01-04 02:42:49,716 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4280565987030665, 'Total loss': 0.4280565987030665} | train loss {'Reaction outcome loss': 0.17134648774399597, 'Total loss': 0.17134648774399597}
2023-01-04 02:42:49,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:49,716 INFO:     Epoch: 96
2023-01-04 02:42:51,303 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4423710236946742, 'Total loss': 0.4423710236946742} | train loss {'Reaction outcome loss': 0.1773808457200294, 'Total loss': 0.1773808457200294}
2023-01-04 02:42:51,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:51,303 INFO:     Epoch: 97
2023-01-04 02:42:52,945 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47137249608834586, 'Total loss': 0.47137249608834586} | train loss {'Reaction outcome loss': 0.18309548498760653, 'Total loss': 0.18309548498760653}
2023-01-04 02:42:52,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:52,945 INFO:     Epoch: 98
2023-01-04 02:42:54,554 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4289236197868983, 'Total loss': 0.4289236197868983} | train loss {'Reaction outcome loss': 0.17185299891971753, 'Total loss': 0.17185299891971753}
2023-01-04 02:42:54,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:54,555 INFO:     Epoch: 99
2023-01-04 02:42:56,149 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4192515343427658, 'Total loss': 0.4192515343427658} | train loss {'Reaction outcome loss': 0.17061079383247357, 'Total loss': 0.17061079383247357}
2023-01-04 02:42:56,149 INFO:     Best model found after epoch 25 of 100.
2023-01-04 02:42:56,149 INFO:   Done with stage: TRAINING
2023-01-04 02:42:56,150 INFO:   Starting stage: EVALUATION
2023-01-04 02:42:56,276 INFO:   Done with stage: EVALUATION
2023-01-04 02:42:56,277 INFO:   Leaving out SEQ value Fold_5
2023-01-04 02:42:56,289 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:42:56,289 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:42:56,955 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:42:56,955 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:42:57,024 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:42:57,024 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:42:57,024 INFO:     No hyperparam tuning for this model
2023-01-04 02:42:57,025 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:42:57,025 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:42:57,025 INFO:     None feature selector for col prot
2023-01-04 02:42:57,026 INFO:     None feature selector for col prot
2023-01-04 02:42:57,026 INFO:     None feature selector for col prot
2023-01-04 02:42:57,026 INFO:     None feature selector for col chem
2023-01-04 02:42:57,026 INFO:     None feature selector for col chem
2023-01-04 02:42:57,026 INFO:     None feature selector for col chem
2023-01-04 02:42:57,027 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:42:57,027 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:42:57,028 INFO:     Number of params in model 70141
2023-01-04 02:42:57,031 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:42:57,031 INFO:   Starting stage: TRAINING
2023-01-04 02:42:57,077 INFO:     Val loss before train {'Reaction outcome loss': 1.0411803503831227, 'Total loss': 1.0411803503831227}
2023-01-04 02:42:57,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:57,077 INFO:     Epoch: 0
2023-01-04 02:42:58,663 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6108684857686361, 'Total loss': 0.6108684857686361} | train loss {'Reaction outcome loss': 0.848107352528883, 'Total loss': 0.848107352528883}
2023-01-04 02:42:58,663 INFO:     Found new best model at epoch 0
2023-01-04 02:42:58,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:42:58,664 INFO:     Epoch: 1
2023-01-04 02:43:00,274 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.494909797112147, 'Total loss': 0.494909797112147} | train loss {'Reaction outcome loss': 0.5976550207621809, 'Total loss': 0.5976550207621809}
2023-01-04 02:43:00,274 INFO:     Found new best model at epoch 1
2023-01-04 02:43:00,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:00,275 INFO:     Epoch: 2
2023-01-04 02:43:01,866 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46624817649523415, 'Total loss': 0.46624817649523415} | train loss {'Reaction outcome loss': 0.5243159305790196, 'Total loss': 0.5243159305790196}
2023-01-04 02:43:01,866 INFO:     Found new best model at epoch 2
2023-01-04 02:43:01,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:01,867 INFO:     Epoch: 3
2023-01-04 02:43:03,452 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4728877385457357, 'Total loss': 0.4728877385457357} | train loss {'Reaction outcome loss': 0.48620636848246923, 'Total loss': 0.48620636848246923}
2023-01-04 02:43:03,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:03,453 INFO:     Epoch: 4
2023-01-04 02:43:05,045 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4122676392396291, 'Total loss': 0.4122676392396291} | train loss {'Reaction outcome loss': 0.4581380266581487, 'Total loss': 0.4581380266581487}
2023-01-04 02:43:05,045 INFO:     Found new best model at epoch 4
2023-01-04 02:43:05,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:05,046 INFO:     Epoch: 5
2023-01-04 02:43:06,640 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42231495877106984, 'Total loss': 0.42231495877106984} | train loss {'Reaction outcome loss': 0.4521811745952869, 'Total loss': 0.4521811745952869}
2023-01-04 02:43:06,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:06,641 INFO:     Epoch: 6
2023-01-04 02:43:08,220 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4069196701049805, 'Total loss': 0.4069196701049805} | train loss {'Reaction outcome loss': 0.4238973031110684, 'Total loss': 0.4238973031110684}
2023-01-04 02:43:08,220 INFO:     Found new best model at epoch 6
2023-01-04 02:43:08,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:08,221 INFO:     Epoch: 7
2023-01-04 02:43:09,830 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40118330518404643, 'Total loss': 0.40118330518404643} | train loss {'Reaction outcome loss': 0.40990254868739756, 'Total loss': 0.40990254868739756}
2023-01-04 02:43:09,830 INFO:     Found new best model at epoch 7
2023-01-04 02:43:09,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:09,831 INFO:     Epoch: 8
2023-01-04 02:43:11,436 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3857379466295242, 'Total loss': 0.3857379466295242} | train loss {'Reaction outcome loss': 0.3986854172865118, 'Total loss': 0.3986854172865118}
2023-01-04 02:43:11,436 INFO:     Found new best model at epoch 8
2023-01-04 02:43:11,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:11,437 INFO:     Epoch: 9
2023-01-04 02:43:13,020 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38357214132944745, 'Total loss': 0.38357214132944745} | train loss {'Reaction outcome loss': 0.38381854547153943, 'Total loss': 0.38381854547153943}
2023-01-04 02:43:13,021 INFO:     Found new best model at epoch 9
2023-01-04 02:43:13,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:13,022 INFO:     Epoch: 10
2023-01-04 02:43:14,622 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3933315674463908, 'Total loss': 0.3933315674463908} | train loss {'Reaction outcome loss': 0.37612223499741376, 'Total loss': 0.37612223499741376}
2023-01-04 02:43:14,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:14,623 INFO:     Epoch: 11
2023-01-04 02:43:16,247 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3721612423658371, 'Total loss': 0.3721612423658371} | train loss {'Reaction outcome loss': 0.3693180626825146, 'Total loss': 0.3693180626825146}
2023-01-04 02:43:16,247 INFO:     Found new best model at epoch 11
2023-01-04 02:43:16,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:16,248 INFO:     Epoch: 12
2023-01-04 02:43:17,829 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3877553621927897, 'Total loss': 0.3877553621927897} | train loss {'Reaction outcome loss': 0.3617555541222564, 'Total loss': 0.3617555541222564}
2023-01-04 02:43:17,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:17,829 INFO:     Epoch: 13
2023-01-04 02:43:19,459 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3788750251134237, 'Total loss': 0.3788750251134237} | train loss {'Reaction outcome loss': 0.36709702292970126, 'Total loss': 0.36709702292970126}
2023-01-04 02:43:19,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:19,459 INFO:     Epoch: 14
2023-01-04 02:43:21,069 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40192149877548217, 'Total loss': 0.40192149877548217} | train loss {'Reaction outcome loss': 0.3563067898478197, 'Total loss': 0.3563067898478197}
2023-01-04 02:43:21,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:21,070 INFO:     Epoch: 15
2023-01-04 02:43:22,693 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.394559105237325, 'Total loss': 0.394559105237325} | train loss {'Reaction outcome loss': 0.3470299659369419, 'Total loss': 0.3470299659369419}
2023-01-04 02:43:22,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:22,694 INFO:     Epoch: 16
2023-01-04 02:43:24,321 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37590655783812205, 'Total loss': 0.37590655783812205} | train loss {'Reaction outcome loss': 0.3339147740743879, 'Total loss': 0.3339147740743879}
2023-01-04 02:43:24,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:24,322 INFO:     Epoch: 17
2023-01-04 02:43:25,924 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3868806471427282, 'Total loss': 0.3868806471427282} | train loss {'Reaction outcome loss': 0.3259804436694021, 'Total loss': 0.3259804436694021}
2023-01-04 02:43:25,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:25,925 INFO:     Epoch: 18
2023-01-04 02:43:27,514 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38749547898769376, 'Total loss': 0.38749547898769376} | train loss {'Reaction outcome loss': 0.3242238030863413, 'Total loss': 0.3242238030863413}
2023-01-04 02:43:27,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:27,514 INFO:     Epoch: 19
2023-01-04 02:43:29,111 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37603457272052765, 'Total loss': 0.37603457272052765} | train loss {'Reaction outcome loss': 0.3187487809024616, 'Total loss': 0.3187487809024616}
2023-01-04 02:43:29,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:29,111 INFO:     Epoch: 20
2023-01-04 02:43:30,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37833149135112765, 'Total loss': 0.37833149135112765} | train loss {'Reaction outcome loss': 0.3142319828055907, 'Total loss': 0.3142319828055907}
2023-01-04 02:43:30,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:30,692 INFO:     Epoch: 21
2023-01-04 02:43:32,304 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3556576391061147, 'Total loss': 0.3556576391061147} | train loss {'Reaction outcome loss': 0.31486117067760316, 'Total loss': 0.31486117067760316}
2023-01-04 02:43:32,304 INFO:     Found new best model at epoch 21
2023-01-04 02:43:32,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:32,305 INFO:     Epoch: 22
2023-01-04 02:43:33,887 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3761629372835159, 'Total loss': 0.3761629372835159} | train loss {'Reaction outcome loss': 0.30908923223662144, 'Total loss': 0.30908923223662144}
2023-01-04 02:43:33,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:33,887 INFO:     Epoch: 23
2023-01-04 02:43:35,485 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3829688976208369, 'Total loss': 0.3829688976208369} | train loss {'Reaction outcome loss': 0.2985908074248152, 'Total loss': 0.2985908074248152}
2023-01-04 02:43:35,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:35,486 INFO:     Epoch: 24
2023-01-04 02:43:37,101 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38185875515143075, 'Total loss': 0.38185875515143075} | train loss {'Reaction outcome loss': 0.29399932226490066, 'Total loss': 0.29399932226490066}
2023-01-04 02:43:37,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:37,101 INFO:     Epoch: 25
2023-01-04 02:43:38,729 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3585827519496282, 'Total loss': 0.3585827519496282} | train loss {'Reaction outcome loss': 0.2900147153456034, 'Total loss': 0.2900147153456034}
2023-01-04 02:43:38,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:38,729 INFO:     Epoch: 26
2023-01-04 02:43:40,320 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.375822484989961, 'Total loss': 0.375822484989961} | train loss {'Reaction outcome loss': 0.28895401174246427, 'Total loss': 0.28895401174246427}
2023-01-04 02:43:40,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:40,320 INFO:     Epoch: 27
2023-01-04 02:43:41,952 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36808922787507375, 'Total loss': 0.36808922787507375} | train loss {'Reaction outcome loss': 0.2855586102907208, 'Total loss': 0.2855586102907208}
2023-01-04 02:43:41,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:41,953 INFO:     Epoch: 28
2023-01-04 02:43:43,564 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.34642331500848134, 'Total loss': 0.34642331500848134} | train loss {'Reaction outcome loss': 0.2893511418934803, 'Total loss': 0.2893511418934803}
2023-01-04 02:43:43,564 INFO:     Found new best model at epoch 28
2023-01-04 02:43:43,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:43,565 INFO:     Epoch: 29
2023-01-04 02:43:45,154 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3649111996094386, 'Total loss': 0.3649111996094386} | train loss {'Reaction outcome loss': 0.27686479019568017, 'Total loss': 0.27686479019568017}
2023-01-04 02:43:45,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:45,155 INFO:     Epoch: 30
2023-01-04 02:43:46,767 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3755261162916819, 'Total loss': 0.3755261162916819} | train loss {'Reaction outcome loss': 0.2730713343868653, 'Total loss': 0.2730713343868653}
2023-01-04 02:43:46,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:46,767 INFO:     Epoch: 31
2023-01-04 02:43:48,372 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3774646540482839, 'Total loss': 0.3774646540482839} | train loss {'Reaction outcome loss': 0.2726745518231073, 'Total loss': 0.2726745518231073}
2023-01-04 02:43:48,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:48,373 INFO:     Epoch: 32
2023-01-04 02:43:49,996 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3715404053529104, 'Total loss': 0.3715404053529104} | train loss {'Reaction outcome loss': 0.265918735023318, 'Total loss': 0.265918735023318}
2023-01-04 02:43:49,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:49,996 INFO:     Epoch: 33
2023-01-04 02:43:51,619 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3840916688243548, 'Total loss': 0.3840916688243548} | train loss {'Reaction outcome loss': 0.26341464937718556, 'Total loss': 0.26341464937718556}
2023-01-04 02:43:51,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:51,620 INFO:     Epoch: 34
2023-01-04 02:43:53,221 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3748173495133718, 'Total loss': 0.3748173495133718} | train loss {'Reaction outcome loss': 0.26190348982514033, 'Total loss': 0.26190348982514033}
2023-01-04 02:43:53,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:53,222 INFO:     Epoch: 35
2023-01-04 02:43:54,839 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36664601465066277, 'Total loss': 0.36664601465066277} | train loss {'Reaction outcome loss': 0.2572657012556126, 'Total loss': 0.2572657012556126}
2023-01-04 02:43:54,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:54,839 INFO:     Epoch: 36
2023-01-04 02:43:56,463 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3604507327079773, 'Total loss': 0.3604507327079773} | train loss {'Reaction outcome loss': 0.25598612675141497, 'Total loss': 0.25598612675141497}
2023-01-04 02:43:56,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:56,463 INFO:     Epoch: 37
2023-01-04 02:43:58,067 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37729011476039886, 'Total loss': 0.37729011476039886} | train loss {'Reaction outcome loss': 0.25446660816669464, 'Total loss': 0.25446660816669464}
2023-01-04 02:43:58,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:58,067 INFO:     Epoch: 38
2023-01-04 02:43:59,691 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34390040834744773, 'Total loss': 0.34390040834744773} | train loss {'Reaction outcome loss': 0.25342931869193347, 'Total loss': 0.25342931869193347}
2023-01-04 02:43:59,691 INFO:     Found new best model at epoch 38
2023-01-04 02:43:59,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:43:59,692 INFO:     Epoch: 39
2023-01-04 02:44:01,321 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3682784140110016, 'Total loss': 0.3682784140110016} | train loss {'Reaction outcome loss': 0.24510240464545516, 'Total loss': 0.24510240464545516}
2023-01-04 02:44:01,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:01,322 INFO:     Epoch: 40
2023-01-04 02:44:02,902 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3818652401367823, 'Total loss': 0.3818652401367823} | train loss {'Reaction outcome loss': 0.24619135281502985, 'Total loss': 0.24619135281502985}
2023-01-04 02:44:02,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:02,902 INFO:     Epoch: 41
2023-01-04 02:44:04,500 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38019504646460217, 'Total loss': 0.38019504646460217} | train loss {'Reaction outcome loss': 0.2433837833485323, 'Total loss': 0.2433837833485323}
2023-01-04 02:44:04,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:04,501 INFO:     Epoch: 42
2023-01-04 02:44:06,090 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37342703839143115, 'Total loss': 0.37342703839143115} | train loss {'Reaction outcome loss': 0.26547421382713143, 'Total loss': 0.26547421382713143}
2023-01-04 02:44:06,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:06,090 INFO:     Epoch: 43
2023-01-04 02:44:07,678 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35115969777107237, 'Total loss': 0.35115969777107237} | train loss {'Reaction outcome loss': 0.23716412055258895, 'Total loss': 0.23716412055258895}
2023-01-04 02:44:07,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:07,678 INFO:     Epoch: 44
2023-01-04 02:44:09,277 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35544318755467735, 'Total loss': 0.35544318755467735} | train loss {'Reaction outcome loss': 0.234613258732007, 'Total loss': 0.234613258732007}
2023-01-04 02:44:09,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:09,277 INFO:     Epoch: 45
2023-01-04 02:44:10,857 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4008271485567093, 'Total loss': 0.4008271485567093} | train loss {'Reaction outcome loss': 0.23429151197922402, 'Total loss': 0.23429151197922402}
2023-01-04 02:44:10,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:10,858 INFO:     Epoch: 46
2023-01-04 02:44:12,452 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3859788497289022, 'Total loss': 0.3859788497289022} | train loss {'Reaction outcome loss': 0.23504083525335442, 'Total loss': 0.23504083525335442}
2023-01-04 02:44:12,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:12,453 INFO:     Epoch: 47
2023-01-04 02:44:14,046 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36118969122568767, 'Total loss': 0.36118969122568767} | train loss {'Reaction outcome loss': 0.23095576146854158, 'Total loss': 0.23095576146854158}
2023-01-04 02:44:14,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:14,046 INFO:     Epoch: 48
2023-01-04 02:44:15,642 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3580834329128265, 'Total loss': 0.3580834329128265} | train loss {'Reaction outcome loss': 0.227929525549753, 'Total loss': 0.227929525549753}
2023-01-04 02:44:15,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:15,643 INFO:     Epoch: 49
2023-01-04 02:44:17,266 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36129773358503975, 'Total loss': 0.36129773358503975} | train loss {'Reaction outcome loss': 0.22578387905652061, 'Total loss': 0.22578387905652061}
2023-01-04 02:44:17,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:17,266 INFO:     Epoch: 50
2023-01-04 02:44:18,902 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39612374901771547, 'Total loss': 0.39612374901771547} | train loss {'Reaction outcome loss': 0.22375646063491053, 'Total loss': 0.22375646063491053}
2023-01-04 02:44:18,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:18,903 INFO:     Epoch: 51
2023-01-04 02:44:20,499 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36345605850219725, 'Total loss': 0.36345605850219725} | train loss {'Reaction outcome loss': 0.2329350673067181, 'Total loss': 0.2329350673067181}
2023-01-04 02:44:20,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:20,499 INFO:     Epoch: 52
2023-01-04 02:44:22,094 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35879217584927875, 'Total loss': 0.35879217584927875} | train loss {'Reaction outcome loss': 0.23867775940511754, 'Total loss': 0.23867775940511754}
2023-01-04 02:44:22,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:22,094 INFO:     Epoch: 53
2023-01-04 02:44:23,719 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35408512155214944, 'Total loss': 0.35408512155214944} | train loss {'Reaction outcome loss': 0.21771526402638605, 'Total loss': 0.21771526402638605}
2023-01-04 02:44:23,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:23,719 INFO:     Epoch: 54
2023-01-04 02:44:25,307 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3888435810804367, 'Total loss': 0.3888435810804367} | train loss {'Reaction outcome loss': 0.21436487950299837, 'Total loss': 0.21436487950299837}
2023-01-04 02:44:25,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:25,307 INFO:     Epoch: 55
2023-01-04 02:44:26,906 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35084041257699333, 'Total loss': 0.35084041257699333} | train loss {'Reaction outcome loss': 0.2157685747910021, 'Total loss': 0.2157685747910021}
2023-01-04 02:44:26,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:26,906 INFO:     Epoch: 56
2023-01-04 02:44:28,501 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37764526208241783, 'Total loss': 0.37764526208241783} | train loss {'Reaction outcome loss': 0.2163530986830322, 'Total loss': 0.2163530986830322}
2023-01-04 02:44:28,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:28,501 INFO:     Epoch: 57
2023-01-04 02:44:30,099 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3729366491238276, 'Total loss': 0.3729366491238276} | train loss {'Reaction outcome loss': 0.2100409368671324, 'Total loss': 0.2100409368671324}
2023-01-04 02:44:30,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:30,100 INFO:     Epoch: 58
2023-01-04 02:44:31,706 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3600242674350739, 'Total loss': 0.3600242674350739} | train loss {'Reaction outcome loss': 0.21001827294578002, 'Total loss': 0.21001827294578002}
2023-01-04 02:44:31,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:31,707 INFO:     Epoch: 59
2023-01-04 02:44:33,296 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3521905918916067, 'Total loss': 0.3521905918916067} | train loss {'Reaction outcome loss': 0.21394181599759537, 'Total loss': 0.21394181599759537}
2023-01-04 02:44:33,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:33,296 INFO:     Epoch: 60
2023-01-04 02:44:34,891 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39153354118267697, 'Total loss': 0.39153354118267697} | train loss {'Reaction outcome loss': 0.21991020345406773, 'Total loss': 0.21991020345406773}
2023-01-04 02:44:34,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:34,891 INFO:     Epoch: 61
2023-01-04 02:44:36,486 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3747518648703893, 'Total loss': 0.3747518648703893} | train loss {'Reaction outcome loss': 0.2091340734285937, 'Total loss': 0.2091340734285937}
2023-01-04 02:44:36,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:36,486 INFO:     Epoch: 62
2023-01-04 02:44:38,064 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3570948660373688, 'Total loss': 0.3570948660373688} | train loss {'Reaction outcome loss': 0.2087706630142708, 'Total loss': 0.2087706630142708}
2023-01-04 02:44:38,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:38,064 INFO:     Epoch: 63
2023-01-04 02:44:39,683 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38232697745164235, 'Total loss': 0.38232697745164235} | train loss {'Reaction outcome loss': 0.20704677184637701, 'Total loss': 0.20704677184637701}
2023-01-04 02:44:39,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:39,683 INFO:     Epoch: 64
2023-01-04 02:44:41,308 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34654907633860904, 'Total loss': 0.34654907633860904} | train loss {'Reaction outcome loss': 0.20002864851899768, 'Total loss': 0.20002864851899768}
2023-01-04 02:44:41,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:41,309 INFO:     Epoch: 65
2023-01-04 02:44:42,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3472427546977997, 'Total loss': 0.3472427546977997} | train loss {'Reaction outcome loss': 0.20275535096313263, 'Total loss': 0.20275535096313263}
2023-01-04 02:44:42,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:42,899 INFO:     Epoch: 66
2023-01-04 02:44:44,513 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3705022394657135, 'Total loss': 0.3705022394657135} | train loss {'Reaction outcome loss': 0.1991137357584892, 'Total loss': 0.1991137357584892}
2023-01-04 02:44:44,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:44,513 INFO:     Epoch: 67
2023-01-04 02:44:46,142 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36960859994093576, 'Total loss': 0.36960859994093576} | train loss {'Reaction outcome loss': 0.1978357261100757, 'Total loss': 0.1978357261100757}
2023-01-04 02:44:46,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:46,142 INFO:     Epoch: 68
2023-01-04 02:44:47,727 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3632140029221773, 'Total loss': 0.3632140029221773} | train loss {'Reaction outcome loss': 0.19959137569758637, 'Total loss': 0.19959137569758637}
2023-01-04 02:44:47,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:47,727 INFO:     Epoch: 69
2023-01-04 02:44:49,323 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3600235551595688, 'Total loss': 0.3600235551595688} | train loss {'Reaction outcome loss': 0.19546590018224683, 'Total loss': 0.19546590018224683}
2023-01-04 02:44:49,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:49,324 INFO:     Epoch: 70
2023-01-04 02:44:50,947 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3729630460341771, 'Total loss': 0.3729630460341771} | train loss {'Reaction outcome loss': 0.19584807562489953, 'Total loss': 0.19584807562489953}
2023-01-04 02:44:50,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:50,947 INFO:     Epoch: 71
2023-01-04 02:44:52,534 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37469929258028667, 'Total loss': 0.37469929258028667} | train loss {'Reaction outcome loss': 0.19527620365978152, 'Total loss': 0.19527620365978152}
2023-01-04 02:44:52,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:52,534 INFO:     Epoch: 72
2023-01-04 02:44:54,131 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3782996475696564, 'Total loss': 0.3782996475696564} | train loss {'Reaction outcome loss': 0.1942957341738477, 'Total loss': 0.1942957341738477}
2023-01-04 02:44:54,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:54,132 INFO:     Epoch: 73
2023-01-04 02:44:55,711 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35440269112586975, 'Total loss': 0.35440269112586975} | train loss {'Reaction outcome loss': 0.19267313241315634, 'Total loss': 0.19267313241315634}
2023-01-04 02:44:55,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:55,711 INFO:     Epoch: 74
2023-01-04 02:44:57,335 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38895229597886405, 'Total loss': 0.38895229597886405} | train loss {'Reaction outcome loss': 0.20496421781085108, 'Total loss': 0.20496421781085108}
2023-01-04 02:44:57,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:57,335 INFO:     Epoch: 75
2023-01-04 02:44:58,960 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3660730997721354, 'Total loss': 0.3660730997721354} | train loss {'Reaction outcome loss': 0.23021517280679857, 'Total loss': 0.23021517280679857}
2023-01-04 02:44:58,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:44:58,960 INFO:     Epoch: 76
2023-01-04 02:45:00,550 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39212553898493446, 'Total loss': 0.39212553898493446} | train loss {'Reaction outcome loss': 0.1901924207644618, 'Total loss': 0.1901924207644618}
2023-01-04 02:45:00,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:00,550 INFO:     Epoch: 77
2023-01-04 02:45:02,169 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36418506105740867, 'Total loss': 0.36418506105740867} | train loss {'Reaction outcome loss': 0.19518151485185692, 'Total loss': 0.19518151485185692}
2023-01-04 02:45:02,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:02,170 INFO:     Epoch: 78
2023-01-04 02:45:03,789 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39591527779897057, 'Total loss': 0.39591527779897057} | train loss {'Reaction outcome loss': 0.1887182231002953, 'Total loss': 0.1887182231002953}
2023-01-04 02:45:03,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:03,790 INFO:     Epoch: 79
2023-01-04 02:45:05,375 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.372002449631691, 'Total loss': 0.372002449631691} | train loss {'Reaction outcome loss': 0.18276052709763357, 'Total loss': 0.18276052709763357}
2023-01-04 02:45:05,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:05,375 INFO:     Epoch: 80
2023-01-04 02:45:06,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3598565657933553, 'Total loss': 0.3598565657933553} | train loss {'Reaction outcome loss': 0.1830317368241621, 'Total loss': 0.1830317368241621}
2023-01-04 02:45:06,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:06,968 INFO:     Epoch: 81
2023-01-04 02:45:08,584 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36392998124162357, 'Total loss': 0.36392998124162357} | train loss {'Reaction outcome loss': 0.2003607998156677, 'Total loss': 0.2003607998156677}
2023-01-04 02:45:08,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:08,584 INFO:     Epoch: 82
2023-01-04 02:45:10,168 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4026685655117035, 'Total loss': 0.4026685655117035} | train loss {'Reaction outcome loss': 0.22505343378440518, 'Total loss': 0.22505343378440518}
2023-01-04 02:45:10,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:10,168 INFO:     Epoch: 83
2023-01-04 02:45:11,800 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39360094666481016, 'Total loss': 0.39360094666481016} | train loss {'Reaction outcome loss': 0.20146542124828135, 'Total loss': 0.20146542124828135}
2023-01-04 02:45:11,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:11,801 INFO:     Epoch: 84
2023-01-04 02:45:13,426 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3703341056903203, 'Total loss': 0.3703341056903203} | train loss {'Reaction outcome loss': 0.1863535721474192, 'Total loss': 0.1863535721474192}
2023-01-04 02:45:13,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:13,427 INFO:     Epoch: 85
2023-01-04 02:45:15,033 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3810677061478297, 'Total loss': 0.3810677061478297} | train loss {'Reaction outcome loss': 0.18081177092592596, 'Total loss': 0.18081177092592596}
2023-01-04 02:45:15,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:15,033 INFO:     Epoch: 86
2023-01-04 02:45:16,665 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3860940679907799, 'Total loss': 0.3860940679907799} | train loss {'Reaction outcome loss': 0.1765466697161437, 'Total loss': 0.1765466697161437}
2023-01-04 02:45:16,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:16,666 INFO:     Epoch: 87
2023-01-04 02:45:18,231 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37783455351988476, 'Total loss': 0.37783455351988476} | train loss {'Reaction outcome loss': 0.1786391363121515, 'Total loss': 0.1786391363121515}
2023-01-04 02:45:18,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:18,231 INFO:     Epoch: 88
2023-01-04 02:45:19,825 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3860379333297412, 'Total loss': 0.3860379333297412} | train loss {'Reaction outcome loss': 0.17816259432584047, 'Total loss': 0.17816259432584047}
2023-01-04 02:45:19,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:19,826 INFO:     Epoch: 89
2023-01-04 02:45:21,422 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3845305323600769, 'Total loss': 0.3845305323600769} | train loss {'Reaction outcome loss': 0.18070089594592623, 'Total loss': 0.18070089594592623}
2023-01-04 02:45:21,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:21,422 INFO:     Epoch: 90
2023-01-04 02:45:23,000 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39646085699399314, 'Total loss': 0.39646085699399314} | train loss {'Reaction outcome loss': 0.17643492888200327, 'Total loss': 0.17643492888200327}
2023-01-04 02:45:23,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:23,001 INFO:     Epoch: 91
2023-01-04 02:45:24,628 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38885831236839297, 'Total loss': 0.38885831236839297} | train loss {'Reaction outcome loss': 0.17801542898456135, 'Total loss': 0.17801542898456135}
2023-01-04 02:45:24,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:24,629 INFO:     Epoch: 92
2023-01-04 02:45:26,261 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38961436301469804, 'Total loss': 0.38961436301469804} | train loss {'Reaction outcome loss': 0.17800917826673907, 'Total loss': 0.17800917826673907}
2023-01-04 02:45:26,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:26,261 INFO:     Epoch: 93
2023-01-04 02:45:27,852 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3760177195072174, 'Total loss': 0.3760177195072174} | train loss {'Reaction outcome loss': 0.18206544613391432, 'Total loss': 0.18206544613391432}
2023-01-04 02:45:27,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:27,852 INFO:     Epoch: 94
2023-01-04 02:45:29,476 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39715745896100996, 'Total loss': 0.39715745896100996} | train loss {'Reaction outcome loss': 0.17452526965649484, 'Total loss': 0.17452526965649484}
2023-01-04 02:45:29,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:29,476 INFO:     Epoch: 95
2023-01-04 02:45:31,081 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3802925010522207, 'Total loss': 0.3802925010522207} | train loss {'Reaction outcome loss': 0.1751403794961347, 'Total loss': 0.1751403794961347}
2023-01-04 02:45:31,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:31,081 INFO:     Epoch: 96
2023-01-04 02:45:32,690 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.392332661151886, 'Total loss': 0.392332661151886} | train loss {'Reaction outcome loss': 0.17522236570737837, 'Total loss': 0.17522236570737837}
2023-01-04 02:45:32,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:32,691 INFO:     Epoch: 97
2023-01-04 02:45:34,313 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4167874038219452, 'Total loss': 0.4167874038219452} | train loss {'Reaction outcome loss': 0.17048855841868857, 'Total loss': 0.17048855841868857}
2023-01-04 02:45:34,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:34,314 INFO:     Epoch: 98
2023-01-04 02:45:35,937 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37478398780028027, 'Total loss': 0.37478398780028027} | train loss {'Reaction outcome loss': 0.1721045942198728, 'Total loss': 0.1721045942198728}
2023-01-04 02:45:35,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:35,937 INFO:     Epoch: 99
2023-01-04 02:45:37,513 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38456707100073495, 'Total loss': 0.38456707100073495} | train loss {'Reaction outcome loss': 0.171553119268788, 'Total loss': 0.171553119268788}
2023-01-04 02:45:37,514 INFO:     Best model found after epoch 39 of 100.
2023-01-04 02:45:37,514 INFO:   Done with stage: TRAINING
2023-01-04 02:45:37,514 INFO:   Starting stage: EVALUATION
2023-01-04 02:45:37,643 INFO:   Done with stage: EVALUATION
2023-01-04 02:45:37,643 INFO:   Leaving out SEQ value Fold_6
2023-01-04 02:45:37,656 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:45:37,656 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:45:38,305 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:45:38,305 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:45:38,374 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:45:38,374 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:45:38,374 INFO:     No hyperparam tuning for this model
2023-01-04 02:45:38,374 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:45:38,374 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:45:38,375 INFO:     None feature selector for col prot
2023-01-04 02:45:38,375 INFO:     None feature selector for col prot
2023-01-04 02:45:38,375 INFO:     None feature selector for col prot
2023-01-04 02:45:38,375 INFO:     None feature selector for col chem
2023-01-04 02:45:38,376 INFO:     None feature selector for col chem
2023-01-04 02:45:38,376 INFO:     None feature selector for col chem
2023-01-04 02:45:38,376 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:45:38,376 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:45:38,377 INFO:     Number of params in model 70141
2023-01-04 02:45:38,380 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:45:38,380 INFO:   Starting stage: TRAINING
2023-01-04 02:45:38,423 INFO:     Val loss before train {'Reaction outcome loss': 0.9987152735392253, 'Total loss': 0.9987152735392253}
2023-01-04 02:45:38,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:38,424 INFO:     Epoch: 0
2023-01-04 02:45:40,034 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6699976364771525, 'Total loss': 0.6699976364771525} | train loss {'Reaction outcome loss': 0.8303887373970255, 'Total loss': 0.8303887373970255}
2023-01-04 02:45:40,034 INFO:     Found new best model at epoch 0
2023-01-04 02:45:40,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:40,035 INFO:     Epoch: 1
2023-01-04 02:45:41,611 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5774693767229716, 'Total loss': 0.5774693767229716} | train loss {'Reaction outcome loss': 0.5995368862438583, 'Total loss': 0.5995368862438583}
2023-01-04 02:45:41,612 INFO:     Found new best model at epoch 1
2023-01-04 02:45:41,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:41,612 INFO:     Epoch: 2
2023-01-04 02:45:43,207 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5466228594382604, 'Total loss': 0.5466228594382604} | train loss {'Reaction outcome loss': 0.525199642984987, 'Total loss': 0.525199642984987}
2023-01-04 02:45:43,207 INFO:     Found new best model at epoch 2
2023-01-04 02:45:43,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:43,208 INFO:     Epoch: 3
2023-01-04 02:45:44,782 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5242424070835113, 'Total loss': 0.5242424070835113} | train loss {'Reaction outcome loss': 0.4854153024768322, 'Total loss': 0.4854153024768322}
2023-01-04 02:45:44,782 INFO:     Found new best model at epoch 3
2023-01-04 02:45:44,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:44,783 INFO:     Epoch: 4
2023-01-04 02:45:46,404 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5089836438496907, 'Total loss': 0.5089836438496907} | train loss {'Reaction outcome loss': 0.4604184248322702, 'Total loss': 0.4604184248322702}
2023-01-04 02:45:46,404 INFO:     Found new best model at epoch 4
2023-01-04 02:45:46,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:46,405 INFO:     Epoch: 5
2023-01-04 02:45:47,982 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5003939787546794, 'Total loss': 0.5003939787546794} | train loss {'Reaction outcome loss': 0.43987627220253606, 'Total loss': 0.43987627220253606}
2023-01-04 02:45:47,982 INFO:     Found new best model at epoch 5
2023-01-04 02:45:47,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:47,983 INFO:     Epoch: 6
2023-01-04 02:45:49,558 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48818694551785785, 'Total loss': 0.48818694551785785} | train loss {'Reaction outcome loss': 0.42355456682887144, 'Total loss': 0.42355456682887144}
2023-01-04 02:45:49,559 INFO:     Found new best model at epoch 6
2023-01-04 02:45:49,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:49,560 INFO:     Epoch: 7
2023-01-04 02:45:51,184 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47711873054504395, 'Total loss': 0.47711873054504395} | train loss {'Reaction outcome loss': 0.4091601634695046, 'Total loss': 0.4091601634695046}
2023-01-04 02:45:51,184 INFO:     Found new best model at epoch 7
2023-01-04 02:45:51,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:51,185 INFO:     Epoch: 8
2023-01-04 02:45:52,766 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4761320143938065, 'Total loss': 0.4761320143938065} | train loss {'Reaction outcome loss': 0.39962988622162654, 'Total loss': 0.39962988622162654}
2023-01-04 02:45:52,766 INFO:     Found new best model at epoch 8
2023-01-04 02:45:52,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:52,767 INFO:     Epoch: 9
2023-01-04 02:45:54,401 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47309520542621614, 'Total loss': 0.47309520542621614} | train loss {'Reaction outcome loss': 0.3871455305910575, 'Total loss': 0.3871455305910575}
2023-01-04 02:45:54,401 INFO:     Found new best model at epoch 9
2023-01-04 02:45:54,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:54,402 INFO:     Epoch: 10
2023-01-04 02:45:56,027 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46803369323412575, 'Total loss': 0.46803369323412575} | train loss {'Reaction outcome loss': 0.37652045370761195, 'Total loss': 0.37652045370761195}
2023-01-04 02:45:56,027 INFO:     Found new best model at epoch 10
2023-01-04 02:45:56,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:56,028 INFO:     Epoch: 11
2023-01-04 02:45:57,611 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45392364958922066, 'Total loss': 0.45392364958922066} | train loss {'Reaction outcome loss': 0.3670683322774678, 'Total loss': 0.3670683322774678}
2023-01-04 02:45:57,611 INFO:     Found new best model at epoch 11
2023-01-04 02:45:57,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:57,612 INFO:     Epoch: 12
2023-01-04 02:45:59,209 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47189888954162595, 'Total loss': 0.47189888954162595} | train loss {'Reaction outcome loss': 0.35972211020756123, 'Total loss': 0.35972211020756123}
2023-01-04 02:45:59,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:45:59,210 INFO:     Epoch: 13
2023-01-04 02:46:00,842 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45484170118967693, 'Total loss': 0.45484170118967693} | train loss {'Reaction outcome loss': 0.3532594351249893, 'Total loss': 0.3532594351249893}
2023-01-04 02:46:00,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:00,842 INFO:     Epoch: 14
2023-01-04 02:46:02,426 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4536999334891637, 'Total loss': 0.4536999334891637} | train loss {'Reaction outcome loss': 0.3462582273489755, 'Total loss': 0.3462582273489755}
2023-01-04 02:46:02,426 INFO:     Found new best model at epoch 14
2023-01-04 02:46:02,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:02,427 INFO:     Epoch: 15
2023-01-04 02:46:04,007 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43470279574394227, 'Total loss': 0.43470279574394227} | train loss {'Reaction outcome loss': 0.3419282977617737, 'Total loss': 0.3419282977617737}
2023-01-04 02:46:04,007 INFO:     Found new best model at epoch 15
2023-01-04 02:46:04,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:04,008 INFO:     Epoch: 16
2023-01-04 02:46:05,601 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45448070764541626, 'Total loss': 0.45448070764541626} | train loss {'Reaction outcome loss': 0.33634421661280206, 'Total loss': 0.33634421661280206}
2023-01-04 02:46:05,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:05,601 INFO:     Epoch: 17
2023-01-04 02:46:07,226 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4263286461432775, 'Total loss': 0.4263286461432775} | train loss {'Reaction outcome loss': 0.32966484314343636, 'Total loss': 0.32966484314343636}
2023-01-04 02:46:07,226 INFO:     Found new best model at epoch 17
2023-01-04 02:46:07,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:07,227 INFO:     Epoch: 18
2023-01-04 02:46:08,847 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44465219378471377, 'Total loss': 0.44465219378471377} | train loss {'Reaction outcome loss': 0.3228885433602862, 'Total loss': 0.3228885433602862}
2023-01-04 02:46:08,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:08,848 INFO:     Epoch: 19
2023-01-04 02:46:10,449 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44177406231562294, 'Total loss': 0.44177406231562294} | train loss {'Reaction outcome loss': 0.3142950169728821, 'Total loss': 0.3142950169728821}
2023-01-04 02:46:10,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:10,449 INFO:     Epoch: 20
2023-01-04 02:46:12,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4408705731232961, 'Total loss': 0.4408705731232961} | train loss {'Reaction outcome loss': 0.3107904162581848, 'Total loss': 0.3107904162581848}
2023-01-04 02:46:12,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:12,047 INFO:     Epoch: 21
2023-01-04 02:46:13,643 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4330691645542781, 'Total loss': 0.4330691645542781} | train loss {'Reaction outcome loss': 0.3079034423996969, 'Total loss': 0.3079034423996969}
2023-01-04 02:46:13,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:13,643 INFO:     Epoch: 22
2023-01-04 02:46:15,243 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4376504858334859, 'Total loss': 0.4376504858334859} | train loss {'Reaction outcome loss': 0.30174444943616996, 'Total loss': 0.30174444943616996}
2023-01-04 02:46:15,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:15,243 INFO:     Epoch: 23
2023-01-04 02:46:16,829 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43028194506963097, 'Total loss': 0.43028194506963097} | train loss {'Reaction outcome loss': 0.3002848256206641, 'Total loss': 0.3002848256206641}
2023-01-04 02:46:16,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:16,829 INFO:     Epoch: 24
2023-01-04 02:46:18,424 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43144508004188536, 'Total loss': 0.43144508004188536} | train loss {'Reaction outcome loss': 0.29457458991732827, 'Total loss': 0.29457458991732827}
2023-01-04 02:46:18,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:18,424 INFO:     Epoch: 25
2023-01-04 02:46:20,064 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46009636322657266, 'Total loss': 0.46009636322657266} | train loss {'Reaction outcome loss': 0.29094088501364423, 'Total loss': 0.29094088501364423}
2023-01-04 02:46:20,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:20,065 INFO:     Epoch: 26
2023-01-04 02:46:21,635 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.448736184835434, 'Total loss': 0.448736184835434} | train loss {'Reaction outcome loss': 0.2883912747826759, 'Total loss': 0.2883912747826759}
2023-01-04 02:46:21,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:21,635 INFO:     Epoch: 27
2023-01-04 02:46:23,257 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4350234031677246, 'Total loss': 0.4350234031677246} | train loss {'Reaction outcome loss': 0.2859282490335054, 'Total loss': 0.2859282490335054}
2023-01-04 02:46:23,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:23,258 INFO:     Epoch: 28
2023-01-04 02:46:24,892 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4265046238899231, 'Total loss': 0.4265046238899231} | train loss {'Reaction outcome loss': 0.29161853494419565, 'Total loss': 0.29161853494419565}
2023-01-04 02:46:24,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:24,892 INFO:     Epoch: 29
2023-01-04 02:46:26,491 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.448655441403389, 'Total loss': 0.448655441403389} | train loss {'Reaction outcome loss': 0.28533915392514586, 'Total loss': 0.28533915392514586}
2023-01-04 02:46:26,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:26,492 INFO:     Epoch: 30
2023-01-04 02:46:28,125 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.427248552441597, 'Total loss': 0.427248552441597} | train loss {'Reaction outcome loss': 0.275208356803742, 'Total loss': 0.275208356803742}
2023-01-04 02:46:28,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:28,126 INFO:     Epoch: 31
2023-01-04 02:46:29,730 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43770947058995563, 'Total loss': 0.43770947058995563} | train loss {'Reaction outcome loss': 0.28085711754966475, 'Total loss': 0.28085711754966475}
2023-01-04 02:46:29,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:29,731 INFO:     Epoch: 32
2023-01-04 02:46:31,356 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4397564152876536, 'Total loss': 0.4397564152876536} | train loss {'Reaction outcome loss': 0.2770924877109212, 'Total loss': 0.2770924877109212}
2023-01-04 02:46:31,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:31,357 INFO:     Epoch: 33
2023-01-04 02:46:32,968 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42286767065525055, 'Total loss': 0.42286767065525055} | train loss {'Reaction outcome loss': 0.2658445060563584, 'Total loss': 0.2658445060563584}
2023-01-04 02:46:32,968 INFO:     Found new best model at epoch 33
2023-01-04 02:46:32,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:32,969 INFO:     Epoch: 34
2023-01-04 02:46:34,536 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4366667151451111, 'Total loss': 0.4366667151451111} | train loss {'Reaction outcome loss': 0.2628806322759044, 'Total loss': 0.2628806322759044}
2023-01-04 02:46:34,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:34,537 INFO:     Epoch: 35
2023-01-04 02:46:36,159 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4433588057756424, 'Total loss': 0.4433588057756424} | train loss {'Reaction outcome loss': 0.25810964403849473, 'Total loss': 0.25810964403849473}
2023-01-04 02:46:36,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:36,159 INFO:     Epoch: 36
2023-01-04 02:46:37,780 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44010388255119326, 'Total loss': 0.44010388255119326} | train loss {'Reaction outcome loss': 0.2556129176763521, 'Total loss': 0.2556129176763521}
2023-01-04 02:46:37,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:37,781 INFO:     Epoch: 37
2023-01-04 02:46:39,390 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43316739598910015, 'Total loss': 0.43316739598910015} | train loss {'Reaction outcome loss': 0.25565074107937, 'Total loss': 0.25565074107937}
2023-01-04 02:46:39,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:39,391 INFO:     Epoch: 38
2023-01-04 02:46:41,010 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43119154969851176, 'Total loss': 0.43119154969851176} | train loss {'Reaction outcome loss': 0.260476381936367, 'Total loss': 0.260476381936367}
2023-01-04 02:46:41,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:41,010 INFO:     Epoch: 39
2023-01-04 02:46:42,645 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43431104719638824, 'Total loss': 0.43431104719638824} | train loss {'Reaction outcome loss': 0.26871085782413895, 'Total loss': 0.26871085782413895}
2023-01-04 02:46:42,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:42,645 INFO:     Epoch: 40
2023-01-04 02:46:44,236 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4425013571977615, 'Total loss': 0.4425013571977615} | train loss {'Reaction outcome loss': 0.2516353982019886, 'Total loss': 0.2516353982019886}
2023-01-04 02:46:44,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:44,236 INFO:     Epoch: 41
2023-01-04 02:46:45,879 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42820650041103364, 'Total loss': 0.42820650041103364} | train loss {'Reaction outcome loss': 0.24589659734638633, 'Total loss': 0.24589659734638633}
2023-01-04 02:46:45,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:45,879 INFO:     Epoch: 42
2023-01-04 02:46:47,493 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41854865550994874, 'Total loss': 0.41854865550994874} | train loss {'Reaction outcome loss': 0.24258729610701793, 'Total loss': 0.24258729610701793}
2023-01-04 02:46:47,494 INFO:     Found new best model at epoch 42
2023-01-04 02:46:47,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:47,494 INFO:     Epoch: 43
2023-01-04 02:46:49,077 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4252043972412745, 'Total loss': 0.4252043972412745} | train loss {'Reaction outcome loss': 0.23849893912193837, 'Total loss': 0.23849893912193837}
2023-01-04 02:46:49,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:49,078 INFO:     Epoch: 44
2023-01-04 02:46:50,677 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4259771098693212, 'Total loss': 0.4259771098693212} | train loss {'Reaction outcome loss': 0.23841918004757684, 'Total loss': 0.23841918004757684}
2023-01-04 02:46:50,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:50,677 INFO:     Epoch: 45
2023-01-04 02:46:52,277 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4459874351819356, 'Total loss': 0.4459874351819356} | train loss {'Reaction outcome loss': 0.2408574527480464, 'Total loss': 0.2408574527480464}
2023-01-04 02:46:52,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:52,277 INFO:     Epoch: 46
2023-01-04 02:46:53,884 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4210355460643768, 'Total loss': 0.4210355460643768} | train loss {'Reaction outcome loss': 0.24616536268107322, 'Total loss': 0.24616536268107322}
2023-01-04 02:46:53,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:53,884 INFO:     Epoch: 47
2023-01-04 02:46:55,507 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4250863611698151, 'Total loss': 0.4250863611698151} | train loss {'Reaction outcome loss': 0.23412014813157325, 'Total loss': 0.23412014813157325}
2023-01-04 02:46:55,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:55,508 INFO:     Epoch: 48
2023-01-04 02:46:57,101 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43675763010978697, 'Total loss': 0.43675763010978697} | train loss {'Reaction outcome loss': 0.22982308365053672, 'Total loss': 0.22982308365053672}
2023-01-04 02:46:57,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:57,102 INFO:     Epoch: 49
2023-01-04 02:46:58,687 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42618092795213064, 'Total loss': 0.42618092795213064} | train loss {'Reaction outcome loss': 0.22956500332498841, 'Total loss': 0.22956500332498841}
2023-01-04 02:46:58,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:46:58,687 INFO:     Epoch: 50
2023-01-04 02:47:00,310 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43971310754617055, 'Total loss': 0.43971310754617055} | train loss {'Reaction outcome loss': 0.23738053573322468, 'Total loss': 0.23738053573322468}
2023-01-04 02:47:00,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:00,310 INFO:     Epoch: 51
2023-01-04 02:47:01,915 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43353128532568613, 'Total loss': 0.43353128532568613} | train loss {'Reaction outcome loss': 0.23872583370277847, 'Total loss': 0.23872583370277847}
2023-01-04 02:47:01,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:01,915 INFO:     Epoch: 52
2023-01-04 02:47:03,520 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4164300590753555, 'Total loss': 0.4164300590753555} | train loss {'Reaction outcome loss': 0.23995095257397633, 'Total loss': 0.23995095257397633}
2023-01-04 02:47:03,521 INFO:     Found new best model at epoch 52
2023-01-04 02:47:03,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:03,522 INFO:     Epoch: 53
2023-01-04 02:47:05,100 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44195572336514793, 'Total loss': 0.44195572336514793} | train loss {'Reaction outcome loss': 0.23715155247760855, 'Total loss': 0.23715155247760855}
2023-01-04 02:47:05,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:05,100 INFO:     Epoch: 54
2023-01-04 02:47:06,693 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4489983300367991, 'Total loss': 0.4489983300367991} | train loss {'Reaction outcome loss': 0.24768026903325666, 'Total loss': 0.24768026903325666}
2023-01-04 02:47:06,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:06,693 INFO:     Epoch: 55
2023-01-04 02:47:08,290 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43106812437375386, 'Total loss': 0.43106812437375386} | train loss {'Reaction outcome loss': 0.25189662424415565, 'Total loss': 0.25189662424415565}
2023-01-04 02:47:08,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:08,290 INFO:     Epoch: 56
2023-01-04 02:47:09,885 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4321166455745697, 'Total loss': 0.4321166455745697} | train loss {'Reaction outcome loss': 0.24289858191395583, 'Total loss': 0.24289858191395583}
2023-01-04 02:47:09,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:09,886 INFO:     Epoch: 57
2023-01-04 02:47:11,483 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4271789252758026, 'Total loss': 0.4271789252758026} | train loss {'Reaction outcome loss': 0.23465601877335535, 'Total loss': 0.23465601877335535}
2023-01-04 02:47:11,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:11,483 INFO:     Epoch: 58
2023-01-04 02:47:13,074 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43876724044481913, 'Total loss': 0.43876724044481913} | train loss {'Reaction outcome loss': 0.21951284191733145, 'Total loss': 0.21951284191733145}
2023-01-04 02:47:13,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:13,074 INFO:     Epoch: 59
2023-01-04 02:47:14,691 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44080447653929394, 'Total loss': 0.44080447653929394} | train loss {'Reaction outcome loss': 0.21500526242011075, 'Total loss': 0.21500526242011075}
2023-01-04 02:47:14,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:14,692 INFO:     Epoch: 60
2023-01-04 02:47:16,298 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45578653216362, 'Total loss': 0.45578653216362} | train loss {'Reaction outcome loss': 0.21410552847394854, 'Total loss': 0.21410552847394854}
2023-01-04 02:47:16,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:16,299 INFO:     Epoch: 61
2023-01-04 02:47:17,878 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4300985167423884, 'Total loss': 0.4300985167423884} | train loss {'Reaction outcome loss': 0.21337685202503792, 'Total loss': 0.21337685202503792}
2023-01-04 02:47:17,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:17,878 INFO:     Epoch: 62
2023-01-04 02:47:19,477 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43001329600811006, 'Total loss': 0.43001329600811006} | train loss {'Reaction outcome loss': 0.2134628406102833, 'Total loss': 0.2134628406102833}
2023-01-04 02:47:19,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:19,478 INFO:     Epoch: 63
2023-01-04 02:47:21,117 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4323052922884623, 'Total loss': 0.4323052922884623} | train loss {'Reaction outcome loss': 0.2112544774874181, 'Total loss': 0.2112544774874181}
2023-01-04 02:47:21,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:21,117 INFO:     Epoch: 64
2023-01-04 02:47:22,756 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4310963014761607, 'Total loss': 0.4310963014761607} | train loss {'Reaction outcome loss': 0.20925939865514695, 'Total loss': 0.20925939865514695}
2023-01-04 02:47:22,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:22,757 INFO:     Epoch: 65
2023-01-04 02:47:24,351 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4509732772906621, 'Total loss': 0.4509732772906621} | train loss {'Reaction outcome loss': 0.20844821563408966, 'Total loss': 0.20844821563408966}
2023-01-04 02:47:24,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:24,351 INFO:     Epoch: 66
2023-01-04 02:47:25,973 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4120077222585678, 'Total loss': 0.4120077222585678} | train loss {'Reaction outcome loss': 0.21150087524691355, 'Total loss': 0.21150087524691355}
2023-01-04 02:47:25,973 INFO:     Found new best model at epoch 66
2023-01-04 02:47:25,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:25,974 INFO:     Epoch: 67
2023-01-04 02:47:27,586 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43728795846303303, 'Total loss': 0.43728795846303303} | train loss {'Reaction outcome loss': 0.2129978544502249, 'Total loss': 0.2129978544502249}
2023-01-04 02:47:27,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:27,586 INFO:     Epoch: 68
2023-01-04 02:47:29,189 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4432161062955856, 'Total loss': 0.4432161062955856} | train loss {'Reaction outcome loss': 0.20565508416705375, 'Total loss': 0.20565508416705375}
2023-01-04 02:47:29,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:29,189 INFO:     Epoch: 69
2023-01-04 02:47:30,794 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4379645218451818, 'Total loss': 0.4379645218451818} | train loss {'Reaction outcome loss': 0.21954538613773775, 'Total loss': 0.21954538613773775}
2023-01-04 02:47:30,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:30,794 INFO:     Epoch: 70
2023-01-04 02:47:32,416 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43278945883115133, 'Total loss': 0.43278945883115133} | train loss {'Reaction outcome loss': 0.23803921928966715, 'Total loss': 0.23803921928966715}
2023-01-04 02:47:32,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:32,417 INFO:     Epoch: 71
2023-01-04 02:47:33,996 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45115078588326774, 'Total loss': 0.45115078588326774} | train loss {'Reaction outcome loss': 0.21051729990142412, 'Total loss': 0.21051729990142412}
2023-01-04 02:47:33,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:33,996 INFO:     Epoch: 72
2023-01-04 02:47:35,595 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4332431137561798, 'Total loss': 0.4332431137561798} | train loss {'Reaction outcome loss': 0.21483237770777466, 'Total loss': 0.21483237770777466}
2023-01-04 02:47:35,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:35,595 INFO:     Epoch: 73
2023-01-04 02:47:37,198 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4326678395271301, 'Total loss': 0.4326678395271301} | train loss {'Reaction outcome loss': 0.21499245706945658, 'Total loss': 0.21499245706945658}
2023-01-04 02:47:37,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:37,198 INFO:     Epoch: 74
2023-01-04 02:47:38,780 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4313426132003466, 'Total loss': 0.4313426132003466} | train loss {'Reaction outcome loss': 0.20636037444279098, 'Total loss': 0.20636037444279098}
2023-01-04 02:47:38,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:38,781 INFO:     Epoch: 75
2023-01-04 02:47:40,405 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.458836696545283, 'Total loss': 0.458836696545283} | train loss {'Reaction outcome loss': 0.19699102574014576, 'Total loss': 0.19699102574014576}
2023-01-04 02:47:40,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:40,405 INFO:     Epoch: 76
2023-01-04 02:47:41,987 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4456762691338857, 'Total loss': 0.4456762691338857} | train loss {'Reaction outcome loss': 0.19557697029676344, 'Total loss': 0.19557697029676344}
2023-01-04 02:47:41,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:41,987 INFO:     Epoch: 77
2023-01-04 02:47:43,573 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4098677863677343, 'Total loss': 0.4098677863677343} | train loss {'Reaction outcome loss': 0.19784200273832117, 'Total loss': 0.19784200273832117}
2023-01-04 02:47:43,574 INFO:     Found new best model at epoch 77
2023-01-04 02:47:43,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:43,574 INFO:     Epoch: 78
2023-01-04 02:47:45,161 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41858911911646524, 'Total loss': 0.41858911911646524} | train loss {'Reaction outcome loss': 0.20612127422915047, 'Total loss': 0.20612127422915047}
2023-01-04 02:47:45,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:45,161 INFO:     Epoch: 79
2023-01-04 02:47:46,759 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4276923328638077, 'Total loss': 0.4276923328638077} | train loss {'Reaction outcome loss': 0.19433467631376738, 'Total loss': 0.19433467631376738}
2023-01-04 02:47:46,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:46,760 INFO:     Epoch: 80
2023-01-04 02:47:48,391 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4382531185944875, 'Total loss': 0.4382531185944875} | train loss {'Reaction outcome loss': 0.1930693795044478, 'Total loss': 0.1930693795044478}
2023-01-04 02:47:48,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:48,391 INFO:     Epoch: 81
2023-01-04 02:47:49,978 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4382048080364863, 'Total loss': 0.4382048080364863} | train loss {'Reaction outcome loss': 0.192528340359463, 'Total loss': 0.192528340359463}
2023-01-04 02:47:49,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:49,978 INFO:     Epoch: 82
2023-01-04 02:47:51,570 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44907855888207754, 'Total loss': 0.44907855888207754} | train loss {'Reaction outcome loss': 0.19147072660912207, 'Total loss': 0.19147072660912207}
2023-01-04 02:47:51,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:51,571 INFO:     Epoch: 83
2023-01-04 02:47:53,166 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4377892111738523, 'Total loss': 0.4377892111738523} | train loss {'Reaction outcome loss': 0.19477170029995908, 'Total loss': 0.19477170029995908}
2023-01-04 02:47:53,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:53,166 INFO:     Epoch: 84
2023-01-04 02:47:54,763 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45090196778376895, 'Total loss': 0.45090196778376895} | train loss {'Reaction outcome loss': 0.189872711515594, 'Total loss': 0.189872711515594}
2023-01-04 02:47:54,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:54,763 INFO:     Epoch: 85
2023-01-04 02:47:56,344 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4623004774252574, 'Total loss': 0.4623004774252574} | train loss {'Reaction outcome loss': 0.1916567951742816, 'Total loss': 0.1916567951742816}
2023-01-04 02:47:56,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:56,344 INFO:     Epoch: 86
2023-01-04 02:47:57,942 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4661574691534042, 'Total loss': 0.4661574691534042} | train loss {'Reaction outcome loss': 0.18601609537406635, 'Total loss': 0.18601609537406635}
2023-01-04 02:47:57,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:57,943 INFO:     Epoch: 87
2023-01-04 02:47:59,562 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45539804399013517, 'Total loss': 0.45539804399013517} | train loss {'Reaction outcome loss': 0.18755273619140295, 'Total loss': 0.18755273619140295}
2023-01-04 02:47:59,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:47:59,563 INFO:     Epoch: 88
2023-01-04 02:48:01,192 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44381068646907806, 'Total loss': 0.44381068646907806} | train loss {'Reaction outcome loss': 0.18761008561409984, 'Total loss': 0.18761008561409984}
2023-01-04 02:48:01,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:01,192 INFO:     Epoch: 89
2023-01-04 02:48:02,828 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43975698550542197, 'Total loss': 0.43975698550542197} | train loss {'Reaction outcome loss': 0.1884527184017836, 'Total loss': 0.1884527184017836}
2023-01-04 02:48:02,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:02,829 INFO:     Epoch: 90
2023-01-04 02:48:04,428 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4369886447985967, 'Total loss': 0.4369886447985967} | train loss {'Reaction outcome loss': 0.18697748724641144, 'Total loss': 0.18697748724641144}
2023-01-04 02:48:04,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:04,428 INFO:     Epoch: 91
2023-01-04 02:48:06,019 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46543800632158916, 'Total loss': 0.46543800632158916} | train loss {'Reaction outcome loss': 0.18764233215968462, 'Total loss': 0.18764233215968462}
2023-01-04 02:48:06,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:06,019 INFO:     Epoch: 92
2023-01-04 02:48:07,614 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46520788967609406, 'Total loss': 0.46520788967609406} | train loss {'Reaction outcome loss': 0.18516330099299777, 'Total loss': 0.18516330099299777}
2023-01-04 02:48:07,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:07,614 INFO:     Epoch: 93
2023-01-04 02:48:09,191 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4400545587142309, 'Total loss': 0.4400545587142309} | train loss {'Reaction outcome loss': 0.18698803222872337, 'Total loss': 0.18698803222872337}
2023-01-04 02:48:09,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:09,192 INFO:     Epoch: 94
2023-01-04 02:48:10,766 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43900338709354403, 'Total loss': 0.43900338709354403} | train loss {'Reaction outcome loss': 0.18401035581706127, 'Total loss': 0.18401035581706127}
2023-01-04 02:48:10,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:10,766 INFO:     Epoch: 95
2023-01-04 02:48:12,385 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46325506965319313, 'Total loss': 0.46325506965319313} | train loss {'Reaction outcome loss': 0.18202716744828806, 'Total loss': 0.18202716744828806}
2023-01-04 02:48:12,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:12,385 INFO:     Epoch: 96
2023-01-04 02:48:13,983 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4391616746783257, 'Total loss': 0.4391616746783257} | train loss {'Reaction outcome loss': 0.1817607557927461, 'Total loss': 0.1817607557927461}
2023-01-04 02:48:13,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:13,983 INFO:     Epoch: 97
2023-01-04 02:48:15,576 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46172770460446677, 'Total loss': 0.46172770460446677} | train loss {'Reaction outcome loss': 0.1868283168507227, 'Total loss': 0.1868283168507227}
2023-01-04 02:48:15,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:15,576 INFO:     Epoch: 98
2023-01-04 02:48:17,181 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4377182881037394, 'Total loss': 0.4377182881037394} | train loss {'Reaction outcome loss': 0.19168208093642403, 'Total loss': 0.19168208093642403}
2023-01-04 02:48:17,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:17,181 INFO:     Epoch: 99
2023-01-04 02:48:18,761 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4368780980507533, 'Total loss': 0.4368780980507533} | train loss {'Reaction outcome loss': 0.180667839569809, 'Total loss': 0.180667839569809}
2023-01-04 02:48:18,761 INFO:     Best model found after epoch 78 of 100.
2023-01-04 02:48:18,761 INFO:   Done with stage: TRAINING
2023-01-04 02:48:18,761 INFO:   Starting stage: EVALUATION
2023-01-04 02:48:18,890 INFO:   Done with stage: EVALUATION
2023-01-04 02:48:18,890 INFO:   Leaving out SEQ value Fold_7
2023-01-04 02:48:18,903 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 02:48:18,903 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:48:19,552 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:48:19,553 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:48:19,622 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:48:19,622 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:48:19,622 INFO:     No hyperparam tuning for this model
2023-01-04 02:48:19,622 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:48:19,622 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:48:19,623 INFO:     None feature selector for col prot
2023-01-04 02:48:19,623 INFO:     None feature selector for col prot
2023-01-04 02:48:19,623 INFO:     None feature selector for col prot
2023-01-04 02:48:19,624 INFO:     None feature selector for col chem
2023-01-04 02:48:19,624 INFO:     None feature selector for col chem
2023-01-04 02:48:19,624 INFO:     None feature selector for col chem
2023-01-04 02:48:19,624 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:48:19,624 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:48:19,625 INFO:     Number of params in model 70141
2023-01-04 02:48:19,628 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:48:19,628 INFO:   Starting stage: TRAINING
2023-01-04 02:48:19,674 INFO:     Val loss before train {'Reaction outcome loss': 1.0380659699440002, 'Total loss': 1.0380659699440002}
2023-01-04 02:48:19,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:19,674 INFO:     Epoch: 0
2023-01-04 02:48:21,276 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6881345570087433, 'Total loss': 0.6881345570087433} | train loss {'Reaction outcome loss': 0.8406762852995835, 'Total loss': 0.8406762852995835}
2023-01-04 02:48:21,277 INFO:     Found new best model at epoch 0
2023-01-04 02:48:21,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:21,278 INFO:     Epoch: 1
2023-01-04 02:48:22,854 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5895438273747762, 'Total loss': 0.5895438273747762} | train loss {'Reaction outcome loss': 0.6149217810226262, 'Total loss': 0.6149217810226262}
2023-01-04 02:48:22,854 INFO:     Found new best model at epoch 1
2023-01-04 02:48:22,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:22,855 INFO:     Epoch: 2
2023-01-04 02:48:24,473 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5277956048647563, 'Total loss': 0.5277956048647563} | train loss {'Reaction outcome loss': 0.5219414968460475, 'Total loss': 0.5219414968460475}
2023-01-04 02:48:24,473 INFO:     Found new best model at epoch 2
2023-01-04 02:48:24,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:24,474 INFO:     Epoch: 3
2023-01-04 02:48:26,071 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5147648831208547, 'Total loss': 0.5147648831208547} | train loss {'Reaction outcome loss': 0.48063524971154625, 'Total loss': 0.48063524971154625}
2023-01-04 02:48:26,071 INFO:     Found new best model at epoch 3
2023-01-04 02:48:26,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:26,072 INFO:     Epoch: 4
2023-01-04 02:48:27,652 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4950118084748586, 'Total loss': 0.4950118084748586} | train loss {'Reaction outcome loss': 0.45396371051292556, 'Total loss': 0.45396371051292556}
2023-01-04 02:48:27,653 INFO:     Found new best model at epoch 4
2023-01-04 02:48:27,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:27,653 INFO:     Epoch: 5
2023-01-04 02:48:29,245 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4931939681371053, 'Total loss': 0.4931939681371053} | train loss {'Reaction outcome loss': 0.4360013457573278, 'Total loss': 0.4360013457573278}
2023-01-04 02:48:29,246 INFO:     Found new best model at epoch 5
2023-01-04 02:48:29,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:29,246 INFO:     Epoch: 6
2023-01-04 02:48:30,842 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4788388729095459, 'Total loss': 0.4788388729095459} | train loss {'Reaction outcome loss': 0.4193049918873646, 'Total loss': 0.4193049918873646}
2023-01-04 02:48:30,842 INFO:     Found new best model at epoch 6
2023-01-04 02:48:30,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:30,843 INFO:     Epoch: 7
2023-01-04 02:48:32,419 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47777280807495115, 'Total loss': 0.47777280807495115} | train loss {'Reaction outcome loss': 0.4086208398107587, 'Total loss': 0.4086208398107587}
2023-01-04 02:48:32,419 INFO:     Found new best model at epoch 7
2023-01-04 02:48:32,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:32,420 INFO:     Epoch: 8
2023-01-04 02:48:34,020 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4593097984790802, 'Total loss': 0.4593097984790802} | train loss {'Reaction outcome loss': 0.39838138841334664, 'Total loss': 0.39838138841334664}
2023-01-04 02:48:34,021 INFO:     Found new best model at epoch 8
2023-01-04 02:48:34,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:34,022 INFO:     Epoch: 9
2023-01-04 02:48:35,604 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4474437346061071, 'Total loss': 0.4474437346061071} | train loss {'Reaction outcome loss': 0.3880312192095746, 'Total loss': 0.3880312192095746}
2023-01-04 02:48:35,604 INFO:     Found new best model at epoch 9
2023-01-04 02:48:35,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:35,605 INFO:     Epoch: 10
2023-01-04 02:48:37,198 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4401656130949656, 'Total loss': 0.4401656130949656} | train loss {'Reaction outcome loss': 0.3782153157550936, 'Total loss': 0.3782153157550936}
2023-01-04 02:48:37,199 INFO:     Found new best model at epoch 10
2023-01-04 02:48:37,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:37,199 INFO:     Epoch: 11
2023-01-04 02:48:38,798 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4577694376309713, 'Total loss': 0.4577694376309713} | train loss {'Reaction outcome loss': 0.37192282333485915, 'Total loss': 0.37192282333485915}
2023-01-04 02:48:38,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:38,798 INFO:     Epoch: 12
2023-01-04 02:48:40,375 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44083331326643627, 'Total loss': 0.44083331326643627} | train loss {'Reaction outcome loss': 0.36538514546001, 'Total loss': 0.36538514546001}
2023-01-04 02:48:40,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:40,376 INFO:     Epoch: 13
2023-01-04 02:48:41,980 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4577916224797567, 'Total loss': 0.4577916224797567} | train loss {'Reaction outcome loss': 0.356886079702997, 'Total loss': 0.356886079702997}
2023-01-04 02:48:41,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:41,981 INFO:     Epoch: 14
2023-01-04 02:48:43,589 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4387271920839945, 'Total loss': 0.4387271920839945} | train loss {'Reaction outcome loss': 0.35214869753333206, 'Total loss': 0.35214869753333206}
2023-01-04 02:48:43,589 INFO:     Found new best model at epoch 14
2023-01-04 02:48:43,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:43,590 INFO:     Epoch: 15
2023-01-04 02:48:45,174 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4488119463125865, 'Total loss': 0.4488119463125865} | train loss {'Reaction outcome loss': 0.3436898480199735, 'Total loss': 0.3436898480199735}
2023-01-04 02:48:45,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:45,175 INFO:     Epoch: 16
2023-01-04 02:48:46,777 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4425299803415934, 'Total loss': 0.4425299803415934} | train loss {'Reaction outcome loss': 0.33914120931057296, 'Total loss': 0.33914120931057296}
2023-01-04 02:48:46,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:46,777 INFO:     Epoch: 17
2023-01-04 02:48:48,380 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43357161482175194, 'Total loss': 0.43357161482175194} | train loss {'Reaction outcome loss': 0.33331299027165784, 'Total loss': 0.33331299027165784}
2023-01-04 02:48:48,380 INFO:     Found new best model at epoch 17
2023-01-04 02:48:48,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:48,381 INFO:     Epoch: 18
2023-01-04 02:48:49,967 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4377130627632141, 'Total loss': 0.4377130627632141} | train loss {'Reaction outcome loss': 0.3287023391695659, 'Total loss': 0.3287023391695659}
2023-01-04 02:48:49,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:49,967 INFO:     Epoch: 19
2023-01-04 02:48:51,569 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4382204075654348, 'Total loss': 0.4382204075654348} | train loss {'Reaction outcome loss': 0.32099970570002223, 'Total loss': 0.32099970570002223}
2023-01-04 02:48:51,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:51,569 INFO:     Epoch: 20
2023-01-04 02:48:53,172 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4425997197628021, 'Total loss': 0.4425997197628021} | train loss {'Reaction outcome loss': 0.3169693334384515, 'Total loss': 0.3169693334384515}
2023-01-04 02:48:53,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:53,173 INFO:     Epoch: 21
2023-01-04 02:48:54,783 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42608768145243325, 'Total loss': 0.42608768145243325} | train loss {'Reaction outcome loss': 0.3121256218275008, 'Total loss': 0.3121256218275008}
2023-01-04 02:48:54,783 INFO:     Found new best model at epoch 21
2023-01-04 02:48:54,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:54,784 INFO:     Epoch: 22
2023-01-04 02:48:56,419 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42659972111384076, 'Total loss': 0.42659972111384076} | train loss {'Reaction outcome loss': 0.307680234770267, 'Total loss': 0.307680234770267}
2023-01-04 02:48:56,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:56,419 INFO:     Epoch: 23
2023-01-04 02:48:58,044 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43001721799373627, 'Total loss': 0.43001721799373627} | train loss {'Reaction outcome loss': 0.3033325476874513, 'Total loss': 0.3033325476874513}
2023-01-04 02:48:58,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:58,044 INFO:     Epoch: 24
2023-01-04 02:48:59,676 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4298164357741674, 'Total loss': 0.4298164357741674} | train loss {'Reaction outcome loss': 0.2985505540502201, 'Total loss': 0.2985505540502201}
2023-01-04 02:48:59,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:48:59,676 INFO:     Epoch: 25
2023-01-04 02:49:01,312 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42464167475700376, 'Total loss': 0.42464167475700376} | train loss {'Reaction outcome loss': 0.2931930949434046, 'Total loss': 0.2931930949434046}
2023-01-04 02:49:01,313 INFO:     Found new best model at epoch 25
2023-01-04 02:49:01,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:01,313 INFO:     Epoch: 26
2023-01-04 02:49:02,905 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4027389407157898, 'Total loss': 0.4027389407157898} | train loss {'Reaction outcome loss': 0.28733162138113477, 'Total loss': 0.28733162138113477}
2023-01-04 02:49:02,905 INFO:     Found new best model at epoch 26
2023-01-04 02:49:02,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:02,906 INFO:     Epoch: 27
2023-01-04 02:49:04,513 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43091911474863687, 'Total loss': 0.43091911474863687} | train loss {'Reaction outcome loss': 0.28336171457537246, 'Total loss': 0.28336171457537246}
2023-01-04 02:49:04,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:04,513 INFO:     Epoch: 28
2023-01-04 02:49:06,119 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44364730020364124, 'Total loss': 0.44364730020364124} | train loss {'Reaction outcome loss': 0.2810398530927806, 'Total loss': 0.2810398530927806}
2023-01-04 02:49:06,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:06,119 INFO:     Epoch: 29
2023-01-04 02:49:07,720 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43086557984352114, 'Total loss': 0.43086557984352114} | train loss {'Reaction outcome loss': 0.27810618137463333, 'Total loss': 0.27810618137463333}
2023-01-04 02:49:07,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:07,720 INFO:     Epoch: 30
2023-01-04 02:49:09,310 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4300985435644786, 'Total loss': 0.4300985435644786} | train loss {'Reaction outcome loss': 0.27482326121644424, 'Total loss': 0.27482326121644424}
2023-01-04 02:49:09,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:09,312 INFO:     Epoch: 31
2023-01-04 02:49:10,929 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4229235579570135, 'Total loss': 0.4229235579570135} | train loss {'Reaction outcome loss': 0.2715296511023914, 'Total loss': 0.2715296511023914}
2023-01-04 02:49:10,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:10,930 INFO:     Epoch: 32
2023-01-04 02:49:12,538 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4052112897237142, 'Total loss': 0.4052112897237142} | train loss {'Reaction outcome loss': 0.2681954621138986, 'Total loss': 0.2681954621138986}
2023-01-04 02:49:12,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:12,538 INFO:     Epoch: 33
2023-01-04 02:49:14,134 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4080657432476679, 'Total loss': 0.4080657432476679} | train loss {'Reaction outcome loss': 0.26369397892256935, 'Total loss': 0.26369397892256935}
2023-01-04 02:49:14,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:14,135 INFO:     Epoch: 34
2023-01-04 02:49:15,762 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41761219600836436, 'Total loss': 0.41761219600836436} | train loss {'Reaction outcome loss': 0.2606857137398169, 'Total loss': 0.2606857137398169}
2023-01-04 02:49:15,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:15,763 INFO:     Epoch: 35
2023-01-04 02:49:17,344 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4107210834821065, 'Total loss': 0.4107210834821065} | train loss {'Reaction outcome loss': 0.2582582967214636, 'Total loss': 0.2582582967214636}
2023-01-04 02:49:17,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:17,344 INFO:     Epoch: 36
2023-01-04 02:49:18,977 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40903665920098625, 'Total loss': 0.40903665920098625} | train loss {'Reaction outcome loss': 0.2548129584922687, 'Total loss': 0.2548129584922687}
2023-01-04 02:49:18,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:18,977 INFO:     Epoch: 37
2023-01-04 02:49:20,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4108806927998861, 'Total loss': 0.4108806927998861} | train loss {'Reaction outcome loss': 0.25290139457916955, 'Total loss': 0.25290139457916955}
2023-01-04 02:49:20,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:20,575 INFO:     Epoch: 38
2023-01-04 02:49:22,179 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4407995939254761, 'Total loss': 0.4407995939254761} | train loss {'Reaction outcome loss': 0.24837217719331114, 'Total loss': 0.24837217719331114}
2023-01-04 02:49:22,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:22,180 INFO:     Epoch: 39
2023-01-04 02:49:23,815 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4221745550632477, 'Total loss': 0.4221745550632477} | train loss {'Reaction outcome loss': 0.24686654366633523, 'Total loss': 0.24686654366633523}
2023-01-04 02:49:23,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:23,815 INFO:     Epoch: 40
2023-01-04 02:49:25,405 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4148552199204763, 'Total loss': 0.4148552199204763} | train loss {'Reaction outcome loss': 0.2456001556253175, 'Total loss': 0.2456001556253175}
2023-01-04 02:49:25,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:25,405 INFO:     Epoch: 41
2023-01-04 02:49:27,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40667081276575723, 'Total loss': 0.40667081276575723} | train loss {'Reaction outcome loss': 0.24248608711447955, 'Total loss': 0.24248608711447955}
2023-01-04 02:49:27,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:27,040 INFO:     Epoch: 42
2023-01-04 02:49:28,676 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4078593780597051, 'Total loss': 0.4078593780597051} | train loss {'Reaction outcome loss': 0.2405692212525688, 'Total loss': 0.2405692212525688}
2023-01-04 02:49:28,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:28,677 INFO:     Epoch: 43
2023-01-04 02:49:30,274 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4322606444358826, 'Total loss': 0.4322606444358826} | train loss {'Reaction outcome loss': 0.2388389468435131, 'Total loss': 0.2388389468435131}
2023-01-04 02:49:30,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:30,274 INFO:     Epoch: 44
2023-01-04 02:49:31,878 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4054467062155406, 'Total loss': 0.4054467062155406} | train loss {'Reaction outcome loss': 0.23575834994496853, 'Total loss': 0.23575834994496853}
2023-01-04 02:49:31,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:31,878 INFO:     Epoch: 45
2023-01-04 02:49:33,503 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4098064551750819, 'Total loss': 0.4098064551750819} | train loss {'Reaction outcome loss': 0.23281668548872325, 'Total loss': 0.23281668548872325}
2023-01-04 02:49:33,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:33,503 INFO:     Epoch: 46
2023-01-04 02:49:35,095 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4180145035187403, 'Total loss': 0.4180145035187403} | train loss {'Reaction outcome loss': 0.23167896870564036, 'Total loss': 0.23167896870564036}
2023-01-04 02:49:35,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:35,095 INFO:     Epoch: 47
2023-01-04 02:49:36,697 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40610536833604177, 'Total loss': 0.40610536833604177} | train loss {'Reaction outcome loss': 0.23077207475577882, 'Total loss': 0.23077207475577882}
2023-01-04 02:49:36,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:36,697 INFO:     Epoch: 48
2023-01-04 02:49:38,281 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41202985843022666, 'Total loss': 0.41202985843022666} | train loss {'Reaction outcome loss': 0.22883633085751792, 'Total loss': 0.22883633085751792}
2023-01-04 02:49:38,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:38,281 INFO:     Epoch: 49
2023-01-04 02:49:39,352 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3996356040239334, 'Total loss': 0.3996356040239334} | train loss {'Reaction outcome loss': 0.22775726064716867, 'Total loss': 0.22775726064716867}
2023-01-04 02:49:39,353 INFO:     Found new best model at epoch 49
2023-01-04 02:49:39,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:39,353 INFO:     Epoch: 50
2023-01-04 02:49:40,420 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40862551927566526, 'Total loss': 0.40862551927566526} | train loss {'Reaction outcome loss': 0.221954273631534, 'Total loss': 0.221954273631534}
2023-01-04 02:49:40,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:40,421 INFO:     Epoch: 51
2023-01-04 02:49:41,491 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40665954450766245, 'Total loss': 0.40665954450766245} | train loss {'Reaction outcome loss': 0.22147973326945994, 'Total loss': 0.22147973326945994}
2023-01-04 02:49:41,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:41,492 INFO:     Epoch: 52
2023-01-04 02:49:42,552 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40013110836346943, 'Total loss': 0.40013110836346943} | train loss {'Reaction outcome loss': 0.2222100876352417, 'Total loss': 0.2222100876352417}
2023-01-04 02:49:42,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:42,553 INFO:     Epoch: 53
2023-01-04 02:49:44,069 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4250581204891205, 'Total loss': 0.4250581204891205} | train loss {'Reaction outcome loss': 0.21715989158848562, 'Total loss': 0.21715989158848562}
2023-01-04 02:49:44,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:44,069 INFO:     Epoch: 54
2023-01-04 02:49:45,687 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40623435775438943, 'Total loss': 0.40623435775438943} | train loss {'Reaction outcome loss': 0.21713837439241393, 'Total loss': 0.21713837439241393}
2023-01-04 02:49:45,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:45,687 INFO:     Epoch: 55
2023-01-04 02:49:47,309 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42427500486373904, 'Total loss': 0.42427500486373904} | train loss {'Reaction outcome loss': 0.21518390050110833, 'Total loss': 0.21518390050110833}
2023-01-04 02:49:47,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:47,310 INFO:     Epoch: 56
2023-01-04 02:49:48,891 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4312322611610095, 'Total loss': 0.4312322611610095} | train loss {'Reaction outcome loss': 0.21212176740546088, 'Total loss': 0.21212176740546088}
2023-01-04 02:49:48,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:48,891 INFO:     Epoch: 57
2023-01-04 02:49:50,481 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40157729188601177, 'Total loss': 0.40157729188601177} | train loss {'Reaction outcome loss': 0.21292393295504555, 'Total loss': 0.21292393295504555}
2023-01-04 02:49:50,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:50,481 INFO:     Epoch: 58
2023-01-04 02:49:52,061 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39987901548544563, 'Total loss': 0.39987901548544563} | train loss {'Reaction outcome loss': 0.2094807140663643, 'Total loss': 0.2094807140663643}
2023-01-04 02:49:52,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:52,061 INFO:     Epoch: 59
2023-01-04 02:49:53,662 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39939693609873456, 'Total loss': 0.39939693609873456} | train loss {'Reaction outcome loss': 0.2101352885096512, 'Total loss': 0.2101352885096512}
2023-01-04 02:49:53,662 INFO:     Found new best model at epoch 59
2023-01-04 02:49:53,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:53,663 INFO:     Epoch: 60
2023-01-04 02:49:55,251 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4219121386607488, 'Total loss': 0.4219121386607488} | train loss {'Reaction outcome loss': 0.2068466736871198, 'Total loss': 0.2068466736871198}
2023-01-04 02:49:55,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:55,252 INFO:     Epoch: 61
2023-01-04 02:49:56,876 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.416162454088529, 'Total loss': 0.416162454088529} | train loss {'Reaction outcome loss': 0.20802835132993946, 'Total loss': 0.20802835132993946}
2023-01-04 02:49:56,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:56,876 INFO:     Epoch: 62
2023-01-04 02:49:58,470 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4170596162478129, 'Total loss': 0.4170596162478129} | train loss {'Reaction outcome loss': 0.20500463368337507, 'Total loss': 0.20500463368337507}
2023-01-04 02:49:58,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:49:58,470 INFO:     Epoch: 63
2023-01-04 02:50:00,040 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4083004057407379, 'Total loss': 0.4083004057407379} | train loss {'Reaction outcome loss': 0.20382018017478368, 'Total loss': 0.20382018017478368}
2023-01-04 02:50:00,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:00,041 INFO:     Epoch: 64
2023-01-04 02:50:01,618 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4220972647269567, 'Total loss': 0.4220972647269567} | train loss {'Reaction outcome loss': 0.20204064033468278, 'Total loss': 0.20204064033468278}
2023-01-04 02:50:01,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:01,619 INFO:     Epoch: 65
2023-01-04 02:50:03,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4172306974728902, 'Total loss': 0.4172306974728902} | train loss {'Reaction outcome loss': 0.20179590515604087, 'Total loss': 0.20179590515604087}
2023-01-04 02:50:03,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:03,223 INFO:     Epoch: 66
2023-01-04 02:50:04,833 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3935126304626465, 'Total loss': 0.3935126304626465} | train loss {'Reaction outcome loss': 0.19834491145874403, 'Total loss': 0.19834491145874403}
2023-01-04 02:50:04,833 INFO:     Found new best model at epoch 66
2023-01-04 02:50:04,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:04,834 INFO:     Epoch: 67
2023-01-04 02:50:06,454 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43410564263661705, 'Total loss': 0.43410564263661705} | train loss {'Reaction outcome loss': 0.19744850466505284, 'Total loss': 0.19744850466505284}
2023-01-04 02:50:06,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:06,454 INFO:     Epoch: 68
2023-01-04 02:50:08,054 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4034147808949153, 'Total loss': 0.4034147808949153} | train loss {'Reaction outcome loss': 0.19839522816805633, 'Total loss': 0.19839522816805633}
2023-01-04 02:50:08,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:08,054 INFO:     Epoch: 69
2023-01-04 02:50:09,682 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39508562088012694, 'Total loss': 0.39508562088012694} | train loss {'Reaction outcome loss': 0.19846610060560144, 'Total loss': 0.19846610060560144}
2023-01-04 02:50:09,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:09,682 INFO:     Epoch: 70
2023-01-04 02:50:11,320 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40954213837782544, 'Total loss': 0.40954213837782544} | train loss {'Reaction outcome loss': 0.19535954443179743, 'Total loss': 0.19535954443179743}
2023-01-04 02:50:11,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:11,322 INFO:     Epoch: 71
2023-01-04 02:50:12,958 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4240552137295405, 'Total loss': 0.4240552137295405} | train loss {'Reaction outcome loss': 0.19328444491439778, 'Total loss': 0.19328444491439778}
2023-01-04 02:50:12,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:12,958 INFO:     Epoch: 72
2023-01-04 02:50:14,582 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4037435034910838, 'Total loss': 0.4037435034910838} | train loss {'Reaction outcome loss': 0.19401383720042473, 'Total loss': 0.19401383720042473}
2023-01-04 02:50:14,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:14,582 INFO:     Epoch: 73
2023-01-04 02:50:16,211 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.427857768535614, 'Total loss': 0.427857768535614} | train loss {'Reaction outcome loss': 0.19059434053672997, 'Total loss': 0.19059434053672997}
2023-01-04 02:50:16,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:16,211 INFO:     Epoch: 74
2023-01-04 02:50:17,800 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41666719913482664, 'Total loss': 0.41666719913482664} | train loss {'Reaction outcome loss': 0.18905645058850087, 'Total loss': 0.18905645058850087}
2023-01-04 02:50:17,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:17,801 INFO:     Epoch: 75
2023-01-04 02:50:19,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41380347857872646, 'Total loss': 0.41380347857872646} | train loss {'Reaction outcome loss': 0.191064208066797, 'Total loss': 0.191064208066797}
2023-01-04 02:50:19,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:19,385 INFO:     Epoch: 76
2023-01-04 02:50:20,985 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.414513923227787, 'Total loss': 0.414513923227787} | train loss {'Reaction outcome loss': 0.18706429779314393, 'Total loss': 0.18706429779314393}
2023-01-04 02:50:20,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:20,985 INFO:     Epoch: 77
2023-01-04 02:50:22,585 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4294896374146144, 'Total loss': 0.4294896374146144} | train loss {'Reaction outcome loss': 0.1873847854992758, 'Total loss': 0.1873847854992758}
2023-01-04 02:50:22,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:22,585 INFO:     Epoch: 78
2023-01-04 02:50:24,204 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42002124587694806, 'Total loss': 0.42002124587694806} | train loss {'Reaction outcome loss': 0.18653031797669425, 'Total loss': 0.18653031797669425}
2023-01-04 02:50:24,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:24,204 INFO:     Epoch: 79
2023-01-04 02:50:25,808 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42116303245226544, 'Total loss': 0.42116303245226544} | train loss {'Reaction outcome loss': 0.184785874553751, 'Total loss': 0.184785874553751}
2023-01-04 02:50:25,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:25,808 INFO:     Epoch: 80
2023-01-04 02:50:27,436 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4198481957117716, 'Total loss': 0.4198481957117716} | train loss {'Reaction outcome loss': 0.18409081204838054, 'Total loss': 0.18409081204838054}
2023-01-04 02:50:27,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:27,436 INFO:     Epoch: 81
2023-01-04 02:50:29,040 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4215787967046102, 'Total loss': 0.4215787967046102} | train loss {'Reaction outcome loss': 0.18548559167486237, 'Total loss': 0.18548559167486237}
2023-01-04 02:50:29,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:29,040 INFO:     Epoch: 82
2023-01-04 02:50:30,671 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42568479080994925, 'Total loss': 0.42568479080994925} | train loss {'Reaction outcome loss': 0.18282724243155024, 'Total loss': 0.18282724243155024}
2023-01-04 02:50:30,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:30,672 INFO:     Epoch: 83
2023-01-04 02:50:32,301 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41268413166205087, 'Total loss': 0.41268413166205087} | train loss {'Reaction outcome loss': 0.18308256883241425, 'Total loss': 0.18308256883241425}
2023-01-04 02:50:32,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:32,301 INFO:     Epoch: 84
2023-01-04 02:50:33,930 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42887946367263796, 'Total loss': 0.42887946367263796} | train loss {'Reaction outcome loss': 0.17962319753553033, 'Total loss': 0.17962319753553033}
2023-01-04 02:50:33,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:33,931 INFO:     Epoch: 85
2023-01-04 02:50:35,523 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42044879992802936, 'Total loss': 0.42044879992802936} | train loss {'Reaction outcome loss': 0.17977139866147662, 'Total loss': 0.17977139866147662}
2023-01-04 02:50:35,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:35,523 INFO:     Epoch: 86
2023-01-04 02:50:37,104 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4429302116235097, 'Total loss': 0.4429302116235097} | train loss {'Reaction outcome loss': 0.17757395797473, 'Total loss': 0.17757395797473}
2023-01-04 02:50:37,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:37,104 INFO:     Epoch: 87
2023-01-04 02:50:38,726 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43047995964686075, 'Total loss': 0.43047995964686075} | train loss {'Reaction outcome loss': 0.17905170202846993, 'Total loss': 0.17905170202846993}
2023-01-04 02:50:38,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:38,726 INFO:     Epoch: 88
2023-01-04 02:50:40,355 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4332533210515976, 'Total loss': 0.4332533210515976} | train loss {'Reaction outcome loss': 0.17731487900960102, 'Total loss': 0.17731487900960102}
2023-01-04 02:50:40,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:40,355 INFO:     Epoch: 89
2023-01-04 02:50:41,982 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41532853444417317, 'Total loss': 0.41532853444417317} | train loss {'Reaction outcome loss': 0.1778700919183045, 'Total loss': 0.1778700919183045}
2023-01-04 02:50:41,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:41,982 INFO:     Epoch: 90
2023-01-04 02:50:43,588 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.422644117474556, 'Total loss': 0.422644117474556} | train loss {'Reaction outcome loss': 0.1764594723507493, 'Total loss': 0.1764594723507493}
2023-01-04 02:50:43,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:43,589 INFO:     Epoch: 91
2023-01-04 02:50:45,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4413903643687566, 'Total loss': 0.4413903643687566} | train loss {'Reaction outcome loss': 0.17832784315013067, 'Total loss': 0.17832784315013067}
2023-01-04 02:50:45,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:45,208 INFO:     Epoch: 92
2023-01-04 02:50:46,805 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4060797323783239, 'Total loss': 0.4060797323783239} | train loss {'Reaction outcome loss': 0.17614442518229734, 'Total loss': 0.17614442518229734}
2023-01-04 02:50:46,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:46,806 INFO:     Epoch: 93
2023-01-04 02:50:48,428 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4344992155830065, 'Total loss': 0.4344992155830065} | train loss {'Reaction outcome loss': 0.17440948694514025, 'Total loss': 0.17440948694514025}
2023-01-04 02:50:48,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:48,428 INFO:     Epoch: 94
2023-01-04 02:50:50,058 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4437264362970988, 'Total loss': 0.4437264362970988} | train loss {'Reaction outcome loss': 0.17266787584561732, 'Total loss': 0.17266787584561732}
2023-01-04 02:50:50,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:50,059 INFO:     Epoch: 95
2023-01-04 02:50:51,688 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4375913937886556, 'Total loss': 0.4375913937886556} | train loss {'Reaction outcome loss': 0.16985479480038912, 'Total loss': 0.16985479480038912}
2023-01-04 02:50:51,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:51,688 INFO:     Epoch: 96
2023-01-04 02:50:53,294 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42033472458521526, 'Total loss': 0.42033472458521526} | train loss {'Reaction outcome loss': 0.17217079895659473, 'Total loss': 0.17217079895659473}
2023-01-04 02:50:53,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:53,295 INFO:     Epoch: 97
2023-01-04 02:50:54,878 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4216685632864634, 'Total loss': 0.4216685632864634} | train loss {'Reaction outcome loss': 0.17132230234813173, 'Total loss': 0.17132230234813173}
2023-01-04 02:50:54,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:54,879 INFO:     Epoch: 98
2023-01-04 02:50:56,477 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4320927123228709, 'Total loss': 0.4320927123228709} | train loss {'Reaction outcome loss': 0.17259157451696774, 'Total loss': 0.17259157451696774}
2023-01-04 02:50:56,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:56,477 INFO:     Epoch: 99
2023-01-04 02:50:58,107 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4244858811299006, 'Total loss': 0.4244858811299006} | train loss {'Reaction outcome loss': 0.1685112470673525, 'Total loss': 0.1685112470673525}
2023-01-04 02:50:58,107 INFO:     Best model found after epoch 67 of 100.
2023-01-04 02:50:58,108 INFO:   Done with stage: TRAINING
2023-01-04 02:50:58,108 INFO:   Starting stage: EVALUATION
2023-01-04 02:50:58,231 INFO:   Done with stage: EVALUATION
2023-01-04 02:50:58,231 INFO:   Leaving out SEQ value Fold_8
2023-01-04 02:50:58,244 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 02:50:58,244 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:50:58,898 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:50:58,899 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:50:58,968 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:50:58,968 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:50:58,968 INFO:     No hyperparam tuning for this model
2023-01-04 02:50:58,968 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:50:58,968 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:50:58,969 INFO:     None feature selector for col prot
2023-01-04 02:50:58,969 INFO:     None feature selector for col prot
2023-01-04 02:50:58,969 INFO:     None feature selector for col prot
2023-01-04 02:50:58,970 INFO:     None feature selector for col chem
2023-01-04 02:50:58,970 INFO:     None feature selector for col chem
2023-01-04 02:50:58,970 INFO:     None feature selector for col chem
2023-01-04 02:50:58,970 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:50:58,970 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:50:58,971 INFO:     Number of params in model 70141
2023-01-04 02:50:58,974 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:50:58,975 INFO:   Starting stage: TRAINING
2023-01-04 02:50:59,018 INFO:     Val loss before train {'Reaction outcome loss': 1.0021984179814656, 'Total loss': 1.0021984179814656}
2023-01-04 02:50:59,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:50:59,018 INFO:     Epoch: 0
2023-01-04 02:51:00,609 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.670744017759959, 'Total loss': 0.670744017759959} | train loss {'Reaction outcome loss': 0.8311173008693443, 'Total loss': 0.8311173008693443}
2023-01-04 02:51:00,609 INFO:     Found new best model at epoch 0
2023-01-04 02:51:00,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:00,610 INFO:     Epoch: 1
2023-01-04 02:51:02,185 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5371125320593516, 'Total loss': 0.5371125320593516} | train loss {'Reaction outcome loss': 0.5899181737131252, 'Total loss': 0.5899181737131252}
2023-01-04 02:51:02,185 INFO:     Found new best model at epoch 1
2023-01-04 02:51:02,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:02,186 INFO:     Epoch: 2
2023-01-04 02:51:03,753 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48182509740193685, 'Total loss': 0.48182509740193685} | train loss {'Reaction outcome loss': 0.5173608936887958, 'Total loss': 0.5173608936887958}
2023-01-04 02:51:03,753 INFO:     Found new best model at epoch 2
2023-01-04 02:51:03,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:03,754 INFO:     Epoch: 3
2023-01-04 02:51:05,335 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46556982000668845, 'Total loss': 0.46556982000668845} | train loss {'Reaction outcome loss': 0.4798971163484203, 'Total loss': 0.4798971163484203}
2023-01-04 02:51:05,336 INFO:     Found new best model at epoch 3
2023-01-04 02:51:05,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:05,337 INFO:     Epoch: 4
2023-01-04 02:51:06,943 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4758553087711334, 'Total loss': 0.4758553087711334} | train loss {'Reaction outcome loss': 0.4536575648265007, 'Total loss': 0.4536575648265007}
2023-01-04 02:51:06,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:06,943 INFO:     Epoch: 5
2023-01-04 02:51:08,556 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4547710875670115, 'Total loss': 0.4547710875670115} | train loss {'Reaction outcome loss': 0.4301688233902166, 'Total loss': 0.4301688233902166}
2023-01-04 02:51:08,556 INFO:     Found new best model at epoch 5
2023-01-04 02:51:08,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:08,557 INFO:     Epoch: 6
2023-01-04 02:51:10,175 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4337213476498922, 'Total loss': 0.4337213476498922} | train loss {'Reaction outcome loss': 0.41468330933934167, 'Total loss': 0.41468330933934167}
2023-01-04 02:51:10,175 INFO:     Found new best model at epoch 6
2023-01-04 02:51:10,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:10,176 INFO:     Epoch: 7
2023-01-04 02:51:11,746 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4205421686172485, 'Total loss': 0.4205421686172485} | train loss {'Reaction outcome loss': 0.4036665154354913, 'Total loss': 0.4036665154354913}
2023-01-04 02:51:11,746 INFO:     Found new best model at epoch 7
2023-01-04 02:51:11,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:11,747 INFO:     Epoch: 8
2023-01-04 02:51:13,311 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4062167823314667, 'Total loss': 0.4062167823314667} | train loss {'Reaction outcome loss': 0.3924139171238347, 'Total loss': 0.3924139171238347}
2023-01-04 02:51:13,311 INFO:     Found new best model at epoch 8
2023-01-04 02:51:13,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:13,312 INFO:     Epoch: 9
2023-01-04 02:51:14,908 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4010320564111074, 'Total loss': 0.4010320564111074} | train loss {'Reaction outcome loss': 0.3814277539213935, 'Total loss': 0.3814277539213935}
2023-01-04 02:51:14,908 INFO:     Found new best model at epoch 9
2023-01-04 02:51:14,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:14,909 INFO:     Epoch: 10
2023-01-04 02:51:16,519 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40793356200059255, 'Total loss': 0.40793356200059255} | train loss {'Reaction outcome loss': 0.3709401081114898, 'Total loss': 0.3709401081114898}
2023-01-04 02:51:16,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:16,520 INFO:     Epoch: 11
2023-01-04 02:51:18,131 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4018786629041036, 'Total loss': 0.4018786629041036} | train loss {'Reaction outcome loss': 0.36306805029893535, 'Total loss': 0.36306805029893535}
2023-01-04 02:51:18,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:18,132 INFO:     Epoch: 12
2023-01-04 02:51:19,692 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3924765298763911, 'Total loss': 0.3924765298763911} | train loss {'Reaction outcome loss': 0.35452029346437247, 'Total loss': 0.35452029346437247}
2023-01-04 02:51:19,693 INFO:     Found new best model at epoch 12
2023-01-04 02:51:19,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:19,693 INFO:     Epoch: 13
2023-01-04 02:51:21,305 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38658224443594613, 'Total loss': 0.38658224443594613} | train loss {'Reaction outcome loss': 0.344894358199158, 'Total loss': 0.344894358199158}
2023-01-04 02:51:21,306 INFO:     Found new best model at epoch 13
2023-01-04 02:51:21,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:21,306 INFO:     Epoch: 14
2023-01-04 02:51:22,889 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4043546050786972, 'Total loss': 0.4043546050786972} | train loss {'Reaction outcome loss': 0.33982960137473794, 'Total loss': 0.33982960137473794}
2023-01-04 02:51:22,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:22,889 INFO:     Epoch: 15
2023-01-04 02:51:24,500 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3923882563908895, 'Total loss': 0.3923882563908895} | train loss {'Reaction outcome loss': 0.3375208929672346, 'Total loss': 0.3375208929672346}
2023-01-04 02:51:24,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:24,501 INFO:     Epoch: 16
2023-01-04 02:51:26,089 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4022664705912272, 'Total loss': 0.4022664705912272} | train loss {'Reaction outcome loss': 0.3253941056165066, 'Total loss': 0.3253941056165066}
2023-01-04 02:51:26,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:26,089 INFO:     Epoch: 17
2023-01-04 02:51:27,693 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3910894900560379, 'Total loss': 0.3910894900560379} | train loss {'Reaction outcome loss': 0.3204957105956235, 'Total loss': 0.3204957105956235}
2023-01-04 02:51:27,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:27,693 INFO:     Epoch: 18
2023-01-04 02:51:29,273 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3760939409335454, 'Total loss': 0.3760939409335454} | train loss {'Reaction outcome loss': 0.31832661328243683, 'Total loss': 0.31832661328243683}
2023-01-04 02:51:29,273 INFO:     Found new best model at epoch 18
2023-01-04 02:51:29,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:29,274 INFO:     Epoch: 19
2023-01-04 02:51:30,862 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3829522728919983, 'Total loss': 0.3829522728919983} | train loss {'Reaction outcome loss': 0.3128074518108106, 'Total loss': 0.3128074518108106}
2023-01-04 02:51:30,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:30,862 INFO:     Epoch: 20
2023-01-04 02:51:32,441 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39802933832009635, 'Total loss': 0.39802933832009635} | train loss {'Reaction outcome loss': 0.30743655756170496, 'Total loss': 0.30743655756170496}
2023-01-04 02:51:32,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:32,442 INFO:     Epoch: 21
2023-01-04 02:51:34,023 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.373804239432017, 'Total loss': 0.373804239432017} | train loss {'Reaction outcome loss': 0.3016694107335129, 'Total loss': 0.3016694107335129}
2023-01-04 02:51:34,024 INFO:     Found new best model at epoch 21
2023-01-04 02:51:34,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:34,024 INFO:     Epoch: 22
2023-01-04 02:51:35,602 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38961439232031503, 'Total loss': 0.38961439232031503} | train loss {'Reaction outcome loss': 0.29569667719659354, 'Total loss': 0.29569667719659354}
2023-01-04 02:51:35,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:35,602 INFO:     Epoch: 23
2023-01-04 02:51:37,175 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3707178006569544, 'Total loss': 0.3707178006569544} | train loss {'Reaction outcome loss': 0.2958493219627129, 'Total loss': 0.2958493219627129}
2023-01-04 02:51:37,176 INFO:     Found new best model at epoch 23
2023-01-04 02:51:37,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:37,177 INFO:     Epoch: 24
2023-01-04 02:51:38,746 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3786855399608612, 'Total loss': 0.3786855399608612} | train loss {'Reaction outcome loss': 0.2870038700163801, 'Total loss': 0.2870038700163801}
2023-01-04 02:51:38,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:38,746 INFO:     Epoch: 25
2023-01-04 02:51:40,326 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3668447196483612, 'Total loss': 0.3668447196483612} | train loss {'Reaction outcome loss': 0.28612123072256535, 'Total loss': 0.28612123072256535}
2023-01-04 02:51:40,327 INFO:     Found new best model at epoch 25
2023-01-04 02:51:40,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:40,328 INFO:     Epoch: 26
2023-01-04 02:51:41,909 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3848374625047048, 'Total loss': 0.3848374625047048} | train loss {'Reaction outcome loss': 0.28049318376423676, 'Total loss': 0.28049318376423676}
2023-01-04 02:51:41,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:41,909 INFO:     Epoch: 27
2023-01-04 02:51:43,529 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.35776196668545407, 'Total loss': 0.35776196668545407} | train loss {'Reaction outcome loss': 0.27456969546747734, 'Total loss': 0.27456969546747734}
2023-01-04 02:51:43,529 INFO:     Found new best model at epoch 27
2023-01-04 02:51:43,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:43,530 INFO:     Epoch: 28
2023-01-04 02:51:45,122 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3667950352032979, 'Total loss': 0.3667950352032979} | train loss {'Reaction outcome loss': 0.27187089299980977, 'Total loss': 0.27187089299980977}
2023-01-04 02:51:45,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:45,122 INFO:     Epoch: 29
2023-01-04 02:51:46,712 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3917755126953125, 'Total loss': 0.3917755126953125} | train loss {'Reaction outcome loss': 0.2716090047097468, 'Total loss': 0.2716090047097468}
2023-01-04 02:51:46,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:46,712 INFO:     Epoch: 30
2023-01-04 02:51:48,295 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3724640280008316, 'Total loss': 0.3724640280008316} | train loss {'Reaction outcome loss': 0.2652673649263906, 'Total loss': 0.2652673649263906}
2023-01-04 02:51:48,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:48,295 INFO:     Epoch: 31
2023-01-04 02:51:49,895 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.34742904305458067, 'Total loss': 0.34742904305458067} | train loss {'Reaction outcome loss': 0.2609218036817325, 'Total loss': 0.2609218036817325}
2023-01-04 02:51:49,895 INFO:     Found new best model at epoch 31
2023-01-04 02:51:49,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:49,896 INFO:     Epoch: 32
2023-01-04 02:51:51,500 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35313636660575864, 'Total loss': 0.35313636660575864} | train loss {'Reaction outcome loss': 0.2625458546037421, 'Total loss': 0.2625458546037421}
2023-01-04 02:51:51,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:51,500 INFO:     Epoch: 33
2023-01-04 02:51:53,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3633983373641968, 'Total loss': 0.3633983373641968} | train loss {'Reaction outcome loss': 0.2576828683716255, 'Total loss': 0.2576828683716255}
2023-01-04 02:51:53,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:53,078 INFO:     Epoch: 34
2023-01-04 02:51:54,685 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3813103367884954, 'Total loss': 0.3813103367884954} | train loss {'Reaction outcome loss': 0.2552723486126561, 'Total loss': 0.2552723486126561}
2023-01-04 02:51:54,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:54,685 INFO:     Epoch: 35
2023-01-04 02:51:56,279 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3764772226413091, 'Total loss': 0.3764772226413091} | train loss {'Reaction outcome loss': 0.25303771839419126, 'Total loss': 0.25303771839419126}
2023-01-04 02:51:56,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:56,280 INFO:     Epoch: 36
2023-01-04 02:51:57,872 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36717140972614287, 'Total loss': 0.36717140972614287} | train loss {'Reaction outcome loss': 0.25044505813947093, 'Total loss': 0.25044505813947093}
2023-01-04 02:51:57,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:57,872 INFO:     Epoch: 37
2023-01-04 02:51:59,477 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3484954098860423, 'Total loss': 0.3484954098860423} | train loss {'Reaction outcome loss': 0.24365595518014369, 'Total loss': 0.24365595518014369}
2023-01-04 02:51:59,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:51:59,478 INFO:     Epoch: 38
2023-01-04 02:52:01,091 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36481665869553886, 'Total loss': 0.36481665869553886} | train loss {'Reaction outcome loss': 0.2450115266409549, 'Total loss': 0.2450115266409549}
2023-01-04 02:52:01,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:01,091 INFO:     Epoch: 39
2023-01-04 02:52:02,665 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37779842217763265, 'Total loss': 0.37779842217763265} | train loss {'Reaction outcome loss': 0.24006169925242554, 'Total loss': 0.24006169925242554}
2023-01-04 02:52:02,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:02,665 INFO:     Epoch: 40
2023-01-04 02:52:04,280 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3596707468231519, 'Total loss': 0.3596707468231519} | train loss {'Reaction outcome loss': 0.24173230722874076, 'Total loss': 0.24173230722874076}
2023-01-04 02:52:04,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:04,281 INFO:     Epoch: 41
2023-01-04 02:52:05,867 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37576696077982585, 'Total loss': 0.37576696077982585} | train loss {'Reaction outcome loss': 0.2355364272063905, 'Total loss': 0.2355364272063905}
2023-01-04 02:52:05,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:05,867 INFO:     Epoch: 42
2023-01-04 02:52:07,452 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35568549384673437, 'Total loss': 0.35568549384673437} | train loss {'Reaction outcome loss': 0.23307296089254892, 'Total loss': 0.23307296089254892}
2023-01-04 02:52:07,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:07,452 INFO:     Epoch: 43
2023-01-04 02:52:09,071 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.361711640159289, 'Total loss': 0.361711640159289} | train loss {'Reaction outcome loss': 0.23094788384743226, 'Total loss': 0.23094788384743226}
2023-01-04 02:52:09,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:09,071 INFO:     Epoch: 44
2023-01-04 02:52:10,687 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3587534576654434, 'Total loss': 0.3587534576654434} | train loss {'Reaction outcome loss': 0.2271155203000093, 'Total loss': 0.2271155203000093}
2023-01-04 02:52:10,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:10,687 INFO:     Epoch: 45
2023-01-04 02:52:12,301 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3561167538166046, 'Total loss': 0.3561167538166046} | train loss {'Reaction outcome loss': 0.22326010068530563, 'Total loss': 0.22326010068530563}
2023-01-04 02:52:12,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:12,302 INFO:     Epoch: 46
2023-01-04 02:52:13,895 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3532804225881894, 'Total loss': 0.3532804225881894} | train loss {'Reaction outcome loss': 0.224963820119808, 'Total loss': 0.224963820119808}
2023-01-04 02:52:13,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:13,896 INFO:     Epoch: 47
2023-01-04 02:52:15,519 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3426760007937749, 'Total loss': 0.3426760007937749} | train loss {'Reaction outcome loss': 0.2214788997566307, 'Total loss': 0.2214788997566307}
2023-01-04 02:52:15,519 INFO:     Found new best model at epoch 47
2023-01-04 02:52:15,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:15,520 INFO:     Epoch: 48
2023-01-04 02:52:17,090 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36103926599025726, 'Total loss': 0.36103926599025726} | train loss {'Reaction outcome loss': 0.22015517034428023, 'Total loss': 0.22015517034428023}
2023-01-04 02:52:17,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:17,090 INFO:     Epoch: 49
2023-01-04 02:52:18,704 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.359310956299305, 'Total loss': 0.359310956299305} | train loss {'Reaction outcome loss': 0.21630933319965562, 'Total loss': 0.21630933319965562}
2023-01-04 02:52:18,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:18,704 INFO:     Epoch: 50
2023-01-04 02:52:20,325 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34656923413276675, 'Total loss': 0.34656923413276675} | train loss {'Reaction outcome loss': 0.21536548423406843, 'Total loss': 0.21536548423406843}
2023-01-04 02:52:20,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:20,325 INFO:     Epoch: 51
2023-01-04 02:52:21,930 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3540713389714559, 'Total loss': 0.3540713389714559} | train loss {'Reaction outcome loss': 0.21565035353977602, 'Total loss': 0.21565035353977602}
2023-01-04 02:52:21,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:21,930 INFO:     Epoch: 52
2023-01-04 02:52:23,510 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3575084149837494, 'Total loss': 0.3575084149837494} | train loss {'Reaction outcome loss': 0.212257077896988, 'Total loss': 0.212257077896988}
2023-01-04 02:52:23,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:23,511 INFO:     Epoch: 53
2023-01-04 02:52:25,069 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3539784779151281, 'Total loss': 0.3539784779151281} | train loss {'Reaction outcome loss': 0.20943784330299486, 'Total loss': 0.20943784330299486}
2023-01-04 02:52:25,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:25,069 INFO:     Epoch: 54
2023-01-04 02:52:26,675 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34490025639533994, 'Total loss': 0.34490025639533994} | train loss {'Reaction outcome loss': 0.21126282340659328, 'Total loss': 0.21126282340659328}
2023-01-04 02:52:26,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:26,675 INFO:     Epoch: 55
2023-01-04 02:52:28,279 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36619107325871786, 'Total loss': 0.36619107325871786} | train loss {'Reaction outcome loss': 0.20852352869816315, 'Total loss': 0.20852352869816315}
2023-01-04 02:52:28,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:28,279 INFO:     Epoch: 56
2023-01-04 02:52:29,885 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3451877156893412, 'Total loss': 0.3451877156893412} | train loss {'Reaction outcome loss': 0.2046592119627465, 'Total loss': 0.2046592119627465}
2023-01-04 02:52:29,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:29,886 INFO:     Epoch: 57
2023-01-04 02:52:31,476 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3424764663601915, 'Total loss': 0.3424764663601915} | train loss {'Reaction outcome loss': 0.2026185144571376, 'Total loss': 0.2026185144571376}
2023-01-04 02:52:31,476 INFO:     Found new best model at epoch 57
2023-01-04 02:52:31,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:31,477 INFO:     Epoch: 58
2023-01-04 02:52:33,068 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38062214056650795, 'Total loss': 0.38062214056650795} | train loss {'Reaction outcome loss': 0.2010169685460054, 'Total loss': 0.2010169685460054}
2023-01-04 02:52:33,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:33,068 INFO:     Epoch: 59
2023-01-04 02:52:34,638 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35593754251797993, 'Total loss': 0.35593754251797993} | train loss {'Reaction outcome loss': 0.19878812537497872, 'Total loss': 0.19878812537497872}
2023-01-04 02:52:34,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:34,638 INFO:     Epoch: 60
2023-01-04 02:52:36,240 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3557652542988459, 'Total loss': 0.3557652542988459} | train loss {'Reaction outcome loss': 0.19850329563512906, 'Total loss': 0.19850329563512906}
2023-01-04 02:52:36,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:36,240 INFO:     Epoch: 61
2023-01-04 02:52:37,844 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3637930989265442, 'Total loss': 0.3637930989265442} | train loss {'Reaction outcome loss': 0.19795587964546987, 'Total loss': 0.19795587964546987}
2023-01-04 02:52:37,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:37,844 INFO:     Epoch: 62
2023-01-04 02:52:39,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34520186136166253, 'Total loss': 0.34520186136166253} | train loss {'Reaction outcome loss': 0.19747030616297825, 'Total loss': 0.19747030616297825}
2023-01-04 02:52:39,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:39,446 INFO:     Epoch: 63
2023-01-04 02:52:41,028 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42125803728898364, 'Total loss': 0.42125803728898364} | train loss {'Reaction outcome loss': 0.19511194571668466, 'Total loss': 0.19511194571668466}
2023-01-04 02:52:41,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:41,028 INFO:     Epoch: 64
2023-01-04 02:52:42,632 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3629006415605545, 'Total loss': 0.3629006415605545} | train loss {'Reaction outcome loss': 0.192043658550624, 'Total loss': 0.192043658550624}
2023-01-04 02:52:42,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:42,633 INFO:     Epoch: 65
2023-01-04 02:52:44,218 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3721254905064901, 'Total loss': 0.3721254905064901} | train loss {'Reaction outcome loss': 0.19185751987682595, 'Total loss': 0.19185751987682595}
2023-01-04 02:52:44,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:44,218 INFO:     Epoch: 66
2023-01-04 02:52:45,828 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33797311037778854, 'Total loss': 0.33797311037778854} | train loss {'Reaction outcome loss': 0.19245719691335936, 'Total loss': 0.19245719691335936}
2023-01-04 02:52:45,828 INFO:     Found new best model at epoch 66
2023-01-04 02:52:45,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:45,829 INFO:     Epoch: 67
2023-01-04 02:52:47,407 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3471328889330228, 'Total loss': 0.3471328889330228} | train loss {'Reaction outcome loss': 0.190814087344777, 'Total loss': 0.190814087344777}
2023-01-04 02:52:47,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:47,407 INFO:     Epoch: 68
2023-01-04 02:52:48,981 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3666543076435725, 'Total loss': 0.3666543076435725} | train loss {'Reaction outcome loss': 0.1885676136847599, 'Total loss': 0.1885676136847599}
2023-01-04 02:52:48,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:48,982 INFO:     Epoch: 69
2023-01-04 02:52:50,551 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3694955398639043, 'Total loss': 0.3694955398639043} | train loss {'Reaction outcome loss': 0.187259593384934, 'Total loss': 0.187259593384934}
2023-01-04 02:52:50,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:50,552 INFO:     Epoch: 70
2023-01-04 02:52:52,135 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3489094540476799, 'Total loss': 0.3489094540476799} | train loss {'Reaction outcome loss': 0.18463027552977007, 'Total loss': 0.18463027552977007}
2023-01-04 02:52:52,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:52,136 INFO:     Epoch: 71
2023-01-04 02:52:53,713 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3681574861208598, 'Total loss': 0.3681574861208598} | train loss {'Reaction outcome loss': 0.18591955206578686, 'Total loss': 0.18591955206578686}
2023-01-04 02:52:53,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:53,713 INFO:     Epoch: 72
2023-01-04 02:52:55,291 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3520988201101621, 'Total loss': 0.3520988201101621} | train loss {'Reaction outcome loss': 0.18434176730476456, 'Total loss': 0.18434176730476456}
2023-01-04 02:52:55,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:55,291 INFO:     Epoch: 73
2023-01-04 02:52:56,870 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3577552154660225, 'Total loss': 0.3577552154660225} | train loss {'Reaction outcome loss': 0.18211835036020138, 'Total loss': 0.18211835036020138}
2023-01-04 02:52:56,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:56,870 INFO:     Epoch: 74
2023-01-04 02:52:58,448 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36938605904579164, 'Total loss': 0.36938605904579164} | train loss {'Reaction outcome loss': 0.18358134749881078, 'Total loss': 0.18358134749881078}
2023-01-04 02:52:58,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:52:58,449 INFO:     Epoch: 75
2023-01-04 02:53:00,008 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37434998552004495, 'Total loss': 0.37434998552004495} | train loss {'Reaction outcome loss': 0.1835904544690153, 'Total loss': 0.1835904544690153}
2023-01-04 02:53:00,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:00,010 INFO:     Epoch: 76
2023-01-04 02:53:01,569 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3815098931392034, 'Total loss': 0.3815098931392034} | train loss {'Reaction outcome loss': 0.18234704133300556, 'Total loss': 0.18234704133300556}
2023-01-04 02:53:01,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:01,569 INFO:     Epoch: 77
2023-01-04 02:53:03,145 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40477393865585326, 'Total loss': 0.40477393865585326} | train loss {'Reaction outcome loss': 0.18090356735089597, 'Total loss': 0.18090356735089597}
2023-01-04 02:53:03,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:03,146 INFO:     Epoch: 78
2023-01-04 02:53:04,752 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35175318320592247, 'Total loss': 0.35175318320592247} | train loss {'Reaction outcome loss': 0.17925759099232844, 'Total loss': 0.17925759099232844}
2023-01-04 02:53:04,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:04,752 INFO:     Epoch: 79
2023-01-04 02:53:06,364 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36622079014778136, 'Total loss': 0.36622079014778136} | train loss {'Reaction outcome loss': 0.17992373353941538, 'Total loss': 0.17992373353941538}
2023-01-04 02:53:06,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:06,365 INFO:     Epoch: 80
2023-01-04 02:53:07,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3516830856601397, 'Total loss': 0.3516830856601397} | train loss {'Reaction outcome loss': 0.17842088030453349, 'Total loss': 0.17842088030453349}
2023-01-04 02:53:07,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:07,937 INFO:     Epoch: 81
2023-01-04 02:53:09,552 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37330489059289296, 'Total loss': 0.37330489059289296} | train loss {'Reaction outcome loss': 0.1772467743455272, 'Total loss': 0.1772467743455272}
2023-01-04 02:53:09,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:09,552 INFO:     Epoch: 82
2023-01-04 02:53:11,105 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3645477289954821, 'Total loss': 0.3645477289954821} | train loss {'Reaction outcome loss': 0.1760205959000594, 'Total loss': 0.1760205959000594}
2023-01-04 02:53:11,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:11,105 INFO:     Epoch: 83
2023-01-04 02:53:12,707 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35381347984075545, 'Total loss': 0.35381347984075545} | train loss {'Reaction outcome loss': 0.17410925731417679, 'Total loss': 0.17410925731417679}
2023-01-04 02:53:12,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:12,707 INFO:     Epoch: 84
2023-01-04 02:53:14,276 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3688090960184733, 'Total loss': 0.3688090960184733} | train loss {'Reaction outcome loss': 0.17609832164295863, 'Total loss': 0.17609832164295863}
2023-01-04 02:53:14,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:14,276 INFO:     Epoch: 85
2023-01-04 02:53:15,875 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3710730582475662, 'Total loss': 0.3710730582475662} | train loss {'Reaction outcome loss': 0.1727586256019471, 'Total loss': 0.1727586256019471}
2023-01-04 02:53:15,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:15,875 INFO:     Epoch: 86
2023-01-04 02:53:17,430 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3709484005967776, 'Total loss': 0.3709484005967776} | train loss {'Reaction outcome loss': 0.17358304637965266, 'Total loss': 0.17358304637965266}
2023-01-04 02:53:17,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:17,430 INFO:     Epoch: 87
2023-01-04 02:53:18,990 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3562033444643021, 'Total loss': 0.3562033444643021} | train loss {'Reaction outcome loss': 0.1742965078643172, 'Total loss': 0.1742965078643172}
2023-01-04 02:53:18,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:18,991 INFO:     Epoch: 88
2023-01-04 02:53:20,569 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35023448020219805, 'Total loss': 0.35023448020219805} | train loss {'Reaction outcome loss': 0.17076749638432548, 'Total loss': 0.17076749638432548}
2023-01-04 02:53:20,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:20,569 INFO:     Epoch: 89
2023-01-04 02:53:22,148 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36773035128911336, 'Total loss': 0.36773035128911336} | train loss {'Reaction outcome loss': 0.17046246974432205, 'Total loss': 0.17046246974432205}
2023-01-04 02:53:22,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:22,148 INFO:     Epoch: 90
2023-01-04 02:53:23,726 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38562440474828086, 'Total loss': 0.38562440474828086} | train loss {'Reaction outcome loss': 0.17216894298027724, 'Total loss': 0.17216894298027724}
2023-01-04 02:53:23,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:23,726 INFO:     Epoch: 91
2023-01-04 02:53:25,304 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36331669290860497, 'Total loss': 0.36331669290860497} | train loss {'Reaction outcome loss': 0.16969230453118736, 'Total loss': 0.16969230453118736}
2023-01-04 02:53:25,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:25,304 INFO:     Epoch: 92
2023-01-04 02:53:26,864 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3927749832471212, 'Total loss': 0.3927749832471212} | train loss {'Reaction outcome loss': 0.1673999547740042, 'Total loss': 0.1673999547740042}
2023-01-04 02:53:26,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:26,865 INFO:     Epoch: 93
2023-01-04 02:53:28,427 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3840494856238365, 'Total loss': 0.3840494856238365} | train loss {'Reaction outcome loss': 0.17031202552628605, 'Total loss': 0.17031202552628605}
2023-01-04 02:53:28,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:28,427 INFO:     Epoch: 94
2023-01-04 02:53:30,006 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36517203971743584, 'Total loss': 0.36517203971743584} | train loss {'Reaction outcome loss': 0.1672247297986796, 'Total loss': 0.1672247297986796}
2023-01-04 02:53:30,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:30,007 INFO:     Epoch: 95
2023-01-04 02:53:31,615 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3892649352550507, 'Total loss': 0.3892649352550507} | train loss {'Reaction outcome loss': 0.16850596406384483, 'Total loss': 0.16850596406384483}
2023-01-04 02:53:31,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:31,616 INFO:     Epoch: 96
2023-01-04 02:53:33,216 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3831698457400004, 'Total loss': 0.3831698457400004} | train loss {'Reaction outcome loss': 0.16663595100851122, 'Total loss': 0.16663595100851122}
2023-01-04 02:53:33,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:33,216 INFO:     Epoch: 97
2023-01-04 02:53:34,794 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38331740647554396, 'Total loss': 0.38331740647554396} | train loss {'Reaction outcome loss': 0.16487469444999764, 'Total loss': 0.16487469444999764}
2023-01-04 02:53:34,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:34,794 INFO:     Epoch: 98
2023-01-04 02:53:36,401 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36509431103865303, 'Total loss': 0.36509431103865303} | train loss {'Reaction outcome loss': 0.16582356412441301, 'Total loss': 0.16582356412441301}
2023-01-04 02:53:36,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:36,401 INFO:     Epoch: 99
2023-01-04 02:53:37,965 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3678302938739459, 'Total loss': 0.3678302938739459} | train loss {'Reaction outcome loss': 0.1662929660330216, 'Total loss': 0.1662929660330216}
2023-01-04 02:53:37,965 INFO:     Best model found after epoch 67 of 100.
2023-01-04 02:53:37,965 INFO:   Done with stage: TRAINING
2023-01-04 02:53:37,965 INFO:   Starting stage: EVALUATION
2023-01-04 02:53:38,106 INFO:   Done with stage: EVALUATION
2023-01-04 02:53:38,106 INFO:   Leaving out SEQ value Fold_9
2023-01-04 02:53:38,119 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 02:53:38,119 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:53:38,773 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:53:38,773 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:53:38,844 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:53:38,844 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:53:38,844 INFO:     No hyperparam tuning for this model
2023-01-04 02:53:38,844 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:53:38,844 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:53:38,845 INFO:     None feature selector for col prot
2023-01-04 02:53:38,845 INFO:     None feature selector for col prot
2023-01-04 02:53:38,845 INFO:     None feature selector for col prot
2023-01-04 02:53:38,846 INFO:     None feature selector for col chem
2023-01-04 02:53:38,846 INFO:     None feature selector for col chem
2023-01-04 02:53:38,846 INFO:     None feature selector for col chem
2023-01-04 02:53:38,846 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:53:38,846 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:53:38,847 INFO:     Number of params in model 70141
2023-01-04 02:53:38,850 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:53:38,850 INFO:   Starting stage: TRAINING
2023-01-04 02:53:38,895 INFO:     Val loss before train {'Reaction outcome loss': 0.9766175111134847, 'Total loss': 0.9766175111134847}
2023-01-04 02:53:38,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:38,895 INFO:     Epoch: 0
2023-01-04 02:53:40,517 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6884175101915996, 'Total loss': 0.6884175101915996} | train loss {'Reaction outcome loss': 0.8673296890319039, 'Total loss': 0.8673296890319039}
2023-01-04 02:53:40,517 INFO:     Found new best model at epoch 0
2023-01-04 02:53:40,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:40,518 INFO:     Epoch: 1
2023-01-04 02:53:42,147 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5607559541861217, 'Total loss': 0.5607559541861217} | train loss {'Reaction outcome loss': 0.6405100420063583, 'Total loss': 0.6405100420063583}
2023-01-04 02:53:42,147 INFO:     Found new best model at epoch 1
2023-01-04 02:53:42,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:42,148 INFO:     Epoch: 2
2023-01-04 02:53:43,747 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5119202733039856, 'Total loss': 0.5119202733039856} | train loss {'Reaction outcome loss': 0.5557206789509054, 'Total loss': 0.5557206789509054}
2023-01-04 02:53:43,747 INFO:     Found new best model at epoch 2
2023-01-04 02:53:43,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:43,748 INFO:     Epoch: 3
2023-01-04 02:53:45,336 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4799397607644399, 'Total loss': 0.4799397607644399} | train loss {'Reaction outcome loss': 0.5086576740664265, 'Total loss': 0.5086576740664265}
2023-01-04 02:53:45,336 INFO:     Found new best model at epoch 3
2023-01-04 02:53:45,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:45,337 INFO:     Epoch: 4
2023-01-04 02:53:46,962 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4655235250790914, 'Total loss': 0.4655235250790914} | train loss {'Reaction outcome loss': 0.47622983249085904, 'Total loss': 0.47622983249085904}
2023-01-04 02:53:46,962 INFO:     Found new best model at epoch 4
2023-01-04 02:53:46,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:46,963 INFO:     Epoch: 5
2023-01-04 02:53:48,555 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4499176383018494, 'Total loss': 0.4499176383018494} | train loss {'Reaction outcome loss': 0.45218187688920475, 'Total loss': 0.45218187688920475}
2023-01-04 02:53:48,555 INFO:     Found new best model at epoch 5
2023-01-04 02:53:48,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:48,556 INFO:     Epoch: 6
2023-01-04 02:53:50,176 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4276847223440806, 'Total loss': 0.4276847223440806} | train loss {'Reaction outcome loss': 0.43422105122989696, 'Total loss': 0.43422105122989696}
2023-01-04 02:53:50,176 INFO:     Found new best model at epoch 6
2023-01-04 02:53:50,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:50,177 INFO:     Epoch: 7
2023-01-04 02:53:51,791 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42969468533992766, 'Total loss': 0.42969468533992766} | train loss {'Reaction outcome loss': 0.4197229329859737, 'Total loss': 0.4197229329859737}
2023-01-04 02:53:51,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:51,791 INFO:     Epoch: 8
2023-01-04 02:53:53,377 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41452224204937616, 'Total loss': 0.41452224204937616} | train loss {'Reaction outcome loss': 0.4068023334879307, 'Total loss': 0.4068023334879307}
2023-01-04 02:53:53,377 INFO:     Found new best model at epoch 8
2023-01-04 02:53:53,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:53,378 INFO:     Epoch: 9
2023-01-04 02:53:54,969 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4120856901009878, 'Total loss': 0.4120856901009878} | train loss {'Reaction outcome loss': 0.3970340200656158, 'Total loss': 0.3970340200656158}
2023-01-04 02:53:54,969 INFO:     Found new best model at epoch 9
2023-01-04 02:53:54,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:54,970 INFO:     Epoch: 10
2023-01-04 02:53:56,569 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40053927501042685, 'Total loss': 0.40053927501042685} | train loss {'Reaction outcome loss': 0.38582952223745065, 'Total loss': 0.38582952223745065}
2023-01-04 02:53:56,569 INFO:     Found new best model at epoch 10
2023-01-04 02:53:56,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:56,570 INFO:     Epoch: 11
2023-01-04 02:53:58,169 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4038594166437785, 'Total loss': 0.4038594166437785} | train loss {'Reaction outcome loss': 0.3743529499437835, 'Total loss': 0.3743529499437835}
2023-01-04 02:53:58,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:58,169 INFO:     Epoch: 12
2023-01-04 02:53:59,768 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3968004157145818, 'Total loss': 0.3968004157145818} | train loss {'Reaction outcome loss': 0.3686115028410612, 'Total loss': 0.3686115028410612}
2023-01-04 02:53:59,768 INFO:     Found new best model at epoch 12
2023-01-04 02:53:59,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:53:59,769 INFO:     Epoch: 13
2023-01-04 02:54:01,351 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4039109140634537, 'Total loss': 0.4039109140634537} | train loss {'Reaction outcome loss': 0.36256926692349817, 'Total loss': 0.36256926692349817}
2023-01-04 02:54:01,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:01,352 INFO:     Epoch: 14
2023-01-04 02:54:02,980 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39138441185156503, 'Total loss': 0.39138441185156503} | train loss {'Reaction outcome loss': 0.3577272509517222, 'Total loss': 0.3577272509517222}
2023-01-04 02:54:02,980 INFO:     Found new best model at epoch 14
2023-01-04 02:54:02,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:02,981 INFO:     Epoch: 15
2023-01-04 02:54:04,569 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3904431571563085, 'Total loss': 0.3904431571563085} | train loss {'Reaction outcome loss': 0.3518614023385926, 'Total loss': 0.3518614023385926}
2023-01-04 02:54:04,569 INFO:     Found new best model at epoch 15
2023-01-04 02:54:04,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:04,570 INFO:     Epoch: 16
2023-01-04 02:54:06,169 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39847913682460784, 'Total loss': 0.39847913682460784} | train loss {'Reaction outcome loss': 0.34163098096417177, 'Total loss': 0.34163098096417177}
2023-01-04 02:54:06,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:06,170 INFO:     Epoch: 17
2023-01-04 02:54:07,802 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39498254855473836, 'Total loss': 0.39498254855473836} | train loss {'Reaction outcome loss': 0.3377310289103632, 'Total loss': 0.3377310289103632}
2023-01-04 02:54:07,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:07,802 INFO:     Epoch: 18
2023-01-04 02:54:09,426 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38475995461146034, 'Total loss': 0.38475995461146034} | train loss {'Reaction outcome loss': 0.33095568133390335, 'Total loss': 0.33095568133390335}
2023-01-04 02:54:09,426 INFO:     Found new best model at epoch 18
2023-01-04 02:54:09,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:09,427 INFO:     Epoch: 19
2023-01-04 02:54:11,020 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38722776571909584, 'Total loss': 0.38722776571909584} | train loss {'Reaction outcome loss': 0.32666069702228484, 'Total loss': 0.32666069702228484}
2023-01-04 02:54:11,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:11,021 INFO:     Epoch: 20
2023-01-04 02:54:12,614 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39596636792023976, 'Total loss': 0.39596636792023976} | train loss {'Reaction outcome loss': 0.32250872571760997, 'Total loss': 0.32250872571760997}
2023-01-04 02:54:12,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:12,615 INFO:     Epoch: 21
2023-01-04 02:54:14,199 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3907886485258738, 'Total loss': 0.3907886485258738} | train loss {'Reaction outcome loss': 0.31856598632430344, 'Total loss': 0.31856598632430344}
2023-01-04 02:54:14,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:14,200 INFO:     Epoch: 22
2023-01-04 02:54:15,824 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38240588903427125, 'Total loss': 0.38240588903427125} | train loss {'Reaction outcome loss': 0.31177908273595334, 'Total loss': 0.31177908273595334}
2023-01-04 02:54:15,824 INFO:     Found new best model at epoch 22
2023-01-04 02:54:15,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:15,825 INFO:     Epoch: 23
2023-01-04 02:54:17,434 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.381916872660319, 'Total loss': 0.381916872660319} | train loss {'Reaction outcome loss': 0.30918217173337076, 'Total loss': 0.30918217173337076}
2023-01-04 02:54:17,434 INFO:     Found new best model at epoch 23
2023-01-04 02:54:17,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:17,435 INFO:     Epoch: 24
2023-01-04 02:54:19,047 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3893433670202891, 'Total loss': 0.3893433670202891} | train loss {'Reaction outcome loss': 0.3042496215511746, 'Total loss': 0.3042496215511746}
2023-01-04 02:54:19,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:19,047 INFO:     Epoch: 25
2023-01-04 02:54:20,664 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40265344580014545, 'Total loss': 0.40265344580014545} | train loss {'Reaction outcome loss': 0.30033407305175647, 'Total loss': 0.30033407305175647}
2023-01-04 02:54:20,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:20,664 INFO:     Epoch: 26
2023-01-04 02:54:22,252 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.406061597665151, 'Total loss': 0.406061597665151} | train loss {'Reaction outcome loss': 0.29421703670752175, 'Total loss': 0.29421703670752175}
2023-01-04 02:54:22,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:22,252 INFO:     Epoch: 27
2023-01-04 02:54:23,853 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37931281626224517, 'Total loss': 0.37931281626224517} | train loss {'Reaction outcome loss': 0.29250027166699677, 'Total loss': 0.29250027166699677}
2023-01-04 02:54:23,853 INFO:     Found new best model at epoch 27
2023-01-04 02:54:23,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:23,854 INFO:     Epoch: 28
2023-01-04 02:54:25,453 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3840445508559545, 'Total loss': 0.3840445508559545} | train loss {'Reaction outcome loss': 0.2874607405077249, 'Total loss': 0.2874607405077249}
2023-01-04 02:54:25,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:25,454 INFO:     Epoch: 29
2023-01-04 02:54:27,055 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.385241570075353, 'Total loss': 0.385241570075353} | train loss {'Reaction outcome loss': 0.2857818425454818, 'Total loss': 0.2857818425454818}
2023-01-04 02:54:27,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:27,055 INFO:     Epoch: 30
2023-01-04 02:54:28,636 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3866198152303696, 'Total loss': 0.3866198152303696} | train loss {'Reaction outcome loss': 0.2791381390355124, 'Total loss': 0.2791381390355124}
2023-01-04 02:54:28,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:28,637 INFO:     Epoch: 31
2023-01-04 02:54:30,221 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40027804573376974, 'Total loss': 0.40027804573376974} | train loss {'Reaction outcome loss': 0.277986266525859, 'Total loss': 0.277986266525859}
2023-01-04 02:54:30,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:30,221 INFO:     Epoch: 32
2023-01-04 02:54:31,820 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39412354727586113, 'Total loss': 0.39412354727586113} | train loss {'Reaction outcome loss': 0.2761429354602249, 'Total loss': 0.2761429354602249}
2023-01-04 02:54:31,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:31,820 INFO:     Epoch: 33
2023-01-04 02:54:33,419 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39167172412077583, 'Total loss': 0.39167172412077583} | train loss {'Reaction outcome loss': 0.2716735885999693, 'Total loss': 0.2716735885999693}
2023-01-04 02:54:33,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:33,420 INFO:     Epoch: 34
2023-01-04 02:54:35,019 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.415580490231514, 'Total loss': 0.415580490231514} | train loss {'Reaction outcome loss': 0.26999764109454, 'Total loss': 0.26999764109454}
2023-01-04 02:54:35,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:35,019 INFO:     Epoch: 35
2023-01-04 02:54:36,620 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38556876381238303, 'Total loss': 0.38556876381238303} | train loss {'Reaction outcome loss': 0.26643477732631704, 'Total loss': 0.26643477732631704}
2023-01-04 02:54:36,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:36,621 INFO:     Epoch: 36
2023-01-04 02:54:38,202 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3921995182832082, 'Total loss': 0.3921995182832082} | train loss {'Reaction outcome loss': 0.26403678803022157, 'Total loss': 0.26403678803022157}
2023-01-04 02:54:38,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:38,203 INFO:     Epoch: 37
2023-01-04 02:54:39,797 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4014963090419769, 'Total loss': 0.4014963090419769} | train loss {'Reaction outcome loss': 0.2601863423678419, 'Total loss': 0.2601863423678419}
2023-01-04 02:54:39,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:39,797 INFO:     Epoch: 38
2023-01-04 02:54:41,424 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40821245114008586, 'Total loss': 0.40821245114008586} | train loss {'Reaction outcome loss': 0.2588319645300239, 'Total loss': 0.2588319645300239}
2023-01-04 02:54:41,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:41,424 INFO:     Epoch: 39
2023-01-04 02:54:43,045 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3888419300317764, 'Total loss': 0.3888419300317764} | train loss {'Reaction outcome loss': 0.2590546074999153, 'Total loss': 0.2590546074999153}
2023-01-04 02:54:43,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:43,046 INFO:     Epoch: 40
2023-01-04 02:54:44,660 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39850826760133107, 'Total loss': 0.39850826760133107} | train loss {'Reaction outcome loss': 0.25232612209845107, 'Total loss': 0.25232612209845107}
2023-01-04 02:54:44,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:44,660 INFO:     Epoch: 41
2023-01-04 02:54:46,237 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40172581672668456, 'Total loss': 0.40172581672668456} | train loss {'Reaction outcome loss': 0.25479123617660265, 'Total loss': 0.25479123617660265}
2023-01-04 02:54:46,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:46,238 INFO:     Epoch: 42
2023-01-04 02:54:47,861 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39568285743395487, 'Total loss': 0.39568285743395487} | train loss {'Reaction outcome loss': 0.2505303666345264, 'Total loss': 0.2505303666345264}
2023-01-04 02:54:47,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:47,861 INFO:     Epoch: 43
2023-01-04 02:54:49,454 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3889862676461538, 'Total loss': 0.3889862676461538} | train loss {'Reaction outcome loss': 0.24761049141468555, 'Total loss': 0.24761049141468555}
2023-01-04 02:54:49,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:49,455 INFO:     Epoch: 44
2023-01-04 02:54:51,056 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39796321193377177, 'Total loss': 0.39796321193377177} | train loss {'Reaction outcome loss': 0.24586890301657066, 'Total loss': 0.24586890301657066}
2023-01-04 02:54:51,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:51,056 INFO:     Epoch: 45
2023-01-04 02:54:52,657 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4064368595679601, 'Total loss': 0.4064368595679601} | train loss {'Reaction outcome loss': 0.24134528569688865, 'Total loss': 0.24134528569688865}
2023-01-04 02:54:52,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:52,657 INFO:     Epoch: 46
2023-01-04 02:54:54,261 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39958886007467903, 'Total loss': 0.39958886007467903} | train loss {'Reaction outcome loss': 0.24178204463546027, 'Total loss': 0.24178204463546027}
2023-01-04 02:54:54,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:54,261 INFO:     Epoch: 47
2023-01-04 02:54:55,836 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4069288412729899, 'Total loss': 0.4069288412729899} | train loss {'Reaction outcome loss': 0.23886466135240633, 'Total loss': 0.23886466135240633}
2023-01-04 02:54:55,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:55,837 INFO:     Epoch: 48
2023-01-04 02:54:57,416 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38985544939835864, 'Total loss': 0.38985544939835864} | train loss {'Reaction outcome loss': 0.2378868806219596, 'Total loss': 0.2378868806219596}
2023-01-04 02:54:57,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:57,417 INFO:     Epoch: 49
2023-01-04 02:54:59,015 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40564753115177155, 'Total loss': 0.40564753115177155} | train loss {'Reaction outcome loss': 0.23460215297847017, 'Total loss': 0.23460215297847017}
2023-01-04 02:54:59,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:54:59,015 INFO:     Epoch: 50
2023-01-04 02:55:00,613 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.380210121969382, 'Total loss': 0.380210121969382} | train loss {'Reaction outcome loss': 0.23303931964971528, 'Total loss': 0.23303931964971528}
2023-01-04 02:55:00,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:00,613 INFO:     Epoch: 51
2023-01-04 02:55:02,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38330399990081787, 'Total loss': 0.38330399990081787} | train loss {'Reaction outcome loss': 0.2350222760750929, 'Total loss': 0.2350222760750929}
2023-01-04 02:55:02,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:02,211 INFO:     Epoch: 52
2023-01-04 02:55:03,782 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3757820645968119, 'Total loss': 0.3757820645968119} | train loss {'Reaction outcome loss': 0.22979215594405303, 'Total loss': 0.22979215594405303}
2023-01-04 02:55:03,782 INFO:     Found new best model at epoch 52
2023-01-04 02:55:03,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:03,783 INFO:     Epoch: 53
2023-01-04 02:55:04,852 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40345451633135476, 'Total loss': 0.40345451633135476} | train loss {'Reaction outcome loss': 0.22709987046271024, 'Total loss': 0.22709987046271024}
2023-01-04 02:55:04,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:04,852 INFO:     Epoch: 54
2023-01-04 02:55:05,931 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37711390455563865, 'Total loss': 0.37711390455563865} | train loss {'Reaction outcome loss': 0.22880494427810077, 'Total loss': 0.22880494427810077}
2023-01-04 02:55:05,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:05,932 INFO:     Epoch: 55
2023-01-04 02:55:07,035 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3937849670648575, 'Total loss': 0.3937849670648575} | train loss {'Reaction outcome loss': 0.2260818672685847, 'Total loss': 0.2260818672685847}
2023-01-04 02:55:07,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:07,035 INFO:     Epoch: 56
2023-01-04 02:55:08,257 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3937860161066055, 'Total loss': 0.3937860161066055} | train loss {'Reaction outcome loss': 0.22546120306698855, 'Total loss': 0.22546120306698855}
2023-01-04 02:55:08,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:08,257 INFO:     Epoch: 57
2023-01-04 02:55:09,885 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3930824637413025, 'Total loss': 0.3930824637413025} | train loss {'Reaction outcome loss': 0.2234617627565396, 'Total loss': 0.2234617627565396}
2023-01-04 02:55:09,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:09,885 INFO:     Epoch: 58
2023-01-04 02:55:11,502 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40478269855181376, 'Total loss': 0.40478269855181376} | train loss {'Reaction outcome loss': 0.21900684259401548, 'Total loss': 0.21900684259401548}
2023-01-04 02:55:11,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:11,502 INFO:     Epoch: 59
2023-01-04 02:55:13,100 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3972772811849912, 'Total loss': 0.3972772811849912} | train loss {'Reaction outcome loss': 0.2205926801484845, 'Total loss': 0.2205926801484845}
2023-01-04 02:55:13,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:13,102 INFO:     Epoch: 60
2023-01-04 02:55:14,696 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40497103134791057, 'Total loss': 0.40497103134791057} | train loss {'Reaction outcome loss': 0.21771359831659587, 'Total loss': 0.21771359831659587}
2023-01-04 02:55:14,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:14,696 INFO:     Epoch: 61
2023-01-04 02:55:16,292 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39522659182548525, 'Total loss': 0.39522659182548525} | train loss {'Reaction outcome loss': 0.21778601841052947, 'Total loss': 0.21778601841052947}
2023-01-04 02:55:16,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:16,292 INFO:     Epoch: 62
2023-01-04 02:55:17,893 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39204021990299226, 'Total loss': 0.39204021990299226} | train loss {'Reaction outcome loss': 0.21753533236978287, 'Total loss': 0.21753533236978287}
2023-01-04 02:55:17,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:17,893 INFO:     Epoch: 63
2023-01-04 02:55:19,517 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3930287405848503, 'Total loss': 0.3930287405848503} | train loss {'Reaction outcome loss': 0.21575639948302658, 'Total loss': 0.21575639948302658}
2023-01-04 02:55:19,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:19,517 INFO:     Epoch: 64
2023-01-04 02:55:21,139 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.404596583545208, 'Total loss': 0.404596583545208} | train loss {'Reaction outcome loss': 0.21197580607332261, 'Total loss': 0.21197580607332261}
2023-01-04 02:55:21,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:21,139 INFO:     Epoch: 65
2023-01-04 02:55:22,744 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3923790787657102, 'Total loss': 0.3923790787657102} | train loss {'Reaction outcome loss': 0.21327200560201806, 'Total loss': 0.21327200560201806}
2023-01-04 02:55:22,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:22,745 INFO:     Epoch: 66
2023-01-04 02:55:24,373 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4057049701611201, 'Total loss': 0.4057049701611201} | train loss {'Reaction outcome loss': 0.2111791859881865, 'Total loss': 0.2111791859881865}
2023-01-04 02:55:24,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:24,373 INFO:     Epoch: 67
2023-01-04 02:55:25,962 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38427370389302573, 'Total loss': 0.38427370389302573} | train loss {'Reaction outcome loss': 0.20834162335049375, 'Total loss': 0.20834162335049375}
2023-01-04 02:55:25,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:25,963 INFO:     Epoch: 68
2023-01-04 02:55:27,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4241217782100042, 'Total loss': 0.4241217782100042} | train loss {'Reaction outcome loss': 0.2066419298226007, 'Total loss': 0.2066419298226007}
2023-01-04 02:55:27,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:27,576 INFO:     Epoch: 69
2023-01-04 02:55:29,200 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.410535940527916, 'Total loss': 0.410535940527916} | train loss {'Reaction outcome loss': 0.20707604146498634, 'Total loss': 0.20707604146498634}
2023-01-04 02:55:29,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:29,200 INFO:     Epoch: 70
2023-01-04 02:55:30,807 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3855217734972636, 'Total loss': 0.3855217734972636} | train loss {'Reaction outcome loss': 0.20733218660262087, 'Total loss': 0.20733218660262087}
2023-01-04 02:55:30,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:30,807 INFO:     Epoch: 71
2023-01-04 02:55:32,405 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4055003295342127, 'Total loss': 0.4055003295342127} | train loss {'Reaction outcome loss': 0.20517916014478524, 'Total loss': 0.20517916014478524}
2023-01-04 02:55:32,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:32,406 INFO:     Epoch: 72
2023-01-04 02:55:34,018 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3759812980890274, 'Total loss': 0.3759812980890274} | train loss {'Reaction outcome loss': 0.2026004477905022, 'Total loss': 0.2026004477905022}
2023-01-04 02:55:34,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:34,019 INFO:     Epoch: 73
2023-01-04 02:55:35,603 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3875594784816106, 'Total loss': 0.3875594784816106} | train loss {'Reaction outcome loss': 0.20321093139235294, 'Total loss': 0.20321093139235294}
2023-01-04 02:55:35,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:35,604 INFO:     Epoch: 74
2023-01-04 02:55:37,203 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3925595134496689, 'Total loss': 0.3925595134496689} | train loss {'Reaction outcome loss': 0.20466590925566985, 'Total loss': 0.20466590925566985}
2023-01-04 02:55:37,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:37,204 INFO:     Epoch: 75
2023-01-04 02:55:38,800 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3987979571024577, 'Total loss': 0.3987979571024577} | train loss {'Reaction outcome loss': 0.20145106981323513, 'Total loss': 0.20145106981323513}
2023-01-04 02:55:38,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:38,800 INFO:     Epoch: 76
2023-01-04 02:55:40,381 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4148350218931834, 'Total loss': 0.4148350218931834} | train loss {'Reaction outcome loss': 0.2010094583411079, 'Total loss': 0.2010094583411079}
2023-01-04 02:55:40,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:40,381 INFO:     Epoch: 77
2023-01-04 02:55:41,988 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40763761003812155, 'Total loss': 0.40763761003812155} | train loss {'Reaction outcome loss': 0.1970767035898803, 'Total loss': 0.1970767035898803}
2023-01-04 02:55:41,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:41,988 INFO:     Epoch: 78
2023-01-04 02:55:43,608 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3964182734489441, 'Total loss': 0.3964182734489441} | train loss {'Reaction outcome loss': 0.19625904821935328, 'Total loss': 0.19625904821935328}
2023-01-04 02:55:43,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:43,610 INFO:     Epoch: 79
2023-01-04 02:55:45,208 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38190524727106095, 'Total loss': 0.38190524727106095} | train loss {'Reaction outcome loss': 0.19586248710643944, 'Total loss': 0.19586248710643944}
2023-01-04 02:55:45,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:45,208 INFO:     Epoch: 80
2023-01-04 02:55:46,830 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40866957704226176, 'Total loss': 0.40866957704226176} | train loss {'Reaction outcome loss': 0.19693598514321908, 'Total loss': 0.19693598514321908}
2023-01-04 02:55:46,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:46,830 INFO:     Epoch: 81
2023-01-04 02:55:48,447 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3785462240378062, 'Total loss': 0.3785462240378062} | train loss {'Reaction outcome loss': 0.19492874589045986, 'Total loss': 0.19492874589045986}
2023-01-04 02:55:48,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:48,447 INFO:     Epoch: 82
2023-01-04 02:55:50,049 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.399887345234553, 'Total loss': 0.399887345234553} | train loss {'Reaction outcome loss': 0.19184803459726085, 'Total loss': 0.19184803459726085}
2023-01-04 02:55:50,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:50,049 INFO:     Epoch: 83
2023-01-04 02:55:51,662 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4130898594856262, 'Total loss': 0.4130898594856262} | train loss {'Reaction outcome loss': 0.19137370334904547, 'Total loss': 0.19137370334904547}
2023-01-04 02:55:51,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:51,663 INFO:     Epoch: 84
2023-01-04 02:55:53,268 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42015841901302337, 'Total loss': 0.42015841901302337} | train loss {'Reaction outcome loss': 0.19173828195040837, 'Total loss': 0.19173828195040837}
2023-01-04 02:55:53,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:53,268 INFO:     Epoch: 85
2023-01-04 02:55:54,893 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3858649348219236, 'Total loss': 0.3858649348219236} | train loss {'Reaction outcome loss': 0.19128967313237139, 'Total loss': 0.19128967313237139}
2023-01-04 02:55:54,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:54,893 INFO:     Epoch: 86
2023-01-04 02:55:56,476 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39233429233233136, 'Total loss': 0.39233429233233136} | train loss {'Reaction outcome loss': 0.19026252647545794, 'Total loss': 0.19026252647545794}
2023-01-04 02:55:56,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:56,476 INFO:     Epoch: 87
2023-01-04 02:55:58,078 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40512725909550984, 'Total loss': 0.40512725909550984} | train loss {'Reaction outcome loss': 0.19057373655455637, 'Total loss': 0.19057373655455637}
2023-01-04 02:55:58,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:58,078 INFO:     Epoch: 88
2023-01-04 02:55:59,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38040793041388193, 'Total loss': 0.38040793041388193} | train loss {'Reaction outcome loss': 0.18611597097630106, 'Total loss': 0.18611597097630106}
2023-01-04 02:55:59,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:55:59,671 INFO:     Epoch: 89
2023-01-04 02:56:01,266 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40203170975049335, 'Total loss': 0.40203170975049335} | train loss {'Reaction outcome loss': 0.1872781054839653, 'Total loss': 0.1872781054839653}
2023-01-04 02:56:01,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:01,266 INFO:     Epoch: 90
2023-01-04 02:56:02,861 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37216173112392426, 'Total loss': 0.37216173112392426} | train loss {'Reaction outcome loss': 0.18610800475231792, 'Total loss': 0.18610800475231792}
2023-01-04 02:56:02,861 INFO:     Found new best model at epoch 90
2023-01-04 02:56:02,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:02,862 INFO:     Epoch: 91
2023-01-04 02:56:04,457 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37491700450579324, 'Total loss': 0.37491700450579324} | train loss {'Reaction outcome loss': 0.18656844000873368, 'Total loss': 0.18656844000873368}
2023-01-04 02:56:04,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:04,457 INFO:     Epoch: 92
2023-01-04 02:56:06,083 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4088011766473452, 'Total loss': 0.4088011766473452} | train loss {'Reaction outcome loss': 0.18591001329923365, 'Total loss': 0.18591001329923365}
2023-01-04 02:56:06,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:06,083 INFO:     Epoch: 93
2023-01-04 02:56:07,695 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.404401366909345, 'Total loss': 0.404401366909345} | train loss {'Reaction outcome loss': 0.1859757692590087, 'Total loss': 0.1859757692590087}
2023-01-04 02:56:07,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:07,696 INFO:     Epoch: 94
2023-01-04 02:56:09,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4030593246221542, 'Total loss': 0.4030593246221542} | train loss {'Reaction outcome loss': 0.1849965237430717, 'Total loss': 0.1849965237430717}
2023-01-04 02:56:09,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:09,318 INFO:     Epoch: 95
2023-01-04 02:56:10,940 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41081269284089406, 'Total loss': 0.41081269284089406} | train loss {'Reaction outcome loss': 0.18228444436881086, 'Total loss': 0.18228444436881086}
2023-01-04 02:56:10,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:10,940 INFO:     Epoch: 96
2023-01-04 02:56:12,553 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3860598385334015, 'Total loss': 0.3860598385334015} | train loss {'Reaction outcome loss': 0.18360601734060672, 'Total loss': 0.18360601734060672}
2023-01-04 02:56:12,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:12,554 INFO:     Epoch: 97
2023-01-04 02:56:14,175 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3941177745660146, 'Total loss': 0.3941177745660146} | train loss {'Reaction outcome loss': 0.18160353046892352, 'Total loss': 0.18160353046892352}
2023-01-04 02:56:14,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:14,176 INFO:     Epoch: 98
2023-01-04 02:56:15,782 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39915406008561455, 'Total loss': 0.39915406008561455} | train loss {'Reaction outcome loss': 0.1807363644975241, 'Total loss': 0.1807363644975241}
2023-01-04 02:56:15,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:15,782 INFO:     Epoch: 99
2023-01-04 02:56:17,404 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40561942557493846, 'Total loss': 0.40561942557493846} | train loss {'Reaction outcome loss': 0.18208947876596063, 'Total loss': 0.18208947876596063}
2023-01-04 02:56:17,404 INFO:     Best model found after epoch 91 of 100.
2023-01-04 02:56:17,404 INFO:   Done with stage: TRAINING
2023-01-04 02:56:17,404 INFO:   Starting stage: EVALUATION
2023-01-04 02:56:17,525 INFO:   Done with stage: EVALUATION
2023-01-04 02:56:17,533 INFO:   Leaving out SEQ value Fold_0
2023-01-04 02:56:17,546 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 02:56:17,546 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:56:18,192 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:56:18,192 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:56:18,260 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:56:18,260 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:56:18,260 INFO:     No hyperparam tuning for this model
2023-01-04 02:56:18,260 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:56:18,260 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:56:18,261 INFO:     None feature selector for col prot
2023-01-04 02:56:18,261 INFO:     None feature selector for col prot
2023-01-04 02:56:18,261 INFO:     None feature selector for col prot
2023-01-04 02:56:18,262 INFO:     None feature selector for col chem
2023-01-04 02:56:18,262 INFO:     None feature selector for col chem
2023-01-04 02:56:18,262 INFO:     None feature selector for col chem
2023-01-04 02:56:18,262 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:56:18,262 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:56:18,263 INFO:     Number of params in model 70141
2023-01-04 02:56:18,266 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:56:18,267 INFO:   Starting stage: TRAINING
2023-01-04 02:56:18,310 INFO:     Val loss before train {'Reaction outcome loss': 0.945472385485967, 'Total loss': 0.945472385485967}
2023-01-04 02:56:18,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:18,310 INFO:     Epoch: 0
2023-01-04 02:56:19,884 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5891000151634216, 'Total loss': 0.5891000151634216} | train loss {'Reaction outcome loss': 0.834441783203595, 'Total loss': 0.834441783203595}
2023-01-04 02:56:19,884 INFO:     Found new best model at epoch 0
2023-01-04 02:56:19,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:19,885 INFO:     Epoch: 1
2023-01-04 02:56:21,495 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5315305550893148, 'Total loss': 0.5315305550893148} | train loss {'Reaction outcome loss': 0.5805098272698082, 'Total loss': 0.5805098272698082}
2023-01-04 02:56:21,496 INFO:     Found new best model at epoch 1
2023-01-04 02:56:21,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:21,497 INFO:     Epoch: 2
2023-01-04 02:56:23,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4781658867994944, 'Total loss': 0.4781658867994944} | train loss {'Reaction outcome loss': 0.5087242687957875, 'Total loss': 0.5087242687957875}
2023-01-04 02:56:23,111 INFO:     Found new best model at epoch 2
2023-01-04 02:56:23,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:23,112 INFO:     Epoch: 3
2023-01-04 02:56:24,680 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46532648205757143, 'Total loss': 0.46532648205757143} | train loss {'Reaction outcome loss': 0.47172003919663635, 'Total loss': 0.47172003919663635}
2023-01-04 02:56:24,680 INFO:     Found new best model at epoch 3
2023-01-04 02:56:24,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:24,681 INFO:     Epoch: 4
2023-01-04 02:56:26,278 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44505611856778465, 'Total loss': 0.44505611856778465} | train loss {'Reaction outcome loss': 0.4486337751681592, 'Total loss': 0.4486337751681592}
2023-01-04 02:56:26,278 INFO:     Found new best model at epoch 4
2023-01-04 02:56:26,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:26,279 INFO:     Epoch: 5
2023-01-04 02:56:27,877 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4195259471734365, 'Total loss': 0.4195259471734365} | train loss {'Reaction outcome loss': 0.42994306348534167, 'Total loss': 0.42994306348534167}
2023-01-04 02:56:27,877 INFO:     Found new best model at epoch 5
2023-01-04 02:56:27,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:27,878 INFO:     Epoch: 6
2023-01-04 02:56:29,456 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4135341942310333, 'Total loss': 0.4135341942310333} | train loss {'Reaction outcome loss': 0.41679284807996475, 'Total loss': 0.41679284807996475}
2023-01-04 02:56:29,456 INFO:     Found new best model at epoch 6
2023-01-04 02:56:29,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:29,457 INFO:     Epoch: 7
2023-01-04 02:56:31,054 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39871369500954945, 'Total loss': 0.39871369500954945} | train loss {'Reaction outcome loss': 0.40335438462595147, 'Total loss': 0.40335438462595147}
2023-01-04 02:56:31,054 INFO:     Found new best model at epoch 7
2023-01-04 02:56:31,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:31,055 INFO:     Epoch: 8
2023-01-04 02:56:32,661 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3999017715454102, 'Total loss': 0.3999017715454102} | train loss {'Reaction outcome loss': 0.3935145678714026, 'Total loss': 0.3935145678714026}
2023-01-04 02:56:32,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:32,661 INFO:     Epoch: 9
2023-01-04 02:56:34,242 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3808738231658936, 'Total loss': 0.3808738231658936} | train loss {'Reaction outcome loss': 0.38445412103707594, 'Total loss': 0.38445412103707594}
2023-01-04 02:56:34,242 INFO:     Found new best model at epoch 9
2023-01-04 02:56:34,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:34,243 INFO:     Epoch: 10
2023-01-04 02:56:35,856 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3851966172456741, 'Total loss': 0.3851966172456741} | train loss {'Reaction outcome loss': 0.3779927948894708, 'Total loss': 0.3779927948894708}
2023-01-04 02:56:35,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:35,856 INFO:     Epoch: 11
2023-01-04 02:56:37,447 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38227855165799457, 'Total loss': 0.38227855165799457} | train loss {'Reaction outcome loss': 0.38247596112120413, 'Total loss': 0.38247596112120413}
2023-01-04 02:56:37,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:37,448 INFO:     Epoch: 12
2023-01-04 02:56:39,055 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38585263590017954, 'Total loss': 0.38585263590017954} | train loss {'Reaction outcome loss': 0.369011010610215, 'Total loss': 0.369011010610215}
2023-01-04 02:56:39,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:39,055 INFO:     Epoch: 13
2023-01-04 02:56:40,671 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3978315552075704, 'Total loss': 0.3978315552075704} | train loss {'Reaction outcome loss': 0.3567630070653083, 'Total loss': 0.3567630070653083}
2023-01-04 02:56:40,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:40,671 INFO:     Epoch: 14
2023-01-04 02:56:42,265 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37364148795604707, 'Total loss': 0.37364148795604707} | train loss {'Reaction outcome loss': 0.3515037850551037, 'Total loss': 0.3515037850551037}
2023-01-04 02:56:42,265 INFO:     Found new best model at epoch 14
2023-01-04 02:56:42,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:42,266 INFO:     Epoch: 15
2023-01-04 02:56:43,869 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37679944733778636, 'Total loss': 0.37679944733778636} | train loss {'Reaction outcome loss': 0.3413759403578613, 'Total loss': 0.3413759403578613}
2023-01-04 02:56:43,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:43,869 INFO:     Epoch: 16
2023-01-04 02:56:45,489 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3685574541489283, 'Total loss': 0.3685574541489283} | train loss {'Reaction outcome loss': 0.333941042949648, 'Total loss': 0.333941042949648}
2023-01-04 02:56:45,490 INFO:     Found new best model at epoch 16
2023-01-04 02:56:45,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:45,491 INFO:     Epoch: 17
2023-01-04 02:56:47,088 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3639860282341639, 'Total loss': 0.3639860282341639} | train loss {'Reaction outcome loss': 0.3307271454672235, 'Total loss': 0.3307271454672235}
2023-01-04 02:56:47,088 INFO:     Found new best model at epoch 17
2023-01-04 02:56:47,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:47,089 INFO:     Epoch: 18
2023-01-04 02:56:48,706 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35429724951585134, 'Total loss': 0.35429724951585134} | train loss {'Reaction outcome loss': 0.32864458647900785, 'Total loss': 0.32864458647900785}
2023-01-04 02:56:48,706 INFO:     Found new best model at epoch 18
2023-01-04 02:56:48,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:48,707 INFO:     Epoch: 19
2023-01-04 02:56:50,295 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37624476850032806, 'Total loss': 0.37624476850032806} | train loss {'Reaction outcome loss': 0.3211947005728017, 'Total loss': 0.3211947005728017}
2023-01-04 02:56:50,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:50,295 INFO:     Epoch: 20
2023-01-04 02:56:51,885 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34740533034006754, 'Total loss': 0.34740533034006754} | train loss {'Reaction outcome loss': 0.31369611872875064, 'Total loss': 0.31369611872875064}
2023-01-04 02:56:51,886 INFO:     Found new best model at epoch 20
2023-01-04 02:56:51,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:51,887 INFO:     Epoch: 21
2023-01-04 02:56:53,504 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3813122510910034, 'Total loss': 0.3813122510910034} | train loss {'Reaction outcome loss': 0.3101015520683638, 'Total loss': 0.3101015520683638}
2023-01-04 02:56:53,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:53,504 INFO:     Epoch: 22
2023-01-04 02:56:55,115 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3529628853003184, 'Total loss': 0.3529628853003184} | train loss {'Reaction outcome loss': 0.3035779642312369, 'Total loss': 0.3035779642312369}
2023-01-04 02:56:55,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:55,115 INFO:     Epoch: 23
2023-01-04 02:56:56,710 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.344656311472257, 'Total loss': 0.344656311472257} | train loss {'Reaction outcome loss': 0.3024076977069827, 'Total loss': 0.3024076977069827}
2023-01-04 02:56:56,711 INFO:     Found new best model at epoch 23
2023-01-04 02:56:56,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:56,711 INFO:     Epoch: 24
2023-01-04 02:56:58,319 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34894397258758547, 'Total loss': 0.34894397258758547} | train loss {'Reaction outcome loss': 0.29409777231352485, 'Total loss': 0.29409777231352485}
2023-01-04 02:56:58,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:58,319 INFO:     Epoch: 25
2023-01-04 02:56:59,931 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36081072489420574, 'Total loss': 0.36081072489420574} | train loss {'Reaction outcome loss': 0.2901237604201542, 'Total loss': 0.2901237604201542}
2023-01-04 02:56:59,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:56:59,932 INFO:     Epoch: 26
2023-01-04 02:57:01,529 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37201445003350575, 'Total loss': 0.37201445003350575} | train loss {'Reaction outcome loss': 0.28636408554180176, 'Total loss': 0.28636408554180176}
2023-01-04 02:57:01,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:01,529 INFO:     Epoch: 27
2023-01-04 02:57:03,145 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34326990842819216, 'Total loss': 0.34326990842819216} | train loss {'Reaction outcome loss': 0.28591336075054563, 'Total loss': 0.28591336075054563}
2023-01-04 02:57:03,145 INFO:     Found new best model at epoch 27
2023-01-04 02:57:03,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:03,146 INFO:     Epoch: 28
2023-01-04 02:57:04,721 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3461741000413895, 'Total loss': 0.3461741000413895} | train loss {'Reaction outcome loss': 0.28694123251066694, 'Total loss': 0.28694123251066694}
2023-01-04 02:57:04,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:04,722 INFO:     Epoch: 29
2023-01-04 02:57:06,333 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.348415699104468, 'Total loss': 0.348415699104468} | train loss {'Reaction outcome loss': 0.28401239409309265, 'Total loss': 0.28401239409309265}
2023-01-04 02:57:06,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:06,333 INFO:     Epoch: 30
2023-01-04 02:57:07,948 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3641548226277033, 'Total loss': 0.3641548226277033} | train loss {'Reaction outcome loss': 0.27044582449404214, 'Total loss': 0.27044582449404214}
2023-01-04 02:57:07,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:07,948 INFO:     Epoch: 31
2023-01-04 02:57:09,541 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3479156938691934, 'Total loss': 0.3479156938691934} | train loss {'Reaction outcome loss': 0.2677067174049823, 'Total loss': 0.2677067174049823}
2023-01-04 02:57:09,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:09,541 INFO:     Epoch: 32
2023-01-04 02:57:11,138 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35263778567314147, 'Total loss': 0.35263778567314147} | train loss {'Reaction outcome loss': 0.2681289922675469, 'Total loss': 0.2681289922675469}
2023-01-04 02:57:11,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:11,139 INFO:     Epoch: 33
2023-01-04 02:57:12,746 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.33671443661053974, 'Total loss': 0.33671443661053974} | train loss {'Reaction outcome loss': 0.2650224587245696, 'Total loss': 0.2650224587245696}
2023-01-04 02:57:12,746 INFO:     Found new best model at epoch 33
2023-01-04 02:57:12,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:12,747 INFO:     Epoch: 34
2023-01-04 02:57:14,317 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35475680728753406, 'Total loss': 0.35475680728753406} | train loss {'Reaction outcome loss': 0.2634473257091578, 'Total loss': 0.2634473257091578}
2023-01-04 02:57:14,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:14,318 INFO:     Epoch: 35
2023-01-04 02:57:15,933 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36469431817531583, 'Total loss': 0.36469431817531583} | train loss {'Reaction outcome loss': 0.2547479863050799, 'Total loss': 0.2547479863050799}
2023-01-04 02:57:15,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:15,933 INFO:     Epoch: 36
2023-01-04 02:57:17,532 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3582595328489939, 'Total loss': 0.3582595328489939} | train loss {'Reaction outcome loss': 0.2580145589224454, 'Total loss': 0.2580145589224454}
2023-01-04 02:57:17,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:17,532 INFO:     Epoch: 37
2023-01-04 02:57:19,110 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3567368338505427, 'Total loss': 0.3567368338505427} | train loss {'Reaction outcome loss': 0.2638154555085972, 'Total loss': 0.2638154555085972}
2023-01-04 02:57:19,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:19,111 INFO:     Epoch: 38
2023-01-04 02:57:20,710 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36051688293615974, 'Total loss': 0.36051688293615974} | train loss {'Reaction outcome loss': 0.24700332085426518, 'Total loss': 0.24700332085426518}
2023-01-04 02:57:20,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:20,711 INFO:     Epoch: 39
2023-01-04 02:57:22,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37293496131896975, 'Total loss': 0.37293496131896975} | train loss {'Reaction outcome loss': 0.24528562053223985, 'Total loss': 0.24528562053223985}
2023-01-04 02:57:22,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:22,306 INFO:     Epoch: 40
2023-01-04 02:57:23,890 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3653210331996282, 'Total loss': 0.3653210331996282} | train loss {'Reaction outcome loss': 0.24125653647601925, 'Total loss': 0.24125653647601925}
2023-01-04 02:57:23,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:23,891 INFO:     Epoch: 41
2023-01-04 02:57:25,512 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35324386060237883, 'Total loss': 0.35324386060237883} | train loss {'Reaction outcome loss': 0.2383679074443627, 'Total loss': 0.2383679074443627}
2023-01-04 02:57:25,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:25,512 INFO:     Epoch: 42
2023-01-04 02:57:27,105 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.350600100060304, 'Total loss': 0.350600100060304} | train loss {'Reaction outcome loss': 0.23715304206057952, 'Total loss': 0.23715304206057952}
2023-01-04 02:57:27,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:27,106 INFO:     Epoch: 43
2023-01-04 02:57:28,703 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.372774671514829, 'Total loss': 0.372774671514829} | train loss {'Reaction outcome loss': 0.23523162872658324, 'Total loss': 0.23523162872658324}
2023-01-04 02:57:28,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:28,703 INFO:     Epoch: 44
2023-01-04 02:57:30,320 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3663228054841359, 'Total loss': 0.3663228054841359} | train loss {'Reaction outcome loss': 0.23162304092129224, 'Total loss': 0.23162304092129224}
2023-01-04 02:57:30,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:30,320 INFO:     Epoch: 45
2023-01-04 02:57:31,907 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3481454014778137, 'Total loss': 0.3481454014778137} | train loss {'Reaction outcome loss': 0.22945594451163703, 'Total loss': 0.22945594451163703}
2023-01-04 02:57:31,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:31,908 INFO:     Epoch: 46
2023-01-04 02:57:33,519 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3868969519933065, 'Total loss': 0.3868969519933065} | train loss {'Reaction outcome loss': 0.2282279745880497, 'Total loss': 0.2282279745880497}
2023-01-04 02:57:33,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:33,519 INFO:     Epoch: 47
2023-01-04 02:57:35,134 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3547401989499728, 'Total loss': 0.3547401989499728} | train loss {'Reaction outcome loss': 0.23160190600901842, 'Total loss': 0.23160190600901842}
2023-01-04 02:57:35,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:35,134 INFO:     Epoch: 48
2023-01-04 02:57:36,729 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34784662624200186, 'Total loss': 0.34784662624200186} | train loss {'Reaction outcome loss': 0.22658438802339503, 'Total loss': 0.22658438802339503}
2023-01-04 02:57:36,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:36,729 INFO:     Epoch: 49
2023-01-04 02:57:38,350 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36228652199109396, 'Total loss': 0.36228652199109396} | train loss {'Reaction outcome loss': 0.22316127382488787, 'Total loss': 0.22316127382488787}
2023-01-04 02:57:38,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:38,350 INFO:     Epoch: 50
2023-01-04 02:57:39,949 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3744748448332151, 'Total loss': 0.3744748448332151} | train loss {'Reaction outcome loss': 0.22272612471673367, 'Total loss': 0.22272612471673367}
2023-01-04 02:57:39,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:39,950 INFO:     Epoch: 51
2023-01-04 02:57:41,544 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3465710937976837, 'Total loss': 0.3465710937976837} | train loss {'Reaction outcome loss': 0.22015543410257585, 'Total loss': 0.22015543410257585}
2023-01-04 02:57:41,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:41,544 INFO:     Epoch: 52
2023-01-04 02:57:43,159 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36660046378771466, 'Total loss': 0.36660046378771466} | train loss {'Reaction outcome loss': 0.21655100359827845, 'Total loss': 0.21655100359827845}
2023-01-04 02:57:43,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:43,160 INFO:     Epoch: 53
2023-01-04 02:57:44,769 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3673106332619985, 'Total loss': 0.3673106332619985} | train loss {'Reaction outcome loss': 0.21978346431168957, 'Total loss': 0.21978346431168957}
2023-01-04 02:57:44,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:44,769 INFO:     Epoch: 54
2023-01-04 02:57:46,360 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38467777470747627, 'Total loss': 0.38467777470747627} | train loss {'Reaction outcome loss': 0.21945706329564058, 'Total loss': 0.21945706329564058}
2023-01-04 02:57:46,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:46,360 INFO:     Epoch: 55
2023-01-04 02:57:47,977 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3613425801197688, 'Total loss': 0.3613425801197688} | train loss {'Reaction outcome loss': 0.21052537011691247, 'Total loss': 0.21052537011691247}
2023-01-04 02:57:47,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:47,977 INFO:     Epoch: 56
2023-01-04 02:57:49,553 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3691163778305054, 'Total loss': 0.3691163778305054} | train loss {'Reaction outcome loss': 0.2130924875618539, 'Total loss': 0.2130924875618539}
2023-01-04 02:57:49,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:49,553 INFO:     Epoch: 57
2023-01-04 02:57:51,144 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4026799221833547, 'Total loss': 0.4026799221833547} | train loss {'Reaction outcome loss': 0.22170479624005762, 'Total loss': 0.22170479624005762}
2023-01-04 02:57:51,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:51,145 INFO:     Epoch: 58
2023-01-04 02:57:52,746 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3853006144364675, 'Total loss': 0.3853006144364675} | train loss {'Reaction outcome loss': 0.22063768978325138, 'Total loss': 0.22063768978325138}
2023-01-04 02:57:52,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:52,746 INFO:     Epoch: 59
2023-01-04 02:57:54,327 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3613722542921702, 'Total loss': 0.3613722542921702} | train loss {'Reaction outcome loss': 0.2120584288639003, 'Total loss': 0.2120584288639003}
2023-01-04 02:57:54,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:54,328 INFO:     Epoch: 60
2023-01-04 02:57:55,942 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37898361186186474, 'Total loss': 0.37898361186186474} | train loss {'Reaction outcome loss': 0.23523477394727693, 'Total loss': 0.23523477394727693}
2023-01-04 02:57:55,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:55,942 INFO:     Epoch: 61
2023-01-04 02:57:57,538 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3697704712549845, 'Total loss': 0.3697704712549845} | train loss {'Reaction outcome loss': 0.21885543468417143, 'Total loss': 0.21885543468417143}
2023-01-04 02:57:57,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:57,539 INFO:     Epoch: 62
2023-01-04 02:57:59,120 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3811052074035009, 'Total loss': 0.3811052074035009} | train loss {'Reaction outcome loss': 0.20239019065437774, 'Total loss': 0.20239019065437774}
2023-01-04 02:57:59,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:57:59,120 INFO:     Epoch: 63
2023-01-04 02:58:00,716 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35303880969683327, 'Total loss': 0.35303880969683327} | train loss {'Reaction outcome loss': 0.19974294139841653, 'Total loss': 0.19974294139841653}
2023-01-04 02:58:00,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:00,717 INFO:     Epoch: 64
2023-01-04 02:58:02,314 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3678676689664523, 'Total loss': 0.3678676689664523} | train loss {'Reaction outcome loss': 0.19645936608962392, 'Total loss': 0.19645936608962392}
2023-01-04 02:58:02,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:02,314 INFO:     Epoch: 65
2023-01-04 02:58:03,892 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3863969802856445, 'Total loss': 0.3863969802856445} | train loss {'Reaction outcome loss': 0.1992544798531394, 'Total loss': 0.1992544798531394}
2023-01-04 02:58:03,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:03,892 INFO:     Epoch: 66
2023-01-04 02:58:05,488 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3854855035742124, 'Total loss': 0.3854855035742124} | train loss {'Reaction outcome loss': 0.20721126681715046, 'Total loss': 0.20721126681715046}
2023-01-04 02:58:05,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:05,488 INFO:     Epoch: 67
2023-01-04 02:58:07,085 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3938806215922038, 'Total loss': 0.3938806215922038} | train loss {'Reaction outcome loss': 0.19510143040943018, 'Total loss': 0.19510143040943018}
2023-01-04 02:58:07,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:07,085 INFO:     Epoch: 68
2023-01-04 02:58:08,666 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38227873891592024, 'Total loss': 0.38227873891592024} | train loss {'Reaction outcome loss': 0.20543571428625265, 'Total loss': 0.20543571428625265}
2023-01-04 02:58:08,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:08,666 INFO:     Epoch: 69
2023-01-04 02:58:10,282 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38124081790447234, 'Total loss': 0.38124081790447234} | train loss {'Reaction outcome loss': 0.21347659379598158, 'Total loss': 0.21347659379598158}
2023-01-04 02:58:10,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:10,283 INFO:     Epoch: 70
2023-01-04 02:58:11,897 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3764110197623571, 'Total loss': 0.3764110197623571} | train loss {'Reaction outcome loss': 0.19227071672068394, 'Total loss': 0.19227071672068394}
2023-01-04 02:58:11,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:11,898 INFO:     Epoch: 71
2023-01-04 02:58:13,476 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38493483861287436, 'Total loss': 0.38493483861287436} | train loss {'Reaction outcome loss': 0.19020063567017054, 'Total loss': 0.19020063567017054}
2023-01-04 02:58:13,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:13,476 INFO:     Epoch: 72
2023-01-04 02:58:15,078 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41819509665171306, 'Total loss': 0.41819509665171306} | train loss {'Reaction outcome loss': 0.1896177386876408, 'Total loss': 0.1896177386876408}
2023-01-04 02:58:15,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:15,078 INFO:     Epoch: 73
2023-01-04 02:58:16,671 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3934184143940608, 'Total loss': 0.3934184143940608} | train loss {'Reaction outcome loss': 0.18664930072038155, 'Total loss': 0.18664930072038155}
2023-01-04 02:58:16,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:16,671 INFO:     Epoch: 74
2023-01-04 02:58:18,300 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3946087290843328, 'Total loss': 0.3946087290843328} | train loss {'Reaction outcome loss': 0.1847232462624442, 'Total loss': 0.1847232462624442}
2023-01-04 02:58:18,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:18,300 INFO:     Epoch: 75
2023-01-04 02:58:19,917 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4166073054075241, 'Total loss': 0.4166073054075241} | train loss {'Reaction outcome loss': 0.1828873304593667, 'Total loss': 0.1828873304593667}
2023-01-04 02:58:19,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:19,917 INFO:     Epoch: 76
2023-01-04 02:58:21,512 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40058681468168894, 'Total loss': 0.40058681468168894} | train loss {'Reaction outcome loss': 0.18437445790007495, 'Total loss': 0.18437445790007495}
2023-01-04 02:58:21,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:21,513 INFO:     Epoch: 77
2023-01-04 02:58:23,126 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3766697903474172, 'Total loss': 0.3766697903474172} | train loss {'Reaction outcome loss': 0.1820246355905049, 'Total loss': 0.1820246355905049}
2023-01-04 02:58:23,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:23,127 INFO:     Epoch: 78
2023-01-04 02:58:24,720 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38946298956871034, 'Total loss': 0.38946298956871034} | train loss {'Reaction outcome loss': 0.1833809885062257, 'Total loss': 0.1833809885062257}
2023-01-04 02:58:24,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:24,720 INFO:     Epoch: 79
2023-01-04 02:58:26,321 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4084085881710052, 'Total loss': 0.4084085881710052} | train loss {'Reaction outcome loss': 0.18115991486155364, 'Total loss': 0.18115991486155364}
2023-01-04 02:58:26,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:26,321 INFO:     Epoch: 80
2023-01-04 02:58:27,951 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4037017693122228, 'Total loss': 0.4037017693122228} | train loss {'Reaction outcome loss': 0.1801255285605768, 'Total loss': 0.1801255285605768}
2023-01-04 02:58:27,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:27,952 INFO:     Epoch: 81
2023-01-04 02:58:29,547 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4010522613922755, 'Total loss': 0.4010522613922755} | train loss {'Reaction outcome loss': 0.1786727353061817, 'Total loss': 0.1786727353061817}
2023-01-04 02:58:29,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:29,547 INFO:     Epoch: 82
2023-01-04 02:58:31,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40968391398588816, 'Total loss': 0.40968391398588816} | train loss {'Reaction outcome loss': 0.17862473697269984, 'Total loss': 0.17862473697269984}
2023-01-04 02:58:31,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:31,127 INFO:     Epoch: 83
2023-01-04 02:58:32,724 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38867867887020113, 'Total loss': 0.38867867887020113} | train loss {'Reaction outcome loss': 0.17638823035024648, 'Total loss': 0.17638823035024648}
2023-01-04 02:58:32,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:32,724 INFO:     Epoch: 84
2023-01-04 02:58:34,314 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4126174742976824, 'Total loss': 0.4126174742976824} | train loss {'Reaction outcome loss': 0.18329078286922965, 'Total loss': 0.18329078286922965}
2023-01-04 02:58:34,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:34,315 INFO:     Epoch: 85
2023-01-04 02:58:35,925 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43545586069424946, 'Total loss': 0.43545586069424946} | train loss {'Reaction outcome loss': 0.17567183268888123, 'Total loss': 0.17567183268888123}
2023-01-04 02:58:35,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:35,925 INFO:     Epoch: 86
2023-01-04 02:58:37,506 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4194419145584106, 'Total loss': 0.4194419145584106} | train loss {'Reaction outcome loss': 0.17679643896543354, 'Total loss': 0.17679643896543354}
2023-01-04 02:58:37,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:37,506 INFO:     Epoch: 87
2023-01-04 02:58:39,114 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42525795797506966, 'Total loss': 0.42525795797506966} | train loss {'Reaction outcome loss': 0.1756246474881967, 'Total loss': 0.1756246474881967}
2023-01-04 02:58:39,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:39,115 INFO:     Epoch: 88
2023-01-04 02:58:40,695 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42326894601186116, 'Total loss': 0.42326894601186116} | train loss {'Reaction outcome loss': 0.1793390765543217, 'Total loss': 0.1793390765543217}
2023-01-04 02:58:40,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:40,695 INFO:     Epoch: 89
2023-01-04 02:58:42,307 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43091164926687875, 'Total loss': 0.43091164926687875} | train loss {'Reaction outcome loss': 0.16858441435117816, 'Total loss': 0.16858441435117816}
2023-01-04 02:58:42,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:42,308 INFO:     Epoch: 90
2023-01-04 02:58:43,876 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40883240501085916, 'Total loss': 0.40883240501085916} | train loss {'Reaction outcome loss': 0.16798089952984205, 'Total loss': 0.16798089952984205}
2023-01-04 02:58:43,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:43,876 INFO:     Epoch: 91
2023-01-04 02:58:45,474 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41103883683681486, 'Total loss': 0.41103883683681486} | train loss {'Reaction outcome loss': 0.17001553592036953, 'Total loss': 0.17001553592036953}
2023-01-04 02:58:45,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:45,474 INFO:     Epoch: 92
2023-01-04 02:58:47,067 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39986032247543335, 'Total loss': 0.39986032247543335} | train loss {'Reaction outcome loss': 0.16871946307377506, 'Total loss': 0.16871946307377506}
2023-01-04 02:58:47,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:47,068 INFO:     Epoch: 93
2023-01-04 02:58:48,640 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4065959230065346, 'Total loss': 0.4065959230065346} | train loss {'Reaction outcome loss': 0.16837413307360333, 'Total loss': 0.16837413307360333}
2023-01-04 02:58:48,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:48,640 INFO:     Epoch: 94
2023-01-04 02:58:50,257 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4316176732381185, 'Total loss': 0.4316176732381185} | train loss {'Reaction outcome loss': 0.17907788566494212, 'Total loss': 0.17907788566494212}
2023-01-04 02:58:50,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:50,257 INFO:     Epoch: 95
2023-01-04 02:58:51,882 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44228981137275697, 'Total loss': 0.44228981137275697} | train loss {'Reaction outcome loss': 0.16631888082454258, 'Total loss': 0.16631888082454258}
2023-01-04 02:58:51,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:51,882 INFO:     Epoch: 96
2023-01-04 02:58:53,458 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.420336319009463, 'Total loss': 0.420336319009463} | train loss {'Reaction outcome loss': 0.1639138812577163, 'Total loss': 0.1639138812577163}
2023-01-04 02:58:53,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:53,459 INFO:     Epoch: 97
2023-01-04 02:58:55,057 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42662300566832223, 'Total loss': 0.42662300566832223} | train loss {'Reaction outcome loss': 0.16507897577484718, 'Total loss': 0.16507897577484718}
2023-01-04 02:58:55,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:55,057 INFO:     Epoch: 98
2023-01-04 02:58:56,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45982250372568767, 'Total loss': 0.45982250372568767} | train loss {'Reaction outcome loss': 0.16204534695708708, 'Total loss': 0.16204534695708708}
2023-01-04 02:58:56,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:56,656 INFO:     Epoch: 99
2023-01-04 02:58:58,233 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4609529872735341, 'Total loss': 0.4609529872735341} | train loss {'Reaction outcome loss': 0.16176482853715887, 'Total loss': 0.16176482853715887}
2023-01-04 02:58:58,233 INFO:     Best model found after epoch 34 of 100.
2023-01-04 02:58:58,234 INFO:   Done with stage: TRAINING
2023-01-04 02:58:58,234 INFO:   Starting stage: EVALUATION
2023-01-04 02:58:58,362 INFO:   Done with stage: EVALUATION
2023-01-04 02:58:58,363 INFO:   Leaving out SEQ value Fold_1
2023-01-04 02:58:58,375 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 02:58:58,375 INFO:   Starting stage: FEATURE SCALING
2023-01-04 02:58:59,025 INFO:   Done with stage: FEATURE SCALING
2023-01-04 02:58:59,025 INFO:   Starting stage: SCALING TARGETS
2023-01-04 02:58:59,093 INFO:   Done with stage: SCALING TARGETS
2023-01-04 02:58:59,093 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:58:59,093 INFO:     No hyperparam tuning for this model
2023-01-04 02:58:59,093 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 02:58:59,093 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 02:58:59,094 INFO:     None feature selector for col prot
2023-01-04 02:58:59,094 INFO:     None feature selector for col prot
2023-01-04 02:58:59,094 INFO:     None feature selector for col prot
2023-01-04 02:58:59,095 INFO:     None feature selector for col chem
2023-01-04 02:58:59,095 INFO:     None feature selector for col chem
2023-01-04 02:58:59,095 INFO:     None feature selector for col chem
2023-01-04 02:58:59,095 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 02:58:59,095 INFO:   Starting stage: BUILD MODEL
2023-01-04 02:58:59,096 INFO:     Number of params in model 70141
2023-01-04 02:58:59,099 INFO:   Done with stage: BUILD MODEL
2023-01-04 02:58:59,099 INFO:   Starting stage: TRAINING
2023-01-04 02:58:59,145 INFO:     Val loss before train {'Reaction outcome loss': 1.115045392513275, 'Total loss': 1.115045392513275}
2023-01-04 02:58:59,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:58:59,146 INFO:     Epoch: 0
2023-01-04 02:59:00,712 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7129611114660899, 'Total loss': 0.7129611114660899} | train loss {'Reaction outcome loss': 0.8384554081517392, 'Total loss': 0.8384554081517392}
2023-01-04 02:59:00,712 INFO:     Found new best model at epoch 0
2023-01-04 02:59:00,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:00,713 INFO:     Epoch: 1
2023-01-04 02:59:02,276 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5910601814587911, 'Total loss': 0.5910601814587911} | train loss {'Reaction outcome loss': 0.6084868502133007, 'Total loss': 0.6084868502133007}
2023-01-04 02:59:02,276 INFO:     Found new best model at epoch 1
2023-01-04 02:59:02,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:02,277 INFO:     Epoch: 2
2023-01-04 02:59:03,880 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5568196813265482, 'Total loss': 0.5568196813265482} | train loss {'Reaction outcome loss': 0.5274726398756583, 'Total loss': 0.5274726398756583}
2023-01-04 02:59:03,881 INFO:     Found new best model at epoch 2
2023-01-04 02:59:03,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:03,882 INFO:     Epoch: 3
2023-01-04 02:59:05,474 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5454245050748189, 'Total loss': 0.5454245050748189} | train loss {'Reaction outcome loss': 0.48749929243128237, 'Total loss': 0.48749929243128237}
2023-01-04 02:59:05,474 INFO:     Found new best model at epoch 3
2023-01-04 02:59:05,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:05,475 INFO:     Epoch: 4
2023-01-04 02:59:07,018 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5038841197888057, 'Total loss': 0.5038841197888057} | train loss {'Reaction outcome loss': 0.4603459869143708, 'Total loss': 0.4603459869143708}
2023-01-04 02:59:07,018 INFO:     Found new best model at epoch 4
2023-01-04 02:59:07,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:07,019 INFO:     Epoch: 5
2023-01-04 02:59:08,574 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47217856099208194, 'Total loss': 0.47217856099208194} | train loss {'Reaction outcome loss': 0.4410370512972019, 'Total loss': 0.4410370512972019}
2023-01-04 02:59:08,574 INFO:     Found new best model at epoch 5
2023-01-04 02:59:08,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:08,575 INFO:     Epoch: 6
2023-01-04 02:59:10,138 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.540942637125651, 'Total loss': 0.540942637125651} | train loss {'Reaction outcome loss': 0.4222767696719328, 'Total loss': 0.4222767696719328}
2023-01-04 02:59:10,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:10,139 INFO:     Epoch: 7
2023-01-04 02:59:11,699 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4685585856437683, 'Total loss': 0.4685585856437683} | train loss {'Reaction outcome loss': 0.4108645843403806, 'Total loss': 0.4108645843403806}
2023-01-04 02:59:11,699 INFO:     Found new best model at epoch 7
2023-01-04 02:59:11,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:11,700 INFO:     Epoch: 8
2023-01-04 02:59:13,267 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4922031303246816, 'Total loss': 0.4922031303246816} | train loss {'Reaction outcome loss': 0.39667116578434664, 'Total loss': 0.39667116578434664}
2023-01-04 02:59:13,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:13,267 INFO:     Epoch: 9
2023-01-04 02:59:14,823 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48032770653565726, 'Total loss': 0.48032770653565726} | train loss {'Reaction outcome loss': 0.3868222803262327, 'Total loss': 0.3868222803262327}
2023-01-04 02:59:14,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:14,824 INFO:     Epoch: 10
2023-01-04 02:59:16,369 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48817423979441327, 'Total loss': 0.48817423979441327} | train loss {'Reaction outcome loss': 0.377615932086517, 'Total loss': 0.377615932086517}
2023-01-04 02:59:16,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:16,369 INFO:     Epoch: 11
2023-01-04 02:59:17,957 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44123106251160304, 'Total loss': 0.44123106251160304} | train loss {'Reaction outcome loss': 0.3689148752121908, 'Total loss': 0.3689148752121908}
2023-01-04 02:59:17,958 INFO:     Found new best model at epoch 11
2023-01-04 02:59:17,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:17,958 INFO:     Epoch: 12
2023-01-04 02:59:19,508 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45507356921831765, 'Total loss': 0.45507356921831765} | train loss {'Reaction outcome loss': 0.36141155069054715, 'Total loss': 0.36141155069054715}
2023-01-04 02:59:19,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:19,509 INFO:     Epoch: 13
2023-01-04 02:59:21,116 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4898956775665283, 'Total loss': 0.4898956775665283} | train loss {'Reaction outcome loss': 0.3518832979991867, 'Total loss': 0.3518832979991867}
2023-01-04 02:59:21,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:21,116 INFO:     Epoch: 14
2023-01-04 02:59:22,716 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45741422871748605, 'Total loss': 0.45741422871748605} | train loss {'Reaction outcome loss': 0.3465147219405843, 'Total loss': 0.3465147219405843}
2023-01-04 02:59:22,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:22,717 INFO:     Epoch: 15
2023-01-04 02:59:24,284 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.451992126305898, 'Total loss': 0.451992126305898} | train loss {'Reaction outcome loss': 0.33994435312783144, 'Total loss': 0.33994435312783144}
2023-01-04 02:59:24,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:24,284 INFO:     Epoch: 16
2023-01-04 02:59:25,851 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.462566622098287, 'Total loss': 0.462566622098287} | train loss {'Reaction outcome loss': 0.33389591970017035, 'Total loss': 0.33389591970017035}
2023-01-04 02:59:25,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:25,852 INFO:     Epoch: 17
2023-01-04 02:59:27,420 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4204807221889496, 'Total loss': 0.4204807221889496} | train loss {'Reaction outcome loss': 0.3270036512195404, 'Total loss': 0.3270036512195404}
2023-01-04 02:59:27,421 INFO:     Found new best model at epoch 17
2023-01-04 02:59:27,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:27,421 INFO:     Epoch: 18
2023-01-04 02:59:28,990 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4414882481098175, 'Total loss': 0.4414882481098175} | train loss {'Reaction outcome loss': 0.3210738227596142, 'Total loss': 0.3210738227596142}
2023-01-04 02:59:28,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:28,990 INFO:     Epoch: 19
2023-01-04 02:59:30,590 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44251218636830647, 'Total loss': 0.44251218636830647} | train loss {'Reaction outcome loss': 0.3186666521474004, 'Total loss': 0.3186666521474004}
2023-01-04 02:59:30,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:30,590 INFO:     Epoch: 20
2023-01-04 02:59:32,195 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4453832228978475, 'Total loss': 0.4453832228978475} | train loss {'Reaction outcome loss': 0.3109903943164762, 'Total loss': 0.3109903943164762}
2023-01-04 02:59:32,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:32,195 INFO:     Epoch: 21
2023-01-04 02:59:33,756 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42177746891975404, 'Total loss': 0.42177746891975404} | train loss {'Reaction outcome loss': 0.3058773205234116, 'Total loss': 0.3058773205234116}
2023-01-04 02:59:33,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:33,756 INFO:     Epoch: 22
2023-01-04 02:59:35,324 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.459285581111908, 'Total loss': 0.459285581111908} | train loss {'Reaction outcome loss': 0.3014567830355845, 'Total loss': 0.3014567830355845}
2023-01-04 02:59:35,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:35,324 INFO:     Epoch: 23
2023-01-04 02:59:36,912 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41530867516994474, 'Total loss': 0.41530867516994474} | train loss {'Reaction outcome loss': 0.29812051737990325, 'Total loss': 0.29812051737990325}
2023-01-04 02:59:36,912 INFO:     Found new best model at epoch 23
2023-01-04 02:59:36,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:36,913 INFO:     Epoch: 24
2023-01-04 02:59:38,471 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4434228837490082, 'Total loss': 0.4434228837490082} | train loss {'Reaction outcome loss': 0.2902713427354489, 'Total loss': 0.2902713427354489}
2023-01-04 02:59:38,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:38,471 INFO:     Epoch: 25
2023-01-04 02:59:40,060 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.433381309111913, 'Total loss': 0.433381309111913} | train loss {'Reaction outcome loss': 0.2884195677633655, 'Total loss': 0.2884195677633655}
2023-01-04 02:59:40,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:40,061 INFO:     Epoch: 26
2023-01-04 02:59:41,652 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4319435973962148, 'Total loss': 0.4319435973962148} | train loss {'Reaction outcome loss': 0.2818258438822968, 'Total loss': 0.2818258438822968}
2023-01-04 02:59:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:41,652 INFO:     Epoch: 27
2023-01-04 02:59:43,219 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42938726445039116, 'Total loss': 0.42938726445039116} | train loss {'Reaction outcome loss': 0.28128266906386373, 'Total loss': 0.28128266906386373}
2023-01-04 02:59:43,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:43,219 INFO:     Epoch: 28
2023-01-04 02:59:44,814 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42999709844589235, 'Total loss': 0.42999709844589235} | train loss {'Reaction outcome loss': 0.27689438970326496, 'Total loss': 0.27689438970326496}
2023-01-04 02:59:44,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:44,814 INFO:     Epoch: 29
2023-01-04 02:59:46,389 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44723814924558003, 'Total loss': 0.44723814924558003} | train loss {'Reaction outcome loss': 0.2740321259437012, 'Total loss': 0.2740321259437012}
2023-01-04 02:59:46,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:46,390 INFO:     Epoch: 30
2023-01-04 02:59:47,963 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40931692520777385, 'Total loss': 0.40931692520777385} | train loss {'Reaction outcome loss': 0.2717412095723117, 'Total loss': 0.2717412095723117}
2023-01-04 02:59:47,963 INFO:     Found new best model at epoch 30
2023-01-04 02:59:47,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:47,964 INFO:     Epoch: 31
2023-01-04 02:59:49,537 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4169343650341034, 'Total loss': 0.4169343650341034} | train loss {'Reaction outcome loss': 0.2640345461419148, 'Total loss': 0.2640345461419148}
2023-01-04 02:59:49,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:49,537 INFO:     Epoch: 32
2023-01-04 02:59:51,090 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44585849543412526, 'Total loss': 0.44585849543412526} | train loss {'Reaction outcome loss': 0.26601663520525304, 'Total loss': 0.26601663520525304}
2023-01-04 02:59:51,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:51,091 INFO:     Epoch: 33
2023-01-04 02:59:52,682 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43706745505332945, 'Total loss': 0.43706745505332945} | train loss {'Reaction outcome loss': 0.2624075287932399, 'Total loss': 0.2624075287932399}
2023-01-04 02:59:52,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:52,682 INFO:     Epoch: 34
2023-01-04 02:59:54,276 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4079173783461253, 'Total loss': 0.4079173783461253} | train loss {'Reaction outcome loss': 0.2574794206946978, 'Total loss': 0.2574794206946978}
2023-01-04 02:59:54,276 INFO:     Found new best model at epoch 34
2023-01-04 02:59:54,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:54,277 INFO:     Epoch: 35
2023-01-04 02:59:55,840 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4368792374928792, 'Total loss': 0.4368792374928792} | train loss {'Reaction outcome loss': 0.2557664034936261, 'Total loss': 0.2557664034936261}
2023-01-04 02:59:55,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:55,840 INFO:     Epoch: 36
2023-01-04 02:59:57,434 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4287424236536026, 'Total loss': 0.4287424236536026} | train loss {'Reaction outcome loss': 0.2515291653271091, 'Total loss': 0.2515291653271091}
2023-01-04 02:59:57,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:57,434 INFO:     Epoch: 37
2023-01-04 02:59:59,001 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44506203532218935, 'Total loss': 0.44506203532218935} | train loss {'Reaction outcome loss': 0.2506414640048773, 'Total loss': 0.2506414640048773}
2023-01-04 02:59:59,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 02:59:59,001 INFO:     Epoch: 38
2023-01-04 03:00:00,542 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42342854738235475, 'Total loss': 0.42342854738235475} | train loss {'Reaction outcome loss': 0.24903667594453946, 'Total loss': 0.24903667594453946}
2023-01-04 03:00:00,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:00,542 INFO:     Epoch: 39
2023-01-04 03:00:02,116 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4196340451637904, 'Total loss': 0.4196340451637904} | train loss {'Reaction outcome loss': 0.24505745755625388, 'Total loss': 0.24505745755625388}
2023-01-04 03:00:02,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:02,116 INFO:     Epoch: 40
2023-01-04 03:00:03,711 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.466092120607694, 'Total loss': 0.466092120607694} | train loss {'Reaction outcome loss': 0.24335533479482926, 'Total loss': 0.24335533479482926}
2023-01-04 03:00:03,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:03,711 INFO:     Epoch: 41
2023-01-04 03:00:05,283 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4154816448688507, 'Total loss': 0.4154816448688507} | train loss {'Reaction outcome loss': 0.24215494668131826, 'Total loss': 0.24215494668131826}
2023-01-04 03:00:05,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:05,283 INFO:     Epoch: 42
2023-01-04 03:00:06,887 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4324841578801473, 'Total loss': 0.4324841578801473} | train loss {'Reaction outcome loss': 0.2368259048055019, 'Total loss': 0.2368259048055019}
2023-01-04 03:00:06,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:06,888 INFO:     Epoch: 43
2023-01-04 03:00:08,488 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40305625001589457, 'Total loss': 0.40305625001589457} | train loss {'Reaction outcome loss': 0.23690016692799837, 'Total loss': 0.23690016692799837}
2023-01-04 03:00:08,488 INFO:     Found new best model at epoch 43
2023-01-04 03:00:08,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:08,489 INFO:     Epoch: 44
2023-01-04 03:00:10,043 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41289978722731274, 'Total loss': 0.41289978722731274} | train loss {'Reaction outcome loss': 0.23444712889205485, 'Total loss': 0.23444712889205485}
2023-01-04 03:00:10,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:10,043 INFO:     Epoch: 45
2023-01-04 03:00:11,609 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4348380754391352, 'Total loss': 0.4348380754391352} | train loss {'Reaction outcome loss': 0.23298660968172594, 'Total loss': 0.23298660968172594}
2023-01-04 03:00:11,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:11,609 INFO:     Epoch: 46
2023-01-04 03:00:13,152 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43747815986474353, 'Total loss': 0.43747815986474353} | train loss {'Reaction outcome loss': 0.2308138002026345, 'Total loss': 0.2308138002026345}
2023-01-04 03:00:13,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:13,152 INFO:     Epoch: 47
2023-01-04 03:00:14,719 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44140811065832775, 'Total loss': 0.44140811065832775} | train loss {'Reaction outcome loss': 0.22995736628660857, 'Total loss': 0.22995736628660857}
2023-01-04 03:00:14,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:14,720 INFO:     Epoch: 48
2023-01-04 03:00:16,281 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.426817512512207, 'Total loss': 0.426817512512207} | train loss {'Reaction outcome loss': 0.2286125821064869, 'Total loss': 0.2286125821064869}
2023-01-04 03:00:16,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:16,281 INFO:     Epoch: 49
2023-01-04 03:00:17,825 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4394114792346954, 'Total loss': 0.4394114792346954} | train loss {'Reaction outcome loss': 0.22342234228589877, 'Total loss': 0.22342234228589877}
2023-01-04 03:00:17,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:17,825 INFO:     Epoch: 50
2023-01-04 03:00:19,392 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45131982266902926, 'Total loss': 0.45131982266902926} | train loss {'Reaction outcome loss': 0.22505906702627554, 'Total loss': 0.22505906702627554}
2023-01-04 03:00:19,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:19,392 INFO:     Epoch: 51
2023-01-04 03:00:20,984 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40766459808995326, 'Total loss': 0.40766459808995326} | train loss {'Reaction outcome loss': 0.22216321401490496, 'Total loss': 0.22216321401490496}
2023-01-04 03:00:20,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:20,985 INFO:     Epoch: 52
2023-01-04 03:00:22,559 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43517840206623076, 'Total loss': 0.43517840206623076} | train loss {'Reaction outcome loss': 0.22117442673422755, 'Total loss': 0.22117442673422755}
2023-01-04 03:00:22,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:22,559 INFO:     Epoch: 53
2023-01-04 03:00:24,152 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41120826502641045, 'Total loss': 0.41120826502641045} | train loss {'Reaction outcome loss': 0.21796229527060396, 'Total loss': 0.21796229527060396}
2023-01-04 03:00:24,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:24,153 INFO:     Epoch: 54
2023-01-04 03:00:25,749 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4385861992835999, 'Total loss': 0.4385861992835999} | train loss {'Reaction outcome loss': 0.21574242832310966, 'Total loss': 0.21574242832310966}
2023-01-04 03:00:25,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:25,749 INFO:     Epoch: 55
2023-01-04 03:00:27,304 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4258526454369227, 'Total loss': 0.4258526454369227} | train loss {'Reaction outcome loss': 0.21621154775203813, 'Total loss': 0.21621154775203813}
2023-01-04 03:00:27,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:27,304 INFO:     Epoch: 56
2023-01-04 03:00:28,873 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4211403429508209, 'Total loss': 0.4211403429508209} | train loss {'Reaction outcome loss': 0.21454927688155226, 'Total loss': 0.21454927688155226}
2023-01-04 03:00:28,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:28,873 INFO:     Epoch: 57
2023-01-04 03:00:30,432 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4289549380540848, 'Total loss': 0.4289549380540848} | train loss {'Reaction outcome loss': 0.21285308106386575, 'Total loss': 0.21285308106386575}
2023-01-04 03:00:30,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:30,432 INFO:     Epoch: 58
2023-01-04 03:00:31,980 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4320565233627955, 'Total loss': 0.4320565233627955} | train loss {'Reaction outcome loss': 0.2090032213535916, 'Total loss': 0.2090032213535916}
2023-01-04 03:00:31,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:31,980 INFO:     Epoch: 59
2023-01-04 03:00:33,575 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43092707395553587, 'Total loss': 0.43092707395553587} | train loss {'Reaction outcome loss': 0.21113875940634536, 'Total loss': 0.21113875940634536}
2023-01-04 03:00:33,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:33,576 INFO:     Epoch: 60
2023-01-04 03:00:35,135 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43302195966243745, 'Total loss': 0.43302195966243745} | train loss {'Reaction outcome loss': 0.20780380410434354, 'Total loss': 0.20780380410434354}
2023-01-04 03:00:35,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:35,135 INFO:     Epoch: 61
2023-01-04 03:00:36,693 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4186108195533355, 'Total loss': 0.4186108195533355} | train loss {'Reaction outcome loss': 0.20673868625091452, 'Total loss': 0.20673868625091452}
2023-01-04 03:00:36,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:36,693 INFO:     Epoch: 62
2023-01-04 03:00:38,260 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44770916601022087, 'Total loss': 0.44770916601022087} | train loss {'Reaction outcome loss': 0.20788693671351868, 'Total loss': 0.20788693671351868}
2023-01-04 03:00:38,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:38,260 INFO:     Epoch: 63
2023-01-04 03:00:39,824 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4221268226703008, 'Total loss': 0.4221268226703008} | train loss {'Reaction outcome loss': 0.20454584305411774, 'Total loss': 0.20454584305411774}
2023-01-04 03:00:39,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:39,824 INFO:     Epoch: 64
2023-01-04 03:00:41,375 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41418529152870176, 'Total loss': 0.41418529152870176} | train loss {'Reaction outcome loss': 0.20241985865954543, 'Total loss': 0.20241985865954543}
2023-01-04 03:00:41,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:41,375 INFO:     Epoch: 65
2023-01-04 03:00:42,969 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41758898496627805, 'Total loss': 0.41758898496627805} | train loss {'Reaction outcome loss': 0.19994915458219079, 'Total loss': 0.19994915458219079}
2023-01-04 03:00:42,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:42,970 INFO:     Epoch: 66
2023-01-04 03:00:44,559 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4512352108955383, 'Total loss': 0.4512352108955383} | train loss {'Reaction outcome loss': 0.1991898148867037, 'Total loss': 0.1991898148867037}
2023-01-04 03:00:44,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:44,559 INFO:     Epoch: 67
2023-01-04 03:00:46,116 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3998362774650256, 'Total loss': 0.3998362774650256} | train loss {'Reaction outcome loss': 0.19875104288223486, 'Total loss': 0.19875104288223486}
2023-01-04 03:00:46,117 INFO:     Found new best model at epoch 67
2023-01-04 03:00:46,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:46,118 INFO:     Epoch: 68
2023-01-04 03:00:47,683 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4309444397687912, 'Total loss': 0.4309444397687912} | train loss {'Reaction outcome loss': 0.1943581782528835, 'Total loss': 0.1943581782528835}
2023-01-04 03:00:47,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:47,684 INFO:     Epoch: 69
2023-01-04 03:00:49,237 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4332868367433548, 'Total loss': 0.4332868367433548} | train loss {'Reaction outcome loss': 0.19642342419476966, 'Total loss': 0.19642342419476966}
2023-01-04 03:00:49,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:49,237 INFO:     Epoch: 70
2023-01-04 03:00:50,793 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47784478863080343, 'Total loss': 0.47784478863080343} | train loss {'Reaction outcome loss': 0.19339139520352178, 'Total loss': 0.19339139520352178}
2023-01-04 03:00:50,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:50,793 INFO:     Epoch: 71
2023-01-04 03:00:52,388 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4354075054327647, 'Total loss': 0.4354075054327647} | train loss {'Reaction outcome loss': 0.19414139787814275, 'Total loss': 0.19414139787814275}
2023-01-04 03:00:52,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:52,389 INFO:     Epoch: 72
2023-01-04 03:00:53,941 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42261270582675936, 'Total loss': 0.42261270582675936} | train loss {'Reaction outcome loss': 0.1932577754326192, 'Total loss': 0.1932577754326192}
2023-01-04 03:00:53,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:53,942 INFO:     Epoch: 73
2023-01-04 03:00:55,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44741112291812896, 'Total loss': 0.44741112291812896} | train loss {'Reaction outcome loss': 0.18985693170465667, 'Total loss': 0.18985693170465667}
2023-01-04 03:00:55,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:55,494 INFO:     Epoch: 74
2023-01-04 03:00:57,083 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45649963517983755, 'Total loss': 0.45649963517983755} | train loss {'Reaction outcome loss': 0.18931955137595918, 'Total loss': 0.18931955137595918}
2023-01-04 03:00:57,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:57,084 INFO:     Epoch: 75
2023-01-04 03:00:58,654 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42643265426158905, 'Total loss': 0.42643265426158905} | train loss {'Reaction outcome loss': 0.19198838501783755, 'Total loss': 0.19198838501783755}
2023-01-04 03:00:58,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:00:58,654 INFO:     Epoch: 76
2023-01-04 03:01:00,261 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4656188815832138, 'Total loss': 0.4656188815832138} | train loss {'Reaction outcome loss': 0.18892749455307242, 'Total loss': 0.18892749455307242}
2023-01-04 03:01:00,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:00,261 INFO:     Epoch: 77
2023-01-04 03:01:01,865 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48627098004023234, 'Total loss': 0.48627098004023234} | train loss {'Reaction outcome loss': 0.1877573844925174, 'Total loss': 0.1877573844925174}
2023-01-04 03:01:01,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:01,865 INFO:     Epoch: 78
2023-01-04 03:01:03,425 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4596079876025518, 'Total loss': 0.4596079876025518} | train loss {'Reaction outcome loss': 0.18611900746217513, 'Total loss': 0.18611900746217513}
2023-01-04 03:01:03,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:03,426 INFO:     Epoch: 79
2023-01-04 03:01:04,997 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42414359947045643, 'Total loss': 0.42414359947045643} | train loss {'Reaction outcome loss': 0.18745041462658077, 'Total loss': 0.18745041462658077}
2023-01-04 03:01:04,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:04,998 INFO:     Epoch: 80
2023-01-04 03:01:06,574 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4262535149852435, 'Total loss': 0.4262535149852435} | train loss {'Reaction outcome loss': 0.18394103132504488, 'Total loss': 0.18394103132504488}
2023-01-04 03:01:06,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:06,574 INFO:     Epoch: 81
2023-01-04 03:01:08,149 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4236472725868225, 'Total loss': 0.4236472725868225} | train loss {'Reaction outcome loss': 0.18338633948641508, 'Total loss': 0.18338633948641508}
2023-01-04 03:01:08,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:08,150 INFO:     Epoch: 82
2023-01-04 03:01:09,712 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4169359604517619, 'Total loss': 0.4169359604517619} | train loss {'Reaction outcome loss': 0.18323254796274255, 'Total loss': 0.18323254796274255}
2023-01-04 03:01:09,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:09,712 INFO:     Epoch: 83
2023-01-04 03:01:11,307 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44932929476102196, 'Total loss': 0.44932929476102196} | train loss {'Reaction outcome loss': 0.18109755474400477, 'Total loss': 0.18109755474400477}
2023-01-04 03:01:11,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:11,307 INFO:     Epoch: 84
2023-01-04 03:01:12,881 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45486464103062946, 'Total loss': 0.45486464103062946} | train loss {'Reaction outcome loss': 0.18131223205490746, 'Total loss': 0.18131223205490746}
2023-01-04 03:01:12,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:12,881 INFO:     Epoch: 85
2023-01-04 03:01:14,470 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4527626280983289, 'Total loss': 0.4527626280983289} | train loss {'Reaction outcome loss': 0.1785821161641846, 'Total loss': 0.1785821161641846}
2023-01-04 03:01:14,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:14,470 INFO:     Epoch: 86
2023-01-04 03:01:16,040 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42512866457303367, 'Total loss': 0.42512866457303367} | train loss {'Reaction outcome loss': 0.17815935438519476, 'Total loss': 0.17815935438519476}
2023-01-04 03:01:16,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:16,040 INFO:     Epoch: 87
2023-01-04 03:01:17,619 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4382337391376495, 'Total loss': 0.4382337391376495} | train loss {'Reaction outcome loss': 0.17648488085208344, 'Total loss': 0.17648488085208344}
2023-01-04 03:01:17,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:17,620 INFO:     Epoch: 88
2023-01-04 03:01:19,195 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4447922517855962, 'Total loss': 0.4447922517855962} | train loss {'Reaction outcome loss': 0.17805792774139076, 'Total loss': 0.17805792774139076}
2023-01-04 03:01:19,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:19,195 INFO:     Epoch: 89
2023-01-04 03:01:20,756 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4544446349143982, 'Total loss': 0.4544446349143982} | train loss {'Reaction outcome loss': 0.17740462561880282, 'Total loss': 0.17740462561880282}
2023-01-04 03:01:20,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:20,756 INFO:     Epoch: 90
2023-01-04 03:01:22,349 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45471155146757763, 'Total loss': 0.45471155146757763} | train loss {'Reaction outcome loss': 0.17454353169404052, 'Total loss': 0.17454353169404052}
2023-01-04 03:01:22,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:22,351 INFO:     Epoch: 91
2023-01-04 03:01:23,944 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44747068484624225, 'Total loss': 0.44747068484624225} | train loss {'Reaction outcome loss': 0.17635978622245171, 'Total loss': 0.17635978622245171}
2023-01-04 03:01:23,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:23,944 INFO:     Epoch: 92
2023-01-04 03:01:25,518 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4533890614906947, 'Total loss': 0.4533890614906947} | train loss {'Reaction outcome loss': 0.17394771668853795, 'Total loss': 0.17394771668853795}
2023-01-04 03:01:25,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:25,518 INFO:     Epoch: 93
2023-01-04 03:01:27,087 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48750215470790864, 'Total loss': 0.48750215470790864} | train loss {'Reaction outcome loss': 0.17398050386197453, 'Total loss': 0.17398050386197453}
2023-01-04 03:01:27,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:27,087 INFO:     Epoch: 94
2023-01-04 03:01:28,656 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5036814530690511, 'Total loss': 0.5036814530690511} | train loss {'Reaction outcome loss': 0.17374598182655349, 'Total loss': 0.17374598182655349}
2023-01-04 03:01:28,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:28,657 INFO:     Epoch: 95
2023-01-04 03:01:30,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4651382068792979, 'Total loss': 0.4651382068792979} | train loss {'Reaction outcome loss': 0.171058919177669, 'Total loss': 0.171058919177669}
2023-01-04 03:01:30,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:30,206 INFO:     Epoch: 96
2023-01-04 03:01:31,798 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4415936576823393, 'Total loss': 0.4415936576823393} | train loss {'Reaction outcome loss': 0.17175763477038633, 'Total loss': 0.17175763477038633}
2023-01-04 03:01:31,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:31,798 INFO:     Epoch: 97
2023-01-04 03:01:33,391 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5228162348270416, 'Total loss': 0.5228162348270416} | train loss {'Reaction outcome loss': 0.17238154348906995, 'Total loss': 0.17238154348906995}
2023-01-04 03:01:33,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:33,391 INFO:     Epoch: 98
2023-01-04 03:01:34,961 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4777724812428156, 'Total loss': 0.4777724812428156} | train loss {'Reaction outcome loss': 0.16958136701908277, 'Total loss': 0.16958136701908277}
2023-01-04 03:01:34,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:34,961 INFO:     Epoch: 99
2023-01-04 03:01:36,556 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4594663759072622, 'Total loss': 0.4594663759072622} | train loss {'Reaction outcome loss': 0.17059803621437936, 'Total loss': 0.17059803621437936}
2023-01-04 03:01:36,556 INFO:     Best model found after epoch 68 of 100.
2023-01-04 03:01:36,557 INFO:   Done with stage: TRAINING
2023-01-04 03:01:36,557 INFO:   Starting stage: EVALUATION
2023-01-04 03:01:36,703 INFO:   Done with stage: EVALUATION
2023-01-04 03:01:36,703 INFO:   Leaving out SEQ value Fold_2
2023-01-04 03:01:36,715 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 03:01:36,716 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:01:37,359 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:01:37,359 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:01:37,428 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:01:37,428 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:01:37,428 INFO:     No hyperparam tuning for this model
2023-01-04 03:01:37,428 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:01:37,428 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:01:37,429 INFO:     None feature selector for col prot
2023-01-04 03:01:37,429 INFO:     None feature selector for col prot
2023-01-04 03:01:37,429 INFO:     None feature selector for col prot
2023-01-04 03:01:37,429 INFO:     None feature selector for col chem
2023-01-04 03:01:37,430 INFO:     None feature selector for col chem
2023-01-04 03:01:37,430 INFO:     None feature selector for col chem
2023-01-04 03:01:37,430 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:01:37,430 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:01:37,431 INFO:     Number of params in model 70141
2023-01-04 03:01:37,434 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:01:37,434 INFO:   Starting stage: TRAINING
2023-01-04 03:01:37,478 INFO:     Val loss before train {'Reaction outcome loss': 0.9601067821184794, 'Total loss': 0.9601067821184794}
2023-01-04 03:01:37,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:37,478 INFO:     Epoch: 0
2023-01-04 03:01:39,041 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6473205010096232, 'Total loss': 0.6473205010096232} | train loss {'Reaction outcome loss': 0.834872792889602, 'Total loss': 0.834872792889602}
2023-01-04 03:01:39,041 INFO:     Found new best model at epoch 0
2023-01-04 03:01:39,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:39,042 INFO:     Epoch: 1
2023-01-04 03:01:40,626 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.523372091849645, 'Total loss': 0.523372091849645} | train loss {'Reaction outcome loss': 0.5828314699286962, 'Total loss': 0.5828314699286962}
2023-01-04 03:01:40,626 INFO:     Found new best model at epoch 1
2023-01-04 03:01:40,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:40,627 INFO:     Epoch: 2
2023-01-04 03:01:42,231 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4780121803283691, 'Total loss': 0.4780121803283691} | train loss {'Reaction outcome loss': 0.5172943502773334, 'Total loss': 0.5172943502773334}
2023-01-04 03:01:42,232 INFO:     Found new best model at epoch 2
2023-01-04 03:01:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:42,233 INFO:     Epoch: 3
2023-01-04 03:01:43,798 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4676889126499494, 'Total loss': 0.4676889126499494} | train loss {'Reaction outcome loss': 0.48090799538976087, 'Total loss': 0.48090799538976087}
2023-01-04 03:01:43,798 INFO:     Found new best model at epoch 3
2023-01-04 03:01:43,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:43,799 INFO:     Epoch: 4
2023-01-04 03:01:45,382 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4383855119347572, 'Total loss': 0.4383855119347572} | train loss {'Reaction outcome loss': 0.45716310597031656, 'Total loss': 0.45716310597031656}
2023-01-04 03:01:45,382 INFO:     Found new best model at epoch 4
2023-01-04 03:01:45,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:45,383 INFO:     Epoch: 5
2023-01-04 03:01:46,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43083931803703307, 'Total loss': 0.43083931803703307} | train loss {'Reaction outcome loss': 0.4388568750480666, 'Total loss': 0.4388568750480666}
2023-01-04 03:01:46,963 INFO:     Found new best model at epoch 5
2023-01-04 03:01:46,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:46,964 INFO:     Epoch: 6
2023-01-04 03:01:48,532 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44249881207942965, 'Total loss': 0.44249881207942965} | train loss {'Reaction outcome loss': 0.4244130768806395, 'Total loss': 0.4244130768806395}
2023-01-04 03:01:48,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:48,532 INFO:     Epoch: 7
2023-01-04 03:01:50,118 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41762146552403767, 'Total loss': 0.41762146552403767} | train loss {'Reaction outcome loss': 0.40990717893969403, 'Total loss': 0.40990717893969403}
2023-01-04 03:01:50,118 INFO:     Found new best model at epoch 7
2023-01-04 03:01:50,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:50,119 INFO:     Epoch: 8
2023-01-04 03:01:51,687 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4442617118358612, 'Total loss': 0.4442617118358612} | train loss {'Reaction outcome loss': 0.39674755571967496, 'Total loss': 0.39674755571967496}
2023-01-04 03:01:51,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:51,687 INFO:     Epoch: 9
2023-01-04 03:01:53,300 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4238648156325022, 'Total loss': 0.4238648156325022} | train loss {'Reaction outcome loss': 0.3880477240377099, 'Total loss': 0.3880477240377099}
2023-01-04 03:01:53,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:53,300 INFO:     Epoch: 10
2023-01-04 03:01:54,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.408865421017011, 'Total loss': 0.408865421017011} | train loss {'Reaction outcome loss': 0.3808645021143186, 'Total loss': 0.3808645021143186}
2023-01-04 03:01:54,912 INFO:     Found new best model at epoch 10
2023-01-04 03:01:54,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:54,913 INFO:     Epoch: 11
2023-01-04 03:01:56,505 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39678432842095696, 'Total loss': 0.39678432842095696} | train loss {'Reaction outcome loss': 0.37044551109310486, 'Total loss': 0.37044551109310486}
2023-01-04 03:01:56,505 INFO:     Found new best model at epoch 11
2023-01-04 03:01:56,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:56,506 INFO:     Epoch: 12
2023-01-04 03:01:58,090 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41570808589458463, 'Total loss': 0.41570808589458463} | train loss {'Reaction outcome loss': 0.36073725790220457, 'Total loss': 0.36073725790220457}
2023-01-04 03:01:58,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:58,091 INFO:     Epoch: 13
2023-01-04 03:01:59,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3930531362692515, 'Total loss': 0.3930531362692515} | train loss {'Reaction outcome loss': 0.3549005545566987, 'Total loss': 0.3549005545566987}
2023-01-04 03:01:59,675 INFO:     Found new best model at epoch 13
2023-01-04 03:01:59,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:01:59,676 INFO:     Epoch: 14
2023-01-04 03:02:01,244 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3877248664697011, 'Total loss': 0.3877248664697011} | train loss {'Reaction outcome loss': 0.3452976524938632, 'Total loss': 0.3452976524938632}
2023-01-04 03:02:01,244 INFO:     Found new best model at epoch 14
2023-01-04 03:02:01,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:01,245 INFO:     Epoch: 15
2023-01-04 03:02:02,853 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38502227067947387, 'Total loss': 0.38502227067947387} | train loss {'Reaction outcome loss': 0.3386753582443199, 'Total loss': 0.3386753582443199}
2023-01-04 03:02:02,853 INFO:     Found new best model at epoch 15
2023-01-04 03:02:02,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:02,854 INFO:     Epoch: 16
2023-01-04 03:02:04,462 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3897467166185379, 'Total loss': 0.3897467166185379} | train loss {'Reaction outcome loss': 0.3324866063457771, 'Total loss': 0.3324866063457771}
2023-01-04 03:02:04,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:04,463 INFO:     Epoch: 17
2023-01-04 03:02:06,042 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3740160306294759, 'Total loss': 0.3740160306294759} | train loss {'Reaction outcome loss': 0.32598134478295804, 'Total loss': 0.32598134478295804}
2023-01-04 03:02:06,042 INFO:     Found new best model at epoch 17
2023-01-04 03:02:06,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:06,043 INFO:     Epoch: 18
2023-01-04 03:02:07,622 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3691148484746615, 'Total loss': 0.3691148484746615} | train loss {'Reaction outcome loss': 0.32194321026114653, 'Total loss': 0.32194321026114653}
2023-01-04 03:02:07,622 INFO:     Found new best model at epoch 18
2023-01-04 03:02:07,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:07,623 INFO:     Epoch: 19
2023-01-04 03:02:09,223 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38746796051661175, 'Total loss': 0.38746796051661175} | train loss {'Reaction outcome loss': 0.3200651935308519, 'Total loss': 0.3200651935308519}
2023-01-04 03:02:09,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:09,224 INFO:     Epoch: 20
2023-01-04 03:02:10,790 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37816335161527, 'Total loss': 0.37816335161527} | train loss {'Reaction outcome loss': 0.31215550531599207, 'Total loss': 0.31215550531599207}
2023-01-04 03:02:10,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:10,790 INFO:     Epoch: 21
2023-01-04 03:02:12,375 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3764017711083094, 'Total loss': 0.3764017711083094} | train loss {'Reaction outcome loss': 0.30588595792107337, 'Total loss': 0.30588595792107337}
2023-01-04 03:02:12,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:12,375 INFO:     Epoch: 22
2023-01-04 03:02:13,952 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38849103649457295, 'Total loss': 0.38849103649457295} | train loss {'Reaction outcome loss': 0.30482523507662934, 'Total loss': 0.30482523507662934}
2023-01-04 03:02:13,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:13,953 INFO:     Epoch: 23
2023-01-04 03:02:15,526 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38211508591969806, 'Total loss': 0.38211508591969806} | train loss {'Reaction outcome loss': 0.2992253288844206, 'Total loss': 0.2992253288844206}
2023-01-04 03:02:15,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:15,526 INFO:     Epoch: 24
2023-01-04 03:02:17,109 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40128946900367735, 'Total loss': 0.40128946900367735} | train loss {'Reaction outcome loss': 0.2943523455220852, 'Total loss': 0.2943523455220852}
2023-01-04 03:02:17,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:17,110 INFO:     Epoch: 25
2023-01-04 03:02:18,682 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39524054527282715, 'Total loss': 0.39524054527282715} | train loss {'Reaction outcome loss': 0.2923285824103947, 'Total loss': 0.2923285824103947}
2023-01-04 03:02:18,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:18,682 INFO:     Epoch: 26
2023-01-04 03:02:20,293 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3922011742989222, 'Total loss': 0.3922011742989222} | train loss {'Reaction outcome loss': 0.2894562934083443, 'Total loss': 0.2894562934083443}
2023-01-04 03:02:20,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:20,293 INFO:     Epoch: 27
2023-01-04 03:02:21,904 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38475700914859773, 'Total loss': 0.38475700914859773} | train loss {'Reaction outcome loss': 0.2824367335351714, 'Total loss': 0.2824367335351714}
2023-01-04 03:02:21,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:21,905 INFO:     Epoch: 28
2023-01-04 03:02:23,491 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3847225884596507, 'Total loss': 0.3847225884596507} | train loss {'Reaction outcome loss': 0.2813648720999269, 'Total loss': 0.2813648720999269}
2023-01-04 03:02:23,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:23,492 INFO:     Epoch: 29
2023-01-04 03:02:25,103 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38379505077997844, 'Total loss': 0.38379505077997844} | train loss {'Reaction outcome loss': 0.2764054686102989, 'Total loss': 0.2764054686102989}
2023-01-04 03:02:25,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:25,103 INFO:     Epoch: 30
2023-01-04 03:02:26,715 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3994869510332743, 'Total loss': 0.3994869510332743} | train loss {'Reaction outcome loss': 0.2730492450786333, 'Total loss': 0.2730492450786333}
2023-01-04 03:02:26,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:26,715 INFO:     Epoch: 31
2023-01-04 03:02:28,303 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3900610864162445, 'Total loss': 0.3900610864162445} | train loss {'Reaction outcome loss': 0.26978072725290797, 'Total loss': 0.26978072725290797}
2023-01-04 03:02:28,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:28,303 INFO:     Epoch: 32
2023-01-04 03:02:29,915 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3809892773628235, 'Total loss': 0.3809892773628235} | train loss {'Reaction outcome loss': 0.2668321050812293, 'Total loss': 0.2668321050812293}
2023-01-04 03:02:29,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:29,915 INFO:     Epoch: 33
2023-01-04 03:02:31,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3831774353981018, 'Total loss': 0.3831774353981018} | train loss {'Reaction outcome loss': 0.2637627370329234, 'Total loss': 0.2637627370329234}
2023-01-04 03:02:31,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:31,526 INFO:     Epoch: 34
2023-01-04 03:02:33,102 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3906331479549408, 'Total loss': 0.3906331479549408} | train loss {'Reaction outcome loss': 0.26199039795102863, 'Total loss': 0.26199039795102863}
2023-01-04 03:02:33,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:33,104 INFO:     Epoch: 35
2023-01-04 03:02:34,688 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3785096968213717, 'Total loss': 0.3785096968213717} | train loss {'Reaction outcome loss': 0.25719468203121726, 'Total loss': 0.25719468203121726}
2023-01-04 03:02:34,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:34,688 INFO:     Epoch: 36
2023-01-04 03:02:36,265 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38143486380577085, 'Total loss': 0.38143486380577085} | train loss {'Reaction outcome loss': 0.2535642247076017, 'Total loss': 0.2535642247076017}
2023-01-04 03:02:36,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:36,266 INFO:     Epoch: 37
2023-01-04 03:02:37,866 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3713750829299291, 'Total loss': 0.3713750829299291} | train loss {'Reaction outcome loss': 0.25282648065718855, 'Total loss': 0.25282648065718855}
2023-01-04 03:02:37,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:37,866 INFO:     Epoch: 38
2023-01-04 03:02:39,472 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3689705496033033, 'Total loss': 0.3689705496033033} | train loss {'Reaction outcome loss': 0.24850959798497876, 'Total loss': 0.24850959798497876}
2023-01-04 03:02:39,473 INFO:     Found new best model at epoch 38
2023-01-04 03:02:39,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:39,474 INFO:     Epoch: 39
2023-01-04 03:02:41,056 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4275064090887705, 'Total loss': 0.4275064090887705} | train loss {'Reaction outcome loss': 0.24566869066525115, 'Total loss': 0.24566869066525115}
2023-01-04 03:02:41,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:41,056 INFO:     Epoch: 40
2023-01-04 03:02:42,635 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39437392055988313, 'Total loss': 0.39437392055988313} | train loss {'Reaction outcome loss': 0.24460649738142634, 'Total loss': 0.24460649738142634}
2023-01-04 03:02:42,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:42,635 INFO:     Epoch: 41
2023-01-04 03:02:44,217 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4172998875379562, 'Total loss': 0.4172998875379562} | train loss {'Reaction outcome loss': 0.24161482610515433, 'Total loss': 0.24161482610515433}
2023-01-04 03:02:44,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:44,217 INFO:     Epoch: 42
2023-01-04 03:02:45,803 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3910066306591034, 'Total loss': 0.3910066306591034} | train loss {'Reaction outcome loss': 0.2401540461166279, 'Total loss': 0.2401540461166279}
2023-01-04 03:02:45,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:45,804 INFO:     Epoch: 43
2023-01-04 03:02:47,409 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3985255797704061, 'Total loss': 0.3985255797704061} | train loss {'Reaction outcome loss': 0.23677471149576843, 'Total loss': 0.23677471149576843}
2023-01-04 03:02:47,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:47,409 INFO:     Epoch: 44
2023-01-04 03:02:49,028 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37964998682339984, 'Total loss': 0.37964998682339984} | train loss {'Reaction outcome loss': 0.23483980108514754, 'Total loss': 0.23483980108514754}
2023-01-04 03:02:49,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:49,029 INFO:     Epoch: 45
2023-01-04 03:02:50,607 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.392928613225619, 'Total loss': 0.392928613225619} | train loss {'Reaction outcome loss': 0.23523745029131427, 'Total loss': 0.23523745029131427}
2023-01-04 03:02:50,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:50,607 INFO:     Epoch: 46
2023-01-04 03:02:52,194 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3836290587981542, 'Total loss': 0.3836290587981542} | train loss {'Reaction outcome loss': 0.22847162227887308, 'Total loss': 0.22847162227887308}
2023-01-04 03:02:52,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:52,195 INFO:     Epoch: 47
2023-01-04 03:02:53,780 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3933447554707527, 'Total loss': 0.3933447554707527} | train loss {'Reaction outcome loss': 0.22811155592220544, 'Total loss': 0.22811155592220544}
2023-01-04 03:02:53,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:53,780 INFO:     Epoch: 48
2023-01-04 03:02:55,360 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37792129516601564, 'Total loss': 0.37792129516601564} | train loss {'Reaction outcome loss': 0.22605767116004968, 'Total loss': 0.22605767116004968}
2023-01-04 03:02:55,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:55,360 INFO:     Epoch: 49
2023-01-04 03:02:56,967 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39160051743189495, 'Total loss': 0.39160051743189495} | train loss {'Reaction outcome loss': 0.22303973203592928, 'Total loss': 0.22303973203592928}
2023-01-04 03:02:56,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:56,967 INFO:     Epoch: 50
2023-01-04 03:02:58,555 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40567218760649365, 'Total loss': 0.40567218760649365} | train loss {'Reaction outcome loss': 0.2225095796582364, 'Total loss': 0.2225095796582364}
2023-01-04 03:02:58,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:02:58,555 INFO:     Epoch: 51
2023-01-04 03:03:00,133 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4206586937109629, 'Total loss': 0.4206586937109629} | train loss {'Reaction outcome loss': 0.22064650314350198, 'Total loss': 0.22064650314350198}
2023-01-04 03:03:00,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:00,134 INFO:     Epoch: 52
2023-01-04 03:03:01,714 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.379377518594265, 'Total loss': 0.379377518594265} | train loss {'Reaction outcome loss': 0.21674877764099706, 'Total loss': 0.21674877764099706}
2023-01-04 03:03:01,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:01,714 INFO:     Epoch: 53
2023-01-04 03:03:03,282 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4144442280133565, 'Total loss': 0.4144442280133565} | train loss {'Reaction outcome loss': 0.21563430607699566, 'Total loss': 0.21563430607699566}
2023-01-04 03:03:03,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:03,283 INFO:     Epoch: 54
2023-01-04 03:03:04,882 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41156426866849266, 'Total loss': 0.41156426866849266} | train loss {'Reaction outcome loss': 0.2158344381074183, 'Total loss': 0.2158344381074183}
2023-01-04 03:03:04,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:04,883 INFO:     Epoch: 55
2023-01-04 03:03:06,489 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41171438892682394, 'Total loss': 0.41171438892682394} | train loss {'Reaction outcome loss': 0.21310682521358024, 'Total loss': 0.21310682521358024}
2023-01-04 03:03:06,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:06,490 INFO:     Epoch: 56
2023-01-04 03:03:08,079 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3932509313027064, 'Total loss': 0.3932509313027064} | train loss {'Reaction outcome loss': 0.2117571749377751, 'Total loss': 0.2117571749377751}
2023-01-04 03:03:08,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:08,080 INFO:     Epoch: 57
2023-01-04 03:03:09,689 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.395330211520195, 'Total loss': 0.395330211520195} | train loss {'Reaction outcome loss': 0.21295096827195073, 'Total loss': 0.21295096827195073}
2023-01-04 03:03:09,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:09,689 INFO:     Epoch: 58
2023-01-04 03:03:11,299 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4213049679994583, 'Total loss': 0.4213049679994583} | train loss {'Reaction outcome loss': 0.208051458218672, 'Total loss': 0.208051458218672}
2023-01-04 03:03:11,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:11,300 INFO:     Epoch: 59
2023-01-04 03:03:12,867 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3926509181658427, 'Total loss': 0.3926509181658427} | train loss {'Reaction outcome loss': 0.2067202407948292, 'Total loss': 0.2067202407948292}
2023-01-04 03:03:12,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:12,867 INFO:     Epoch: 60
2023-01-04 03:03:14,470 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39198808471361796, 'Total loss': 0.39198808471361796} | train loss {'Reaction outcome loss': 0.205549531765826, 'Total loss': 0.205549531765826}
2023-01-04 03:03:14,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:14,470 INFO:     Epoch: 61
2023-01-04 03:03:16,080 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39731770534999666, 'Total loss': 0.39731770534999666} | train loss {'Reaction outcome loss': 0.2031266980729725, 'Total loss': 0.2031266980729725}
2023-01-04 03:03:16,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:16,080 INFO:     Epoch: 62
2023-01-04 03:03:17,659 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4247184971968333, 'Total loss': 0.4247184971968333} | train loss {'Reaction outcome loss': 0.2030081672145285, 'Total loss': 0.2030081672145285}
2023-01-04 03:03:17,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:17,660 INFO:     Epoch: 63
2023-01-04 03:03:19,269 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4092224478721619, 'Total loss': 0.4092224478721619} | train loss {'Reaction outcome loss': 0.20406552276363338, 'Total loss': 0.20406552276363338}
2023-01-04 03:03:19,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:19,269 INFO:     Epoch: 64
2023-01-04 03:03:20,878 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40113237003485364, 'Total loss': 0.40113237003485364} | train loss {'Reaction outcome loss': 0.20086597842266307, 'Total loss': 0.20086597842266307}
2023-01-04 03:03:20,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:20,879 INFO:     Epoch: 65
2023-01-04 03:03:22,459 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38269636531670886, 'Total loss': 0.38269636531670886} | train loss {'Reaction outcome loss': 0.20072704136888259, 'Total loss': 0.20072704136888259}
2023-01-04 03:03:22,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:22,460 INFO:     Epoch: 66
2023-01-04 03:03:24,069 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4123031248648961, 'Total loss': 0.4123031248648961} | train loss {'Reaction outcome loss': 0.1990182422862871, 'Total loss': 0.1990182422862871}
2023-01-04 03:03:24,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:24,070 INFO:     Epoch: 67
2023-01-04 03:03:25,646 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4027875522772471, 'Total loss': 0.4027875522772471} | train loss {'Reaction outcome loss': 0.19795073502880595, 'Total loss': 0.19795073502880595}
2023-01-04 03:03:25,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:25,646 INFO:     Epoch: 68
2023-01-04 03:03:27,211 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4374481866757075, 'Total loss': 0.4374481866757075} | train loss {'Reaction outcome loss': 0.1953421740174076, 'Total loss': 0.1953421740174076}
2023-01-04 03:03:27,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:27,211 INFO:     Epoch: 69
2023-01-04 03:03:28,819 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4101653218269348, 'Total loss': 0.4101653218269348} | train loss {'Reaction outcome loss': 0.19547058731643824, 'Total loss': 0.19547058731643824}
2023-01-04 03:03:28,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:28,819 INFO:     Epoch: 70
2023-01-04 03:03:30,407 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3903589755296707, 'Total loss': 0.3903589755296707} | train loss {'Reaction outcome loss': 0.19456827855349457, 'Total loss': 0.19456827855349457}
2023-01-04 03:03:30,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:30,407 INFO:     Epoch: 71
2023-01-04 03:03:32,016 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4208626021941503, 'Total loss': 0.4208626021941503} | train loss {'Reaction outcome loss': 0.1929434995255331, 'Total loss': 0.1929434995255331}
2023-01-04 03:03:32,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:32,017 INFO:     Epoch: 72
2023-01-04 03:03:33,624 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40844675252834955, 'Total loss': 0.40844675252834955} | train loss {'Reaction outcome loss': 0.191431203109287, 'Total loss': 0.191431203109287}
2023-01-04 03:03:33,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:33,624 INFO:     Epoch: 73
2023-01-04 03:03:35,220 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4100838954250018, 'Total loss': 0.4100838954250018} | train loss {'Reaction outcome loss': 0.1912711383978816, 'Total loss': 0.1912711383978816}
2023-01-04 03:03:35,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:35,220 INFO:     Epoch: 74
2023-01-04 03:03:36,833 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40279455184936525, 'Total loss': 0.40279455184936525} | train loss {'Reaction outcome loss': 0.19187485086765602, 'Total loss': 0.19187485086765602}
2023-01-04 03:03:36,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:36,833 INFO:     Epoch: 75
2023-01-04 03:03:38,407 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.410631000995636, 'Total loss': 0.410631000995636} | train loss {'Reaction outcome loss': 0.1881274886660441, 'Total loss': 0.1881274886660441}
2023-01-04 03:03:38,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:38,407 INFO:     Epoch: 76
2023-01-04 03:03:39,994 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4237909376621246, 'Total loss': 0.4237909376621246} | train loss {'Reaction outcome loss': 0.18918522821236267, 'Total loss': 0.18918522821236267}
2023-01-04 03:03:39,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:39,995 INFO:     Epoch: 77
2023-01-04 03:03:41,607 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43071892857551575, 'Total loss': 0.43071892857551575} | train loss {'Reaction outcome loss': 0.18849357269894684, 'Total loss': 0.18849357269894684}
2023-01-04 03:03:41,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:41,607 INFO:     Epoch: 78
2023-01-04 03:03:43,220 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3985047866900762, 'Total loss': 0.3985047866900762} | train loss {'Reaction outcome loss': 0.18709319441776423, 'Total loss': 0.18709319441776423}
2023-01-04 03:03:43,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:43,220 INFO:     Epoch: 79
2023-01-04 03:03:44,800 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39968984524408974, 'Total loss': 0.39968984524408974} | train loss {'Reaction outcome loss': 0.1856768932057558, 'Total loss': 0.1856768932057558}
2023-01-04 03:03:44,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:44,800 INFO:     Epoch: 80
2023-01-04 03:03:46,381 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4068080311020215, 'Total loss': 0.4068080311020215} | train loss {'Reaction outcome loss': 0.1839781383963397, 'Total loss': 0.1839781383963397}
2023-01-04 03:03:46,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:46,382 INFO:     Epoch: 81
2023-01-04 03:03:48,020 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39753192762533823, 'Total loss': 0.39753192762533823} | train loss {'Reaction outcome loss': 0.18218935824196486, 'Total loss': 0.18218935824196486}
2023-01-04 03:03:48,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:48,020 INFO:     Epoch: 82
2023-01-04 03:03:49,611 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4305871665477753, 'Total loss': 0.4305871665477753} | train loss {'Reaction outcome loss': 0.18324541764157096, 'Total loss': 0.18324541764157096}
2023-01-04 03:03:49,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:49,611 INFO:     Epoch: 83
2023-01-04 03:03:51,254 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4244413549701373, 'Total loss': 0.4244413549701373} | train loss {'Reaction outcome loss': 0.18039697526281115, 'Total loss': 0.18039697526281115}
2023-01-04 03:03:51,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:51,254 INFO:     Epoch: 84
2023-01-04 03:03:52,899 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4016851782798767, 'Total loss': 0.4016851782798767} | train loss {'Reaction outcome loss': 0.17881936210132862, 'Total loss': 0.17881936210132862}
2023-01-04 03:03:52,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:52,899 INFO:     Epoch: 85
2023-01-04 03:03:54,473 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4283571183681488, 'Total loss': 0.4283571183681488} | train loss {'Reaction outcome loss': 0.1791873063321096, 'Total loss': 0.1791873063321096}
2023-01-04 03:03:54,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:54,473 INFO:     Epoch: 86
2023-01-04 03:03:56,117 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41455510854721067, 'Total loss': 0.41455510854721067} | train loss {'Reaction outcome loss': 0.1800403294772127, 'Total loss': 0.1800403294772127}
2023-01-04 03:03:56,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:56,117 INFO:     Epoch: 87
2023-01-04 03:03:57,731 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4226455142100652, 'Total loss': 0.4226455142100652} | train loss {'Reaction outcome loss': 0.17818893037097405, 'Total loss': 0.17818893037097405}
2023-01-04 03:03:57,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:57,731 INFO:     Epoch: 88
2023-01-04 03:03:59,376 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4375572760899862, 'Total loss': 0.4375572760899862} | train loss {'Reaction outcome loss': 0.18038134126631666, 'Total loss': 0.18038134126631666}
2023-01-04 03:03:59,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:03:59,376 INFO:     Epoch: 89
2023-01-04 03:04:01,001 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4108384013175964, 'Total loss': 0.4108384013175964} | train loss {'Reaction outcome loss': 0.17701605926301792, 'Total loss': 0.17701605926301792}
2023-01-04 03:04:01,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:01,002 INFO:     Epoch: 90
2023-01-04 03:04:02,619 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4273419896761576, 'Total loss': 0.4273419896761576} | train loss {'Reaction outcome loss': 0.17531324901284961, 'Total loss': 0.17531324901284961}
2023-01-04 03:04:02,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:02,620 INFO:     Epoch: 91
2023-01-04 03:04:04,261 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43293577631314595, 'Total loss': 0.43293577631314595} | train loss {'Reaction outcome loss': 0.17450276316299926, 'Total loss': 0.17450276316299926}
2023-01-04 03:04:04,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:04,261 INFO:     Epoch: 92
2023-01-04 03:04:05,907 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4540568153063456, 'Total loss': 0.4540568153063456} | train loss {'Reaction outcome loss': 0.1746797238333817, 'Total loss': 0.1746797238333817}
2023-01-04 03:04:05,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:05,907 INFO:     Epoch: 93
2023-01-04 03:04:07,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43863836030165354, 'Total loss': 0.43863836030165354} | train loss {'Reaction outcome loss': 0.1739458779695641, 'Total loss': 0.1739458779695641}
2023-01-04 03:04:07,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:07,538 INFO:     Epoch: 94
2023-01-04 03:04:09,113 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4326160033543905, 'Total loss': 0.4326160033543905} | train loss {'Reaction outcome loss': 0.17342505004447306, 'Total loss': 0.17342505004447306}
2023-01-04 03:04:09,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:09,113 INFO:     Epoch: 95
2023-01-04 03:04:10,758 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43043177127838134, 'Total loss': 0.43043177127838134} | train loss {'Reaction outcome loss': 0.1706407619640231, 'Total loss': 0.1706407619640231}
2023-01-04 03:04:10,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:10,759 INFO:     Epoch: 96
2023-01-04 03:04:12,327 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42384226123491925, 'Total loss': 0.42384226123491925} | train loss {'Reaction outcome loss': 0.1726235226204578, 'Total loss': 0.1726235226204578}
2023-01-04 03:04:12,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:12,328 INFO:     Epoch: 97
2023-01-04 03:04:13,909 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4427782972653707, 'Total loss': 0.4427782972653707} | train loss {'Reaction outcome loss': 0.1723515414870786, 'Total loss': 0.1723515414870786}
2023-01-04 03:04:13,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:13,910 INFO:     Epoch: 98
2023-01-04 03:04:15,492 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4588763991991679, 'Total loss': 0.4588763991991679} | train loss {'Reaction outcome loss': 0.1716726820535251, 'Total loss': 0.1716726820535251}
2023-01-04 03:04:15,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:15,493 INFO:     Epoch: 99
2023-01-04 03:04:17,080 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43834274808565776, 'Total loss': 0.43834274808565776} | train loss {'Reaction outcome loss': 0.17275647153520454, 'Total loss': 0.17275647153520454}
2023-01-04 03:04:17,081 INFO:     Best model found after epoch 39 of 100.
2023-01-04 03:04:17,082 INFO:   Done with stage: TRAINING
2023-01-04 03:04:17,082 INFO:   Starting stage: EVALUATION
2023-01-04 03:04:17,214 INFO:   Done with stage: EVALUATION
2023-01-04 03:04:17,215 INFO:   Leaving out SEQ value Fold_3
2023-01-04 03:04:17,227 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 03:04:17,227 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:04:17,875 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:04:17,875 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:04:17,944 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:04:17,944 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:04:17,944 INFO:     No hyperparam tuning for this model
2023-01-04 03:04:17,944 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:04:17,944 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:04:17,945 INFO:     None feature selector for col prot
2023-01-04 03:04:17,945 INFO:     None feature selector for col prot
2023-01-04 03:04:17,945 INFO:     None feature selector for col prot
2023-01-04 03:04:17,946 INFO:     None feature selector for col chem
2023-01-04 03:04:17,946 INFO:     None feature selector for col chem
2023-01-04 03:04:17,946 INFO:     None feature selector for col chem
2023-01-04 03:04:17,946 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:04:17,946 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:04:17,947 INFO:     Number of params in model 70141
2023-01-04 03:04:17,951 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:04:17,951 INFO:   Starting stage: TRAINING
2023-01-04 03:04:17,994 INFO:     Val loss before train {'Reaction outcome loss': 0.9596171498298645, 'Total loss': 0.9596171498298645}
2023-01-04 03:04:17,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:17,994 INFO:     Epoch: 0
2023-01-04 03:04:19,613 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6187877535820008, 'Total loss': 0.6187877535820008} | train loss {'Reaction outcome loss': 0.8504963512838322, 'Total loss': 0.8504963512838322}
2023-01-04 03:04:19,613 INFO:     Found new best model at epoch 0
2023-01-04 03:04:19,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:19,614 INFO:     Epoch: 1
2023-01-04 03:04:21,197 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.530817644794782, 'Total loss': 0.530817644794782} | train loss {'Reaction outcome loss': 0.6043965871969279, 'Total loss': 0.6043965871969279}
2023-01-04 03:04:21,197 INFO:     Found new best model at epoch 1
2023-01-04 03:04:21,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:21,198 INFO:     Epoch: 2
2023-01-04 03:04:22,770 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4906085709730784, 'Total loss': 0.4906085709730784} | train loss {'Reaction outcome loss': 0.5400545735211268, 'Total loss': 0.5400545735211268}
2023-01-04 03:04:22,770 INFO:     Found new best model at epoch 2
2023-01-04 03:04:22,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:22,771 INFO:     Epoch: 3
2023-01-04 03:04:24,381 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46933218638102214, 'Total loss': 0.46933218638102214} | train loss {'Reaction outcome loss': 0.5031213359023533, 'Total loss': 0.5031213359023533}
2023-01-04 03:04:24,381 INFO:     Found new best model at epoch 3
2023-01-04 03:04:24,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:24,382 INFO:     Epoch: 4
2023-01-04 03:04:25,960 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47019011080265044, 'Total loss': 0.47019011080265044} | train loss {'Reaction outcome loss': 0.47474369004260014, 'Total loss': 0.47474369004260014}
2023-01-04 03:04:25,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:25,960 INFO:     Epoch: 5
2023-01-04 03:04:27,541 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4528776446978251, 'Total loss': 0.4528776446978251} | train loss {'Reaction outcome loss': 0.45378040293925, 'Total loss': 0.45378040293925}
2023-01-04 03:04:27,541 INFO:     Found new best model at epoch 5
2023-01-04 03:04:27,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:27,542 INFO:     Epoch: 6
2023-01-04 03:04:29,105 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45811866223812103, 'Total loss': 0.45811866223812103} | train loss {'Reaction outcome loss': 0.43643494836822916, 'Total loss': 0.43643494836822916}
2023-01-04 03:04:29,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:29,106 INFO:     Epoch: 7
2023-01-04 03:04:30,692 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42562937140464785, 'Total loss': 0.42562937140464785} | train loss {'Reaction outcome loss': 0.4212673620259675, 'Total loss': 0.4212673620259675}
2023-01-04 03:04:30,692 INFO:     Found new best model at epoch 7
2023-01-04 03:04:30,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:30,693 INFO:     Epoch: 8
2023-01-04 03:04:32,276 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4155849913756053, 'Total loss': 0.4155849913756053} | train loss {'Reaction outcome loss': 0.4087235954773687, 'Total loss': 0.4087235954773687}
2023-01-04 03:04:32,276 INFO:     Found new best model at epoch 8
2023-01-04 03:04:32,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:32,277 INFO:     Epoch: 9
2023-01-04 03:04:33,837 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.422879030307134, 'Total loss': 0.422879030307134} | train loss {'Reaction outcome loss': 0.3971233848672714, 'Total loss': 0.3971233848672714}
2023-01-04 03:04:33,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:33,837 INFO:     Epoch: 10
2023-01-04 03:04:35,420 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42012785176436107, 'Total loss': 0.42012785176436107} | train loss {'Reaction outcome loss': 0.3870851811375061, 'Total loss': 0.3870851811375061}
2023-01-04 03:04:35,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:35,421 INFO:     Epoch: 11
2023-01-04 03:04:37,005 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4112905542055766, 'Total loss': 0.4112905542055766} | train loss {'Reaction outcome loss': 0.37836790748321225, 'Total loss': 0.37836790748321225}
2023-01-04 03:04:37,005 INFO:     Found new best model at epoch 11
2023-01-04 03:04:37,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:37,006 INFO:     Epoch: 12
2023-01-04 03:04:38,377 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.411643260717392, 'Total loss': 0.411643260717392} | train loss {'Reaction outcome loss': 0.36878853818795976, 'Total loss': 0.36878853818795976}
2023-01-04 03:04:38,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:38,377 INFO:     Epoch: 13
2023-01-04 03:04:39,421 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4097326288620631, 'Total loss': 0.4097326288620631} | train loss {'Reaction outcome loss': 0.3618834920662598, 'Total loss': 0.3618834920662598}
2023-01-04 03:04:39,421 INFO:     Found new best model at epoch 13
2023-01-04 03:04:39,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:39,422 INFO:     Epoch: 14
2023-01-04 03:04:40,460 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43597969313462576, 'Total loss': 0.43597969313462576} | train loss {'Reaction outcome loss': 0.3525622191764142, 'Total loss': 0.3525622191764142}
2023-01-04 03:04:40,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:40,460 INFO:     Epoch: 15
2023-01-04 03:04:41,537 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41869584619998934, 'Total loss': 0.41869584619998934} | train loss {'Reaction outcome loss': 0.34555885016265575, 'Total loss': 0.34555885016265575}
2023-01-04 03:04:41,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:41,538 INFO:     Epoch: 16
2023-01-04 03:04:42,669 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40680977602799734, 'Total loss': 0.40680977602799734} | train loss {'Reaction outcome loss': 0.33998578501335025, 'Total loss': 0.33998578501335025}
2023-01-04 03:04:42,669 INFO:     Found new best model at epoch 16
2023-01-04 03:04:42,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:42,670 INFO:     Epoch: 17
2023-01-04 03:04:44,271 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40815575619538624, 'Total loss': 0.40815575619538624} | train loss {'Reaction outcome loss': 0.3341493535868443, 'Total loss': 0.3341493535868443}
2023-01-04 03:04:44,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:44,271 INFO:     Epoch: 18
2023-01-04 03:04:45,844 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40737732549508415, 'Total loss': 0.40737732549508415} | train loss {'Reaction outcome loss': 0.33006252209744313, 'Total loss': 0.33006252209744313}
2023-01-04 03:04:45,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:45,845 INFO:     Epoch: 19
2023-01-04 03:04:47,450 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4102604607741038, 'Total loss': 0.4102604607741038} | train loss {'Reaction outcome loss': 0.32404639077012554, 'Total loss': 0.32404639077012554}
2023-01-04 03:04:47,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:47,450 INFO:     Epoch: 20
2023-01-04 03:04:49,036 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4049953470627467, 'Total loss': 0.4049953470627467} | train loss {'Reaction outcome loss': 0.31762681634974305, 'Total loss': 0.31762681634974305}
2023-01-04 03:04:49,037 INFO:     Found new best model at epoch 20
2023-01-04 03:04:49,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:49,038 INFO:     Epoch: 21
2023-01-04 03:04:50,620 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4094583600759506, 'Total loss': 0.4094583600759506} | train loss {'Reaction outcome loss': 0.31392528655102653, 'Total loss': 0.31392528655102653}
2023-01-04 03:04:50,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:50,620 INFO:     Epoch: 22
2023-01-04 03:04:52,192 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38594863514105476, 'Total loss': 0.38594863514105476} | train loss {'Reaction outcome loss': 0.30792011176473905, 'Total loss': 0.30792011176473905}
2023-01-04 03:04:52,192 INFO:     Found new best model at epoch 22
2023-01-04 03:04:52,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:52,193 INFO:     Epoch: 23
2023-01-04 03:04:53,777 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39836332599322, 'Total loss': 0.39836332599322} | train loss {'Reaction outcome loss': 0.3043869651418968, 'Total loss': 0.3043869651418968}
2023-01-04 03:04:53,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:53,777 INFO:     Epoch: 24
2023-01-04 03:04:55,362 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40707001884778343, 'Total loss': 0.40707001884778343} | train loss {'Reaction outcome loss': 0.3000750013076476, 'Total loss': 0.3000750013076476}
2023-01-04 03:04:55,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:55,362 INFO:     Epoch: 25
2023-01-04 03:04:56,948 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39011464913686117, 'Total loss': 0.39011464913686117} | train loss {'Reaction outcome loss': 0.29770999415403737, 'Total loss': 0.29770999415403737}
2023-01-04 03:04:56,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:56,948 INFO:     Epoch: 26
2023-01-04 03:04:58,533 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42096967399120333, 'Total loss': 0.42096967399120333} | train loss {'Reaction outcome loss': 0.2922058188947883, 'Total loss': 0.2922058188947883}
2023-01-04 03:04:58,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:04:58,534 INFO:     Epoch: 27
2023-01-04 03:05:00,153 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4154545783996582, 'Total loss': 0.4154545783996582} | train loss {'Reaction outcome loss': 0.28897207975387573, 'Total loss': 0.28897207975387573}
2023-01-04 03:05:00,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:00,153 INFO:     Epoch: 28
2023-01-04 03:05:01,718 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4115206728378932, 'Total loss': 0.4115206728378932} | train loss {'Reaction outcome loss': 0.2846918333131466, 'Total loss': 0.2846918333131466}
2023-01-04 03:05:01,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:01,718 INFO:     Epoch: 29
2023-01-04 03:05:03,320 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40418792540828385, 'Total loss': 0.40418792540828385} | train loss {'Reaction outcome loss': 0.2816318099516152, 'Total loss': 0.2816318099516152}
2023-01-04 03:05:03,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:03,320 INFO:     Epoch: 30
2023-01-04 03:05:04,913 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42812257011731464, 'Total loss': 0.42812257011731464} | train loss {'Reaction outcome loss': 0.27913423244209185, 'Total loss': 0.27913423244209185}
2023-01-04 03:05:04,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:04,914 INFO:     Epoch: 31
2023-01-04 03:05:06,527 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4152010599772135, 'Total loss': 0.4152010599772135} | train loss {'Reaction outcome loss': 0.2760363995865749, 'Total loss': 0.2760363995865749}
2023-01-04 03:05:06,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:06,527 INFO:     Epoch: 32
2023-01-04 03:05:08,111 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38577095965544383, 'Total loss': 0.38577095965544383} | train loss {'Reaction outcome loss': 0.273040831034636, 'Total loss': 0.273040831034636}
2023-01-04 03:05:08,111 INFO:     Found new best model at epoch 32
2023-01-04 03:05:08,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:08,112 INFO:     Epoch: 33
2023-01-04 03:05:09,719 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4142766853173574, 'Total loss': 0.4142766853173574} | train loss {'Reaction outcome loss': 0.27048277471513643, 'Total loss': 0.27048277471513643}
2023-01-04 03:05:09,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:09,719 INFO:     Epoch: 34
2023-01-04 03:05:11,314 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41174318790435793, 'Total loss': 0.41174318790435793} | train loss {'Reaction outcome loss': 0.26755229922106666, 'Total loss': 0.26755229922106666}
2023-01-04 03:05:11,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:11,314 INFO:     Epoch: 35
2023-01-04 03:05:12,935 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4203341960906982, 'Total loss': 0.4203341960906982} | train loss {'Reaction outcome loss': 0.2638884593535514, 'Total loss': 0.2638884593535514}
2023-01-04 03:05:12,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:12,937 INFO:     Epoch: 36
2023-01-04 03:05:14,536 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4374099443356196, 'Total loss': 0.4374099443356196} | train loss {'Reaction outcome loss': 0.2588709383169665, 'Total loss': 0.2588709383169665}
2023-01-04 03:05:14,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:14,537 INFO:     Epoch: 37
2023-01-04 03:05:16,124 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40344456136226653, 'Total loss': 0.40344456136226653} | train loss {'Reaction outcome loss': 0.2587084110799062, 'Total loss': 0.2587084110799062}
2023-01-04 03:05:16,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:16,125 INFO:     Epoch: 38
2023-01-04 03:05:17,730 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40609455704689024, 'Total loss': 0.40609455704689024} | train loss {'Reaction outcome loss': 0.2569995017001664, 'Total loss': 0.2569995017001664}
2023-01-04 03:05:17,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:17,730 INFO:     Epoch: 39
2023-01-04 03:05:19,333 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40471083025137583, 'Total loss': 0.40471083025137583} | train loss {'Reaction outcome loss': 0.25279700531739824, 'Total loss': 0.25279700531739824}
2023-01-04 03:05:19,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:19,334 INFO:     Epoch: 40
2023-01-04 03:05:20,936 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4368785798549652, 'Total loss': 0.4368785798549652} | train loss {'Reaction outcome loss': 0.2516177671342871, 'Total loss': 0.2516177671342871}
2023-01-04 03:05:20,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:20,936 INFO:     Epoch: 41
2023-01-04 03:05:22,529 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4109598398208618, 'Total loss': 0.4109598398208618} | train loss {'Reaction outcome loss': 0.2510371199761429, 'Total loss': 0.2510371199761429}
2023-01-04 03:05:22,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:22,530 INFO:     Epoch: 42
2023-01-04 03:05:24,144 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4208174109458923, 'Total loss': 0.4208174109458923} | train loss {'Reaction outcome loss': 0.245411960013809, 'Total loss': 0.245411960013809}
2023-01-04 03:05:24,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:24,145 INFO:     Epoch: 43
2023-01-04 03:05:25,738 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39819284280141193, 'Total loss': 0.39819284280141193} | train loss {'Reaction outcome loss': 0.2450004854939715, 'Total loss': 0.2450004854939715}
2023-01-04 03:05:25,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:25,738 INFO:     Epoch: 44
2023-01-04 03:05:27,329 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40232166945934295, 'Total loss': 0.40232166945934295} | train loss {'Reaction outcome loss': 0.24182129334522426, 'Total loss': 0.24182129334522426}
2023-01-04 03:05:27,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:27,329 INFO:     Epoch: 45
2023-01-04 03:05:28,917 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4048831949631373, 'Total loss': 0.4048831949631373} | train loss {'Reaction outcome loss': 0.24218179346708052, 'Total loss': 0.24218179346708052}
2023-01-04 03:05:28,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:28,917 INFO:     Epoch: 46
2023-01-04 03:05:30,516 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40988076527913414, 'Total loss': 0.40988076527913414} | train loss {'Reaction outcome loss': 0.24055153814001676, 'Total loss': 0.24055153814001676}
2023-01-04 03:05:30,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:30,516 INFO:     Epoch: 47
2023-01-04 03:05:32,127 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41639270484447477, 'Total loss': 0.41639270484447477} | train loss {'Reaction outcome loss': 0.2383540278558966, 'Total loss': 0.2383540278558966}
2023-01-04 03:05:32,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:32,128 INFO:     Epoch: 48
2023-01-04 03:05:33,730 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40390675365924833, 'Total loss': 0.40390675365924833} | train loss {'Reaction outcome loss': 0.2346602109852281, 'Total loss': 0.2346602109852281}
2023-01-04 03:05:33,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:33,730 INFO:     Epoch: 49
2023-01-04 03:05:35,303 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4201000849405924, 'Total loss': 0.4201000849405924} | train loss {'Reaction outcome loss': 0.2318571718260102, 'Total loss': 0.2318571718260102}
2023-01-04 03:05:35,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:35,304 INFO:     Epoch: 50
2023-01-04 03:05:36,872 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4186425526936849, 'Total loss': 0.4186425526936849} | train loss {'Reaction outcome loss': 0.2313876767935109, 'Total loss': 0.2313876767935109}
2023-01-04 03:05:36,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:36,872 INFO:     Epoch: 51
2023-01-04 03:05:38,468 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41292182008425393, 'Total loss': 0.41292182008425393} | train loss {'Reaction outcome loss': 0.23193935018685394, 'Total loss': 0.23193935018685394}
2023-01-04 03:05:38,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:38,468 INFO:     Epoch: 52
2023-01-04 03:05:40,054 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40119465986887615, 'Total loss': 0.40119465986887615} | train loss {'Reaction outcome loss': 0.22713267286546038, 'Total loss': 0.22713267286546038}
2023-01-04 03:05:40,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:40,055 INFO:     Epoch: 53
2023-01-04 03:05:41,642 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4448212097088496, 'Total loss': 0.4448212097088496} | train loss {'Reaction outcome loss': 0.2253715792113412, 'Total loss': 0.2253715792113412}
2023-01-04 03:05:41,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:41,642 INFO:     Epoch: 54
2023-01-04 03:05:43,207 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40265883406003317, 'Total loss': 0.40265883406003317} | train loss {'Reaction outcome loss': 0.22446217323333895, 'Total loss': 0.22446217323333895}
2023-01-04 03:05:43,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:43,207 INFO:     Epoch: 55
2023-01-04 03:05:44,793 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40052607680360475, 'Total loss': 0.40052607680360475} | train loss {'Reaction outcome loss': 0.2242430711885656, 'Total loss': 0.2242430711885656}
2023-01-04 03:05:44,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:44,794 INFO:     Epoch: 56
2023-01-04 03:05:46,363 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41983999411265055, 'Total loss': 0.41983999411265055} | train loss {'Reaction outcome loss': 0.2238410969883421, 'Total loss': 0.2238410969883421}
2023-01-04 03:05:46,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:46,364 INFO:     Epoch: 57
2023-01-04 03:05:47,970 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4368230750163396, 'Total loss': 0.4368230750163396} | train loss {'Reaction outcome loss': 0.22117294479895683, 'Total loss': 0.22117294479895683}
2023-01-04 03:05:47,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:47,971 INFO:     Epoch: 58
2023-01-04 03:05:49,574 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39467697168389954, 'Total loss': 0.39467697168389954} | train loss {'Reaction outcome loss': 0.2158607233070979, 'Total loss': 0.2158607233070979}
2023-01-04 03:05:49,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:49,574 INFO:     Epoch: 59
2023-01-04 03:05:51,182 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43194560905297597, 'Total loss': 0.43194560905297597} | train loss {'Reaction outcome loss': 0.21555782510579502, 'Total loss': 0.21555782510579502}
2023-01-04 03:05:51,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:51,182 INFO:     Epoch: 60
2023-01-04 03:05:52,763 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40862006445725757, 'Total loss': 0.40862006445725757} | train loss {'Reaction outcome loss': 0.21639722833124392, 'Total loss': 0.21639722833124392}
2023-01-04 03:05:52,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:52,764 INFO:     Epoch: 61
2023-01-04 03:05:54,376 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4060483937462171, 'Total loss': 0.4060483937462171} | train loss {'Reaction outcome loss': 0.21347379091664823, 'Total loss': 0.21347379091664823}
2023-01-04 03:05:54,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:54,377 INFO:     Epoch: 62
2023-01-04 03:05:55,937 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43150436083475746, 'Total loss': 0.43150436083475746} | train loss {'Reaction outcome loss': 0.21125989718648203, 'Total loss': 0.21125989718648203}
2023-01-04 03:05:55,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:55,937 INFO:     Epoch: 63
2023-01-04 03:05:57,545 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41687239209810895, 'Total loss': 0.41687239209810895} | train loss {'Reaction outcome loss': 0.21129325561116646, 'Total loss': 0.21129325561116646}
2023-01-04 03:05:57,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:57,545 INFO:     Epoch: 64
2023-01-04 03:05:59,147 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.397630633910497, 'Total loss': 0.397630633910497} | train loss {'Reaction outcome loss': 0.2104375825746216, 'Total loss': 0.2104375825746216}
2023-01-04 03:05:59,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:05:59,147 INFO:     Epoch: 65
2023-01-04 03:06:00,748 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4132257660230001, 'Total loss': 0.4132257660230001} | train loss {'Reaction outcome loss': 0.2087581467128148, 'Total loss': 0.2087581467128148}
2023-01-04 03:06:00,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:00,749 INFO:     Epoch: 66
2023-01-04 03:06:02,328 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41309844255447387, 'Total loss': 0.41309844255447387} | train loss {'Reaction outcome loss': 0.20812508571267563, 'Total loss': 0.20812508571267563}
2023-01-04 03:06:02,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:02,328 INFO:     Epoch: 67
2023-01-04 03:06:03,921 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44241018990675607, 'Total loss': 0.44241018990675607} | train loss {'Reaction outcome loss': 0.20684853688317495, 'Total loss': 0.20684853688317495}
2023-01-04 03:06:03,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:03,921 INFO:     Epoch: 68
2023-01-04 03:06:05,530 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4165458112955093, 'Total loss': 0.4165458112955093} | train loss {'Reaction outcome loss': 0.20300109083526327, 'Total loss': 0.20300109083526327}
2023-01-04 03:06:05,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:05,531 INFO:     Epoch: 69
2023-01-04 03:06:07,106 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40466040521860125, 'Total loss': 0.40466040521860125} | train loss {'Reaction outcome loss': 0.20592716176497894, 'Total loss': 0.20592716176497894}
2023-01-04 03:06:07,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:07,107 INFO:     Epoch: 70
2023-01-04 03:06:08,697 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43301162123680115, 'Total loss': 0.43301162123680115} | train loss {'Reaction outcome loss': 0.2006450816717026, 'Total loss': 0.2006450816717026}
2023-01-04 03:06:08,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:08,697 INFO:     Epoch: 71
2023-01-04 03:06:10,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4122943143049876, 'Total loss': 0.4122943143049876} | train loss {'Reaction outcome loss': 0.20154035943186413, 'Total loss': 0.20154035943186413}
2023-01-04 03:06:10,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:10,282 INFO:     Epoch: 72
2023-01-04 03:06:11,866 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43061683773994447, 'Total loss': 0.43061683773994447} | train loss {'Reaction outcome loss': 0.1993159727213809, 'Total loss': 0.1993159727213809}
2023-01-04 03:06:11,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:11,866 INFO:     Epoch: 73
2023-01-04 03:06:13,439 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42295087973276774, 'Total loss': 0.42295087973276774} | train loss {'Reaction outcome loss': 0.19775338575624637, 'Total loss': 0.19775338575624637}
2023-01-04 03:06:13,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:13,439 INFO:     Epoch: 74
2023-01-04 03:06:15,031 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42837350169817606, 'Total loss': 0.42837350169817606} | train loss {'Reaction outcome loss': 0.19784150423522848, 'Total loss': 0.19784150423522848}
2023-01-04 03:06:15,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:15,032 INFO:     Epoch: 75
2023-01-04 03:06:16,615 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.412321005264918, 'Total loss': 0.412321005264918} | train loss {'Reaction outcome loss': 0.19729568538031655, 'Total loss': 0.19729568538031655}
2023-01-04 03:06:16,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:16,615 INFO:     Epoch: 76
2023-01-04 03:06:18,197 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47380760808785755, 'Total loss': 0.47380760808785755} | train loss {'Reaction outcome loss': 0.1945322615903442, 'Total loss': 0.1945322615903442}
2023-01-04 03:06:18,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:18,198 INFO:     Epoch: 77
2023-01-04 03:06:19,762 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4407923231522242, 'Total loss': 0.4407923231522242} | train loss {'Reaction outcome loss': 0.19289530359589271, 'Total loss': 0.19289530359589271}
2023-01-04 03:06:19,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:19,762 INFO:     Epoch: 78
2023-01-04 03:06:21,371 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4354158411423365, 'Total loss': 0.4354158411423365} | train loss {'Reaction outcome loss': 0.19339575630741834, 'Total loss': 0.19339575630741834}
2023-01-04 03:06:21,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:21,371 INFO:     Epoch: 79
2023-01-04 03:06:22,935 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43221255838871003, 'Total loss': 0.43221255838871003} | train loss {'Reaction outcome loss': 0.19440425553080373, 'Total loss': 0.19440425553080373}
2023-01-04 03:06:22,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:22,935 INFO:     Epoch: 80
2023-01-04 03:06:24,516 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4317200337847074, 'Total loss': 0.4317200337847074} | train loss {'Reaction outcome loss': 0.1942367789056832, 'Total loss': 0.1942367789056832}
2023-01-04 03:06:24,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:24,517 INFO:     Epoch: 81
2023-01-04 03:06:26,124 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4340275456508001, 'Total loss': 0.4340275456508001} | train loss {'Reaction outcome loss': 0.19171954517381906, 'Total loss': 0.19171954517381906}
2023-01-04 03:06:26,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:26,124 INFO:     Epoch: 82
2023-01-04 03:06:27,738 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45921052793661754, 'Total loss': 0.45921052793661754} | train loss {'Reaction outcome loss': 0.19117913732345956, 'Total loss': 0.19117913732345956}
2023-01-04 03:06:27,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:27,738 INFO:     Epoch: 83
2023-01-04 03:06:29,334 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44944075296322505, 'Total loss': 0.44944075296322505} | train loss {'Reaction outcome loss': 0.18950906459133338, 'Total loss': 0.18950906459133338}
2023-01-04 03:06:29,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:29,334 INFO:     Epoch: 84
2023-01-04 03:06:30,922 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4270456622044245, 'Total loss': 0.4270456622044245} | train loss {'Reaction outcome loss': 0.18704212791401975, 'Total loss': 0.18704212791401975}
2023-01-04 03:06:30,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:30,922 INFO:     Epoch: 85
2023-01-04 03:06:32,529 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43545131584008534, 'Total loss': 0.43545131584008534} | train loss {'Reaction outcome loss': 0.18831895619467662, 'Total loss': 0.18831895619467662}
2023-01-04 03:06:32,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:32,529 INFO:     Epoch: 86
2023-01-04 03:06:34,137 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4286467562119166, 'Total loss': 0.4286467562119166} | train loss {'Reaction outcome loss': 0.18410991656043343, 'Total loss': 0.18410991656043343}
2023-01-04 03:06:34,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:34,138 INFO:     Epoch: 87
2023-01-04 03:06:35,746 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.460362978776296, 'Total loss': 0.460362978776296} | train loss {'Reaction outcome loss': 0.18317670704810507, 'Total loss': 0.18317670704810507}
2023-01-04 03:06:35,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:35,746 INFO:     Epoch: 88
2023-01-04 03:06:37,341 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4385573585828145, 'Total loss': 0.4385573585828145} | train loss {'Reaction outcome loss': 0.18614857427667092, 'Total loss': 0.18614857427667092}
2023-01-04 03:06:37,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:37,342 INFO:     Epoch: 89
2023-01-04 03:06:38,936 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42831345498561857, 'Total loss': 0.42831345498561857} | train loss {'Reaction outcome loss': 0.18204949525640393, 'Total loss': 0.18204949525640393}
2023-01-04 03:06:38,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:38,936 INFO:     Epoch: 90
2023-01-04 03:06:40,514 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4420920024315516, 'Total loss': 0.4420920024315516} | train loss {'Reaction outcome loss': 0.18316761153430616, 'Total loss': 0.18316761153430616}
2023-01-04 03:06:40,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:40,514 INFO:     Epoch: 91
2023-01-04 03:06:42,103 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4544815316796303, 'Total loss': 0.4544815316796303} | train loss {'Reaction outcome loss': 0.18321693144793058, 'Total loss': 0.18321693144793058}
2023-01-04 03:06:42,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:42,103 INFO:     Epoch: 92
2023-01-04 03:06:43,692 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44368085463841755, 'Total loss': 0.44368085463841755} | train loss {'Reaction outcome loss': 0.18208402786811773, 'Total loss': 0.18208402786811773}
2023-01-04 03:06:43,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:43,692 INFO:     Epoch: 93
2023-01-04 03:06:45,283 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4475754757722219, 'Total loss': 0.4475754757722219} | train loss {'Reaction outcome loss': 0.18140397703506217, 'Total loss': 0.18140397703506217}
2023-01-04 03:06:45,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:45,283 INFO:     Epoch: 94
2023-01-04 03:06:46,866 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4550587058067322, 'Total loss': 0.4550587058067322} | train loss {'Reaction outcome loss': 0.1792945785543127, 'Total loss': 0.1792945785543127}
2023-01-04 03:06:46,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:46,866 INFO:     Epoch: 95
2023-01-04 03:06:48,479 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44184263547261554, 'Total loss': 0.44184263547261554} | train loss {'Reaction outcome loss': 0.18114297283663802, 'Total loss': 0.18114297283663802}
2023-01-04 03:06:48,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:48,479 INFO:     Epoch: 96
2023-01-04 03:06:50,045 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4431581377983093, 'Total loss': 0.4431581377983093} | train loss {'Reaction outcome loss': 0.1776233346330641, 'Total loss': 0.1776233346330641}
2023-01-04 03:06:50,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:50,047 INFO:     Epoch: 97
2023-01-04 03:06:51,618 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4564558188120524, 'Total loss': 0.4564558188120524} | train loss {'Reaction outcome loss': 0.1788027246285529, 'Total loss': 0.1788027246285529}
2023-01-04 03:06:51,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:51,618 INFO:     Epoch: 98
2023-01-04 03:06:53,227 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45157241026560463, 'Total loss': 0.45157241026560463} | train loss {'Reaction outcome loss': 0.17774152700673707, 'Total loss': 0.17774152700673707}
2023-01-04 03:06:53,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:53,227 INFO:     Epoch: 99
2023-01-04 03:06:54,803 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46123024622599285, 'Total loss': 0.46123024622599285} | train loss {'Reaction outcome loss': 0.17734161559084471, 'Total loss': 0.17734161559084471}
2023-01-04 03:06:54,803 INFO:     Best model found after epoch 33 of 100.
2023-01-04 03:06:54,803 INFO:   Done with stage: TRAINING
2023-01-04 03:06:54,803 INFO:   Starting stage: EVALUATION
2023-01-04 03:06:54,942 INFO:   Done with stage: EVALUATION
2023-01-04 03:06:54,942 INFO:   Leaving out SEQ value Fold_4
2023-01-04 03:06:54,962 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:06:54,962 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:06:55,620 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:06:55,620 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:06:55,689 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:06:55,689 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:06:55,689 INFO:     No hyperparam tuning for this model
2023-01-04 03:06:55,689 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:06:55,689 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:06:55,690 INFO:     None feature selector for col prot
2023-01-04 03:06:55,690 INFO:     None feature selector for col prot
2023-01-04 03:06:55,690 INFO:     None feature selector for col prot
2023-01-04 03:06:55,691 INFO:     None feature selector for col chem
2023-01-04 03:06:55,691 INFO:     None feature selector for col chem
2023-01-04 03:06:55,691 INFO:     None feature selector for col chem
2023-01-04 03:06:55,691 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:06:55,691 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:06:55,692 INFO:     Number of params in model 70141
2023-01-04 03:06:55,695 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:06:55,695 INFO:   Starting stage: TRAINING
2023-01-04 03:06:55,740 INFO:     Val loss before train {'Reaction outcome loss': 0.9374310851097107, 'Total loss': 0.9374310851097107}
2023-01-04 03:06:55,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:55,741 INFO:     Epoch: 0
2023-01-04 03:06:57,329 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6384959876537323, 'Total loss': 0.6384959876537323} | train loss {'Reaction outcome loss': 0.8380705437528483, 'Total loss': 0.8380705437528483}
2023-01-04 03:06:57,330 INFO:     Found new best model at epoch 0
2023-01-04 03:06:57,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:57,331 INFO:     Epoch: 1
2023-01-04 03:06:58,933 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5324453393618266, 'Total loss': 0.5324453393618266} | train loss {'Reaction outcome loss': 0.5961839616622614, 'Total loss': 0.5961839616622614}
2023-01-04 03:06:58,933 INFO:     Found new best model at epoch 1
2023-01-04 03:06:58,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:06:58,934 INFO:     Epoch: 2
2023-01-04 03:07:00,546 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5055972536404928, 'Total loss': 0.5055972536404928} | train loss {'Reaction outcome loss': 0.5129223149581947, 'Total loss': 0.5129223149581947}
2023-01-04 03:07:00,546 INFO:     Found new best model at epoch 2
2023-01-04 03:07:00,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:00,547 INFO:     Epoch: 3
2023-01-04 03:07:02,158 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47235350211461385, 'Total loss': 0.47235350211461385} | train loss {'Reaction outcome loss': 0.4771267088379819, 'Total loss': 0.4771267088379819}
2023-01-04 03:07:02,158 INFO:     Found new best model at epoch 3
2023-01-04 03:07:02,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:02,159 INFO:     Epoch: 4
2023-01-04 03:07:03,750 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47033315896987915, 'Total loss': 0.47033315896987915} | train loss {'Reaction outcome loss': 0.454919733201572, 'Total loss': 0.454919733201572}
2023-01-04 03:07:03,750 INFO:     Found new best model at epoch 4
2023-01-04 03:07:03,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:03,751 INFO:     Epoch: 5
2023-01-04 03:07:05,365 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44778168499469756, 'Total loss': 0.44778168499469756} | train loss {'Reaction outcome loss': 0.434532646710674, 'Total loss': 0.434532646710674}
2023-01-04 03:07:05,365 INFO:     Found new best model at epoch 5
2023-01-04 03:07:05,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:05,366 INFO:     Epoch: 6
2023-01-04 03:07:06,948 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43572053710619607, 'Total loss': 0.43572053710619607} | train loss {'Reaction outcome loss': 0.43085394861797494, 'Total loss': 0.43085394861797494}
2023-01-04 03:07:06,948 INFO:     Found new best model at epoch 6
2023-01-04 03:07:06,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:06,949 INFO:     Epoch: 7
2023-01-04 03:07:08,567 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41358328262964883, 'Total loss': 0.41358328262964883} | train loss {'Reaction outcome loss': 0.41812389835283376, 'Total loss': 0.41812389835283376}
2023-01-04 03:07:08,567 INFO:     Found new best model at epoch 7
2023-01-04 03:07:08,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:08,568 INFO:     Epoch: 8
2023-01-04 03:07:10,186 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42182612319787344, 'Total loss': 0.42182612319787344} | train loss {'Reaction outcome loss': 0.3975301018858706, 'Total loss': 0.3975301018858706}
2023-01-04 03:07:10,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:10,187 INFO:     Epoch: 9
2023-01-04 03:07:11,807 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4054976344108582, 'Total loss': 0.4054976344108582} | train loss {'Reaction outcome loss': 0.38844647834578255, 'Total loss': 0.38844647834578255}
2023-01-04 03:07:11,808 INFO:     Found new best model at epoch 9
2023-01-04 03:07:11,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:11,808 INFO:     Epoch: 10
2023-01-04 03:07:13,405 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4178742339213689, 'Total loss': 0.4178742339213689} | train loss {'Reaction outcome loss': 0.38027568706783693, 'Total loss': 0.38027568706783693}
2023-01-04 03:07:13,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:13,406 INFO:     Epoch: 11
2023-01-04 03:07:15,014 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40613197684288027, 'Total loss': 0.40613197684288027} | train loss {'Reaction outcome loss': 0.37456353041562723, 'Total loss': 0.37456353041562723}
2023-01-04 03:07:15,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:15,014 INFO:     Epoch: 12
2023-01-04 03:07:16,617 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4028499354918798, 'Total loss': 0.4028499354918798} | train loss {'Reaction outcome loss': 0.36478612698830554, 'Total loss': 0.36478612698830554}
2023-01-04 03:07:16,618 INFO:     Found new best model at epoch 12
2023-01-04 03:07:16,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:16,618 INFO:     Epoch: 13
2023-01-04 03:07:18,231 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38907671769460045, 'Total loss': 0.38907671769460045} | train loss {'Reaction outcome loss': 0.35707738335148187, 'Total loss': 0.35707738335148187}
2023-01-04 03:07:18,231 INFO:     Found new best model at epoch 13
2023-01-04 03:07:18,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:18,232 INFO:     Epoch: 14
2023-01-04 03:07:19,854 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39875022172927854, 'Total loss': 0.39875022172927854} | train loss {'Reaction outcome loss': 0.34782286694330716, 'Total loss': 0.34782286694330716}
2023-01-04 03:07:19,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:19,855 INFO:     Epoch: 15
2023-01-04 03:07:21,474 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38722431659698486, 'Total loss': 0.38722431659698486} | train loss {'Reaction outcome loss': 0.3423987487254582, 'Total loss': 0.3423987487254582}
2023-01-04 03:07:21,474 INFO:     Found new best model at epoch 15
2023-01-04 03:07:21,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:21,475 INFO:     Epoch: 16
2023-01-04 03:07:23,064 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3918383866548538, 'Total loss': 0.3918383866548538} | train loss {'Reaction outcome loss': 0.3383203283816144, 'Total loss': 0.3383203283816144}
2023-01-04 03:07:23,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:23,065 INFO:     Epoch: 17
2023-01-04 03:07:24,673 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3846993009249369, 'Total loss': 0.3846993009249369} | train loss {'Reaction outcome loss': 0.3318434505735227, 'Total loss': 0.3318434505735227}
2023-01-04 03:07:24,674 INFO:     Found new best model at epoch 17
2023-01-04 03:07:24,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:24,675 INFO:     Epoch: 18
2023-01-04 03:07:26,271 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3866351912419001, 'Total loss': 0.3866351912419001} | train loss {'Reaction outcome loss': 0.3243732719034281, 'Total loss': 0.3243732719034281}
2023-01-04 03:07:26,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:26,271 INFO:     Epoch: 19
2023-01-04 03:07:27,868 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38839765389760333, 'Total loss': 0.38839765389760333} | train loss {'Reaction outcome loss': 0.31960485285220575, 'Total loss': 0.31960485285220575}
2023-01-04 03:07:27,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:27,868 INFO:     Epoch: 20
2023-01-04 03:07:29,464 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39291511476039886, 'Total loss': 0.39291511476039886} | train loss {'Reaction outcome loss': 0.31322009708948323, 'Total loss': 0.31322009708948323}
2023-01-04 03:07:29,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:29,464 INFO:     Epoch: 21
2023-01-04 03:07:31,044 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38933929403622947, 'Total loss': 0.38933929403622947} | train loss {'Reaction outcome loss': 0.329499545034723, 'Total loss': 0.329499545034723}
2023-01-04 03:07:31,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:31,045 INFO:     Epoch: 22
2023-01-04 03:07:32,662 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38267274300257365, 'Total loss': 0.38267274300257365} | train loss {'Reaction outcome loss': 0.3091863899734681, 'Total loss': 0.3091863899734681}
2023-01-04 03:07:32,662 INFO:     Found new best model at epoch 22
2023-01-04 03:07:32,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:32,663 INFO:     Epoch: 23
2023-01-04 03:07:34,243 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4028009663025538, 'Total loss': 0.4028009663025538} | train loss {'Reaction outcome loss': 0.2991165160336464, 'Total loss': 0.2991165160336464}
2023-01-04 03:07:34,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:34,243 INFO:     Epoch: 24
2023-01-04 03:07:35,852 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3751722236474355, 'Total loss': 0.3751722236474355} | train loss {'Reaction outcome loss': 0.2946894523313107, 'Total loss': 0.2946894523313107}
2023-01-04 03:07:35,852 INFO:     Found new best model at epoch 24
2023-01-04 03:07:35,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:35,853 INFO:     Epoch: 25
2023-01-04 03:07:37,456 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3711153566837311, 'Total loss': 0.3711153566837311} | train loss {'Reaction outcome loss': 0.28819010458950733, 'Total loss': 0.28819010458950733}
2023-01-04 03:07:37,456 INFO:     Found new best model at epoch 25
2023-01-04 03:07:37,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:37,457 INFO:     Epoch: 26
2023-01-04 03:07:39,046 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3840484102567037, 'Total loss': 0.3840484102567037} | train loss {'Reaction outcome loss': 0.2859874923863875, 'Total loss': 0.2859874923863875}
2023-01-04 03:07:39,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:39,046 INFO:     Epoch: 27
2023-01-04 03:07:40,627 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3811473806699117, 'Total loss': 0.3811473806699117} | train loss {'Reaction outcome loss': 0.281761729279938, 'Total loss': 0.281761729279938}
2023-01-04 03:07:40,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:40,627 INFO:     Epoch: 28
2023-01-04 03:07:42,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37068898379802706, 'Total loss': 0.37068898379802706} | train loss {'Reaction outcome loss': 0.27537598096988286, 'Total loss': 0.27537598096988286}
2023-01-04 03:07:42,255 INFO:     Found new best model at epoch 28
2023-01-04 03:07:42,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:42,256 INFO:     Epoch: 29
2023-01-04 03:07:43,833 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3826665759086609, 'Total loss': 0.3826665759086609} | train loss {'Reaction outcome loss': 0.275907798299053, 'Total loss': 0.275907798299053}
2023-01-04 03:07:43,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:43,834 INFO:     Epoch: 30
2023-01-04 03:07:45,444 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3697341561317444, 'Total loss': 0.3697341561317444} | train loss {'Reaction outcome loss': 0.27085880739310675, 'Total loss': 0.27085880739310675}
2023-01-04 03:07:45,444 INFO:     Found new best model at epoch 30
2023-01-04 03:07:45,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:45,445 INFO:     Epoch: 31
2023-01-04 03:07:47,065 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3643822471300761, 'Total loss': 0.3643822471300761} | train loss {'Reaction outcome loss': 0.2695667157894459, 'Total loss': 0.2695667157894459}
2023-01-04 03:07:47,065 INFO:     Found new best model at epoch 31
2023-01-04 03:07:47,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:47,066 INFO:     Epoch: 32
2023-01-04 03:07:48,678 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37207494576772054, 'Total loss': 0.37207494576772054} | train loss {'Reaction outcome loss': 0.27049214969493746, 'Total loss': 0.27049214969493746}
2023-01-04 03:07:48,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:48,678 INFO:     Epoch: 33
2023-01-04 03:07:50,258 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3935486902793249, 'Total loss': 0.3935486902793249} | train loss {'Reaction outcome loss': 0.2593643831197118, 'Total loss': 0.2593643831197118}
2023-01-04 03:07:50,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:50,258 INFO:     Epoch: 34
2023-01-04 03:07:51,836 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3612041066090266, 'Total loss': 0.3612041066090266} | train loss {'Reaction outcome loss': 0.27211807454949705, 'Total loss': 0.27211807454949705}
2023-01-04 03:07:51,836 INFO:     Found new best model at epoch 34
2023-01-04 03:07:51,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:51,837 INFO:     Epoch: 35
2023-01-04 03:07:53,424 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35889456073443093, 'Total loss': 0.35889456073443093} | train loss {'Reaction outcome loss': 0.26697325522916904, 'Total loss': 0.26697325522916904}
2023-01-04 03:07:53,424 INFO:     Found new best model at epoch 35
2023-01-04 03:07:53,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:53,425 INFO:     Epoch: 36
2023-01-04 03:07:55,047 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3696095148722331, 'Total loss': 0.3696095148722331} | train loss {'Reaction outcome loss': 0.25181459157181013, 'Total loss': 0.25181459157181013}
2023-01-04 03:07:55,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:55,047 INFO:     Epoch: 37
2023-01-04 03:07:56,651 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36497920751571655, 'Total loss': 0.36497920751571655} | train loss {'Reaction outcome loss': 0.24888425793809196, 'Total loss': 0.24888425793809196}
2023-01-04 03:07:56,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:56,651 INFO:     Epoch: 38
2023-01-04 03:07:58,231 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3471723169088364, 'Total loss': 0.3471723169088364} | train loss {'Reaction outcome loss': 0.2452726005576551, 'Total loss': 0.2452726005576551}
2023-01-04 03:07:58,231 INFO:     Found new best model at epoch 38
2023-01-04 03:07:58,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:58,232 INFO:     Epoch: 39
2023-01-04 03:07:59,815 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36535323957602184, 'Total loss': 0.36535323957602184} | train loss {'Reaction outcome loss': 0.24276067306213983, 'Total loss': 0.24276067306213983}
2023-01-04 03:07:59,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:07:59,815 INFO:     Epoch: 40
2023-01-04 03:08:01,389 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3520092407862345, 'Total loss': 0.3520092407862345} | train loss {'Reaction outcome loss': 0.23920975742858255, 'Total loss': 0.23920975742858255}
2023-01-04 03:08:01,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:01,391 INFO:     Epoch: 41
2023-01-04 03:08:02,970 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36831390857696533, 'Total loss': 0.36831390857696533} | train loss {'Reaction outcome loss': 0.23921536674446833, 'Total loss': 0.23921536674446833}
2023-01-04 03:08:02,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:02,970 INFO:     Epoch: 42
2023-01-04 03:08:04,588 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35723065833250683, 'Total loss': 0.35723065833250683} | train loss {'Reaction outcome loss': 0.2371281679243902, 'Total loss': 0.2371281679243902}
2023-01-04 03:08:04,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:04,589 INFO:     Epoch: 43
2023-01-04 03:08:06,206 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3809068252642949, 'Total loss': 0.3809068252642949} | train loss {'Reaction outcome loss': 0.23366352365827997, 'Total loss': 0.23366352365827997}
2023-01-04 03:08:06,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:06,206 INFO:     Epoch: 44
2023-01-04 03:08:07,776 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3814636796712875, 'Total loss': 0.3814636796712875} | train loss {'Reaction outcome loss': 0.23364288131773903, 'Total loss': 0.23364288131773903}
2023-01-04 03:08:07,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:07,777 INFO:     Epoch: 45
2023-01-04 03:08:09,360 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3862580349047979, 'Total loss': 0.3862580349047979} | train loss {'Reaction outcome loss': 0.23236825963755584, 'Total loss': 0.23236825963755584}
2023-01-04 03:08:09,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:09,360 INFO:     Epoch: 46
2023-01-04 03:08:10,968 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38091655671596525, 'Total loss': 0.38091655671596525} | train loss {'Reaction outcome loss': 0.23340641595153272, 'Total loss': 0.23340641595153272}
2023-01-04 03:08:10,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:10,968 INFO:     Epoch: 47
2023-01-04 03:08:12,545 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3568685233592987, 'Total loss': 0.3568685233592987} | train loss {'Reaction outcome loss': 0.23532162784207342, 'Total loss': 0.23532162784207342}
2023-01-04 03:08:12,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:12,545 INFO:     Epoch: 48
2023-01-04 03:08:14,168 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3836466004451116, 'Total loss': 0.3836466004451116} | train loss {'Reaction outcome loss': 0.22721654453409323, 'Total loss': 0.22721654453409323}
2023-01-04 03:08:14,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:14,168 INFO:     Epoch: 49
2023-01-04 03:08:15,761 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35584356635808945, 'Total loss': 0.35584356635808945} | train loss {'Reaction outcome loss': 0.22324479406402595, 'Total loss': 0.22324479406402595}
2023-01-04 03:08:15,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:15,761 INFO:     Epoch: 50
2023-01-04 03:08:17,391 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36296924750010173, 'Total loss': 0.36296924750010173} | train loss {'Reaction outcome loss': 0.22057345210856327, 'Total loss': 0.22057345210856327}
2023-01-04 03:08:17,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:17,391 INFO:     Epoch: 51
2023-01-04 03:08:18,973 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3493296871582667, 'Total loss': 0.3493296871582667} | train loss {'Reaction outcome loss': 0.22036964430109315, 'Total loss': 0.22036964430109315}
2023-01-04 03:08:18,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:18,973 INFO:     Epoch: 52
2023-01-04 03:08:20,564 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3713330248991648, 'Total loss': 0.3713330248991648} | train loss {'Reaction outcome loss': 0.219642103622681, 'Total loss': 0.219642103622681}
2023-01-04 03:08:20,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:20,565 INFO:     Epoch: 53
2023-01-04 03:08:22,155 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3573091914256414, 'Total loss': 0.3573091914256414} | train loss {'Reaction outcome loss': 0.21920654202551595, 'Total loss': 0.21920654202551595}
2023-01-04 03:08:22,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:22,155 INFO:     Epoch: 54
2023-01-04 03:08:23,744 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.351728817820549, 'Total loss': 0.351728817820549} | train loss {'Reaction outcome loss': 0.2129875202637935, 'Total loss': 0.2129875202637935}
2023-01-04 03:08:23,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:23,744 INFO:     Epoch: 55
2023-01-04 03:08:25,338 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35175699094931284, 'Total loss': 0.35175699094931284} | train loss {'Reaction outcome loss': 0.21385195351024816, 'Total loss': 0.21385195351024816}
2023-01-04 03:08:25,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:25,338 INFO:     Epoch: 56
2023-01-04 03:08:26,927 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3508246844013532, 'Total loss': 0.3508246844013532} | train loss {'Reaction outcome loss': 0.21296403739277436, 'Total loss': 0.21296403739277436}
2023-01-04 03:08:26,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:26,927 INFO:     Epoch: 57
2023-01-04 03:08:28,503 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35602696339289347, 'Total loss': 0.35602696339289347} | train loss {'Reaction outcome loss': 0.20963152967169005, 'Total loss': 0.20963152967169005}
2023-01-04 03:08:28,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:28,503 INFO:     Epoch: 58
2023-01-04 03:08:30,095 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35827009081840516, 'Total loss': 0.35827009081840516} | train loss {'Reaction outcome loss': 0.20994176947789273, 'Total loss': 0.20994176947789273}
2023-01-04 03:08:30,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:30,096 INFO:     Epoch: 59
2023-01-04 03:08:31,687 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3460994452238083, 'Total loss': 0.3460994452238083} | train loss {'Reaction outcome loss': 0.20818930028843274, 'Total loss': 0.20818930028843274}
2023-01-04 03:08:31,687 INFO:     Found new best model at epoch 59
2023-01-04 03:08:31,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:31,688 INFO:     Epoch: 60
2023-01-04 03:08:33,279 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37510883013407387, 'Total loss': 0.37510883013407387} | train loss {'Reaction outcome loss': 0.21371662821890652, 'Total loss': 0.21371662821890652}
2023-01-04 03:08:33,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:33,279 INFO:     Epoch: 61
2023-01-04 03:08:34,856 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37972778975963595, 'Total loss': 0.37972778975963595} | train loss {'Reaction outcome loss': 0.21316235017561205, 'Total loss': 0.21316235017561205}
2023-01-04 03:08:34,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:34,856 INFO:     Epoch: 62
2023-01-04 03:08:36,432 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37479402984802923, 'Total loss': 0.37479402984802923} | train loss {'Reaction outcome loss': 0.2073225941562998, 'Total loss': 0.2073225941562998}
2023-01-04 03:08:36,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:36,433 INFO:     Epoch: 63
2023-01-04 03:08:38,049 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3522128666440646, 'Total loss': 0.3522128666440646} | train loss {'Reaction outcome loss': 0.20658702381057292, 'Total loss': 0.20658702381057292}
2023-01-04 03:08:38,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:38,049 INFO:     Epoch: 64
2023-01-04 03:08:39,664 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3641979813575745, 'Total loss': 0.3641979813575745} | train loss {'Reaction outcome loss': 0.2011749824142907, 'Total loss': 0.2011749824142907}
2023-01-04 03:08:39,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:39,664 INFO:     Epoch: 65
2023-01-04 03:08:41,282 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37701676934957506, 'Total loss': 0.37701676934957506} | train loss {'Reaction outcome loss': 0.19980725297785323, 'Total loss': 0.19980725297785323}
2023-01-04 03:08:41,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:41,283 INFO:     Epoch: 66
2023-01-04 03:08:42,876 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37181613345940906, 'Total loss': 0.37181613345940906} | train loss {'Reaction outcome loss': 0.1961453097494508, 'Total loss': 0.1961453097494508}
2023-01-04 03:08:42,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:42,877 INFO:     Epoch: 67
2023-01-04 03:08:44,493 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3715278481443723, 'Total loss': 0.3715278481443723} | train loss {'Reaction outcome loss': 0.19684269455846978, 'Total loss': 0.19684269455846978}
2023-01-04 03:08:44,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:44,493 INFO:     Epoch: 68
2023-01-04 03:08:46,071 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35324623187383014, 'Total loss': 0.35324623187383014} | train loss {'Reaction outcome loss': 0.19501545347705268, 'Total loss': 0.19501545347705268}
2023-01-04 03:08:46,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:46,072 INFO:     Epoch: 69
2023-01-04 03:08:47,688 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3731580207745234, 'Total loss': 0.3731580207745234} | train loss {'Reaction outcome loss': 0.19407947322579802, 'Total loss': 0.19407947322579802}
2023-01-04 03:08:47,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:47,688 INFO:     Epoch: 70
2023-01-04 03:08:49,302 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35947381059328715, 'Total loss': 0.35947381059328715} | train loss {'Reaction outcome loss': 0.19289822303403195, 'Total loss': 0.19289822303403195}
2023-01-04 03:08:49,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:49,302 INFO:     Epoch: 71
2023-01-04 03:08:50,919 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3872918466726939, 'Total loss': 0.3872918466726939} | train loss {'Reaction outcome loss': 0.1910977876758662, 'Total loss': 0.1910977876758662}
2023-01-04 03:08:50,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:50,919 INFO:     Epoch: 72
2023-01-04 03:08:52,498 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37569774985313414, 'Total loss': 0.37569774985313414} | train loss {'Reaction outcome loss': 0.19577490142209159, 'Total loss': 0.19577490142209159}
2023-01-04 03:08:52,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:52,498 INFO:     Epoch: 73
2023-01-04 03:08:54,081 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38487077752749127, 'Total loss': 0.38487077752749127} | train loss {'Reaction outcome loss': 0.1900272126549153, 'Total loss': 0.1900272126549153}
2023-01-04 03:08:54,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:54,081 INFO:     Epoch: 74
2023-01-04 03:08:55,683 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3683540791273117, 'Total loss': 0.3683540791273117} | train loss {'Reaction outcome loss': 0.19011586967574828, 'Total loss': 0.19011586967574828}
2023-01-04 03:08:55,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:55,684 INFO:     Epoch: 75
2023-01-04 03:08:57,299 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40492055465777715, 'Total loss': 0.40492055465777715} | train loss {'Reaction outcome loss': 0.18853477123757725, 'Total loss': 0.18853477123757725}
2023-01-04 03:08:57,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:57,299 INFO:     Epoch: 76
2023-01-04 03:08:58,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3826580305894216, 'Total loss': 0.3826580305894216} | train loss {'Reaction outcome loss': 0.18611385063933625, 'Total loss': 0.18611385063933625}
2023-01-04 03:08:58,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:08:58,899 INFO:     Epoch: 77
2023-01-04 03:09:00,477 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3852502981821696, 'Total loss': 0.3852502981821696} | train loss {'Reaction outcome loss': 0.18579820937884506, 'Total loss': 0.18579820937884506}
2023-01-04 03:09:00,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:00,477 INFO:     Epoch: 78
2023-01-04 03:09:02,098 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36916286846001944, 'Total loss': 0.36916286846001944} | train loss {'Reaction outcome loss': 0.18704738035170443, 'Total loss': 0.18704738035170443}
2023-01-04 03:09:02,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:02,098 INFO:     Epoch: 79
2023-01-04 03:09:03,690 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40659330785274506, 'Total loss': 0.40659330785274506} | train loss {'Reaction outcome loss': 0.18292123927107162, 'Total loss': 0.18292123927107162}
2023-01-04 03:09:03,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:03,690 INFO:     Epoch: 80
2023-01-04 03:09:05,288 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3816256523132324, 'Total loss': 0.3816256523132324} | train loss {'Reaction outcome loss': 0.18334230803850296, 'Total loss': 0.18334230803850296}
2023-01-04 03:09:05,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:05,288 INFO:     Epoch: 81
2023-01-04 03:09:06,884 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39618616700172427, 'Total loss': 0.39618616700172427} | train loss {'Reaction outcome loss': 0.18168081422594287, 'Total loss': 0.18168081422594287}
2023-01-04 03:09:06,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:06,884 INFO:     Epoch: 82
2023-01-04 03:09:08,488 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3853316883246104, 'Total loss': 0.3853316883246104} | train loss {'Reaction outcome loss': 0.1871789053261307, 'Total loss': 0.1871789053261307}
2023-01-04 03:09:08,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:08,489 INFO:     Epoch: 83
2023-01-04 03:09:10,076 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3788957814375559, 'Total loss': 0.3788957814375559} | train loss {'Reaction outcome loss': 0.18042341832483214, 'Total loss': 0.18042341832483214}
2023-01-04 03:09:10,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:10,076 INFO:     Epoch: 84
2023-01-04 03:09:11,694 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36781042416890464, 'Total loss': 0.36781042416890464} | train loss {'Reaction outcome loss': 0.17968169576488435, 'Total loss': 0.17968169576488435}
2023-01-04 03:09:11,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:11,694 INFO:     Epoch: 85
2023-01-04 03:09:13,281 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.385360032816728, 'Total loss': 0.385360032816728} | train loss {'Reaction outcome loss': 0.17885799165410193, 'Total loss': 0.17885799165410193}
2023-01-04 03:09:13,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:13,282 INFO:     Epoch: 86
2023-01-04 03:09:14,897 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3803039791683356, 'Total loss': 0.3803039791683356} | train loss {'Reaction outcome loss': 0.18625691463998723, 'Total loss': 0.18625691463998723}
2023-01-04 03:09:14,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:14,898 INFO:     Epoch: 87
2023-01-04 03:09:16,500 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35362263321876525, 'Total loss': 0.35362263321876525} | train loss {'Reaction outcome loss': 0.17730403499746794, 'Total loss': 0.17730403499746794}
2023-01-04 03:09:16,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:16,500 INFO:     Epoch: 88
2023-01-04 03:09:18,095 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38695829808712007, 'Total loss': 0.38695829808712007} | train loss {'Reaction outcome loss': 0.17814802268580737, 'Total loss': 0.17814802268580737}
2023-01-04 03:09:18,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:18,095 INFO:     Epoch: 89
2023-01-04 03:09:19,673 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4023043115933736, 'Total loss': 0.4023043115933736} | train loss {'Reaction outcome loss': 0.17650265945796517, 'Total loss': 0.17650265945796517}
2023-01-04 03:09:19,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:19,673 INFO:     Epoch: 90
2023-01-04 03:09:21,249 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3741327861944834, 'Total loss': 0.3741327861944834} | train loss {'Reaction outcome loss': 0.17447502235131343, 'Total loss': 0.17447502235131343}
2023-01-04 03:09:21,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:21,250 INFO:     Epoch: 91
2023-01-04 03:09:22,843 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3704542229572932, 'Total loss': 0.3704542229572932} | train loss {'Reaction outcome loss': 0.1735216180266276, 'Total loss': 0.1735216180266276}
2023-01-04 03:09:22,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:22,843 INFO:     Epoch: 92
2023-01-04 03:09:24,439 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3630676940083504, 'Total loss': 0.3630676940083504} | train loss {'Reaction outcome loss': 0.1731208036921537, 'Total loss': 0.1731208036921537}
2023-01-04 03:09:24,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:24,439 INFO:     Epoch: 93
2023-01-04 03:09:26,055 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36543517212073007, 'Total loss': 0.36543517212073007} | train loss {'Reaction outcome loss': 0.1728418961747725, 'Total loss': 0.1728418961747725}
2023-01-04 03:09:26,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:26,055 INFO:     Epoch: 94
2023-01-04 03:09:27,653 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36714523335297905, 'Total loss': 0.36714523335297905} | train loss {'Reaction outcome loss': 0.17084015497053717, 'Total loss': 0.17084015497053717}
2023-01-04 03:09:27,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:27,654 INFO:     Epoch: 95
2023-01-04 03:09:29,257 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3745117125411828, 'Total loss': 0.3745117125411828} | train loss {'Reaction outcome loss': 0.19571434643686467, 'Total loss': 0.19571434643686467}
2023-01-04 03:09:29,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:29,257 INFO:     Epoch: 96
2023-01-04 03:09:30,854 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.373294772207737, 'Total loss': 0.373294772207737} | train loss {'Reaction outcome loss': 0.1724753136193191, 'Total loss': 0.1724753136193191}
2023-01-04 03:09:30,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:30,854 INFO:     Epoch: 97
2023-01-04 03:09:32,472 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36592894941568377, 'Total loss': 0.36592894941568377} | train loss {'Reaction outcome loss': 0.16997458913786997, 'Total loss': 0.16997458913786997}
2023-01-04 03:09:32,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:32,472 INFO:     Epoch: 98
2023-01-04 03:09:34,092 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3793065716822942, 'Total loss': 0.3793065716822942} | train loss {'Reaction outcome loss': 0.16919358107143256, 'Total loss': 0.16919358107143256}
2023-01-04 03:09:34,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:34,093 INFO:     Epoch: 99
2023-01-04 03:09:35,691 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36094970554113387, 'Total loss': 0.36094970554113387} | train loss {'Reaction outcome loss': 0.16691748379726315, 'Total loss': 0.16691748379726315}
2023-01-04 03:09:35,691 INFO:     Best model found after epoch 60 of 100.
2023-01-04 03:09:35,691 INFO:   Done with stage: TRAINING
2023-01-04 03:09:35,691 INFO:   Starting stage: EVALUATION
2023-01-04 03:09:35,819 INFO:   Done with stage: EVALUATION
2023-01-04 03:09:35,820 INFO:   Leaving out SEQ value Fold_5
2023-01-04 03:09:35,832 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 03:09:35,832 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:09:36,482 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:09:36,482 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:09:36,551 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:09:36,551 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:09:36,551 INFO:     No hyperparam tuning for this model
2023-01-04 03:09:36,552 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:09:36,552 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:09:36,552 INFO:     None feature selector for col prot
2023-01-04 03:09:36,552 INFO:     None feature selector for col prot
2023-01-04 03:09:36,553 INFO:     None feature selector for col prot
2023-01-04 03:09:36,553 INFO:     None feature selector for col chem
2023-01-04 03:09:36,553 INFO:     None feature selector for col chem
2023-01-04 03:09:36,553 INFO:     None feature selector for col chem
2023-01-04 03:09:36,553 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:09:36,553 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:09:36,554 INFO:     Number of params in model 70141
2023-01-04 03:09:36,558 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:09:36,558 INFO:   Starting stage: TRAINING
2023-01-04 03:09:36,602 INFO:     Val loss before train {'Reaction outcome loss': 0.9539707223574321, 'Total loss': 0.9539707223574321}
2023-01-04 03:09:36,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:36,602 INFO:     Epoch: 0
2023-01-04 03:09:38,227 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6890971581141154, 'Total loss': 0.6890971581141154} | train loss {'Reaction outcome loss': 0.8418879612258195, 'Total loss': 0.8418879612258195}
2023-01-04 03:09:38,227 INFO:     Found new best model at epoch 0
2023-01-04 03:09:38,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:38,228 INFO:     Epoch: 1
2023-01-04 03:09:39,829 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5929951965808868, 'Total loss': 0.5929951965808868} | train loss {'Reaction outcome loss': 0.6140702242562918, 'Total loss': 0.6140702242562918}
2023-01-04 03:09:39,829 INFO:     Found new best model at epoch 1
2023-01-04 03:09:39,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:39,830 INFO:     Epoch: 2
2023-01-04 03:09:41,452 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5724416116873423, 'Total loss': 0.5724416116873423} | train loss {'Reaction outcome loss': 0.537420491180265, 'Total loss': 0.537420491180265}
2023-01-04 03:09:41,452 INFO:     Found new best model at epoch 2
2023-01-04 03:09:41,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:41,453 INFO:     Epoch: 3
2023-01-04 03:09:43,073 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5392453372478485, 'Total loss': 0.5392453372478485} | train loss {'Reaction outcome loss': 0.4956458954658319, 'Total loss': 0.4956458954658319}
2023-01-04 03:09:43,074 INFO:     Found new best model at epoch 3
2023-01-04 03:09:43,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:43,075 INFO:     Epoch: 4
2023-01-04 03:09:44,702 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5420191923777262, 'Total loss': 0.5420191923777262} | train loss {'Reaction outcome loss': 0.470406827136928, 'Total loss': 0.470406827136928}
2023-01-04 03:09:44,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:44,702 INFO:     Epoch: 5
2023-01-04 03:09:46,286 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5306178371111552, 'Total loss': 0.5306178371111552} | train loss {'Reaction outcome loss': 0.44707790716460466, 'Total loss': 0.44707790716460466}
2023-01-04 03:09:46,286 INFO:     Found new best model at epoch 5
2023-01-04 03:09:46,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:46,287 INFO:     Epoch: 6
2023-01-04 03:09:47,873 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5144596685965855, 'Total loss': 0.5144596685965855} | train loss {'Reaction outcome loss': 0.4300342413062223, 'Total loss': 0.4300342413062223}
2023-01-04 03:09:47,873 INFO:     Found new best model at epoch 6
2023-01-04 03:09:47,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:47,874 INFO:     Epoch: 7
2023-01-04 03:09:49,497 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5270138998826345, 'Total loss': 0.5270138998826345} | train loss {'Reaction outcome loss': 0.4146169892609765, 'Total loss': 0.4146169892609765}
2023-01-04 03:09:49,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:49,498 INFO:     Epoch: 8
2023-01-04 03:09:51,122 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5105280786752701, 'Total loss': 0.5105280786752701} | train loss {'Reaction outcome loss': 0.4009648243281385, 'Total loss': 0.4009648243281385}
2023-01-04 03:09:51,122 INFO:     Found new best model at epoch 8
2023-01-04 03:09:51,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:51,123 INFO:     Epoch: 9
2023-01-04 03:09:52,747 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48961943984031675, 'Total loss': 0.48961943984031675} | train loss {'Reaction outcome loss': 0.38957643933890096, 'Total loss': 0.38957643933890096}
2023-01-04 03:09:52,747 INFO:     Found new best model at epoch 9
2023-01-04 03:09:52,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:52,748 INFO:     Epoch: 10
2023-01-04 03:09:54,342 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5071953396002452, 'Total loss': 0.5071953396002452} | train loss {'Reaction outcome loss': 0.38021139905448426, 'Total loss': 0.38021139905448426}
2023-01-04 03:09:54,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:54,342 INFO:     Epoch: 11
2023-01-04 03:09:55,969 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5002967238426208, 'Total loss': 0.5002967238426208} | train loss {'Reaction outcome loss': 0.36929276859932425, 'Total loss': 0.36929276859932425}
2023-01-04 03:09:55,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:55,969 INFO:     Epoch: 12
2023-01-04 03:09:57,559 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4788117915391922, 'Total loss': 0.4788117915391922} | train loss {'Reaction outcome loss': 0.3605035622789111, 'Total loss': 0.3605035622789111}
2023-01-04 03:09:57,559 INFO:     Found new best model at epoch 12
2023-01-04 03:09:57,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:57,560 INFO:     Epoch: 13
2023-01-04 03:09:59,169 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4766868710517883, 'Total loss': 0.4766868710517883} | train loss {'Reaction outcome loss': 0.35660705441064355, 'Total loss': 0.35660705441064355}
2023-01-04 03:09:59,169 INFO:     Found new best model at epoch 13
2023-01-04 03:09:59,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:09:59,170 INFO:     Epoch: 14
2023-01-04 03:10:00,780 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.467580176393191, 'Total loss': 0.467580176393191} | train loss {'Reaction outcome loss': 0.34629732814183734, 'Total loss': 0.34629732814183734}
2023-01-04 03:10:00,780 INFO:     Found new best model at epoch 14
2023-01-04 03:10:00,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:00,781 INFO:     Epoch: 15
2023-01-04 03:10:02,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4827042798201243, 'Total loss': 0.4827042798201243} | train loss {'Reaction outcome loss': 0.3411187721073412, 'Total loss': 0.3411187721073412}
2023-01-04 03:10:02,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:02,403 INFO:     Epoch: 16
2023-01-04 03:10:03,683 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45234795411427814, 'Total loss': 0.45234795411427814} | train loss {'Reaction outcome loss': 0.33475188004518674, 'Total loss': 0.33475188004518674}
2023-01-04 03:10:03,683 INFO:     Found new best model at epoch 16
2023-01-04 03:10:03,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:03,684 INFO:     Epoch: 17
2023-01-04 03:10:04,763 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48138870994249977, 'Total loss': 0.48138870994249977} | train loss {'Reaction outcome loss': 0.3289935538807501, 'Total loss': 0.3289935538807501}
2023-01-04 03:10:04,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:04,763 INFO:     Epoch: 18
2023-01-04 03:10:05,845 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46219300230344135, 'Total loss': 0.46219300230344135} | train loss {'Reaction outcome loss': 0.32380866482584914, 'Total loss': 0.32380866482584914}
2023-01-04 03:10:05,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:05,845 INFO:     Epoch: 19
2023-01-04 03:10:06,917 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46423288186391193, 'Total loss': 0.46423288186391193} | train loss {'Reaction outcome loss': 0.3172704213793097, 'Total loss': 0.3172704213793097}
2023-01-04 03:10:06,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:06,917 INFO:     Epoch: 20
2023-01-04 03:10:08,406 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47249904870986936, 'Total loss': 0.47249904870986936} | train loss {'Reaction outcome loss': 0.3140942119196434, 'Total loss': 0.3140942119196434}
2023-01-04 03:10:08,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:08,406 INFO:     Epoch: 21
2023-01-04 03:10:10,004 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45965874592463174, 'Total loss': 0.45965874592463174} | train loss {'Reaction outcome loss': 0.3095761493709113, 'Total loss': 0.3095761493709113}
2023-01-04 03:10:10,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:10,004 INFO:     Epoch: 22
2023-01-04 03:10:11,627 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46629413962364197, 'Total loss': 0.46629413962364197} | train loss {'Reaction outcome loss': 0.3064412274246612, 'Total loss': 0.3064412274246612}
2023-01-04 03:10:11,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:11,628 INFO:     Epoch: 23
2023-01-04 03:10:13,221 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45271034936110177, 'Total loss': 0.45271034936110177} | train loss {'Reaction outcome loss': 0.3014506385913825, 'Total loss': 0.3014506385913825}
2023-01-04 03:10:13,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:13,221 INFO:     Epoch: 24
2023-01-04 03:10:14,820 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46868096590042113, 'Total loss': 0.46868096590042113} | train loss {'Reaction outcome loss': 0.2960821800606345, 'Total loss': 0.2960821800606345}
2023-01-04 03:10:14,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:14,822 INFO:     Epoch: 25
2023-01-04 03:10:16,404 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45337332487106324, 'Total loss': 0.45337332487106324} | train loss {'Reaction outcome loss': 0.29338349934519414, 'Total loss': 0.29338349934519414}
2023-01-04 03:10:16,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:16,404 INFO:     Epoch: 26
2023-01-04 03:10:18,027 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44569573402404783, 'Total loss': 0.44569573402404783} | train loss {'Reaction outcome loss': 0.29148393500905606, 'Total loss': 0.29148393500905606}
2023-01-04 03:10:18,028 INFO:     Found new best model at epoch 26
2023-01-04 03:10:18,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:18,028 INFO:     Epoch: 27
2023-01-04 03:10:19,657 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44910303354263303, 'Total loss': 0.44910303354263303} | train loss {'Reaction outcome loss': 0.2844742351221694, 'Total loss': 0.2844742351221694}
2023-01-04 03:10:19,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:19,657 INFO:     Epoch: 28
2023-01-04 03:10:21,278 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44618893166383106, 'Total loss': 0.44618893166383106} | train loss {'Reaction outcome loss': 0.28368950317805425, 'Total loss': 0.28368950317805425}
2023-01-04 03:10:21,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:21,279 INFO:     Epoch: 29
2023-01-04 03:10:22,858 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44325881203015643, 'Total loss': 0.44325881203015643} | train loss {'Reaction outcome loss': 0.279636693264388, 'Total loss': 0.279636693264388}
2023-01-04 03:10:22,858 INFO:     Found new best model at epoch 29
2023-01-04 03:10:22,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:22,859 INFO:     Epoch: 30
2023-01-04 03:10:24,475 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4558140953381856, 'Total loss': 0.4558140953381856} | train loss {'Reaction outcome loss': 0.27837489163402185, 'Total loss': 0.27837489163402185}
2023-01-04 03:10:24,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:24,475 INFO:     Epoch: 31
2023-01-04 03:10:26,062 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4489452491203944, 'Total loss': 0.4489452491203944} | train loss {'Reaction outcome loss': 0.27234632000058134, 'Total loss': 0.27234632000058134}
2023-01-04 03:10:26,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:26,063 INFO:     Epoch: 32
2023-01-04 03:10:27,713 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4517286409934362, 'Total loss': 0.4517286409934362} | train loss {'Reaction outcome loss': 0.2705820383846975, 'Total loss': 0.2705820383846975}
2023-01-04 03:10:27,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:27,713 INFO:     Epoch: 33
2023-01-04 03:10:29,364 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46627105176448824, 'Total loss': 0.46627105176448824} | train loss {'Reaction outcome loss': 0.2661536986593305, 'Total loss': 0.2661536986593305}
2023-01-04 03:10:29,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:29,364 INFO:     Epoch: 34
2023-01-04 03:10:30,970 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45582113166650134, 'Total loss': 0.45582113166650134} | train loss {'Reaction outcome loss': 0.2655832397916257, 'Total loss': 0.2655832397916257}
2023-01-04 03:10:30,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:30,970 INFO:     Epoch: 35
2023-01-04 03:10:32,572 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4373352239529292, 'Total loss': 0.4373352239529292} | train loss {'Reaction outcome loss': 0.26126015761914234, 'Total loss': 0.26126015761914234}
2023-01-04 03:10:32,572 INFO:     Found new best model at epoch 35
2023-01-04 03:10:32,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:32,573 INFO:     Epoch: 36
2023-01-04 03:10:34,164 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45534102420012157, 'Total loss': 0.45534102420012157} | train loss {'Reaction outcome loss': 0.2585678939784907, 'Total loss': 0.2585678939784907}
2023-01-04 03:10:34,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:34,165 INFO:     Epoch: 37
2023-01-04 03:10:35,777 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48682233492533367, 'Total loss': 0.48682233492533367} | train loss {'Reaction outcome loss': 0.2546290942343349, 'Total loss': 0.2546290942343349}
2023-01-04 03:10:35,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:35,778 INFO:     Epoch: 38
2023-01-04 03:10:37,411 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4467026154200236, 'Total loss': 0.4467026154200236} | train loss {'Reaction outcome loss': 0.2513608557276347, 'Total loss': 0.2513608557276347}
2023-01-04 03:10:37,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:37,411 INFO:     Epoch: 39
2023-01-04 03:10:39,040 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4565493126710256, 'Total loss': 0.4565493126710256} | train loss {'Reaction outcome loss': 0.2500444245306163, 'Total loss': 0.2500444245306163}
2023-01-04 03:10:39,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:39,040 INFO:     Epoch: 40
2023-01-04 03:10:40,660 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4478888084491094, 'Total loss': 0.4478888084491094} | train loss {'Reaction outcome loss': 0.2482830043411427, 'Total loss': 0.2482830043411427}
2023-01-04 03:10:40,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:40,660 INFO:     Epoch: 41
2023-01-04 03:10:42,320 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45156114796797436, 'Total loss': 0.45156114796797436} | train loss {'Reaction outcome loss': 0.24629454528543063, 'Total loss': 0.24629454528543063}
2023-01-04 03:10:42,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:42,321 INFO:     Epoch: 42
2023-01-04 03:10:43,938 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4589015871286392, 'Total loss': 0.4589015871286392} | train loss {'Reaction outcome loss': 0.24355568163876928, 'Total loss': 0.24355568163876928}
2023-01-04 03:10:43,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:43,939 INFO:     Epoch: 43
2023-01-04 03:10:45,589 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4631249149640401, 'Total loss': 0.4631249149640401} | train loss {'Reaction outcome loss': 0.24055397168931547, 'Total loss': 0.24055397168931547}
2023-01-04 03:10:45,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:45,589 INFO:     Epoch: 44
2023-01-04 03:10:47,219 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45416179994742073, 'Total loss': 0.45416179994742073} | train loss {'Reaction outcome loss': 0.23834047354892274, 'Total loss': 0.23834047354892274}
2023-01-04 03:10:47,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:47,220 INFO:     Epoch: 45
2023-01-04 03:10:48,827 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4706939111153285, 'Total loss': 0.4706939111153285} | train loss {'Reaction outcome loss': 0.23399238043636192, 'Total loss': 0.23399238043636192}
2023-01-04 03:10:48,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:48,827 INFO:     Epoch: 46
2023-01-04 03:10:50,445 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46576040585835776, 'Total loss': 0.46576040585835776} | train loss {'Reaction outcome loss': 0.23558622765411968, 'Total loss': 0.23558622765411968}
2023-01-04 03:10:50,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:50,447 INFO:     Epoch: 47
2023-01-04 03:10:52,026 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44441977043946584, 'Total loss': 0.44441977043946584} | train loss {'Reaction outcome loss': 0.23311540465600225, 'Total loss': 0.23311540465600225}
2023-01-04 03:10:52,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:52,026 INFO:     Epoch: 48
2023-01-04 03:10:53,632 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46909704903761545, 'Total loss': 0.46909704903761545} | train loss {'Reaction outcome loss': 0.23133683250376463, 'Total loss': 0.23133683250376463}
2023-01-04 03:10:53,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:53,632 INFO:     Epoch: 49
2023-01-04 03:10:55,261 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4648451884587606, 'Total loss': 0.4648451884587606} | train loss {'Reaction outcome loss': 0.2284949390950616, 'Total loss': 0.2284949390950616}
2023-01-04 03:10:55,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:55,261 INFO:     Epoch: 50
2023-01-04 03:10:56,892 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44113727112611134, 'Total loss': 0.44113727112611134} | train loss {'Reaction outcome loss': 0.2276806148031343, 'Total loss': 0.2276806148031343}
2023-01-04 03:10:56,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:56,893 INFO:     Epoch: 51
2023-01-04 03:10:58,472 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4478794818123182, 'Total loss': 0.4478794818123182} | train loss {'Reaction outcome loss': 0.22541329723241527, 'Total loss': 0.22541329723241527}
2023-01-04 03:10:58,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:10:58,472 INFO:     Epoch: 52
2023-01-04 03:11:00,071 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46960671643416085, 'Total loss': 0.46960671643416085} | train loss {'Reaction outcome loss': 0.22525676318346807, 'Total loss': 0.22525676318346807}
2023-01-04 03:11:00,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:00,072 INFO:     Epoch: 53
2023-01-04 03:11:01,674 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4650391002496084, 'Total loss': 0.4650391002496084} | train loss {'Reaction outcome loss': 0.22056100245847599, 'Total loss': 0.22056100245847599}
2023-01-04 03:11:01,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:01,675 INFO:     Epoch: 54
2023-01-04 03:11:03,261 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4726381381352743, 'Total loss': 0.4726381381352743} | train loss {'Reaction outcome loss': 0.21961867828123835, 'Total loss': 0.21961867828123835}
2023-01-04 03:11:03,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:03,261 INFO:     Epoch: 55
2023-01-04 03:11:04,884 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4533643205960592, 'Total loss': 0.4533643205960592} | train loss {'Reaction outcome loss': 0.21955983905585663, 'Total loss': 0.21955983905585663}
2023-01-04 03:11:04,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:04,885 INFO:     Epoch: 56
2023-01-04 03:11:06,508 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4570566515127818, 'Total loss': 0.4570566515127818} | train loss {'Reaction outcome loss': 0.21343560557180363, 'Total loss': 0.21343560557180363}
2023-01-04 03:11:06,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:06,508 INFO:     Epoch: 57
2023-01-04 03:11:08,096 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45489052633444466, 'Total loss': 0.45489052633444466} | train loss {'Reaction outcome loss': 0.21454039421806698, 'Total loss': 0.21454039421806698}
2023-01-04 03:11:08,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:08,096 INFO:     Epoch: 58
2023-01-04 03:11:09,684 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45734913150469464, 'Total loss': 0.45734913150469464} | train loss {'Reaction outcome loss': 0.21444871347895167, 'Total loss': 0.21444871347895167}
2023-01-04 03:11:09,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:09,684 INFO:     Epoch: 59
2023-01-04 03:11:11,281 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46491384506225586, 'Total loss': 0.46491384506225586} | train loss {'Reaction outcome loss': 0.21188062630486187, 'Total loss': 0.21188062630486187}
2023-01-04 03:11:11,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:11,281 INFO:     Epoch: 60
2023-01-04 03:11:12,912 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44391052921613056, 'Total loss': 0.44391052921613056} | train loss {'Reaction outcome loss': 0.21024853082555295, 'Total loss': 0.21024853082555295}
2023-01-04 03:11:12,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:12,912 INFO:     Epoch: 61
2023-01-04 03:11:14,536 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4581518212954203, 'Total loss': 0.4581518212954203} | train loss {'Reaction outcome loss': 0.2077915455594605, 'Total loss': 0.2077915455594605}
2023-01-04 03:11:14,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:14,536 INFO:     Epoch: 62
2023-01-04 03:11:16,128 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48401044607162474, 'Total loss': 0.48401044607162474} | train loss {'Reaction outcome loss': 0.20726221798505592, 'Total loss': 0.20726221798505592}
2023-01-04 03:11:16,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:16,128 INFO:     Epoch: 63
2023-01-04 03:11:17,753 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48036025166511537, 'Total loss': 0.48036025166511537} | train loss {'Reaction outcome loss': 0.20549778255637371, 'Total loss': 0.20549778255637371}
2023-01-04 03:11:17,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:17,753 INFO:     Epoch: 64
2023-01-04 03:11:19,376 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4802009145418803, 'Total loss': 0.4802009145418803} | train loss {'Reaction outcome loss': 0.2022693327456605, 'Total loss': 0.2022693327456605}
2023-01-04 03:11:19,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:19,376 INFO:     Epoch: 65
2023-01-04 03:11:21,000 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4639445732037226, 'Total loss': 0.4639445732037226} | train loss {'Reaction outcome loss': 0.2000718959590373, 'Total loss': 0.2000718959590373}
2023-01-04 03:11:21,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:21,000 INFO:     Epoch: 66
2023-01-04 03:11:22,635 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4684769570827484, 'Total loss': 0.4684769570827484} | train loss {'Reaction outcome loss': 0.20115746333791676, 'Total loss': 0.20115746333791676}
2023-01-04 03:11:22,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:22,635 INFO:     Epoch: 67
2023-01-04 03:11:24,254 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46722547312577567, 'Total loss': 0.46722547312577567} | train loss {'Reaction outcome loss': 0.20098164213639735, 'Total loss': 0.20098164213639735}
2023-01-04 03:11:24,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:24,254 INFO:     Epoch: 68
2023-01-04 03:11:25,840 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.485272874434789, 'Total loss': 0.485272874434789} | train loss {'Reaction outcome loss': 0.19816981017966132, 'Total loss': 0.19816981017966132}
2023-01-04 03:11:25,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:25,841 INFO:     Epoch: 69
2023-01-04 03:11:27,436 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46392705142498014, 'Total loss': 0.46392705142498014} | train loss {'Reaction outcome loss': 0.1983482660826578, 'Total loss': 0.1983482660826578}
2023-01-04 03:11:27,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:27,436 INFO:     Epoch: 70
2023-01-04 03:11:29,037 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4389759143193563, 'Total loss': 0.4389759143193563} | train loss {'Reaction outcome loss': 0.19549836212977606, 'Total loss': 0.19549836212977606}
2023-01-04 03:11:29,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:29,038 INFO:     Epoch: 71
2023-01-04 03:11:30,668 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4659699777762095, 'Total loss': 0.4659699777762095} | train loss {'Reaction outcome loss': 0.19462831108578707, 'Total loss': 0.19462831108578707}
2023-01-04 03:11:30,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:30,668 INFO:     Epoch: 72
2023-01-04 03:11:32,288 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4902989556392034, 'Total loss': 0.4902989556392034} | train loss {'Reaction outcome loss': 0.19115554092162784, 'Total loss': 0.19115554092162784}
2023-01-04 03:11:32,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:32,289 INFO:     Epoch: 73
2023-01-04 03:11:33,893 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4600991189479828, 'Total loss': 0.4600991189479828} | train loss {'Reaction outcome loss': 0.19235716655258667, 'Total loss': 0.19235716655258667}
2023-01-04 03:11:33,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:33,893 INFO:     Epoch: 74
2023-01-04 03:11:35,512 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4743962466716766, 'Total loss': 0.4743962466716766} | train loss {'Reaction outcome loss': 0.19107854697140544, 'Total loss': 0.19107854697140544}
2023-01-04 03:11:35,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:35,513 INFO:     Epoch: 75
2023-01-04 03:11:37,113 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4556420753399531, 'Total loss': 0.4556420753399531} | train loss {'Reaction outcome loss': 0.19114128665642188, 'Total loss': 0.19114128665642188}
2023-01-04 03:11:37,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:37,113 INFO:     Epoch: 76
2023-01-04 03:11:38,693 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4504487544298172, 'Total loss': 0.4504487544298172} | train loss {'Reaction outcome loss': 0.1903904975402011, 'Total loss': 0.1903904975402011}
2023-01-04 03:11:38,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:38,693 INFO:     Epoch: 77
2023-01-04 03:11:40,288 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4614045222600301, 'Total loss': 0.4614045222600301} | train loss {'Reaction outcome loss': 0.18762593774212397, 'Total loss': 0.18762593774212397}
2023-01-04 03:11:40,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:40,288 INFO:     Epoch: 78
2023-01-04 03:11:41,883 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4739464501539866, 'Total loss': 0.4739464501539866} | train loss {'Reaction outcome loss': 0.18852313251540548, 'Total loss': 0.18852313251540548}
2023-01-04 03:11:41,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:41,883 INFO:     Epoch: 79
2023-01-04 03:11:43,478 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4788186232248942, 'Total loss': 0.4788186232248942} | train loss {'Reaction outcome loss': 0.18633275337866928, 'Total loss': 0.18633275337866928}
2023-01-04 03:11:43,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:43,478 INFO:     Epoch: 80
2023-01-04 03:11:45,114 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46339840392271675, 'Total loss': 0.46339840392271675} | train loss {'Reaction outcome loss': 0.18414084766638408, 'Total loss': 0.18414084766638408}
2023-01-04 03:11:45,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:45,115 INFO:     Epoch: 81
2023-01-04 03:11:46,728 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4633739948272705, 'Total loss': 0.4633739948272705} | train loss {'Reaction outcome loss': 0.1840751942126114, 'Total loss': 0.1840751942126114}
2023-01-04 03:11:46,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:46,729 INFO:     Epoch: 82
2023-01-04 03:11:48,357 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44279433886210123, 'Total loss': 0.44279433886210123} | train loss {'Reaction outcome loss': 0.18276435992132456, 'Total loss': 0.18276435992132456}
2023-01-04 03:11:48,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:48,357 INFO:     Epoch: 83
2023-01-04 03:11:49,988 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.482372385263443, 'Total loss': 0.482372385263443} | train loss {'Reaction outcome loss': 0.18347374286623638, 'Total loss': 0.18347374286623638}
2023-01-04 03:11:49,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:49,989 INFO:     Epoch: 84
2023-01-04 03:11:51,572 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4494231045246124, 'Total loss': 0.4494231045246124} | train loss {'Reaction outcome loss': 0.18368338538663267, 'Total loss': 0.18368338538663267}
2023-01-04 03:11:51,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:51,572 INFO:     Epoch: 85
2023-01-04 03:11:53,177 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47104867299397785, 'Total loss': 0.47104867299397785} | train loss {'Reaction outcome loss': 0.1809330033172016, 'Total loss': 0.1809330033172016}
2023-01-04 03:11:53,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:53,177 INFO:     Epoch: 86
2023-01-04 03:11:54,793 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4990641276041667, 'Total loss': 0.4990641276041667} | train loss {'Reaction outcome loss': 0.18230577116489194, 'Total loss': 0.18230577116489194}
2023-01-04 03:11:54,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:54,794 INFO:     Epoch: 87
2023-01-04 03:11:56,375 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4724829981724421, 'Total loss': 0.4724829981724421} | train loss {'Reaction outcome loss': 0.17729067053672748, 'Total loss': 0.17729067053672748}
2023-01-04 03:11:56,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:56,376 INFO:     Epoch: 88
2023-01-04 03:11:58,001 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4750359276930491, 'Total loss': 0.4750359276930491} | train loss {'Reaction outcome loss': 0.17709235647955526, 'Total loss': 0.17709235647955526}
2023-01-04 03:11:58,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:58,001 INFO:     Epoch: 89
2023-01-04 03:11:59,628 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4622322956720988, 'Total loss': 0.4622322956720988} | train loss {'Reaction outcome loss': 0.1762696765026999, 'Total loss': 0.1762696765026999}
2023-01-04 03:11:59,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:11:59,628 INFO:     Epoch: 90
2023-01-04 03:12:01,233 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4503305693467458, 'Total loss': 0.4503305693467458} | train loss {'Reaction outcome loss': 0.17771381289035834, 'Total loss': 0.17771381289035834}
2023-01-04 03:12:01,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:01,233 INFO:     Epoch: 91
2023-01-04 03:12:02,867 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48147616783777875, 'Total loss': 0.48147616783777875} | train loss {'Reaction outcome loss': 0.17799268092704593, 'Total loss': 0.17799268092704593}
2023-01-04 03:12:02,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:02,868 INFO:     Epoch: 92
2023-01-04 03:12:04,454 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4737671713034312, 'Total loss': 0.4737671713034312} | train loss {'Reaction outcome loss': 0.17366816404120936, 'Total loss': 0.17366816404120936}
2023-01-04 03:12:04,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:04,454 INFO:     Epoch: 93
2023-01-04 03:12:06,054 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48471261858940123, 'Total loss': 0.48471261858940123} | train loss {'Reaction outcome loss': 0.17595952012935914, 'Total loss': 0.17595952012935914}
2023-01-04 03:12:06,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:06,054 INFO:     Epoch: 94
2023-01-04 03:12:07,678 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.466595425705115, 'Total loss': 0.466595425705115} | train loss {'Reaction outcome loss': 0.17588247695016518, 'Total loss': 0.17588247695016518}
2023-01-04 03:12:07,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:07,678 INFO:     Epoch: 95
2023-01-04 03:12:09,301 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4621432195107142, 'Total loss': 0.4621432195107142} | train loss {'Reaction outcome loss': 0.17370839999309515, 'Total loss': 0.17370839999309515}
2023-01-04 03:12:09,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:09,301 INFO:     Epoch: 96
2023-01-04 03:12:10,884 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4574911991755168, 'Total loss': 0.4574911991755168} | train loss {'Reaction outcome loss': 0.17179991731870692, 'Total loss': 0.17179991731870692}
2023-01-04 03:12:10,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:10,884 INFO:     Epoch: 97
2023-01-04 03:12:12,487 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4763028512398402, 'Total loss': 0.4763028512398402} | train loss {'Reaction outcome loss': 0.1731053444654395, 'Total loss': 0.1731053444654395}
2023-01-04 03:12:12,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:12,488 INFO:     Epoch: 98
2023-01-04 03:12:14,077 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47908177276452385, 'Total loss': 0.47908177276452385} | train loss {'Reaction outcome loss': 0.17032439195776244, 'Total loss': 0.17032439195776244}
2023-01-04 03:12:14,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:14,077 INFO:     Epoch: 99
2023-01-04 03:12:15,675 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48096079130967456, 'Total loss': 0.48096079130967456} | train loss {'Reaction outcome loss': 0.17165127652108886, 'Total loss': 0.17165127652108886}
2023-01-04 03:12:15,676 INFO:     Best model found after epoch 36 of 100.
2023-01-04 03:12:15,676 INFO:   Done with stage: TRAINING
2023-01-04 03:12:15,676 INFO:   Starting stage: EVALUATION
2023-01-04 03:12:15,796 INFO:   Done with stage: EVALUATION
2023-01-04 03:12:15,796 INFO:   Leaving out SEQ value Fold_6
2023-01-04 03:12:15,809 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 03:12:15,809 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:12:16,460 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:12:16,460 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:12:16,531 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:12:16,531 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:12:16,531 INFO:     No hyperparam tuning for this model
2023-01-04 03:12:16,531 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:12:16,531 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:12:16,532 INFO:     None feature selector for col prot
2023-01-04 03:12:16,532 INFO:     None feature selector for col prot
2023-01-04 03:12:16,532 INFO:     None feature selector for col prot
2023-01-04 03:12:16,532 INFO:     None feature selector for col chem
2023-01-04 03:12:16,532 INFO:     None feature selector for col chem
2023-01-04 03:12:16,533 INFO:     None feature selector for col chem
2023-01-04 03:12:16,533 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:12:16,533 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:12:16,534 INFO:     Number of params in model 70141
2023-01-04 03:12:16,537 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:12:16,537 INFO:   Starting stage: TRAINING
2023-01-04 03:12:16,581 INFO:     Val loss before train {'Reaction outcome loss': 0.9426017324129741, 'Total loss': 0.9426017324129741}
2023-01-04 03:12:16,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:16,581 INFO:     Epoch: 0
2023-01-04 03:12:18,191 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.669822112719218, 'Total loss': 0.669822112719218} | train loss {'Reaction outcome loss': 0.86350692415926, 'Total loss': 0.86350692415926}
2023-01-04 03:12:18,191 INFO:     Found new best model at epoch 0
2023-01-04 03:12:18,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:18,192 INFO:     Epoch: 1
2023-01-04 03:12:19,796 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.567605584859848, 'Total loss': 0.567605584859848} | train loss {'Reaction outcome loss': 0.6305790850186607, 'Total loss': 0.6305790850186607}
2023-01-04 03:12:19,797 INFO:     Found new best model at epoch 1
2023-01-04 03:12:19,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:19,798 INFO:     Epoch: 2
2023-01-04 03:12:21,399 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5300108591715494, 'Total loss': 0.5300108591715494} | train loss {'Reaction outcome loss': 0.5392614448113562, 'Total loss': 0.5392614448113562}
2023-01-04 03:12:21,399 INFO:     Found new best model at epoch 2
2023-01-04 03:12:21,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:21,400 INFO:     Epoch: 3
2023-01-04 03:12:22,988 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4905352195103963, 'Total loss': 0.4905352195103963} | train loss {'Reaction outcome loss': 0.49458708466175233, 'Total loss': 0.49458708466175233}
2023-01-04 03:12:22,988 INFO:     Found new best model at epoch 3
2023-01-04 03:12:22,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:22,989 INFO:     Epoch: 4
2023-01-04 03:12:24,587 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4823026458422343, 'Total loss': 0.4823026458422343} | train loss {'Reaction outcome loss': 0.4660732030115403, 'Total loss': 0.4660732030115403}
2023-01-04 03:12:24,587 INFO:     Found new best model at epoch 4
2023-01-04 03:12:24,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:24,588 INFO:     Epoch: 5
2023-01-04 03:12:26,197 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4546983152627945, 'Total loss': 0.4546983152627945} | train loss {'Reaction outcome loss': 0.44385260903017615, 'Total loss': 0.44385260903017615}
2023-01-04 03:12:26,197 INFO:     Found new best model at epoch 5
2023-01-04 03:12:26,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:26,198 INFO:     Epoch: 6
2023-01-04 03:12:27,791 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4691713849703471, 'Total loss': 0.4691713849703471} | train loss {'Reaction outcome loss': 0.4264339822939587, 'Total loss': 0.4264339822939587}
2023-01-04 03:12:27,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:27,792 INFO:     Epoch: 7
2023-01-04 03:12:29,389 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44014959732691444, 'Total loss': 0.44014959732691444} | train loss {'Reaction outcome loss': 0.4120937843238834, 'Total loss': 0.4120937843238834}
2023-01-04 03:12:29,390 INFO:     Found new best model at epoch 7
2023-01-04 03:12:29,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:29,390 INFO:     Epoch: 8
2023-01-04 03:12:30,969 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4475183526674906, 'Total loss': 0.4475183526674906} | train loss {'Reaction outcome loss': 0.3995218773503596, 'Total loss': 0.3995218773503596}
2023-01-04 03:12:30,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:30,969 INFO:     Epoch: 9
2023-01-04 03:12:32,589 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4417086939016978, 'Total loss': 0.4417086939016978} | train loss {'Reaction outcome loss': 0.3915519607841753, 'Total loss': 0.3915519607841753}
2023-01-04 03:12:32,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:32,590 INFO:     Epoch: 10
2023-01-04 03:12:34,200 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4343089977900187, 'Total loss': 0.4343089977900187} | train loss {'Reaction outcome loss': 0.3822106909988589, 'Total loss': 0.3822106909988589}
2023-01-04 03:12:34,201 INFO:     Found new best model at epoch 10
2023-01-04 03:12:34,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:34,202 INFO:     Epoch: 11
2023-01-04 03:12:35,824 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42377398411432904, 'Total loss': 0.42377398411432904} | train loss {'Reaction outcome loss': 0.3750840705224323, 'Total loss': 0.3750840705224323}
2023-01-04 03:12:35,824 INFO:     Found new best model at epoch 11
2023-01-04 03:12:35,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:35,825 INFO:     Epoch: 12
2023-01-04 03:12:37,408 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42916202545166016, 'Total loss': 0.42916202545166016} | train loss {'Reaction outcome loss': 0.3668740915961644, 'Total loss': 0.3668740915961644}
2023-01-04 03:12:37,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:37,408 INFO:     Epoch: 13
2023-01-04 03:12:39,012 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43491279184818266, 'Total loss': 0.43491279184818266} | train loss {'Reaction outcome loss': 0.35846645723934206, 'Total loss': 0.35846645723934206}
2023-01-04 03:12:39,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:39,012 INFO:     Epoch: 14
2023-01-04 03:12:40,590 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4187910179297129, 'Total loss': 0.4187910179297129} | train loss {'Reaction outcome loss': 0.35366066488763487, 'Total loss': 0.35366066488763487}
2023-01-04 03:12:40,590 INFO:     Found new best model at epoch 14
2023-01-04 03:12:40,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:40,591 INFO:     Epoch: 15
2023-01-04 03:12:42,182 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41612131198247276, 'Total loss': 0.41612131198247276} | train loss {'Reaction outcome loss': 0.35048502083827443, 'Total loss': 0.35048502083827443}
2023-01-04 03:12:42,182 INFO:     Found new best model at epoch 15
2023-01-04 03:12:42,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:42,183 INFO:     Epoch: 16
2023-01-04 03:12:43,790 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41805952390034995, 'Total loss': 0.41805952390034995} | train loss {'Reaction outcome loss': 0.3412713318901802, 'Total loss': 0.3412713318901802}
2023-01-04 03:12:43,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:43,790 INFO:     Epoch: 17
2023-01-04 03:12:45,388 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41175766587257384, 'Total loss': 0.41175766587257384} | train loss {'Reaction outcome loss': 0.3359606809080293, 'Total loss': 0.3359606809080293}
2023-01-04 03:12:45,388 INFO:     Found new best model at epoch 17
2023-01-04 03:12:45,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:45,389 INFO:     Epoch: 18
2023-01-04 03:12:47,004 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4130634720126788, 'Total loss': 0.4130634720126788} | train loss {'Reaction outcome loss': 0.3301518906163395, 'Total loss': 0.3301518906163395}
2023-01-04 03:12:47,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:47,005 INFO:     Epoch: 19
2023-01-04 03:12:48,624 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4163842022418976, 'Total loss': 0.4163842022418976} | train loss {'Reaction outcome loss': 0.3258394044874377, 'Total loss': 0.3258394044874377}
2023-01-04 03:12:48,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:48,624 INFO:     Epoch: 20
2023-01-04 03:12:50,237 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39806901613871254, 'Total loss': 0.39806901613871254} | train loss {'Reaction outcome loss': 0.3212805491492206, 'Total loss': 0.3212805491492206}
2023-01-04 03:12:50,238 INFO:     Found new best model at epoch 20
2023-01-04 03:12:50,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:50,238 INFO:     Epoch: 21
2023-01-04 03:12:51,852 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40388226707776387, 'Total loss': 0.40388226707776387} | train loss {'Reaction outcome loss': 0.31480781830820365, 'Total loss': 0.31480781830820365}
2023-01-04 03:12:51,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:51,852 INFO:     Epoch: 22
2023-01-04 03:12:53,450 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41024892330169677, 'Total loss': 0.41024892330169677} | train loss {'Reaction outcome loss': 0.3105223840270662, 'Total loss': 0.3105223840270662}
2023-01-04 03:12:53,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:53,451 INFO:     Epoch: 23
2023-01-04 03:12:55,043 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40420070588588713, 'Total loss': 0.40420070588588713} | train loss {'Reaction outcome loss': 0.3069796428783706, 'Total loss': 0.3069796428783706}
2023-01-04 03:12:55,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:55,043 INFO:     Epoch: 24
2023-01-04 03:12:56,670 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.405545895298322, 'Total loss': 0.405545895298322} | train loss {'Reaction outcome loss': 0.303651308916536, 'Total loss': 0.303651308916536}
2023-01-04 03:12:56,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:56,670 INFO:     Epoch: 25
2023-01-04 03:12:58,266 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40563582479953764, 'Total loss': 0.40563582479953764} | train loss {'Reaction outcome loss': 0.3008760574546101, 'Total loss': 0.3008760574546101}
2023-01-04 03:12:58,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:58,267 INFO:     Epoch: 26
2023-01-04 03:12:59,888 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38562109718720117, 'Total loss': 0.38562109718720117} | train loss {'Reaction outcome loss': 0.29516776530105715, 'Total loss': 0.29516776530105715}
2023-01-04 03:12:59,888 INFO:     Found new best model at epoch 26
2023-01-04 03:12:59,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:12:59,889 INFO:     Epoch: 27
2023-01-04 03:13:01,513 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4205574164787928, 'Total loss': 0.4205574164787928} | train loss {'Reaction outcome loss': 0.29237424124987116, 'Total loss': 0.29237424124987116}
2023-01-04 03:13:01,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:01,513 INFO:     Epoch: 28
2023-01-04 03:13:03,124 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4051345328489939, 'Total loss': 0.4051345328489939} | train loss {'Reaction outcome loss': 0.2882872020509699, 'Total loss': 0.2882872020509699}
2023-01-04 03:13:03,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:03,126 INFO:     Epoch: 29
2023-01-04 03:13:04,721 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3884395202000936, 'Total loss': 0.3884395202000936} | train loss {'Reaction outcome loss': 0.2860709251264372, 'Total loss': 0.2860709251264372}
2023-01-04 03:13:04,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:04,721 INFO:     Epoch: 30
2023-01-04 03:13:06,325 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41444861590862275, 'Total loss': 0.41444861590862275} | train loss {'Reaction outcome loss': 0.28204205538068866, 'Total loss': 0.28204205538068866}
2023-01-04 03:13:06,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:06,325 INFO:     Epoch: 31
2023-01-04 03:13:07,923 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41833927631378176, 'Total loss': 0.41833927631378176} | train loss {'Reaction outcome loss': 0.27883266827044506, 'Total loss': 0.27883266827044506}
2023-01-04 03:13:07,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:07,924 INFO:     Epoch: 32
2023-01-04 03:13:09,546 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3957690621415774, 'Total loss': 0.3957690621415774} | train loss {'Reaction outcome loss': 0.27479026324051814, 'Total loss': 0.27479026324051814}
2023-01-04 03:13:09,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:09,547 INFO:     Epoch: 33
2023-01-04 03:13:11,155 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40398995677630106, 'Total loss': 0.40398995677630106} | train loss {'Reaction outcome loss': 0.2758702553190049, 'Total loss': 0.2758702553190049}
2023-01-04 03:13:11,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:11,156 INFO:     Epoch: 34
2023-01-04 03:13:12,746 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39626451532046, 'Total loss': 0.39626451532046} | train loss {'Reaction outcome loss': 0.2717108521005307, 'Total loss': 0.2717108521005307}
2023-01-04 03:13:12,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:12,746 INFO:     Epoch: 35
2023-01-04 03:13:14,371 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3951530387004217, 'Total loss': 0.3951530387004217} | train loss {'Reaction outcome loss': 0.2657148876640986, 'Total loss': 0.2657148876640986}
2023-01-04 03:13:14,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:14,371 INFO:     Epoch: 36
2023-01-04 03:13:15,976 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40043142090241113, 'Total loss': 0.40043142090241113} | train loss {'Reaction outcome loss': 0.26372000792934575, 'Total loss': 0.26372000792934575}
2023-01-04 03:13:15,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:15,976 INFO:     Epoch: 37
2023-01-04 03:13:17,602 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40307046274344127, 'Total loss': 0.40307046274344127} | train loss {'Reaction outcome loss': 0.2636089447603329, 'Total loss': 0.2636089447603329}
2023-01-04 03:13:17,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:17,602 INFO:     Epoch: 38
2023-01-04 03:13:19,229 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4029143472512563, 'Total loss': 0.4029143472512563} | train loss {'Reaction outcome loss': 0.2597902314165869, 'Total loss': 0.2597902314165869}
2023-01-04 03:13:19,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:19,229 INFO:     Epoch: 39
2023-01-04 03:13:20,855 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4239073932170868, 'Total loss': 0.4239073932170868} | train loss {'Reaction outcome loss': 0.2580098200737354, 'Total loss': 0.2580098200737354}
2023-01-04 03:13:20,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:20,855 INFO:     Epoch: 40
2023-01-04 03:13:22,462 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41746914982795713, 'Total loss': 0.41746914982795713} | train loss {'Reaction outcome loss': 0.2550908627815625, 'Total loss': 0.2550908627815625}
2023-01-04 03:13:22,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:22,463 INFO:     Epoch: 41
2023-01-04 03:13:24,073 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40142476856708526, 'Total loss': 0.40142476856708526} | train loss {'Reaction outcome loss': 0.252375193531978, 'Total loss': 0.252375193531978}
2023-01-04 03:13:24,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:24,073 INFO:     Epoch: 42
2023-01-04 03:13:25,681 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41077325542767845, 'Total loss': 0.41077325542767845} | train loss {'Reaction outcome loss': 0.2520374807424924, 'Total loss': 0.2520374807424924}
2023-01-04 03:13:25,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:25,681 INFO:     Epoch: 43
2023-01-04 03:13:27,299 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3843755915760994, 'Total loss': 0.3843755915760994} | train loss {'Reaction outcome loss': 0.2452194133524645, 'Total loss': 0.2452194133524645}
2023-01-04 03:13:27,299 INFO:     Found new best model at epoch 43
2023-01-04 03:13:27,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:27,300 INFO:     Epoch: 44
2023-01-04 03:13:28,908 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4167658825715383, 'Total loss': 0.4167658825715383} | train loss {'Reaction outcome loss': 0.24476395835192194, 'Total loss': 0.24476395835192194}
2023-01-04 03:13:28,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:28,908 INFO:     Epoch: 45
2023-01-04 03:13:30,513 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3924059470494588, 'Total loss': 0.3924059470494588} | train loss {'Reaction outcome loss': 0.24381539450171621, 'Total loss': 0.24381539450171621}
2023-01-04 03:13:30,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:30,513 INFO:     Epoch: 46
2023-01-04 03:13:32,118 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39337307810783384, 'Total loss': 0.39337307810783384} | train loss {'Reaction outcome loss': 0.23967474809299738, 'Total loss': 0.23967474809299738}
2023-01-04 03:13:32,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:32,118 INFO:     Epoch: 47
2023-01-04 03:13:33,711 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42929377655188244, 'Total loss': 0.42929377655188244} | train loss {'Reaction outcome loss': 0.23704087102133445, 'Total loss': 0.23704087102133445}
2023-01-04 03:13:33,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:33,712 INFO:     Epoch: 48
2023-01-04 03:13:35,327 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40884547034899393, 'Total loss': 0.40884547034899393} | train loss {'Reaction outcome loss': 0.23980299127876542, 'Total loss': 0.23980299127876542}
2023-01-04 03:13:35,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:35,328 INFO:     Epoch: 49
2023-01-04 03:13:36,946 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40653536121050515, 'Total loss': 0.40653536121050515} | train loss {'Reaction outcome loss': 0.23409999706631102, 'Total loss': 0.23409999706631102}
2023-01-04 03:13:36,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:36,946 INFO:     Epoch: 50
2023-01-04 03:13:38,551 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4100158845384916, 'Total loss': 0.4100158845384916} | train loss {'Reaction outcome loss': 0.23153502972870527, 'Total loss': 0.23153502972870527}
2023-01-04 03:13:38,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:38,551 INFO:     Epoch: 51
2023-01-04 03:13:40,140 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39900111059347787, 'Total loss': 0.39900111059347787} | train loss {'Reaction outcome loss': 0.23242387345013635, 'Total loss': 0.23242387345013635}
2023-01-04 03:13:40,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:40,141 INFO:     Epoch: 52
2023-01-04 03:13:41,745 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4020587960879008, 'Total loss': 0.4020587960879008} | train loss {'Reaction outcome loss': 0.22855010950124222, 'Total loss': 0.22855010950124222}
2023-01-04 03:13:41,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:41,745 INFO:     Epoch: 53
2023-01-04 03:13:43,326 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3898330142100652, 'Total loss': 0.3898330142100652} | train loss {'Reaction outcome loss': 0.23117972866695927, 'Total loss': 0.23117972866695927}
2023-01-04 03:13:43,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:43,326 INFO:     Epoch: 54
2023-01-04 03:13:44,955 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39946529467900593, 'Total loss': 0.39946529467900593} | train loss {'Reaction outcome loss': 0.22390234966624514, 'Total loss': 0.22390234966624514}
2023-01-04 03:13:44,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:44,955 INFO:     Epoch: 55
2023-01-04 03:13:46,560 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40255346794923147, 'Total loss': 0.40255346794923147} | train loss {'Reaction outcome loss': 0.22550237318668986, 'Total loss': 0.22550237318668986}
2023-01-04 03:13:46,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:46,560 INFO:     Epoch: 56
2023-01-04 03:13:48,171 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40897458493709565, 'Total loss': 0.40897458493709565} | train loss {'Reaction outcome loss': 0.22378635110622708, 'Total loss': 0.22378635110622708}
2023-01-04 03:13:48,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:48,171 INFO:     Epoch: 57
2023-01-04 03:13:49,776 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4156773646672567, 'Total loss': 0.4156773646672567} | train loss {'Reaction outcome loss': 0.22195438828171377, 'Total loss': 0.22195438828171377}
2023-01-04 03:13:49,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:49,776 INFO:     Epoch: 58
2023-01-04 03:13:51,380 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40076320568720497, 'Total loss': 0.40076320568720497} | train loss {'Reaction outcome loss': 0.2207154314225331, 'Total loss': 0.2207154314225331}
2023-01-04 03:13:51,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:51,380 INFO:     Epoch: 59
2023-01-04 03:13:52,995 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4155588199694951, 'Total loss': 0.4155588199694951} | train loss {'Reaction outcome loss': 0.21665049264953884, 'Total loss': 0.21665049264953884}
2023-01-04 03:13:52,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:52,996 INFO:     Epoch: 60
2023-01-04 03:13:54,633 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4273105561733246, 'Total loss': 0.4273105561733246} | train loss {'Reaction outcome loss': 0.2162007689072552, 'Total loss': 0.2162007689072552}
2023-01-04 03:13:54,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:54,633 INFO:     Epoch: 61
2023-01-04 03:13:56,272 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42402447511752445, 'Total loss': 0.42402447511752445} | train loss {'Reaction outcome loss': 0.21612310765936488, 'Total loss': 0.21612310765936488}
2023-01-04 03:13:56,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:56,272 INFO:     Epoch: 62
2023-01-04 03:13:57,867 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3874322295188904, 'Total loss': 0.3874322295188904} | train loss {'Reaction outcome loss': 0.2126875441750034, 'Total loss': 0.2126875441750034}
2023-01-04 03:13:57,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:57,868 INFO:     Epoch: 63
2023-01-04 03:13:59,497 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4032683531443278, 'Total loss': 0.4032683531443278} | train loss {'Reaction outcome loss': 0.21058120449419918, 'Total loss': 0.21058120449419918}
2023-01-04 03:13:59,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:13:59,498 INFO:     Epoch: 64
2023-01-04 03:14:01,079 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41423189640045166, 'Total loss': 0.41423189640045166} | train loss {'Reaction outcome loss': 0.21111498871273512, 'Total loss': 0.21111498871273512}
2023-01-04 03:14:01,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:01,080 INFO:     Epoch: 65
2023-01-04 03:14:02,723 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4063442622621854, 'Total loss': 0.4063442622621854} | train loss {'Reaction outcome loss': 0.207601015842671, 'Total loss': 0.207601015842671}
2023-01-04 03:14:02,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:02,723 INFO:     Epoch: 66
2023-01-04 03:14:04,311 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4084364930788676, 'Total loss': 0.4084364930788676} | train loss {'Reaction outcome loss': 0.2074840603403021, 'Total loss': 0.2074840603403021}
2023-01-04 03:14:04,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:04,312 INFO:     Epoch: 67
2023-01-04 03:14:05,904 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43652463058630625, 'Total loss': 0.43652463058630625} | train loss {'Reaction outcome loss': 0.21042892305913385, 'Total loss': 0.21042892305913385}
2023-01-04 03:14:05,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:05,904 INFO:     Epoch: 68
2023-01-04 03:14:07,517 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41673309803009034, 'Total loss': 0.41673309803009034} | train loss {'Reaction outcome loss': 0.20501408072370053, 'Total loss': 0.20501408072370053}
2023-01-04 03:14:07,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:07,517 INFO:     Epoch: 69
2023-01-04 03:14:09,155 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41659942269325256, 'Total loss': 0.41659942269325256} | train loss {'Reaction outcome loss': 0.20431683899747335, 'Total loss': 0.20431683899747335}
2023-01-04 03:14:09,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:09,156 INFO:     Epoch: 70
2023-01-04 03:14:10,764 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.405338184038798, 'Total loss': 0.405338184038798} | train loss {'Reaction outcome loss': 0.20309690796242294, 'Total loss': 0.20309690796242294}
2023-01-04 03:14:10,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:10,765 INFO:     Epoch: 71
2023-01-04 03:14:12,366 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4396426518758138, 'Total loss': 0.4396426518758138} | train loss {'Reaction outcome loss': 0.199412552888643, 'Total loss': 0.199412552888643}
2023-01-04 03:14:12,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:12,366 INFO:     Epoch: 72
2023-01-04 03:14:13,953 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43029864529768624, 'Total loss': 0.43029864529768624} | train loss {'Reaction outcome loss': 0.20208485634318327, 'Total loss': 0.20208485634318327}
2023-01-04 03:14:13,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:13,953 INFO:     Epoch: 73
2023-01-04 03:14:15,564 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4005269149939219, 'Total loss': 0.4005269149939219} | train loss {'Reaction outcome loss': 0.20097679166049304, 'Total loss': 0.20097679166049304}
2023-01-04 03:14:15,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:15,564 INFO:     Epoch: 74
2023-01-04 03:14:17,148 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42084457476933795, 'Total loss': 0.42084457476933795} | train loss {'Reaction outcome loss': 0.1991821136460085, 'Total loss': 0.1991821136460085}
2023-01-04 03:14:17,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:17,148 INFO:     Epoch: 75
2023-01-04 03:14:18,758 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42498599290847777, 'Total loss': 0.42498599290847777} | train loss {'Reaction outcome loss': 0.1976927933333583, 'Total loss': 0.1976927933333583}
2023-01-04 03:14:18,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:18,758 INFO:     Epoch: 76
2023-01-04 03:14:20,357 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4082185318072637, 'Total loss': 0.4082185318072637} | train loss {'Reaction outcome loss': 0.19606685572529098, 'Total loss': 0.19606685572529098}
2023-01-04 03:14:20,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:20,357 INFO:     Epoch: 77
2023-01-04 03:14:21,962 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4294258842865626, 'Total loss': 0.4294258842865626} | train loss {'Reaction outcome loss': 0.19553015761696044, 'Total loss': 0.19553015761696044}
2023-01-04 03:14:21,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:21,963 INFO:     Epoch: 78
2023-01-04 03:14:23,568 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43428011337916056, 'Total loss': 0.43428011337916056} | train loss {'Reaction outcome loss': 0.19490767368502135, 'Total loss': 0.19490767368502135}
2023-01-04 03:14:23,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:23,569 INFO:     Epoch: 79
2023-01-04 03:14:25,146 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4228675365447998, 'Total loss': 0.4228675365447998} | train loss {'Reaction outcome loss': 0.1921689648127405, 'Total loss': 0.1921689648127405}
2023-01-04 03:14:25,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:25,146 INFO:     Epoch: 80
2023-01-04 03:14:26,776 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4472741916775703, 'Total loss': 0.4472741916775703} | train loss {'Reaction outcome loss': 0.19415843153258092, 'Total loss': 0.19415843153258092}
2023-01-04 03:14:26,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:26,776 INFO:     Epoch: 81
2023-01-04 03:14:28,384 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4316150705019633, 'Total loss': 0.4316150705019633} | train loss {'Reaction outcome loss': 0.19217766778348586, 'Total loss': 0.19217766778348586}
2023-01-04 03:14:28,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:28,385 INFO:     Epoch: 82
2023-01-04 03:14:30,020 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4197240481774012, 'Total loss': 0.4197240481774012} | train loss {'Reaction outcome loss': 0.19054897357491166, 'Total loss': 0.19054897357491166}
2023-01-04 03:14:30,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:30,020 INFO:     Epoch: 83
2023-01-04 03:14:31,663 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43647641837596896, 'Total loss': 0.43647641837596896} | train loss {'Reaction outcome loss': 0.19168342091815566, 'Total loss': 0.19168342091815566}
2023-01-04 03:14:31,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:31,664 INFO:     Epoch: 84
2023-01-04 03:14:33,280 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4206079761187235, 'Total loss': 0.4206079761187235} | train loss {'Reaction outcome loss': 0.19026575460761033, 'Total loss': 0.19026575460761033}
2023-01-04 03:14:33,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:33,280 INFO:     Epoch: 85
2023-01-04 03:14:34,907 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41310419539610543, 'Total loss': 0.41310419539610543} | train loss {'Reaction outcome loss': 0.18634310866359768, 'Total loss': 0.18634310866359768}
2023-01-04 03:14:34,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:34,908 INFO:     Epoch: 86
2023-01-04 03:14:36,491 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43712198436260224, 'Total loss': 0.43712198436260224} | train loss {'Reaction outcome loss': 0.1874173651197219, 'Total loss': 0.1874173651197219}
2023-01-04 03:14:36,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:36,492 INFO:     Epoch: 87
2023-01-04 03:14:38,109 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40527991553147635, 'Total loss': 0.40527991553147635} | train loss {'Reaction outcome loss': 0.18202340703740016, 'Total loss': 0.18202340703740016}
2023-01-04 03:14:38,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:38,109 INFO:     Epoch: 88
2023-01-04 03:14:39,754 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4207764188448588, 'Total loss': 0.4207764188448588} | train loss {'Reaction outcome loss': 0.18864816818588045, 'Total loss': 0.18864816818588045}
2023-01-04 03:14:39,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:39,754 INFO:     Epoch: 89
2023-01-04 03:14:41,395 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44803450206915535, 'Total loss': 0.44803450206915535} | train loss {'Reaction outcome loss': 0.18517575647668502, 'Total loss': 0.18517575647668502}
2023-01-04 03:14:41,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:41,396 INFO:     Epoch: 90
2023-01-04 03:14:42,992 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4052437727650007, 'Total loss': 0.4052437727650007} | train loss {'Reaction outcome loss': 0.1856443084615017, 'Total loss': 0.1856443084615017}
2023-01-04 03:14:42,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:42,993 INFO:     Epoch: 91
2023-01-04 03:14:44,598 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4210062702496847, 'Total loss': 0.4210062702496847} | train loss {'Reaction outcome loss': 0.18194083098174219, 'Total loss': 0.18194083098174219}
2023-01-04 03:14:44,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:44,598 INFO:     Epoch: 92
2023-01-04 03:14:46,179 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42473369240760805, 'Total loss': 0.42473369240760805} | train loss {'Reaction outcome loss': 0.18339064321900964, 'Total loss': 0.18339064321900964}
2023-01-04 03:14:46,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:46,179 INFO:     Epoch: 93
2023-01-04 03:14:47,771 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4224067042271296, 'Total loss': 0.4224067042271296} | train loss {'Reaction outcome loss': 0.18330361368638945, 'Total loss': 0.18330361368638945}
2023-01-04 03:14:47,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:47,771 INFO:     Epoch: 94
2023-01-04 03:14:49,400 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4209632168213526, 'Total loss': 0.4209632168213526} | train loss {'Reaction outcome loss': 0.18305283463442368, 'Total loss': 0.18305283463442368}
2023-01-04 03:14:49,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:49,401 INFO:     Epoch: 95
2023-01-04 03:14:51,024 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44768228332201637, 'Total loss': 0.44768228332201637} | train loss {'Reaction outcome loss': 0.18095880698426106, 'Total loss': 0.18095880698426106}
2023-01-04 03:14:51,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:51,024 INFO:     Epoch: 96
2023-01-04 03:14:52,614 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4246128698190053, 'Total loss': 0.4246128698190053} | train loss {'Reaction outcome loss': 0.17944220639092828, 'Total loss': 0.17944220639092828}
2023-01-04 03:14:52,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:52,615 INFO:     Epoch: 97
2023-01-04 03:14:54,215 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4297554830710093, 'Total loss': 0.4297554830710093} | train loss {'Reaction outcome loss': 0.17948284297374612, 'Total loss': 0.17948284297374612}
2023-01-04 03:14:54,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:54,216 INFO:     Epoch: 98
2023-01-04 03:14:55,815 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42993160486221316, 'Total loss': 0.42993160486221316} | train loss {'Reaction outcome loss': 0.1781992720648485, 'Total loss': 0.1781992720648485}
2023-01-04 03:14:55,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:55,816 INFO:     Epoch: 99
2023-01-04 03:14:57,458 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40489854911963147, 'Total loss': 0.40489854911963147} | train loss {'Reaction outcome loss': 0.17720420908734255, 'Total loss': 0.17720420908734255}
2023-01-04 03:14:57,458 INFO:     Best model found after epoch 44 of 100.
2023-01-04 03:14:57,458 INFO:   Done with stage: TRAINING
2023-01-04 03:14:57,458 INFO:   Starting stage: EVALUATION
2023-01-04 03:14:57,580 INFO:   Done with stage: EVALUATION
2023-01-04 03:14:57,580 INFO:   Leaving out SEQ value Fold_7
2023-01-04 03:14:57,592 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:14:57,592 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:14:58,239 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:14:58,239 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:14:58,308 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:14:58,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:14:58,308 INFO:     No hyperparam tuning for this model
2023-01-04 03:14:58,309 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:14:58,309 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:14:58,309 INFO:     None feature selector for col prot
2023-01-04 03:14:58,309 INFO:     None feature selector for col prot
2023-01-04 03:14:58,309 INFO:     None feature selector for col prot
2023-01-04 03:14:58,310 INFO:     None feature selector for col chem
2023-01-04 03:14:58,310 INFO:     None feature selector for col chem
2023-01-04 03:14:58,310 INFO:     None feature selector for col chem
2023-01-04 03:14:58,310 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:14:58,310 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:14:58,311 INFO:     Number of params in model 70141
2023-01-04 03:14:58,315 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:14:58,315 INFO:   Starting stage: TRAINING
2023-01-04 03:14:58,358 INFO:     Val loss before train {'Reaction outcome loss': 1.1548473954200744, 'Total loss': 1.1548473954200744}
2023-01-04 03:14:58,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:58,358 INFO:     Epoch: 0
2023-01-04 03:14:59,961 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7458089272181193, 'Total loss': 0.7458089272181193} | train loss {'Reaction outcome loss': 0.8339782529626287, 'Total loss': 0.8339782529626287}
2023-01-04 03:14:59,961 INFO:     Found new best model at epoch 0
2023-01-04 03:14:59,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:14:59,962 INFO:     Epoch: 1
2023-01-04 03:15:01,558 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6420705457528432, 'Total loss': 0.6420705457528432} | train loss {'Reaction outcome loss': 0.6064148243462694, 'Total loss': 0.6064148243462694}
2023-01-04 03:15:01,558 INFO:     Found new best model at epoch 1
2023-01-04 03:15:01,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:01,559 INFO:     Epoch: 2
2023-01-04 03:15:03,152 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5936052362124126, 'Total loss': 0.5936052362124126} | train loss {'Reaction outcome loss': 0.5375074755157465, 'Total loss': 0.5375074755157465}
2023-01-04 03:15:03,153 INFO:     Found new best model at epoch 2
2023-01-04 03:15:03,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:03,153 INFO:     Epoch: 3
2023-01-04 03:15:04,758 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5636704703172047, 'Total loss': 0.5636704703172047} | train loss {'Reaction outcome loss': 0.49828588314678357, 'Total loss': 0.49828588314678357}
2023-01-04 03:15:04,759 INFO:     Found new best model at epoch 3
2023-01-04 03:15:04,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:04,759 INFO:     Epoch: 4
2023-01-04 03:15:06,361 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5459682762622833, 'Total loss': 0.5459682762622833} | train loss {'Reaction outcome loss': 0.46944628369765007, 'Total loss': 0.46944628369765007}
2023-01-04 03:15:06,362 INFO:     Found new best model at epoch 4
2023-01-04 03:15:06,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:06,363 INFO:     Epoch: 5
2023-01-04 03:15:07,994 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5366992016633352, 'Total loss': 0.5366992016633352} | train loss {'Reaction outcome loss': 0.4496417032095833, 'Total loss': 0.4496417032095833}
2023-01-04 03:15:07,994 INFO:     Found new best model at epoch 5
2023-01-04 03:15:07,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:07,995 INFO:     Epoch: 6
2023-01-04 03:15:09,594 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5497527062892914, 'Total loss': 0.5497527062892914} | train loss {'Reaction outcome loss': 0.4274723052867162, 'Total loss': 0.4274723052867162}
2023-01-04 03:15:09,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:09,594 INFO:     Epoch: 7
2023-01-04 03:15:11,216 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5240713834762574, 'Total loss': 0.5240713834762574} | train loss {'Reaction outcome loss': 0.41535951689803513, 'Total loss': 0.41535951689803513}
2023-01-04 03:15:11,216 INFO:     Found new best model at epoch 7
2023-01-04 03:15:11,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:11,217 INFO:     Epoch: 8
2023-01-04 03:15:12,819 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.52354217171669, 'Total loss': 0.52354217171669} | train loss {'Reaction outcome loss': 0.40117120278486307, 'Total loss': 0.40117120278486307}
2023-01-04 03:15:12,820 INFO:     Found new best model at epoch 8
2023-01-04 03:15:12,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:12,821 INFO:     Epoch: 9
2023-01-04 03:15:14,428 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5045485864082973, 'Total loss': 0.5045485864082973} | train loss {'Reaction outcome loss': 0.39188680184357194, 'Total loss': 0.39188680184357194}
2023-01-04 03:15:14,428 INFO:     Found new best model at epoch 9
2023-01-04 03:15:14,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:14,429 INFO:     Epoch: 10
2023-01-04 03:15:16,049 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4968513449033101, 'Total loss': 0.4968513449033101} | train loss {'Reaction outcome loss': 0.38100162531802617, 'Total loss': 0.38100162531802617}
2023-01-04 03:15:16,049 INFO:     Found new best model at epoch 10
2023-01-04 03:15:16,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:16,050 INFO:     Epoch: 11
2023-01-04 03:15:17,631 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49271161754926046, 'Total loss': 0.49271161754926046} | train loss {'Reaction outcome loss': 0.3741272356072037, 'Total loss': 0.3741272356072037}
2023-01-04 03:15:17,631 INFO:     Found new best model at epoch 11
2023-01-04 03:15:17,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:17,632 INFO:     Epoch: 12
2023-01-04 03:15:19,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4904522478580475, 'Total loss': 0.4904522478580475} | train loss {'Reaction outcome loss': 0.36378008482447977, 'Total loss': 0.36378008482447977}
2023-01-04 03:15:19,221 INFO:     Found new best model at epoch 12
2023-01-04 03:15:19,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:19,222 INFO:     Epoch: 13
2023-01-04 03:15:20,815 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4797928512096405, 'Total loss': 0.4797928512096405} | train loss {'Reaction outcome loss': 0.3720618394082007, 'Total loss': 0.3720618394082007}
2023-01-04 03:15:20,815 INFO:     Found new best model at epoch 13
2023-01-04 03:15:20,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:20,816 INFO:     Epoch: 14
2023-01-04 03:15:22,418 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.488351168235143, 'Total loss': 0.488351168235143} | train loss {'Reaction outcome loss': 0.3522986100903928, 'Total loss': 0.3522986100903928}
2023-01-04 03:15:22,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:22,418 INFO:     Epoch: 15
2023-01-04 03:15:24,000 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48780359625816344, 'Total loss': 0.48780359625816344} | train loss {'Reaction outcome loss': 0.3407262458320052, 'Total loss': 0.3407262458320052}
2023-01-04 03:15:24,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:24,000 INFO:     Epoch: 16
2023-01-04 03:15:25,619 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4726950963338216, 'Total loss': 0.4726950963338216} | train loss {'Reaction outcome loss': 0.33448610906792886, 'Total loss': 0.33448610906792886}
2023-01-04 03:15:25,620 INFO:     Found new best model at epoch 16
2023-01-04 03:15:25,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:25,621 INFO:     Epoch: 17
2023-01-04 03:15:27,214 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4811143765846888, 'Total loss': 0.4811143765846888} | train loss {'Reaction outcome loss': 0.3303559761548388, 'Total loss': 0.3303559761548388}
2023-01-04 03:15:27,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:27,214 INFO:     Epoch: 18
2023-01-04 03:15:28,810 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47248145143191017, 'Total loss': 0.47248145143191017} | train loss {'Reaction outcome loss': 0.33579358412627724, 'Total loss': 0.33579358412627724}
2023-01-04 03:15:28,811 INFO:     Found new best model at epoch 18
2023-01-04 03:15:28,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:28,811 INFO:     Epoch: 19
2023-01-04 03:15:30,417 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47880743940671283, 'Total loss': 0.47880743940671283} | train loss {'Reaction outcome loss': 0.3207153200671293, 'Total loss': 0.3207153200671293}
2023-01-04 03:15:30,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:30,418 INFO:     Epoch: 20
2023-01-04 03:15:32,030 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46107890804608664, 'Total loss': 0.46107890804608664} | train loss {'Reaction outcome loss': 0.3098551638353113, 'Total loss': 0.3098551638353113}
2023-01-04 03:15:32,030 INFO:     Found new best model at epoch 20
2023-01-04 03:15:32,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:32,031 INFO:     Epoch: 21
2023-01-04 03:15:33,627 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46247089505195615, 'Total loss': 0.46247089505195615} | train loss {'Reaction outcome loss': 0.30536892083794065, 'Total loss': 0.30536892083794065}
2023-01-04 03:15:33,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:33,627 INFO:     Epoch: 22
2023-01-04 03:15:35,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45921281377474465, 'Total loss': 0.45921281377474465} | train loss {'Reaction outcome loss': 0.30235565727343783, 'Total loss': 0.30235565727343783}
2023-01-04 03:15:35,250 INFO:     Found new best model at epoch 22
2023-01-04 03:15:35,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:35,251 INFO:     Epoch: 23
2023-01-04 03:15:36,849 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4761908292770386, 'Total loss': 0.4761908292770386} | train loss {'Reaction outcome loss': 0.2984837093862934, 'Total loss': 0.2984837093862934}
2023-01-04 03:15:36,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:36,849 INFO:     Epoch: 24
2023-01-04 03:15:38,464 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4581315318743388, 'Total loss': 0.4581315318743388} | train loss {'Reaction outcome loss': 0.29570550174516474, 'Total loss': 0.29570550174516474}
2023-01-04 03:15:38,464 INFO:     Found new best model at epoch 24
2023-01-04 03:15:38,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:38,465 INFO:     Epoch: 25
2023-01-04 03:15:40,038 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46861875454584756, 'Total loss': 0.46861875454584756} | train loss {'Reaction outcome loss': 0.28598532777117647, 'Total loss': 0.28598532777117647}
2023-01-04 03:15:40,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:40,039 INFO:     Epoch: 26
2023-01-04 03:15:41,657 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.436545400818189, 'Total loss': 0.436545400818189} | train loss {'Reaction outcome loss': 0.28534504611962946, 'Total loss': 0.28534504611962946}
2023-01-04 03:15:41,658 INFO:     Found new best model at epoch 26
2023-01-04 03:15:41,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:41,659 INFO:     Epoch: 27
2023-01-04 03:15:43,285 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4656099557876587, 'Total loss': 0.4656099557876587} | train loss {'Reaction outcome loss': 0.2815356870600279, 'Total loss': 0.2815356870600279}
2023-01-04 03:15:43,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:43,285 INFO:     Epoch: 28
2023-01-04 03:15:44,885 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4408834993839264, 'Total loss': 0.4408834993839264} | train loss {'Reaction outcome loss': 0.275815300508048, 'Total loss': 0.275815300508048}
2023-01-04 03:15:44,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:44,885 INFO:     Epoch: 29
2023-01-04 03:15:46,505 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4354695330063502, 'Total loss': 0.4354695330063502} | train loss {'Reaction outcome loss': 0.2733085273589561, 'Total loss': 0.2733085273589561}
2023-01-04 03:15:46,506 INFO:     Found new best model at epoch 29
2023-01-04 03:15:46,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:46,507 INFO:     Epoch: 30
2023-01-04 03:15:48,128 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4473721504211426, 'Total loss': 0.4473721504211426} | train loss {'Reaction outcome loss': 0.26977518468186684, 'Total loss': 0.26977518468186684}
2023-01-04 03:15:48,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:48,129 INFO:     Epoch: 31
2023-01-04 03:15:49,706 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4665343383948008, 'Total loss': 0.4665343383948008} | train loss {'Reaction outcome loss': 0.27013379170734814, 'Total loss': 0.27013379170734814}
2023-01-04 03:15:49,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:49,706 INFO:     Epoch: 32
2023-01-04 03:15:51,303 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4518173721929391, 'Total loss': 0.4518173721929391} | train loss {'Reaction outcome loss': 0.2861234505384135, 'Total loss': 0.2861234505384135}
2023-01-04 03:15:51,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:51,303 INFO:     Epoch: 33
2023-01-04 03:15:52,898 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4417587697505951, 'Total loss': 0.4417587697505951} | train loss {'Reaction outcome loss': 0.25729846204289375, 'Total loss': 0.25729846204289375}
2023-01-04 03:15:52,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:52,899 INFO:     Epoch: 34
2023-01-04 03:15:54,484 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4436733990907669, 'Total loss': 0.4436733990907669} | train loss {'Reaction outcome loss': 0.254750310436593, 'Total loss': 0.254750310436593}
2023-01-04 03:15:54,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:54,485 INFO:     Epoch: 35
2023-01-04 03:15:56,122 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44111462235450744, 'Total loss': 0.44111462235450744} | train loss {'Reaction outcome loss': 0.25602761372599914, 'Total loss': 0.25602761372599914}
2023-01-04 03:15:56,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:56,123 INFO:     Epoch: 36
2023-01-04 03:15:57,749 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4415840784708659, 'Total loss': 0.4415840784708659} | train loss {'Reaction outcome loss': 0.25508651097534574, 'Total loss': 0.25508651097534574}
2023-01-04 03:15:57,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:57,749 INFO:     Epoch: 37
2023-01-04 03:15:59,418 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4385840266942978, 'Total loss': 0.4385840266942978} | train loss {'Reaction outcome loss': 0.24979399314232043, 'Total loss': 0.24979399314232043}
2023-01-04 03:15:59,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:15:59,419 INFO:     Epoch: 38
2023-01-04 03:16:01,083 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43681471844514214, 'Total loss': 0.43681471844514214} | train loss {'Reaction outcome loss': 0.24662011270613773, 'Total loss': 0.24662011270613773}
2023-01-04 03:16:01,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:01,084 INFO:     Epoch: 39
2023-01-04 03:16:02,738 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4664299190044403, 'Total loss': 0.4664299190044403} | train loss {'Reaction outcome loss': 0.2427526707963451, 'Total loss': 0.2427526707963451}
2023-01-04 03:16:02,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:02,739 INFO:     Epoch: 40
2023-01-04 03:16:04,378 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44868404070536294, 'Total loss': 0.44868404070536294} | train loss {'Reaction outcome loss': 0.24347494058104308, 'Total loss': 0.24347494058104308}
2023-01-04 03:16:04,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:04,378 INFO:     Epoch: 41
2023-01-04 03:16:06,037 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4589049120744069, 'Total loss': 0.4589049120744069} | train loss {'Reaction outcome loss': 0.23918498980988195, 'Total loss': 0.23918498980988195}
2023-01-04 03:16:06,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:06,038 INFO:     Epoch: 42
2023-01-04 03:16:07,679 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4655700266361237, 'Total loss': 0.4655700266361237} | train loss {'Reaction outcome loss': 0.23867058141184025, 'Total loss': 0.23867058141184025}
2023-01-04 03:16:07,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:07,679 INFO:     Epoch: 43
2023-01-04 03:16:09,337 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4518463651339213, 'Total loss': 0.4518463651339213} | train loss {'Reaction outcome loss': 0.24210524534725625, 'Total loss': 0.24210524534725625}
2023-01-04 03:16:09,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:09,337 INFO:     Epoch: 44
2023-01-04 03:16:10,969 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43068830569585165, 'Total loss': 0.43068830569585165} | train loss {'Reaction outcome loss': 0.23912740302500385, 'Total loss': 0.23912740302500385}
2023-01-04 03:16:10,969 INFO:     Found new best model at epoch 44
2023-01-04 03:16:10,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:10,970 INFO:     Epoch: 45
2023-01-04 03:16:12,567 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4319974690675735, 'Total loss': 0.4319974690675735} | train loss {'Reaction outcome loss': 0.232539399675485, 'Total loss': 0.232539399675485}
2023-01-04 03:16:12,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:12,568 INFO:     Epoch: 46
2023-01-04 03:16:14,186 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45581073860327403, 'Total loss': 0.45581073860327403} | train loss {'Reaction outcome loss': 0.2369072851387487, 'Total loss': 0.2369072851387487}
2023-01-04 03:16:14,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:14,187 INFO:     Epoch: 47
2023-01-04 03:16:15,795 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42707157706220944, 'Total loss': 0.42707157706220944} | train loss {'Reaction outcome loss': 0.2281412336624403, 'Total loss': 0.2281412336624403}
2023-01-04 03:16:15,796 INFO:     Found new best model at epoch 47
2023-01-04 03:16:15,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:15,796 INFO:     Epoch: 48
2023-01-04 03:16:17,381 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4404880275328954, 'Total loss': 0.4404880275328954} | train loss {'Reaction outcome loss': 0.22609436757984044, 'Total loss': 0.22609436757984044}
2023-01-04 03:16:17,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:17,382 INFO:     Epoch: 49
2023-01-04 03:16:18,984 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44997261663277943, 'Total loss': 0.44997261663277943} | train loss {'Reaction outcome loss': 0.2221453003306954, 'Total loss': 0.2221453003306954}
2023-01-04 03:16:18,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:18,985 INFO:     Epoch: 50
2023-01-04 03:16:20,579 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44034058749675753, 'Total loss': 0.44034058749675753} | train loss {'Reaction outcome loss': 0.2302254084902613, 'Total loss': 0.2302254084902613}
2023-01-04 03:16:20,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:20,579 INFO:     Epoch: 51
2023-01-04 03:16:22,158 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46547612448533376, 'Total loss': 0.46547612448533376} | train loss {'Reaction outcome loss': 0.2276526833800059, 'Total loss': 0.2276526833800059}
2023-01-04 03:16:22,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:22,158 INFO:     Epoch: 52
2023-01-04 03:16:23,778 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4521665374437968, 'Total loss': 0.4521665374437968} | train loss {'Reaction outcome loss': 0.21556566856578802, 'Total loss': 0.21556566856578802}
2023-01-04 03:16:23,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:23,779 INFO:     Epoch: 53
2023-01-04 03:16:25,348 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4465165207783381, 'Total loss': 0.4465165207783381} | train loss {'Reaction outcome loss': 0.21622398020564645, 'Total loss': 0.21622398020564645}
2023-01-04 03:16:25,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:25,348 INFO:     Epoch: 54
2023-01-04 03:16:26,944 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4629712919394175, 'Total loss': 0.4629712919394175} | train loss {'Reaction outcome loss': 0.23021276778393035, 'Total loss': 0.23021276778393035}
2023-01-04 03:16:26,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:26,945 INFO:     Epoch: 55
2023-01-04 03:16:28,541 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4587676187356313, 'Total loss': 0.4587676187356313} | train loss {'Reaction outcome loss': 0.25964642401136784, 'Total loss': 0.25964642401136784}
2023-01-04 03:16:28,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:28,541 INFO:     Epoch: 56
2023-01-04 03:16:30,121 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4338458220163981, 'Total loss': 0.4338458220163981} | train loss {'Reaction outcome loss': 0.22178515853981176, 'Total loss': 0.22178515853981176}
2023-01-04 03:16:30,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:30,121 INFO:     Epoch: 57
2023-01-04 03:16:31,717 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46049354076385496, 'Total loss': 0.46049354076385496} | train loss {'Reaction outcome loss': 0.21037162940922208, 'Total loss': 0.21037162940922208}
2023-01-04 03:16:31,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:31,718 INFO:     Epoch: 58
2023-01-04 03:16:33,313 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4522552559773127, 'Total loss': 0.4522552559773127} | train loss {'Reaction outcome loss': 0.208227764537973, 'Total loss': 0.208227764537973}
2023-01-04 03:16:33,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:33,313 INFO:     Epoch: 59
2023-01-04 03:16:34,892 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47521194219589236, 'Total loss': 0.47521194219589236} | train loss {'Reaction outcome loss': 0.2057048571961681, 'Total loss': 0.2057048571961681}
2023-01-04 03:16:34,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:34,892 INFO:     Epoch: 60
2023-01-04 03:16:36,515 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47044887642065686, 'Total loss': 0.47044887642065686} | train loss {'Reaction outcome loss': 0.2040063125587303, 'Total loss': 0.2040063125587303}
2023-01-04 03:16:36,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:36,515 INFO:     Epoch: 61
2023-01-04 03:16:38,138 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4569074809551239, 'Total loss': 0.4569074809551239} | train loss {'Reaction outcome loss': 0.20419166193544475, 'Total loss': 0.20419166193544475}
2023-01-04 03:16:38,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:38,138 INFO:     Epoch: 62
2023-01-04 03:16:39,716 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46653580069541933, 'Total loss': 0.46653580069541933} | train loss {'Reaction outcome loss': 0.20182832150316823, 'Total loss': 0.20182832150316823}
2023-01-04 03:16:39,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:39,717 INFO:     Epoch: 63
2023-01-04 03:16:41,312 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4391450385252635, 'Total loss': 0.4391450385252635} | train loss {'Reaction outcome loss': 0.2020271741869468, 'Total loss': 0.2020271741869468}
2023-01-04 03:16:41,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:41,312 INFO:     Epoch: 64
2023-01-04 03:16:42,892 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46490112543106077, 'Total loss': 0.46490112543106077} | train loss {'Reaction outcome loss': 0.2101286469378333, 'Total loss': 0.2101286469378333}
2023-01-04 03:16:42,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:42,893 INFO:     Epoch: 65
2023-01-04 03:16:44,510 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4722582389911016, 'Total loss': 0.4722582389911016} | train loss {'Reaction outcome loss': 0.2266739780737924, 'Total loss': 0.2266739780737924}
2023-01-04 03:16:44,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:44,510 INFO:     Epoch: 66
2023-01-04 03:16:46,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46947781642278036, 'Total loss': 0.46947781642278036} | train loss {'Reaction outcome loss': 0.21209144011052136, 'Total loss': 0.21209144011052136}
2023-01-04 03:16:46,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:46,137 INFO:     Epoch: 67
2023-01-04 03:16:47,759 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4695460816224416, 'Total loss': 0.4695460816224416} | train loss {'Reaction outcome loss': 0.2071537024854426, 'Total loss': 0.2071537024854426}
2023-01-04 03:16:47,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:47,759 INFO:     Epoch: 68
2023-01-04 03:16:49,344 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4691963771979014, 'Total loss': 0.4691963771979014} | train loss {'Reaction outcome loss': 0.20610520211419603, 'Total loss': 0.20610520211419603}
2023-01-04 03:16:49,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:49,345 INFO:     Epoch: 69
2023-01-04 03:16:50,927 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.464568680524826, 'Total loss': 0.464568680524826} | train loss {'Reaction outcome loss': 0.20313771181584647, 'Total loss': 0.20313771181584647}
2023-01-04 03:16:50,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:50,928 INFO:     Epoch: 70
2023-01-04 03:16:52,514 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46928780774275464, 'Total loss': 0.46928780774275464} | train loss {'Reaction outcome loss': 0.199477940072319, 'Total loss': 0.199477940072319}
2023-01-04 03:16:52,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:52,515 INFO:     Epoch: 71
2023-01-04 03:16:54,133 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4619556705156962, 'Total loss': 0.4619556705156962} | train loss {'Reaction outcome loss': 0.19951968298604092, 'Total loss': 0.19951968298604092}
2023-01-04 03:16:54,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:54,133 INFO:     Epoch: 72
2023-01-04 03:16:55,753 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46142102976640065, 'Total loss': 0.46142102976640065} | train loss {'Reaction outcome loss': 0.19699648236058673, 'Total loss': 0.19699648236058673}
2023-01-04 03:16:55,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:55,754 INFO:     Epoch: 73
2023-01-04 03:16:57,325 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4480520745118459, 'Total loss': 0.4480520745118459} | train loss {'Reaction outcome loss': 0.19455531253977137, 'Total loss': 0.19455531253977137}
2023-01-04 03:16:57,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:57,326 INFO:     Epoch: 74
2023-01-04 03:16:58,918 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4638130029042562, 'Total loss': 0.4638130029042562} | train loss {'Reaction outcome loss': 0.1928443676063224, 'Total loss': 0.1928443676063224}
2023-01-04 03:16:58,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:16:58,918 INFO:     Epoch: 75
2023-01-04 03:17:00,509 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4380582898855209, 'Total loss': 0.4380582898855209} | train loss {'Reaction outcome loss': 0.1905418252909853, 'Total loss': 0.1905418252909853}
2023-01-04 03:17:00,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:00,510 INFO:     Epoch: 76
2023-01-04 03:17:02,110 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4700395365556081, 'Total loss': 0.4700395365556081} | train loss {'Reaction outcome loss': 0.1880658035038883, 'Total loss': 0.1880658035038883}
2023-01-04 03:17:02,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:02,111 INFO:     Epoch: 77
2023-01-04 03:17:03,713 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46489540338516233, 'Total loss': 0.46489540338516233} | train loss {'Reaction outcome loss': 0.18708831946487012, 'Total loss': 0.18708831946487012}
2023-01-04 03:17:03,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:03,714 INFO:     Epoch: 78
2023-01-04 03:17:05,337 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44213309784730276, 'Total loss': 0.44213309784730276} | train loss {'Reaction outcome loss': 0.1892796426039675, 'Total loss': 0.1892796426039675}
2023-01-04 03:17:05,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:05,337 INFO:     Epoch: 79
2023-01-04 03:17:06,923 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4640057941277822, 'Total loss': 0.4640057941277822} | train loss {'Reaction outcome loss': 0.19872234992520965, 'Total loss': 0.19872234992520965}
2023-01-04 03:17:06,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:06,923 INFO:     Epoch: 80
2023-01-04 03:17:08,528 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47498795787493386, 'Total loss': 0.47498795787493386} | train loss {'Reaction outcome loss': 0.20409759871235228, 'Total loss': 0.20409759871235228}
2023-01-04 03:17:08,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:08,529 INFO:     Epoch: 81
2023-01-04 03:17:10,123 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45993133187294005, 'Total loss': 0.45993133187294005} | train loss {'Reaction outcome loss': 0.18239349725384577, 'Total loss': 0.18239349725384577}
2023-01-04 03:17:10,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:10,123 INFO:     Epoch: 82
2023-01-04 03:17:11,717 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47482320467631023, 'Total loss': 0.47482320467631023} | train loss {'Reaction outcome loss': 0.18145102177083533, 'Total loss': 0.18145102177083533}
2023-01-04 03:17:11,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:11,717 INFO:     Epoch: 83
2023-01-04 03:17:13,307 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4584471484025319, 'Total loss': 0.4584471484025319} | train loss {'Reaction outcome loss': 0.18243832617704553, 'Total loss': 0.18243832617704553}
2023-01-04 03:17:13,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:13,308 INFO:     Epoch: 84
2023-01-04 03:17:14,917 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45270594557126365, 'Total loss': 0.45270594557126365} | train loss {'Reaction outcome loss': 0.1802060052320577, 'Total loss': 0.1802060052320577}
2023-01-04 03:17:14,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:14,917 INFO:     Epoch: 85
2023-01-04 03:17:16,536 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44877405762672423, 'Total loss': 0.44877405762672423} | train loss {'Reaction outcome loss': 0.18465253989995908, 'Total loss': 0.18465253989995908}
2023-01-04 03:17:16,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:16,536 INFO:     Epoch: 86
2023-01-04 03:17:18,160 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48618663450082145, 'Total loss': 0.48618663450082145} | train loss {'Reaction outcome loss': 0.17957807189204555, 'Total loss': 0.17957807189204555}
2023-01-04 03:17:18,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:18,161 INFO:     Epoch: 87
2023-01-04 03:17:19,768 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4558462560176849, 'Total loss': 0.4558462560176849} | train loss {'Reaction outcome loss': 0.17938980621461204, 'Total loss': 0.17938980621461204}
2023-01-04 03:17:19,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:19,770 INFO:     Epoch: 88
2023-01-04 03:17:21,357 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4581345677375793, 'Total loss': 0.4581345677375793} | train loss {'Reaction outcome loss': 0.17454976422532523, 'Total loss': 0.17454976422532523}
2023-01-04 03:17:21,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:21,357 INFO:     Epoch: 89
2023-01-04 03:17:22,944 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4561212783058484, 'Total loss': 0.4561212783058484} | train loss {'Reaction outcome loss': 0.1761249337763782, 'Total loss': 0.1761249337763782}
2023-01-04 03:17:22,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:22,944 INFO:     Epoch: 90
2023-01-04 03:17:24,519 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4711225191752116, 'Total loss': 0.4711225191752116} | train loss {'Reaction outcome loss': 0.1840121945420253, 'Total loss': 0.1840121945420253}
2023-01-04 03:17:24,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:24,520 INFO:     Epoch: 91
2023-01-04 03:17:26,117 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4715191721916199, 'Total loss': 0.4715191721916199} | train loss {'Reaction outcome loss': 0.1872933827664541, 'Total loss': 0.1872933827664541}
2023-01-04 03:17:26,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:26,118 INFO:     Epoch: 92
2023-01-04 03:17:27,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4673049678405126, 'Total loss': 0.4673049678405126} | train loss {'Reaction outcome loss': 0.18869609813128077, 'Total loss': 0.18869609813128077}
2023-01-04 03:17:27,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:27,699 INFO:     Epoch: 93
2023-01-04 03:17:29,289 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46875555415948233, 'Total loss': 0.46875555415948233} | train loss {'Reaction outcome loss': 0.17781360835626558, 'Total loss': 0.17781360835626558}
2023-01-04 03:17:29,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:29,289 INFO:     Epoch: 94
2023-01-04 03:17:30,913 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4604447841644287, 'Total loss': 0.4604447841644287} | train loss {'Reaction outcome loss': 0.1830431937795093, 'Total loss': 0.1830431937795093}
2023-01-04 03:17:30,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:30,913 INFO:     Epoch: 95
2023-01-04 03:17:32,537 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45860473116238915, 'Total loss': 0.45860473116238915} | train loss {'Reaction outcome loss': 0.17520844416403503, 'Total loss': 0.17520844416403503}
2023-01-04 03:17:32,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:32,538 INFO:     Epoch: 96
2023-01-04 03:17:34,115 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4671928783257802, 'Total loss': 0.4671928783257802} | train loss {'Reaction outcome loss': 0.16998326218616558, 'Total loss': 0.16998326218616558}
2023-01-04 03:17:34,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:34,115 INFO:     Epoch: 97
2023-01-04 03:17:35,710 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48335654934247335, 'Total loss': 0.48335654934247335} | train loss {'Reaction outcome loss': 0.18256326480026264, 'Total loss': 0.18256326480026264}
2023-01-04 03:17:35,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:35,710 INFO:     Epoch: 98
2023-01-04 03:17:37,299 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4751774032910665, 'Total loss': 0.4751774032910665} | train loss {'Reaction outcome loss': 0.19875347060893755, 'Total loss': 0.19875347060893755}
2023-01-04 03:17:37,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:37,299 INFO:     Epoch: 99
2023-01-04 03:17:38,925 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4781476298967997, 'Total loss': 0.4781476298967997} | train loss {'Reaction outcome loss': 0.17335862017310885, 'Total loss': 0.17335862017310885}
2023-01-04 03:17:38,925 INFO:     Best model found after epoch 48 of 100.
2023-01-04 03:17:38,925 INFO:   Done with stage: TRAINING
2023-01-04 03:17:38,925 INFO:   Starting stage: EVALUATION
2023-01-04 03:17:39,054 INFO:   Done with stage: EVALUATION
2023-01-04 03:17:39,055 INFO:   Leaving out SEQ value Fold_8
2023-01-04 03:17:39,067 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 03:17:39,067 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:17:39,708 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:17:39,708 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:17:39,777 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:17:39,777 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:17:39,777 INFO:     No hyperparam tuning for this model
2023-01-04 03:17:39,777 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:17:39,777 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:17:39,778 INFO:     None feature selector for col prot
2023-01-04 03:17:39,778 INFO:     None feature selector for col prot
2023-01-04 03:17:39,778 INFO:     None feature selector for col prot
2023-01-04 03:17:39,779 INFO:     None feature selector for col chem
2023-01-04 03:17:39,779 INFO:     None feature selector for col chem
2023-01-04 03:17:39,779 INFO:     None feature selector for col chem
2023-01-04 03:17:39,779 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:17:39,779 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:17:39,780 INFO:     Number of params in model 70141
2023-01-04 03:17:39,784 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:17:39,784 INFO:   Starting stage: TRAINING
2023-01-04 03:17:39,828 INFO:     Val loss before train {'Reaction outcome loss': 0.820943288008372, 'Total loss': 0.820943288008372}
2023-01-04 03:17:39,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:39,828 INFO:     Epoch: 0
2023-01-04 03:17:41,424 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6310783386230469, 'Total loss': 0.6310783386230469} | train loss {'Reaction outcome loss': 0.8617271153378661, 'Total loss': 0.8617271153378661}
2023-01-04 03:17:41,424 INFO:     Found new best model at epoch 0
2023-01-04 03:17:41,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:41,425 INFO:     Epoch: 1
2023-01-04 03:17:43,001 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5213838875293731, 'Total loss': 0.5213838875293731} | train loss {'Reaction outcome loss': 0.6220065558152478, 'Total loss': 0.6220065558152478}
2023-01-04 03:17:43,001 INFO:     Found new best model at epoch 1
2023-01-04 03:17:43,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:43,002 INFO:     Epoch: 2
2023-01-04 03:17:44,582 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5393224199612935, 'Total loss': 0.5393224199612935} | train loss {'Reaction outcome loss': 0.5371515744902792, 'Total loss': 0.5371515744902792}
2023-01-04 03:17:44,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:44,583 INFO:     Epoch: 3
2023-01-04 03:17:46,148 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48319827715555824, 'Total loss': 0.48319827715555824} | train loss {'Reaction outcome loss': 0.49350443852208825, 'Total loss': 0.49350443852208825}
2023-01-04 03:17:46,149 INFO:     Found new best model at epoch 3
2023-01-04 03:17:46,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:46,150 INFO:     Epoch: 4
2023-01-04 03:17:47,731 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48761852582295734, 'Total loss': 0.48761852582295734} | train loss {'Reaction outcome loss': 0.46618065102039463, 'Total loss': 0.46618065102039463}
2023-01-04 03:17:47,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:47,731 INFO:     Epoch: 5
2023-01-04 03:17:49,315 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4628546297550201, 'Total loss': 0.4628546297550201} | train loss {'Reaction outcome loss': 0.4455152324190105, 'Total loss': 0.4455152324190105}
2023-01-04 03:17:49,316 INFO:     Found new best model at epoch 5
2023-01-04 03:17:49,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:49,317 INFO:     Epoch: 6
2023-01-04 03:17:50,900 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4776689887046814, 'Total loss': 0.4776689887046814} | train loss {'Reaction outcome loss': 0.4287424506823512, 'Total loss': 0.4287424506823512}
2023-01-04 03:17:50,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:50,900 INFO:     Epoch: 7
2023-01-04 03:17:52,511 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4416914542516073, 'Total loss': 0.4416914542516073} | train loss {'Reaction outcome loss': 0.417396655319816, 'Total loss': 0.417396655319816}
2023-01-04 03:17:52,512 INFO:     Found new best model at epoch 7
2023-01-04 03:17:52,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:52,513 INFO:     Epoch: 8
2023-01-04 03:17:54,083 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4502252459526062, 'Total loss': 0.4502252459526062} | train loss {'Reaction outcome loss': 0.4065122575546703, 'Total loss': 0.4065122575546703}
2023-01-04 03:17:54,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:54,083 INFO:     Epoch: 9
2023-01-04 03:17:55,652 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43440160850683845, 'Total loss': 0.43440160850683845} | train loss {'Reaction outcome loss': 0.3933793086912075, 'Total loss': 0.3933793086912075}
2023-01-04 03:17:55,653 INFO:     Found new best model at epoch 9
2023-01-04 03:17:55,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:55,654 INFO:     Epoch: 10
2023-01-04 03:17:57,225 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4383578598499298, 'Total loss': 0.4383578598499298} | train loss {'Reaction outcome loss': 0.3852292633731, 'Total loss': 0.3852292633731}
2023-01-04 03:17:57,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:57,225 INFO:     Epoch: 11
2023-01-04 03:17:58,816 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4316478282213211, 'Total loss': 0.4316478282213211} | train loss {'Reaction outcome loss': 0.3778708108367711, 'Total loss': 0.3778708108367711}
2023-01-04 03:17:58,816 INFO:     Found new best model at epoch 11
2023-01-04 03:17:58,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:17:58,817 INFO:     Epoch: 12
2023-01-04 03:18:00,388 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4556840658187866, 'Total loss': 0.4556840658187866} | train loss {'Reaction outcome loss': 0.37039928668498123, 'Total loss': 0.37039928668498123}
2023-01-04 03:18:00,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:00,388 INFO:     Epoch: 13
2023-01-04 03:18:01,999 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4306822727123896, 'Total loss': 0.4306822727123896} | train loss {'Reaction outcome loss': 0.36379605221704847, 'Total loss': 0.36379605221704847}
2023-01-04 03:18:02,000 INFO:     Found new best model at epoch 13
2023-01-04 03:18:02,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:02,000 INFO:     Epoch: 14
2023-01-04 03:18:03,564 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4191579918066661, 'Total loss': 0.4191579918066661} | train loss {'Reaction outcome loss': 0.35600298273302344, 'Total loss': 0.35600298273302344}
2023-01-04 03:18:03,564 INFO:     Found new best model at epoch 14
2023-01-04 03:18:03,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:03,565 INFO:     Epoch: 15
2023-01-04 03:18:05,155 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4262929826974869, 'Total loss': 0.4262929826974869} | train loss {'Reaction outcome loss': 0.35082430195362463, 'Total loss': 0.35082430195362463}
2023-01-04 03:18:05,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:05,155 INFO:     Epoch: 16
2023-01-04 03:18:06,743 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4330979953209559, 'Total loss': 0.4330979953209559} | train loss {'Reaction outcome loss': 0.34492307292283886, 'Total loss': 0.34492307292283886}
2023-01-04 03:18:06,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:06,744 INFO:     Epoch: 17
2023-01-04 03:18:08,307 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.417866841952006, 'Total loss': 0.417866841952006} | train loss {'Reaction outcome loss': 0.3384038703448146, 'Total loss': 0.3384038703448146}
2023-01-04 03:18:08,308 INFO:     Found new best model at epoch 17
2023-01-04 03:18:08,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:08,309 INFO:     Epoch: 18
2023-01-04 03:18:09,905 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42812392910321556, 'Total loss': 0.42812392910321556} | train loss {'Reaction outcome loss': 0.3369741137173489, 'Total loss': 0.3369741137173489}
2023-01-04 03:18:09,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:09,906 INFO:     Epoch: 19
2023-01-04 03:18:11,484 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4479805946350098, 'Total loss': 0.4479805946350098} | train loss {'Reaction outcome loss': 0.3310321992276794, 'Total loss': 0.3310321992276794}
2023-01-04 03:18:11,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:11,485 INFO:     Epoch: 20
2023-01-04 03:18:13,063 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.415559188524882, 'Total loss': 0.415559188524882} | train loss {'Reaction outcome loss': 0.3246998206651124, 'Total loss': 0.3246998206651124}
2023-01-04 03:18:13,063 INFO:     Found new best model at epoch 20
2023-01-04 03:18:13,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:13,064 INFO:     Epoch: 21
2023-01-04 03:18:14,671 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4186265468597412, 'Total loss': 0.4186265468597412} | train loss {'Reaction outcome loss': 0.3211876595542379, 'Total loss': 0.3211876595542379}
2023-01-04 03:18:14,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:14,671 INFO:     Epoch: 22
2023-01-04 03:18:16,286 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44801885485649107, 'Total loss': 0.44801885485649107} | train loss {'Reaction outcome loss': 0.317394872107645, 'Total loss': 0.317394872107645}
2023-01-04 03:18:16,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:16,286 INFO:     Epoch: 23
2023-01-04 03:18:17,860 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4155128180980682, 'Total loss': 0.4155128180980682} | train loss {'Reaction outcome loss': 0.31273969776765276, 'Total loss': 0.31273969776765276}
2023-01-04 03:18:17,860 INFO:     Found new best model at epoch 23
2023-01-04 03:18:17,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:17,861 INFO:     Epoch: 24
2023-01-04 03:18:19,441 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44274521470069883, 'Total loss': 0.44274521470069883} | train loss {'Reaction outcome loss': 0.31044549261131427, 'Total loss': 0.31044549261131427}
2023-01-04 03:18:19,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:19,441 INFO:     Epoch: 25
2023-01-04 03:18:21,010 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41827394962310793, 'Total loss': 0.41827394962310793} | train loss {'Reaction outcome loss': 0.30536822689166904, 'Total loss': 0.30536822689166904}
2023-01-04 03:18:21,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:21,011 INFO:     Epoch: 26
2023-01-04 03:18:22,592 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4254991337656975, 'Total loss': 0.4254991337656975} | train loss {'Reaction outcome loss': 0.3000308367947157, 'Total loss': 0.3000308367947157}
2023-01-04 03:18:22,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:22,592 INFO:     Epoch: 27
2023-01-04 03:18:24,173 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4402067909638087, 'Total loss': 0.4402067909638087} | train loss {'Reaction outcome loss': 0.2970163958949329, 'Total loss': 0.2970163958949329}
2023-01-04 03:18:24,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:24,173 INFO:     Epoch: 28
2023-01-04 03:18:25,754 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4159765526652336, 'Total loss': 0.4159765526652336} | train loss {'Reaction outcome loss': 0.295343994088199, 'Total loss': 0.295343994088199}
2023-01-04 03:18:25,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:25,754 INFO:     Epoch: 29
2023-01-04 03:18:27,316 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43374895056088764, 'Total loss': 0.43374895056088764} | train loss {'Reaction outcome loss': 0.2914966524571833, 'Total loss': 0.2914966524571833}
2023-01-04 03:18:27,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:27,317 INFO:     Epoch: 30
2023-01-04 03:18:28,895 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4286669075489044, 'Total loss': 0.4286669075489044} | train loss {'Reaction outcome loss': 0.2893743396593924, 'Total loss': 0.2893743396593924}
2023-01-04 03:18:28,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:28,896 INFO:     Epoch: 31
2023-01-04 03:18:30,461 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41895004113515216, 'Total loss': 0.41895004113515216} | train loss {'Reaction outcome loss': 0.28550562871633656, 'Total loss': 0.28550562871633656}
2023-01-04 03:18:30,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:30,461 INFO:     Epoch: 32
2023-01-04 03:18:32,040 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4273971130450567, 'Total loss': 0.4273971130450567} | train loss {'Reaction outcome loss': 0.2812700731829353, 'Total loss': 0.2812700731829353}
2023-01-04 03:18:32,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:32,041 INFO:     Epoch: 33
2023-01-04 03:18:33,619 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42375357846419015, 'Total loss': 0.42375357846419015} | train loss {'Reaction outcome loss': 0.28120967147559145, 'Total loss': 0.28120967147559145}
2023-01-04 03:18:33,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:33,619 INFO:     Epoch: 34
2023-01-04 03:18:35,184 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4362505733966827, 'Total loss': 0.4362505733966827} | train loss {'Reaction outcome loss': 0.27496568850465936, 'Total loss': 0.27496568850465936}
2023-01-04 03:18:35,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:35,184 INFO:     Epoch: 35
2023-01-04 03:18:36,796 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44810801148414614, 'Total loss': 0.44810801148414614} | train loss {'Reaction outcome loss': 0.2728310715760628, 'Total loss': 0.2728310715760628}
2023-01-04 03:18:36,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:36,797 INFO:     Epoch: 36
2023-01-04 03:18:38,373 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41461182534694674, 'Total loss': 0.41461182534694674} | train loss {'Reaction outcome loss': 0.27239875886997167, 'Total loss': 0.27239875886997167}
2023-01-04 03:18:38,373 INFO:     Found new best model at epoch 36
2023-01-04 03:18:38,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:38,374 INFO:     Epoch: 37
2023-01-04 03:18:39,934 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43705481390158335, 'Total loss': 0.43705481390158335} | train loss {'Reaction outcome loss': 0.26708898296321393, 'Total loss': 0.26708898296321393}
2023-01-04 03:18:39,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:39,935 INFO:     Epoch: 38
2023-01-04 03:18:41,532 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42595063348611195, 'Total loss': 0.42595063348611195} | train loss {'Reaction outcome loss': 0.26677370424905833, 'Total loss': 0.26677370424905833}
2023-01-04 03:18:41,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:41,533 INFO:     Epoch: 39
2023-01-04 03:18:43,146 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4215495973825455, 'Total loss': 0.4215495973825455} | train loss {'Reaction outcome loss': 0.26290399192349756, 'Total loss': 0.26290399192349756}
2023-01-04 03:18:43,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:43,146 INFO:     Epoch: 40
2023-01-04 03:18:44,725 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42751725514729816, 'Total loss': 0.42751725514729816} | train loss {'Reaction outcome loss': 0.2592170678323855, 'Total loss': 0.2592170678323855}
2023-01-04 03:18:44,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:44,725 INFO:     Epoch: 41
2023-01-04 03:18:46,303 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4358233173688253, 'Total loss': 0.4358233173688253} | train loss {'Reaction outcome loss': 0.2584385026626996, 'Total loss': 0.2584385026626996}
2023-01-04 03:18:46,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:46,303 INFO:     Epoch: 42
2023-01-04 03:18:47,902 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4334090828895569, 'Total loss': 0.4334090828895569} | train loss {'Reaction outcome loss': 0.2576642540847733, 'Total loss': 0.2576642540847733}
2023-01-04 03:18:47,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:47,902 INFO:     Epoch: 43
2023-01-04 03:18:49,513 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42127051651477815, 'Total loss': 0.42127051651477815} | train loss {'Reaction outcome loss': 0.2532052095761917, 'Total loss': 0.2532052095761917}
2023-01-04 03:18:49,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:49,513 INFO:     Epoch: 44
2023-01-04 03:18:51,126 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43415849755207697, 'Total loss': 0.43415849755207697} | train loss {'Reaction outcome loss': 0.2513451651282554, 'Total loss': 0.2513451651282554}
2023-01-04 03:18:51,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:51,126 INFO:     Epoch: 45
2023-01-04 03:18:52,736 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4412713994582494, 'Total loss': 0.4412713994582494} | train loss {'Reaction outcome loss': 0.24938134248470412, 'Total loss': 0.24938134248470412}
2023-01-04 03:18:52,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:52,736 INFO:     Epoch: 46
2023-01-04 03:18:54,327 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.442683482170105, 'Total loss': 0.442683482170105} | train loss {'Reaction outcome loss': 0.2457881928115648, 'Total loss': 0.2457881928115648}
2023-01-04 03:18:54,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:54,328 INFO:     Epoch: 47
2023-01-04 03:18:55,901 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43095049311717354, 'Total loss': 0.43095049311717354} | train loss {'Reaction outcome loss': 0.2428461773198669, 'Total loss': 0.2428461773198669}
2023-01-04 03:18:55,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:55,902 INFO:     Epoch: 48
2023-01-04 03:18:57,487 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4357097566127777, 'Total loss': 0.4357097566127777} | train loss {'Reaction outcome loss': 0.24095963727492486, 'Total loss': 0.24095963727492486}
2023-01-04 03:18:57,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:57,487 INFO:     Epoch: 49
2023-01-04 03:18:59,100 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42577830503384273, 'Total loss': 0.42577830503384273} | train loss {'Reaction outcome loss': 0.2404441637986333, 'Total loss': 0.2404441637986333}
2023-01-04 03:18:59,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:18:59,100 INFO:     Epoch: 50
2023-01-04 03:19:00,709 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45842367013295493, 'Total loss': 0.45842367013295493} | train loss {'Reaction outcome loss': 0.23736363045708106, 'Total loss': 0.23736363045708106}
2023-01-04 03:19:00,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:00,709 INFO:     Epoch: 51
2023-01-04 03:19:02,296 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4179284393787384, 'Total loss': 0.4179284393787384} | train loss {'Reaction outcome loss': 0.2349863981107508, 'Total loss': 0.2349863981107508}
2023-01-04 03:19:02,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:02,297 INFO:     Epoch: 52
2023-01-04 03:19:03,871 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.426719289769729, 'Total loss': 0.426719289769729} | train loss {'Reaction outcome loss': 0.2328569833461168, 'Total loss': 0.2328569833461168}
2023-01-04 03:19:03,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:03,871 INFO:     Epoch: 53
2023-01-04 03:19:05,488 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43407284915447236, 'Total loss': 0.43407284915447236} | train loss {'Reaction outcome loss': 0.23091143799306701, 'Total loss': 0.23091143799306701}
2023-01-04 03:19:05,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:05,489 INFO:     Epoch: 54
2023-01-04 03:19:07,081 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45830312569936116, 'Total loss': 0.45830312569936116} | train loss {'Reaction outcome loss': 0.23080646199085852, 'Total loss': 0.23080646199085852}
2023-01-04 03:19:07,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:07,081 INFO:     Epoch: 55
2023-01-04 03:19:08,690 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43550244470437366, 'Total loss': 0.43550244470437366} | train loss {'Reaction outcome loss': 0.23071098919060543, 'Total loss': 0.23071098919060543}
2023-01-04 03:19:08,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:08,690 INFO:     Epoch: 56
2023-01-04 03:19:10,283 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4350116511185964, 'Total loss': 0.4350116511185964} | train loss {'Reaction outcome loss': 0.2266865218207784, 'Total loss': 0.2266865218207784}
2023-01-04 03:19:10,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:10,284 INFO:     Epoch: 57
2023-01-04 03:19:11,869 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43560470740000407, 'Total loss': 0.43560470740000407} | train loss {'Reaction outcome loss': 0.22395323835530856, 'Total loss': 0.22395323835530856}
2023-01-04 03:19:11,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:11,870 INFO:     Epoch: 58
2023-01-04 03:19:13,479 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44755107661088306, 'Total loss': 0.44755107661088306} | train loss {'Reaction outcome loss': 0.22453593330824898, 'Total loss': 0.22453593330824898}
2023-01-04 03:19:13,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:13,479 INFO:     Epoch: 59
2023-01-04 03:19:15,068 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43859764536221824, 'Total loss': 0.43859764536221824} | train loss {'Reaction outcome loss': 0.2215519767512914, 'Total loss': 0.2215519767512914}
2023-01-04 03:19:15,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:15,068 INFO:     Epoch: 60
2023-01-04 03:19:16,679 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44798022707303364, 'Total loss': 0.44798022707303364} | train loss {'Reaction outcome loss': 0.2171479693484785, 'Total loss': 0.2171479693484785}
2023-01-04 03:19:16,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:16,679 INFO:     Epoch: 61
2023-01-04 03:19:18,272 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.455020006497701, 'Total loss': 0.455020006497701} | train loss {'Reaction outcome loss': 0.21520855110546533, 'Total loss': 0.21520855110546533}
2023-01-04 03:19:18,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:18,272 INFO:     Epoch: 62
2023-01-04 03:19:19,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42694537043571473, 'Total loss': 0.42694537043571473} | train loss {'Reaction outcome loss': 0.21652155198211218, 'Total loss': 0.21652155198211218}
2023-01-04 03:19:19,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:19,879 INFO:     Epoch: 63
2023-01-04 03:19:21,462 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4659017374118169, 'Total loss': 0.4659017374118169} | train loss {'Reaction outcome loss': 0.21406022621060375, 'Total loss': 0.21406022621060375}
2023-01-04 03:19:21,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:21,462 INFO:     Epoch: 64
2023-01-04 03:19:23,070 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4947476009527842, 'Total loss': 0.4947476009527842} | train loss {'Reaction outcome loss': 0.21220939102018402, 'Total loss': 0.21220939102018402}
2023-01-04 03:19:23,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:23,070 INFO:     Epoch: 65
2023-01-04 03:19:24,658 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42186094224452975, 'Total loss': 0.42186094224452975} | train loss {'Reaction outcome loss': 0.21367719489401274, 'Total loss': 0.21367719489401274}
2023-01-04 03:19:24,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:24,658 INFO:     Epoch: 66
2023-01-04 03:19:26,266 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4119829018910726, 'Total loss': 0.4119829018910726} | train loss {'Reaction outcome loss': 0.20909019028020165, 'Total loss': 0.20909019028020165}
2023-01-04 03:19:26,267 INFO:     Found new best model at epoch 66
2023-01-04 03:19:26,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:26,267 INFO:     Epoch: 67
2023-01-04 03:19:27,867 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44423975149790446, 'Total loss': 0.44423975149790446} | train loss {'Reaction outcome loss': 0.20873608281088135, 'Total loss': 0.20873608281088135}
2023-01-04 03:19:27,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:27,868 INFO:     Epoch: 68
2023-01-04 03:19:29,454 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4328607439994812, 'Total loss': 0.4328607439994812} | train loss {'Reaction outcome loss': 0.20750613779808483, 'Total loss': 0.20750613779808483}
2023-01-04 03:19:29,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:29,454 INFO:     Epoch: 69
2023-01-04 03:19:31,037 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4307567795117696, 'Total loss': 0.4307567795117696} | train loss {'Reaction outcome loss': 0.20580678909038105, 'Total loss': 0.20580678909038105}
2023-01-04 03:19:31,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:31,037 INFO:     Epoch: 70
2023-01-04 03:19:32,615 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45697906414667766, 'Total loss': 0.45697906414667766} | train loss {'Reaction outcome loss': 0.20349280388658716, 'Total loss': 0.20349280388658716}
2023-01-04 03:19:32,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:32,615 INFO:     Epoch: 71
2023-01-04 03:19:34,207 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43315849602222445, 'Total loss': 0.43315849602222445} | train loss {'Reaction outcome loss': 0.20196837772798798, 'Total loss': 0.20196837772798798}
2023-01-04 03:19:34,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:34,208 INFO:     Epoch: 72
2023-01-04 03:19:35,808 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4364165543268124, 'Total loss': 0.4364165543268124} | train loss {'Reaction outcome loss': 0.2025033410801722, 'Total loss': 0.2025033410801722}
2023-01-04 03:19:35,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:35,808 INFO:     Epoch: 73
2023-01-04 03:19:37,414 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.427485025425752, 'Total loss': 0.427485025425752} | train loss {'Reaction outcome loss': 0.19835887162735427, 'Total loss': 0.19835887162735427}
2023-01-04 03:19:37,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:37,414 INFO:     Epoch: 74
2023-01-04 03:19:38,691 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42728720704714457, 'Total loss': 0.42728720704714457} | train loss {'Reaction outcome loss': 0.19827821224683176, 'Total loss': 0.19827821224683176}
2023-01-04 03:19:38,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:38,691 INFO:     Epoch: 75
2023-01-04 03:19:39,739 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.441581928730011, 'Total loss': 0.441581928730011} | train loss {'Reaction outcome loss': 0.1981192612000843, 'Total loss': 0.1981192612000843}
2023-01-04 03:19:39,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:39,739 INFO:     Epoch: 76
2023-01-04 03:19:40,796 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44932086368401847, 'Total loss': 0.44932086368401847} | train loss {'Reaction outcome loss': 0.19465010803546348, 'Total loss': 0.19465010803546348}
2023-01-04 03:19:40,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:40,797 INFO:     Epoch: 77
2023-01-04 03:19:41,844 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45987644692262014, 'Total loss': 0.45987644692262014} | train loss {'Reaction outcome loss': 0.1945046335866634, 'Total loss': 0.1945046335866634}
2023-01-04 03:19:41,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:41,844 INFO:     Epoch: 78
2023-01-04 03:19:43,019 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.462556865811348, 'Total loss': 0.462556865811348} | train loss {'Reaction outcome loss': 0.19159201308269136, 'Total loss': 0.19159201308269136}
2023-01-04 03:19:43,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:43,019 INFO:     Epoch: 79
2023-01-04 03:19:44,624 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45467673540115355, 'Total loss': 0.45467673540115355} | train loss {'Reaction outcome loss': 0.19208671683513553, 'Total loss': 0.19208671683513553}
2023-01-04 03:19:44,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:44,624 INFO:     Epoch: 80
2023-01-04 03:19:46,229 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.451003227631251, 'Total loss': 0.451003227631251} | train loss {'Reaction outcome loss': 0.1890615890903847, 'Total loss': 0.1890615890903847}
2023-01-04 03:19:46,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:46,230 INFO:     Epoch: 81
2023-01-04 03:19:47,820 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4824952781200409, 'Total loss': 0.4824952781200409} | train loss {'Reaction outcome loss': 0.18681946390029722, 'Total loss': 0.18681946390029722}
2023-01-04 03:19:47,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:47,820 INFO:     Epoch: 82
2023-01-04 03:19:49,402 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46659181714057923, 'Total loss': 0.46659181714057923} | train loss {'Reaction outcome loss': 0.18776370792982788, 'Total loss': 0.18776370792982788}
2023-01-04 03:19:49,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:49,402 INFO:     Epoch: 83
2023-01-04 03:19:51,004 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4440087030331294, 'Total loss': 0.4440087030331294} | train loss {'Reaction outcome loss': 0.1864312864758455, 'Total loss': 0.1864312864758455}
2023-01-04 03:19:51,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:51,004 INFO:     Epoch: 84
2023-01-04 03:19:52,580 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4485243340333303, 'Total loss': 0.4485243340333303} | train loss {'Reaction outcome loss': 0.18618884383544435, 'Total loss': 0.18618884383544435}
2023-01-04 03:19:52,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:52,580 INFO:     Epoch: 85
2023-01-04 03:19:54,164 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47895237704118093, 'Total loss': 0.47895237704118093} | train loss {'Reaction outcome loss': 0.18521522842075702, 'Total loss': 0.18521522842075702}
2023-01-04 03:19:54,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:54,165 INFO:     Epoch: 86
2023-01-04 03:19:55,748 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4474869936704636, 'Total loss': 0.4474869936704636} | train loss {'Reaction outcome loss': 0.1835859045182375, 'Total loss': 0.1835859045182375}
2023-01-04 03:19:55,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:55,748 INFO:     Epoch: 87
2023-01-04 03:19:57,317 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45545026163260144, 'Total loss': 0.45545026163260144} | train loss {'Reaction outcome loss': 0.18258378256357063, 'Total loss': 0.18258378256357063}
2023-01-04 03:19:57,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:57,317 INFO:     Epoch: 88
2023-01-04 03:19:58,922 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4536941409111023, 'Total loss': 0.4536941409111023} | train loss {'Reaction outcome loss': 0.18122489918295268, 'Total loss': 0.18122489918295268}
2023-01-04 03:19:58,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:19:58,922 INFO:     Epoch: 89
2023-01-04 03:20:00,528 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4658585329850515, 'Total loss': 0.4658585329850515} | train loss {'Reaction outcome loss': 0.18259168916592633, 'Total loss': 0.18259168916592633}
2023-01-04 03:20:00,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:00,528 INFO:     Epoch: 90
2023-01-04 03:20:02,089 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.459898853302002, 'Total loss': 0.459898853302002} | train loss {'Reaction outcome loss': 0.18133347847220235, 'Total loss': 0.18133347847220235}
2023-01-04 03:20:02,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:02,089 INFO:     Epoch: 91
2023-01-04 03:20:03,687 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4689738353093465, 'Total loss': 0.4689738353093465} | train loss {'Reaction outcome loss': 0.17918876955543991, 'Total loss': 0.17918876955543991}
2023-01-04 03:20:03,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:03,689 INFO:     Epoch: 92
2023-01-04 03:20:05,297 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44765977958838143, 'Total loss': 0.44765977958838143} | train loss {'Reaction outcome loss': 0.1791108146744923, 'Total loss': 0.1791108146744923}
2023-01-04 03:20:05,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:05,297 INFO:     Epoch: 93
2023-01-04 03:20:06,863 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4643053889274597, 'Total loss': 0.4643053889274597} | train loss {'Reaction outcome loss': 0.17546454375868079, 'Total loss': 0.17546454375868079}
2023-01-04 03:20:06,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:06,863 INFO:     Epoch: 94
2023-01-04 03:20:08,469 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4892645905415217, 'Total loss': 0.4892645905415217} | train loss {'Reaction outcome loss': 0.17467863172510245, 'Total loss': 0.17467863172510245}
2023-01-04 03:20:08,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:08,470 INFO:     Epoch: 95
2023-01-04 03:20:10,048 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4405863218009472, 'Total loss': 0.4405863218009472} | train loss {'Reaction outcome loss': 0.17442575309860664, 'Total loss': 0.17442575309860664}
2023-01-04 03:20:10,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:10,048 INFO:     Epoch: 96
2023-01-04 03:20:11,650 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45001784612735113, 'Total loss': 0.45001784612735113} | train loss {'Reaction outcome loss': 0.17182768136942692, 'Total loss': 0.17182768136942692}
2023-01-04 03:20:11,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:11,651 INFO:     Epoch: 97
2023-01-04 03:20:13,259 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47065926492214205, 'Total loss': 0.47065926492214205} | train loss {'Reaction outcome loss': 0.1728126303816255, 'Total loss': 0.1728126303816255}
2023-01-04 03:20:13,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:13,259 INFO:     Epoch: 98
2023-01-04 03:20:14,868 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43935127357641857, 'Total loss': 0.43935127357641857} | train loss {'Reaction outcome loss': 0.1710370291418729, 'Total loss': 0.1710370291418729}
2023-01-04 03:20:14,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:14,868 INFO:     Epoch: 99
2023-01-04 03:20:16,463 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46706415017445885, 'Total loss': 0.46706415017445885} | train loss {'Reaction outcome loss': 0.16896297603872787, 'Total loss': 0.16896297603872787}
2023-01-04 03:20:16,463 INFO:     Best model found after epoch 67 of 100.
2023-01-04 03:20:16,464 INFO:   Done with stage: TRAINING
2023-01-04 03:20:16,464 INFO:   Starting stage: EVALUATION
2023-01-04 03:20:16,597 INFO:   Done with stage: EVALUATION
2023-01-04 03:20:16,597 INFO:   Leaving out SEQ value Fold_9
2023-01-04 03:20:16,609 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:20:16,610 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:20:17,250 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:20:17,250 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:20:17,320 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:20:17,320 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:20:17,320 INFO:     No hyperparam tuning for this model
2023-01-04 03:20:17,320 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:20:17,320 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:20:17,321 INFO:     None feature selector for col prot
2023-01-04 03:20:17,321 INFO:     None feature selector for col prot
2023-01-04 03:20:17,321 INFO:     None feature selector for col prot
2023-01-04 03:20:17,321 INFO:     None feature selector for col chem
2023-01-04 03:20:17,322 INFO:     None feature selector for col chem
2023-01-04 03:20:17,322 INFO:     None feature selector for col chem
2023-01-04 03:20:17,322 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:20:17,322 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:20:17,323 INFO:     Number of params in model 70141
2023-01-04 03:20:17,326 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:20:17,326 INFO:   Starting stage: TRAINING
2023-01-04 03:20:17,369 INFO:     Val loss before train {'Reaction outcome loss': 1.0469280203183493, 'Total loss': 1.0469280203183493}
2023-01-04 03:20:17,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:17,369 INFO:     Epoch: 0
2023-01-04 03:20:18,947 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7129370252291362, 'Total loss': 0.7129370252291362} | train loss {'Reaction outcome loss': 0.8342594338338012, 'Total loss': 0.8342594338338012}
2023-01-04 03:20:18,947 INFO:     Found new best model at epoch 0
2023-01-04 03:20:18,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:18,948 INFO:     Epoch: 1
2023-01-04 03:20:20,559 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6048559814691543, 'Total loss': 0.6048559814691543} | train loss {'Reaction outcome loss': 0.6207710245077539, 'Total loss': 0.6207710245077539}
2023-01-04 03:20:20,559 INFO:     Found new best model at epoch 1
2023-01-04 03:20:20,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:20,560 INFO:     Epoch: 2
2023-01-04 03:20:22,169 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5759567260742188, 'Total loss': 0.5759567260742188} | train loss {'Reaction outcome loss': 0.5311089789642922, 'Total loss': 0.5311089789642922}
2023-01-04 03:20:22,170 INFO:     Found new best model at epoch 2
2023-01-04 03:20:22,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:22,171 INFO:     Epoch: 3
2023-01-04 03:20:23,751 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5663917442162831, 'Total loss': 0.5663917442162831} | train loss {'Reaction outcome loss': 0.48895241080553853, 'Total loss': 0.48895241080553853}
2023-01-04 03:20:23,752 INFO:     Found new best model at epoch 3
2023-01-04 03:20:23,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:23,752 INFO:     Epoch: 4
2023-01-04 03:20:25,325 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5045744111140569, 'Total loss': 0.5045744111140569} | train loss {'Reaction outcome loss': 0.4673513013167658, 'Total loss': 0.4673513013167658}
2023-01-04 03:20:25,325 INFO:     Found new best model at epoch 4
2023-01-04 03:20:25,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:25,326 INFO:     Epoch: 5
2023-01-04 03:20:26,913 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5022890289624532, 'Total loss': 0.5022890289624532} | train loss {'Reaction outcome loss': 0.4437023916322252, 'Total loss': 0.4437023916322252}
2023-01-04 03:20:26,913 INFO:     Found new best model at epoch 5
2023-01-04 03:20:26,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:26,914 INFO:     Epoch: 6
2023-01-04 03:20:28,491 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49785224894682567, 'Total loss': 0.49785224894682567} | train loss {'Reaction outcome loss': 0.4281833416957786, 'Total loss': 0.4281833416957786}
2023-01-04 03:20:28,491 INFO:     Found new best model at epoch 6
2023-01-04 03:20:28,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:28,492 INFO:     Epoch: 7
2023-01-04 03:20:30,115 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48040168881416323, 'Total loss': 0.48040168881416323} | train loss {'Reaction outcome loss': 0.41551530157364364, 'Total loss': 0.41551530157364364}
2023-01-04 03:20:30,115 INFO:     Found new best model at epoch 7
2023-01-04 03:20:30,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:30,116 INFO:     Epoch: 8
2023-01-04 03:20:31,710 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47896074255307514, 'Total loss': 0.47896074255307514} | train loss {'Reaction outcome loss': 0.4031411226892817, 'Total loss': 0.4031411226892817}
2023-01-04 03:20:31,710 INFO:     Found new best model at epoch 8
2023-01-04 03:20:31,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:31,711 INFO:     Epoch: 9
2023-01-04 03:20:33,309 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4690296232700348, 'Total loss': 0.4690296232700348} | train loss {'Reaction outcome loss': 0.39201017666230165, 'Total loss': 0.39201017666230165}
2023-01-04 03:20:33,310 INFO:     Found new best model at epoch 9
2023-01-04 03:20:33,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:33,310 INFO:     Epoch: 10
2023-01-04 03:20:34,896 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47582516074180603, 'Total loss': 0.47582516074180603} | train loss {'Reaction outcome loss': 0.3822102716759495, 'Total loss': 0.3822102716759495}
2023-01-04 03:20:34,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:34,896 INFO:     Epoch: 11
2023-01-04 03:20:36,486 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46028715272744497, 'Total loss': 0.46028715272744497} | train loss {'Reaction outcome loss': 0.37433021797261207, 'Total loss': 0.37433021797261207}
2023-01-04 03:20:36,486 INFO:     Found new best model at epoch 11
2023-01-04 03:20:36,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:36,487 INFO:     Epoch: 12
2023-01-04 03:20:38,116 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4487545847892761, 'Total loss': 0.4487545847892761} | train loss {'Reaction outcome loss': 0.36753349290296866, 'Total loss': 0.36753349290296866}
2023-01-04 03:20:38,117 INFO:     Found new best model at epoch 12
2023-01-04 03:20:38,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:38,118 INFO:     Epoch: 13
2023-01-04 03:20:39,740 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4653961698214213, 'Total loss': 0.4653961698214213} | train loss {'Reaction outcome loss': 0.3582636569559142, 'Total loss': 0.3582636569559142}
2023-01-04 03:20:39,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:39,740 INFO:     Epoch: 14
2023-01-04 03:20:41,348 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44867751200993855, 'Total loss': 0.44867751200993855} | train loss {'Reaction outcome loss': 0.3510704654660346, 'Total loss': 0.3510704654660346}
2023-01-04 03:20:41,348 INFO:     Found new best model at epoch 14
2023-01-04 03:20:41,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:41,349 INFO:     Epoch: 15
2023-01-04 03:20:42,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46254725058873497, 'Total loss': 0.46254725058873497} | train loss {'Reaction outcome loss': 0.34656859930750006, 'Total loss': 0.34656859930750006}
2023-01-04 03:20:42,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:42,944 INFO:     Epoch: 16
2023-01-04 03:20:44,564 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44625074962774913, 'Total loss': 0.44625074962774913} | train loss {'Reaction outcome loss': 0.3376673411628977, 'Total loss': 0.3376673411628977}
2023-01-04 03:20:44,565 INFO:     Found new best model at epoch 16
2023-01-04 03:20:44,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:44,566 INFO:     Epoch: 17
2023-01-04 03:20:46,160 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4417234599590302, 'Total loss': 0.4417234599590302} | train loss {'Reaction outcome loss': 0.33526000861024513, 'Total loss': 0.33526000861024513}
2023-01-04 03:20:46,160 INFO:     Found new best model at epoch 17
2023-01-04 03:20:46,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:46,161 INFO:     Epoch: 18
2023-01-04 03:20:47,760 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4413390854994456, 'Total loss': 0.4413390854994456} | train loss {'Reaction outcome loss': 0.334078891472756, 'Total loss': 0.334078891472756}
2023-01-04 03:20:47,760 INFO:     Found new best model at epoch 18
2023-01-04 03:20:47,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:47,761 INFO:     Epoch: 19
2023-01-04 03:20:49,381 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44892343978087107, 'Total loss': 0.44892343978087107} | train loss {'Reaction outcome loss': 0.32035072361105593, 'Total loss': 0.32035072361105593}
2023-01-04 03:20:49,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:49,381 INFO:     Epoch: 20
2023-01-04 03:20:50,973 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4377290685971578, 'Total loss': 0.4377290685971578} | train loss {'Reaction outcome loss': 0.3147814104306525, 'Total loss': 0.3147814104306525}
2023-01-04 03:20:50,973 INFO:     Found new best model at epoch 20
2023-01-04 03:20:50,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:50,974 INFO:     Epoch: 21
2023-01-04 03:20:52,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44650110602378845, 'Total loss': 0.44650110602378845} | train loss {'Reaction outcome loss': 0.3101403536207542, 'Total loss': 0.3101403536207542}
2023-01-04 03:20:52,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:52,554 INFO:     Epoch: 22
2023-01-04 03:20:54,173 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4372371276219686, 'Total loss': 0.4372371276219686} | train loss {'Reaction outcome loss': 0.3071714712819759, 'Total loss': 0.3071714712819759}
2023-01-04 03:20:54,174 INFO:     Found new best model at epoch 22
2023-01-04 03:20:54,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:54,174 INFO:     Epoch: 23
2023-01-04 03:20:55,775 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45120055675506593, 'Total loss': 0.45120055675506593} | train loss {'Reaction outcome loss': 0.30135582812616357, 'Total loss': 0.30135582812616357}
2023-01-04 03:20:55,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:55,776 INFO:     Epoch: 24
2023-01-04 03:20:57,360 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4465328703324, 'Total loss': 0.4465328703324} | train loss {'Reaction outcome loss': 0.2969785181272343, 'Total loss': 0.2969785181272343}
2023-01-04 03:20:57,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:57,361 INFO:     Epoch: 25
2023-01-04 03:20:58,981 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4246331294377645, 'Total loss': 0.4246331294377645} | train loss {'Reaction outcome loss': 0.2923648394382748, 'Total loss': 0.2923648394382748}
2023-01-04 03:20:58,981 INFO:     Found new best model at epoch 25
2023-01-04 03:20:58,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:20:58,982 INFO:     Epoch: 26
2023-01-04 03:21:00,567 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4460058311621348, 'Total loss': 0.4460058311621348} | train loss {'Reaction outcome loss': 0.28789137115540064, 'Total loss': 0.28789137115540064}
2023-01-04 03:21:00,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:00,567 INFO:     Epoch: 27
2023-01-04 03:21:02,189 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.441283173362414, 'Total loss': 0.441283173362414} | train loss {'Reaction outcome loss': 0.28442016038773715, 'Total loss': 0.28442016038773715}
2023-01-04 03:21:02,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:02,189 INFO:     Epoch: 28
2023-01-04 03:21:03,785 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43267247279485066, 'Total loss': 0.43267247279485066} | train loss {'Reaction outcome loss': 0.2814135011454261, 'Total loss': 0.2814135011454261}
2023-01-04 03:21:03,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:03,785 INFO:     Epoch: 29
2023-01-04 03:21:05,400 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44293327927589415, 'Total loss': 0.44293327927589415} | train loss {'Reaction outcome loss': 0.2737334922750723, 'Total loss': 0.2737334922750723}
2023-01-04 03:21:05,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:05,400 INFO:     Epoch: 30
2023-01-04 03:21:07,014 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42869056661923727, 'Total loss': 0.42869056661923727} | train loss {'Reaction outcome loss': 0.2741440056242805, 'Total loss': 0.2741440056242805}
2023-01-04 03:21:07,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:07,014 INFO:     Epoch: 31
2023-01-04 03:21:08,634 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44121033946673077, 'Total loss': 0.44121033946673077} | train loss {'Reaction outcome loss': 0.26733013410694845, 'Total loss': 0.26733013410694845}
2023-01-04 03:21:08,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:08,635 INFO:     Epoch: 32
2023-01-04 03:21:10,235 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4375234733025233, 'Total loss': 0.4375234733025233} | train loss {'Reaction outcome loss': 0.2659156618747806, 'Total loss': 0.2659156618747806}
2023-01-04 03:21:10,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:10,236 INFO:     Epoch: 33
2023-01-04 03:21:11,854 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.452379310131073, 'Total loss': 0.452379310131073} | train loss {'Reaction outcome loss': 0.26204502090716403, 'Total loss': 0.26204502090716403}
2023-01-04 03:21:11,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:11,855 INFO:     Epoch: 34
2023-01-04 03:21:13,439 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4381503760814667, 'Total loss': 0.4381503760814667} | train loss {'Reaction outcome loss': 0.2573893715870445, 'Total loss': 0.2573893715870445}
2023-01-04 03:21:13,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:13,439 INFO:     Epoch: 35
2023-01-04 03:21:15,038 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4386238197485606, 'Total loss': 0.4386238197485606} | train loss {'Reaction outcome loss': 0.2564336191365104, 'Total loss': 0.2564336191365104}
2023-01-04 03:21:15,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:15,040 INFO:     Epoch: 36
2023-01-04 03:21:16,638 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42028993368148804, 'Total loss': 0.42028993368148804} | train loss {'Reaction outcome loss': 0.2546605248226906, 'Total loss': 0.2546605248226906}
2023-01-04 03:21:16,638 INFO:     Found new best model at epoch 36
2023-01-04 03:21:16,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:16,639 INFO:     Epoch: 37
2023-01-04 03:21:18,216 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4199256896972656, 'Total loss': 0.4199256896972656} | train loss {'Reaction outcome loss': 0.24753092110926367, 'Total loss': 0.24753092110926367}
2023-01-04 03:21:18,216 INFO:     Found new best model at epoch 37
2023-01-04 03:21:18,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:18,217 INFO:     Epoch: 38
2023-01-04 03:21:19,839 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43014934062957766, 'Total loss': 0.43014934062957766} | train loss {'Reaction outcome loss': 0.2451130566406536, 'Total loss': 0.2451130566406536}
2023-01-04 03:21:19,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:19,840 INFO:     Epoch: 39
2023-01-04 03:21:21,441 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44105413953463235, 'Total loss': 0.44105413953463235} | train loss {'Reaction outcome loss': 0.24554167187475748, 'Total loss': 0.24554167187475748}
2023-01-04 03:21:21,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:21,442 INFO:     Epoch: 40
2023-01-04 03:21:23,041 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4359327336152395, 'Total loss': 0.4359327336152395} | train loss {'Reaction outcome loss': 0.24275841127973105, 'Total loss': 0.24275841127973105}
2023-01-04 03:21:23,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:23,042 INFO:     Epoch: 41
2023-01-04 03:21:24,641 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42755323747793833, 'Total loss': 0.42755323747793833} | train loss {'Reaction outcome loss': 0.2457841577116346, 'Total loss': 0.2457841577116346}
2023-01-04 03:21:24,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:24,641 INFO:     Epoch: 42
2023-01-04 03:21:26,240 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44861118992169696, 'Total loss': 0.44861118992169696} | train loss {'Reaction outcome loss': 0.2420977156177379, 'Total loss': 0.2420977156177379}
2023-01-04 03:21:26,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:26,240 INFO:     Epoch: 43
2023-01-04 03:21:27,836 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43802182873090106, 'Total loss': 0.43802182873090106} | train loss {'Reaction outcome loss': 0.23411299659452145, 'Total loss': 0.23411299659452145}
2023-01-04 03:21:27,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:27,836 INFO:     Epoch: 44
2023-01-04 03:21:29,456 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43666378358999886, 'Total loss': 0.43666378358999886} | train loss {'Reaction outcome loss': 0.23888899392677823, 'Total loss': 0.23888899392677823}
2023-01-04 03:21:29,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:29,457 INFO:     Epoch: 45
2023-01-04 03:21:31,048 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.449002343416214, 'Total loss': 0.449002343416214} | train loss {'Reaction outcome loss': 0.23708857376587347, 'Total loss': 0.23708857376587347}
2023-01-04 03:21:31,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:31,048 INFO:     Epoch: 46
2023-01-04 03:21:32,668 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4263674899935722, 'Total loss': 0.4263674899935722} | train loss {'Reaction outcome loss': 0.22684675445307748, 'Total loss': 0.22684675445307748}
2023-01-04 03:21:32,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:32,668 INFO:     Epoch: 47
2023-01-04 03:21:34,286 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4466951698064804, 'Total loss': 0.4466951698064804} | train loss {'Reaction outcome loss': 0.22439985200796492, 'Total loss': 0.22439985200796492}
2023-01-04 03:21:34,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:34,286 INFO:     Epoch: 48
2023-01-04 03:21:35,855 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4253518352905909, 'Total loss': 0.4253518352905909} | train loss {'Reaction outcome loss': 0.23251927140222836, 'Total loss': 0.23251927140222836}
2023-01-04 03:21:35,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:35,855 INFO:     Epoch: 49
2023-01-04 03:21:37,455 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4312310367822647, 'Total loss': 0.4312310367822647} | train loss {'Reaction outcome loss': 0.23929413717132117, 'Total loss': 0.23929413717132117}
2023-01-04 03:21:37,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:37,455 INFO:     Epoch: 50
2023-01-04 03:21:39,077 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4417518804470698, 'Total loss': 0.4417518804470698} | train loss {'Reaction outcome loss': 0.23172203281327433, 'Total loss': 0.23172203281327433}
2023-01-04 03:21:39,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:39,077 INFO:     Epoch: 51
2023-01-04 03:21:40,663 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42686124046643575, 'Total loss': 0.42686124046643575} | train loss {'Reaction outcome loss': 0.22592070160359415, 'Total loss': 0.22592070160359415}
2023-01-04 03:21:40,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:40,663 INFO:     Epoch: 52
2023-01-04 03:21:42,284 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4332754025856654, 'Total loss': 0.4332754025856654} | train loss {'Reaction outcome loss': 0.2177000276312448, 'Total loss': 0.2177000276312448}
2023-01-04 03:21:42,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:42,284 INFO:     Epoch: 53
2023-01-04 03:21:43,902 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4323576629161835, 'Total loss': 0.4323576629161835} | train loss {'Reaction outcome loss': 0.21856207547682352, 'Total loss': 0.21856207547682352}
2023-01-04 03:21:43,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:43,902 INFO:     Epoch: 54
2023-01-04 03:21:45,498 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45356668879588447, 'Total loss': 0.45356668879588447} | train loss {'Reaction outcome loss': 0.2136927079392489, 'Total loss': 0.2136927079392489}
2023-01-04 03:21:45,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:45,498 INFO:     Epoch: 55
2023-01-04 03:21:47,114 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42522213657697044, 'Total loss': 0.42522213657697044} | train loss {'Reaction outcome loss': 0.22000293633428172, 'Total loss': 0.22000293633428172}
2023-01-04 03:21:47,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:47,115 INFO:     Epoch: 56
2023-01-04 03:21:48,719 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4280499001344045, 'Total loss': 0.4280499001344045} | train loss {'Reaction outcome loss': 0.2243014715757032, 'Total loss': 0.2243014715757032}
2023-01-04 03:21:48,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:48,720 INFO:     Epoch: 57
2023-01-04 03:21:50,332 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4171021560827891, 'Total loss': 0.4171021560827891} | train loss {'Reaction outcome loss': 0.2083044766475433, 'Total loss': 0.2083044766475433}
2023-01-04 03:21:50,333 INFO:     Found new best model at epoch 57
2023-01-04 03:21:50,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:50,334 INFO:     Epoch: 58
2023-01-04 03:21:51,946 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4427576829989751, 'Total loss': 0.4427576829989751} | train loss {'Reaction outcome loss': 0.20883576970284237, 'Total loss': 0.20883576970284237}
2023-01-04 03:21:51,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:51,947 INFO:     Epoch: 59
2023-01-04 03:21:53,553 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43554139137268066, 'Total loss': 0.43554139137268066} | train loss {'Reaction outcome loss': 0.20762472136782995, 'Total loss': 0.20762472136782995}
2023-01-04 03:21:53,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:53,553 INFO:     Epoch: 60
2023-01-04 03:21:55,151 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4512879381577174, 'Total loss': 0.4512879381577174} | train loss {'Reaction outcome loss': 0.2062093413306697, 'Total loss': 0.2062093413306697}
2023-01-04 03:21:55,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:55,152 INFO:     Epoch: 61
2023-01-04 03:21:56,773 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45358776251475014, 'Total loss': 0.45358776251475014} | train loss {'Reaction outcome loss': 0.20452280516695717, 'Total loss': 0.20452280516695717}
2023-01-04 03:21:56,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:56,774 INFO:     Epoch: 62
2023-01-04 03:21:58,380 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4458962460358938, 'Total loss': 0.4458962460358938} | train loss {'Reaction outcome loss': 0.2060191786924696, 'Total loss': 0.2060191786924696}
2023-01-04 03:21:58,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:58,380 INFO:     Epoch: 63
2023-01-04 03:21:59,997 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45153627594312035, 'Total loss': 0.45153627594312035} | train loss {'Reaction outcome loss': 0.20233673397484855, 'Total loss': 0.20233673397484855}
2023-01-04 03:21:59,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:21:59,998 INFO:     Epoch: 64
2023-01-04 03:22:01,628 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45768682261308036, 'Total loss': 0.45768682261308036} | train loss {'Reaction outcome loss': 0.19875327189641911, 'Total loss': 0.19875327189641911}
2023-01-04 03:22:01,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:01,628 INFO:     Epoch: 65
2023-01-04 03:22:03,230 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4512530694405238, 'Total loss': 0.4512530694405238} | train loss {'Reaction outcome loss': 0.19946484695580127, 'Total loss': 0.19946484695580127}
2023-01-04 03:22:03,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:03,231 INFO:     Epoch: 66
2023-01-04 03:22:04,822 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4648633897304535, 'Total loss': 0.4648633897304535} | train loss {'Reaction outcome loss': 0.20117889555336477, 'Total loss': 0.20117889555336477}
2023-01-04 03:22:04,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:04,822 INFO:     Epoch: 67
2023-01-04 03:22:06,414 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46966180503368377, 'Total loss': 0.46966180503368377} | train loss {'Reaction outcome loss': 0.19569968055947212, 'Total loss': 0.19569968055947212}
2023-01-04 03:22:06,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:06,414 INFO:     Epoch: 68
2023-01-04 03:22:08,017 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4423134535551071, 'Total loss': 0.4423134535551071} | train loss {'Reaction outcome loss': 0.19431399783386133, 'Total loss': 0.19431399783386133}
2023-01-04 03:22:08,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:08,017 INFO:     Epoch: 69
2023-01-04 03:22:09,621 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4451942006746928, 'Total loss': 0.4451942006746928} | train loss {'Reaction outcome loss': 0.19145407614406143, 'Total loss': 0.19145407614406143}
2023-01-04 03:22:09,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:09,622 INFO:     Epoch: 70
2023-01-04 03:22:11,227 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4655528128147125, 'Total loss': 0.4655528128147125} | train loss {'Reaction outcome loss': 0.19318428205788488, 'Total loss': 0.19318428205788488}
2023-01-04 03:22:11,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:11,228 INFO:     Epoch: 71
2023-01-04 03:22:12,813 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.467836199204127, 'Total loss': 0.467836199204127} | train loss {'Reaction outcome loss': 0.19135773283188176, 'Total loss': 0.19135773283188176}
2023-01-04 03:22:12,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:12,813 INFO:     Epoch: 72
2023-01-04 03:22:14,408 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44763718247413636, 'Total loss': 0.44763718247413636} | train loss {'Reaction outcome loss': 0.19160522303233543, 'Total loss': 0.19160522303233543}
2023-01-04 03:22:14,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:14,408 INFO:     Epoch: 73
2023-01-04 03:22:16,007 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4395729869604111, 'Total loss': 0.4395729869604111} | train loss {'Reaction outcome loss': 0.19364928103351448, 'Total loss': 0.19364928103351448}
2023-01-04 03:22:16,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:16,007 INFO:     Epoch: 74
2023-01-04 03:22:17,607 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4627700279156367, 'Total loss': 0.4627700279156367} | train loss {'Reaction outcome loss': 0.1873974662064912, 'Total loss': 0.1873974662064912}
2023-01-04 03:22:17,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:17,608 INFO:     Epoch: 75
2023-01-04 03:22:19,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47310913701852164, 'Total loss': 0.47310913701852164} | train loss {'Reaction outcome loss': 0.18700636603424084, 'Total loss': 0.18700636603424084}
2023-01-04 03:22:19,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:19,207 INFO:     Epoch: 76
2023-01-04 03:22:20,801 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43964088360468545, 'Total loss': 0.43964088360468545} | train loss {'Reaction outcome loss': 0.18831879546126837, 'Total loss': 0.18831879546126837}
2023-01-04 03:22:20,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:20,802 INFO:     Epoch: 77
2023-01-04 03:22:22,399 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44736303289731344, 'Total loss': 0.44736303289731344} | train loss {'Reaction outcome loss': 0.18549550222097963, 'Total loss': 0.18549550222097963}
2023-01-04 03:22:22,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:22,399 INFO:     Epoch: 78
2023-01-04 03:22:24,018 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4737387051184972, 'Total loss': 0.4737387051184972} | train loss {'Reaction outcome loss': 0.18624431720219445, 'Total loss': 0.18624431720219445}
2023-01-04 03:22:24,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:24,018 INFO:     Epoch: 79
2023-01-04 03:22:25,637 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4470361034075419, 'Total loss': 0.4470361034075419} | train loss {'Reaction outcome loss': 0.1929282808391229, 'Total loss': 0.1929282808391229}
2023-01-04 03:22:25,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:25,637 INFO:     Epoch: 80
2023-01-04 03:22:27,263 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46600400904814404, 'Total loss': 0.46600400904814404} | train loss {'Reaction outcome loss': 0.18235175352932909, 'Total loss': 0.18235175352932909}
2023-01-04 03:22:27,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:27,263 INFO:     Epoch: 81
2023-01-04 03:22:28,880 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46920700172583263, 'Total loss': 0.46920700172583263} | train loss {'Reaction outcome loss': 0.18158479213741593, 'Total loss': 0.18158479213741593}
2023-01-04 03:22:28,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:28,880 INFO:     Epoch: 82
2023-01-04 03:22:30,491 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46368368268013, 'Total loss': 0.46368368268013} | train loss {'Reaction outcome loss': 0.17937341352681752, 'Total loss': 0.17937341352681752}
2023-01-04 03:22:30,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:30,491 INFO:     Epoch: 83
2023-01-04 03:22:32,100 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4631552110115687, 'Total loss': 0.4631552110115687} | train loss {'Reaction outcome loss': 0.17965548282170304, 'Total loss': 0.17965548282170304}
2023-01-04 03:22:32,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:32,101 INFO:     Epoch: 84
2023-01-04 03:22:33,706 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4476217836141586, 'Total loss': 0.4476217836141586} | train loss {'Reaction outcome loss': 0.17663159859586047, 'Total loss': 0.17663159859586047}
2023-01-04 03:22:33,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:33,707 INFO:     Epoch: 85
2023-01-04 03:22:35,325 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47782231171925865, 'Total loss': 0.47782231171925865} | train loss {'Reaction outcome loss': 0.191781397011347, 'Total loss': 0.191781397011347}
2023-01-04 03:22:35,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:35,325 INFO:     Epoch: 86
2023-01-04 03:22:36,944 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.456647227704525, 'Total loss': 0.456647227704525} | train loss {'Reaction outcome loss': 0.19937494214357593, 'Total loss': 0.19937494214357593}
2023-01-04 03:22:36,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:36,944 INFO:     Epoch: 87
2023-01-04 03:22:38,563 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48531354864438375, 'Total loss': 0.48531354864438375} | train loss {'Reaction outcome loss': 0.17644221140717095, 'Total loss': 0.17644221140717095}
2023-01-04 03:22:38,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:38,563 INFO:     Epoch: 88
2023-01-04 03:22:40,142 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4615308968971173, 'Total loss': 0.4615308968971173} | train loss {'Reaction outcome loss': 0.17367977861557965, 'Total loss': 0.17367977861557965}
2023-01-04 03:22:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:40,142 INFO:     Epoch: 89
2023-01-04 03:22:41,767 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45806273619333904, 'Total loss': 0.45806273619333904} | train loss {'Reaction outcome loss': 0.17342347783151257, 'Total loss': 0.17342347783151257}
2023-01-04 03:22:41,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:41,767 INFO:     Epoch: 90
2023-01-04 03:22:43,377 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45656920162340003, 'Total loss': 0.45656920162340003} | train loss {'Reaction outcome loss': 0.17292651629237377, 'Total loss': 0.17292651629237377}
2023-01-04 03:22:43,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:43,377 INFO:     Epoch: 91
2023-01-04 03:22:44,981 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47658630708853406, 'Total loss': 0.47658630708853406} | train loss {'Reaction outcome loss': 0.17349454100527192, 'Total loss': 0.17349454100527192}
2023-01-04 03:22:44,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:44,981 INFO:     Epoch: 92
2023-01-04 03:22:46,597 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48146807253360746, 'Total loss': 0.48146807253360746} | train loss {'Reaction outcome loss': 0.17268757248445804, 'Total loss': 0.17268757248445804}
2023-01-04 03:22:46,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:46,597 INFO:     Epoch: 93
2023-01-04 03:22:48,194 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47204636633396146, 'Total loss': 0.47204636633396146} | train loss {'Reaction outcome loss': 0.17952248613194874, 'Total loss': 0.17952248613194874}
2023-01-04 03:22:48,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:48,194 INFO:     Epoch: 94
2023-01-04 03:22:49,802 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45368702014287315, 'Total loss': 0.45368702014287315} | train loss {'Reaction outcome loss': 0.17052015569820272, 'Total loss': 0.17052015569820272}
2023-01-04 03:22:49,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:49,802 INFO:     Epoch: 95
2023-01-04 03:22:51,416 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46788037319978076, 'Total loss': 0.46788037319978076} | train loss {'Reaction outcome loss': 0.1690645408616283, 'Total loss': 0.1690645408616283}
2023-01-04 03:22:51,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:51,417 INFO:     Epoch: 96
2023-01-04 03:22:53,022 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4995033929745356, 'Total loss': 0.4995033929745356} | train loss {'Reaction outcome loss': 0.1690157610755046, 'Total loss': 0.1690157610755046}
2023-01-04 03:22:53,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:53,022 INFO:     Epoch: 97
2023-01-04 03:22:54,664 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46293452978134153, 'Total loss': 0.46293452978134153} | train loss {'Reaction outcome loss': 0.17150818458184655, 'Total loss': 0.17150818458184655}
2023-01-04 03:22:54,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:54,664 INFO:     Epoch: 98
2023-01-04 03:22:56,300 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4599270870288213, 'Total loss': 0.4599270870288213} | train loss {'Reaction outcome loss': 0.17175048934386458, 'Total loss': 0.17175048934386458}
2023-01-04 03:22:56,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:22:56,301 INFO:     Epoch: 99
2023-01-04 03:22:57,891 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4807145635286967, 'Total loss': 0.4807145635286967} | train loss {'Reaction outcome loss': 0.16808942011621053, 'Total loss': 0.16808942011621053}
2023-01-04 03:22:57,892 INFO:     Best model found after epoch 58 of 100.
2023-01-04 03:22:57,892 INFO:   Done with stage: TRAINING
2023-01-04 03:22:57,892 INFO:   Starting stage: EVALUATION
2023-01-04 03:22:58,019 INFO:   Done with stage: EVALUATION
2023-01-04 03:22:58,019 INFO: Done with stage: RUNNING SPLITS
2023-01-04 03:22:58,019 INFO: Starting stage: COMPUTE METRICS
2023-01-04 03:22:59,180 INFO: Done with stage: COMPUTE METRICS
2023-01-04 03:22:59,180 INFO: Starting stage: EXPORT RESULTS
2023-01-04 03:22:59,197 INFO:   Final results averaged over 50 folds: 
2023-01-04 03:22:59,201 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.179222           NaN  0.313549       NaN
2023-01-04 03:23:00,825 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 03:23:00,830 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 03:23:00,831 DEBUG:   interactive is False
2023-01-04 03:23:00,831 DEBUG:   platform is linux
2023-01-04 03:23:00,832 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 03:23:01,002 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 03:23:01,004 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 03:23:01,437 DEBUG:   Loaded backend agg version unknown.
2023-01-04 03:23:01,439 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,439 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,440 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,441 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,442 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,442 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,442 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,442 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 03:23:01,478 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 03:23:01,478 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,478 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,478 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,478 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,481 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,481 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 03:23:01,489 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 03:23:01,489 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,490 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,491 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 03:23:01,492 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 03:23:01,492 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 03:23:01,814 INFO: Done with stage: EXPORT RESULTS
2023-01-04 03:23:01,814 INFO: Starting stage: SAVE MODEL
2023-01-04 03:23:01,875 INFO: Done with stage: SAVE MODEL
2023-01-04 03:23:01,875 INFO: Wall time for program:  8005.97 seconds
