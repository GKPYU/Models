2022-12-31 04:58:53,591 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/f537efcb4358b601001f3077efa89dd1/2022_12_31-024241",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 04:58:53,599 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 04:58:53,602 INFO:   Creating esm representation model
2022-12-31 04:58:53,602 INFO:   Done esm representation model
2022-12-31 04:58:53,602 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 04:58:53,602 INFO: Starting stage: BUILDING DATASET
2022-12-31 04:58:53,657 INFO: Done with stage: BUILDING DATASET
2022-12-31 04:58:53,657 INFO: Starting stage: FEATURIZING DATA
2022-12-31 04:58:53,657 INFO:   Featurizing proteins
2022-12-31 04:58:53,658 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 04:58:53,687 INFO:   Loaded feature cache of size 489
2022-12-31 04:58:53,688 INFO:   Starting to pool ESM Embeddings
2022-12-31 04:58:53,797 INFO:   Featurizing molecules
2022-12-31 04:58:53,799 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 04:58:53,801 INFO:   Loaded feature cache of size 498
2022-12-31 04:58:55,139 INFO: Done with stage: FEATURIZING DATA
2022-12-31 04:58:55,139 INFO: Starting stage: RUNNING SPLITS
2022-12-31 04:58:55,147 INFO:   Leaving out SEQ value Fold_0
2022-12-31 04:58:55,161 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 04:58:55,162 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:58:55,836 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:58:55,836 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:58:55,905 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:58:55,905 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:58:55,905 INFO:     No hyperparam tuning for this model
2022-12-31 04:58:55,905 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:58:55,905 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:58:55,906 INFO:     None feature selector for col prot
2022-12-31 04:58:55,906 INFO:     None feature selector for col prot
2022-12-31 04:58:55,906 INFO:     None feature selector for col prot
2022-12-31 04:58:55,907 INFO:     None feature selector for col chem
2022-12-31 04:58:55,907 INFO:     None feature selector for col chem
2022-12-31 04:58:55,907 INFO:     None feature selector for col chem
2022-12-31 04:58:55,907 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:58:55,907 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:58:55,909 INFO:     Number of params in model 224011
2022-12-31 04:58:55,909 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:58:55,909 INFO:   Starting stage: TRAINING
2022-12-31 04:58:57,532 INFO:     Val loss before train {'Reaction outcome loss': 1.0893299142519632, 'Total loss': 1.0893299142519632}
2022-12-31 04:58:57,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:57,533 INFO:     Epoch: 0
2022-12-31 04:58:59,183 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6098925669987997, 'Total loss': 0.6098925669987997} | train loss {'Reaction outcome loss': 0.7784797050904878, 'Total loss': 0.7784797050904878}
2022-12-31 04:58:59,183 INFO:     Found new best model at epoch 0
2022-12-31 04:58:59,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:59,184 INFO:     Epoch: 1
2022-12-31 04:59:00,814 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5203551093737284, 'Total loss': 0.5203551093737284} | train loss {'Reaction outcome loss': 0.514624243363356, 'Total loss': 0.514624243363356}
2022-12-31 04:59:00,814 INFO:     Found new best model at epoch 1
2022-12-31 04:59:00,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:00,815 INFO:     Epoch: 2
2022-12-31 04:59:02,413 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5247481028238933, 'Total loss': 0.5247481028238933} | train loss {'Reaction outcome loss': 0.4443755483616403, 'Total loss': 0.4443755483616403}
2022-12-31 04:59:02,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:02,414 INFO:     Epoch: 3
2022-12-31 04:59:04,060 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49097486237684884, 'Total loss': 0.49097486237684884} | train loss {'Reaction outcome loss': 0.40320667034977087, 'Total loss': 0.40320667034977087}
2022-12-31 04:59:04,060 INFO:     Found new best model at epoch 3
2022-12-31 04:59:04,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:04,062 INFO:     Epoch: 4
2022-12-31 04:59:05,666 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4703230579694112, 'Total loss': 0.4703230579694112} | train loss {'Reaction outcome loss': 0.3759504620245088, 'Total loss': 0.3759504620245088}
2022-12-31 04:59:05,667 INFO:     Found new best model at epoch 4
2022-12-31 04:59:05,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:05,668 INFO:     Epoch: 5
2022-12-31 04:59:07,301 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48024923404057823, 'Total loss': 0.48024923404057823} | train loss {'Reaction outcome loss': 0.3510285250487782, 'Total loss': 0.3510285250487782}
2022-12-31 04:59:07,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:07,301 INFO:     Epoch: 6
2022-12-31 04:59:08,902 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4783243109782537, 'Total loss': 0.4783243109782537} | train loss {'Reaction outcome loss': 0.329556327190373, 'Total loss': 0.329556327190373}
2022-12-31 04:59:08,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:08,902 INFO:     Epoch: 7
2022-12-31 04:59:10,523 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48448069592316945, 'Total loss': 0.48448069592316945} | train loss {'Reaction outcome loss': 0.3134822240133425, 'Total loss': 0.3134822240133425}
2022-12-31 04:59:10,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:10,523 INFO:     Epoch: 8
2022-12-31 04:59:12,130 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4763908386230469, 'Total loss': 0.4763908386230469} | train loss {'Reaction outcome loss': 0.2981935931240028, 'Total loss': 0.2981935931240028}
2022-12-31 04:59:12,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:12,130 INFO:     Epoch: 9
2022-12-31 04:59:13,739 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43737081562479335, 'Total loss': 0.43737081562479335} | train loss {'Reaction outcome loss': 0.2811008698337681, 'Total loss': 0.2811008698337681}
2022-12-31 04:59:13,740 INFO:     Found new best model at epoch 9
2022-12-31 04:59:13,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:13,741 INFO:     Epoch: 10
2022-12-31 04:59:15,341 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45236005385716754, 'Total loss': 0.45236005385716754} | train loss {'Reaction outcome loss': 0.26943247617928534, 'Total loss': 0.26943247617928534}
2022-12-31 04:59:15,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:15,341 INFO:     Epoch: 11
2022-12-31 04:59:16,950 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4705040951569875, 'Total loss': 0.4705040951569875} | train loss {'Reaction outcome loss': 0.25887474494102675, 'Total loss': 0.25887474494102675}
2022-12-31 04:59:16,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:16,951 INFO:     Epoch: 12
2022-12-31 04:59:18,560 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46374704738458, 'Total loss': 0.46374704738458} | train loss {'Reaction outcome loss': 0.24763744301930235, 'Total loss': 0.24763744301930235}
2022-12-31 04:59:18,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:18,560 INFO:     Epoch: 13
2022-12-31 04:59:20,160 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4604659080505371, 'Total loss': 0.4604659080505371} | train loss {'Reaction outcome loss': 0.24157154344486229, 'Total loss': 0.24157154344486229}
2022-12-31 04:59:20,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:20,160 INFO:     Epoch: 14
2022-12-31 04:59:21,768 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4753680209318797, 'Total loss': 0.4753680209318797} | train loss {'Reaction outcome loss': 0.23055361979555733, 'Total loss': 0.23055361979555733}
2022-12-31 04:59:21,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:21,768 INFO:     Epoch: 15
2022-12-31 04:59:23,365 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45601728558540344, 'Total loss': 0.45601728558540344} | train loss {'Reaction outcome loss': 0.22083935421301332, 'Total loss': 0.22083935421301332}
2022-12-31 04:59:23,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:23,366 INFO:     Epoch: 16
2022-12-31 04:59:25,013 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46744716465473174, 'Total loss': 0.46744716465473174} | train loss {'Reaction outcome loss': 0.21680610494572164, 'Total loss': 0.21680610494572164}
2022-12-31 04:59:25,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:25,013 INFO:     Epoch: 17
2022-12-31 04:59:26,662 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4519148031870524, 'Total loss': 0.4519148031870524} | train loss {'Reaction outcome loss': 0.20789113376057627, 'Total loss': 0.20789113376057627}
2022-12-31 04:59:26,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:26,662 INFO:     Epoch: 18
2022-12-31 04:59:28,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47249438936511673, 'Total loss': 0.47249438936511673} | train loss {'Reaction outcome loss': 0.20300723968121487, 'Total loss': 0.20300723968121487}
2022-12-31 04:59:28,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:28,299 INFO:     Epoch: 19
2022-12-31 04:59:29,902 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45812015160918235, 'Total loss': 0.45812015160918235} | train loss {'Reaction outcome loss': 0.19846738106656425, 'Total loss': 0.19846738106656425}
2022-12-31 04:59:29,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:29,903 INFO:     Epoch: 20
2022-12-31 04:59:31,519 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49058003226915997, 'Total loss': 0.49058003226915997} | train loss {'Reaction outcome loss': 0.19255211705771777, 'Total loss': 0.19255211705771777}
2022-12-31 04:59:31,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:31,520 INFO:     Epoch: 21
2022-12-31 04:59:33,141 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4682992845773697, 'Total loss': 0.4682992845773697} | train loss {'Reaction outcome loss': 0.1854498034083854, 'Total loss': 0.1854498034083854}
2022-12-31 04:59:33,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:33,141 INFO:     Epoch: 22
2022-12-31 04:59:34,749 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4882434984048208, 'Total loss': 0.4882434984048208} | train loss {'Reaction outcome loss': 0.18163927220108309, 'Total loss': 0.18163927220108309}
2022-12-31 04:59:34,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:34,750 INFO:     Epoch: 23
2022-12-31 04:59:36,359 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47360414614280066, 'Total loss': 0.47360414614280066} | train loss {'Reaction outcome loss': 0.17611893067552603, 'Total loss': 0.17611893067552603}
2022-12-31 04:59:36,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:36,360 INFO:     Epoch: 24
2022-12-31 04:59:37,962 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49480177760124205, 'Total loss': 0.49480177760124205} | train loss {'Reaction outcome loss': 0.17116697382304694, 'Total loss': 0.17116697382304694}
2022-12-31 04:59:37,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:37,962 INFO:     Epoch: 25
2022-12-31 04:59:39,572 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4683770020802816, 'Total loss': 0.4683770020802816} | train loss {'Reaction outcome loss': 0.1712282246026473, 'Total loss': 0.1712282246026473}
2022-12-31 04:59:39,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:39,572 INFO:     Epoch: 26
2022-12-31 04:59:41,188 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46466099683505796, 'Total loss': 0.46466099683505796} | train loss {'Reaction outcome loss': 0.1669994211506658, 'Total loss': 0.1669994211506658}
2022-12-31 04:59:41,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:41,189 INFO:     Epoch: 27
2022-12-31 04:59:42,814 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47500288039445876, 'Total loss': 0.47500288039445876} | train loss {'Reaction outcome loss': 0.1650453353839698, 'Total loss': 0.1650453353839698}
2022-12-31 04:59:42,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:42,814 INFO:     Epoch: 28
2022-12-31 04:59:44,426 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4657915413379669, 'Total loss': 0.4657915413379669} | train loss {'Reaction outcome loss': 0.16624021951805104, 'Total loss': 0.16624021951805104}
2022-12-31 04:59:44,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:44,426 INFO:     Epoch: 29
2022-12-31 04:59:46,039 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4818919837474823, 'Total loss': 0.4818919837474823} | train loss {'Reaction outcome loss': 0.16031729998646965, 'Total loss': 0.16031729998646965}
2022-12-31 04:59:46,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:46,040 INFO:     Epoch: 30
2022-12-31 04:59:47,644 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4634531199932098, 'Total loss': 0.4634531199932098} | train loss {'Reaction outcome loss': 0.16002278743250356, 'Total loss': 0.16002278743250356}
2022-12-31 04:59:47,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:47,644 INFO:     Epoch: 31
2022-12-31 04:59:49,257 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4801408588886261, 'Total loss': 0.4801408588886261} | train loss {'Reaction outcome loss': 0.15385207690762512, 'Total loss': 0.15385207690762512}
2022-12-31 04:59:49,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:49,257 INFO:     Epoch: 32
2022-12-31 04:59:50,890 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4595846518874168, 'Total loss': 0.4595846518874168} | train loss {'Reaction outcome loss': 0.15151337214878627, 'Total loss': 0.15151337214878627}
2022-12-31 04:59:50,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:50,891 INFO:     Epoch: 33
2022-12-31 04:59:52,538 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4792458186546961, 'Total loss': 0.4792458186546961} | train loss {'Reaction outcome loss': 0.1532058968471411, 'Total loss': 0.1532058968471411}
2022-12-31 04:59:52,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:52,538 INFO:     Epoch: 34
2022-12-31 04:59:54,184 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4854280928770701, 'Total loss': 0.4854280928770701} | train loss {'Reaction outcome loss': 0.1473088811864674, 'Total loss': 0.1473088811864674}
2022-12-31 04:59:54,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:54,184 INFO:     Epoch: 35
2022-12-31 04:59:55,777 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5106616924206416, 'Total loss': 0.5106616924206416} | train loss {'Reaction outcome loss': 0.14682444775879602, 'Total loss': 0.14682444775879602}
2022-12-31 04:59:55,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:55,778 INFO:     Epoch: 36
2022-12-31 04:59:57,423 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4689206105967363, 'Total loss': 0.4689206105967363} | train loss {'Reaction outcome loss': 0.14213834040808482, 'Total loss': 0.14213834040808482}
2022-12-31 04:59:57,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:57,424 INFO:     Epoch: 37
2022-12-31 04:59:59,070 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4838485876719157, 'Total loss': 0.4838485876719157} | train loss {'Reaction outcome loss': 0.14276842338514034, 'Total loss': 0.14276842338514034}
2022-12-31 04:59:59,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:59:59,070 INFO:     Epoch: 38
2022-12-31 05:00:00,686 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48480913440386453, 'Total loss': 0.48480913440386453} | train loss {'Reaction outcome loss': 0.13954567901223844, 'Total loss': 0.13954567901223844}
2022-12-31 05:00:00,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:00,686 INFO:     Epoch: 39
2022-12-31 05:00:02,334 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49099169770876566, 'Total loss': 0.49099169770876566} | train loss {'Reaction outcome loss': 0.1351693259013114, 'Total loss': 0.1351693259013114}
2022-12-31 05:00:02,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:02,334 INFO:     Epoch: 40
2022-12-31 05:00:03,980 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5341197431087494, 'Total loss': 0.5341197431087494} | train loss {'Reaction outcome loss': 0.13500045585973128, 'Total loss': 0.13500045585973128}
2022-12-31 05:00:03,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:03,981 INFO:     Epoch: 41
2022-12-31 05:00:05,574 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4851934889952342, 'Total loss': 0.4851934889952342} | train loss {'Reaction outcome loss': 0.1328248644380697, 'Total loss': 0.1328248644380697}
2022-12-31 05:00:05,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:05,574 INFO:     Epoch: 42
2022-12-31 05:00:07,222 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4941562374432882, 'Total loss': 0.4941562374432882} | train loss {'Reaction outcome loss': 0.1345727089690147, 'Total loss': 0.1345727089690147}
2022-12-31 05:00:07,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:07,222 INFO:     Epoch: 43
2022-12-31 05:00:08,869 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4788413713375727, 'Total loss': 0.4788413713375727} | train loss {'Reaction outcome loss': 0.1334721976532959, 'Total loss': 0.1334721976532959}
2022-12-31 05:00:08,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:08,869 INFO:     Epoch: 44
2022-12-31 05:00:10,507 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47295828262964884, 'Total loss': 0.47295828262964884} | train loss {'Reaction outcome loss': 0.1311807660812396, 'Total loss': 0.1311807660812396}
2022-12-31 05:00:10,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:10,507 INFO:     Epoch: 45
2022-12-31 05:00:12,103 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4629736500481764, 'Total loss': 0.4629736500481764} | train loss {'Reaction outcome loss': 0.1304890718106385, 'Total loss': 0.1304890718106385}
2022-12-31 05:00:12,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:12,103 INFO:     Epoch: 46
2022-12-31 05:00:13,750 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5072197051524806, 'Total loss': 0.5072197051524806} | train loss {'Reaction outcome loss': 0.12768963220846521, 'Total loss': 0.12768963220846521}
2022-12-31 05:00:13,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:13,750 INFO:     Epoch: 47
2022-12-31 05:00:15,357 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48412804504235585, 'Total loss': 0.48412804504235585} | train loss {'Reaction outcome loss': 0.13284538052771444, 'Total loss': 0.13284538052771444}
2022-12-31 05:00:15,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:15,357 INFO:     Epoch: 48
2022-12-31 05:00:16,967 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5555556376775106, 'Total loss': 0.5555556376775106} | train loss {'Reaction outcome loss': 0.12445797086710404, 'Total loss': 0.12445797086710404}
2022-12-31 05:00:16,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:16,967 INFO:     Epoch: 49
2022-12-31 05:00:18,574 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4959615876277288, 'Total loss': 0.4959615876277288} | train loss {'Reaction outcome loss': 0.12826620614763362, 'Total loss': 0.12826620614763362}
2022-12-31 05:00:18,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:18,574 INFO:     Epoch: 50
2022-12-31 05:00:20,192 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5001561204592387, 'Total loss': 0.5001561204592387} | train loss {'Reaction outcome loss': 0.13279138397657392, 'Total loss': 0.13279138397657392}
2022-12-31 05:00:20,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:20,192 INFO:     Epoch: 51
2022-12-31 05:00:21,809 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4807979037364324, 'Total loss': 0.4807979037364324} | train loss {'Reaction outcome loss': 0.12850549993797755, 'Total loss': 0.12850549993797755}
2022-12-31 05:00:21,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:21,810 INFO:     Epoch: 52
2022-12-31 05:00:23,416 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.488581379254659, 'Total loss': 0.488581379254659} | train loss {'Reaction outcome loss': 0.1196976918863617, 'Total loss': 0.1196976918863617}
2022-12-31 05:00:23,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:23,417 INFO:     Epoch: 53
2022-12-31 05:00:25,031 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4808054501811663, 'Total loss': 0.4808054501811663} | train loss {'Reaction outcome loss': 0.12121467873276699, 'Total loss': 0.12121467873276699}
2022-12-31 05:00:25,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:25,032 INFO:     Epoch: 54
2022-12-31 05:00:26,640 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4924495190382004, 'Total loss': 0.4924495190382004} | train loss {'Reaction outcome loss': 0.11601241694715543, 'Total loss': 0.11601241694715543}
2022-12-31 05:00:26,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:26,640 INFO:     Epoch: 55
2022-12-31 05:00:28,261 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5000121315320333, 'Total loss': 0.5000121315320333} | train loss {'Reaction outcome loss': 0.12293215673723883, 'Total loss': 0.12293215673723883}
2022-12-31 05:00:28,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:28,261 INFO:     Epoch: 56
2022-12-31 05:00:29,874 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4783513963222504, 'Total loss': 0.4783513963222504} | train loss {'Reaction outcome loss': 0.11858025607021846, 'Total loss': 0.11858025607021846}
2022-12-31 05:00:29,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:29,874 INFO:     Epoch: 57
2022-12-31 05:00:31,483 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5165091007947922, 'Total loss': 0.5165091007947922} | train loss {'Reaction outcome loss': 0.11721041991956184, 'Total loss': 0.11721041991956184}
2022-12-31 05:00:31,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:31,484 INFO:     Epoch: 58
2022-12-31 05:00:33,086 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49059749647664525, 'Total loss': 0.49059749647664525} | train loss {'Reaction outcome loss': 0.1211042212179074, 'Total loss': 0.1211042212179074}
2022-12-31 05:00:33,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:33,087 INFO:     Epoch: 59
2022-12-31 05:00:34,704 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4796326239903768, 'Total loss': 0.4796326239903768} | train loss {'Reaction outcome loss': 0.11634387888505564, 'Total loss': 0.11634387888505564}
2022-12-31 05:00:34,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:34,704 INFO:     Epoch: 60
2022-12-31 05:00:36,321 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5109719605185091, 'Total loss': 0.5109719605185091} | train loss {'Reaction outcome loss': 0.1181566702891073, 'Total loss': 0.1181566702891073}
2022-12-31 05:00:36,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:36,321 INFO:     Epoch: 61
2022-12-31 05:00:37,910 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5140438556671143, 'Total loss': 0.5140438556671143} | train loss {'Reaction outcome loss': 0.11570554929393115, 'Total loss': 0.11570554929393115}
2022-12-31 05:00:37,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:37,910 INFO:     Epoch: 62
2022-12-31 05:00:39,510 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49654032786687213, 'Total loss': 0.49654032786687213} | train loss {'Reaction outcome loss': 0.11579614248461066, 'Total loss': 0.11579614248461066}
2022-12-31 05:00:39,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:39,511 INFO:     Epoch: 63
2022-12-31 05:00:41,110 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5091959496339162, 'Total loss': 0.5091959496339162} | train loss {'Reaction outcome loss': 0.126125717025605, 'Total loss': 0.126125717025605}
2022-12-31 05:00:41,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:41,110 INFO:     Epoch: 64
2022-12-31 05:00:42,321 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46920877024531366, 'Total loss': 0.46920877024531366} | train loss {'Reaction outcome loss': 0.11383741367233051, 'Total loss': 0.11383741367233051}
2022-12-31 05:00:42,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:42,321 INFO:     Epoch: 65
2022-12-31 05:00:43,428 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49262046813964844, 'Total loss': 0.49262046813964844} | train loss {'Reaction outcome loss': 0.11057240604559444, 'Total loss': 0.11057240604559444}
2022-12-31 05:00:43,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:43,429 INFO:     Epoch: 66
2022-12-31 05:00:44,579 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46342124193906786, 'Total loss': 0.46342124193906786} | train loss {'Reaction outcome loss': 0.10847413290680928, 'Total loss': 0.10847413290680928}
2022-12-31 05:00:44,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:44,580 INFO:     Epoch: 67
2022-12-31 05:00:45,686 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4830815931161245, 'Total loss': 0.4830815931161245} | train loss {'Reaction outcome loss': 0.11278709691041747, 'Total loss': 0.11278709691041747}
2022-12-31 05:00:45,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:45,686 INFO:     Epoch: 68
2022-12-31 05:00:47,185 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5130536983410517, 'Total loss': 0.5130536983410517} | train loss {'Reaction outcome loss': 0.11411252132558942, 'Total loss': 0.11411252132558942}
2022-12-31 05:00:47,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:47,186 INFO:     Epoch: 69
2022-12-31 05:00:48,797 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4825953900814056, 'Total loss': 0.4825953900814056} | train loss {'Reaction outcome loss': 0.1095887768225601, 'Total loss': 0.1095887768225601}
2022-12-31 05:00:48,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:48,797 INFO:     Epoch: 70
2022-12-31 05:00:50,410 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48418744256099067, 'Total loss': 0.48418744256099067} | train loss {'Reaction outcome loss': 0.11015487041054874, 'Total loss': 0.11015487041054874}
2022-12-31 05:00:50,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:50,411 INFO:     Epoch: 71
2022-12-31 05:00:52,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5407720178365707, 'Total loss': 0.5407720178365707} | train loss {'Reaction outcome loss': 0.10631456036946221, 'Total loss': 0.10631456036946221}
2022-12-31 05:00:52,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:52,035 INFO:     Epoch: 72
2022-12-31 05:00:53,630 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5319568991661072, 'Total loss': 0.5319568991661072} | train loss {'Reaction outcome loss': 0.11077331727875513, 'Total loss': 0.11077331727875513}
2022-12-31 05:00:53,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:53,630 INFO:     Epoch: 73
2022-12-31 05:00:55,268 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5204376429319382, 'Total loss': 0.5204376429319382} | train loss {'Reaction outcome loss': 0.11099534229743857, 'Total loss': 0.11099534229743857}
2022-12-31 05:00:55,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:55,268 INFO:     Epoch: 74
2022-12-31 05:00:56,905 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48268088859816394, 'Total loss': 0.48268088859816394} | train loss {'Reaction outcome loss': 0.10949757404543542, 'Total loss': 0.10949757404543542}
2022-12-31 05:00:56,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:56,906 INFO:     Epoch: 75
2022-12-31 05:00:58,555 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5042767971754074, 'Total loss': 0.5042767971754074} | train loss {'Reaction outcome loss': 0.1096700811779959, 'Total loss': 0.1096700811779959}
2022-12-31 05:00:58,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:00:58,556 INFO:     Epoch: 76
2022-12-31 05:01:00,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.494437246521314, 'Total loss': 0.494437246521314} | train loss {'Reaction outcome loss': 0.11181264536816886, 'Total loss': 0.11181264536816886}
2022-12-31 05:01:00,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:00,178 INFO:     Epoch: 77
2022-12-31 05:01:01,784 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5091245491057634, 'Total loss': 0.5091245491057634} | train loss {'Reaction outcome loss': 0.10700587329673052, 'Total loss': 0.10700587329673052}
2022-12-31 05:01:01,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:01,784 INFO:     Epoch: 78
2022-12-31 05:01:03,372 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4955922777454058, 'Total loss': 0.4955922777454058} | train loss {'Reaction outcome loss': 0.10596696089444879, 'Total loss': 0.10596696089444879}
2022-12-31 05:01:03,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:03,373 INFO:     Epoch: 79
2022-12-31 05:01:04,975 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5074872612953186, 'Total loss': 0.5074872612953186} | train loss {'Reaction outcome loss': 0.10895871203017486, 'Total loss': 0.10895871203017486}
2022-12-31 05:01:04,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:04,975 INFO:     Epoch: 80
2022-12-31 05:01:06,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5018392741680145, 'Total loss': 0.5018392741680145} | train loss {'Reaction outcome loss': 0.1087349221620354, 'Total loss': 0.1087349221620354}
2022-12-31 05:01:06,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:06,621 INFO:     Epoch: 81
2022-12-31 05:01:08,268 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5285333514213562, 'Total loss': 0.5285333514213562} | train loss {'Reaction outcome loss': 0.11311320728032198, 'Total loss': 0.11311320728032198}
2022-12-31 05:01:08,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:08,268 INFO:     Epoch: 82
2022-12-31 05:01:09,895 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4941237159073353, 'Total loss': 0.4941237159073353} | train loss {'Reaction outcome loss': 0.10313934704711858, 'Total loss': 0.10313934704711858}
2022-12-31 05:01:09,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:09,895 INFO:     Epoch: 83
2022-12-31 05:01:11,522 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.515990764896075, 'Total loss': 0.515990764896075} | train loss {'Reaction outcome loss': 0.10541521160157172, 'Total loss': 0.10541521160157172}
2022-12-31 05:01:11,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:11,522 INFO:     Epoch: 84
2022-12-31 05:01:13,168 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5136300722757975, 'Total loss': 0.5136300722757975} | train loss {'Reaction outcome loss': 0.10477131840622823, 'Total loss': 0.10477131840622823}
2022-12-31 05:01:13,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:13,169 INFO:     Epoch: 85
2022-12-31 05:01:14,774 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5369218587875366, 'Total loss': 0.5369218587875366} | train loss {'Reaction outcome loss': 0.1017713060000427, 'Total loss': 0.1017713060000427}
2022-12-31 05:01:14,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:14,775 INFO:     Epoch: 86
2022-12-31 05:01:16,378 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5139054139455159, 'Total loss': 0.5139054139455159} | train loss {'Reaction outcome loss': 0.10489458147258986, 'Total loss': 0.10489458147258986}
2022-12-31 05:01:16,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:16,378 INFO:     Epoch: 87
2022-12-31 05:01:18,015 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5776398301124572, 'Total loss': 0.5776398301124572} | train loss {'Reaction outcome loss': 0.10776728622686978, 'Total loss': 0.10776728622686978}
2022-12-31 05:01:18,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:18,016 INFO:     Epoch: 88
2022-12-31 05:01:19,626 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5038516650597255, 'Total loss': 0.5038516650597255} | train loss {'Reaction outcome loss': 0.10677811495564032, 'Total loss': 0.10677811495564032}
2022-12-31 05:01:19,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:19,626 INFO:     Epoch: 89
2022-12-31 05:01:21,253 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4970351179440816, 'Total loss': 0.4970351179440816} | train loss {'Reaction outcome loss': 0.09963969610061756, 'Total loss': 0.09963969610061756}
2022-12-31 05:01:21,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:21,254 INFO:     Epoch: 90
2022-12-31 05:01:22,840 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5226060837507248, 'Total loss': 0.5226060837507248} | train loss {'Reaction outcome loss': 0.09825404815848289, 'Total loss': 0.09825404815848289}
2022-12-31 05:01:22,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:22,840 INFO:     Epoch: 91
2022-12-31 05:01:24,460 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5034908389051755, 'Total loss': 0.5034908389051755} | train loss {'Reaction outcome loss': 0.10562538403349045, 'Total loss': 0.10562538403349045}
2022-12-31 05:01:24,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:24,460 INFO:     Epoch: 92
2022-12-31 05:01:26,095 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5111757347981135, 'Total loss': 0.5111757347981135} | train loss {'Reaction outcome loss': 0.10319466691382312, 'Total loss': 0.10319466691382312}
2022-12-31 05:01:26,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:26,095 INFO:     Epoch: 93
2022-12-31 05:01:27,712 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5167526592810948, 'Total loss': 0.5167526592810948} | train loss {'Reaction outcome loss': 0.10079568679122111, 'Total loss': 0.10079568679122111}
2022-12-31 05:01:27,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:27,713 INFO:     Epoch: 94
2022-12-31 05:01:29,322 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4927806688162188, 'Total loss': 0.4927806688162188} | train loss {'Reaction outcome loss': 0.10913960174947376, 'Total loss': 0.10913960174947376}
2022-12-31 05:01:29,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:29,322 INFO:     Epoch: 95
2022-12-31 05:01:30,917 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5134617507457733, 'Total loss': 0.5134617507457733} | train loss {'Reaction outcome loss': 0.10565227708496126, 'Total loss': 0.10565227708496126}
2022-12-31 05:01:30,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:30,917 INFO:     Epoch: 96
2022-12-31 05:01:32,530 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5186842381954193, 'Total loss': 0.5186842381954193} | train loss {'Reaction outcome loss': 0.10239848436023562, 'Total loss': 0.10239848436023562}
2022-12-31 05:01:32,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:32,531 INFO:     Epoch: 97
2022-12-31 05:01:34,177 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.519677193959554, 'Total loss': 0.519677193959554} | train loss {'Reaction outcome loss': 0.10264477145264518, 'Total loss': 0.10264477145264518}
2022-12-31 05:01:34,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:34,178 INFO:     Epoch: 98
2022-12-31 05:01:35,774 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.510278179248174, 'Total loss': 0.510278179248174} | train loss {'Reaction outcome loss': 0.10016909784265544, 'Total loss': 0.10016909784265544}
2022-12-31 05:01:35,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:35,774 INFO:     Epoch: 99
2022-12-31 05:01:37,375 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5061717410882314, 'Total loss': 0.5061717410882314} | train loss {'Reaction outcome loss': 0.0964111048828865, 'Total loss': 0.0964111048828865}
2022-12-31 05:01:37,375 INFO:     Best model found after epoch 10 of 100.
2022-12-31 05:01:37,375 INFO:   Done with stage: TRAINING
2022-12-31 05:01:37,375 INFO:   Starting stage: EVALUATION
2022-12-31 05:01:37,517 INFO:   Done with stage: EVALUATION
2022-12-31 05:01:37,517 INFO:   Leaving out SEQ value Fold_1
2022-12-31 05:01:37,530 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:01:37,530 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:01:38,183 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:01:38,183 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:01:38,254 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:01:38,254 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:01:38,254 INFO:     No hyperparam tuning for this model
2022-12-31 05:01:38,254 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:01:38,254 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:01:38,255 INFO:     None feature selector for col prot
2022-12-31 05:01:38,255 INFO:     None feature selector for col prot
2022-12-31 05:01:38,255 INFO:     None feature selector for col prot
2022-12-31 05:01:38,256 INFO:     None feature selector for col chem
2022-12-31 05:01:38,256 INFO:     None feature selector for col chem
2022-12-31 05:01:38,256 INFO:     None feature selector for col chem
2022-12-31 05:01:38,256 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:01:38,256 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:01:38,258 INFO:     Number of params in model 224011
2022-12-31 05:01:38,261 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:01:38,261 INFO:   Starting stage: TRAINING
2022-12-31 05:01:38,305 INFO:     Val loss before train {'Reaction outcome loss': 1.1442989468574525, 'Total loss': 1.1442989468574525}
2022-12-31 05:01:38,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:38,305 INFO:     Epoch: 0
2022-12-31 05:01:39,974 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5971399704615276, 'Total loss': 0.5971399704615276} | train loss {'Reaction outcome loss': 0.799077219127313, 'Total loss': 0.799077219127313}
2022-12-31 05:01:39,974 INFO:     Found new best model at epoch 0
2022-12-31 05:01:39,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:39,975 INFO:     Epoch: 1
2022-12-31 05:01:41,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5278855105241139, 'Total loss': 0.5278855105241139} | train loss {'Reaction outcome loss': 0.5101608939888969, 'Total loss': 0.5101608939888969}
2022-12-31 05:01:41,590 INFO:     Found new best model at epoch 1
2022-12-31 05:01:41,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:41,591 INFO:     Epoch: 2
2022-12-31 05:01:43,204 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4966161956389745, 'Total loss': 0.4966161956389745} | train loss {'Reaction outcome loss': 0.44378182880472444, 'Total loss': 0.44378182880472444}
2022-12-31 05:01:43,204 INFO:     Found new best model at epoch 2
2022-12-31 05:01:43,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:43,205 INFO:     Epoch: 3
2022-12-31 05:01:44,815 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4849315782388051, 'Total loss': 0.4849315782388051} | train loss {'Reaction outcome loss': 0.40410365634889056, 'Total loss': 0.40410365634889056}
2022-12-31 05:01:44,815 INFO:     Found new best model at epoch 3
2022-12-31 05:01:44,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:44,816 INFO:     Epoch: 4
2022-12-31 05:01:46,427 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4610762844483058, 'Total loss': 0.4610762844483058} | train loss {'Reaction outcome loss': 0.3886944760662922, 'Total loss': 0.3886944760662922}
2022-12-31 05:01:46,428 INFO:     Found new best model at epoch 4
2022-12-31 05:01:46,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:46,429 INFO:     Epoch: 5
2022-12-31 05:01:48,048 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4878335416316986, 'Total loss': 0.4878335416316986} | train loss {'Reaction outcome loss': 0.36843610029862484, 'Total loss': 0.36843610029862484}
2022-12-31 05:01:48,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:48,048 INFO:     Epoch: 6
2022-12-31 05:01:49,661 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4688578446706136, 'Total loss': 0.4688578446706136} | train loss {'Reaction outcome loss': 0.3364450635854155, 'Total loss': 0.3364450635854155}
2022-12-31 05:01:49,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:49,661 INFO:     Epoch: 7
2022-12-31 05:01:51,288 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4877345860004425, 'Total loss': 0.4877345860004425} | train loss {'Reaction outcome loss': 0.3217303203439887, 'Total loss': 0.3217303203439887}
2022-12-31 05:01:51,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:51,288 INFO:     Epoch: 8
2022-12-31 05:01:52,921 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4535452922185262, 'Total loss': 0.4535452922185262} | train loss {'Reaction outcome loss': 0.31084360729099886, 'Total loss': 0.31084360729099886}
2022-12-31 05:01:52,922 INFO:     Found new best model at epoch 8
2022-12-31 05:01:52,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:52,923 INFO:     Epoch: 9
2022-12-31 05:01:54,556 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44215932389100393, 'Total loss': 0.44215932389100393} | train loss {'Reaction outcome loss': 0.2930996785179941, 'Total loss': 0.2930996785179941}
2022-12-31 05:01:54,556 INFO:     Found new best model at epoch 9
2022-12-31 05:01:54,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:54,557 INFO:     Epoch: 10
2022-12-31 05:01:56,187 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5130271822214126, 'Total loss': 0.5130271822214126} | train loss {'Reaction outcome loss': 0.2854874011576665, 'Total loss': 0.2854874011576665}
2022-12-31 05:01:56,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:56,187 INFO:     Epoch: 11
2022-12-31 05:01:57,844 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4609330813090006, 'Total loss': 0.4609330813090006} | train loss {'Reaction outcome loss': 0.27306777738208504, 'Total loss': 0.27306777738208504}
2022-12-31 05:01:57,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:57,844 INFO:     Epoch: 12
2022-12-31 05:01:59,493 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4487388948599497, 'Total loss': 0.4487388948599497} | train loss {'Reaction outcome loss': 0.2643257122752244, 'Total loss': 0.2643257122752244}
2022-12-31 05:01:59,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:01:59,493 INFO:     Epoch: 13
2022-12-31 05:02:01,138 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45662933091322583, 'Total loss': 0.45662933091322583} | train loss {'Reaction outcome loss': 0.25857821117033775, 'Total loss': 0.25857821117033775}
2022-12-31 05:02:01,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:01,138 INFO:     Epoch: 14
2022-12-31 05:02:02,794 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45339059333006543, 'Total loss': 0.45339059333006543} | train loss {'Reaction outcome loss': 0.257069014782167, 'Total loss': 0.257069014782167}
2022-12-31 05:02:02,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:02,794 INFO:     Epoch: 15
2022-12-31 05:02:04,458 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4793073097864787, 'Total loss': 0.4793073097864787} | train loss {'Reaction outcome loss': 0.2481729125824843, 'Total loss': 0.2481729125824843}
2022-12-31 05:02:04,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:04,458 INFO:     Epoch: 16
2022-12-31 05:02:06,070 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45107536017894745, 'Total loss': 0.45107536017894745} | train loss {'Reaction outcome loss': 0.2328727981657721, 'Total loss': 0.2328727981657721}
2022-12-31 05:02:06,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:06,071 INFO:     Epoch: 17
2022-12-31 05:02:07,719 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4681577205657959, 'Total loss': 0.4681577205657959} | train loss {'Reaction outcome loss': 0.22850473076645014, 'Total loss': 0.22850473076645014}
2022-12-31 05:02:07,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:07,719 INFO:     Epoch: 18
2022-12-31 05:02:09,370 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44449869990348817, 'Total loss': 0.44449869990348817} | train loss {'Reaction outcome loss': 0.2222100728582861, 'Total loss': 0.2222100728582861}
2022-12-31 05:02:09,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:09,371 INFO:     Epoch: 19
2022-12-31 05:02:11,035 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4635713338851929, 'Total loss': 0.4635713338851929} | train loss {'Reaction outcome loss': 0.21794240072072632, 'Total loss': 0.21794240072072632}
2022-12-31 05:02:11,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:11,035 INFO:     Epoch: 20
2022-12-31 05:02:12,698 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4597143073876699, 'Total loss': 0.4597143073876699} | train loss {'Reaction outcome loss': 0.20831164882348158, 'Total loss': 0.20831164882348158}
2022-12-31 05:02:12,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:12,699 INFO:     Epoch: 21
2022-12-31 05:02:14,362 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45151351193586986, 'Total loss': 0.45151351193586986} | train loss {'Reaction outcome loss': 0.2094520883562138, 'Total loss': 0.2094520883562138}
2022-12-31 05:02:14,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:14,363 INFO:     Epoch: 22
2022-12-31 05:02:15,992 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4797613461812337, 'Total loss': 0.4797613461812337} | train loss {'Reaction outcome loss': 0.20056611167914842, 'Total loss': 0.20056611167914842}
2022-12-31 05:02:15,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:15,993 INFO:     Epoch: 23
2022-12-31 05:02:17,621 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4281309480468432, 'Total loss': 0.4281309480468432} | train loss {'Reaction outcome loss': 0.19678818183087243, 'Total loss': 0.19678818183087243}
2022-12-31 05:02:17,621 INFO:     Found new best model at epoch 23
2022-12-31 05:02:17,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:17,622 INFO:     Epoch: 24
2022-12-31 05:02:19,237 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45086338321367897, 'Total loss': 0.45086338321367897} | train loss {'Reaction outcome loss': 0.19409026522729275, 'Total loss': 0.19409026522729275}
2022-12-31 05:02:19,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:19,237 INFO:     Epoch: 25
2022-12-31 05:02:20,889 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43401920795440674, 'Total loss': 0.43401920795440674} | train loss {'Reaction outcome loss': 0.19393966710734842, 'Total loss': 0.19393966710734842}
2022-12-31 05:02:20,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:20,890 INFO:     Epoch: 26
2022-12-31 05:02:22,505 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44363629519939424, 'Total loss': 0.44363629519939424} | train loss {'Reaction outcome loss': 0.18193220952387992, 'Total loss': 0.18193220952387992}
2022-12-31 05:02:22,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:22,506 INFO:     Epoch: 27
2022-12-31 05:02:24,149 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4501658856868744, 'Total loss': 0.4501658856868744} | train loss {'Reaction outcome loss': 0.18126622438633247, 'Total loss': 0.18126622438633247}
2022-12-31 05:02:24,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:24,149 INFO:     Epoch: 28
2022-12-31 05:02:25,780 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4521739443143209, 'Total loss': 0.4521739443143209} | train loss {'Reaction outcome loss': 0.17765366742421157, 'Total loss': 0.17765366742421157}
2022-12-31 05:02:25,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:25,781 INFO:     Epoch: 29
2022-12-31 05:02:27,420 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4841078042984009, 'Total loss': 0.4841078042984009} | train loss {'Reaction outcome loss': 0.17527290302720192, 'Total loss': 0.17527290302720192}
2022-12-31 05:02:27,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:27,421 INFO:     Epoch: 30
2022-12-31 05:02:29,037 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42313816646734875, 'Total loss': 0.42313816646734875} | train loss {'Reaction outcome loss': 0.17090480256592855, 'Total loss': 0.17090480256592855}
2022-12-31 05:02:29,037 INFO:     Found new best model at epoch 30
2022-12-31 05:02:29,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:29,038 INFO:     Epoch: 31
2022-12-31 05:02:30,653 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46220419406890867, 'Total loss': 0.46220419406890867} | train loss {'Reaction outcome loss': 0.16920381489857708, 'Total loss': 0.16920381489857708}
2022-12-31 05:02:30,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:30,653 INFO:     Epoch: 32
2022-12-31 05:02:32,270 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4437785466512044, 'Total loss': 0.4437785466512044} | train loss {'Reaction outcome loss': 0.1785178393483216, 'Total loss': 0.1785178393483216}
2022-12-31 05:02:32,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:32,271 INFO:     Epoch: 33
2022-12-31 05:02:33,913 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4445838669935862, 'Total loss': 0.4445838669935862} | train loss {'Reaction outcome loss': 0.16623042408542277, 'Total loss': 0.16623042408542277}
2022-12-31 05:02:33,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:33,913 INFO:     Epoch: 34
2022-12-31 05:02:35,530 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4617407073577245, 'Total loss': 0.4617407073577245} | train loss {'Reaction outcome loss': 0.16143819095526377, 'Total loss': 0.16143819095526377}
2022-12-31 05:02:35,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:35,530 INFO:     Epoch: 35
2022-12-31 05:02:37,191 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4722869704167048, 'Total loss': 0.4722869704167048} | train loss {'Reaction outcome loss': 0.1609515584397899, 'Total loss': 0.1609515584397899}
2022-12-31 05:02:37,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:37,191 INFO:     Epoch: 36
2022-12-31 05:02:38,855 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4705602000157038, 'Total loss': 0.4705602000157038} | train loss {'Reaction outcome loss': 0.16022018250914963, 'Total loss': 0.16022018250914963}
2022-12-31 05:02:38,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:38,856 INFO:     Epoch: 37
2022-12-31 05:02:40,521 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4605703433354696, 'Total loss': 0.4605703433354696} | train loss {'Reaction outcome loss': 0.1586097295436522, 'Total loss': 0.1586097295436522}
2022-12-31 05:02:40,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:40,522 INFO:     Epoch: 38
2022-12-31 05:02:42,139 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44888707598050437, 'Total loss': 0.44888707598050437} | train loss {'Reaction outcome loss': 0.15666089944568448, 'Total loss': 0.15666089944568448}
2022-12-31 05:02:42,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:42,139 INFO:     Epoch: 39
2022-12-31 05:02:43,750 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48757173915704094, 'Total loss': 0.48757173915704094} | train loss {'Reaction outcome loss': 0.1531474956731393, 'Total loss': 0.1531474956731393}
2022-12-31 05:02:43,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:43,751 INFO:     Epoch: 40
2022-12-31 05:02:45,367 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42628445823987327, 'Total loss': 0.42628445823987327} | train loss {'Reaction outcome loss': 0.1523820056286438, 'Total loss': 0.1523820056286438}
2022-12-31 05:02:45,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:45,367 INFO:     Epoch: 41
2022-12-31 05:02:47,034 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46811262567838036, 'Total loss': 0.46811262567838036} | train loss {'Reaction outcome loss': 0.15093434097555777, 'Total loss': 0.15093434097555777}
2022-12-31 05:02:47,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:47,034 INFO:     Epoch: 42
2022-12-31 05:02:48,646 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45774910350640613, 'Total loss': 0.45774910350640613} | train loss {'Reaction outcome loss': 0.15091958771971395, 'Total loss': 0.15091958771971395}
2022-12-31 05:02:48,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:48,646 INFO:     Epoch: 43
2022-12-31 05:02:50,260 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4606519967317581, 'Total loss': 0.4606519967317581} | train loss {'Reaction outcome loss': 0.15136811756900093, 'Total loss': 0.15136811756900093}
2022-12-31 05:02:50,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:50,261 INFO:     Epoch: 44
2022-12-31 05:02:51,899 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4562142411867777, 'Total loss': 0.4562142411867777} | train loss {'Reaction outcome loss': 0.14912824092122415, 'Total loss': 0.14912824092122415}
2022-12-31 05:02:51,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:51,899 INFO:     Epoch: 45
2022-12-31 05:02:53,525 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4618733823299408, 'Total loss': 0.4618733823299408} | train loss {'Reaction outcome loss': 0.1476327607001556, 'Total loss': 0.1476327607001556}
2022-12-31 05:02:53,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:53,525 INFO:     Epoch: 46
2022-12-31 05:02:55,142 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4208494971195857, 'Total loss': 0.4208494971195857} | train loss {'Reaction outcome loss': 0.14384296699595786, 'Total loss': 0.14384296699595786}
2022-12-31 05:02:55,143 INFO:     Found new best model at epoch 46
2022-12-31 05:02:55,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:55,144 INFO:     Epoch: 47
2022-12-31 05:02:56,767 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4323016385237376, 'Total loss': 0.4323016385237376} | train loss {'Reaction outcome loss': 0.1439542003353236, 'Total loss': 0.1439542003353236}
2022-12-31 05:02:56,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:56,768 INFO:     Epoch: 48
2022-12-31 05:02:58,390 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46948130130767823, 'Total loss': 0.46948130130767823} | train loss {'Reaction outcome loss': 0.14134034504810267, 'Total loss': 0.14134034504810267}
2022-12-31 05:02:58,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:02:58,391 INFO:     Epoch: 49
2022-12-31 05:03:00,016 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45180456240971884, 'Total loss': 0.45180456240971884} | train loss {'Reaction outcome loss': 0.14148994038333657, 'Total loss': 0.14148994038333657}
2022-12-31 05:03:00,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:00,016 INFO:     Epoch: 50
2022-12-31 05:03:01,626 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44117471277713777, 'Total loss': 0.44117471277713777} | train loss {'Reaction outcome loss': 0.14166398032608887, 'Total loss': 0.14166398032608887}
2022-12-31 05:03:01,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:01,626 INFO:     Epoch: 51
2022-12-31 05:03:03,269 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4491793428858121, 'Total loss': 0.4491793428858121} | train loss {'Reaction outcome loss': 0.14042370247762595, 'Total loss': 0.14042370247762595}
2022-12-31 05:03:03,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:03,270 INFO:     Epoch: 52
2022-12-31 05:03:04,896 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47005368967851, 'Total loss': 0.47005368967851} | train loss {'Reaction outcome loss': 0.13629007266464885, 'Total loss': 0.13629007266464885}
2022-12-31 05:03:04,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:04,897 INFO:     Epoch: 53
2022-12-31 05:03:06,521 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46453990787267685, 'Total loss': 0.46453990787267685} | train loss {'Reaction outcome loss': 0.139659706979359, 'Total loss': 0.139659706979359}
2022-12-31 05:03:06,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:06,522 INFO:     Epoch: 54
2022-12-31 05:03:08,148 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5019469817479452, 'Total loss': 0.5019469817479452} | train loss {'Reaction outcome loss': 0.13637727332884358, 'Total loss': 0.13637727332884358}
2022-12-31 05:03:08,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:08,148 INFO:     Epoch: 55
2022-12-31 05:03:09,765 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4622593899567922, 'Total loss': 0.4622593899567922} | train loss {'Reaction outcome loss': 0.13470359598231615, 'Total loss': 0.13470359598231615}
2022-12-31 05:03:09,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:09,765 INFO:     Epoch: 56
2022-12-31 05:03:11,392 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48907032708326975, 'Total loss': 0.48907032708326975} | train loss {'Reaction outcome loss': 0.1395491594273641, 'Total loss': 0.1395491594273641}
2022-12-31 05:03:11,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:11,392 INFO:     Epoch: 57
2022-12-31 05:03:13,033 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48503339489301045, 'Total loss': 0.48503339489301045} | train loss {'Reaction outcome loss': 0.13712300403057126, 'Total loss': 0.13712300403057126}
2022-12-31 05:03:13,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:13,033 INFO:     Epoch: 58
2022-12-31 05:03:14,697 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4633503536383311, 'Total loss': 0.4633503536383311} | train loss {'Reaction outcome loss': 0.13371874201979866, 'Total loss': 0.13371874201979866}
2022-12-31 05:03:14,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:14,698 INFO:     Epoch: 59
2022-12-31 05:03:16,361 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44997760181625684, 'Total loss': 0.44997760181625684} | train loss {'Reaction outcome loss': 0.12892565368383657, 'Total loss': 0.12892565368383657}
2022-12-31 05:03:16,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:16,362 INFO:     Epoch: 60
2022-12-31 05:03:17,976 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47581272224585214, 'Total loss': 0.47581272224585214} | train loss {'Reaction outcome loss': 0.13277577204575788, 'Total loss': 0.13277577204575788}
2022-12-31 05:03:17,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:17,976 INFO:     Epoch: 61
2022-12-31 05:03:19,598 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47044010361035665, 'Total loss': 0.47044010361035665} | train loss {'Reaction outcome loss': 0.12903324846875097, 'Total loss': 0.12903324846875097}
2022-12-31 05:03:19,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:19,598 INFO:     Epoch: 62
2022-12-31 05:03:21,252 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45473952492078146, 'Total loss': 0.45473952492078146} | train loss {'Reaction outcome loss': 0.13060651088565373, 'Total loss': 0.13060651088565373}
2022-12-31 05:03:21,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:21,252 INFO:     Epoch: 63
2022-12-31 05:03:22,916 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43994856973489127, 'Total loss': 0.43994856973489127} | train loss {'Reaction outcome loss': 0.12602543240021644, 'Total loss': 0.12602543240021644}
2022-12-31 05:03:22,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:22,916 INFO:     Epoch: 64
2022-12-31 05:03:24,539 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4874107917149862, 'Total loss': 0.4874107917149862} | train loss {'Reaction outcome loss': 0.1316478166845627, 'Total loss': 0.1316478166845627}
2022-12-31 05:03:24,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:24,540 INFO:     Epoch: 65
2022-12-31 05:03:26,203 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44376905461152394, 'Total loss': 0.44376905461152394} | train loss {'Reaction outcome loss': 0.13045776742206805, 'Total loss': 0.13045776742206805}
2022-12-31 05:03:26,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:26,203 INFO:     Epoch: 66
2022-12-31 05:03:27,853 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44876868054270747, 'Total loss': 0.44876868054270747} | train loss {'Reaction outcome loss': 0.12744655242641928, 'Total loss': 0.12744655242641928}
2022-12-31 05:03:27,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:27,853 INFO:     Epoch: 67
2022-12-31 05:03:29,466 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4968967696030935, 'Total loss': 0.4968967696030935} | train loss {'Reaction outcome loss': 0.1337626069789226, 'Total loss': 0.1337626069789226}
2022-12-31 05:03:29,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:29,466 INFO:     Epoch: 68
2022-12-31 05:03:31,101 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42612087627251943, 'Total loss': 0.42612087627251943} | train loss {'Reaction outcome loss': 0.13341729783628514, 'Total loss': 0.13341729783628514}
2022-12-31 05:03:31,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:31,102 INFO:     Epoch: 69
2022-12-31 05:03:32,727 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43541007687648137, 'Total loss': 0.43541007687648137} | train loss {'Reaction outcome loss': 0.1503141771806269, 'Total loss': 0.1503141771806269}
2022-12-31 05:03:32,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:32,729 INFO:     Epoch: 70
2022-12-31 05:03:34,374 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4525077780087789, 'Total loss': 0.4525077780087789} | train loss {'Reaction outcome loss': 0.13002830009366112, 'Total loss': 0.13002830009366112}
2022-12-31 05:03:34,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:34,374 INFO:     Epoch: 71
2022-12-31 05:03:35,992 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4629734774430593, 'Total loss': 0.4629734774430593} | train loss {'Reaction outcome loss': 0.12404992082251144, 'Total loss': 0.12404992082251144}
2022-12-31 05:03:35,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:35,992 INFO:     Epoch: 72
2022-12-31 05:03:37,642 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4874182144800822, 'Total loss': 0.4874182144800822} | train loss {'Reaction outcome loss': 0.1264793304760225, 'Total loss': 0.1264793304760225}
2022-12-31 05:03:37,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:37,642 INFO:     Epoch: 73
2022-12-31 05:03:39,262 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49741825262705486, 'Total loss': 0.49741825262705486} | train loss {'Reaction outcome loss': 0.1261680257990467, 'Total loss': 0.1261680257990467}
2022-12-31 05:03:39,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:39,262 INFO:     Epoch: 74
2022-12-31 05:03:40,912 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4621172045667966, 'Total loss': 0.4621172045667966} | train loss {'Reaction outcome loss': 0.12921328405945384, 'Total loss': 0.12921328405945384}
2022-12-31 05:03:40,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:40,912 INFO:     Epoch: 75
2022-12-31 05:03:42,576 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4546328951915105, 'Total loss': 0.4546328951915105} | train loss {'Reaction outcome loss': 0.12705642000799053, 'Total loss': 0.12705642000799053}
2022-12-31 05:03:42,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:42,576 INFO:     Epoch: 76
2022-12-31 05:03:44,195 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49125511248906456, 'Total loss': 0.49125511248906456} | train loss {'Reaction outcome loss': 0.12414173439585442, 'Total loss': 0.12414173439585442}
2022-12-31 05:03:44,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:44,196 INFO:     Epoch: 77
2022-12-31 05:03:45,804 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4897015929222107, 'Total loss': 0.4897015929222107} | train loss {'Reaction outcome loss': 0.12338505747226483, 'Total loss': 0.12338505747226483}
2022-12-31 05:03:45,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:45,804 INFO:     Epoch: 78
2022-12-31 05:03:47,409 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48411363636453947, 'Total loss': 0.48411363636453947} | train loss {'Reaction outcome loss': 0.12199195070233132, 'Total loss': 0.12199195070233132}
2022-12-31 05:03:47,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:47,409 INFO:     Epoch: 79
2022-12-31 05:03:49,033 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.451649808883667, 'Total loss': 0.451649808883667} | train loss {'Reaction outcome loss': 0.11884571178466169, 'Total loss': 0.11884571178466169}
2022-12-31 05:03:49,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:49,033 INFO:     Epoch: 80
2022-12-31 05:03:50,658 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46383934865395227, 'Total loss': 0.46383934865395227} | train loss {'Reaction outcome loss': 0.12380798650227244, 'Total loss': 0.12380798650227244}
2022-12-31 05:03:50,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:50,658 INFO:     Epoch: 81
2022-12-31 05:03:52,281 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47249911228815716, 'Total loss': 0.47249911228815716} | train loss {'Reaction outcome loss': 0.12102039306431096, 'Total loss': 0.12102039306431096}
2022-12-31 05:03:52,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:52,282 INFO:     Epoch: 82
2022-12-31 05:03:53,904 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46563144425551095, 'Total loss': 0.46563144425551095} | train loss {'Reaction outcome loss': 0.12490360706747658, 'Total loss': 0.12490360706747658}
2022-12-31 05:03:53,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:53,905 INFO:     Epoch: 83
2022-12-31 05:03:55,552 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45890334248542786, 'Total loss': 0.45890334248542786} | train loss {'Reaction outcome loss': 0.1270434431127691, 'Total loss': 0.1270434431127691}
2022-12-31 05:03:55,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:55,552 INFO:     Epoch: 84
2022-12-31 05:03:57,166 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5103865871826808, 'Total loss': 0.5103865871826808} | train loss {'Reaction outcome loss': 0.14864294091113034, 'Total loss': 0.14864294091113034}
2022-12-31 05:03:57,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:57,167 INFO:     Epoch: 85
2022-12-31 05:03:58,787 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.480418120821317, 'Total loss': 0.480418120821317} | train loss {'Reaction outcome loss': 0.12401294003517462, 'Total loss': 0.12401294003517462}
2022-12-31 05:03:58,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:03:58,787 INFO:     Epoch: 86
2022-12-31 05:04:00,450 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48596588770548504, 'Total loss': 0.48596588770548504} | train loss {'Reaction outcome loss': 0.11875068134846199, 'Total loss': 0.11875068134846199}
2022-12-31 05:04:00,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:00,450 INFO:     Epoch: 87
2022-12-31 05:04:02,112 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4615326980749766, 'Total loss': 0.4615326980749766} | train loss {'Reaction outcome loss': 0.11606171227965759, 'Total loss': 0.11606171227965759}
2022-12-31 05:04:02,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:02,112 INFO:     Epoch: 88
2022-12-31 05:04:03,725 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4680951466163, 'Total loss': 0.4680951466163} | train loss {'Reaction outcome loss': 0.1428650533831071, 'Total loss': 0.1428650533831071}
2022-12-31 05:04:03,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:03,725 INFO:     Epoch: 89
2022-12-31 05:04:05,340 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4427585711081823, 'Total loss': 0.4427585711081823} | train loss {'Reaction outcome loss': 0.1189971559919833, 'Total loss': 0.1189971559919833}
2022-12-31 05:04:05,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:05,340 INFO:     Epoch: 90
2022-12-31 05:04:06,953 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4589332183202108, 'Total loss': 0.4589332183202108} | train loss {'Reaction outcome loss': 0.12008880049003326, 'Total loss': 0.12008880049003326}
2022-12-31 05:04:06,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:06,953 INFO:     Epoch: 91
2022-12-31 05:04:08,566 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44877926347156366, 'Total loss': 0.44877926347156366} | train loss {'Reaction outcome loss': 0.12060212813641714, 'Total loss': 0.12060212813641714}
2022-12-31 05:04:08,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:08,568 INFO:     Epoch: 92
2022-12-31 05:04:10,180 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4830696115891139, 'Total loss': 0.4830696115891139} | train loss {'Reaction outcome loss': 0.117045523800408, 'Total loss': 0.117045523800408}
2022-12-31 05:04:10,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:10,180 INFO:     Epoch: 93
2022-12-31 05:04:11,796 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4451789431273937, 'Total loss': 0.4451789431273937} | train loss {'Reaction outcome loss': 0.11960979241727425, 'Total loss': 0.11960979241727425}
2022-12-31 05:04:11,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:11,796 INFO:     Epoch: 94
2022-12-31 05:04:13,443 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48652960260709127, 'Total loss': 0.48652960260709127} | train loss {'Reaction outcome loss': 0.11665861618104392, 'Total loss': 0.11665861618104392}
2022-12-31 05:04:13,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:13,443 INFO:     Epoch: 95
2022-12-31 05:04:15,104 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44223968833684923, 'Total loss': 0.44223968833684923} | train loss {'Reaction outcome loss': 0.11501353542721979, 'Total loss': 0.11501353542721979}
2022-12-31 05:04:15,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:15,105 INFO:     Epoch: 96
2022-12-31 05:04:16,708 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4674636041124662, 'Total loss': 0.4674636041124662} | train loss {'Reaction outcome loss': 0.11912421993253267, 'Total loss': 0.11912421993253267}
2022-12-31 05:04:16,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:16,709 INFO:     Epoch: 97
2022-12-31 05:04:18,370 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47328948179880775, 'Total loss': 0.47328948179880775} | train loss {'Reaction outcome loss': 0.11603986039636252, 'Total loss': 0.11603986039636252}
2022-12-31 05:04:18,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:18,370 INFO:     Epoch: 98
2022-12-31 05:04:19,980 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.471829258898894, 'Total loss': 0.471829258898894} | train loss {'Reaction outcome loss': 0.11802797513719533, 'Total loss': 0.11802797513719533}
2022-12-31 05:04:19,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:19,980 INFO:     Epoch: 99
2022-12-31 05:04:21,591 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4989605754613876, 'Total loss': 0.4989605754613876} | train loss {'Reaction outcome loss': 0.11813239166058075, 'Total loss': 0.11813239166058075}
2022-12-31 05:04:21,591 INFO:     Best model found after epoch 47 of 100.
2022-12-31 05:04:21,591 INFO:   Done with stage: TRAINING
2022-12-31 05:04:21,591 INFO:   Starting stage: EVALUATION
2022-12-31 05:04:21,719 INFO:   Done with stage: EVALUATION
2022-12-31 05:04:21,719 INFO:   Leaving out SEQ value Fold_2
2022-12-31 05:04:21,732 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:04:21,732 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:04:22,391 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:04:22,392 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:04:22,463 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:04:22,463 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:04:22,463 INFO:     No hyperparam tuning for this model
2022-12-31 05:04:22,463 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:04:22,463 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:04:22,464 INFO:     None feature selector for col prot
2022-12-31 05:04:22,464 INFO:     None feature selector for col prot
2022-12-31 05:04:22,464 INFO:     None feature selector for col prot
2022-12-31 05:04:22,465 INFO:     None feature selector for col chem
2022-12-31 05:04:22,465 INFO:     None feature selector for col chem
2022-12-31 05:04:22,465 INFO:     None feature selector for col chem
2022-12-31 05:04:22,465 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:04:22,465 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:04:22,467 INFO:     Number of params in model 224011
2022-12-31 05:04:22,470 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:04:22,470 INFO:   Starting stage: TRAINING
2022-12-31 05:04:22,515 INFO:     Val loss before train {'Reaction outcome loss': 0.8794520974159241, 'Total loss': 0.8794520974159241}
2022-12-31 05:04:22,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:22,515 INFO:     Epoch: 0
2022-12-31 05:04:24,116 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5442172408103942, 'Total loss': 0.5442172408103942} | train loss {'Reaction outcome loss': 0.7796673194987931, 'Total loss': 0.7796673194987931}
2022-12-31 05:04:24,116 INFO:     Found new best model at epoch 0
2022-12-31 05:04:24,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:24,117 INFO:     Epoch: 1
2022-12-31 05:04:25,720 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47560972968737286, 'Total loss': 0.47560972968737286} | train loss {'Reaction outcome loss': 0.5117663392239679, 'Total loss': 0.5117663392239679}
2022-12-31 05:04:25,721 INFO:     Found new best model at epoch 1
2022-12-31 05:04:25,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:25,722 INFO:     Epoch: 2
2022-12-31 05:04:27,323 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4547826925913493, 'Total loss': 0.4547826925913493} | train loss {'Reaction outcome loss': 0.4412691664412944, 'Total loss': 0.4412691664412944}
2022-12-31 05:04:27,324 INFO:     Found new best model at epoch 2
2022-12-31 05:04:27,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:27,325 INFO:     Epoch: 3
2022-12-31 05:04:28,929 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4099046846230825, 'Total loss': 0.4099046846230825} | train loss {'Reaction outcome loss': 0.4018431582426938, 'Total loss': 0.4018431582426938}
2022-12-31 05:04:28,930 INFO:     Found new best model at epoch 3
2022-12-31 05:04:28,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:28,931 INFO:     Epoch: 4
2022-12-31 05:04:30,540 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4283972203731537, 'Total loss': 0.4283972203731537} | train loss {'Reaction outcome loss': 0.36980881762221784, 'Total loss': 0.36980881762221784}
2022-12-31 05:04:30,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:30,540 INFO:     Epoch: 5
2022-12-31 05:04:32,158 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3889030694961548, 'Total loss': 0.3889030694961548} | train loss {'Reaction outcome loss': 0.3455452169869503, 'Total loss': 0.3455452169869503}
2022-12-31 05:04:32,158 INFO:     Found new best model at epoch 5
2022-12-31 05:04:32,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:32,159 INFO:     Epoch: 6
2022-12-31 05:04:33,762 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3864372968673706, 'Total loss': 0.3864372968673706} | train loss {'Reaction outcome loss': 0.32245727900388466, 'Total loss': 0.32245727900388466}
2022-12-31 05:04:33,762 INFO:     Found new best model at epoch 6
2022-12-31 05:04:33,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:33,763 INFO:     Epoch: 7
2022-12-31 05:04:35,375 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.352349645892779, 'Total loss': 0.352349645892779} | train loss {'Reaction outcome loss': 0.30423934181241225, 'Total loss': 0.30423934181241225}
2022-12-31 05:04:35,375 INFO:     Found new best model at epoch 7
2022-12-31 05:04:35,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:35,376 INFO:     Epoch: 8
2022-12-31 05:04:36,991 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3718033254146576, 'Total loss': 0.3718033254146576} | train loss {'Reaction outcome loss': 0.2898804049422271, 'Total loss': 0.2898804049422271}
2022-12-31 05:04:36,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:36,991 INFO:     Epoch: 9
2022-12-31 05:04:38,605 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37011142273743947, 'Total loss': 0.37011142273743947} | train loss {'Reaction outcome loss': 0.2743912745185577, 'Total loss': 0.2743912745185577}
2022-12-31 05:04:38,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:38,606 INFO:     Epoch: 10
2022-12-31 05:04:40,211 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3413693676392237, 'Total loss': 0.3413693676392237} | train loss {'Reaction outcome loss': 0.2643212155051475, 'Total loss': 0.2643212155051475}
2022-12-31 05:04:40,211 INFO:     Found new best model at epoch 10
2022-12-31 05:04:40,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:40,212 INFO:     Epoch: 11
2022-12-31 05:04:41,815 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36291263649861016, 'Total loss': 0.36291263649861016} | train loss {'Reaction outcome loss': 0.25066437826485094, 'Total loss': 0.25066437826485094}
2022-12-31 05:04:41,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:41,815 INFO:     Epoch: 12
2022-12-31 05:04:43,440 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36690177222092946, 'Total loss': 0.36690177222092946} | train loss {'Reaction outcome loss': 0.23971163998120024, 'Total loss': 0.23971163998120024}
2022-12-31 05:04:43,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:43,440 INFO:     Epoch: 13
2022-12-31 05:04:45,053 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39358243296543755, 'Total loss': 0.39358243296543755} | train loss {'Reaction outcome loss': 0.23650778373227502, 'Total loss': 0.23650778373227502}
2022-12-31 05:04:45,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:45,054 INFO:     Epoch: 14
2022-12-31 05:04:46,655 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35536010364691417, 'Total loss': 0.35536010364691417} | train loss {'Reaction outcome loss': 0.22429116382977388, 'Total loss': 0.22429116382977388}
2022-12-31 05:04:46,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:46,655 INFO:     Epoch: 15
2022-12-31 05:04:48,305 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3406170576810837, 'Total loss': 0.3406170576810837} | train loss {'Reaction outcome loss': 0.2165364927075205, 'Total loss': 0.2165364927075205}
2022-12-31 05:04:48,305 INFO:     Found new best model at epoch 15
2022-12-31 05:04:48,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:48,306 INFO:     Epoch: 16
2022-12-31 05:04:49,906 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3636403501033783, 'Total loss': 0.3636403501033783} | train loss {'Reaction outcome loss': 0.21178183080560534, 'Total loss': 0.21178183080560534}
2022-12-31 05:04:49,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:49,906 INFO:     Epoch: 17
2022-12-31 05:04:51,516 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3501044804851214, 'Total loss': 0.3501044804851214} | train loss {'Reaction outcome loss': 0.19994990013023145, 'Total loss': 0.19994990013023145}
2022-12-31 05:04:51,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:51,517 INFO:     Epoch: 18
2022-12-31 05:04:53,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35770990153153737, 'Total loss': 0.35770990153153737} | train loss {'Reaction outcome loss': 0.19793512180012507, 'Total loss': 0.19793512180012507}
2022-12-31 05:04:53,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:53,122 INFO:     Epoch: 19
2022-12-31 05:04:54,737 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3883107225100199, 'Total loss': 0.3883107225100199} | train loss {'Reaction outcome loss': 0.1940875410843287, 'Total loss': 0.1940875410843287}
2022-12-31 05:04:54,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:54,737 INFO:     Epoch: 20
2022-12-31 05:04:56,352 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3871288100878398, 'Total loss': 0.3871288100878398} | train loss {'Reaction outcome loss': 0.18739073922055483, 'Total loss': 0.18739073922055483}
2022-12-31 05:04:56,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:56,352 INFO:     Epoch: 21
2022-12-31 05:04:57,967 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3419142082333565, 'Total loss': 0.3419142082333565} | train loss {'Reaction outcome loss': 0.18061300169805705, 'Total loss': 0.18061300169805705}
2022-12-31 05:04:57,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:57,967 INFO:     Epoch: 22
2022-12-31 05:04:59,575 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35418026347955067, 'Total loss': 0.35418026347955067} | train loss {'Reaction outcome loss': 0.17625964827577237, 'Total loss': 0.17625964827577237}
2022-12-31 05:04:59,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:04:59,575 INFO:     Epoch: 23
2022-12-31 05:05:01,182 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3731695771217346, 'Total loss': 0.3731695771217346} | train loss {'Reaction outcome loss': 0.1756605049323318, 'Total loss': 0.1756605049323318}
2022-12-31 05:05:01,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:01,183 INFO:     Epoch: 24
2022-12-31 05:05:02,786 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3709781050682068, 'Total loss': 0.3709781050682068} | train loss {'Reaction outcome loss': 0.17544965409286264, 'Total loss': 0.17544965409286264}
2022-12-31 05:05:02,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:02,786 INFO:     Epoch: 25
2022-12-31 05:05:04,387 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3666124807049831, 'Total loss': 0.3666124807049831} | train loss {'Reaction outcome loss': 0.1691499268500148, 'Total loss': 0.1691499268500148}
2022-12-31 05:05:04,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:04,388 INFO:     Epoch: 26
2022-12-31 05:05:05,992 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36179205775260925, 'Total loss': 0.36179205775260925} | train loss {'Reaction outcome loss': 0.16636333704321055, 'Total loss': 0.16636333704321055}
2022-12-31 05:05:05,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:05,992 INFO:     Epoch: 27
2022-12-31 05:05:07,629 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.35141174793243407, 'Total loss': 0.35141174793243407} | train loss {'Reaction outcome loss': 0.1644934338490295, 'Total loss': 0.1644934338490295}
2022-12-31 05:05:07,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:07,630 INFO:     Epoch: 28
2022-12-31 05:05:09,232 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35237702131271365, 'Total loss': 0.35237702131271365} | train loss {'Reaction outcome loss': 0.1618576169551017, 'Total loss': 0.1618576169551017}
2022-12-31 05:05:09,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:09,232 INFO:     Epoch: 29
2022-12-31 05:05:10,838 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3286189824342728, 'Total loss': 0.3286189824342728} | train loss {'Reaction outcome loss': 0.16219866455253892, 'Total loss': 0.16219866455253892}
2022-12-31 05:05:10,839 INFO:     Found new best model at epoch 29
2022-12-31 05:05:10,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:10,840 INFO:     Epoch: 30
2022-12-31 05:05:12,441 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3674933284521103, 'Total loss': 0.3674933284521103} | train loss {'Reaction outcome loss': 0.1566955928833489, 'Total loss': 0.1566955928833489}
2022-12-31 05:05:12,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:12,441 INFO:     Epoch: 31
2022-12-31 05:05:14,091 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3599594215552012, 'Total loss': 0.3599594215552012} | train loss {'Reaction outcome loss': 0.1579107651453003, 'Total loss': 0.1579107651453003}
2022-12-31 05:05:14,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:14,091 INFO:     Epoch: 32
2022-12-31 05:05:15,741 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4133284310499827, 'Total loss': 0.4133284310499827} | train loss {'Reaction outcome loss': 0.1547265892940145, 'Total loss': 0.1547265892940145}
2022-12-31 05:05:15,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:15,742 INFO:     Epoch: 33
2022-12-31 05:05:17,344 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38957133889198303, 'Total loss': 0.38957133889198303} | train loss {'Reaction outcome loss': 0.15530343693307172, 'Total loss': 0.15530343693307172}
2022-12-31 05:05:17,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:17,345 INFO:     Epoch: 34
2022-12-31 05:05:18,959 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37776220639546715, 'Total loss': 0.37776220639546715} | train loss {'Reaction outcome loss': 0.14888006482905553, 'Total loss': 0.14888006482905553}
2022-12-31 05:05:18,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:18,960 INFO:     Epoch: 35
2022-12-31 05:05:20,565 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34319136006136736, 'Total loss': 0.34319136006136736} | train loss {'Reaction outcome loss': 0.14856455017928116, 'Total loss': 0.14856455017928116}
2022-12-31 05:05:20,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:20,566 INFO:     Epoch: 36
2022-12-31 05:05:22,178 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3432447426021099, 'Total loss': 0.3432447426021099} | train loss {'Reaction outcome loss': 0.1462009158529287, 'Total loss': 0.1462009158529287}
2022-12-31 05:05:22,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:22,179 INFO:     Epoch: 37
2022-12-31 05:05:23,791 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3807535837093989, 'Total loss': 0.3807535837093989} | train loss {'Reaction outcome loss': 0.14342040483955376, 'Total loss': 0.14342040483955376}
2022-12-31 05:05:23,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:23,791 INFO:     Epoch: 38
2022-12-31 05:05:25,402 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3645889401435852, 'Total loss': 0.3645889401435852} | train loss {'Reaction outcome loss': 0.14547157556117668, 'Total loss': 0.14547157556117668}
2022-12-31 05:05:25,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:25,403 INFO:     Epoch: 39
2022-12-31 05:05:27,019 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3559088056286176, 'Total loss': 0.3559088056286176} | train loss {'Reaction outcome loss': 0.144505076382282, 'Total loss': 0.144505076382282}
2022-12-31 05:05:27,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:27,019 INFO:     Epoch: 40
2022-12-31 05:05:28,651 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37591277019431196, 'Total loss': 0.37591277019431196} | train loss {'Reaction outcome loss': 0.14249364880464263, 'Total loss': 0.14249364880464263}
2022-12-31 05:05:28,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:28,651 INFO:     Epoch: 41
2022-12-31 05:05:30,266 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34227449502795937, 'Total loss': 0.34227449502795937} | train loss {'Reaction outcome loss': 0.1427370273426556, 'Total loss': 0.1427370273426556}
2022-12-31 05:05:30,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:30,267 INFO:     Epoch: 42
2022-12-31 05:05:31,884 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37497239410877226, 'Total loss': 0.37497239410877226} | train loss {'Reaction outcome loss': 0.14085422325148553, 'Total loss': 0.14085422325148553}
2022-12-31 05:05:31,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:31,885 INFO:     Epoch: 43
2022-12-31 05:05:33,501 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3624292739666998, 'Total loss': 0.3624292739666998} | train loss {'Reaction outcome loss': 0.14059382141907664, 'Total loss': 0.14059382141907664}
2022-12-31 05:05:33,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:33,501 INFO:     Epoch: 44
2022-12-31 05:05:35,109 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.380019008119901, 'Total loss': 0.380019008119901} | train loss {'Reaction outcome loss': 0.1401877974374152, 'Total loss': 0.1401877974374152}
2022-12-31 05:05:35,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:35,110 INFO:     Epoch: 45
2022-12-31 05:05:36,725 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38661009098092713, 'Total loss': 0.38661009098092713} | train loss {'Reaction outcome loss': 0.13702383953194222, 'Total loss': 0.13702383953194222}
2022-12-31 05:05:36,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:36,725 INFO:     Epoch: 46
2022-12-31 05:05:38,333 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41296822056174276, 'Total loss': 0.41296822056174276} | train loss {'Reaction outcome loss': 0.138231482889578, 'Total loss': 0.138231482889578}
2022-12-31 05:05:38,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:38,333 INFO:     Epoch: 47
2022-12-31 05:05:39,978 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3457775870958964, 'Total loss': 0.3457775870958964} | train loss {'Reaction outcome loss': 0.13806079316843492, 'Total loss': 0.13806079316843492}
2022-12-31 05:05:39,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:39,978 INFO:     Epoch: 48
2022-12-31 05:05:41,583 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3811594267686208, 'Total loss': 0.3811594267686208} | train loss {'Reaction outcome loss': 0.13628111291935083, 'Total loss': 0.13628111291935083}
2022-12-31 05:05:41,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:41,583 INFO:     Epoch: 49
2022-12-31 05:05:43,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39073904752731325, 'Total loss': 0.39073904752731325} | train loss {'Reaction outcome loss': 0.1350693341351393, 'Total loss': 0.1350693341351393}
2022-12-31 05:05:43,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:43,234 INFO:     Epoch: 50
2022-12-31 05:05:44,843 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37338652710119885, 'Total loss': 0.37338652710119885} | train loss {'Reaction outcome loss': 0.13462583770989067, 'Total loss': 0.13462583770989067}
2022-12-31 05:05:44,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:44,843 INFO:     Epoch: 51
2022-12-31 05:05:46,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3523074766000112, 'Total loss': 0.3523074766000112} | train loss {'Reaction outcome loss': 0.13113868901553652, 'Total loss': 0.13113868901553652}
2022-12-31 05:05:46,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:46,453 INFO:     Epoch: 52
2022-12-31 05:05:48,056 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36511778434117637, 'Total loss': 0.36511778434117637} | train loss {'Reaction outcome loss': 0.13014734750375642, 'Total loss': 0.13014734750375642}
2022-12-31 05:05:48,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:48,057 INFO:     Epoch: 53
2022-12-31 05:05:49,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35711675385634106, 'Total loss': 0.35711675385634106} | train loss {'Reaction outcome loss': 0.12916905245825266, 'Total loss': 0.12916905245825266}
2022-12-31 05:05:49,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:49,663 INFO:     Epoch: 54
2022-12-31 05:05:51,313 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38025608062744143, 'Total loss': 0.38025608062744143} | train loss {'Reaction outcome loss': 0.12484405139787462, 'Total loss': 0.12484405139787462}
2022-12-31 05:05:51,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:51,313 INFO:     Epoch: 55
2022-12-31 05:05:52,949 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3687051206827164, 'Total loss': 0.3687051206827164} | train loss {'Reaction outcome loss': 0.12760034124163, 'Total loss': 0.12760034124163}
2022-12-31 05:05:52,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:52,949 INFO:     Epoch: 56
2022-12-31 05:05:54,110 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41846309304237367, 'Total loss': 0.41846309304237367} | train loss {'Reaction outcome loss': 0.12746579124062002, 'Total loss': 0.12746579124062002}
2022-12-31 05:05:54,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:54,110 INFO:     Epoch: 57
2022-12-31 05:05:55,237 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3433298182984193, 'Total loss': 0.3433298182984193} | train loss {'Reaction outcome loss': 0.12713662577099608, 'Total loss': 0.12713662577099608}
2022-12-31 05:05:55,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:55,237 INFO:     Epoch: 58
2022-12-31 05:05:56,344 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39703281919161476, 'Total loss': 0.39703281919161476} | train loss {'Reaction outcome loss': 0.12504932021273532, 'Total loss': 0.12504932021273532}
2022-12-31 05:05:56,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:56,344 INFO:     Epoch: 59
2022-12-31 05:05:57,511 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38029593651493393, 'Total loss': 0.38029593651493393} | train loss {'Reaction outcome loss': 0.12946629997879866, 'Total loss': 0.12946629997879866}
2022-12-31 05:05:57,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:57,511 INFO:     Epoch: 60
2022-12-31 05:05:59,124 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35176576574643453, 'Total loss': 0.35176576574643453} | train loss {'Reaction outcome loss': 0.12485695173148148, 'Total loss': 0.12485695173148148}
2022-12-31 05:05:59,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:05:59,125 INFO:     Epoch: 61
2022-12-31 05:06:00,723 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3978709071874619, 'Total loss': 0.3978709071874619} | train loss {'Reaction outcome loss': 0.12493606571645142, 'Total loss': 0.12493606571645142}
2022-12-31 05:06:00,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:00,723 INFO:     Epoch: 62
2022-12-31 05:06:02,324 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37666814476251603, 'Total loss': 0.37666814476251603} | train loss {'Reaction outcome loss': 0.12033016654241313, 'Total loss': 0.12033016654241313}
2022-12-31 05:06:02,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:02,324 INFO:     Epoch: 63
2022-12-31 05:06:03,926 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37521801044543585, 'Total loss': 0.37521801044543585} | train loss {'Reaction outcome loss': 0.1221026624433941, 'Total loss': 0.1221026624433941}
2022-12-31 05:06:03,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:03,926 INFO:     Epoch: 64
2022-12-31 05:06:05,530 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3559046526749929, 'Total loss': 0.3559046526749929} | train loss {'Reaction outcome loss': 0.12414764783882203, 'Total loss': 0.12414764783882203}
2022-12-31 05:06:05,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:05,531 INFO:     Epoch: 65
2022-12-31 05:06:07,140 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4055882265170415, 'Total loss': 0.4055882265170415} | train loss {'Reaction outcome loss': 0.120971564135521, 'Total loss': 0.120971564135521}
2022-12-31 05:06:07,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:07,140 INFO:     Epoch: 66
2022-12-31 05:06:08,790 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38839022219181063, 'Total loss': 0.38839022219181063} | train loss {'Reaction outcome loss': 0.12177763739260879, 'Total loss': 0.12177763739260879}
2022-12-31 05:06:08,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:08,790 INFO:     Epoch: 67
2022-12-31 05:06:10,395 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3579792957752943, 'Total loss': 0.3579792957752943} | train loss {'Reaction outcome loss': 0.12043420377061669, 'Total loss': 0.12043420377061669}
2022-12-31 05:06:10,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:10,395 INFO:     Epoch: 68
2022-12-31 05:06:12,002 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3576467593510946, 'Total loss': 0.3576467593510946} | train loss {'Reaction outcome loss': 0.11902314349057248, 'Total loss': 0.11902314349057248}
2022-12-31 05:06:12,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:12,002 INFO:     Epoch: 69
2022-12-31 05:06:13,624 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3484964390595754, 'Total loss': 0.3484964390595754} | train loss {'Reaction outcome loss': 0.12322850303255348, 'Total loss': 0.12322850303255348}
2022-12-31 05:06:13,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:13,624 INFO:     Epoch: 70
2022-12-31 05:06:15,245 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3576071153084437, 'Total loss': 0.3576071153084437} | train loss {'Reaction outcome loss': 0.1259049405768704, 'Total loss': 0.1259049405768704}
2022-12-31 05:06:15,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:15,245 INFO:     Epoch: 71
2022-12-31 05:06:16,854 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3584489683310191, 'Total loss': 0.3584489683310191} | train loss {'Reaction outcome loss': 0.12084285690564744, 'Total loss': 0.12084285690564744}
2022-12-31 05:06:16,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:16,856 INFO:     Epoch: 72
2022-12-31 05:06:18,475 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3571157137552897, 'Total loss': 0.3571157137552897} | train loss {'Reaction outcome loss': 0.11788738429559951, 'Total loss': 0.11788738429559951}
2022-12-31 05:06:18,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:18,475 INFO:     Epoch: 73
2022-12-31 05:06:20,093 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3834971050421397, 'Total loss': 0.3834971050421397} | train loss {'Reaction outcome loss': 0.11919841936952605, 'Total loss': 0.11919841936952605}
2022-12-31 05:06:20,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:20,093 INFO:     Epoch: 74
2022-12-31 05:06:21,703 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37101973295211793, 'Total loss': 0.37101973295211793} | train loss {'Reaction outcome loss': 0.11819686999979571, 'Total loss': 0.11819686999979571}
2022-12-31 05:06:21,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:21,704 INFO:     Epoch: 75
2022-12-31 05:06:23,322 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4104760974645615, 'Total loss': 0.4104760974645615} | train loss {'Reaction outcome loss': 0.11688781470012763, 'Total loss': 0.11688781470012763}
2022-12-31 05:06:23,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:23,323 INFO:     Epoch: 76
2022-12-31 05:06:24,929 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38365718772013985, 'Total loss': 0.38365718772013985} | train loss {'Reaction outcome loss': 0.11630522963135456, 'Total loss': 0.11630522963135456}
2022-12-31 05:06:24,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:24,930 INFO:     Epoch: 77
2022-12-31 05:06:26,550 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43827212750911715, 'Total loss': 0.43827212750911715} | train loss {'Reaction outcome loss': 0.11604138705488566, 'Total loss': 0.11604138705488566}
2022-12-31 05:06:26,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:26,550 INFO:     Epoch: 78
2022-12-31 05:06:28,167 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3711651854837934, 'Total loss': 0.3711651854837934} | train loss {'Reaction outcome loss': 0.11366838493969046, 'Total loss': 0.11366838493969046}
2022-12-31 05:06:28,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:28,167 INFO:     Epoch: 79
2022-12-31 05:06:29,787 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3865864649415016, 'Total loss': 0.3865864649415016} | train loss {'Reaction outcome loss': 0.11645401793151387, 'Total loss': 0.11645401793151387}
2022-12-31 05:06:29,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:29,787 INFO:     Epoch: 80
2022-12-31 05:06:31,387 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4036104222138723, 'Total loss': 0.4036104222138723} | train loss {'Reaction outcome loss': 0.11526594068396184, 'Total loss': 0.11526594068396184}
2022-12-31 05:06:31,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:31,387 INFO:     Epoch: 81
2022-12-31 05:06:32,994 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3612801253795624, 'Total loss': 0.3612801253795624} | train loss {'Reaction outcome loss': 0.11538026230341762, 'Total loss': 0.11538026230341762}
2022-12-31 05:06:32,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:32,994 INFO:     Epoch: 82
2022-12-31 05:06:34,591 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4086629383265972, 'Total loss': 0.4086629383265972} | train loss {'Reaction outcome loss': 0.1106705290357154, 'Total loss': 0.1106705290357154}
2022-12-31 05:06:34,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:34,592 INFO:     Epoch: 83
2022-12-31 05:06:36,241 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40089417099952696, 'Total loss': 0.40089417099952696} | train loss {'Reaction outcome loss': 0.11230293367853401, 'Total loss': 0.11230293367853401}
2022-12-31 05:06:36,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:36,242 INFO:     Epoch: 84
2022-12-31 05:06:37,835 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38103432158629097, 'Total loss': 0.38103432158629097} | train loss {'Reaction outcome loss': 0.11494633096209081, 'Total loss': 0.11494633096209081}
2022-12-31 05:06:37,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:37,835 INFO:     Epoch: 85
2022-12-31 05:06:39,468 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37416974479953446, 'Total loss': 0.37416974479953446} | train loss {'Reaction outcome loss': 0.11338114524328143, 'Total loss': 0.11338114524328143}
2022-12-31 05:06:39,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:39,469 INFO:     Epoch: 86
2022-12-31 05:06:41,072 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38917216360569, 'Total loss': 0.38917216360569} | train loss {'Reaction outcome loss': 0.11260236141672969, 'Total loss': 0.11260236141672969}
2022-12-31 05:06:41,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:41,072 INFO:     Epoch: 87
2022-12-31 05:06:42,680 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38270925829807917, 'Total loss': 0.38270925829807917} | train loss {'Reaction outcome loss': 0.11689116415248191, 'Total loss': 0.11689116415248191}
2022-12-31 05:06:42,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:42,681 INFO:     Epoch: 88
2022-12-31 05:06:44,293 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40790301462014517, 'Total loss': 0.40790301462014517} | train loss {'Reaction outcome loss': 0.11342742680198084, 'Total loss': 0.11342742680198084}
2022-12-31 05:06:44,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:44,294 INFO:     Epoch: 89
2022-12-31 05:06:45,904 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4108231380581856, 'Total loss': 0.4108231380581856} | train loss {'Reaction outcome loss': 0.11146961411896304, 'Total loss': 0.11146961411896304}
2022-12-31 05:06:45,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:45,904 INFO:     Epoch: 90
2022-12-31 05:06:47,511 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.359541567414999, 'Total loss': 0.359541567414999} | train loss {'Reaction outcome loss': 0.1097549731566156, 'Total loss': 0.1097549731566156}
2022-12-31 05:06:47,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:47,512 INFO:     Epoch: 91
2022-12-31 05:06:49,112 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39354170858860016, 'Total loss': 0.39354170858860016} | train loss {'Reaction outcome loss': 0.11066945485752008, 'Total loss': 0.11066945485752008}
2022-12-31 05:06:49,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:49,112 INFO:     Epoch: 92
2022-12-31 05:06:50,763 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3969640543063482, 'Total loss': 0.3969640543063482} | train loss {'Reaction outcome loss': 0.10876823149716658, 'Total loss': 0.10876823149716658}
2022-12-31 05:06:50,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:50,764 INFO:     Epoch: 93
2022-12-31 05:06:52,395 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39943869213263195, 'Total loss': 0.39943869213263195} | train loss {'Reaction outcome loss': 0.1094282247248466, 'Total loss': 0.1094282247248466}
2022-12-31 05:06:52,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:52,395 INFO:     Epoch: 94
2022-12-31 05:06:54,007 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40069386462370554, 'Total loss': 0.40069386462370554} | train loss {'Reaction outcome loss': 0.1145655559137953, 'Total loss': 0.1145655559137953}
2022-12-31 05:06:54,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:54,008 INFO:     Epoch: 95
2022-12-31 05:06:55,659 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39423620452483493, 'Total loss': 0.39423620452483493} | train loss {'Reaction outcome loss': 0.11464385096541177, 'Total loss': 0.11464385096541177}
2022-12-31 05:06:55,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:55,659 INFO:     Epoch: 96
2022-12-31 05:06:57,311 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3888817861676216, 'Total loss': 0.3888817861676216} | train loss {'Reaction outcome loss': 0.10846581620956179, 'Total loss': 0.10846581620956179}
2022-12-31 05:06:57,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:57,311 INFO:     Epoch: 97
2022-12-31 05:06:58,912 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3782513091961543, 'Total loss': 0.3782513091961543} | train loss {'Reaction outcome loss': 0.1078946514014345, 'Total loss': 0.1078946514014345}
2022-12-31 05:06:58,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:06:58,912 INFO:     Epoch: 98
2022-12-31 05:07:00,522 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3618170137206713, 'Total loss': 0.3618170137206713} | train loss {'Reaction outcome loss': 0.1065697333015787, 'Total loss': 0.1065697333015787}
2022-12-31 05:07:00,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:00,522 INFO:     Epoch: 99
2022-12-31 05:07:02,143 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3957132413983345, 'Total loss': 0.3957132413983345} | train loss {'Reaction outcome loss': 0.1096658771908604, 'Total loss': 0.1096658771908604}
2022-12-31 05:07:02,144 INFO:     Best model found after epoch 30 of 100.
2022-12-31 05:07:02,144 INFO:   Done with stage: TRAINING
2022-12-31 05:07:02,144 INFO:   Starting stage: EVALUATION
2022-12-31 05:07:02,279 INFO:   Done with stage: EVALUATION
2022-12-31 05:07:02,280 INFO:   Leaving out SEQ value Fold_3
2022-12-31 05:07:02,292 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 05:07:02,292 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:07:02,953 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:07:02,953 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:07:03,023 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:07:03,023 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:07:03,023 INFO:     No hyperparam tuning for this model
2022-12-31 05:07:03,023 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:07:03,023 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:07:03,024 INFO:     None feature selector for col prot
2022-12-31 05:07:03,024 INFO:     None feature selector for col prot
2022-12-31 05:07:03,024 INFO:     None feature selector for col prot
2022-12-31 05:07:03,025 INFO:     None feature selector for col chem
2022-12-31 05:07:03,025 INFO:     None feature selector for col chem
2022-12-31 05:07:03,025 INFO:     None feature selector for col chem
2022-12-31 05:07:03,025 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:07:03,025 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:07:03,027 INFO:     Number of params in model 224011
2022-12-31 05:07:03,031 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:07:03,031 INFO:   Starting stage: TRAINING
2022-12-31 05:07:03,075 INFO:     Val loss before train {'Reaction outcome loss': 0.9599005579948425, 'Total loss': 0.9599005579948425}
2022-12-31 05:07:03,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:03,075 INFO:     Epoch: 0
2022-12-31 05:07:04,674 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5221475919087728, 'Total loss': 0.5221475919087728} | train loss {'Reaction outcome loss': 0.7817843827135834, 'Total loss': 0.7817843827135834}
2022-12-31 05:07:04,675 INFO:     Found new best model at epoch 0
2022-12-31 05:07:04,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:04,676 INFO:     Epoch: 1
2022-12-31 05:07:06,267 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4630928119023641, 'Total loss': 0.4630928119023641} | train loss {'Reaction outcome loss': 0.5255359545513824, 'Total loss': 0.5255359545513824}
2022-12-31 05:07:06,268 INFO:     Found new best model at epoch 1
2022-12-31 05:07:06,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:06,269 INFO:     Epoch: 2
2022-12-31 05:07:07,867 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4332501192887624, 'Total loss': 0.4332501192887624} | train loss {'Reaction outcome loss': 0.45422359044244004, 'Total loss': 0.45422359044244004}
2022-12-31 05:07:07,867 INFO:     Found new best model at epoch 2
2022-12-31 05:07:07,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:07,868 INFO:     Epoch: 3
2022-12-31 05:07:09,466 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4128142555554708, 'Total loss': 0.4128142555554708} | train loss {'Reaction outcome loss': 0.41860517411878256, 'Total loss': 0.41860517411878256}
2022-12-31 05:07:09,466 INFO:     Found new best model at epoch 3
2022-12-31 05:07:09,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:09,467 INFO:     Epoch: 4
2022-12-31 05:07:11,081 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.431968088944753, 'Total loss': 0.431968088944753} | train loss {'Reaction outcome loss': 0.38630175792472266, 'Total loss': 0.38630175792472266}
2022-12-31 05:07:11,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:11,081 INFO:     Epoch: 5
2022-12-31 05:07:12,725 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43157961666584016, 'Total loss': 0.43157961666584016} | train loss {'Reaction outcome loss': 0.3630816787745694, 'Total loss': 0.3630816787745694}
2022-12-31 05:07:12,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:12,725 INFO:     Epoch: 6
2022-12-31 05:07:14,370 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38622246086597445, 'Total loss': 0.38622246086597445} | train loss {'Reaction outcome loss': 0.3415277770860291, 'Total loss': 0.3415277770860291}
2022-12-31 05:07:14,370 INFO:     Found new best model at epoch 6
2022-12-31 05:07:14,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:14,371 INFO:     Epoch: 7
2022-12-31 05:07:15,971 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.36401010205348333, 'Total loss': 0.36401010205348333} | train loss {'Reaction outcome loss': 0.3240124869805116, 'Total loss': 0.3240124869805116}
2022-12-31 05:07:15,971 INFO:     Found new best model at epoch 7
2022-12-31 05:07:15,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:15,972 INFO:     Epoch: 8
2022-12-31 05:07:17,571 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3885590761899948, 'Total loss': 0.3885590761899948} | train loss {'Reaction outcome loss': 0.30877299655754215, 'Total loss': 0.30877299655754215}
2022-12-31 05:07:17,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:17,571 INFO:     Epoch: 9
2022-12-31 05:07:19,202 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36481994738181434, 'Total loss': 0.36481994738181434} | train loss {'Reaction outcome loss': 0.29530457001957267, 'Total loss': 0.29530457001957267}
2022-12-31 05:07:19,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:19,204 INFO:     Epoch: 10
2022-12-31 05:07:20,801 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40448507368564607, 'Total loss': 0.40448507368564607} | train loss {'Reaction outcome loss': 0.2799272967482006, 'Total loss': 0.2799272967482006}
2022-12-31 05:07:20,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:20,801 INFO:     Epoch: 11
2022-12-31 05:07:22,400 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37251123537619907, 'Total loss': 0.37251123537619907} | train loss {'Reaction outcome loss': 0.26540615941370554, 'Total loss': 0.26540615941370554}
2022-12-31 05:07:22,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:22,400 INFO:     Epoch: 12
2022-12-31 05:07:24,000 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36494625185926755, 'Total loss': 0.36494625185926755} | train loss {'Reaction outcome loss': 0.2570273567523275, 'Total loss': 0.2570273567523275}
2022-12-31 05:07:24,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:24,000 INFO:     Epoch: 13
2022-12-31 05:07:25,603 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38071038722991946, 'Total loss': 0.38071038722991946} | train loss {'Reaction outcome loss': 0.24681278799861778, 'Total loss': 0.24681278799861778}
2022-12-31 05:07:25,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:25,604 INFO:     Epoch: 14
2022-12-31 05:07:27,214 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3752303163210551, 'Total loss': 0.3752303163210551} | train loss {'Reaction outcome loss': 0.23623777736974505, 'Total loss': 0.23623777736974505}
2022-12-31 05:07:27,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:27,214 INFO:     Epoch: 15
2022-12-31 05:07:28,816 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3788592835267385, 'Total loss': 0.3788592835267385} | train loss {'Reaction outcome loss': 0.23077857800019094, 'Total loss': 0.23077857800019094}
2022-12-31 05:07:28,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:28,816 INFO:     Epoch: 16
2022-12-31 05:07:30,428 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3966365844011307, 'Total loss': 0.3966365844011307} | train loss {'Reaction outcome loss': 0.22177250963727851, 'Total loss': 0.22177250963727851}
2022-12-31 05:07:30,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:30,428 INFO:     Epoch: 17
2022-12-31 05:07:32,049 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36003756125768027, 'Total loss': 0.36003756125768027} | train loss {'Reaction outcome loss': 0.21288517639109175, 'Total loss': 0.21288517639109175}
2022-12-31 05:07:32,049 INFO:     Found new best model at epoch 17
2022-12-31 05:07:32,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:32,051 INFO:     Epoch: 18
2022-12-31 05:07:33,651 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37962002158164976, 'Total loss': 0.37962002158164976} | train loss {'Reaction outcome loss': 0.20607700613037352, 'Total loss': 0.20607700613037352}
2022-12-31 05:07:33,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:33,651 INFO:     Epoch: 19
2022-12-31 05:07:35,259 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42437547544638315, 'Total loss': 0.42437547544638315} | train loss {'Reaction outcome loss': 0.2019034625327849, 'Total loss': 0.2019034625327849}
2022-12-31 05:07:35,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:35,259 INFO:     Epoch: 20
2022-12-31 05:07:36,907 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4128558854262034, 'Total loss': 0.4128558854262034} | train loss {'Reaction outcome loss': 0.19692029416451962, 'Total loss': 0.19692029416451962}
2022-12-31 05:07:36,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:36,907 INFO:     Epoch: 21
2022-12-31 05:07:38,503 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.387910920381546, 'Total loss': 0.387910920381546} | train loss {'Reaction outcome loss': 0.19113624340175708, 'Total loss': 0.19113624340175708}
2022-12-31 05:07:38,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:38,504 INFO:     Epoch: 22
2022-12-31 05:07:40,102 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3862955947717031, 'Total loss': 0.3862955947717031} | train loss {'Reaction outcome loss': 0.18539715649375876, 'Total loss': 0.18539715649375876}
2022-12-31 05:07:40,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:40,102 INFO:     Epoch: 23
2022-12-31 05:07:41,748 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3815554474170009, 'Total loss': 0.3815554474170009} | train loss {'Reaction outcome loss': 0.1823494497672979, 'Total loss': 0.1823494497672979}
2022-12-31 05:07:41,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:41,748 INFO:     Epoch: 24
2022-12-31 05:07:43,364 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3607535029451052, 'Total loss': 0.3607535029451052} | train loss {'Reaction outcome loss': 0.18032714039182815, 'Total loss': 0.18032714039182815}
2022-12-31 05:07:43,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:43,364 INFO:     Epoch: 25
2022-12-31 05:07:44,974 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37843454281489053, 'Total loss': 0.37843454281489053} | train loss {'Reaction outcome loss': 0.17571056380376712, 'Total loss': 0.17571056380376712}
2022-12-31 05:07:44,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:44,974 INFO:     Epoch: 26
2022-12-31 05:07:46,582 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3773030733068784, 'Total loss': 0.3773030733068784} | train loss {'Reaction outcome loss': 0.17575438959940232, 'Total loss': 0.17575438959940232}
2022-12-31 05:07:46,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:46,583 INFO:     Epoch: 27
2022-12-31 05:07:48,230 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3799989183743795, 'Total loss': 0.3799989183743795} | train loss {'Reaction outcome loss': 0.16877352446658817, 'Total loss': 0.16877352446658817}
2022-12-31 05:07:48,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:48,230 INFO:     Epoch: 28
2022-12-31 05:07:49,845 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3836487392584483, 'Total loss': 0.3836487392584483} | train loss {'Reaction outcome loss': 0.16498956997919786, 'Total loss': 0.16498956997919786}
2022-12-31 05:07:49,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:49,845 INFO:     Epoch: 29
2022-12-31 05:07:51,508 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39155396272738774, 'Total loss': 0.39155396272738774} | train loss {'Reaction outcome loss': 0.1634643063505245, 'Total loss': 0.1634643063505245}
2022-12-31 05:07:51,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:51,508 INFO:     Epoch: 30
2022-12-31 05:07:53,128 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3613814726471901, 'Total loss': 0.3613814726471901} | train loss {'Reaction outcome loss': 0.16010527575095168, 'Total loss': 0.16010527575095168}
2022-12-31 05:07:53,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:53,128 INFO:     Epoch: 31
2022-12-31 05:07:54,736 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40346220235029856, 'Total loss': 0.40346220235029856} | train loss {'Reaction outcome loss': 0.16173441342381767, 'Total loss': 0.16173441342381767}
2022-12-31 05:07:54,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:54,737 INFO:     Epoch: 32
2022-12-31 05:07:56,332 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3793294032414754, 'Total loss': 0.3793294032414754} | train loss {'Reaction outcome loss': 0.16218822339256278, 'Total loss': 0.16218822339256278}
2022-12-31 05:07:56,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:56,332 INFO:     Epoch: 33
2022-12-31 05:07:57,933 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4643054147561391, 'Total loss': 0.4643054147561391} | train loss {'Reaction outcome loss': 0.15626564123684833, 'Total loss': 0.15626564123684833}
2022-12-31 05:07:57,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:57,934 INFO:     Epoch: 34
2022-12-31 05:07:59,530 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41631967226664224, 'Total loss': 0.41631967226664224} | train loss {'Reaction outcome loss': 0.15084686603792857, 'Total loss': 0.15084686603792857}
2022-12-31 05:07:59,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:07:59,530 INFO:     Epoch: 35
2022-12-31 05:08:01,119 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38683924873669945, 'Total loss': 0.38683924873669945} | train loss {'Reaction outcome loss': 0.15099291048684726, 'Total loss': 0.15099291048684726}
2022-12-31 05:08:01,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:01,119 INFO:     Epoch: 36
2022-12-31 05:08:02,723 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4175725708405177, 'Total loss': 0.4175725708405177} | train loss {'Reaction outcome loss': 0.1521400228490705, 'Total loss': 0.1521400228490705}
2022-12-31 05:08:02,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:02,723 INFO:     Epoch: 37
2022-12-31 05:08:04,368 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4126603022217751, 'Total loss': 0.4126603022217751} | train loss {'Reaction outcome loss': 0.15142487147959433, 'Total loss': 0.15142487147959433}
2022-12-31 05:08:04,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:04,368 INFO:     Epoch: 38
2022-12-31 05:08:05,967 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4005012859900792, 'Total loss': 0.4005012859900792} | train loss {'Reaction outcome loss': 0.14439659759456858, 'Total loss': 0.14439659759456858}
2022-12-31 05:08:05,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:05,967 INFO:     Epoch: 39
2022-12-31 05:08:07,611 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39217085565129917, 'Total loss': 0.39217085565129917} | train loss {'Reaction outcome loss': 0.14507412941846656, 'Total loss': 0.14507412941846656}
2022-12-31 05:08:07,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:07,612 INFO:     Epoch: 40
2022-12-31 05:08:09,257 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44313980440298717, 'Total loss': 0.44313980440298717} | train loss {'Reaction outcome loss': 0.14336314621030083, 'Total loss': 0.14336314621030083}
2022-12-31 05:08:09,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:09,258 INFO:     Epoch: 41
2022-12-31 05:08:10,858 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4202625890572866, 'Total loss': 0.4202625890572866} | train loss {'Reaction outcome loss': 0.14121552426436226, 'Total loss': 0.14121552426436226}
2022-12-31 05:08:10,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:10,859 INFO:     Epoch: 42
2022-12-31 05:08:12,504 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4043095111846924, 'Total loss': 0.4043095111846924} | train loss {'Reaction outcome loss': 0.1402475326765506, 'Total loss': 0.1402475326765506}
2022-12-31 05:08:12,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:12,504 INFO:     Epoch: 43
2022-12-31 05:08:14,101 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4092425594727198, 'Total loss': 0.4092425594727198} | train loss {'Reaction outcome loss': 0.13681353725690817, 'Total loss': 0.13681353725690817}
2022-12-31 05:08:14,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:14,102 INFO:     Epoch: 44
2022-12-31 05:08:15,699 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3877847378452619, 'Total loss': 0.3877847378452619} | train loss {'Reaction outcome loss': 0.13767698947374366, 'Total loss': 0.13767698947374366}
2022-12-31 05:08:15,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:15,699 INFO:     Epoch: 45
2022-12-31 05:08:17,296 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44382479588190715, 'Total loss': 0.44382479588190715} | train loss {'Reaction outcome loss': 0.13876980341520612, 'Total loss': 0.13876980341520612}
2022-12-31 05:08:17,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:17,297 INFO:     Epoch: 46
2022-12-31 05:08:18,886 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43636322816212975, 'Total loss': 0.43636322816212975} | train loss {'Reaction outcome loss': 0.13596702721515747, 'Total loss': 0.13596702721515747}
2022-12-31 05:08:18,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:18,886 INFO:     Epoch: 47
2022-12-31 05:08:20,517 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4209822217623393, 'Total loss': 0.4209822217623393} | train loss {'Reaction outcome loss': 0.13487034405823864, 'Total loss': 0.13487034405823864}
2022-12-31 05:08:20,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:20,517 INFO:     Epoch: 48
2022-12-31 05:08:22,163 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43120120763778685, 'Total loss': 0.43120120763778685} | train loss {'Reaction outcome loss': 0.13617049951119956, 'Total loss': 0.13617049951119956}
2022-12-31 05:08:22,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:22,164 INFO:     Epoch: 49
2022-12-31 05:08:23,767 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4224898179372152, 'Total loss': 0.4224898179372152} | train loss {'Reaction outcome loss': 0.13371167032239148, 'Total loss': 0.13371167032239148}
2022-12-31 05:08:23,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:23,767 INFO:     Epoch: 50
2022-12-31 05:08:25,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40923927625020345, 'Total loss': 0.40923927625020345} | train loss {'Reaction outcome loss': 0.1295089283463419, 'Total loss': 0.1295089283463419}
2022-12-31 05:08:25,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:25,413 INFO:     Epoch: 51
2022-12-31 05:08:27,009 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4113132506608963, 'Total loss': 0.4113132506608963} | train loss {'Reaction outcome loss': 0.1350703088979445, 'Total loss': 0.1350703088979445}
2022-12-31 05:08:27,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:27,009 INFO:     Epoch: 52
2022-12-31 05:08:28,633 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44046817446748415, 'Total loss': 0.44046817446748415} | train loss {'Reaction outcome loss': 0.1287289508857215, 'Total loss': 0.1287289508857215}
2022-12-31 05:08:28,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:28,633 INFO:     Epoch: 53
2022-12-31 05:08:30,277 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46960075398286183, 'Total loss': 0.46960075398286183} | train loss {'Reaction outcome loss': 0.12628673247979347, 'Total loss': 0.12628673247979347}
2022-12-31 05:08:30,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:30,279 INFO:     Epoch: 54
2022-12-31 05:08:31,884 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4301196465889613, 'Total loss': 0.4301196465889613} | train loss {'Reaction outcome loss': 0.1296756974534019, 'Total loss': 0.1296756974534019}
2022-12-31 05:08:31,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:31,884 INFO:     Epoch: 55
2022-12-31 05:08:33,520 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4313800563414892, 'Total loss': 0.4313800563414892} | train loss {'Reaction outcome loss': 0.13201290528006823, 'Total loss': 0.13201290528006823}
2022-12-31 05:08:33,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:33,520 INFO:     Epoch: 56
2022-12-31 05:08:35,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43274261554082233, 'Total loss': 0.43274261554082233} | train loss {'Reaction outcome loss': 0.1261870320647573, 'Total loss': 0.1261870320647573}
2022-12-31 05:08:35,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:35,165 INFO:     Epoch: 57
2022-12-31 05:08:36,765 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39563320676485697, 'Total loss': 0.39563320676485697} | train loss {'Reaction outcome loss': 0.12628259850263376, 'Total loss': 0.12628259850263376}
2022-12-31 05:08:36,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:36,766 INFO:     Epoch: 58
2022-12-31 05:08:38,381 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.397455508261919, 'Total loss': 0.397455508261919} | train loss {'Reaction outcome loss': 0.12482533788977143, 'Total loss': 0.12482533788977143}
2022-12-31 05:08:38,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:38,381 INFO:     Epoch: 59
2022-12-31 05:08:40,025 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4591481387615204, 'Total loss': 0.4591481387615204} | train loss {'Reaction outcome loss': 0.12086968356743455, 'Total loss': 0.12086968356743455}
2022-12-31 05:08:40,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:40,025 INFO:     Epoch: 60
2022-12-31 05:08:41,651 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4163235838214556, 'Total loss': 0.4163235838214556} | train loss {'Reaction outcome loss': 0.12931746642374786, 'Total loss': 0.12931746642374786}
2022-12-31 05:08:41,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:41,651 INFO:     Epoch: 61
2022-12-31 05:08:43,259 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42230574041604996, 'Total loss': 0.42230574041604996} | train loss {'Reaction outcome loss': 0.12291479056817053, 'Total loss': 0.12291479056817053}
2022-12-31 05:08:43,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:43,259 INFO:     Epoch: 62
2022-12-31 05:08:44,867 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4480908284584681, 'Total loss': 0.4480908284584681} | train loss {'Reaction outcome loss': 0.12582914199809725, 'Total loss': 0.12582914199809725}
2022-12-31 05:08:44,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:44,867 INFO:     Epoch: 63
2022-12-31 05:08:46,512 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4273510833581289, 'Total loss': 0.4273510833581289} | train loss {'Reaction outcome loss': 0.1216028292071511, 'Total loss': 0.1216028292071511}
2022-12-31 05:08:46,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:46,512 INFO:     Epoch: 64
2022-12-31 05:08:48,110 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4549788902203242, 'Total loss': 0.4549788902203242} | train loss {'Reaction outcome loss': 0.11880602529391837, 'Total loss': 0.11880602529391837}
2022-12-31 05:08:48,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:48,110 INFO:     Epoch: 65
2022-12-31 05:08:49,720 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.426273681409657, 'Total loss': 0.426273681409657} | train loss {'Reaction outcome loss': 0.11920051346746216, 'Total loss': 0.11920051346746216}
2022-12-31 05:08:49,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:49,721 INFO:     Epoch: 66
2022-12-31 05:08:51,341 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4461233288049698, 'Total loss': 0.4461233288049698} | train loss {'Reaction outcome loss': 0.11824822858369981, 'Total loss': 0.11824822858369981}
2022-12-31 05:08:51,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:51,341 INFO:     Epoch: 67
2022-12-31 05:08:52,985 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4138754725456238, 'Total loss': 0.4138754725456238} | train loss {'Reaction outcome loss': 0.12077836936165752, 'Total loss': 0.12077836936165752}
2022-12-31 05:08:52,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:52,985 INFO:     Epoch: 68
2022-12-31 05:08:54,629 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43241226573785146, 'Total loss': 0.43241226573785146} | train loss {'Reaction outcome loss': 0.12383648660033941, 'Total loss': 0.12383648660033941}
2022-12-31 05:08:54,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:54,629 INFO:     Epoch: 69
2022-12-31 05:08:56,252 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4067831894770885, 'Total loss': 0.4067831894770885} | train loss {'Reaction outcome loss': 0.13213777687100373, 'Total loss': 0.13213777687100373}
2022-12-31 05:08:56,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:56,252 INFO:     Epoch: 70
2022-12-31 05:08:57,896 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44817859729131065, 'Total loss': 0.44817859729131065} | train loss {'Reaction outcome loss': 0.1300353648673211, 'Total loss': 0.1300353648673211}
2022-12-31 05:08:57,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:57,896 INFO:     Epoch: 71
2022-12-31 05:08:59,534 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43537245293458304, 'Total loss': 0.43537245293458304} | train loss {'Reaction outcome loss': 0.11994418165656728, 'Total loss': 0.11994418165656728}
2022-12-31 05:08:59,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:08:59,534 INFO:     Epoch: 72
2022-12-31 05:09:01,125 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4344541847705841, 'Total loss': 0.4344541847705841} | train loss {'Reaction outcome loss': 0.11950050181821807, 'Total loss': 0.11950050181821807}
2022-12-31 05:09:01,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:01,127 INFO:     Epoch: 73
2022-12-31 05:09:02,723 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4237804571787516, 'Total loss': 0.4237804571787516} | train loss {'Reaction outcome loss': 0.11603434568598539, 'Total loss': 0.11603434568598539}
2022-12-31 05:09:02,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:02,723 INFO:     Epoch: 74
2022-12-31 05:09:04,368 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4050631771485011, 'Total loss': 0.4050631771485011} | train loss {'Reaction outcome loss': 0.11507153083935326, 'Total loss': 0.11507153083935326}
2022-12-31 05:09:04,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:04,368 INFO:     Epoch: 75
2022-12-31 05:09:05,977 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45832610328992207, 'Total loss': 0.45832610328992207} | train loss {'Reaction outcome loss': 0.11048086863966325, 'Total loss': 0.11048086863966325}
2022-12-31 05:09:05,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:05,978 INFO:     Epoch: 76
2022-12-31 05:09:07,583 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48316864172617596, 'Total loss': 0.48316864172617596} | train loss {'Reaction outcome loss': 0.1166070777402198, 'Total loss': 0.1166070777402198}
2022-12-31 05:09:07,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:07,584 INFO:     Epoch: 77
2022-12-31 05:09:09,183 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42548686067263286, 'Total loss': 0.42548686067263286} | train loss {'Reaction outcome loss': 0.119879352597472, 'Total loss': 0.119879352597472}
2022-12-31 05:09:09,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:09,184 INFO:     Epoch: 78
2022-12-31 05:09:10,791 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41469801863034567, 'Total loss': 0.41469801863034567} | train loss {'Reaction outcome loss': 0.11961569264008759, 'Total loss': 0.11961569264008759}
2022-12-31 05:09:10,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:10,792 INFO:     Epoch: 79
2022-12-31 05:09:12,424 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41536427785952884, 'Total loss': 0.41536427785952884} | train loss {'Reaction outcome loss': 0.115566779847424, 'Total loss': 0.115566779847424}
2022-12-31 05:09:12,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:12,424 INFO:     Epoch: 80
2022-12-31 05:09:14,028 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4604210635026296, 'Total loss': 0.4604210635026296} | train loss {'Reaction outcome loss': 0.1145540607987388, 'Total loss': 0.1145540607987388}
2022-12-31 05:09:14,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:14,029 INFO:     Epoch: 81
2022-12-31 05:09:15,677 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41853310316801073, 'Total loss': 0.41853310316801073} | train loss {'Reaction outcome loss': 0.11574740496301178, 'Total loss': 0.11574740496301178}
2022-12-31 05:09:15,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:15,677 INFO:     Epoch: 82
2022-12-31 05:09:17,279 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43745401700337727, 'Total loss': 0.43745401700337727} | train loss {'Reaction outcome loss': 0.11608568193295445, 'Total loss': 0.11608568193295445}
2022-12-31 05:09:17,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:17,279 INFO:     Epoch: 83
2022-12-31 05:09:18,885 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4320536990960439, 'Total loss': 0.4320536990960439} | train loss {'Reaction outcome loss': 0.11691951085455142, 'Total loss': 0.11691951085455142}
2022-12-31 05:09:18,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:18,886 INFO:     Epoch: 84
2022-12-31 05:09:20,530 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.431445786356926, 'Total loss': 0.431445786356926} | train loss {'Reaction outcome loss': 0.11219320971273132, 'Total loss': 0.11219320971273132}
2022-12-31 05:09:20,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:20,531 INFO:     Epoch: 85
2022-12-31 05:09:22,124 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46311790744463605, 'Total loss': 0.46311790744463605} | train loss {'Reaction outcome loss': 0.11109147537687296, 'Total loss': 0.11109147537687296}
2022-12-31 05:09:22,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:22,124 INFO:     Epoch: 86
2022-12-31 05:09:23,747 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4262646933396657, 'Total loss': 0.4262646933396657} | train loss {'Reaction outcome loss': 0.11770238165296751, 'Total loss': 0.11770238165296751}
2022-12-31 05:09:23,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:23,747 INFO:     Epoch: 87
2022-12-31 05:09:25,391 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46528721451759336, 'Total loss': 0.46528721451759336} | train loss {'Reaction outcome loss': 0.12012462642883043, 'Total loss': 0.12012462642883043}
2022-12-31 05:09:25,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:25,391 INFO:     Epoch: 88
2022-12-31 05:09:27,026 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43100060323874156, 'Total loss': 0.43100060323874156} | train loss {'Reaction outcome loss': 0.11235768241627012, 'Total loss': 0.11235768241627012}
2022-12-31 05:09:27,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:27,026 INFO:     Epoch: 89
2022-12-31 05:09:28,671 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4335381774852673, 'Total loss': 0.4335381774852673} | train loss {'Reaction outcome loss': 0.11425390259120545, 'Total loss': 0.11425390259120545}
2022-12-31 05:09:28,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:28,671 INFO:     Epoch: 90
2022-12-31 05:09:30,279 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47153475085894264, 'Total loss': 0.47153475085894264} | train loss {'Reaction outcome loss': 0.11044905485326062, 'Total loss': 0.11044905485326062}
2022-12-31 05:09:30,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:30,280 INFO:     Epoch: 91
2022-12-31 05:09:31,925 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4359507898489634, 'Total loss': 0.4359507898489634} | train loss {'Reaction outcome loss': 0.11123102459154217, 'Total loss': 0.11123102459154217}
2022-12-31 05:09:31,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:31,926 INFO:     Epoch: 92
2022-12-31 05:09:33,528 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4260768632094065, 'Total loss': 0.4260768632094065} | train loss {'Reaction outcome loss': 0.1104123341294872, 'Total loss': 0.1104123341294872}
2022-12-31 05:09:33,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:33,528 INFO:     Epoch: 93
2022-12-31 05:09:35,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4242989937464396, 'Total loss': 0.4242989937464396} | train loss {'Reaction outcome loss': 0.11466234215047388, 'Total loss': 0.11466234215047388}
2022-12-31 05:09:35,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:35,174 INFO:     Epoch: 94
2022-12-31 05:09:36,784 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4436078190803528, 'Total loss': 0.4436078190803528} | train loss {'Reaction outcome loss': 0.112247697493887, 'Total loss': 0.112247697493887}
2022-12-31 05:09:36,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:36,785 INFO:     Epoch: 95
2022-12-31 05:09:38,379 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4244340161482493, 'Total loss': 0.4244340161482493} | train loss {'Reaction outcome loss': 0.11358238628258649, 'Total loss': 0.11358238628258649}
2022-12-31 05:09:38,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:38,380 INFO:     Epoch: 96
2022-12-31 05:09:39,972 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38418533094227314, 'Total loss': 0.38418533094227314} | train loss {'Reaction outcome loss': 0.10987630204703563, 'Total loss': 0.10987630204703563}
2022-12-31 05:09:39,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:39,973 INFO:     Epoch: 97
2022-12-31 05:09:41,609 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4042282740275065, 'Total loss': 0.4042282740275065} | train loss {'Reaction outcome loss': 0.10947536120801864, 'Total loss': 0.10947536120801864}
2022-12-31 05:09:41,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:41,609 INFO:     Epoch: 98
2022-12-31 05:09:43,207 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3984159876902898, 'Total loss': 0.3984159876902898} | train loss {'Reaction outcome loss': 0.10986299646912559, 'Total loss': 0.10986299646912559}
2022-12-31 05:09:43,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:43,208 INFO:     Epoch: 99
2022-12-31 05:09:44,813 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4429224153359731, 'Total loss': 0.4429224153359731} | train loss {'Reaction outcome loss': 0.10635469768933214, 'Total loss': 0.10635469768933214}
2022-12-31 05:09:44,813 INFO:     Best model found after epoch 18 of 100.
2022-12-31 05:09:44,814 INFO:   Done with stage: TRAINING
2022-12-31 05:09:44,814 INFO:   Starting stage: EVALUATION
2022-12-31 05:09:44,955 INFO:   Done with stage: EVALUATION
2022-12-31 05:09:44,956 INFO:   Leaving out SEQ value Fold_4
2022-12-31 05:09:44,968 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 05:09:44,969 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:09:45,624 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:09:45,625 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:09:45,696 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:09:45,696 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:09:45,696 INFO:     No hyperparam tuning for this model
2022-12-31 05:09:45,696 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:09:45,696 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:09:45,697 INFO:     None feature selector for col prot
2022-12-31 05:09:45,697 INFO:     None feature selector for col prot
2022-12-31 05:09:45,697 INFO:     None feature selector for col prot
2022-12-31 05:09:45,698 INFO:     None feature selector for col chem
2022-12-31 05:09:45,698 INFO:     None feature selector for col chem
2022-12-31 05:09:45,698 INFO:     None feature selector for col chem
2022-12-31 05:09:45,698 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:09:45,698 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:09:45,700 INFO:     Number of params in model 224011
2022-12-31 05:09:45,703 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:09:45,704 INFO:   Starting stage: TRAINING
2022-12-31 05:09:45,748 INFO:     Val loss before train {'Reaction outcome loss': 0.9873640636603037, 'Total loss': 0.9873640636603037}
2022-12-31 05:09:45,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:45,748 INFO:     Epoch: 0
2022-12-31 05:09:47,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5816994587580363, 'Total loss': 0.5816994587580363} | train loss {'Reaction outcome loss': 0.7936246165407264, 'Total loss': 0.7936246165407264}
2022-12-31 05:09:47,410 INFO:     Found new best model at epoch 0
2022-12-31 05:09:47,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:47,411 INFO:     Epoch: 1
2022-12-31 05:09:49,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5342359602451324, 'Total loss': 0.5342359602451324} | train loss {'Reaction outcome loss': 0.5173586348226354, 'Total loss': 0.5173586348226354}
2022-12-31 05:09:49,025 INFO:     Found new best model at epoch 1
2022-12-31 05:09:49,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:49,026 INFO:     Epoch: 2
2022-12-31 05:09:50,653 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48132893641789753, 'Total loss': 0.48132893641789753} | train loss {'Reaction outcome loss': 0.45035094135719944, 'Total loss': 0.45035094135719944}
2022-12-31 05:09:50,654 INFO:     Found new best model at epoch 2
2022-12-31 05:09:50,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:50,655 INFO:     Epoch: 3
2022-12-31 05:09:52,324 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48012704650561017, 'Total loss': 0.48012704650561017} | train loss {'Reaction outcome loss': 0.40603568730371525, 'Total loss': 0.40603568730371525}
2022-12-31 05:09:52,324 INFO:     Found new best model at epoch 3
2022-12-31 05:09:52,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:52,325 INFO:     Epoch: 4
2022-12-31 05:09:53,947 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44538471500078836, 'Total loss': 0.44538471500078836} | train loss {'Reaction outcome loss': 0.37856202131466743, 'Total loss': 0.37856202131466743}
2022-12-31 05:09:53,947 INFO:     Found new best model at epoch 4
2022-12-31 05:09:53,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:53,948 INFO:     Epoch: 5
2022-12-31 05:09:55,574 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4318497637907664, 'Total loss': 0.4318497637907664} | train loss {'Reaction outcome loss': 0.35539060182842536, 'Total loss': 0.35539060182842536}
2022-12-31 05:09:55,574 INFO:     Found new best model at epoch 5
2022-12-31 05:09:55,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:55,576 INFO:     Epoch: 6
2022-12-31 05:09:57,205 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4341617961724599, 'Total loss': 0.4341617961724599} | train loss {'Reaction outcome loss': 0.33096423661773383, 'Total loss': 0.33096423661773383}
2022-12-31 05:09:57,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:57,205 INFO:     Epoch: 7
2022-12-31 05:09:58,837 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4171532094478607, 'Total loss': 0.4171532094478607} | train loss {'Reaction outcome loss': 0.3150715101039582, 'Total loss': 0.3150715101039582}
2022-12-31 05:09:58,837 INFO:     Found new best model at epoch 7
2022-12-31 05:09:58,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:09:58,838 INFO:     Epoch: 8
2022-12-31 05:10:00,462 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4415288418531418, 'Total loss': 0.4415288418531418} | train loss {'Reaction outcome loss': 0.30259721459894834, 'Total loss': 0.30259721459894834}
2022-12-31 05:10:00,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:00,462 INFO:     Epoch: 9
2022-12-31 05:10:02,099 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43131064971288047, 'Total loss': 0.43131064971288047} | train loss {'Reaction outcome loss': 0.29316675270292303, 'Total loss': 0.29316675270292303}
2022-12-31 05:10:02,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:02,100 INFO:     Epoch: 10
2022-12-31 05:10:03,728 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47717832823594414, 'Total loss': 0.47717832823594414} | train loss {'Reaction outcome loss': 0.27641946287146546, 'Total loss': 0.27641946287146546}
2022-12-31 05:10:03,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:03,728 INFO:     Epoch: 11
2022-12-31 05:10:05,370 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44757519563039144, 'Total loss': 0.44757519563039144} | train loss {'Reaction outcome loss': 0.2660985239361167, 'Total loss': 0.2660985239361167}
2022-12-31 05:10:05,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:05,370 INFO:     Epoch: 12
2022-12-31 05:10:07,011 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43773310283819833, 'Total loss': 0.43773310283819833} | train loss {'Reaction outcome loss': 0.2587589161867269, 'Total loss': 0.2587589161867269}
2022-12-31 05:10:07,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:07,011 INFO:     Epoch: 13
2022-12-31 05:10:08,643 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44633491734663644, 'Total loss': 0.44633491734663644} | train loss {'Reaction outcome loss': 0.2486979151245489, 'Total loss': 0.2486979151245489}
2022-12-31 05:10:08,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:08,644 INFO:     Epoch: 14
2022-12-31 05:10:10,277 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4170301785071691, 'Total loss': 0.4170301785071691} | train loss {'Reaction outcome loss': 0.24163350370789907, 'Total loss': 0.24163350370789907}
2022-12-31 05:10:10,277 INFO:     Found new best model at epoch 14
2022-12-31 05:10:10,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:10,278 INFO:     Epoch: 15
2022-12-31 05:10:11,914 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4300074279308319, 'Total loss': 0.4300074279308319} | train loss {'Reaction outcome loss': 0.23486675683825886, 'Total loss': 0.23486675683825886}
2022-12-31 05:10:11,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:11,914 INFO:     Epoch: 16
2022-12-31 05:10:13,528 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43226986229419706, 'Total loss': 0.43226986229419706} | train loss {'Reaction outcome loss': 0.22337715958483814, 'Total loss': 0.22337715958483814}
2022-12-31 05:10:13,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:13,529 INFO:     Epoch: 17
2022-12-31 05:10:15,149 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4429054363320271, 'Total loss': 0.4429054363320271} | train loss {'Reaction outcome loss': 0.22060037401609042, 'Total loss': 0.22060037401609042}
2022-12-31 05:10:15,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:15,149 INFO:     Epoch: 18
2022-12-31 05:10:16,772 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4448726922273636, 'Total loss': 0.4448726922273636} | train loss {'Reaction outcome loss': 0.2135906747545684, 'Total loss': 0.2135906747545684}
2022-12-31 05:10:16,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:16,772 INFO:     Epoch: 19
2022-12-31 05:10:18,393 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43995839059352876, 'Total loss': 0.43995839059352876} | train loss {'Reaction outcome loss': 0.20819357514300715, 'Total loss': 0.20819357514300715}
2022-12-31 05:10:18,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:18,394 INFO:     Epoch: 20
2022-12-31 05:10:20,028 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4304652710755666, 'Total loss': 0.4304652710755666} | train loss {'Reaction outcome loss': 0.20382298327753798, 'Total loss': 0.20382298327753798}
2022-12-31 05:10:20,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:20,028 INFO:     Epoch: 21
2022-12-31 05:10:21,663 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4478940655787786, 'Total loss': 0.4478940655787786} | train loss {'Reaction outcome loss': 0.19897393536643002, 'Total loss': 0.19897393536643002}
2022-12-31 05:10:21,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:21,664 INFO:     Epoch: 22
2022-12-31 05:10:23,285 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4382556160291036, 'Total loss': 0.4382556160291036} | train loss {'Reaction outcome loss': 0.19498859330446927, 'Total loss': 0.19498859330446927}
2022-12-31 05:10:23,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:23,285 INFO:     Epoch: 23
2022-12-31 05:10:24,907 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44792624562978745, 'Total loss': 0.44792624562978745} | train loss {'Reaction outcome loss': 0.19206703864441452, 'Total loss': 0.19206703864441452}
2022-12-31 05:10:24,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:24,907 INFO:     Epoch: 24
2022-12-31 05:10:26,529 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4179783428708712, 'Total loss': 0.4179783428708712} | train loss {'Reaction outcome loss': 0.1871701260752949, 'Total loss': 0.1871701260752949}
2022-12-31 05:10:26,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:26,529 INFO:     Epoch: 25
2022-12-31 05:10:28,153 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4456068555514018, 'Total loss': 0.4456068555514018} | train loss {'Reaction outcome loss': 0.18714016162208702, 'Total loss': 0.18714016162208702}
2022-12-31 05:10:28,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:28,153 INFO:     Epoch: 26
2022-12-31 05:10:29,785 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45453244373202323, 'Total loss': 0.45453244373202323} | train loss {'Reaction outcome loss': 0.1786692422488536, 'Total loss': 0.1786692422488536}
2022-12-31 05:10:29,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:29,785 INFO:     Epoch: 27
2022-12-31 05:10:31,413 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43623164494832356, 'Total loss': 0.43623164494832356} | train loss {'Reaction outcome loss': 0.17573116934229535, 'Total loss': 0.17573116934229535}
2022-12-31 05:10:31,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:31,414 INFO:     Epoch: 28
2022-12-31 05:10:33,047 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47106319467226665, 'Total loss': 0.47106319467226665} | train loss {'Reaction outcome loss': 0.17357218533162605, 'Total loss': 0.17357218533162605}
2022-12-31 05:10:33,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:33,048 INFO:     Epoch: 29
2022-12-31 05:10:34,679 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4405445178349813, 'Total loss': 0.4405445178349813} | train loss {'Reaction outcome loss': 0.17217610527287214, 'Total loss': 0.17217610527287214}
2022-12-31 05:10:34,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:34,679 INFO:     Epoch: 30
2022-12-31 05:10:36,302 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4443105508883794, 'Total loss': 0.4443105508883794} | train loss {'Reaction outcome loss': 0.1684928636843278, 'Total loss': 0.1684928636843278}
2022-12-31 05:10:36,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:36,302 INFO:     Epoch: 31
2022-12-31 05:10:37,927 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44029137392838796, 'Total loss': 0.44029137392838796} | train loss {'Reaction outcome loss': 0.16484529658183725, 'Total loss': 0.16484529658183725}
2022-12-31 05:10:37,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:37,927 INFO:     Epoch: 32
2022-12-31 05:10:39,541 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4367519577344259, 'Total loss': 0.4367519577344259} | train loss {'Reaction outcome loss': 0.1637737300879043, 'Total loss': 0.1637737300879043}
2022-12-31 05:10:39,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:39,542 INFO:     Epoch: 33
2022-12-31 05:10:41,170 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45238056977589924, 'Total loss': 0.45238056977589924} | train loss {'Reaction outcome loss': 0.1627459181640768, 'Total loss': 0.1627459181640768}
2022-12-31 05:10:41,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:41,170 INFO:     Epoch: 34
2022-12-31 05:10:42,838 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43278565605481467, 'Total loss': 0.43278565605481467} | train loss {'Reaction outcome loss': 0.15593848871369761, 'Total loss': 0.15593848871369761}
2022-12-31 05:10:42,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:42,838 INFO:     Epoch: 35
2022-12-31 05:10:44,506 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4520290245612462, 'Total loss': 0.4520290245612462} | train loss {'Reaction outcome loss': 0.15569981126726642, 'Total loss': 0.15569981126726642}
2022-12-31 05:10:44,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:44,507 INFO:     Epoch: 36
2022-12-31 05:10:46,132 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4455221027135849, 'Total loss': 0.4455221027135849} | train loss {'Reaction outcome loss': 0.15350354031494917, 'Total loss': 0.15350354031494917}
2022-12-31 05:10:46,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:46,133 INFO:     Epoch: 37
2022-12-31 05:10:47,754 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.425979800025622, 'Total loss': 0.425979800025622} | train loss {'Reaction outcome loss': 0.15182341003642563, 'Total loss': 0.15182341003642563}
2022-12-31 05:10:47,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:47,754 INFO:     Epoch: 38
2022-12-31 05:10:49,383 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42907475928465527, 'Total loss': 0.42907475928465527} | train loss {'Reaction outcome loss': 0.15048526130475454, 'Total loss': 0.15048526130475454}
2022-12-31 05:10:49,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:49,384 INFO:     Epoch: 39
2022-12-31 05:10:51,008 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4521813584491611, 'Total loss': 0.4521813584491611} | train loss {'Reaction outcome loss': 0.14760642905218613, 'Total loss': 0.14760642905218613}
2022-12-31 05:10:51,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:51,008 INFO:     Epoch: 40
2022-12-31 05:10:52,634 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42114391922950745, 'Total loss': 0.42114391922950745} | train loss {'Reaction outcome loss': 0.14763230134292576, 'Total loss': 0.14763230134292576}
2022-12-31 05:10:52,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:52,635 INFO:     Epoch: 41
2022-12-31 05:10:54,263 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4304442971944809, 'Total loss': 0.4304442971944809} | train loss {'Reaction outcome loss': 0.1443878843311207, 'Total loss': 0.1443878843311207}
2022-12-31 05:10:54,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:54,263 INFO:     Epoch: 42
2022-12-31 05:10:55,931 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4332305371761322, 'Total loss': 0.4332305371761322} | train loss {'Reaction outcome loss': 0.14631381452702227, 'Total loss': 0.14631381452702227}
2022-12-31 05:10:55,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:55,932 INFO:     Epoch: 43
2022-12-31 05:10:57,553 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44875783920288087, 'Total loss': 0.44875783920288087} | train loss {'Reaction outcome loss': 0.1438469374989452, 'Total loss': 0.1438469374989452}
2022-12-31 05:10:57,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:57,553 INFO:     Epoch: 44
2022-12-31 05:10:59,170 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4514424030979474, 'Total loss': 0.4514424030979474} | train loss {'Reaction outcome loss': 0.1432652953904566, 'Total loss': 0.1432652953904566}
2022-12-31 05:10:59,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:10:59,170 INFO:     Epoch: 45
2022-12-31 05:11:00,798 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4301474799712499, 'Total loss': 0.4301474799712499} | train loss {'Reaction outcome loss': 0.1350380627821714, 'Total loss': 0.1350380627821714}
2022-12-31 05:11:00,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:00,798 INFO:     Epoch: 46
2022-12-31 05:11:02,426 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4331955581903458, 'Total loss': 0.4331955581903458} | train loss {'Reaction outcome loss': 0.13946395736046485, 'Total loss': 0.13946395736046485}
2022-12-31 05:11:02,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:02,426 INFO:     Epoch: 47
2022-12-31 05:11:04,050 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4670646031697591, 'Total loss': 0.4670646031697591} | train loss {'Reaction outcome loss': 0.13679436989303423, 'Total loss': 0.13679436989303423}
2022-12-31 05:11:04,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:04,052 INFO:     Epoch: 48
2022-12-31 05:11:05,681 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43336196392774584, 'Total loss': 0.43336196392774584} | train loss {'Reaction outcome loss': 0.13419478832465, 'Total loss': 0.13419478832465}
2022-12-31 05:11:05,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:05,681 INFO:     Epoch: 49
2022-12-31 05:11:07,316 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4455142915248871, 'Total loss': 0.4455142915248871} | train loss {'Reaction outcome loss': 0.13345312258221936, 'Total loss': 0.13345312258221936}
2022-12-31 05:11:07,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:07,316 INFO:     Epoch: 50
2022-12-31 05:11:08,985 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4450233926375707, 'Total loss': 0.4450233926375707} | train loss {'Reaction outcome loss': 0.14019408786084356, 'Total loss': 0.14019408786084356}
2022-12-31 05:11:08,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:08,985 INFO:     Epoch: 51
2022-12-31 05:11:10,654 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4512926081816355, 'Total loss': 0.4512926081816355} | train loss {'Reaction outcome loss': 0.13873160677871227, 'Total loss': 0.13873160677871227}
2022-12-31 05:11:10,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:10,655 INFO:     Epoch: 52
2022-12-31 05:11:12,279 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4232064962387085, 'Total loss': 0.4232064962387085} | train loss {'Reaction outcome loss': 0.13244521179629845, 'Total loss': 0.13244521179629845}
2022-12-31 05:11:12,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:12,280 INFO:     Epoch: 53
2022-12-31 05:11:13,909 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45397253930568693, 'Total loss': 0.45397253930568693} | train loss {'Reaction outcome loss': 0.13253702748472726, 'Total loss': 0.13253702748472726}
2022-12-31 05:11:13,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:13,909 INFO:     Epoch: 54
2022-12-31 05:11:15,538 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44675851861635846, 'Total loss': 0.44675851861635846} | train loss {'Reaction outcome loss': 0.13088827366211084, 'Total loss': 0.13088827366211084}
2022-12-31 05:11:15,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:15,538 INFO:     Epoch: 55
2022-12-31 05:11:17,170 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4318193544944127, 'Total loss': 0.4318193544944127} | train loss {'Reaction outcome loss': 0.1321356002046367, 'Total loss': 0.1321356002046367}
2022-12-31 05:11:17,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:17,170 INFO:     Epoch: 56
2022-12-31 05:11:18,803 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45883052150408427, 'Total loss': 0.45883052150408427} | train loss {'Reaction outcome loss': 0.12726735269200284, 'Total loss': 0.12726735269200284}
2022-12-31 05:11:18,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:18,804 INFO:     Epoch: 57
2022-12-31 05:11:20,443 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42029235462347664, 'Total loss': 0.42029235462347664} | train loss {'Reaction outcome loss': 0.12795650151084154, 'Total loss': 0.12795650151084154}
2022-12-31 05:11:20,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:20,443 INFO:     Epoch: 58
2022-12-31 05:11:22,069 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44773385574420294, 'Total loss': 0.44773385574420294} | train loss {'Reaction outcome loss': 0.13000851519076348, 'Total loss': 0.13000851519076348}
2022-12-31 05:11:22,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:22,069 INFO:     Epoch: 59
2022-12-31 05:11:23,709 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47518926362196606, 'Total loss': 0.47518926362196606} | train loss {'Reaction outcome loss': 0.1327875043410095, 'Total loss': 0.1327875043410095}
2022-12-31 05:11:23,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:23,709 INFO:     Epoch: 60
2022-12-31 05:11:25,340 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44882505337397255, 'Total loss': 0.44882505337397255} | train loss {'Reaction outcome loss': 0.13324429038979302, 'Total loss': 0.13324429038979302}
2022-12-31 05:11:25,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:25,340 INFO:     Epoch: 61
2022-12-31 05:11:26,976 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48437903126080833, 'Total loss': 0.48437903126080833} | train loss {'Reaction outcome loss': 0.12972912245803253, 'Total loss': 0.12972912245803253}
2022-12-31 05:11:26,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:26,977 INFO:     Epoch: 62
2022-12-31 05:11:28,617 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4304892897605896, 'Total loss': 0.4304892897605896} | train loss {'Reaction outcome loss': 0.12687854928095632, 'Total loss': 0.12687854928095632}
2022-12-31 05:11:28,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:28,617 INFO:     Epoch: 63
2022-12-31 05:11:30,252 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42632146974404656, 'Total loss': 0.42632146974404656} | train loss {'Reaction outcome loss': 0.12465794434575936, 'Total loss': 0.12465794434575936}
2022-12-31 05:11:30,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:30,252 INFO:     Epoch: 64
2022-12-31 05:11:31,890 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41915214161078135, 'Total loss': 0.41915214161078135} | train loss {'Reaction outcome loss': 0.1317197937192227, 'Total loss': 0.1317197937192227}
2022-12-31 05:11:31,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:31,891 INFO:     Epoch: 65
2022-12-31 05:11:33,559 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42402948687473935, 'Total loss': 0.42402948687473935} | train loss {'Reaction outcome loss': 0.1234626096811159, 'Total loss': 0.1234626096811159}
2022-12-31 05:11:33,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:33,559 INFO:     Epoch: 66
2022-12-31 05:11:35,188 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4120830198129018, 'Total loss': 0.4120830198129018} | train loss {'Reaction outcome loss': 0.12012763062175968, 'Total loss': 0.12012763062175968}
2022-12-31 05:11:35,189 INFO:     Found new best model at epoch 66
2022-12-31 05:11:35,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:35,190 INFO:     Epoch: 67
2022-12-31 05:11:36,815 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43210209558407464, 'Total loss': 0.43210209558407464} | train loss {'Reaction outcome loss': 0.12125442106115367, 'Total loss': 0.12125442106115367}
2022-12-31 05:11:36,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:36,815 INFO:     Epoch: 68
2022-12-31 05:11:38,442 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43750721563895545, 'Total loss': 0.43750721563895545} | train loss {'Reaction outcome loss': 0.12365259584510155, 'Total loss': 0.12365259584510155}
2022-12-31 05:11:38,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:38,442 INFO:     Epoch: 69
2022-12-31 05:11:40,092 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46256594931085904, 'Total loss': 0.46256594931085904} | train loss {'Reaction outcome loss': 0.12190520435753228, 'Total loss': 0.12190520435753228}
2022-12-31 05:11:40,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:40,092 INFO:     Epoch: 70
2022-12-31 05:11:41,725 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4522852639357249, 'Total loss': 0.4522852639357249} | train loss {'Reaction outcome loss': 0.12162260253432909, 'Total loss': 0.12162260253432909}
2022-12-31 05:11:41,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:41,726 INFO:     Epoch: 71
2022-12-31 05:11:43,347 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4159221351146698, 'Total loss': 0.4159221351146698} | train loss {'Reaction outcome loss': 0.12336760089188034, 'Total loss': 0.12336760089188034}
2022-12-31 05:11:43,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:43,348 INFO:     Epoch: 72
2022-12-31 05:11:45,018 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4531135787566503, 'Total loss': 0.4531135787566503} | train loss {'Reaction outcome loss': 0.12696232504147484, 'Total loss': 0.12696232504147484}
2022-12-31 05:11:45,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:45,019 INFO:     Epoch: 73
2022-12-31 05:11:46,647 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4664549012978872, 'Total loss': 0.4664549012978872} | train loss {'Reaction outcome loss': 0.12458747427150715, 'Total loss': 0.12458747427150715}
2022-12-31 05:11:46,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:46,647 INFO:     Epoch: 74
2022-12-31 05:11:48,315 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44694751302401226, 'Total loss': 0.44694751302401226} | train loss {'Reaction outcome loss': 0.11826511180290569, 'Total loss': 0.11826511180290569}
2022-12-31 05:11:48,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:48,315 INFO:     Epoch: 75
2022-12-31 05:11:49,948 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4538207232952118, 'Total loss': 0.4538207232952118} | train loss {'Reaction outcome loss': 0.11886830666919478, 'Total loss': 0.11886830666919478}
2022-12-31 05:11:49,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:49,948 INFO:     Epoch: 76
2022-12-31 05:11:51,636 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4288829912741979, 'Total loss': 0.4288829912741979} | train loss {'Reaction outcome loss': 0.11904385778716756, 'Total loss': 0.11904385778716756}
2022-12-31 05:11:51,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:51,637 INFO:     Epoch: 77
2022-12-31 05:11:53,334 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4523854687809944, 'Total loss': 0.4523854687809944} | train loss {'Reaction outcome loss': 0.1182906883533385, 'Total loss': 0.1182906883533385}
2022-12-31 05:11:53,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:53,334 INFO:     Epoch: 78
2022-12-31 05:11:54,965 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4516619674861431, 'Total loss': 0.4516619674861431} | train loss {'Reaction outcome loss': 0.11958673660431582, 'Total loss': 0.11958673660431582}
2022-12-31 05:11:54,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:54,966 INFO:     Epoch: 79
2022-12-31 05:11:56,629 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44570056597391766, 'Total loss': 0.44570056597391766} | train loss {'Reaction outcome loss': 0.11574652783122143, 'Total loss': 0.11574652783122143}
2022-12-31 05:11:56,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:56,629 INFO:     Epoch: 80
2022-12-31 05:11:58,246 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4436264862616857, 'Total loss': 0.4436264862616857} | train loss {'Reaction outcome loss': 0.1154652433268161, 'Total loss': 0.1154652433268161}
2022-12-31 05:11:58,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:58,246 INFO:     Epoch: 81
2022-12-31 05:11:59,916 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45189415315786996, 'Total loss': 0.45189415315786996} | train loss {'Reaction outcome loss': 0.1229079727819761, 'Total loss': 0.1229079727819761}
2022-12-31 05:11:59,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:11:59,916 INFO:     Epoch: 82
2022-12-31 05:12:01,549 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4357386901974678, 'Total loss': 0.4357386901974678} | train loss {'Reaction outcome loss': 0.12275761781371324, 'Total loss': 0.12275761781371324}
2022-12-31 05:12:01,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:01,549 INFO:     Epoch: 83
2022-12-31 05:12:03,168 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43821328481038413, 'Total loss': 0.43821328481038413} | train loss {'Reaction outcome loss': 0.12021257204175104, 'Total loss': 0.12021257204175104}
2022-12-31 05:12:03,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:03,169 INFO:     Epoch: 84
2022-12-31 05:12:04,792 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4426456997791926, 'Total loss': 0.4426456997791926} | train loss {'Reaction outcome loss': 0.12193769533926829, 'Total loss': 0.12193769533926829}
2022-12-31 05:12:04,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:04,792 INFO:     Epoch: 85
2022-12-31 05:12:06,417 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43939138352870943, 'Total loss': 0.43939138352870943} | train loss {'Reaction outcome loss': 0.12139871525695876, 'Total loss': 0.12139871525695876}
2022-12-31 05:12:06,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:06,417 INFO:     Epoch: 86
2022-12-31 05:12:08,041 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4568597381313642, 'Total loss': 0.4568597381313642} | train loss {'Reaction outcome loss': 0.12024940114589375, 'Total loss': 0.12024940114589375}
2022-12-31 05:12:08,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:08,041 INFO:     Epoch: 87
2022-12-31 05:12:09,664 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4563541243473689, 'Total loss': 0.4563541243473689} | train loss {'Reaction outcome loss': 0.11868713012751905, 'Total loss': 0.11868713012751905}
2022-12-31 05:12:09,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:09,665 INFO:     Epoch: 88
2022-12-31 05:12:11,284 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4362847050031026, 'Total loss': 0.4362847050031026} | train loss {'Reaction outcome loss': 0.11705190165889608, 'Total loss': 0.11705190165889608}
2022-12-31 05:12:11,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:11,285 INFO:     Epoch: 89
2022-12-31 05:12:12,911 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.455681756635507, 'Total loss': 0.455681756635507} | train loss {'Reaction outcome loss': 0.11451054531879158, 'Total loss': 0.11451054531879158}
2022-12-31 05:12:12,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:12,911 INFO:     Epoch: 90
2022-12-31 05:12:14,539 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4436878641446432, 'Total loss': 0.4436878641446432} | train loss {'Reaction outcome loss': 0.11637924089422617, 'Total loss': 0.11637924089422617}
2022-12-31 05:12:14,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:14,539 INFO:     Epoch: 91
2022-12-31 05:12:16,206 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4238437776764234, 'Total loss': 0.4238437776764234} | train loss {'Reaction outcome loss': 0.11285350988501354, 'Total loss': 0.11285350988501354}
2022-12-31 05:12:16,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:16,206 INFO:     Epoch: 92
2022-12-31 05:12:17,825 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4601130853096644, 'Total loss': 0.4601130853096644} | train loss {'Reaction outcome loss': 0.11523062226258299, 'Total loss': 0.11523062226258299}
2022-12-31 05:12:17,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:17,826 INFO:     Epoch: 93
2022-12-31 05:12:19,449 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4488349715868632, 'Total loss': 0.4488349715868632} | train loss {'Reaction outcome loss': 0.11317552321351769, 'Total loss': 0.11317552321351769}
2022-12-31 05:12:19,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:19,449 INFO:     Epoch: 94
2022-12-31 05:12:21,073 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44415420095125835, 'Total loss': 0.44415420095125835} | train loss {'Reaction outcome loss': 0.11611152766860806, 'Total loss': 0.11611152766860806}
2022-12-31 05:12:21,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:21,074 INFO:     Epoch: 95
2022-12-31 05:12:22,705 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43072587822874386, 'Total loss': 0.43072587822874386} | train loss {'Reaction outcome loss': 0.11654649496529022, 'Total loss': 0.11654649496529022}
2022-12-31 05:12:22,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:22,705 INFO:     Epoch: 96
2022-12-31 05:12:24,340 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.411943061153094, 'Total loss': 0.411943061153094} | train loss {'Reaction outcome loss': 0.11394383829080294, 'Total loss': 0.11394383829080294}
2022-12-31 05:12:24,340 INFO:     Found new best model at epoch 96
2022-12-31 05:12:24,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:24,341 INFO:     Epoch: 97
2022-12-31 05:12:25,964 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44857019384702046, 'Total loss': 0.44857019384702046} | train loss {'Reaction outcome loss': 0.12080293518511262, 'Total loss': 0.12080293518511262}
2022-12-31 05:12:25,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:25,964 INFO:     Epoch: 98
2022-12-31 05:12:27,596 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43326115409533184, 'Total loss': 0.43326115409533184} | train loss {'Reaction outcome loss': 0.11238946848454807, 'Total loss': 0.11238946848454807}
2022-12-31 05:12:27,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:27,596 INFO:     Epoch: 99
2022-12-31 05:12:29,218 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44224778612454735, 'Total loss': 0.44224778612454735} | train loss {'Reaction outcome loss': 0.11569522746539396, 'Total loss': 0.11569522746539396}
2022-12-31 05:12:29,218 INFO:     Best model found after epoch 97 of 100.
2022-12-31 05:12:29,218 INFO:   Done with stage: TRAINING
2022-12-31 05:12:29,218 INFO:   Starting stage: EVALUATION
2022-12-31 05:12:29,342 INFO:   Done with stage: EVALUATION
2022-12-31 05:12:29,343 INFO:   Leaving out SEQ value Fold_5
2022-12-31 05:12:29,355 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 05:12:29,355 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:12:30,007 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:12:30,008 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:12:30,080 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:12:30,080 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:12:30,081 INFO:     No hyperparam tuning for this model
2022-12-31 05:12:30,081 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:12:30,081 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:12:30,081 INFO:     None feature selector for col prot
2022-12-31 05:12:30,081 INFO:     None feature selector for col prot
2022-12-31 05:12:30,082 INFO:     None feature selector for col prot
2022-12-31 05:12:30,082 INFO:     None feature selector for col chem
2022-12-31 05:12:30,082 INFO:     None feature selector for col chem
2022-12-31 05:12:30,082 INFO:     None feature selector for col chem
2022-12-31 05:12:30,082 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:12:30,082 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:12:30,084 INFO:     Number of params in model 224011
2022-12-31 05:12:30,088 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:12:30,088 INFO:   Starting stage: TRAINING
2022-12-31 05:12:30,134 INFO:     Val loss before train {'Reaction outcome loss': 0.970599647363027, 'Total loss': 0.970599647363027}
2022-12-31 05:12:30,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:30,134 INFO:     Epoch: 0
2022-12-31 05:12:31,768 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5169981529315313, 'Total loss': 0.5169981529315313} | train loss {'Reaction outcome loss': 0.7797695326245648, 'Total loss': 0.7797695326245648}
2022-12-31 05:12:31,768 INFO:     Found new best model at epoch 0
2022-12-31 05:12:31,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:31,769 INFO:     Epoch: 1
2022-12-31 05:12:33,402 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45304533541202546, 'Total loss': 0.45304533541202546} | train loss {'Reaction outcome loss': 0.5160232490258096, 'Total loss': 0.5160232490258096}
2022-12-31 05:12:33,402 INFO:     Found new best model at epoch 1
2022-12-31 05:12:33,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:33,403 INFO:     Epoch: 2
2022-12-31 05:12:35,027 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4361700336138407, 'Total loss': 0.4361700336138407} | train loss {'Reaction outcome loss': 0.44402405786385174, 'Total loss': 0.44402405786385174}
2022-12-31 05:12:35,027 INFO:     Found new best model at epoch 2
2022-12-31 05:12:35,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:35,028 INFO:     Epoch: 3
2022-12-31 05:12:36,660 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.40554228524367014, 'Total loss': 0.40554228524367014} | train loss {'Reaction outcome loss': 0.4059112908231222, 'Total loss': 0.4059112908231222}
2022-12-31 05:12:36,661 INFO:     Found new best model at epoch 3
2022-12-31 05:12:36,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:36,662 INFO:     Epoch: 4
2022-12-31 05:12:38,286 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4051373650630315, 'Total loss': 0.4051373650630315} | train loss {'Reaction outcome loss': 0.3766672541303325, 'Total loss': 0.3766672541303325}
2022-12-31 05:12:38,286 INFO:     Found new best model at epoch 4
2022-12-31 05:12:38,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:38,288 INFO:     Epoch: 5
2022-12-31 05:12:39,919 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.400518207748731, 'Total loss': 0.400518207748731} | train loss {'Reaction outcome loss': 0.3531159298891195, 'Total loss': 0.3531159298891195}
2022-12-31 05:12:39,919 INFO:     Found new best model at epoch 5
2022-12-31 05:12:39,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:39,920 INFO:     Epoch: 6
2022-12-31 05:12:41,551 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3956986288229624, 'Total loss': 0.3956986288229624} | train loss {'Reaction outcome loss': 0.33494484249757944, 'Total loss': 0.33494484249757944}
2022-12-31 05:12:41,551 INFO:     Found new best model at epoch 6
2022-12-31 05:12:41,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:41,552 INFO:     Epoch: 7
2022-12-31 05:12:43,185 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40328817889094354, 'Total loss': 0.40328817889094354} | train loss {'Reaction outcome loss': 0.3190597602525988, 'Total loss': 0.3190597602525988}
2022-12-31 05:12:43,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:43,185 INFO:     Epoch: 8
2022-12-31 05:12:44,813 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3917459547519684, 'Total loss': 0.3917459547519684} | train loss {'Reaction outcome loss': 0.30035736228907584, 'Total loss': 0.30035736228907584}
2022-12-31 05:12:44,813 INFO:     Found new best model at epoch 8
2022-12-31 05:12:44,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:44,814 INFO:     Epoch: 9
2022-12-31 05:12:46,450 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39583893020947775, 'Total loss': 0.39583893020947775} | train loss {'Reaction outcome loss': 0.2891833361520664, 'Total loss': 0.2891833361520664}
2022-12-31 05:12:46,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:46,451 INFO:     Epoch: 10
2022-12-31 05:12:48,065 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4045616567134857, 'Total loss': 0.4045616567134857} | train loss {'Reaction outcome loss': 0.27824520061485175, 'Total loss': 0.27824520061485175}
2022-12-31 05:12:48,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:48,065 INFO:     Epoch: 11
2022-12-31 05:12:49,683 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3910091499487559, 'Total loss': 0.3910091499487559} | train loss {'Reaction outcome loss': 0.2678839141496252, 'Total loss': 0.2678839141496252}
2022-12-31 05:12:49,683 INFO:     Found new best model at epoch 11
2022-12-31 05:12:49,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:49,684 INFO:     Epoch: 12
2022-12-31 05:12:51,301 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3798717975616455, 'Total loss': 0.3798717975616455} | train loss {'Reaction outcome loss': 0.25496276980434085, 'Total loss': 0.25496276980434085}
2022-12-31 05:12:51,301 INFO:     Found new best model at epoch 12
2022-12-31 05:12:51,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:51,303 INFO:     Epoch: 13
2022-12-31 05:12:52,917 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4120006039738655, 'Total loss': 0.4120006039738655} | train loss {'Reaction outcome loss': 0.2492593359941825, 'Total loss': 0.2492593359941825}
2022-12-31 05:12:52,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:52,918 INFO:     Epoch: 14
2022-12-31 05:12:54,542 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39884825348854064, 'Total loss': 0.39884825348854064} | train loss {'Reaction outcome loss': 0.24151814060574833, 'Total loss': 0.24151814060574833}
2022-12-31 05:12:54,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:54,542 INFO:     Epoch: 15
2022-12-31 05:12:56,200 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38978198170661926, 'Total loss': 0.38978198170661926} | train loss {'Reaction outcome loss': 0.2298629787424411, 'Total loss': 0.2298629787424411}
2022-12-31 05:12:56,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:56,201 INFO:     Epoch: 16
2022-12-31 05:12:57,820 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.404835569858551, 'Total loss': 0.404835569858551} | train loss {'Reaction outcome loss': 0.22786662934704377, 'Total loss': 0.22786662934704377}
2022-12-31 05:12:57,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:57,820 INFO:     Epoch: 17
2022-12-31 05:12:59,437 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39541704853375753, 'Total loss': 0.39541704853375753} | train loss {'Reaction outcome loss': 0.21814150725649367, 'Total loss': 0.21814150725649367}
2022-12-31 05:12:59,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:12:59,437 INFO:     Epoch: 18
2022-12-31 05:13:01,055 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40737319787343346, 'Total loss': 0.40737319787343346} | train loss {'Reaction outcome loss': 0.21582765933731402, 'Total loss': 0.21582765933731402}
2022-12-31 05:13:01,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:01,055 INFO:     Epoch: 19
2022-12-31 05:13:02,676 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3990668535232544, 'Total loss': 0.3990668535232544} | train loss {'Reaction outcome loss': 0.21084303429034212, 'Total loss': 0.21084303429034212}
2022-12-31 05:13:02,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:02,676 INFO:     Epoch: 20
2022-12-31 05:13:04,345 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.394415320456028, 'Total loss': 0.394415320456028} | train loss {'Reaction outcome loss': 0.2068817028002511, 'Total loss': 0.2068817028002511}
2022-12-31 05:13:04,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:04,345 INFO:     Epoch: 21
2022-12-31 05:13:05,978 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3855266273021698, 'Total loss': 0.3855266273021698} | train loss {'Reaction outcome loss': 0.1987321949017567, 'Total loss': 0.1987321949017567}
2022-12-31 05:13:05,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:05,979 INFO:     Epoch: 22
2022-12-31 05:13:07,603 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4045904298623403, 'Total loss': 0.4045904298623403} | train loss {'Reaction outcome loss': 0.19511896570882212, 'Total loss': 0.19511896570882212}
2022-12-31 05:13:07,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:07,603 INFO:     Epoch: 23
2022-12-31 05:13:09,271 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4236875087022781, 'Total loss': 0.4236875087022781} | train loss {'Reaction outcome loss': 0.1900711820632327, 'Total loss': 0.1900711820632327}
2022-12-31 05:13:09,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:09,272 INFO:     Epoch: 24
2022-12-31 05:13:10,922 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4099176655213038, 'Total loss': 0.4099176655213038} | train loss {'Reaction outcome loss': 0.1878845270232227, 'Total loss': 0.1878845270232227}
2022-12-31 05:13:10,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:10,922 INFO:     Epoch: 25
2022-12-31 05:13:12,544 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42286308904488884, 'Total loss': 0.42286308904488884} | train loss {'Reaction outcome loss': 0.1863353268751061, 'Total loss': 0.1863353268751061}
2022-12-31 05:13:12,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:12,544 INFO:     Epoch: 26
2022-12-31 05:13:14,198 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43911103109518684, 'Total loss': 0.43911103109518684} | train loss {'Reaction outcome loss': 0.18187459385096488, 'Total loss': 0.18187459385096488}
2022-12-31 05:13:14,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:14,198 INFO:     Epoch: 27
2022-12-31 05:13:15,821 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4167936533689499, 'Total loss': 0.4167936533689499} | train loss {'Reaction outcome loss': 0.17940593773788277, 'Total loss': 0.17940593773788277}
2022-12-31 05:13:15,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:15,821 INFO:     Epoch: 28
2022-12-31 05:13:17,490 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4439906790852547, 'Total loss': 0.4439906790852547} | train loss {'Reaction outcome loss': 0.17649724259838084, 'Total loss': 0.17649724259838084}
2022-12-31 05:13:17,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:17,491 INFO:     Epoch: 29
2022-12-31 05:13:19,114 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44055847028891243, 'Total loss': 0.44055847028891243} | train loss {'Reaction outcome loss': 0.17364882521116132, 'Total loss': 0.17364882521116132}
2022-12-31 05:13:19,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:19,114 INFO:     Epoch: 30
2022-12-31 05:13:20,768 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4348153491814931, 'Total loss': 0.4348153491814931} | train loss {'Reaction outcome loss': 0.1710313553972311, 'Total loss': 0.1710313553972311}
2022-12-31 05:13:20,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:20,768 INFO:     Epoch: 31
2022-12-31 05:13:22,388 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41093501398960747, 'Total loss': 0.41093501398960747} | train loss {'Reaction outcome loss': 0.1663003202749665, 'Total loss': 0.1663003202749665}
2022-12-31 05:13:22,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:22,388 INFO:     Epoch: 32
2022-12-31 05:13:24,027 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4306048740943273, 'Total loss': 0.4306048740943273} | train loss {'Reaction outcome loss': 0.1650594296707143, 'Total loss': 0.1650594296707143}
2022-12-31 05:13:24,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:24,028 INFO:     Epoch: 33
2022-12-31 05:13:25,688 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4518120189507802, 'Total loss': 0.4518120189507802} | train loss {'Reaction outcome loss': 0.16547651952704154, 'Total loss': 0.16547651952704154}
2022-12-31 05:13:25,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:25,688 INFO:     Epoch: 34
2022-12-31 05:13:27,356 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4324114640553792, 'Total loss': 0.4324114640553792} | train loss {'Reaction outcome loss': 0.16314334125469845, 'Total loss': 0.16314334125469845}
2022-12-31 05:13:27,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:27,356 INFO:     Epoch: 35
2022-12-31 05:13:28,974 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4192892134189606, 'Total loss': 0.4192892134189606} | train loss {'Reaction outcome loss': 0.16018932493275792, 'Total loss': 0.16018932493275792}
2022-12-31 05:13:28,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:28,974 INFO:     Epoch: 36
2022-12-31 05:13:30,590 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4380162979165713, 'Total loss': 0.4380162979165713} | train loss {'Reaction outcome loss': 0.1555392888478854, 'Total loss': 0.1555392888478854}
2022-12-31 05:13:30,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:30,590 INFO:     Epoch: 37
2022-12-31 05:13:32,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.428435684243838, 'Total loss': 0.428435684243838} | train loss {'Reaction outcome loss': 0.15450570342931158, 'Total loss': 0.15450570342931158}
2022-12-31 05:13:32,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:32,256 INFO:     Epoch: 38
2022-12-31 05:13:33,870 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42564639151096345, 'Total loss': 0.42564639151096345} | train loss {'Reaction outcome loss': 0.15842523712611048, 'Total loss': 0.15842523712611048}
2022-12-31 05:13:33,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:33,870 INFO:     Epoch: 39
2022-12-31 05:13:35,538 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44953494469324745, 'Total loss': 0.44953494469324745} | train loss {'Reaction outcome loss': 0.15170343032288314, 'Total loss': 0.15170343032288314}
2022-12-31 05:13:35,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:35,538 INFO:     Epoch: 40
2022-12-31 05:13:37,206 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4439068694909414, 'Total loss': 0.4439068694909414} | train loss {'Reaction outcome loss': 0.14849887448547927, 'Total loss': 0.14849887448547927}
2022-12-31 05:13:37,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:37,206 INFO:     Epoch: 41
2022-12-31 05:13:38,828 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4165940463542938, 'Total loss': 0.4165940463542938} | train loss {'Reaction outcome loss': 0.15015557868278415, 'Total loss': 0.15015557868278415}
2022-12-31 05:13:38,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:38,828 INFO:     Epoch: 42
2022-12-31 05:13:40,488 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4396744395295779, 'Total loss': 0.4396744395295779} | train loss {'Reaction outcome loss': 0.15166850537330664, 'Total loss': 0.15166850537330664}
2022-12-31 05:13:40,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:40,488 INFO:     Epoch: 43
2022-12-31 05:13:42,129 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4329269786675771, 'Total loss': 0.4329269786675771} | train loss {'Reaction outcome loss': 0.1434873105800082, 'Total loss': 0.1434873105800082}
2022-12-31 05:13:42,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:42,130 INFO:     Epoch: 44
2022-12-31 05:13:43,760 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43572090168794, 'Total loss': 0.43572090168794} | train loss {'Reaction outcome loss': 0.1470857690128797, 'Total loss': 0.1470857690128797}
2022-12-31 05:13:43,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:43,760 INFO:     Epoch: 45
2022-12-31 05:13:45,391 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4062150853375594, 'Total loss': 0.4062150853375594} | train loss {'Reaction outcome loss': 0.14715475816488105, 'Total loss': 0.14715475816488105}
2022-12-31 05:13:45,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:45,391 INFO:     Epoch: 46
2022-12-31 05:13:47,022 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43594157646099724, 'Total loss': 0.43594157646099724} | train loss {'Reaction outcome loss': 0.14524519006092948, 'Total loss': 0.14524519006092948}
2022-12-31 05:13:47,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:47,022 INFO:     Epoch: 47
2022-12-31 05:13:48,645 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4422017271320025, 'Total loss': 0.4422017271320025} | train loss {'Reaction outcome loss': 0.14260846093323903, 'Total loss': 0.14260846093323903}
2022-12-31 05:13:48,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:48,645 INFO:     Epoch: 48
2022-12-31 05:13:50,273 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4363876670598984, 'Total loss': 0.4363876670598984} | train loss {'Reaction outcome loss': 0.14065310377156906, 'Total loss': 0.14065310377156906}
2022-12-31 05:13:50,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:50,274 INFO:     Epoch: 49
2022-12-31 05:13:51,926 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4294004499912262, 'Total loss': 0.4294004499912262} | train loss {'Reaction outcome loss': 0.1398665263159503, 'Total loss': 0.1398665263159503}
2022-12-31 05:13:51,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:51,926 INFO:     Epoch: 50
2022-12-31 05:13:53,555 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4236660093069077, 'Total loss': 0.4236660093069077} | train loss {'Reaction outcome loss': 0.13728781433150655, 'Total loss': 0.13728781433150655}
2022-12-31 05:13:53,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:53,556 INFO:     Epoch: 51
2022-12-31 05:13:55,181 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42787552773952486, 'Total loss': 0.42787552773952486} | train loss {'Reaction outcome loss': 0.1349011220690199, 'Total loss': 0.1349011220690199}
2022-12-31 05:13:55,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:55,181 INFO:     Epoch: 52
2022-12-31 05:13:56,826 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.420211169620355, 'Total loss': 0.420211169620355} | train loss {'Reaction outcome loss': 0.13668705343642013, 'Total loss': 0.13668705343642013}
2022-12-31 05:13:56,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:56,826 INFO:     Epoch: 53
2022-12-31 05:13:58,494 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4224514921506246, 'Total loss': 0.4224514921506246} | train loss {'Reaction outcome loss': 0.13732794049239652, 'Total loss': 0.13732794049239652}
2022-12-31 05:13:58,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:13:58,494 INFO:     Epoch: 54
2022-12-31 05:14:00,121 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4313046266635259, 'Total loss': 0.4313046266635259} | train loss {'Reaction outcome loss': 0.13943045048567632, 'Total loss': 0.13943045048567632}
2022-12-31 05:14:00,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:00,121 INFO:     Epoch: 55
2022-12-31 05:14:01,749 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43493568201859795, 'Total loss': 0.43493568201859795} | train loss {'Reaction outcome loss': 0.1340585160346547, 'Total loss': 0.1340585160346547}
2022-12-31 05:14:01,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:01,749 INFO:     Epoch: 56
2022-12-31 05:14:03,373 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44134955008824667, 'Total loss': 0.44134955008824667} | train loss {'Reaction outcome loss': 0.1324946635246398, 'Total loss': 0.1324946635246398}
2022-12-31 05:14:03,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:03,374 INFO:     Epoch: 57
2022-12-31 05:14:05,042 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42094926834106444, 'Total loss': 0.42094926834106444} | train loss {'Reaction outcome loss': 0.13092163336944063, 'Total loss': 0.13092163336944063}
2022-12-31 05:14:05,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:05,042 INFO:     Epoch: 58
2022-12-31 05:14:06,683 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4364835957686106, 'Total loss': 0.4364835957686106} | train loss {'Reaction outcome loss': 0.1311181578129557, 'Total loss': 0.1311181578129557}
2022-12-31 05:14:06,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:06,683 INFO:     Epoch: 59
2022-12-31 05:14:08,306 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.452722430229187, 'Total loss': 0.452722430229187} | train loss {'Reaction outcome loss': 0.1295967618716269, 'Total loss': 0.1295967618716269}
2022-12-31 05:14:08,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:08,306 INFO:     Epoch: 60
2022-12-31 05:14:09,934 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4366772770881653, 'Total loss': 0.4366772770881653} | train loss {'Reaction outcome loss': 0.12975909681789013, 'Total loss': 0.12975909681789013}
2022-12-31 05:14:09,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:09,934 INFO:     Epoch: 61
2022-12-31 05:14:11,563 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4355231503645579, 'Total loss': 0.4355231503645579} | train loss {'Reaction outcome loss': 0.1322032757446385, 'Total loss': 0.1322032757446385}
2022-12-31 05:14:11,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:11,563 INFO:     Epoch: 62
2022-12-31 05:14:13,190 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4320354660352071, 'Total loss': 0.4320354660352071} | train loss {'Reaction outcome loss': 0.1277834709686654, 'Total loss': 0.1277834709686654}
2022-12-31 05:14:13,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:13,190 INFO:     Epoch: 63
2022-12-31 05:14:14,807 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4231857568025589, 'Total loss': 0.4231857568025589} | train loss {'Reaction outcome loss': 0.1268878855779498, 'Total loss': 0.1268878855779498}
2022-12-31 05:14:14,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:14,808 INFO:     Epoch: 64
2022-12-31 05:14:16,475 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4471572905778885, 'Total loss': 0.4471572905778885} | train loss {'Reaction outcome loss': 0.1267764565639117, 'Total loss': 0.1267764565639117}
2022-12-31 05:14:16,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:16,475 INFO:     Epoch: 65
2022-12-31 05:14:18,130 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.424704384803772, 'Total loss': 0.424704384803772} | train loss {'Reaction outcome loss': 0.12393469691767428, 'Total loss': 0.12393469691767428}
2022-12-31 05:14:18,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:18,131 INFO:     Epoch: 66
2022-12-31 05:14:19,799 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46516309479872386, 'Total loss': 0.46516309479872386} | train loss {'Reaction outcome loss': 0.13026298870356073, 'Total loss': 0.13026298870356073}
2022-12-31 05:14:19,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:19,800 INFO:     Epoch: 67
2022-12-31 05:14:21,424 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43140651484330494, 'Total loss': 0.43140651484330494} | train loss {'Reaction outcome loss': 0.12293294893194406, 'Total loss': 0.12293294893194406}
2022-12-31 05:14:21,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:21,424 INFO:     Epoch: 68
2022-12-31 05:14:23,050 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4284477591514587, 'Total loss': 0.4284477591514587} | train loss {'Reaction outcome loss': 0.1234542492218988, 'Total loss': 0.1234542492218988}
2022-12-31 05:14:23,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:23,050 INFO:     Epoch: 69
2022-12-31 05:14:24,676 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4152338226636251, 'Total loss': 0.4152338226636251} | train loss {'Reaction outcome loss': 0.1218496396984663, 'Total loss': 0.1218496396984663}
2022-12-31 05:14:24,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:24,676 INFO:     Epoch: 70
2022-12-31 05:14:26,344 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41004515488942467, 'Total loss': 0.41004515488942467} | train loss {'Reaction outcome loss': 0.12311651050163575, 'Total loss': 0.12311651050163575}
2022-12-31 05:14:26,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:26,344 INFO:     Epoch: 71
2022-12-31 05:14:27,963 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4145572225252787, 'Total loss': 0.4145572225252787} | train loss {'Reaction outcome loss': 0.12310351580482258, 'Total loss': 0.12310351580482258}
2022-12-31 05:14:27,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:27,964 INFO:     Epoch: 72
2022-12-31 05:14:29,582 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4344052463769913, 'Total loss': 0.4344052463769913} | train loss {'Reaction outcome loss': 0.12558241148516266, 'Total loss': 0.12558241148516266}
2022-12-31 05:14:29,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:29,582 INFO:     Epoch: 73
2022-12-31 05:14:31,201 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41063283445934456, 'Total loss': 0.41063283445934456} | train loss {'Reaction outcome loss': 0.1261976439689054, 'Total loss': 0.1261976439689054}
2022-12-31 05:14:31,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:31,201 INFO:     Epoch: 74
2022-12-31 05:14:32,825 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44005552530288694, 'Total loss': 0.44005552530288694} | train loss {'Reaction outcome loss': 0.12230263282259125, 'Total loss': 0.12230263282259125}
2022-12-31 05:14:32,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:32,826 INFO:     Epoch: 75
2022-12-31 05:14:34,445 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4490039000908534, 'Total loss': 0.4490039000908534} | train loss {'Reaction outcome loss': 0.12142734488115951, 'Total loss': 0.12142734488115951}
2022-12-31 05:14:34,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:34,446 INFO:     Epoch: 76
2022-12-31 05:14:36,067 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4341041326522827, 'Total loss': 0.4341041326522827} | train loss {'Reaction outcome loss': 0.12135137584974942, 'Total loss': 0.12135137584974942}
2022-12-31 05:14:36,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:36,067 INFO:     Epoch: 77
2022-12-31 05:14:37,687 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44914457636574906, 'Total loss': 0.44914457636574906} | train loss {'Reaction outcome loss': 0.11885911146504972, 'Total loss': 0.11885911146504972}
2022-12-31 05:14:37,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:37,687 INFO:     Epoch: 78
2022-12-31 05:14:39,309 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42727505465348564, 'Total loss': 0.42727505465348564} | train loss {'Reaction outcome loss': 0.12240083985760243, 'Total loss': 0.12240083985760243}
2022-12-31 05:14:39,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:39,309 INFO:     Epoch: 79
2022-12-31 05:14:40,961 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43572411437829334, 'Total loss': 0.43572411437829334} | train loss {'Reaction outcome loss': 0.11881648244282453, 'Total loss': 0.11881648244282453}
2022-12-31 05:14:40,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:40,961 INFO:     Epoch: 80
2022-12-31 05:14:42,583 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4303576946258545, 'Total loss': 0.4303576946258545} | train loss {'Reaction outcome loss': 0.11657424064332936, 'Total loss': 0.11657424064332936}
2022-12-31 05:14:42,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:42,583 INFO:     Epoch: 81
2022-12-31 05:14:44,204 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.433466774225235, 'Total loss': 0.433466774225235} | train loss {'Reaction outcome loss': 0.11952064427822855, 'Total loss': 0.11952064427822855}
2022-12-31 05:14:44,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:44,205 INFO:     Epoch: 82
2022-12-31 05:14:45,826 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42820254067579905, 'Total loss': 0.42820254067579905} | train loss {'Reaction outcome loss': 0.11968789402721618, 'Total loss': 0.11968789402721618}
2022-12-31 05:14:45,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:45,826 INFO:     Epoch: 83
2022-12-31 05:14:47,484 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4290505769352118, 'Total loss': 0.4290505769352118} | train loss {'Reaction outcome loss': 0.12109819088141276, 'Total loss': 0.12109819088141276}
2022-12-31 05:14:47,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:47,485 INFO:     Epoch: 84
2022-12-31 05:14:49,109 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4258733173211416, 'Total loss': 0.4258733173211416} | train loss {'Reaction outcome loss': 0.11667667555081446, 'Total loss': 0.11667667555081446}
2022-12-31 05:14:49,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:49,109 INFO:     Epoch: 85
2022-12-31 05:14:50,734 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.412170946598053, 'Total loss': 0.412170946598053} | train loss {'Reaction outcome loss': 0.11942221908846917, 'Total loss': 0.11942221908846917}
2022-12-31 05:14:50,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:50,734 INFO:     Epoch: 86
2022-12-31 05:14:52,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43859331011772157, 'Total loss': 0.43859331011772157} | train loss {'Reaction outcome loss': 0.1176928075758357, 'Total loss': 0.1176928075758357}
2022-12-31 05:14:52,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:52,364 INFO:     Epoch: 87
2022-12-31 05:14:53,987 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44156757394472756, 'Total loss': 0.44156757394472756} | train loss {'Reaction outcome loss': 0.11612613975080503, 'Total loss': 0.11612613975080503}
2022-12-31 05:14:53,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:53,987 INFO:     Epoch: 88
2022-12-31 05:14:55,602 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43040604094664253, 'Total loss': 0.43040604094664253} | train loss {'Reaction outcome loss': 0.1127017132033483, 'Total loss': 0.1127017132033483}
2022-12-31 05:14:55,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:55,602 INFO:     Epoch: 89
2022-12-31 05:14:57,224 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4388333131869634, 'Total loss': 0.4388333131869634} | train loss {'Reaction outcome loss': 0.11230134726031296, 'Total loss': 0.11230134726031296}
2022-12-31 05:14:57,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:57,224 INFO:     Epoch: 90
2022-12-31 05:14:58,845 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4493025163809458, 'Total loss': 0.4493025163809458} | train loss {'Reaction outcome loss': 0.11533502054262892, 'Total loss': 0.11533502054262892}
2022-12-31 05:14:58,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:14:58,845 INFO:     Epoch: 91
2022-12-31 05:15:00,470 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42140831251939137, 'Total loss': 0.42140831251939137} | train loss {'Reaction outcome loss': 0.117941307309941, 'Total loss': 0.117941307309941}
2022-12-31 05:15:00,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:00,470 INFO:     Epoch: 92
2022-12-31 05:15:02,092 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4520045648018519, 'Total loss': 0.4520045648018519} | train loss {'Reaction outcome loss': 0.11436656234442973, 'Total loss': 0.11436656234442973}
2022-12-31 05:15:02,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:02,092 INFO:     Epoch: 93
2022-12-31 05:15:03,711 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4089157789945602, 'Total loss': 0.4089157789945602} | train loss {'Reaction outcome loss': 0.11750074791039478, 'Total loss': 0.11750074791039478}
2022-12-31 05:15:03,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:03,711 INFO:     Epoch: 94
2022-12-31 05:15:05,339 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4401048570871353, 'Total loss': 0.4401048570871353} | train loss {'Reaction outcome loss': 0.11908578258579335, 'Total loss': 0.11908578258579335}
2022-12-31 05:15:05,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:05,341 INFO:     Epoch: 95
2022-12-31 05:15:06,965 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44919002056121826, 'Total loss': 0.44919002056121826} | train loss {'Reaction outcome loss': 0.11839889350518693, 'Total loss': 0.11839889350518693}
2022-12-31 05:15:06,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:06,966 INFO:     Epoch: 96
2022-12-31 05:15:08,589 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43605866432189944, 'Total loss': 0.43605866432189944} | train loss {'Reaction outcome loss': 0.11257137448463038, 'Total loss': 0.11257137448463038}
2022-12-31 05:15:08,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:08,590 INFO:     Epoch: 97
2022-12-31 05:15:10,216 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4366273780663808, 'Total loss': 0.4366273780663808} | train loss {'Reaction outcome loss': 0.11186762060549796, 'Total loss': 0.11186762060549796}
2022-12-31 05:15:10,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:10,216 INFO:     Epoch: 98
2022-12-31 05:15:11,843 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4317164947589239, 'Total loss': 0.4317164947589239} | train loss {'Reaction outcome loss': 0.11083653608222731, 'Total loss': 0.11083653608222731}
2022-12-31 05:15:11,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:11,844 INFO:     Epoch: 99
2022-12-31 05:15:13,464 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4247366507848104, 'Total loss': 0.4247366507848104} | train loss {'Reaction outcome loss': 0.1147669806890694, 'Total loss': 0.1147669806890694}
2022-12-31 05:15:13,464 INFO:     Best model found after epoch 13 of 100.
2022-12-31 05:15:13,464 INFO:   Done with stage: TRAINING
2022-12-31 05:15:13,464 INFO:   Starting stage: EVALUATION
2022-12-31 05:15:13,588 INFO:   Done with stage: EVALUATION
2022-12-31 05:15:13,588 INFO:   Leaving out SEQ value Fold_6
2022-12-31 05:15:13,600 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 05:15:13,600 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:15:14,259 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:15:14,260 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:15:14,330 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:15:14,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:15:14,331 INFO:     No hyperparam tuning for this model
2022-12-31 05:15:14,331 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:15:14,331 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:15:14,331 INFO:     None feature selector for col prot
2022-12-31 05:15:14,332 INFO:     None feature selector for col prot
2022-12-31 05:15:14,332 INFO:     None feature selector for col prot
2022-12-31 05:15:14,332 INFO:     None feature selector for col chem
2022-12-31 05:15:14,332 INFO:     None feature selector for col chem
2022-12-31 05:15:14,333 INFO:     None feature selector for col chem
2022-12-31 05:15:14,333 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:15:14,333 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:15:14,335 INFO:     Number of params in model 224011
2022-12-31 05:15:14,338 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:15:14,338 INFO:   Starting stage: TRAINING
2022-12-31 05:15:14,383 INFO:     Val loss before train {'Reaction outcome loss': 0.9334031343460083, 'Total loss': 0.9334031343460083}
2022-12-31 05:15:14,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:14,383 INFO:     Epoch: 0
2022-12-31 05:15:16,011 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5263140956560771, 'Total loss': 0.5263140956560771} | train loss {'Reaction outcome loss': 0.7749068492801611, 'Total loss': 0.7749068492801611}
2022-12-31 05:15:16,011 INFO:     Found new best model at epoch 0
2022-12-31 05:15:16,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:16,012 INFO:     Epoch: 1
2022-12-31 05:15:17,635 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4547343611717224, 'Total loss': 0.4547343611717224} | train loss {'Reaction outcome loss': 0.5185568839419189, 'Total loss': 0.5185568839419189}
2022-12-31 05:15:17,635 INFO:     Found new best model at epoch 1
2022-12-31 05:15:17,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:17,637 INFO:     Epoch: 2
2022-12-31 05:15:19,265 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44129683474699655, 'Total loss': 0.44129683474699655} | train loss {'Reaction outcome loss': 0.4492826114815495, 'Total loss': 0.4492826114815495}
2022-12-31 05:15:19,265 INFO:     Found new best model at epoch 2
2022-12-31 05:15:19,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:19,266 INFO:     Epoch: 3
2022-12-31 05:15:20,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41778275966644285, 'Total loss': 0.41778275966644285} | train loss {'Reaction outcome loss': 0.40752755568130783, 'Total loss': 0.40752755568130783}
2022-12-31 05:15:20,888 INFO:     Found new best model at epoch 3
2022-12-31 05:15:20,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:20,889 INFO:     Epoch: 4
2022-12-31 05:15:22,503 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4060222824414571, 'Total loss': 0.4060222824414571} | train loss {'Reaction outcome loss': 0.3746273605294176, 'Total loss': 0.3746273605294176}
2022-12-31 05:15:22,503 INFO:     Found new best model at epoch 4
2022-12-31 05:15:22,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:22,504 INFO:     Epoch: 5
2022-12-31 05:15:24,126 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39693396190802255, 'Total loss': 0.39693396190802255} | train loss {'Reaction outcome loss': 0.3503388238781626, 'Total loss': 0.3503388238781626}
2022-12-31 05:15:24,127 INFO:     Found new best model at epoch 5
2022-12-31 05:15:24,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:24,128 INFO:     Epoch: 6
2022-12-31 05:15:25,850 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40276943147182465, 'Total loss': 0.40276943147182465} | train loss {'Reaction outcome loss': 0.3307788333307535, 'Total loss': 0.3307788333307535}
2022-12-31 05:15:25,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:25,850 INFO:     Epoch: 7
2022-12-31 05:15:27,482 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40092727144559226, 'Total loss': 0.40092727144559226} | train loss {'Reaction outcome loss': 0.3163050795074835, 'Total loss': 0.3163050795074835}
2022-12-31 05:15:27,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:27,482 INFO:     Epoch: 8
2022-12-31 05:15:29,103 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39779024124145507, 'Total loss': 0.39779024124145507} | train loss {'Reaction outcome loss': 0.2944792352267121, 'Total loss': 0.2944792352267121}
2022-12-31 05:15:29,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:29,103 INFO:     Epoch: 9
2022-12-31 05:15:30,724 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4117535372575124, 'Total loss': 0.4117535372575124} | train loss {'Reaction outcome loss': 0.28577594358191594, 'Total loss': 0.28577594358191594}
2022-12-31 05:15:30,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:30,724 INFO:     Epoch: 10
2022-12-31 05:15:32,357 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40126853783925376, 'Total loss': 0.40126853783925376} | train loss {'Reaction outcome loss': 0.2719347742705569, 'Total loss': 0.2719347742705569}
2022-12-31 05:15:32,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:32,358 INFO:     Epoch: 11
2022-12-31 05:15:33,988 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40424640774726867, 'Total loss': 0.40424640774726867} | train loss {'Reaction outcome loss': 0.2596238207556173, 'Total loss': 0.2596238207556173}
2022-12-31 05:15:33,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:33,988 INFO:     Epoch: 12
2022-12-31 05:15:35,622 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4091497520605723, 'Total loss': 0.4091497520605723} | train loss {'Reaction outcome loss': 0.2517714993860102, 'Total loss': 0.2517714993860102}
2022-12-31 05:15:35,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:35,622 INFO:     Epoch: 13
2022-12-31 05:15:37,252 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.399986720085144, 'Total loss': 0.399986720085144} | train loss {'Reaction outcome loss': 0.2406826295119976, 'Total loss': 0.2406826295119976}
2022-12-31 05:15:37,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:37,252 INFO:     Epoch: 14
2022-12-31 05:15:38,890 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4070890376965205, 'Total loss': 0.4070890376965205} | train loss {'Reaction outcome loss': 0.23167546262917535, 'Total loss': 0.23167546262917535}
2022-12-31 05:15:38,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:38,891 INFO:     Epoch: 15
2022-12-31 05:15:40,541 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40370864073435464, 'Total loss': 0.40370864073435464} | train loss {'Reaction outcome loss': 0.22514673939566482, 'Total loss': 0.22514673939566482}
2022-12-31 05:15:40,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:40,542 INFO:     Epoch: 16
2022-12-31 05:15:42,174 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43105429808298745, 'Total loss': 0.43105429808298745} | train loss {'Reaction outcome loss': 0.22033054204086103, 'Total loss': 0.22033054204086103}
2022-12-31 05:15:42,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:42,174 INFO:     Epoch: 17
2022-12-31 05:15:43,842 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4107600212097168, 'Total loss': 0.4107600212097168} | train loss {'Reaction outcome loss': 0.2158856455922557, 'Total loss': 0.2158856455922557}
2022-12-31 05:15:43,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:43,842 INFO:     Epoch: 18
2022-12-31 05:15:45,494 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42103668848673503, 'Total loss': 0.42103668848673503} | train loss {'Reaction outcome loss': 0.20948599524365652, 'Total loss': 0.20948599524365652}
2022-12-31 05:15:45,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:45,494 INFO:     Epoch: 19
2022-12-31 05:15:47,157 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.404700576265653, 'Total loss': 0.404700576265653} | train loss {'Reaction outcome loss': 0.20317986008748143, 'Total loss': 0.20317986008748143}
2022-12-31 05:15:47,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:47,158 INFO:     Epoch: 20
2022-12-31 05:15:48,790 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40160779158274335, 'Total loss': 0.40160779158274335} | train loss {'Reaction outcome loss': 0.19602150100851531, 'Total loss': 0.19602150100851531}
2022-12-31 05:15:48,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:48,790 INFO:     Epoch: 21
2022-12-31 05:15:50,458 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.412484539548556, 'Total loss': 0.412484539548556} | train loss {'Reaction outcome loss': 0.19178713574359993, 'Total loss': 0.19178713574359993}
2022-12-31 05:15:50,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:50,458 INFO:     Epoch: 22
2022-12-31 05:15:52,125 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.419553396354119, 'Total loss': 0.419553396354119} | train loss {'Reaction outcome loss': 0.19121418734642573, 'Total loss': 0.19121418734642573}
2022-12-31 05:15:52,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:52,125 INFO:     Epoch: 23
2022-12-31 05:15:53,791 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41539199550946554, 'Total loss': 0.41539199550946554} | train loss {'Reaction outcome loss': 0.18691762916017526, 'Total loss': 0.18691762916017526}
2022-12-31 05:15:53,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:53,791 INFO:     Epoch: 24
2022-12-31 05:15:55,167 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43202180564403536, 'Total loss': 0.43202180564403536} | train loss {'Reaction outcome loss': 0.18176041043528257, 'Total loss': 0.18176041043528257}
2022-12-31 05:15:55,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:55,167 INFO:     Epoch: 25
2022-12-31 05:15:56,336 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4297634998957316, 'Total loss': 0.4297634998957316} | train loss {'Reaction outcome loss': 0.17629958894977932, 'Total loss': 0.17629958894977932}
2022-12-31 05:15:56,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:56,336 INFO:     Epoch: 26
2022-12-31 05:15:57,641 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.423914380868276, 'Total loss': 0.423914380868276} | train loss {'Reaction outcome loss': 0.17501548716011675, 'Total loss': 0.17501548716011675}
2022-12-31 05:15:57,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:57,641 INFO:     Epoch: 27
2022-12-31 05:15:58,773 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4183877984682719, 'Total loss': 0.4183877984682719} | train loss {'Reaction outcome loss': 0.1737856991582345, 'Total loss': 0.1737856991582345}
2022-12-31 05:15:58,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:15:58,773 INFO:     Epoch: 28
2022-12-31 05:16:00,302 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4413502593835195, 'Total loss': 0.4413502593835195} | train loss {'Reaction outcome loss': 0.16756176166505374, 'Total loss': 0.16756176166505374}
2022-12-31 05:16:00,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:00,303 INFO:     Epoch: 29
2022-12-31 05:16:01,945 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4371472954750061, 'Total loss': 0.4371472954750061} | train loss {'Reaction outcome loss': 0.16764146760980253, 'Total loss': 0.16764146760980253}
2022-12-31 05:16:01,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:01,945 INFO:     Epoch: 30
2022-12-31 05:16:03,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4653168002764384, 'Total loss': 0.4653168002764384} | train loss {'Reaction outcome loss': 0.16541081187500206, 'Total loss': 0.16541081187500206}
2022-12-31 05:16:03,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:03,577 INFO:     Epoch: 31
2022-12-31 05:16:05,202 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4094522215425968, 'Total loss': 0.4094522215425968} | train loss {'Reaction outcome loss': 0.1631875719525431, 'Total loss': 0.1631875719525431}
2022-12-31 05:16:05,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:05,202 INFO:     Epoch: 32
2022-12-31 05:16:06,826 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4268788605928421, 'Total loss': 0.4268788605928421} | train loss {'Reaction outcome loss': 0.1637146981224579, 'Total loss': 0.1637146981224579}
2022-12-31 05:16:06,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:06,826 INFO:     Epoch: 33
2022-12-31 05:16:08,448 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4531323418021202, 'Total loss': 0.4531323418021202} | train loss {'Reaction outcome loss': 0.15838233123294712, 'Total loss': 0.15838233123294712}
2022-12-31 05:16:08,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:08,448 INFO:     Epoch: 34
2022-12-31 05:16:10,072 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4429589584469795, 'Total loss': 0.4429589584469795} | train loss {'Reaction outcome loss': 0.1578247094819396, 'Total loss': 0.1578247094819396}
2022-12-31 05:16:10,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:10,073 INFO:     Epoch: 35
2022-12-31 05:16:11,693 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41029406785964967, 'Total loss': 0.41029406785964967} | train loss {'Reaction outcome loss': 0.15704015574488614, 'Total loss': 0.15704015574488614}
2022-12-31 05:16:11,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:11,695 INFO:     Epoch: 36
2022-12-31 05:16:13,320 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4522817273934682, 'Total loss': 0.4522817273934682} | train loss {'Reaction outcome loss': 0.15420812020071578, 'Total loss': 0.15420812020071578}
2022-12-31 05:16:13,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:13,320 INFO:     Epoch: 37
2022-12-31 05:16:14,974 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43929097751776375, 'Total loss': 0.43929097751776375} | train loss {'Reaction outcome loss': 0.15077761978933096, 'Total loss': 0.15077761978933096}
2022-12-31 05:16:14,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:14,974 INFO:     Epoch: 38
2022-12-31 05:16:16,603 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42808691660563153, 'Total loss': 0.42808691660563153} | train loss {'Reaction outcome loss': 0.148830614994122, 'Total loss': 0.148830614994122}
2022-12-31 05:16:16,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:16,603 INFO:     Epoch: 39
2022-12-31 05:16:18,256 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4590137228369713, 'Total loss': 0.4590137228369713} | train loss {'Reaction outcome loss': 0.14841872781165455, 'Total loss': 0.14841872781165455}
2022-12-31 05:16:18,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:18,257 INFO:     Epoch: 40
2022-12-31 05:16:19,910 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46056225697199504, 'Total loss': 0.46056225697199504} | train loss {'Reaction outcome loss': 0.1523737607503626, 'Total loss': 0.1523737607503626}
2022-12-31 05:16:19,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:19,910 INFO:     Epoch: 41
2022-12-31 05:16:21,580 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4329625944296519, 'Total loss': 0.4329625944296519} | train loss {'Reaction outcome loss': 0.1491590190564521, 'Total loss': 0.1491590190564521}
2022-12-31 05:16:21,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:21,580 INFO:     Epoch: 42
2022-12-31 05:16:23,205 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4194662518799305, 'Total loss': 0.4194662518799305} | train loss {'Reaction outcome loss': 0.14578678626365396, 'Total loss': 0.14578678626365396}
2022-12-31 05:16:23,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:23,205 INFO:     Epoch: 43
2022-12-31 05:16:24,863 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4603143036365509, 'Total loss': 0.4603143036365509} | train loss {'Reaction outcome loss': 0.14356504231254277, 'Total loss': 0.14356504231254277}
2022-12-31 05:16:24,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:24,863 INFO:     Epoch: 44
2022-12-31 05:16:26,488 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4492055336634318, 'Total loss': 0.4492055336634318} | train loss {'Reaction outcome loss': 0.14122544809005858, 'Total loss': 0.14122544809005858}
2022-12-31 05:16:26,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:26,488 INFO:     Epoch: 45
2022-12-31 05:16:28,108 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4332596520582835, 'Total loss': 0.4332596520582835} | train loss {'Reaction outcome loss': 0.14305350536460373, 'Total loss': 0.14305350536460373}
2022-12-31 05:16:28,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:28,108 INFO:     Epoch: 46
2022-12-31 05:16:29,728 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45376405119895935, 'Total loss': 0.45376405119895935} | train loss {'Reaction outcome loss': 0.13925132739260146, 'Total loss': 0.13925132739260146}
2022-12-31 05:16:29,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:29,728 INFO:     Epoch: 47
2022-12-31 05:16:31,388 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45727826555569967, 'Total loss': 0.45727826555569967} | train loss {'Reaction outcome loss': 0.14044392652580992, 'Total loss': 0.14044392652580992}
2022-12-31 05:16:31,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:31,389 INFO:     Epoch: 48
2022-12-31 05:16:33,018 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43596359839042026, 'Total loss': 0.43596359839042026} | train loss {'Reaction outcome loss': 0.1363083022017879, 'Total loss': 0.1363083022017879}
2022-12-31 05:16:33,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:33,019 INFO:     Epoch: 49
2022-12-31 05:16:34,687 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4227735370397568, 'Total loss': 0.4227735370397568} | train loss {'Reaction outcome loss': 0.13726151393245678, 'Total loss': 0.13726151393245678}
2022-12-31 05:16:34,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:34,687 INFO:     Epoch: 50
2022-12-31 05:16:36,322 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4265081286430359, 'Total loss': 0.4265081286430359} | train loss {'Reaction outcome loss': 0.13476710333169475, 'Total loss': 0.13476710333169475}
2022-12-31 05:16:36,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:36,323 INFO:     Epoch: 51
2022-12-31 05:16:37,991 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4582211176554362, 'Total loss': 0.4582211176554362} | train loss {'Reaction outcome loss': 0.13300348219498723, 'Total loss': 0.13300348219498723}
2022-12-31 05:16:37,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:37,991 INFO:     Epoch: 52
2022-12-31 05:16:39,660 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48713707526524863, 'Total loss': 0.48713707526524863} | train loss {'Reaction outcome loss': 0.14078848491446366, 'Total loss': 0.14078848491446366}
2022-12-31 05:16:39,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:39,660 INFO:     Epoch: 53
2022-12-31 05:16:41,290 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42781182726224265, 'Total loss': 0.42781182726224265} | train loss {'Reaction outcome loss': 0.1322631735223537, 'Total loss': 0.1322631735223537}
2022-12-31 05:16:41,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:41,290 INFO:     Epoch: 54
2022-12-31 05:16:42,920 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45230419834454855, 'Total loss': 0.45230419834454855} | train loss {'Reaction outcome loss': 0.1354235741124902, 'Total loss': 0.1354235741124902}
2022-12-31 05:16:42,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:42,921 INFO:     Epoch: 55
2022-12-31 05:16:44,550 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.446080407500267, 'Total loss': 0.446080407500267} | train loss {'Reaction outcome loss': 0.13480517408719778, 'Total loss': 0.13480517408719778}
2022-12-31 05:16:44,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:44,551 INFO:     Epoch: 56
2022-12-31 05:16:46,208 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4473803440729777, 'Total loss': 0.4473803440729777} | train loss {'Reaction outcome loss': 0.13143023891737585, 'Total loss': 0.13143023891737585}
2022-12-31 05:16:46,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:46,210 INFO:     Epoch: 57
2022-12-31 05:16:47,839 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41032124559084576, 'Total loss': 0.41032124559084576} | train loss {'Reaction outcome loss': 0.12923821107911396, 'Total loss': 0.12923821107911396}
2022-12-31 05:16:47,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:47,839 INFO:     Epoch: 58
2022-12-31 05:16:49,508 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4319646269083023, 'Total loss': 0.4319646269083023} | train loss {'Reaction outcome loss': 0.12518530012367274, 'Total loss': 0.12518530012367274}
2022-12-31 05:16:49,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:49,509 INFO:     Epoch: 59
2022-12-31 05:16:51,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44266214917103447, 'Total loss': 0.44266214917103447} | train loss {'Reaction outcome loss': 0.12896191764501888, 'Total loss': 0.12896191764501888}
2022-12-31 05:16:51,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:51,154 INFO:     Epoch: 60
2022-12-31 05:16:52,772 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4260244394342105, 'Total loss': 0.4260244394342105} | train loss {'Reaction outcome loss': 0.12641229080238012, 'Total loss': 0.12641229080238012}
2022-12-31 05:16:52,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:52,773 INFO:     Epoch: 61
2022-12-31 05:16:54,396 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4829514890909195, 'Total loss': 0.4829514890909195} | train loss {'Reaction outcome loss': 0.13219772953042486, 'Total loss': 0.13219772953042486}
2022-12-31 05:16:54,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:54,396 INFO:     Epoch: 62
2022-12-31 05:16:56,023 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4649062936504682, 'Total loss': 0.4649062936504682} | train loss {'Reaction outcome loss': 0.12884656147735482, 'Total loss': 0.12884656147735482}
2022-12-31 05:16:56,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:56,023 INFO:     Epoch: 63
2022-12-31 05:16:57,649 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44071128889918326, 'Total loss': 0.44071128889918326} | train loss {'Reaction outcome loss': 0.1267864089022098, 'Total loss': 0.1267864089022098}
2022-12-31 05:16:57,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:57,649 INFO:     Epoch: 64
2022-12-31 05:16:59,276 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44177146355311075, 'Total loss': 0.44177146355311075} | train loss {'Reaction outcome loss': 0.12708947131921292, 'Total loss': 0.12708947131921292}
2022-12-31 05:16:59,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:16:59,276 INFO:     Epoch: 65
2022-12-31 05:17:00,896 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4439969519774119, 'Total loss': 0.4439969519774119} | train loss {'Reaction outcome loss': 0.12604529003105008, 'Total loss': 0.12604529003105008}
2022-12-31 05:17:00,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:00,896 INFO:     Epoch: 66
2022-12-31 05:17:02,526 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47317354182402294, 'Total loss': 0.47317354182402294} | train loss {'Reaction outcome loss': 0.12517170064379915, 'Total loss': 0.12517170064379915}
2022-12-31 05:17:02,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:02,527 INFO:     Epoch: 67
2022-12-31 05:17:04,148 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48422613243261975, 'Total loss': 0.48422613243261975} | train loss {'Reaction outcome loss': 0.12562824126386793, 'Total loss': 0.12562824126386793}
2022-12-31 05:17:04,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:04,148 INFO:     Epoch: 68
2022-12-31 05:17:05,821 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.443207856019338, 'Total loss': 0.443207856019338} | train loss {'Reaction outcome loss': 0.12529604789289892, 'Total loss': 0.12529604789289892}
2022-12-31 05:17:05,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:05,822 INFO:     Epoch: 69
2022-12-31 05:17:07,445 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43916370868682864, 'Total loss': 0.43916370868682864} | train loss {'Reaction outcome loss': 0.12064241532182543, 'Total loss': 0.12064241532182543}
2022-12-31 05:17:07,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:07,446 INFO:     Epoch: 70
2022-12-31 05:17:09,105 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46392565096418065, 'Total loss': 0.46392565096418065} | train loss {'Reaction outcome loss': 0.11951807215439983, 'Total loss': 0.11951807215439983}
2022-12-31 05:17:09,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:09,105 INFO:     Epoch: 71
2022-12-31 05:17:10,734 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4520937164624532, 'Total loss': 0.4520937164624532} | train loss {'Reaction outcome loss': 0.12135855063614485, 'Total loss': 0.12135855063614485}
2022-12-31 05:17:10,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:10,734 INFO:     Epoch: 72
2022-12-31 05:17:12,392 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45516127347946167, 'Total loss': 0.45516127347946167} | train loss {'Reaction outcome loss': 0.12220473699557464, 'Total loss': 0.12220473699557464}
2022-12-31 05:17:12,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:12,392 INFO:     Epoch: 73
2022-12-31 05:17:14,064 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4714055339495341, 'Total loss': 0.4714055339495341} | train loss {'Reaction outcome loss': 0.12352075056754563, 'Total loss': 0.12352075056754563}
2022-12-31 05:17:14,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:14,064 INFO:     Epoch: 74
2022-12-31 05:17:15,737 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47786711653073627, 'Total loss': 0.47786711653073627} | train loss {'Reaction outcome loss': 0.12441940021294334, 'Total loss': 0.12441940021294334}
2022-12-31 05:17:15,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:15,737 INFO:     Epoch: 75
2022-12-31 05:17:17,367 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47806535959243773, 'Total loss': 0.47806535959243773} | train loss {'Reaction outcome loss': 0.12435216770342648, 'Total loss': 0.12435216770342648}
2022-12-31 05:17:17,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:17,368 INFO:     Epoch: 76
2022-12-31 05:17:19,003 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45514033337434134, 'Total loss': 0.45514033337434134} | train loss {'Reaction outcome loss': 0.1200274770847431, 'Total loss': 0.1200274770847431}
2022-12-31 05:17:19,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:19,004 INFO:     Epoch: 77
2022-12-31 05:17:20,631 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43927791317303977, 'Total loss': 0.43927791317303977} | train loss {'Reaction outcome loss': 0.1179733411526637, 'Total loss': 0.1179733411526637}
2022-12-31 05:17:20,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:20,631 INFO:     Epoch: 78
2022-12-31 05:17:22,258 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.435716050863266, 'Total loss': 0.435716050863266} | train loss {'Reaction outcome loss': 0.12129093176392765, 'Total loss': 0.12129093176392765}
2022-12-31 05:17:22,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:22,259 INFO:     Epoch: 79
2022-12-31 05:17:23,890 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4453511824210485, 'Total loss': 0.4453511824210485} | train loss {'Reaction outcome loss': 0.1153468212469175, 'Total loss': 0.1153468212469175}
2022-12-31 05:17:23,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:23,890 INFO:     Epoch: 80
2022-12-31 05:17:25,521 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.463588817914327, 'Total loss': 0.463588817914327} | train loss {'Reaction outcome loss': 0.1213601303584403, 'Total loss': 0.1213601303584403}
2022-12-31 05:17:25,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:25,521 INFO:     Epoch: 81
2022-12-31 05:17:27,150 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45171686112880705, 'Total loss': 0.45171686112880705} | train loss {'Reaction outcome loss': 0.1178693554501994, 'Total loss': 0.1178693554501994}
2022-12-31 05:17:27,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:27,150 INFO:     Epoch: 82
2022-12-31 05:17:28,808 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46644493341445925, 'Total loss': 0.46644493341445925} | train loss {'Reaction outcome loss': 0.11712427303995197, 'Total loss': 0.11712427303995197}
2022-12-31 05:17:28,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:28,808 INFO:     Epoch: 83
2022-12-31 05:17:30,433 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44229406813780464, 'Total loss': 0.44229406813780464} | train loss {'Reaction outcome loss': 0.11610207467975384, 'Total loss': 0.11610207467975384}
2022-12-31 05:17:30,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:30,433 INFO:     Epoch: 84
2022-12-31 05:17:32,060 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46301191051801044, 'Total loss': 0.46301191051801044} | train loss {'Reaction outcome loss': 0.11541191879189186, 'Total loss': 0.11541191879189186}
2022-12-31 05:17:32,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:32,060 INFO:     Epoch: 85
2022-12-31 05:17:33,687 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4275462259848913, 'Total loss': 0.4275462259848913} | train loss {'Reaction outcome loss': 0.1148600116479698, 'Total loss': 0.1148600116479698}
2022-12-31 05:17:33,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:33,688 INFO:     Epoch: 86
2022-12-31 05:17:35,314 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4350409785906474, 'Total loss': 0.4350409785906474} | train loss {'Reaction outcome loss': 0.11263254688992182, 'Total loss': 0.11263254688992182}
2022-12-31 05:17:35,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:35,314 INFO:     Epoch: 87
2022-12-31 05:17:36,937 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4290735383828481, 'Total loss': 0.4290735383828481} | train loss {'Reaction outcome loss': 0.11785739097687069, 'Total loss': 0.11785739097687069}
2022-12-31 05:17:36,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:36,937 INFO:     Epoch: 88
2022-12-31 05:17:38,607 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4507178455591202, 'Total loss': 0.4507178455591202} | train loss {'Reaction outcome loss': 0.11684231507669234, 'Total loss': 0.11684231507669234}
2022-12-31 05:17:38,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:38,608 INFO:     Epoch: 89
2022-12-31 05:17:40,250 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44438891609509784, 'Total loss': 0.44438891609509784} | train loss {'Reaction outcome loss': 0.11525459344488727, 'Total loss': 0.11525459344488727}
2022-12-31 05:17:40,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:40,250 INFO:     Epoch: 90
2022-12-31 05:17:41,882 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4351997743050257, 'Total loss': 0.4351997743050257} | train loss {'Reaction outcome loss': 0.11389500309716546, 'Total loss': 0.11389500309716546}
2022-12-31 05:17:41,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:41,883 INFO:     Epoch: 91
2022-12-31 05:17:43,514 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44944088061650594, 'Total loss': 0.44944088061650594} | train loss {'Reaction outcome loss': 0.11134423885834051, 'Total loss': 0.11134423885834051}
2022-12-31 05:17:43,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:43,514 INFO:     Epoch: 92
2022-12-31 05:17:45,145 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48557275235652925, 'Total loss': 0.48557275235652925} | train loss {'Reaction outcome loss': 0.11759015229036393, 'Total loss': 0.11759015229036393}
2022-12-31 05:17:45,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:45,145 INFO:     Epoch: 93
2022-12-31 05:17:46,792 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4397658328215281, 'Total loss': 0.4397658328215281} | train loss {'Reaction outcome loss': 0.11938014152100047, 'Total loss': 0.11938014152100047}
2022-12-31 05:17:46,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:46,792 INFO:     Epoch: 94
2022-12-31 05:17:48,438 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45305157005786895, 'Total loss': 0.45305157005786895} | train loss {'Reaction outcome loss': 0.11710757203904461, 'Total loss': 0.11710757203904461}
2022-12-31 05:17:48,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:48,439 INFO:     Epoch: 95
2022-12-31 05:17:50,063 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4373621493577957, 'Total loss': 0.4373621493577957} | train loss {'Reaction outcome loss': 0.11573305503559377, 'Total loss': 0.11573305503559377}
2022-12-31 05:17:50,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:50,063 INFO:     Epoch: 96
2022-12-31 05:17:51,694 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44333826303482055, 'Total loss': 0.44333826303482055} | train loss {'Reaction outcome loss': 0.11056361336173617, 'Total loss': 0.11056361336173617}
2022-12-31 05:17:51,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:51,695 INFO:     Epoch: 97
2022-12-31 05:17:53,330 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45353613297144574, 'Total loss': 0.45353613297144574} | train loss {'Reaction outcome loss': 0.11589811792065952, 'Total loss': 0.11589811792065952}
2022-12-31 05:17:53,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:53,331 INFO:     Epoch: 98
2022-12-31 05:17:54,957 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42522414873043696, 'Total loss': 0.42522414873043696} | train loss {'Reaction outcome loss': 0.11191313254852049, 'Total loss': 0.11191313254852049}
2022-12-31 05:17:54,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:54,957 INFO:     Epoch: 99
2022-12-31 05:17:56,627 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4588773638010025, 'Total loss': 0.4588773638010025} | train loss {'Reaction outcome loss': 0.10926792722208836, 'Total loss': 0.10926792722208836}
2022-12-31 05:17:56,628 INFO:     Best model found after epoch 6 of 100.
2022-12-31 05:17:56,628 INFO:   Done with stage: TRAINING
2022-12-31 05:17:56,628 INFO:   Starting stage: EVALUATION
2022-12-31 05:17:56,752 INFO:   Done with stage: EVALUATION
2022-12-31 05:17:56,752 INFO:   Leaving out SEQ value Fold_7
2022-12-31 05:17:56,764 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 05:17:56,764 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:17:57,405 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:17:57,405 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:17:57,475 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:17:57,475 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:17:57,475 INFO:     No hyperparam tuning for this model
2022-12-31 05:17:57,475 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:17:57,475 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:17:57,476 INFO:     None feature selector for col prot
2022-12-31 05:17:57,476 INFO:     None feature selector for col prot
2022-12-31 05:17:57,476 INFO:     None feature selector for col prot
2022-12-31 05:17:57,477 INFO:     None feature selector for col chem
2022-12-31 05:17:57,477 INFO:     None feature selector for col chem
2022-12-31 05:17:57,477 INFO:     None feature selector for col chem
2022-12-31 05:17:57,477 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:17:57,477 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:17:57,479 INFO:     Number of params in model 224011
2022-12-31 05:17:57,482 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:17:57,482 INFO:   Starting stage: TRAINING
2022-12-31 05:17:57,526 INFO:     Val loss before train {'Reaction outcome loss': 1.0519375443458556, 'Total loss': 1.0519375443458556}
2022-12-31 05:17:57,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:57,526 INFO:     Epoch: 0
2022-12-31 05:17:59,132 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5807173550128937, 'Total loss': 0.5807173550128937} | train loss {'Reaction outcome loss': 0.7713862579220381, 'Total loss': 0.7713862579220381}
2022-12-31 05:17:59,133 INFO:     Found new best model at epoch 0
2022-12-31 05:17:59,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:17:59,135 INFO:     Epoch: 1
2022-12-31 05:18:00,744 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5485233187675476, 'Total loss': 0.5485233187675476} | train loss {'Reaction outcome loss': 0.5011416530652797, 'Total loss': 0.5011416530652797}
2022-12-31 05:18:00,744 INFO:     Found new best model at epoch 1
2022-12-31 05:18:00,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:00,745 INFO:     Epoch: 2
2022-12-31 05:18:02,356 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.518464881181717, 'Total loss': 0.518464881181717} | train loss {'Reaction outcome loss': 0.4331887605644408, 'Total loss': 0.4331887605644408}
2022-12-31 05:18:02,356 INFO:     Found new best model at epoch 2
2022-12-31 05:18:02,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:02,357 INFO:     Epoch: 3
2022-12-31 05:18:03,963 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4797379513581594, 'Total loss': 0.4797379513581594} | train loss {'Reaction outcome loss': 0.39638988553604365, 'Total loss': 0.39638988553604365}
2022-12-31 05:18:03,963 INFO:     Found new best model at epoch 3
2022-12-31 05:18:03,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:03,964 INFO:     Epoch: 4
2022-12-31 05:18:05,571 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47184390425682066, 'Total loss': 0.47184390425682066} | train loss {'Reaction outcome loss': 0.3703720144408963, 'Total loss': 0.3703720144408963}
2022-12-31 05:18:05,571 INFO:     Found new best model at epoch 4
2022-12-31 05:18:05,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:05,572 INFO:     Epoch: 5
2022-12-31 05:18:07,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4848840296268463, 'Total loss': 0.4848840296268463} | train loss {'Reaction outcome loss': 0.3479921863356353, 'Total loss': 0.3479921863356353}
2022-12-31 05:18:07,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:07,184 INFO:     Epoch: 6
2022-12-31 05:18:08,832 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4566803087790807, 'Total loss': 0.4566803087790807} | train loss {'Reaction outcome loss': 0.3272739725508096, 'Total loss': 0.3272739725508096}
2022-12-31 05:18:08,833 INFO:     Found new best model at epoch 6
2022-12-31 05:18:08,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:08,834 INFO:     Epoch: 7
2022-12-31 05:18:10,442 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4686919430891673, 'Total loss': 0.4686919430891673} | train loss {'Reaction outcome loss': 0.31201135367155075, 'Total loss': 0.31201135367155075}
2022-12-31 05:18:10,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:10,442 INFO:     Epoch: 8
2022-12-31 05:18:12,091 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5202797691027323, 'Total loss': 0.5202797691027323} | train loss {'Reaction outcome loss': 0.30139450281312613, 'Total loss': 0.30139450281312613}
2022-12-31 05:18:12,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:12,091 INFO:     Epoch: 9
2022-12-31 05:18:13,700 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43905378902951875, 'Total loss': 0.43905378902951875} | train loss {'Reaction outcome loss': 0.2897859232520664, 'Total loss': 0.2897859232520664}
2022-12-31 05:18:13,700 INFO:     Found new best model at epoch 9
2022-12-31 05:18:13,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:13,701 INFO:     Epoch: 10
2022-12-31 05:18:15,311 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4746149092912674, 'Total loss': 0.4746149092912674} | train loss {'Reaction outcome loss': 0.2777431030849834, 'Total loss': 0.2777431030849834}
2022-12-31 05:18:15,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:15,311 INFO:     Epoch: 11
2022-12-31 05:18:16,938 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4431858609120051, 'Total loss': 0.4431858609120051} | train loss {'Reaction outcome loss': 0.2643954944643345, 'Total loss': 0.2643954944643345}
2022-12-31 05:18:16,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:16,938 INFO:     Epoch: 12
2022-12-31 05:18:18,536 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4580084244410197, 'Total loss': 0.4580084244410197} | train loss {'Reaction outcome loss': 0.25453475275974136, 'Total loss': 0.25453475275974136}
2022-12-31 05:18:18,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:18,537 INFO:     Epoch: 13
2022-12-31 05:18:20,136 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46283565858999887, 'Total loss': 0.46283565858999887} | train loss {'Reaction outcome loss': 0.24467655900360902, 'Total loss': 0.24467655900360902}
2022-12-31 05:18:20,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:20,136 INFO:     Epoch: 14
2022-12-31 05:18:21,771 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4897247592608134, 'Total loss': 0.4897247592608134} | train loss {'Reaction outcome loss': 0.23616333563740438, 'Total loss': 0.23616333563740438}
2022-12-31 05:18:21,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:21,772 INFO:     Epoch: 15
2022-12-31 05:18:23,419 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4673105299472809, 'Total loss': 0.4673105299472809} | train loss {'Reaction outcome loss': 0.23153712738291685, 'Total loss': 0.23153712738291685}
2022-12-31 05:18:23,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:23,420 INFO:     Epoch: 16
2022-12-31 05:18:25,020 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4703058401743571, 'Total loss': 0.4703058401743571} | train loss {'Reaction outcome loss': 0.22486429874386107, 'Total loss': 0.22486429874386107}
2022-12-31 05:18:25,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:25,020 INFO:     Epoch: 17
2022-12-31 05:18:26,674 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49431477884451547, 'Total loss': 0.49431477884451547} | train loss {'Reaction outcome loss': 0.21942442401752368, 'Total loss': 0.21942442401752368}
2022-12-31 05:18:26,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:26,675 INFO:     Epoch: 18
2022-12-31 05:18:28,278 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48701162338256837, 'Total loss': 0.48701162338256837} | train loss {'Reaction outcome loss': 0.2117229373409198, 'Total loss': 0.2117229373409198}
2022-12-31 05:18:28,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:28,279 INFO:     Epoch: 19
2022-12-31 05:18:29,930 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4580726087093353, 'Total loss': 0.4580726087093353} | train loss {'Reaction outcome loss': 0.20673965474406442, 'Total loss': 0.20673965474406442}
2022-12-31 05:18:29,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:29,931 INFO:     Epoch: 20
2022-12-31 05:18:31,533 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4738997394839923, 'Total loss': 0.4738997394839923} | train loss {'Reaction outcome loss': 0.19905211352112093, 'Total loss': 0.19905211352112093}
2022-12-31 05:18:31,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:31,534 INFO:     Epoch: 21
2022-12-31 05:18:33,185 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4509390264749527, 'Total loss': 0.4509390264749527} | train loss {'Reaction outcome loss': 0.1952607967641764, 'Total loss': 0.1952607967641764}
2022-12-31 05:18:33,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:33,185 INFO:     Epoch: 22
2022-12-31 05:18:34,806 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4817786494890849, 'Total loss': 0.4817786494890849} | train loss {'Reaction outcome loss': 0.19080872939483368, 'Total loss': 0.19080872939483368}
2022-12-31 05:18:34,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:34,806 INFO:     Epoch: 23
2022-12-31 05:18:36,457 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.463382322449858, 'Total loss': 0.463382322449858} | train loss {'Reaction outcome loss': 0.18954549136574997, 'Total loss': 0.18954549136574997}
2022-12-31 05:18:36,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:36,458 INFO:     Epoch: 24
2022-12-31 05:18:38,066 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4852770119905472, 'Total loss': 0.4852770119905472} | train loss {'Reaction outcome loss': 0.18462568896757814, 'Total loss': 0.18462568896757814}
2022-12-31 05:18:38,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:38,066 INFO:     Epoch: 25
2022-12-31 05:18:39,718 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4838698337475459, 'Total loss': 0.4838698337475459} | train loss {'Reaction outcome loss': 0.18198106591436233, 'Total loss': 0.18198106591436233}
2022-12-31 05:18:39,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:39,719 INFO:     Epoch: 26
2022-12-31 05:18:41,331 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5031213621298473, 'Total loss': 0.5031213621298473} | train loss {'Reaction outcome loss': 0.17640602912740175, 'Total loss': 0.17640602912740175}
2022-12-31 05:18:41,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:41,331 INFO:     Epoch: 27
2022-12-31 05:18:42,983 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4873587727546692, 'Total loss': 0.4873587727546692} | train loss {'Reaction outcome loss': 0.1702841568683639, 'Total loss': 0.1702841568683639}
2022-12-31 05:18:42,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:42,984 INFO:     Epoch: 28
2022-12-31 05:18:44,588 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5056377043326695, 'Total loss': 0.5056377043326695} | train loss {'Reaction outcome loss': 0.1724052501317018, 'Total loss': 0.1724052501317018}
2022-12-31 05:18:44,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:44,589 INFO:     Epoch: 29
2022-12-31 05:18:46,229 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4994964172442754, 'Total loss': 0.4994964172442754} | train loss {'Reaction outcome loss': 0.1679457462863526, 'Total loss': 0.1679457462863526}
2022-12-31 05:18:46,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:46,230 INFO:     Epoch: 30
2022-12-31 05:18:47,877 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49090645611286166, 'Total loss': 0.49090645611286166} | train loss {'Reaction outcome loss': 0.16671361040064703, 'Total loss': 0.16671361040064703}
2022-12-31 05:18:47,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:47,878 INFO:     Epoch: 31
2022-12-31 05:18:49,472 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.500436416765054, 'Total loss': 0.500436416765054} | train loss {'Reaction outcome loss': 0.16046782602102327, 'Total loss': 0.16046782602102327}
2022-12-31 05:18:49,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:49,473 INFO:     Epoch: 32
2022-12-31 05:18:51,073 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4840499361356099, 'Total loss': 0.4840499361356099} | train loss {'Reaction outcome loss': 0.16257042999996807, 'Total loss': 0.16257042999996807}
2022-12-31 05:18:51,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:51,073 INFO:     Epoch: 33
2022-12-31 05:18:52,709 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5080219864845276, 'Total loss': 0.5080219864845276} | train loss {'Reaction outcome loss': 0.1568136740264384, 'Total loss': 0.1568136740264384}
2022-12-31 05:18:52,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:52,709 INFO:     Epoch: 34
2022-12-31 05:18:54,327 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5051075100898743, 'Total loss': 0.5051075100898743} | train loss {'Reaction outcome loss': 0.15456387691281653, 'Total loss': 0.15456387691281653}
2022-12-31 05:18:54,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:54,327 INFO:     Epoch: 35
2022-12-31 05:18:55,947 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4999351441860199, 'Total loss': 0.4999351441860199} | train loss {'Reaction outcome loss': 0.15410618452635003, 'Total loss': 0.15410618452635003}
2022-12-31 05:18:55,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:55,947 INFO:     Epoch: 36
2022-12-31 05:18:57,567 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5322380085786184, 'Total loss': 0.5322380085786184} | train loss {'Reaction outcome loss': 0.15129233528979313, 'Total loss': 0.15129233528979313}
2022-12-31 05:18:57,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:57,568 INFO:     Epoch: 37
2022-12-31 05:18:59,190 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4952492892742157, 'Total loss': 0.4952492892742157} | train loss {'Reaction outcome loss': 0.15185109899919172, 'Total loss': 0.15185109899919172}
2022-12-31 05:18:59,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:18:59,190 INFO:     Epoch: 38
2022-12-31 05:19:00,790 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48146464427312213, 'Total loss': 0.48146464427312213} | train loss {'Reaction outcome loss': 0.14755193168986522, 'Total loss': 0.14755193168986522}
2022-12-31 05:19:00,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:00,791 INFO:     Epoch: 39
2022-12-31 05:19:02,412 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49550283706436554, 'Total loss': 0.49550283706436554} | train loss {'Reaction outcome loss': 0.14827781479682897, 'Total loss': 0.14827781479682897}
2022-12-31 05:19:02,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:02,412 INFO:     Epoch: 40
2022-12-31 05:19:04,062 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4722406546274821, 'Total loss': 0.4722406546274821} | train loss {'Reaction outcome loss': 0.14458654903475837, 'Total loss': 0.14458654903475837}
2022-12-31 05:19:04,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:04,062 INFO:     Epoch: 41
2022-12-31 05:19:05,714 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5060869018236797, 'Total loss': 0.5060869018236797} | train loss {'Reaction outcome loss': 0.14381151273846626, 'Total loss': 0.14381151273846626}
2022-12-31 05:19:05,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:05,716 INFO:     Epoch: 42
2022-12-31 05:19:07,317 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5233415424823761, 'Total loss': 0.5233415424823761} | train loss {'Reaction outcome loss': 0.14707621693612852, 'Total loss': 0.14707621693612852}
2022-12-31 05:19:07,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:07,317 INFO:     Epoch: 43
2022-12-31 05:19:08,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4604275518407424, 'Total loss': 0.4604275518407424} | train loss {'Reaction outcome loss': 0.1418390255694315, 'Total loss': 0.1418390255694315}
2022-12-31 05:19:08,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:08,955 INFO:     Epoch: 44
2022-12-31 05:19:10,605 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4760057469209035, 'Total loss': 0.4760057469209035} | train loss {'Reaction outcome loss': 0.1359870633990555, 'Total loss': 0.1359870633990555}
2022-12-31 05:19:10,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:10,605 INFO:     Epoch: 45
2022-12-31 05:19:12,235 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4958401143550873, 'Total loss': 0.4958401143550873} | train loss {'Reaction outcome loss': 0.13510437718091103, 'Total loss': 0.13510437718091103}
2022-12-31 05:19:12,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:12,236 INFO:     Epoch: 46
2022-12-31 05:19:13,841 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48616654947400095, 'Total loss': 0.48616654947400095} | train loss {'Reaction outcome loss': 0.13645554031160123, 'Total loss': 0.13645554031160123}
2022-12-31 05:19:13,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:13,841 INFO:     Epoch: 47
2022-12-31 05:19:15,491 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4895950237909953, 'Total loss': 0.4895950237909953} | train loss {'Reaction outcome loss': 0.1382310345953146, 'Total loss': 0.1382310345953146}
2022-12-31 05:19:15,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:15,491 INFO:     Epoch: 48
2022-12-31 05:19:17,126 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4842926263809204, 'Total loss': 0.4842926263809204} | train loss {'Reaction outcome loss': 0.13094406134889022, 'Total loss': 0.13094406134889022}
2022-12-31 05:19:17,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:17,126 INFO:     Epoch: 49
2022-12-31 05:19:18,776 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49432258009910585, 'Total loss': 0.49432258009910585} | train loss {'Reaction outcome loss': 0.13424307025709759, 'Total loss': 0.13424307025709759}
2022-12-31 05:19:18,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:18,776 INFO:     Epoch: 50
2022-12-31 05:19:20,416 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5068263759215673, 'Total loss': 0.5068263759215673} | train loss {'Reaction outcome loss': 0.13143996287464768, 'Total loss': 0.13143996287464768}
2022-12-31 05:19:20,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:20,417 INFO:     Epoch: 51
2022-12-31 05:19:22,066 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4642936279376348, 'Total loss': 0.4642936279376348} | train loss {'Reaction outcome loss': 0.1307649139976709, 'Total loss': 0.1307649139976709}
2022-12-31 05:19:22,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:22,066 INFO:     Epoch: 52
2022-12-31 05:19:23,715 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44907974104086557, 'Total loss': 0.44907974104086557} | train loss {'Reaction outcome loss': 0.1322911577265123, 'Total loss': 0.1322911577265123}
2022-12-31 05:19:23,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:23,715 INFO:     Epoch: 53
2022-12-31 05:19:25,315 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47719386108219625, 'Total loss': 0.47719386108219625} | train loss {'Reaction outcome loss': 0.12976879782756387, 'Total loss': 0.12976879782756387}
2022-12-31 05:19:25,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:25,316 INFO:     Epoch: 54
2022-12-31 05:19:26,908 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5278338303168615, 'Total loss': 0.5278338303168615} | train loss {'Reaction outcome loss': 0.12933685565060313, 'Total loss': 0.12933685565060313}
2022-12-31 05:19:26,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:26,908 INFO:     Epoch: 55
2022-12-31 05:19:28,556 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5026398122310638, 'Total loss': 0.5026398122310638} | train loss {'Reaction outcome loss': 0.12885843326197766, 'Total loss': 0.12885843326197766}
2022-12-31 05:19:28,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:28,557 INFO:     Epoch: 56
2022-12-31 05:19:30,179 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5319439520438513, 'Total loss': 0.5319439520438513} | train loss {'Reaction outcome loss': 0.12987651589886037, 'Total loss': 0.12987651589886037}
2022-12-31 05:19:30,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:30,179 INFO:     Epoch: 57
2022-12-31 05:19:31,800 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5011780540148417, 'Total loss': 0.5011780540148417} | train loss {'Reaction outcome loss': 0.12364384479097504, 'Total loss': 0.12364384479097504}
2022-12-31 05:19:31,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:31,801 INFO:     Epoch: 58
2022-12-31 05:19:33,421 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5091603100299835, 'Total loss': 0.5091603100299835} | train loss {'Reaction outcome loss': 0.12391066083159202, 'Total loss': 0.12391066083159202}
2022-12-31 05:19:33,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:33,421 INFO:     Epoch: 59
2022-12-31 05:19:35,039 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5055076266328494, 'Total loss': 0.5055076266328494} | train loss {'Reaction outcome loss': 0.12815806204487226, 'Total loss': 0.12815806204487226}
2022-12-31 05:19:35,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:35,039 INFO:     Epoch: 60
2022-12-31 05:19:36,651 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4896843532721202, 'Total loss': 0.4896843532721202} | train loss {'Reaction outcome loss': 0.12318740641500378, 'Total loss': 0.12318740641500378}
2022-12-31 05:19:36,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:36,653 INFO:     Epoch: 61
2022-12-31 05:19:38,271 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5044956604639689, 'Total loss': 0.5044956604639689} | train loss {'Reaction outcome loss': 0.12309522722121123, 'Total loss': 0.12309522722121123}
2022-12-31 05:19:38,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:38,271 INFO:     Epoch: 62
2022-12-31 05:19:39,905 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5009599020083745, 'Total loss': 0.5009599020083745} | train loss {'Reaction outcome loss': 0.12305839633528184, 'Total loss': 0.12305839633528184}
2022-12-31 05:19:39,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:39,905 INFO:     Epoch: 63
2022-12-31 05:19:41,537 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5061433990796407, 'Total loss': 0.5061433990796407} | train loss {'Reaction outcome loss': 0.12238652713856091, 'Total loss': 0.12238652713856091}
2022-12-31 05:19:41,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:41,537 INFO:     Epoch: 64
2022-12-31 05:19:43,158 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5267056961854298, 'Total loss': 0.5267056961854298} | train loss {'Reaction outcome loss': 0.12229336191466822, 'Total loss': 0.12229336191466822}
2022-12-31 05:19:43,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:43,159 INFO:     Epoch: 65
2022-12-31 05:19:44,766 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5145798494418462, 'Total loss': 0.5145798494418462} | train loss {'Reaction outcome loss': 0.1256214092543601, 'Total loss': 0.1256214092543601}
2022-12-31 05:19:44,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:44,767 INFO:     Epoch: 66
2022-12-31 05:19:46,379 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5066324214140574, 'Total loss': 0.5066324214140574} | train loss {'Reaction outcome loss': 0.11815445244332755, 'Total loss': 0.11815445244332755}
2022-12-31 05:19:46,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:46,379 INFO:     Epoch: 67
2022-12-31 05:19:47,983 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4769373873869578, 'Total loss': 0.4769373873869578} | train loss {'Reaction outcome loss': 0.11947896589282832, 'Total loss': 0.11947896589282832}
2022-12-31 05:19:47,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:47,983 INFO:     Epoch: 68
2022-12-31 05:19:49,599 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.489059520761172, 'Total loss': 0.489059520761172} | train loss {'Reaction outcome loss': 0.11657050085141436, 'Total loss': 0.11657050085141436}
2022-12-31 05:19:49,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:49,599 INFO:     Epoch: 69
2022-12-31 05:19:51,216 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5259285569190979, 'Total loss': 0.5259285569190979} | train loss {'Reaction outcome loss': 0.12047125409773445, 'Total loss': 0.12047125409773445}
2022-12-31 05:19:51,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:51,216 INFO:     Epoch: 70
2022-12-31 05:19:52,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5371834352612496, 'Total loss': 0.5371834352612496} | train loss {'Reaction outcome loss': 0.12091637335226431, 'Total loss': 0.12091637335226431}
2022-12-31 05:19:52,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:52,830 INFO:     Epoch: 71
2022-12-31 05:19:54,439 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4693962020178636, 'Total loss': 0.4693962020178636} | train loss {'Reaction outcome loss': 0.11947811895302554, 'Total loss': 0.11947811895302554}
2022-12-31 05:19:54,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:54,439 INFO:     Epoch: 72
2022-12-31 05:19:56,055 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5195093085368474, 'Total loss': 0.5195093085368474} | train loss {'Reaction outcome loss': 0.11443304038357549, 'Total loss': 0.11443304038357549}
2022-12-31 05:19:56,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:56,056 INFO:     Epoch: 73
2022-12-31 05:19:57,677 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5201634715000788, 'Total loss': 0.5201634715000788} | train loss {'Reaction outcome loss': 0.11817984757927884, 'Total loss': 0.11817984757927884}
2022-12-31 05:19:57,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:57,677 INFO:     Epoch: 74
2022-12-31 05:19:59,287 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5200118939081828, 'Total loss': 0.5200118939081828} | train loss {'Reaction outcome loss': 0.11527240706519001, 'Total loss': 0.11527240706519001}
2022-12-31 05:19:59,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:19:59,287 INFO:     Epoch: 75
2022-12-31 05:20:00,935 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5158748586972555, 'Total loss': 0.5158748586972555} | train loss {'Reaction outcome loss': 0.11499898728228859, 'Total loss': 0.11499898728228859}
2022-12-31 05:20:00,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:00,936 INFO:     Epoch: 76
2022-12-31 05:20:02,540 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45816433324168127, 'Total loss': 0.45816433324168127} | train loss {'Reaction outcome loss': 0.11746170719396391, 'Total loss': 0.11746170719396391}
2022-12-31 05:20:02,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:02,541 INFO:     Epoch: 77
2022-12-31 05:20:04,135 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5125586713353792, 'Total loss': 0.5125586713353792} | train loss {'Reaction outcome loss': 0.11588266051814451, 'Total loss': 0.11588266051814451}
2022-12-31 05:20:04,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:04,135 INFO:     Epoch: 78
2022-12-31 05:20:05,783 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4905950759847959, 'Total loss': 0.4905950759847959} | train loss {'Reaction outcome loss': 0.11113465883199385, 'Total loss': 0.11113465883199385}
2022-12-31 05:20:05,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:05,783 INFO:     Epoch: 79
2022-12-31 05:20:07,385 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5116941111783186, 'Total loss': 0.5116941111783186} | train loss {'Reaction outcome loss': 0.11014703695147192, 'Total loss': 0.11014703695147192}
2022-12-31 05:20:07,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:07,386 INFO:     Epoch: 80
2022-12-31 05:20:09,034 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5374693254629771, 'Total loss': 0.5374693254629771} | train loss {'Reaction outcome loss': 0.11865762880604182, 'Total loss': 0.11865762880604182}
2022-12-31 05:20:09,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:09,034 INFO:     Epoch: 81
2022-12-31 05:20:10,645 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48761609233915804, 'Total loss': 0.48761609233915804} | train loss {'Reaction outcome loss': 0.1140732151002456, 'Total loss': 0.1140732151002456}
2022-12-31 05:20:10,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:10,645 INFO:     Epoch: 82
2022-12-31 05:20:12,277 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5339959184328715, 'Total loss': 0.5339959184328715} | train loss {'Reaction outcome loss': 0.11533358281532868, 'Total loss': 0.11533358281532868}
2022-12-31 05:20:12,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:12,278 INFO:     Epoch: 83
2022-12-31 05:20:13,891 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4946711540222168, 'Total loss': 0.4946711540222168} | train loss {'Reaction outcome loss': 0.10999064186192203, 'Total loss': 0.10999064186192203}
2022-12-31 05:20:13,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:13,891 INFO:     Epoch: 84
2022-12-31 05:20:15,497 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5133191247781118, 'Total loss': 0.5133191247781118} | train loss {'Reaction outcome loss': 0.11502899753352824, 'Total loss': 0.11502899753352824}
2022-12-31 05:20:15,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:15,497 INFO:     Epoch: 85
2022-12-31 05:20:17,112 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49803453584512075, 'Total loss': 0.49803453584512075} | train loss {'Reaction outcome loss': 0.1082031822510937, 'Total loss': 0.1082031822510937}
2022-12-31 05:20:17,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:17,112 INFO:     Epoch: 86
2022-12-31 05:20:18,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49869821667671205, 'Total loss': 0.49869821667671205} | train loss {'Reaction outcome loss': 0.10604485408565023, 'Total loss': 0.10604485408565023}
2022-12-31 05:20:18,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:18,727 INFO:     Epoch: 87
2022-12-31 05:20:20,344 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5101062993208567, 'Total loss': 0.5101062993208567} | train loss {'Reaction outcome loss': 0.10859066942338269, 'Total loss': 0.10859066942338269}
2022-12-31 05:20:20,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:20,344 INFO:     Epoch: 88
2022-12-31 05:20:21,951 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5213104883829752, 'Total loss': 0.5213104883829752} | train loss {'Reaction outcome loss': 0.11577826570685366, 'Total loss': 0.11577826570685366}
2022-12-31 05:20:21,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:21,951 INFO:     Epoch: 89
2022-12-31 05:20:23,565 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5258263890941938, 'Total loss': 0.5258263890941938} | train loss {'Reaction outcome loss': 0.10923671596316832, 'Total loss': 0.10923671596316832}
2022-12-31 05:20:23,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:23,565 INFO:     Epoch: 90
2022-12-31 05:20:25,187 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48867438435554506, 'Total loss': 0.48867438435554506} | train loss {'Reaction outcome loss': 0.10990823345640913, 'Total loss': 0.10990823345640913}
2022-12-31 05:20:25,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:25,187 INFO:     Epoch: 91
2022-12-31 05:20:26,795 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4687023570140203, 'Total loss': 0.4687023570140203} | train loss {'Reaction outcome loss': 0.11110735072962422, 'Total loss': 0.11110735072962422}
2022-12-31 05:20:26,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:26,795 INFO:     Epoch: 92
2022-12-31 05:20:28,443 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5040330290794373, 'Total loss': 0.5040330290794373} | train loss {'Reaction outcome loss': 0.1181547260560068, 'Total loss': 0.1181547260560068}
2022-12-31 05:20:28,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:28,444 INFO:     Epoch: 93
2022-12-31 05:20:30,085 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5057059993346532, 'Total loss': 0.5057059993346532} | train loss {'Reaction outcome loss': 0.10946406048105095, 'Total loss': 0.10946406048105095}
2022-12-31 05:20:30,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:30,085 INFO:     Epoch: 94
2022-12-31 05:20:31,691 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5236945917208989, 'Total loss': 0.5236945917208989} | train loss {'Reaction outcome loss': 0.10692178229238469, 'Total loss': 0.10692178229238469}
2022-12-31 05:20:31,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:31,692 INFO:     Epoch: 95
2022-12-31 05:20:33,306 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5193426910787821, 'Total loss': 0.5193426910787821} | train loss {'Reaction outcome loss': 0.10996993143459434, 'Total loss': 0.10996993143459434}
2022-12-31 05:20:33,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:33,306 INFO:     Epoch: 96
2022-12-31 05:20:34,912 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5222608715295791, 'Total loss': 0.5222608715295791} | train loss {'Reaction outcome loss': 0.10969828581437469, 'Total loss': 0.10969828581437469}
2022-12-31 05:20:34,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:34,912 INFO:     Epoch: 97
2022-12-31 05:20:36,529 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48071515361468, 'Total loss': 0.48071515361468} | train loss {'Reaction outcome loss': 0.10818129520941758, 'Total loss': 0.10818129520941758}
2022-12-31 05:20:36,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:36,530 INFO:     Epoch: 98
2022-12-31 05:20:38,143 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5013233443101247, 'Total loss': 0.5013233443101247} | train loss {'Reaction outcome loss': 0.10903054976753973, 'Total loss': 0.10903054976753973}
2022-12-31 05:20:38,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:38,143 INFO:     Epoch: 99
2022-12-31 05:20:39,758 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5229138394196828, 'Total loss': 0.5229138394196828} | train loss {'Reaction outcome loss': 0.10796539061583388, 'Total loss': 0.10796539061583388}
2022-12-31 05:20:39,758 INFO:     Best model found after epoch 10 of 100.
2022-12-31 05:20:39,759 INFO:   Done with stage: TRAINING
2022-12-31 05:20:39,759 INFO:   Starting stage: EVALUATION
2022-12-31 05:20:39,900 INFO:   Done with stage: EVALUATION
2022-12-31 05:20:39,900 INFO:   Leaving out SEQ value Fold_8
2022-12-31 05:20:39,913 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:20:39,913 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:20:40,559 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:20:40,559 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:20:40,628 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:20:40,628 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:20:40,628 INFO:     No hyperparam tuning for this model
2022-12-31 05:20:40,628 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:20:40,628 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:20:40,629 INFO:     None feature selector for col prot
2022-12-31 05:20:40,629 INFO:     None feature selector for col prot
2022-12-31 05:20:40,629 INFO:     None feature selector for col prot
2022-12-31 05:20:40,630 INFO:     None feature selector for col chem
2022-12-31 05:20:40,630 INFO:     None feature selector for col chem
2022-12-31 05:20:40,630 INFO:     None feature selector for col chem
2022-12-31 05:20:40,630 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:20:40,630 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:20:40,632 INFO:     Number of params in model 224011
2022-12-31 05:20:40,635 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:20:40,635 INFO:   Starting stage: TRAINING
2022-12-31 05:20:40,681 INFO:     Val loss before train {'Reaction outcome loss': 0.9468007206916809, 'Total loss': 0.9468007206916809}
2022-12-31 05:20:40,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:40,681 INFO:     Epoch: 0
2022-12-31 05:20:42,298 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5637014051278432, 'Total loss': 0.5637014051278432} | train loss {'Reaction outcome loss': 0.7952364091691814, 'Total loss': 0.7952364091691814}
2022-12-31 05:20:42,299 INFO:     Found new best model at epoch 0
2022-12-31 05:20:42,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:42,300 INFO:     Epoch: 1
2022-12-31 05:20:43,965 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4896960218747457, 'Total loss': 0.4896960218747457} | train loss {'Reaction outcome loss': 0.5131540012316428, 'Total loss': 0.5131540012316428}
2022-12-31 05:20:43,966 INFO:     Found new best model at epoch 1
2022-12-31 05:20:43,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:43,967 INFO:     Epoch: 2
2022-12-31 05:20:45,589 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4476330508788427, 'Total loss': 0.4476330508788427} | train loss {'Reaction outcome loss': 0.4421994598055987, 'Total loss': 0.4421994598055987}
2022-12-31 05:20:45,590 INFO:     Found new best model at epoch 2
2022-12-31 05:20:45,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:45,591 INFO:     Epoch: 3
2022-12-31 05:20:47,211 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42462038397789004, 'Total loss': 0.42462038397789004} | train loss {'Reaction outcome loss': 0.40735816761203436, 'Total loss': 0.40735816761203436}
2022-12-31 05:20:47,211 INFO:     Found new best model at epoch 3
2022-12-31 05:20:47,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:47,212 INFO:     Epoch: 4
2022-12-31 05:20:48,836 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4293535083532333, 'Total loss': 0.4293535083532333} | train loss {'Reaction outcome loss': 0.3836192676014658, 'Total loss': 0.3836192676014658}
2022-12-31 05:20:48,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:48,837 INFO:     Epoch: 5
2022-12-31 05:20:50,459 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41377953489621483, 'Total loss': 0.41377953489621483} | train loss {'Reaction outcome loss': 0.36165196545746015, 'Total loss': 0.36165196545746015}
2022-12-31 05:20:50,459 INFO:     Found new best model at epoch 5
2022-12-31 05:20:50,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:50,460 INFO:     Epoch: 6
2022-12-31 05:20:52,075 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4157464444637299, 'Total loss': 0.4157464444637299} | train loss {'Reaction outcome loss': 0.34569235062361625, 'Total loss': 0.34569235062361625}
2022-12-31 05:20:52,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:52,075 INFO:     Epoch: 7
2022-12-31 05:20:53,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41685220301151277, 'Total loss': 0.41685220301151277} | train loss {'Reaction outcome loss': 0.32355991522174166, 'Total loss': 0.32355991522174166}
2022-12-31 05:20:53,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:53,708 INFO:     Epoch: 8
2022-12-31 05:20:55,374 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43375317653020223, 'Total loss': 0.43375317653020223} | train loss {'Reaction outcome loss': 0.3136064403190993, 'Total loss': 0.3136064403190993}
2022-12-31 05:20:55,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:55,374 INFO:     Epoch: 9
2022-12-31 05:20:56,992 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4159932871659597, 'Total loss': 0.4159932871659597} | train loss {'Reaction outcome loss': 0.3194513037679312, 'Total loss': 0.3194513037679312}
2022-12-31 05:20:56,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:56,992 INFO:     Epoch: 10
2022-12-31 05:20:58,619 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42075269917647046, 'Total loss': 0.42075269917647046} | train loss {'Reaction outcome loss': 0.2794145691289526, 'Total loss': 0.2794145691289526}
2022-12-31 05:20:58,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:20:58,619 INFO:     Epoch: 11
2022-12-31 05:21:00,252 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4074080546696981, 'Total loss': 0.4074080546696981} | train loss {'Reaction outcome loss': 0.2672817418844742, 'Total loss': 0.2672817418844742}
2022-12-31 05:21:00,252 INFO:     Found new best model at epoch 11
2022-12-31 05:21:00,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:00,253 INFO:     Epoch: 12
2022-12-31 05:21:01,876 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3965110590060552, 'Total loss': 0.3965110590060552} | train loss {'Reaction outcome loss': 0.25530912787299087, 'Total loss': 0.25530912787299087}
2022-12-31 05:21:01,877 INFO:     Found new best model at epoch 12
2022-12-31 05:21:01,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:01,878 INFO:     Epoch: 13
2022-12-31 05:21:03,509 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4186834285656611, 'Total loss': 0.4186834285656611} | train loss {'Reaction outcome loss': 0.250318655286126, 'Total loss': 0.250318655286126}
2022-12-31 05:21:03,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:03,509 INFO:     Epoch: 14
2022-12-31 05:21:05,141 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39392491231362026, 'Total loss': 0.39392491231362026} | train loss {'Reaction outcome loss': 0.23925762461452826, 'Total loss': 0.23925762461452826}
2022-12-31 05:21:05,141 INFO:     Found new best model at epoch 14
2022-12-31 05:21:05,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:05,142 INFO:     Epoch: 15
2022-12-31 05:21:06,591 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40376296589771904, 'Total loss': 0.40376296589771904} | train loss {'Reaction outcome loss': 0.22851237177214437, 'Total loss': 0.22851237177214437}
2022-12-31 05:21:06,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:06,591 INFO:     Epoch: 16
2022-12-31 05:21:07,705 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43049775262673695, 'Total loss': 0.43049775262673695} | train loss {'Reaction outcome loss': 0.22718382227585476, 'Total loss': 0.22718382227585476}
2022-12-31 05:21:07,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:07,705 INFO:     Epoch: 17
2022-12-31 05:21:08,878 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38503633067011833, 'Total loss': 0.38503633067011833} | train loss {'Reaction outcome loss': 0.21682139133580663, 'Total loss': 0.21682139133580663}
2022-12-31 05:21:08,878 INFO:     Found new best model at epoch 17
2022-12-31 05:21:08,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:08,879 INFO:     Epoch: 18
2022-12-31 05:21:09,988 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40802019139130913, 'Total loss': 0.40802019139130913} | train loss {'Reaction outcome loss': 0.21234551349492825, 'Total loss': 0.21234551349492825}
2022-12-31 05:21:09,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:09,988 INFO:     Epoch: 19
2022-12-31 05:21:11,273 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4031247307856878, 'Total loss': 0.4031247307856878} | train loss {'Reaction outcome loss': 0.2057822290841706, 'Total loss': 0.2057822290841706}
2022-12-31 05:21:11,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:11,273 INFO:     Epoch: 20
2022-12-31 05:21:12,904 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41772642930348713, 'Total loss': 0.41772642930348713} | train loss {'Reaction outcome loss': 0.19902363566992184, 'Total loss': 0.19902363566992184}
2022-12-31 05:21:12,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:12,904 INFO:     Epoch: 21
2022-12-31 05:21:14,536 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39794096946716306, 'Total loss': 0.39794096946716306} | train loss {'Reaction outcome loss': 0.1919417049106467, 'Total loss': 0.1919417049106467}
2022-12-31 05:21:14,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:14,537 INFO:     Epoch: 22
2022-12-31 05:21:16,188 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3937506896754106, 'Total loss': 0.3937506896754106} | train loss {'Reaction outcome loss': 0.18748168181986513, 'Total loss': 0.18748168181986513}
2022-12-31 05:21:16,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:16,189 INFO:     Epoch: 23
2022-12-31 05:21:17,809 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.419625120361646, 'Total loss': 0.419625120361646} | train loss {'Reaction outcome loss': 0.1854140880699877, 'Total loss': 0.1854140880699877}
2022-12-31 05:21:17,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:17,809 INFO:     Epoch: 24
2022-12-31 05:21:19,426 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37408763021230695, 'Total loss': 0.37408763021230695} | train loss {'Reaction outcome loss': 0.1946957734062512, 'Total loss': 0.1946957734062512}
2022-12-31 05:21:19,426 INFO:     Found new best model at epoch 24
2022-12-31 05:21:19,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:19,427 INFO:     Epoch: 25
2022-12-31 05:21:21,041 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3707225346316894, 'Total loss': 0.3707225346316894} | train loss {'Reaction outcome loss': 0.19176609194318703, 'Total loss': 0.19176609194318703}
2022-12-31 05:21:21,041 INFO:     Found new best model at epoch 25
2022-12-31 05:21:21,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:21,043 INFO:     Epoch: 26
2022-12-31 05:21:22,658 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3969540650645892, 'Total loss': 0.3969540650645892} | train loss {'Reaction outcome loss': 0.17379200161245745, 'Total loss': 0.17379200161245745}
2022-12-31 05:21:22,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:22,658 INFO:     Epoch: 27
2022-12-31 05:21:24,275 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41571055849393207, 'Total loss': 0.41571055849393207} | train loss {'Reaction outcome loss': 0.1719941790148184, 'Total loss': 0.1719941790148184}
2022-12-31 05:21:24,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:24,275 INFO:     Epoch: 28
2022-12-31 05:21:25,928 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39047787537177403, 'Total loss': 0.39047787537177403} | train loss {'Reaction outcome loss': 0.171553374590682, 'Total loss': 0.171553374590682}
2022-12-31 05:21:25,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:25,928 INFO:     Epoch: 29
2022-12-31 05:21:27,549 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40741020838419595, 'Total loss': 0.40741020838419595} | train loss {'Reaction outcome loss': 0.16546180476333297, 'Total loss': 0.16546180476333297}
2022-12-31 05:21:27,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:27,549 INFO:     Epoch: 30
2022-12-31 05:21:29,203 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4043756147225698, 'Total loss': 0.4043756147225698} | train loss {'Reaction outcome loss': 0.16550061877806793, 'Total loss': 0.16550061877806793}
2022-12-31 05:21:29,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:29,203 INFO:     Epoch: 31
2022-12-31 05:21:30,835 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41223360896110534, 'Total loss': 0.41223360896110534} | train loss {'Reaction outcome loss': 0.16450532282486666, 'Total loss': 0.16450532282486666}
2022-12-31 05:21:30,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:30,835 INFO:     Epoch: 32
2022-12-31 05:21:32,467 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42181168297926586, 'Total loss': 0.42181168297926586} | train loss {'Reaction outcome loss': 0.16698953312943163, 'Total loss': 0.16698953312943163}
2022-12-31 05:21:32,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:32,467 INFO:     Epoch: 33
2022-12-31 05:21:34,100 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4036885624130567, 'Total loss': 0.4036885624130567} | train loss {'Reaction outcome loss': 0.1574860981718698, 'Total loss': 0.1574860981718698}
2022-12-31 05:21:34,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:34,101 INFO:     Epoch: 34
2022-12-31 05:21:35,723 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38514782935380937, 'Total loss': 0.38514782935380937} | train loss {'Reaction outcome loss': 0.15593767918281906, 'Total loss': 0.15593767918281906}
2022-12-31 05:21:35,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:35,724 INFO:     Epoch: 35
2022-12-31 05:21:37,355 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4015393222371737, 'Total loss': 0.4015393222371737} | train loss {'Reaction outcome loss': 0.15309997712535298, 'Total loss': 0.15309997712535298}
2022-12-31 05:21:37,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:37,356 INFO:     Epoch: 36
2022-12-31 05:21:39,003 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40953663289546965, 'Total loss': 0.40953663289546965} | train loss {'Reaction outcome loss': 0.15043657471128888, 'Total loss': 0.15043657471128888}
2022-12-31 05:21:39,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:39,003 INFO:     Epoch: 37
2022-12-31 05:21:40,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4283350358406703, 'Total loss': 0.4283350358406703} | train loss {'Reaction outcome loss': 0.15039260274784613, 'Total loss': 0.15039260274784613}
2022-12-31 05:21:40,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:40,669 INFO:     Epoch: 38
2022-12-31 05:21:42,288 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40460120836893715, 'Total loss': 0.40460120836893715} | train loss {'Reaction outcome loss': 0.14851635475676722, 'Total loss': 0.14851635475676722}
2022-12-31 05:21:42,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:42,289 INFO:     Epoch: 39
2022-12-31 05:21:43,954 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39717881083488465, 'Total loss': 0.39717881083488465} | train loss {'Reaction outcome loss': 0.15037573331231385, 'Total loss': 0.15037573331231385}
2022-12-31 05:21:43,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:43,955 INFO:     Epoch: 40
2022-12-31 05:21:45,575 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3962257087230682, 'Total loss': 0.3962257087230682} | train loss {'Reaction outcome loss': 0.15089593481177976, 'Total loss': 0.15089593481177976}
2022-12-31 05:21:45,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:45,575 INFO:     Epoch: 41
2022-12-31 05:21:47,190 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3682868844674279, 'Total loss': 0.3682868844674279} | train loss {'Reaction outcome loss': 0.1449109758288377, 'Total loss': 0.1449109758288377}
2022-12-31 05:21:47,190 INFO:     Found new best model at epoch 41
2022-12-31 05:21:47,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:47,191 INFO:     Epoch: 42
2022-12-31 05:21:48,803 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46310877601305644, 'Total loss': 0.46310877601305644} | train loss {'Reaction outcome loss': 0.14647647428690738, 'Total loss': 0.14647647428690738}
2022-12-31 05:21:48,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:48,803 INFO:     Epoch: 43
2022-12-31 05:21:50,470 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3873883791267872, 'Total loss': 0.3873883791267872} | train loss {'Reaction outcome loss': 0.14461194008480813, 'Total loss': 0.14461194008480813}
2022-12-31 05:21:50,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:50,471 INFO:     Epoch: 44
2022-12-31 05:21:52,092 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4063740481932958, 'Total loss': 0.4063740481932958} | train loss {'Reaction outcome loss': 0.14941650683455088, 'Total loss': 0.14941650683455088}
2022-12-31 05:21:52,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:52,092 INFO:     Epoch: 45
2022-12-31 05:21:53,722 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4024068425099055, 'Total loss': 0.4024068425099055} | train loss {'Reaction outcome loss': 0.1394827974111557, 'Total loss': 0.1394827974111557}
2022-12-31 05:21:53,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:53,722 INFO:     Epoch: 46
2022-12-31 05:21:55,374 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40709495147069297, 'Total loss': 0.40709495147069297} | train loss {'Reaction outcome loss': 0.13757563237289805, 'Total loss': 0.13757563237289805}
2022-12-31 05:21:55,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:55,374 INFO:     Epoch: 47
2022-12-31 05:21:56,993 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3975959246357282, 'Total loss': 0.3975959246357282} | train loss {'Reaction outcome loss': 0.13793232738195607, 'Total loss': 0.13793232738195607}
2022-12-31 05:21:56,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:56,993 INFO:     Epoch: 48
2022-12-31 05:21:58,612 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42381478448708854, 'Total loss': 0.42381478448708854} | train loss {'Reaction outcome loss': 0.14947935515015887, 'Total loss': 0.14947935515015887}
2022-12-31 05:21:58,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:21:58,613 INFO:     Epoch: 49
2022-12-31 05:22:00,281 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41238822440306344, 'Total loss': 0.41238822440306344} | train loss {'Reaction outcome loss': 0.1372657759442307, 'Total loss': 0.1372657759442307}
2022-12-31 05:22:00,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:00,281 INFO:     Epoch: 50
2022-12-31 05:22:01,948 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3885475386554996, 'Total loss': 0.3885475386554996} | train loss {'Reaction outcome loss': 0.1363423184510253, 'Total loss': 0.1363423184510253}
2022-12-31 05:22:01,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:01,948 INFO:     Epoch: 51
2022-12-31 05:22:03,592 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41639132648706434, 'Total loss': 0.41639132648706434} | train loss {'Reaction outcome loss': 0.14000399143391196, 'Total loss': 0.14000399143391196}
2022-12-31 05:22:03,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:03,593 INFO:     Epoch: 52
2022-12-31 05:22:05,213 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42122138738632203, 'Total loss': 0.42122138738632203} | train loss {'Reaction outcome loss': 0.13590456302949777, 'Total loss': 0.13590456302949777}
2022-12-31 05:22:05,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:05,214 INFO:     Epoch: 53
2022-12-31 05:22:06,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3997263247768084, 'Total loss': 0.3997263247768084} | train loss {'Reaction outcome loss': 0.1294148104953701, 'Total loss': 0.1294148104953701}
2022-12-31 05:22:06,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:06,866 INFO:     Epoch: 54
2022-12-31 05:22:08,532 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42193162739276885, 'Total loss': 0.42193162739276885} | train loss {'Reaction outcome loss': 0.13146792507926136, 'Total loss': 0.13146792507926136}
2022-12-31 05:22:08,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:08,533 INFO:     Epoch: 55
2022-12-31 05:22:10,199 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4468667934338252, 'Total loss': 0.4468667934338252} | train loss {'Reaction outcome loss': 0.13255727251374122, 'Total loss': 0.13255727251374122}
2022-12-31 05:22:10,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:10,199 INFO:     Epoch: 56
2022-12-31 05:22:11,848 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42677325109640757, 'Total loss': 0.42677325109640757} | train loss {'Reaction outcome loss': 0.1317626765199036, 'Total loss': 0.1317626765199036}
2022-12-31 05:22:11,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:11,849 INFO:     Epoch: 57
2022-12-31 05:22:13,515 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40236442784468335, 'Total loss': 0.40236442784468335} | train loss {'Reaction outcome loss': 0.13151858957059195, 'Total loss': 0.13151858957059195}
2022-12-31 05:22:13,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:13,515 INFO:     Epoch: 58
2022-12-31 05:22:15,169 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4415105521678925, 'Total loss': 0.4415105521678925} | train loss {'Reaction outcome loss': 0.1344236183778275, 'Total loss': 0.1344236183778275}
2022-12-31 05:22:15,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:15,170 INFO:     Epoch: 59
2022-12-31 05:22:16,798 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4019656171401342, 'Total loss': 0.4019656171401342} | train loss {'Reaction outcome loss': 0.12610059665514753, 'Total loss': 0.12610059665514753}
2022-12-31 05:22:16,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:16,798 INFO:     Epoch: 60
2022-12-31 05:22:18,465 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4215550070007642, 'Total loss': 0.4215550070007642} | train loss {'Reaction outcome loss': 0.12585608198887843, 'Total loss': 0.12585608198887843}
2022-12-31 05:22:18,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:18,465 INFO:     Epoch: 61
2022-12-31 05:22:20,132 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44910915394624074, 'Total loss': 0.44910915394624074} | train loss {'Reaction outcome loss': 0.1296091805941061, 'Total loss': 0.1296091805941061}
2022-12-31 05:22:20,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:20,132 INFO:     Epoch: 62
2022-12-31 05:22:21,772 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42511386374632515, 'Total loss': 0.42511386374632515} | train loss {'Reaction outcome loss': 0.12657844952596148, 'Total loss': 0.12657844952596148}
2022-12-31 05:22:21,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:21,773 INFO:     Epoch: 63
2022-12-31 05:22:23,389 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44707839290301005, 'Total loss': 0.44707839290301005} | train loss {'Reaction outcome loss': 0.12130110767717217, 'Total loss': 0.12130110767717217}
2022-12-31 05:22:23,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:23,390 INFO:     Epoch: 64
2022-12-31 05:22:25,026 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4374812106291453, 'Total loss': 0.4374812106291453} | train loss {'Reaction outcome loss': 0.12253729472349337, 'Total loss': 0.12253729472349337}
2022-12-31 05:22:25,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:25,027 INFO:     Epoch: 65
2022-12-31 05:22:26,656 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43341480642557145, 'Total loss': 0.43341480642557145} | train loss {'Reaction outcome loss': 0.119343800357192, 'Total loss': 0.119343800357192}
2022-12-31 05:22:26,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:26,656 INFO:     Epoch: 66
2022-12-31 05:22:28,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41964972615242, 'Total loss': 0.41964972615242} | train loss {'Reaction outcome loss': 0.1213663897449252, 'Total loss': 0.1213663897449252}
2022-12-31 05:22:28,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:28,286 INFO:     Epoch: 67
2022-12-31 05:22:29,906 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4107982948422432, 'Total loss': 0.4107982948422432} | train loss {'Reaction outcome loss': 0.12854192231126313, 'Total loss': 0.12854192231126313}
2022-12-31 05:22:29,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:29,906 INFO:     Epoch: 68
2022-12-31 05:22:31,560 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43306555300951005, 'Total loss': 0.43306555300951005} | train loss {'Reaction outcome loss': 0.12356510886056113, 'Total loss': 0.12356510886056113}
2022-12-31 05:22:31,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:31,561 INFO:     Epoch: 69
2022-12-31 05:22:33,185 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40181568066279094, 'Total loss': 0.40181568066279094} | train loss {'Reaction outcome loss': 0.12256759757250277, 'Total loss': 0.12256759757250277}
2022-12-31 05:22:33,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:33,185 INFO:     Epoch: 70
2022-12-31 05:22:34,797 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4205862502257029, 'Total loss': 0.4205862502257029} | train loss {'Reaction outcome loss': 0.11979471855506679, 'Total loss': 0.11979471855506679}
2022-12-31 05:22:34,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:34,798 INFO:     Epoch: 71
2022-12-31 05:22:36,459 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4387914260228475, 'Total loss': 0.4387914260228475} | train loss {'Reaction outcome loss': 0.1197963343558671, 'Total loss': 0.1197963343558671}
2022-12-31 05:22:36,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:36,460 INFO:     Epoch: 72
2022-12-31 05:22:38,142 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4275173564751943, 'Total loss': 0.4275173564751943} | train loss {'Reaction outcome loss': 0.12850061262218768, 'Total loss': 0.12850061262218768}
2022-12-31 05:22:38,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:38,143 INFO:     Epoch: 73
2022-12-31 05:22:39,826 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4451031635204951, 'Total loss': 0.4451031635204951} | train loss {'Reaction outcome loss': 0.12220150205995077, 'Total loss': 0.12220150205995077}
2022-12-31 05:22:39,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:39,826 INFO:     Epoch: 74
2022-12-31 05:22:41,507 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4370455861091614, 'Total loss': 0.4370455861091614} | train loss {'Reaction outcome loss': 0.13626303871279705, 'Total loss': 0.13626303871279705}
2022-12-31 05:22:41,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:41,507 INFO:     Epoch: 75
2022-12-31 05:22:43,157 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43655025685826937, 'Total loss': 0.43655025685826937} | train loss {'Reaction outcome loss': 0.12012233698835084, 'Total loss': 0.12012233698835084}
2022-12-31 05:22:43,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:43,157 INFO:     Epoch: 76
2022-12-31 05:22:44,874 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4438497265179952, 'Total loss': 0.4438497265179952} | train loss {'Reaction outcome loss': 0.11421727570537453, 'Total loss': 0.11421727570537453}
2022-12-31 05:22:44,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:44,874 INFO:     Epoch: 77
2022-12-31 05:22:46,501 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4400355656941732, 'Total loss': 0.4400355656941732} | train loss {'Reaction outcome loss': 0.11255708616733065, 'Total loss': 0.11255708616733065}
2022-12-31 05:22:46,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:46,503 INFO:     Epoch: 78
2022-12-31 05:22:48,135 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4096773639321327, 'Total loss': 0.4096773639321327} | train loss {'Reaction outcome loss': 0.11008053732212579, 'Total loss': 0.11008053732212579}
2022-12-31 05:22:48,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:48,135 INFO:     Epoch: 79
2022-12-31 05:22:49,758 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4725727697213491, 'Total loss': 0.4725727697213491} | train loss {'Reaction outcome loss': 0.12335039909806295, 'Total loss': 0.12335039909806295}
2022-12-31 05:22:49,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:49,758 INFO:     Epoch: 80
2022-12-31 05:22:51,385 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4297850375374158, 'Total loss': 0.4297850375374158} | train loss {'Reaction outcome loss': 0.11589580326139896, 'Total loss': 0.11589580326139896}
2022-12-31 05:22:51,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:51,385 INFO:     Epoch: 81
2022-12-31 05:22:53,014 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45018463482459387, 'Total loss': 0.45018463482459387} | train loss {'Reaction outcome loss': 0.11259453949505636, 'Total loss': 0.11259453949505636}
2022-12-31 05:22:53,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:53,015 INFO:     Epoch: 82
2022-12-31 05:22:54,645 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4353705495595932, 'Total loss': 0.4353705495595932} | train loss {'Reaction outcome loss': 0.11261964181566314, 'Total loss': 0.11261964181566314}
2022-12-31 05:22:54,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:54,645 INFO:     Epoch: 83
2022-12-31 05:22:56,279 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4377262622117996, 'Total loss': 0.4377262622117996} | train loss {'Reaction outcome loss': 0.1097616050812075, 'Total loss': 0.1097616050812075}
2022-12-31 05:22:56,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:56,279 INFO:     Epoch: 84
2022-12-31 05:22:57,979 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4472367907563845, 'Total loss': 0.4472367907563845} | train loss {'Reaction outcome loss': 0.112463201450157, 'Total loss': 0.112463201450157}
2022-12-31 05:22:57,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:57,979 INFO:     Epoch: 85
2022-12-31 05:22:59,702 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4510878582795461, 'Total loss': 0.4510878582795461} | train loss {'Reaction outcome loss': 0.11344575178826335, 'Total loss': 0.11344575178826335}
2022-12-31 05:22:59,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:22:59,702 INFO:     Epoch: 86
2022-12-31 05:23:01,330 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.417184708515803, 'Total loss': 0.417184708515803} | train loss {'Reaction outcome loss': 0.11636513955132957, 'Total loss': 0.11636513955132957}
2022-12-31 05:23:01,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:01,330 INFO:     Epoch: 87
2022-12-31 05:23:03,052 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4254610508680344, 'Total loss': 0.4254610508680344} | train loss {'Reaction outcome loss': 0.10996039145275195, 'Total loss': 0.10996039145275195}
2022-12-31 05:23:03,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:03,053 INFO:     Epoch: 88
2022-12-31 05:23:04,685 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4451358407735825, 'Total loss': 0.4451358407735825} | train loss {'Reaction outcome loss': 0.11297758039090432, 'Total loss': 0.11297758039090432}
2022-12-31 05:23:04,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:04,685 INFO:     Epoch: 89
2022-12-31 05:23:06,380 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46535419474045436, 'Total loss': 0.46535419474045436} | train loss {'Reaction outcome loss': 0.10866117363869873, 'Total loss': 0.10866117363869873}
2022-12-31 05:23:06,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:06,381 INFO:     Epoch: 90
2022-12-31 05:23:08,012 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4537357836961746, 'Total loss': 0.4537357836961746} | train loss {'Reaction outcome loss': 0.10638256432434572, 'Total loss': 0.10638256432434572}
2022-12-31 05:23:08,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:08,012 INFO:     Epoch: 91
2022-12-31 05:23:09,636 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4226829876502355, 'Total loss': 0.4226829876502355} | train loss {'Reaction outcome loss': 0.11249892116348496, 'Total loss': 0.11249892116348496}
2022-12-31 05:23:09,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:09,637 INFO:     Epoch: 92
2022-12-31 05:23:11,279 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43005168239275615, 'Total loss': 0.43005168239275615} | train loss {'Reaction outcome loss': 0.10901679282896098, 'Total loss': 0.10901679282896098}
2022-12-31 05:23:11,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:11,279 INFO:     Epoch: 93
2022-12-31 05:23:12,910 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44659394125143687, 'Total loss': 0.44659394125143687} | train loss {'Reaction outcome loss': 0.10793740451952073, 'Total loss': 0.10793740451952073}
2022-12-31 05:23:12,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:12,910 INFO:     Epoch: 94
2022-12-31 05:23:14,539 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46182924558719, 'Total loss': 0.46182924558719} | train loss {'Reaction outcome loss': 0.10660262266173959, 'Total loss': 0.10660262266173959}
2022-12-31 05:23:14,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:14,540 INFO:     Epoch: 95
2022-12-31 05:23:16,167 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4567306399345398, 'Total loss': 0.4567306399345398} | train loss {'Reaction outcome loss': 0.12280998431125899, 'Total loss': 0.12280998431125899}
2022-12-31 05:23:16,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:16,167 INFO:     Epoch: 96
2022-12-31 05:23:17,879 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4537777503331502, 'Total loss': 0.4537777503331502} | train loss {'Reaction outcome loss': 0.11572932048559027, 'Total loss': 0.11572932048559027}
2022-12-31 05:23:17,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:17,879 INFO:     Epoch: 97
2022-12-31 05:23:19,539 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44947003641476235, 'Total loss': 0.44947003641476235} | train loss {'Reaction outcome loss': 0.10561142887185059, 'Total loss': 0.10561142887185059}
2022-12-31 05:23:19,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:19,539 INFO:     Epoch: 98
2022-12-31 05:23:21,165 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43174363697568574, 'Total loss': 0.43174363697568574} | train loss {'Reaction outcome loss': 0.1050671716251257, 'Total loss': 0.1050671716251257}
2022-12-31 05:23:21,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:21,167 INFO:     Epoch: 99
2022-12-31 05:23:22,827 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4494371960560481, 'Total loss': 0.4494371960560481} | train loss {'Reaction outcome loss': 0.10490361337682427, 'Total loss': 0.10490361337682427}
2022-12-31 05:23:22,827 INFO:     Best model found after epoch 42 of 100.
2022-12-31 05:23:22,827 INFO:   Done with stage: TRAINING
2022-12-31 05:23:22,827 INFO:   Starting stage: EVALUATION
2022-12-31 05:23:22,956 INFO:   Done with stage: EVALUATION
2022-12-31 05:23:22,957 INFO:   Leaving out SEQ value Fold_9
2022-12-31 05:23:22,969 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:23:22,969 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:23:23,606 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:23:23,607 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:23:23,677 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:23:23,677 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:23:23,677 INFO:     No hyperparam tuning for this model
2022-12-31 05:23:23,677 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:23:23,677 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:23:23,678 INFO:     None feature selector for col prot
2022-12-31 05:23:23,678 INFO:     None feature selector for col prot
2022-12-31 05:23:23,678 INFO:     None feature selector for col prot
2022-12-31 05:23:23,679 INFO:     None feature selector for col chem
2022-12-31 05:23:23,679 INFO:     None feature selector for col chem
2022-12-31 05:23:23,679 INFO:     None feature selector for col chem
2022-12-31 05:23:23,679 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:23:23,679 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:23:23,681 INFO:     Number of params in model 224011
2022-12-31 05:23:23,684 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:23:23,684 INFO:   Starting stage: TRAINING
2022-12-31 05:23:23,729 INFO:     Val loss before train {'Reaction outcome loss': 1.030935009320577, 'Total loss': 1.030935009320577}
2022-12-31 05:23:23,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:23,729 INFO:     Epoch: 0
2022-12-31 05:23:25,342 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5519219815731049, 'Total loss': 0.5519219815731049} | train loss {'Reaction outcome loss': 0.7667826993620374, 'Total loss': 0.7667826993620374}
2022-12-31 05:23:25,342 INFO:     Found new best model at epoch 0
2022-12-31 05:23:25,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:25,343 INFO:     Epoch: 1
2022-12-31 05:23:26,969 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49631543358167013, 'Total loss': 0.49631543358167013} | train loss {'Reaction outcome loss': 0.4972831194636587, 'Total loss': 0.4972831194636587}
2022-12-31 05:23:26,969 INFO:     Found new best model at epoch 1
2022-12-31 05:23:26,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:26,970 INFO:     Epoch: 2
2022-12-31 05:23:28,597 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44534086585044863, 'Total loss': 0.44534086585044863} | train loss {'Reaction outcome loss': 0.43540081921694934, 'Total loss': 0.43540081921694934}
2022-12-31 05:23:28,598 INFO:     Found new best model at epoch 2
2022-12-31 05:23:28,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:28,599 INFO:     Epoch: 3
2022-12-31 05:23:30,217 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43443595667680107, 'Total loss': 0.43443595667680107} | train loss {'Reaction outcome loss': 0.40111757333194703, 'Total loss': 0.40111757333194703}
2022-12-31 05:23:30,218 INFO:     Found new best model at epoch 3
2022-12-31 05:23:30,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:30,219 INFO:     Epoch: 4
2022-12-31 05:23:31,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42954152822494507, 'Total loss': 0.42954152822494507} | train loss {'Reaction outcome loss': 0.36680436417446943, 'Total loss': 0.36680436417446943}
2022-12-31 05:23:31,839 INFO:     Found new best model at epoch 4
2022-12-31 05:23:31,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:31,840 INFO:     Epoch: 5
2022-12-31 05:23:33,459 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41060368418693544, 'Total loss': 0.41060368418693544} | train loss {'Reaction outcome loss': 0.3404453519786699, 'Total loss': 0.3404453519786699}
2022-12-31 05:23:33,459 INFO:     Found new best model at epoch 5
2022-12-31 05:23:33,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:33,460 INFO:     Epoch: 6
2022-12-31 05:23:35,098 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4264705220858256, 'Total loss': 0.4264705220858256} | train loss {'Reaction outcome loss': 0.31830173937529593, 'Total loss': 0.31830173937529593}
2022-12-31 05:23:35,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:35,099 INFO:     Epoch: 7
2022-12-31 05:23:36,716 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43526780009269717, 'Total loss': 0.43526780009269717} | train loss {'Reaction outcome loss': 0.3106072941471053, 'Total loss': 0.3106072941471053}
2022-12-31 05:23:36,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:36,716 INFO:     Epoch: 8
2022-12-31 05:23:38,344 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43322814007600147, 'Total loss': 0.43322814007600147} | train loss {'Reaction outcome loss': 0.3002637408866102, 'Total loss': 0.3002637408866102}
2022-12-31 05:23:38,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:38,345 INFO:     Epoch: 9
2022-12-31 05:23:39,961 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41717701554298403, 'Total loss': 0.41717701554298403} | train loss {'Reaction outcome loss': 0.27883117189090967, 'Total loss': 0.27883117189090967}
2022-12-31 05:23:39,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:39,961 INFO:     Epoch: 10
2022-12-31 05:23:41,578 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41987667282422386, 'Total loss': 0.41987667282422386} | train loss {'Reaction outcome loss': 0.26311036296765844, 'Total loss': 0.26311036296765844}
2022-12-31 05:23:41,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:41,579 INFO:     Epoch: 11
2022-12-31 05:23:43,189 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4129271864891052, 'Total loss': 0.4129271864891052} | train loss {'Reaction outcome loss': 0.25263935904953594, 'Total loss': 0.25263935904953594}
2022-12-31 05:23:43,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:43,190 INFO:     Epoch: 12
2022-12-31 05:23:44,799 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.434103328982989, 'Total loss': 0.434103328982989} | train loss {'Reaction outcome loss': 0.24524052155544085, 'Total loss': 0.24524052155544085}
2022-12-31 05:23:44,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:44,799 INFO:     Epoch: 13
2022-12-31 05:23:46,450 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42072938283284506, 'Total loss': 0.42072938283284506} | train loss {'Reaction outcome loss': 0.23767876462585738, 'Total loss': 0.23767876462585738}
2022-12-31 05:23:46,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:46,450 INFO:     Epoch: 14
2022-12-31 05:23:48,073 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43069948156674703, 'Total loss': 0.43069948156674703} | train loss {'Reaction outcome loss': 0.23125146898931143, 'Total loss': 0.23125146898931143}
2022-12-31 05:23:48,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:48,073 INFO:     Epoch: 15
2022-12-31 05:23:49,699 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42823894917964933, 'Total loss': 0.42823894917964933} | train loss {'Reaction outcome loss': 0.22223435507897893, 'Total loss': 0.22223435507897893}
2022-12-31 05:23:49,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:49,699 INFO:     Epoch: 16
2022-12-31 05:23:51,323 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4303117871284485, 'Total loss': 0.4303117871284485} | train loss {'Reaction outcome loss': 0.21723065456680543, 'Total loss': 0.21723065456680543}
2022-12-31 05:23:51,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:51,323 INFO:     Epoch: 17
2022-12-31 05:23:52,945 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41299158533414204, 'Total loss': 0.41299158533414204} | train loss {'Reaction outcome loss': 0.20833142483531011, 'Total loss': 0.20833142483531011}
2022-12-31 05:23:52,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:52,945 INFO:     Epoch: 18
2022-12-31 05:23:54,569 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4359354575475057, 'Total loss': 0.4359354575475057} | train loss {'Reaction outcome loss': 0.2051249682929441, 'Total loss': 0.2051249682929441}
2022-12-31 05:23:54,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:54,570 INFO:     Epoch: 19
2022-12-31 05:23:56,201 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4177044744292895, 'Total loss': 0.4177044744292895} | train loss {'Reaction outcome loss': 0.20115535255646808, 'Total loss': 0.20115535255646808}
2022-12-31 05:23:56,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:56,201 INFO:     Epoch: 20
2022-12-31 05:23:57,864 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4413234829902649, 'Total loss': 0.4413234829902649} | train loss {'Reaction outcome loss': 0.19253325264661977, 'Total loss': 0.19253325264661977}
2022-12-31 05:23:57,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:57,865 INFO:     Epoch: 21
2022-12-31 05:23:59,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41988373597462975, 'Total loss': 0.41988373597462975} | train loss {'Reaction outcome loss': 0.18765226103014487, 'Total loss': 0.18765226103014487}
2022-12-31 05:23:59,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:23:59,485 INFO:     Epoch: 22
2022-12-31 05:24:01,148 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41481932550668715, 'Total loss': 0.41481932550668715} | train loss {'Reaction outcome loss': 0.1881262453144713, 'Total loss': 0.1881262453144713}
2022-12-31 05:24:01,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:01,148 INFO:     Epoch: 23
2022-12-31 05:24:02,761 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44380484422047933, 'Total loss': 0.44380484422047933} | train loss {'Reaction outcome loss': 0.18018808379428516, 'Total loss': 0.18018808379428516}
2022-12-31 05:24:02,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:02,761 INFO:     Epoch: 24
2022-12-31 05:24:04,424 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43298935890197754, 'Total loss': 0.43298935890197754} | train loss {'Reaction outcome loss': 0.17656176557015305, 'Total loss': 0.17656176557015305}
2022-12-31 05:24:04,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:04,425 INFO:     Epoch: 25
2022-12-31 05:24:06,069 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43110066652297974, 'Total loss': 0.43110066652297974} | train loss {'Reaction outcome loss': 0.17452243345768945, 'Total loss': 0.17452243345768945}
2022-12-31 05:24:06,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:06,069 INFO:     Epoch: 26
2022-12-31 05:24:07,724 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4303894358376662, 'Total loss': 0.4303894358376662} | train loss {'Reaction outcome loss': 0.16674320958027503, 'Total loss': 0.16674320958027503}
2022-12-31 05:24:07,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:07,724 INFO:     Epoch: 27
2022-12-31 05:24:09,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43829875787099204, 'Total loss': 0.43829875787099204} | train loss {'Reaction outcome loss': 0.16506213072241974, 'Total loss': 0.16506213072241974}
2022-12-31 05:24:09,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:09,357 INFO:     Epoch: 28
2022-12-31 05:24:10,978 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45279415597518285, 'Total loss': 0.45279415597518285} | train loss {'Reaction outcome loss': 0.16897910494726207, 'Total loss': 0.16897910494726207}
2022-12-31 05:24:10,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:10,978 INFO:     Epoch: 29
2022-12-31 05:24:12,609 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4354019155104955, 'Total loss': 0.4354019155104955} | train loss {'Reaction outcome loss': 0.1619069632644718, 'Total loss': 0.1619069632644718}
2022-12-31 05:24:12,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:12,610 INFO:     Epoch: 30
2022-12-31 05:24:14,231 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4422753525276979, 'Total loss': 0.4422753525276979} | train loss {'Reaction outcome loss': 0.15751683022708807, 'Total loss': 0.15751683022708807}
2022-12-31 05:24:14,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:14,232 INFO:     Epoch: 31
2022-12-31 05:24:15,862 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.425515283147494, 'Total loss': 0.425515283147494} | train loss {'Reaction outcome loss': 0.15247197873870152, 'Total loss': 0.15247197873870152}
2022-12-31 05:24:15,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:15,862 INFO:     Epoch: 32
2022-12-31 05:24:17,493 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46134692629178364, 'Total loss': 0.46134692629178364} | train loss {'Reaction outcome loss': 0.15373192209543945, 'Total loss': 0.15373192209543945}
2022-12-31 05:24:17,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:17,494 INFO:     Epoch: 33
2022-12-31 05:24:19,114 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4468703250090281, 'Total loss': 0.4468703250090281} | train loss {'Reaction outcome loss': 0.15316250001120826, 'Total loss': 0.15316250001120826}
2022-12-31 05:24:19,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:19,115 INFO:     Epoch: 34
2022-12-31 05:24:20,763 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4352914442618688, 'Total loss': 0.4352914442618688} | train loss {'Reaction outcome loss': 0.14943060698662547, 'Total loss': 0.14943060698662547}
2022-12-31 05:24:20,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:20,763 INFO:     Epoch: 35
2022-12-31 05:24:22,425 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42078429212172824, 'Total loss': 0.42078429212172824} | train loss {'Reaction outcome loss': 0.148855098961866, 'Total loss': 0.148855098961866}
2022-12-31 05:24:22,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:22,425 INFO:     Epoch: 36
2022-12-31 05:24:24,046 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42114029328028363, 'Total loss': 0.42114029328028363} | train loss {'Reaction outcome loss': 0.14572389284347848, 'Total loss': 0.14572389284347848}
2022-12-31 05:24:24,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:24,046 INFO:     Epoch: 37
2022-12-31 05:24:25,708 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4513474335273107, 'Total loss': 0.4513474335273107} | train loss {'Reaction outcome loss': 0.14039750054602654, 'Total loss': 0.14039750054602654}
2022-12-31 05:24:25,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:25,708 INFO:     Epoch: 38
2022-12-31 05:24:27,369 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4522910664478938, 'Total loss': 0.4522910664478938} | train loss {'Reaction outcome loss': 0.14404177494978523, 'Total loss': 0.14404177494978523}
2022-12-31 05:24:27,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:27,370 INFO:     Epoch: 39
2022-12-31 05:24:28,985 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46287508805592853, 'Total loss': 0.46287508805592853} | train loss {'Reaction outcome loss': 0.13867634505499998, 'Total loss': 0.13867634505499998}
2022-12-31 05:24:28,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:28,985 INFO:     Epoch: 40
2022-12-31 05:24:30,609 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4125849147637685, 'Total loss': 0.4125849147637685} | train loss {'Reaction outcome loss': 0.14084400281775533, 'Total loss': 0.14084400281775533}
2022-12-31 05:24:30,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:30,609 INFO:     Epoch: 41
2022-12-31 05:24:32,229 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44272357324759165, 'Total loss': 0.44272357324759165} | train loss {'Reaction outcome loss': 0.1371385515919191, 'Total loss': 0.1371385515919191}
2022-12-31 05:24:32,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:32,229 INFO:     Epoch: 42
2022-12-31 05:24:33,856 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4901094138622284, 'Total loss': 0.4901094138622284} | train loss {'Reaction outcome loss': 0.13506881945489813, 'Total loss': 0.13506881945489813}
2022-12-31 05:24:33,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:33,857 INFO:     Epoch: 43
2022-12-31 05:24:35,485 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45329523384571074, 'Total loss': 0.45329523384571074} | train loss {'Reaction outcome loss': 0.1396530754426604, 'Total loss': 0.1396530754426604}
2022-12-31 05:24:35,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:35,485 INFO:     Epoch: 44
2022-12-31 05:24:37,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46416976153850553, 'Total loss': 0.46416976153850553} | train loss {'Reaction outcome loss': 0.1365107022705859, 'Total loss': 0.1365107022705859}
2022-12-31 05:24:37,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:37,115 INFO:     Epoch: 45
2022-12-31 05:24:38,734 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4569075584411621, 'Total loss': 0.4569075584411621} | train loss {'Reaction outcome loss': 0.13334058216276098, 'Total loss': 0.13334058216276098}
2022-12-31 05:24:38,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:38,734 INFO:     Epoch: 46
2022-12-31 05:24:40,364 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44838830331961316, 'Total loss': 0.44838830331961316} | train loss {'Reaction outcome loss': 0.13408931950213407, 'Total loss': 0.13408931950213407}
2022-12-31 05:24:40,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:40,365 INFO:     Epoch: 47
2022-12-31 05:24:41,984 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4456122577190399, 'Total loss': 0.4456122577190399} | train loss {'Reaction outcome loss': 0.13388146997085246, 'Total loss': 0.13388146997085246}
2022-12-31 05:24:41,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:41,985 INFO:     Epoch: 48
2022-12-31 05:24:43,614 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44788752992947894, 'Total loss': 0.44788752992947894} | train loss {'Reaction outcome loss': 0.1303315675283649, 'Total loss': 0.1303315675283649}
2022-12-31 05:24:43,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:43,614 INFO:     Epoch: 49
2022-12-31 05:24:45,244 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4371706972519557, 'Total loss': 0.4371706972519557} | train loss {'Reaction outcome loss': 0.127219901244459, 'Total loss': 0.127219901244459}
2022-12-31 05:24:45,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:45,244 INFO:     Epoch: 50
2022-12-31 05:24:46,871 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44783912698427836, 'Total loss': 0.44783912698427836} | train loss {'Reaction outcome loss': 0.12712098193014096, 'Total loss': 0.12712098193014096}
2022-12-31 05:24:46,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:46,871 INFO:     Epoch: 51
2022-12-31 05:24:48,515 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4478817502657572, 'Total loss': 0.4478817502657572} | train loss {'Reaction outcome loss': 0.12923973510202114, 'Total loss': 0.12923973510202114}
2022-12-31 05:24:48,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:48,516 INFO:     Epoch: 52
2022-12-31 05:24:50,175 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45626983642578123, 'Total loss': 0.45626983642578123} | train loss {'Reaction outcome loss': 0.12697327197475464, 'Total loss': 0.12697327197475464}
2022-12-31 05:24:50,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:50,176 INFO:     Epoch: 53
2022-12-31 05:24:51,794 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.472269731760025, 'Total loss': 0.472269731760025} | train loss {'Reaction outcome loss': 0.1267916872410738, 'Total loss': 0.1267916872410738}
2022-12-31 05:24:51,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:51,794 INFO:     Epoch: 54
2022-12-31 05:24:53,427 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4669036487738291, 'Total loss': 0.4669036487738291} | train loss {'Reaction outcome loss': 0.12636771434040714, 'Total loss': 0.12636771434040714}
2022-12-31 05:24:53,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:53,428 INFO:     Epoch: 55
2022-12-31 05:24:55,061 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4478337327639262, 'Total loss': 0.4478337327639262} | train loss {'Reaction outcome loss': 0.12545599613735828, 'Total loss': 0.12545599613735828}
2022-12-31 05:24:55,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:55,062 INFO:     Epoch: 56
2022-12-31 05:24:56,684 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4249045376976331, 'Total loss': 0.4249045376976331} | train loss {'Reaction outcome loss': 0.1234653717736997, 'Total loss': 0.1234653717736997}
2022-12-31 05:24:56,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:56,684 INFO:     Epoch: 57
2022-12-31 05:24:58,305 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4375366657972336, 'Total loss': 0.4375366657972336} | train loss {'Reaction outcome loss': 0.12180279168718487, 'Total loss': 0.12180279168718487}
2022-12-31 05:24:58,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:58,305 INFO:     Epoch: 58
2022-12-31 05:24:59,927 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4279848868648211, 'Total loss': 0.4279848868648211} | train loss {'Reaction outcome loss': 0.11955736396223496, 'Total loss': 0.11955736396223496}
2022-12-31 05:24:59,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:24:59,927 INFO:     Epoch: 59
2022-12-31 05:25:01,558 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4132078856229782, 'Total loss': 0.4132078856229782} | train loss {'Reaction outcome loss': 0.12143079916216042, 'Total loss': 0.12143079916216042}
2022-12-31 05:25:01,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:01,558 INFO:     Epoch: 60
2022-12-31 05:25:03,191 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4613392621278763, 'Total loss': 0.4613392621278763} | train loss {'Reaction outcome loss': 0.12146223154264009, 'Total loss': 0.12146223154264009}
2022-12-31 05:25:03,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:03,191 INFO:     Epoch: 61
2022-12-31 05:25:04,824 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4554802343249321, 'Total loss': 0.4554802343249321} | train loss {'Reaction outcome loss': 0.11818184602343848, 'Total loss': 0.11818184602343848}
2022-12-31 05:25:04,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:04,824 INFO:     Epoch: 62
2022-12-31 05:25:06,448 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4290673404932022, 'Total loss': 0.4290673404932022} | train loss {'Reaction outcome loss': 0.11854183977230888, 'Total loss': 0.11854183977230888}
2022-12-31 05:25:06,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:06,448 INFO:     Epoch: 63
2022-12-31 05:25:08,081 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4579244350393613, 'Total loss': 0.4579244350393613} | train loss {'Reaction outcome loss': 0.11897022392266714, 'Total loss': 0.11897022392266714}
2022-12-31 05:25:08,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:08,081 INFO:     Epoch: 64
2022-12-31 05:25:09,702 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42664119799931843, 'Total loss': 0.42664119799931843} | train loss {'Reaction outcome loss': 0.11853173576157028, 'Total loss': 0.11853173576157028}
2022-12-31 05:25:09,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:09,704 INFO:     Epoch: 65
2022-12-31 05:25:11,323 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4405356228351593, 'Total loss': 0.4405356228351593} | train loss {'Reaction outcome loss': 0.11928445818077729, 'Total loss': 0.11928445818077729}
2022-12-31 05:25:11,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:11,323 INFO:     Epoch: 66
2022-12-31 05:25:12,990 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4803643802801768, 'Total loss': 0.4803643802801768} | train loss {'Reaction outcome loss': 0.12459009089951101, 'Total loss': 0.12459009089951101}
2022-12-31 05:25:12,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:12,990 INFO:     Epoch: 67
2022-12-31 05:25:14,608 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4111730376879374, 'Total loss': 0.4111730376879374} | train loss {'Reaction outcome loss': 0.11513522330424956, 'Total loss': 0.11513522330424956}
2022-12-31 05:25:14,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:14,609 INFO:     Epoch: 68
2022-12-31 05:25:16,234 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4045974130431811, 'Total loss': 0.4045974130431811} | train loss {'Reaction outcome loss': 0.11457898058807073, 'Total loss': 0.11457898058807073}
2022-12-31 05:25:16,235 INFO:     Found new best model at epoch 68
2022-12-31 05:25:16,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:16,236 INFO:     Epoch: 69
2022-12-31 05:25:17,855 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42358650142947835, 'Total loss': 0.42358650142947835} | train loss {'Reaction outcome loss': 0.11592297891721777, 'Total loss': 0.11592297891721777}
2022-12-31 05:25:17,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:17,855 INFO:     Epoch: 70
2022-12-31 05:25:19,483 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42515693654616676, 'Total loss': 0.42515693654616676} | train loss {'Reaction outcome loss': 0.1165907612843169, 'Total loss': 0.1165907612843169}
2022-12-31 05:25:19,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:19,483 INFO:     Epoch: 71
2022-12-31 05:25:21,109 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3868669162193934, 'Total loss': 0.3868669162193934} | train loss {'Reaction outcome loss': 0.13698235134264053, 'Total loss': 0.13698235134264053}
2022-12-31 05:25:21,109 INFO:     Found new best model at epoch 71
2022-12-31 05:25:21,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:21,111 INFO:     Epoch: 72
2022-12-31 05:25:22,738 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41037775774796803, 'Total loss': 0.41037775774796803} | train loss {'Reaction outcome loss': 0.11842859001573769, 'Total loss': 0.11842859001573769}
2022-12-31 05:25:22,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:22,738 INFO:     Epoch: 73
2022-12-31 05:25:24,368 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.432551871240139, 'Total loss': 0.432551871240139} | train loss {'Reaction outcome loss': 0.14793050272788422, 'Total loss': 0.14793050272788422}
2022-12-31 05:25:24,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:24,369 INFO:     Epoch: 74
2022-12-31 05:25:25,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4148729224999746, 'Total loss': 0.4148729224999746} | train loss {'Reaction outcome loss': 0.12002302195026499, 'Total loss': 0.12002302195026499}
2022-12-31 05:25:25,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:25,990 INFO:     Epoch: 75
2022-12-31 05:25:27,642 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4233901639779409, 'Total loss': 0.4233901639779409} | train loss {'Reaction outcome loss': 0.1332298730967391, 'Total loss': 0.1332298730967391}
2022-12-31 05:25:27,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:27,643 INFO:     Epoch: 76
2022-12-31 05:25:29,262 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43179462949434916, 'Total loss': 0.43179462949434916} | train loss {'Reaction outcome loss': 0.11160906806353656, 'Total loss': 0.11160906806353656}
2022-12-31 05:25:29,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:29,263 INFO:     Epoch: 77
2022-12-31 05:25:30,924 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41155182669560114, 'Total loss': 0.41155182669560114} | train loss {'Reaction outcome loss': 0.1130454856310794, 'Total loss': 0.1130454856310794}
2022-12-31 05:25:30,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:30,924 INFO:     Epoch: 78
2022-12-31 05:25:32,544 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3914564698934555, 'Total loss': 0.3914564698934555} | train loss {'Reaction outcome loss': 0.10629922149203502, 'Total loss': 0.10629922149203502}
2022-12-31 05:25:32,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:32,545 INFO:     Epoch: 79
2022-12-31 05:25:34,194 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41041864156723024, 'Total loss': 0.41041864156723024} | train loss {'Reaction outcome loss': 0.10708554351781524, 'Total loss': 0.10708554351781524}
2022-12-31 05:25:34,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:34,195 INFO:     Epoch: 80
2022-12-31 05:25:35,851 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42554553747177126, 'Total loss': 0.42554553747177126} | train loss {'Reaction outcome loss': 0.11058624601582119, 'Total loss': 0.11058624601582119}
2022-12-31 05:25:35,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:35,851 INFO:     Epoch: 81
2022-12-31 05:25:37,466 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41519662241141003, 'Total loss': 0.41519662241141003} | train loss {'Reaction outcome loss': 0.11145381674029614, 'Total loss': 0.11145381674029614}
2022-12-31 05:25:37,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:37,466 INFO:     Epoch: 82
2022-12-31 05:25:39,088 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44300643901030223, 'Total loss': 0.44300643901030223} | train loss {'Reaction outcome loss': 0.10774322956179579, 'Total loss': 0.10774322956179579}
2022-12-31 05:25:39,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:39,088 INFO:     Epoch: 83
2022-12-31 05:25:40,711 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4423773944377899, 'Total loss': 0.4423773944377899} | train loss {'Reaction outcome loss': 0.1051580305211246, 'Total loss': 0.1051580305211246}
2022-12-31 05:25:40,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:40,711 INFO:     Epoch: 84
2022-12-31 05:25:42,326 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4231949172914028, 'Total loss': 0.4231949172914028} | train loss {'Reaction outcome loss': 0.10721891691850877, 'Total loss': 0.10721891691850877}
2022-12-31 05:25:42,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:42,327 INFO:     Epoch: 85
2022-12-31 05:25:43,951 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43962338169415793, 'Total loss': 0.43962338169415793} | train loss {'Reaction outcome loss': 0.1116802477884356, 'Total loss': 0.1116802477884356}
2022-12-31 05:25:43,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:43,951 INFO:     Epoch: 86
2022-12-31 05:25:45,569 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46418389678001404, 'Total loss': 0.46418389678001404} | train loss {'Reaction outcome loss': 0.11264455374009273, 'Total loss': 0.11264455374009273}
2022-12-31 05:25:45,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:45,570 INFO:     Epoch: 87
2022-12-31 05:25:47,216 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4238451530536016, 'Total loss': 0.4238451530536016} | train loss {'Reaction outcome loss': 0.11115485823382557, 'Total loss': 0.11115485823382557}
2022-12-31 05:25:47,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:47,216 INFO:     Epoch: 88
2022-12-31 05:25:48,876 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44103734493255614, 'Total loss': 0.44103734493255614} | train loss {'Reaction outcome loss': 0.11252856845427575, 'Total loss': 0.11252856845427575}
2022-12-31 05:25:48,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:48,876 INFO:     Epoch: 89
2022-12-31 05:25:50,537 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4114512473344803, 'Total loss': 0.4114512473344803} | train loss {'Reaction outcome loss': 0.10708544631166739, 'Total loss': 0.10708544631166739}
2022-12-31 05:25:50,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:50,537 INFO:     Epoch: 90
2022-12-31 05:25:52,157 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40629969028135143, 'Total loss': 0.40629969028135143} | train loss {'Reaction outcome loss': 0.10310855585460861, 'Total loss': 0.10310855585460861}
2022-12-31 05:25:52,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:52,157 INFO:     Epoch: 91
2022-12-31 05:25:53,774 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4070607602596283, 'Total loss': 0.4070607602596283} | train loss {'Reaction outcome loss': 0.10824370334022745, 'Total loss': 0.10824370334022745}
2022-12-31 05:25:53,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:53,774 INFO:     Epoch: 92
2022-12-31 05:25:55,386 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4435176541407903, 'Total loss': 0.4435176541407903} | train loss {'Reaction outcome loss': 0.11141919515406092, 'Total loss': 0.11141919515406092}
2022-12-31 05:25:55,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:55,387 INFO:     Epoch: 93
2022-12-31 05:25:57,046 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4231376384695371, 'Total loss': 0.4231376384695371} | train loss {'Reaction outcome loss': 0.10454147767386926, 'Total loss': 0.10454147767386926}
2022-12-31 05:25:57,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:57,046 INFO:     Epoch: 94
2022-12-31 05:25:58,706 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.436646631360054, 'Total loss': 0.436646631360054} | train loss {'Reaction outcome loss': 0.110401995466115, 'Total loss': 0.110401995466115}
2022-12-31 05:25:58,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:25:58,707 INFO:     Epoch: 95
2022-12-31 05:26:00,324 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4189528117577235, 'Total loss': 0.4189528117577235} | train loss {'Reaction outcome loss': 0.13860140738846816, 'Total loss': 0.13860140738846816}
2022-12-31 05:26:00,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:00,324 INFO:     Epoch: 96
2022-12-31 05:26:01,941 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4215753654638926, 'Total loss': 0.4215753654638926} | train loss {'Reaction outcome loss': 0.1276004617702447, 'Total loss': 0.1276004617702447}
2022-12-31 05:26:01,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:01,941 INFO:     Epoch: 97
2022-12-31 05:26:03,588 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4322827865680059, 'Total loss': 0.4322827865680059} | train loss {'Reaction outcome loss': 0.10683788508058702, 'Total loss': 0.10683788508058702}
2022-12-31 05:26:03,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:03,588 INFO:     Epoch: 98
2022-12-31 05:26:05,208 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4355719228585561, 'Total loss': 0.4355719228585561} | train loss {'Reaction outcome loss': 0.10275252466807075, 'Total loss': 0.10275252466807075}
2022-12-31 05:26:05,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:05,209 INFO:     Epoch: 99
2022-12-31 05:26:06,828 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4183445741732915, 'Total loss': 0.4183445741732915} | train loss {'Reaction outcome loss': 0.10168570334992735, 'Total loss': 0.10168570334992735}
2022-12-31 05:26:06,828 INFO:     Best model found after epoch 72 of 100.
2022-12-31 05:26:06,828 INFO:   Done with stage: TRAINING
2022-12-31 05:26:06,829 INFO:   Starting stage: EVALUATION
2022-12-31 05:26:06,960 INFO:   Done with stage: EVALUATION
2022-12-31 05:26:06,968 INFO:   Leaving out SEQ value Fold_0
2022-12-31 05:26:06,981 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:26:06,981 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:26:07,635 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:26:07,635 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:26:07,706 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:26:07,706 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:26:07,706 INFO:     No hyperparam tuning for this model
2022-12-31 05:26:07,706 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:26:07,706 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:26:07,707 INFO:     None feature selector for col prot
2022-12-31 05:26:07,707 INFO:     None feature selector for col prot
2022-12-31 05:26:07,707 INFO:     None feature selector for col prot
2022-12-31 05:26:07,708 INFO:     None feature selector for col chem
2022-12-31 05:26:07,708 INFO:     None feature selector for col chem
2022-12-31 05:26:07,708 INFO:     None feature selector for col chem
2022-12-31 05:26:07,708 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:26:07,708 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:26:07,710 INFO:     Number of params in model 224011
2022-12-31 05:26:07,713 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:26:07,713 INFO:   Starting stage: TRAINING
2022-12-31 05:26:07,758 INFO:     Val loss before train {'Reaction outcome loss': 1.0348129709561666, 'Total loss': 1.0348129709561666}
2022-12-31 05:26:07,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:07,759 INFO:     Epoch: 0
2022-12-31 05:26:09,370 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5506434182325999, 'Total loss': 0.5506434182325999} | train loss {'Reaction outcome loss': 0.7746921807149614, 'Total loss': 0.7746921807149614}
2022-12-31 05:26:09,370 INFO:     Found new best model at epoch 0
2022-12-31 05:26:09,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:09,371 INFO:     Epoch: 1
2022-12-31 05:26:10,991 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45756537715593976, 'Total loss': 0.45756537715593976} | train loss {'Reaction outcome loss': 0.5091899842803326, 'Total loss': 0.5091899842803326}
2022-12-31 05:26:10,991 INFO:     Found new best model at epoch 1
2022-12-31 05:26:10,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:10,992 INFO:     Epoch: 2
2022-12-31 05:26:12,618 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43527232805887855, 'Total loss': 0.43527232805887855} | train loss {'Reaction outcome loss': 0.4432218940591143, 'Total loss': 0.4432218940591143}
2022-12-31 05:26:12,618 INFO:     Found new best model at epoch 2
2022-12-31 05:26:12,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:12,619 INFO:     Epoch: 3
2022-12-31 05:26:14,235 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3869138553738594, 'Total loss': 0.3869138553738594} | train loss {'Reaction outcome loss': 0.4023273428802908, 'Total loss': 0.4023273428802908}
2022-12-31 05:26:14,235 INFO:     Found new best model at epoch 3
2022-12-31 05:26:14,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:14,236 INFO:     Epoch: 4
2022-12-31 05:26:15,852 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.38496214846769966, 'Total loss': 0.38496214846769966} | train loss {'Reaction outcome loss': 0.37385805072667805, 'Total loss': 0.37385805072667805}
2022-12-31 05:26:15,852 INFO:     Found new best model at epoch 4
2022-12-31 05:26:15,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:15,853 INFO:     Epoch: 5
2022-12-31 05:26:17,469 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38839819729328157, 'Total loss': 0.38839819729328157} | train loss {'Reaction outcome loss': 0.3596461210939763, 'Total loss': 0.3596461210939763}
2022-12-31 05:26:17,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:17,469 INFO:     Epoch: 6
2022-12-31 05:26:19,095 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38361866772174835, 'Total loss': 0.38361866772174835} | train loss {'Reaction outcome loss': 0.3327954532072434, 'Total loss': 0.3327954532072434}
2022-12-31 05:26:19,095 INFO:     Found new best model at epoch 6
2022-12-31 05:26:19,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:19,096 INFO:     Epoch: 7
2022-12-31 05:26:20,720 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.36696704626083376, 'Total loss': 0.36696704626083376} | train loss {'Reaction outcome loss': 0.31235029797771596, 'Total loss': 0.31235029797771596}
2022-12-31 05:26:20,721 INFO:     Found new best model at epoch 7
2022-12-31 05:26:20,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:20,722 INFO:     Epoch: 8
2022-12-31 05:26:22,338 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.36826840341091155, 'Total loss': 0.36826840341091155} | train loss {'Reaction outcome loss': 0.30586534274229105, 'Total loss': 0.30586534274229105}
2022-12-31 05:26:22,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:22,338 INFO:     Epoch: 9
2022-12-31 05:26:23,963 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3619809647401174, 'Total loss': 0.3619809647401174} | train loss {'Reaction outcome loss': 0.29148546809944714, 'Total loss': 0.29148546809944714}
2022-12-31 05:26:23,963 INFO:     Found new best model at epoch 9
2022-12-31 05:26:23,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:23,964 INFO:     Epoch: 10
2022-12-31 05:26:25,589 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.36236211558183035, 'Total loss': 0.36236211558183035} | train loss {'Reaction outcome loss': 0.2729980632581789, 'Total loss': 0.2729980632581789}
2022-12-31 05:26:25,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:25,589 INFO:     Epoch: 11
2022-12-31 05:26:27,206 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38442302743593854, 'Total loss': 0.38442302743593854} | train loss {'Reaction outcome loss': 0.27589994303180254, 'Total loss': 0.27589994303180254}
2022-12-31 05:26:27,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:27,207 INFO:     Epoch: 12
2022-12-31 05:26:28,833 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3473487307627996, 'Total loss': 0.3473487307627996} | train loss {'Reaction outcome loss': 0.2664062178214938, 'Total loss': 0.2664062178214938}
2022-12-31 05:26:28,833 INFO:     Found new best model at epoch 12
2022-12-31 05:26:28,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:28,834 INFO:     Epoch: 13
2022-12-31 05:26:30,452 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35816261370976765, 'Total loss': 0.35816261370976765} | train loss {'Reaction outcome loss': 0.25103565270378103, 'Total loss': 0.25103565270378103}
2022-12-31 05:26:30,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:30,453 INFO:     Epoch: 14
2022-12-31 05:26:32,079 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34772512366374336, 'Total loss': 0.34772512366374336} | train loss {'Reaction outcome loss': 0.2536969259921191, 'Total loss': 0.2536969259921191}
2022-12-31 05:26:32,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:32,079 INFO:     Epoch: 15
2022-12-31 05:26:33,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3474864959716797, 'Total loss': 0.3474864959716797} | train loss {'Reaction outcome loss': 0.22868011672993738, 'Total loss': 0.22868011672993738}
2022-12-31 05:26:33,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:33,720 INFO:     Epoch: 16
2022-12-31 05:26:35,338 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3478790650765101, 'Total loss': 0.3478790650765101} | train loss {'Reaction outcome loss': 0.22191649061742413, 'Total loss': 0.22191649061742413}
2022-12-31 05:26:35,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:35,339 INFO:     Epoch: 17
2022-12-31 05:26:36,957 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.34289252509673435, 'Total loss': 0.34289252509673435} | train loss {'Reaction outcome loss': 0.21339149598782609, 'Total loss': 0.21339149598782609}
2022-12-31 05:26:36,957 INFO:     Found new best model at epoch 17
2022-12-31 05:26:36,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:36,958 INFO:     Epoch: 18
2022-12-31 05:26:38,586 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3580857515335083, 'Total loss': 0.3580857515335083} | train loss {'Reaction outcome loss': 0.20963803275177875, 'Total loss': 0.20963803275177875}
2022-12-31 05:26:38,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:38,586 INFO:     Epoch: 19
2022-12-31 05:26:40,205 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3397286951541901, 'Total loss': 0.3397286951541901} | train loss {'Reaction outcome loss': 0.2257619691553755, 'Total loss': 0.2257619691553755}
2022-12-31 05:26:40,206 INFO:     Found new best model at epoch 19
2022-12-31 05:26:40,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:40,207 INFO:     Epoch: 20
2022-12-31 05:26:41,827 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3501878589391708, 'Total loss': 0.3501878589391708} | train loss {'Reaction outcome loss': 0.1975732863909376, 'Total loss': 0.1975732863909376}
2022-12-31 05:26:41,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:41,827 INFO:     Epoch: 21
2022-12-31 05:26:43,492 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3512607914706071, 'Total loss': 0.3512607914706071} | train loss {'Reaction outcome loss': 0.19138857133347684, 'Total loss': 0.19138857133347684}
2022-12-31 05:26:43,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:43,492 INFO:     Epoch: 22
2022-12-31 05:26:45,112 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34839305430650713, 'Total loss': 0.34839305430650713} | train loss {'Reaction outcome loss': 0.192609255310094, 'Total loss': 0.192609255310094}
2022-12-31 05:26:45,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:45,112 INFO:     Epoch: 23
2022-12-31 05:26:46,728 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.31962699393431343, 'Total loss': 0.31962699393431343} | train loss {'Reaction outcome loss': 0.19578241627955256, 'Total loss': 0.19578241627955256}
2022-12-31 05:26:46,728 INFO:     Found new best model at epoch 23
2022-12-31 05:26:46,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:46,729 INFO:     Epoch: 24
2022-12-31 05:26:48,350 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.348323533932368, 'Total loss': 0.348323533932368} | train loss {'Reaction outcome loss': 0.18271603745760975, 'Total loss': 0.18271603745760975}
2022-12-31 05:26:48,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:48,351 INFO:     Epoch: 25
2022-12-31 05:26:49,985 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3723796375095844, 'Total loss': 0.3723796375095844} | train loss {'Reaction outcome loss': 0.1755258582863093, 'Total loss': 0.1755258582863093}
2022-12-31 05:26:49,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:49,985 INFO:     Epoch: 26
2022-12-31 05:26:51,619 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38191777368386587, 'Total loss': 0.38191777368386587} | train loss {'Reaction outcome loss': 0.17381346218631286, 'Total loss': 0.17381346218631286}
2022-12-31 05:26:51,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:51,621 INFO:     Epoch: 27
2022-12-31 05:26:53,254 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3501327807704608, 'Total loss': 0.3501327807704608} | train loss {'Reaction outcome loss': 0.17033710941145924, 'Total loss': 0.17033710941145924}
2022-12-31 05:26:53,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:53,254 INFO:     Epoch: 28
2022-12-31 05:26:54,885 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36248599489529926, 'Total loss': 0.36248599489529926} | train loss {'Reaction outcome loss': 0.16839857132984343, 'Total loss': 0.16839857132984343}
2022-12-31 05:26:54,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:54,886 INFO:     Epoch: 29
2022-12-31 05:26:56,518 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3399087697267532, 'Total loss': 0.3399087697267532} | train loss {'Reaction outcome loss': 0.16965251802247477, 'Total loss': 0.16965251802247477}
2022-12-31 05:26:56,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:56,519 INFO:     Epoch: 30
2022-12-31 05:26:58,157 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3668803170323372, 'Total loss': 0.3668803170323372} | train loss {'Reaction outcome loss': 0.187842646272907, 'Total loss': 0.187842646272907}
2022-12-31 05:26:58,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:58,158 INFO:     Epoch: 31
2022-12-31 05:26:59,824 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36449054181575774, 'Total loss': 0.36449054181575774} | train loss {'Reaction outcome loss': 0.16259088155778084, 'Total loss': 0.16259088155778084}
2022-12-31 05:26:59,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:26:59,824 INFO:     Epoch: 32
2022-12-31 05:27:01,489 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3435978206495444, 'Total loss': 0.3435978206495444} | train loss {'Reaction outcome loss': 0.16423392489720584, 'Total loss': 0.16423392489720584}
2022-12-31 05:27:01,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:01,489 INFO:     Epoch: 33
2022-12-31 05:27:03,113 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3484772006670634, 'Total loss': 0.3484772006670634} | train loss {'Reaction outcome loss': 0.15749615640163978, 'Total loss': 0.15749615640163978}
2022-12-31 05:27:03,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:03,113 INFO:     Epoch: 34
2022-12-31 05:27:04,733 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.30856160273154576, 'Total loss': 0.30856160273154576} | train loss {'Reaction outcome loss': 0.15338613108400276, 'Total loss': 0.15338613108400276}
2022-12-31 05:27:04,733 INFO:     Found new best model at epoch 34
2022-12-31 05:27:04,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:04,734 INFO:     Epoch: 35
2022-12-31 05:27:06,363 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3425195967157682, 'Total loss': 0.3425195967157682} | train loss {'Reaction outcome loss': 0.15299834495944314, 'Total loss': 0.15299834495944314}
2022-12-31 05:27:06,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:06,363 INFO:     Epoch: 36
2022-12-31 05:27:07,989 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33619484504063923, 'Total loss': 0.33619484504063923} | train loss {'Reaction outcome loss': 0.14695140192033368, 'Total loss': 0.14695140192033368}
2022-12-31 05:27:07,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:07,989 INFO:     Epoch: 37
2022-12-31 05:27:09,622 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3183508957425753, 'Total loss': 0.3183508957425753} | train loss {'Reaction outcome loss': 0.14454081898852103, 'Total loss': 0.14454081898852103}
2022-12-31 05:27:09,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:09,622 INFO:     Epoch: 38
2022-12-31 05:27:11,254 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.33321929176648457, 'Total loss': 0.33321929176648457} | train loss {'Reaction outcome loss': 0.14547461235644363, 'Total loss': 0.14547461235644363}
2022-12-31 05:27:11,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:11,255 INFO:     Epoch: 39
2022-12-31 05:27:12,876 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.31941652595996856, 'Total loss': 0.31941652595996856} | train loss {'Reaction outcome loss': 0.14425114396569055, 'Total loss': 0.14425114396569055}
2022-12-31 05:27:12,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:12,877 INFO:     Epoch: 40
2022-12-31 05:27:14,505 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35685129861036935, 'Total loss': 0.35685129861036935} | train loss {'Reaction outcome loss': 0.14257514741357358, 'Total loss': 0.14257514741357358}
2022-12-31 05:27:14,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:14,505 INFO:     Epoch: 41
2022-12-31 05:27:16,125 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3244622930884361, 'Total loss': 0.3244622930884361} | train loss {'Reaction outcome loss': 0.13934626315544912, 'Total loss': 0.13934626315544912}
2022-12-31 05:27:16,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:16,125 INFO:     Epoch: 42
2022-12-31 05:27:17,753 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3278782178958257, 'Total loss': 0.3278782178958257} | train loss {'Reaction outcome loss': 0.13963921984617153, 'Total loss': 0.13963921984617153}
2022-12-31 05:27:17,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:17,753 INFO:     Epoch: 43
2022-12-31 05:27:19,380 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34364288051923114, 'Total loss': 0.34364288051923114} | train loss {'Reaction outcome loss': 0.13625904391992136, 'Total loss': 0.13625904391992136}
2022-12-31 05:27:19,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:19,380 INFO:     Epoch: 44
2022-12-31 05:27:21,007 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3392557313044866, 'Total loss': 0.3392557313044866} | train loss {'Reaction outcome loss': 0.13935699876046914, 'Total loss': 0.13935699876046914}
2022-12-31 05:27:21,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:21,007 INFO:     Epoch: 45
2022-12-31 05:27:22,626 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.34347617626190186, 'Total loss': 0.34347617626190186} | train loss {'Reaction outcome loss': 0.13925018630613087, 'Total loss': 0.13925018630613087}
2022-12-31 05:27:22,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:22,627 INFO:     Epoch: 46
2022-12-31 05:27:24,251 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3753705496589343, 'Total loss': 0.3753705496589343} | train loss {'Reaction outcome loss': 0.13355122312297707, 'Total loss': 0.13355122312297707}
2022-12-31 05:27:24,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:24,252 INFO:     Epoch: 47
2022-12-31 05:27:25,871 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3199694474538167, 'Total loss': 0.3199694474538167} | train loss {'Reaction outcome loss': 0.13720842352072857, 'Total loss': 0.13720842352072857}
2022-12-31 05:27:25,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:25,871 INFO:     Epoch: 48
2022-12-31 05:27:27,500 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3178851986924807, 'Total loss': 0.3178851986924807} | train loss {'Reaction outcome loss': 0.1333855820171859, 'Total loss': 0.1333855820171859}
2022-12-31 05:27:27,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:27,500 INFO:     Epoch: 49
2022-12-31 05:27:29,128 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33892344584067663, 'Total loss': 0.33892344584067663} | train loss {'Reaction outcome loss': 0.1323355876054426, 'Total loss': 0.1323355876054426}
2022-12-31 05:27:29,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:29,129 INFO:     Epoch: 50
2022-12-31 05:27:30,755 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33978224396705625, 'Total loss': 0.33978224396705625} | train loss {'Reaction outcome loss': 0.12869866240762876, 'Total loss': 0.12869866240762876}
2022-12-31 05:27:30,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:30,755 INFO:     Epoch: 51
2022-12-31 05:27:32,404 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3178752392530441, 'Total loss': 0.3178752392530441} | train loss {'Reaction outcome loss': 0.13077964824412408, 'Total loss': 0.13077964824412408}
2022-12-31 05:27:32,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:32,404 INFO:     Epoch: 52
2022-12-31 05:27:34,049 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3633123298486074, 'Total loss': 0.3633123298486074} | train loss {'Reaction outcome loss': 0.13234511324876425, 'Total loss': 0.13234511324876425}
2022-12-31 05:27:34,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:34,049 INFO:     Epoch: 53
2022-12-31 05:27:35,676 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.33405064741770424, 'Total loss': 0.33405064741770424} | train loss {'Reaction outcome loss': 0.12768909623137797, 'Total loss': 0.12768909623137797}
2022-12-31 05:27:35,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:35,676 INFO:     Epoch: 54
2022-12-31 05:27:37,303 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.33825018455584843, 'Total loss': 0.33825018455584843} | train loss {'Reaction outcome loss': 0.12790724254243643, 'Total loss': 0.12790724254243643}
2022-12-31 05:27:37,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:37,303 INFO:     Epoch: 55
2022-12-31 05:27:38,931 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.339014521241188, 'Total loss': 0.339014521241188} | train loss {'Reaction outcome loss': 0.12315183159544309, 'Total loss': 0.12315183159544309}
2022-12-31 05:27:38,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:38,932 INFO:     Epoch: 56
2022-12-31 05:27:40,550 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32053914467493694, 'Total loss': 0.32053914467493694} | train loss {'Reaction outcome loss': 0.12766050030536397, 'Total loss': 0.12766050030536397}
2022-12-31 05:27:40,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:40,551 INFO:     Epoch: 57
2022-12-31 05:27:42,176 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3546085089445114, 'Total loss': 0.3546085089445114} | train loss {'Reaction outcome loss': 0.12304689792369533, 'Total loss': 0.12304689792369533}
2022-12-31 05:27:42,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:42,177 INFO:     Epoch: 58
2022-12-31 05:27:43,797 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34321289708216984, 'Total loss': 0.34321289708216984} | train loss {'Reaction outcome loss': 0.12362128843707741, 'Total loss': 0.12362128843707741}
2022-12-31 05:27:43,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:43,797 INFO:     Epoch: 59
2022-12-31 05:27:45,424 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33568996489048003, 'Total loss': 0.33568996489048003} | train loss {'Reaction outcome loss': 0.12489030332864681, 'Total loss': 0.12489030332864681}
2022-12-31 05:27:45,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:45,424 INFO:     Epoch: 60
2022-12-31 05:27:47,056 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3515569647153219, 'Total loss': 0.3515569647153219} | train loss {'Reaction outcome loss': 0.12121655079671115, 'Total loss': 0.12121655079671115}
2022-12-31 05:27:47,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:47,057 INFO:     Epoch: 61
2022-12-31 05:27:48,683 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35054160753885905, 'Total loss': 0.35054160753885905} | train loss {'Reaction outcome loss': 0.1223116750386881, 'Total loss': 0.1223116750386881}
2022-12-31 05:27:48,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:48,683 INFO:     Epoch: 62
2022-12-31 05:27:50,297 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3328352391719818, 'Total loss': 0.3328352391719818} | train loss {'Reaction outcome loss': 0.12106186369150553, 'Total loss': 0.12106186369150553}
2022-12-31 05:27:50,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:50,297 INFO:     Epoch: 63
2022-12-31 05:27:51,919 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.335909511645635, 'Total loss': 0.335909511645635} | train loss {'Reaction outcome loss': 0.12076235833376193, 'Total loss': 0.12076235833376193}
2022-12-31 05:27:51,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:51,919 INFO:     Epoch: 64
2022-12-31 05:27:53,570 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3355292049547037, 'Total loss': 0.3355292049547037} | train loss {'Reaction outcome loss': 0.12248594673372651, 'Total loss': 0.12248594673372651}
2022-12-31 05:27:53,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:53,570 INFO:     Epoch: 65
2022-12-31 05:27:55,181 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3424428790807724, 'Total loss': 0.3424428790807724} | train loss {'Reaction outcome loss': 0.11547306377147122, 'Total loss': 0.11547306377147122}
2022-12-31 05:27:55,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:55,181 INFO:     Epoch: 66
2022-12-31 05:27:56,841 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.31509723644703624, 'Total loss': 0.31509723644703624} | train loss {'Reaction outcome loss': 0.11662659016935546, 'Total loss': 0.11662659016935546}
2022-12-31 05:27:56,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:56,841 INFO:     Epoch: 67
2022-12-31 05:27:58,488 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35127325281500815, 'Total loss': 0.35127325281500815} | train loss {'Reaction outcome loss': 0.11947600353799488, 'Total loss': 0.11947600353799488}
2022-12-31 05:27:58,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:27:58,489 INFO:     Epoch: 68
2022-12-31 05:28:00,115 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3494418829679489, 'Total loss': 0.3494418829679489} | train loss {'Reaction outcome loss': 0.1184959622121929, 'Total loss': 0.1184959622121929}
2022-12-31 05:28:00,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:00,115 INFO:     Epoch: 69
2022-12-31 05:28:01,737 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3502666528026263, 'Total loss': 0.3502666528026263} | train loss {'Reaction outcome loss': 0.11699067683072654, 'Total loss': 0.11699067683072654}
2022-12-31 05:28:01,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:01,737 INFO:     Epoch: 70
2022-12-31 05:28:03,364 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3643039678533872, 'Total loss': 0.3643039678533872} | train loss {'Reaction outcome loss': 0.11743391893358658, 'Total loss': 0.11743391893358658}
2022-12-31 05:28:03,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:03,364 INFO:     Epoch: 71
2022-12-31 05:28:04,994 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35779376129309337, 'Total loss': 0.35779376129309337} | train loss {'Reaction outcome loss': 0.12483974157215055, 'Total loss': 0.12483974157215055}
2022-12-31 05:28:04,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:04,995 INFO:     Epoch: 72
2022-12-31 05:28:06,647 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3325950548052788, 'Total loss': 0.3325950548052788} | train loss {'Reaction outcome loss': 0.12154907252313907, 'Total loss': 0.12154907252313907}
2022-12-31 05:28:06,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:06,647 INFO:     Epoch: 73
2022-12-31 05:28:08,268 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3287025531133016, 'Total loss': 0.3287025531133016} | train loss {'Reaction outcome loss': 0.11371812174774527, 'Total loss': 0.11371812174774527}
2022-12-31 05:28:08,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:08,269 INFO:     Epoch: 74
2022-12-31 05:28:09,930 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.32931917992730936, 'Total loss': 0.32931917992730936} | train loss {'Reaction outcome loss': 0.10965687340037708, 'Total loss': 0.10965687340037708}
2022-12-31 05:28:09,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:09,931 INFO:     Epoch: 75
2022-12-31 05:28:11,553 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3512557754913966, 'Total loss': 0.3512557754913966} | train loss {'Reaction outcome loss': 0.110294570452095, 'Total loss': 0.110294570452095}
2022-12-31 05:28:11,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:11,554 INFO:     Epoch: 76
2022-12-31 05:28:13,214 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3469196935494741, 'Total loss': 0.3469196935494741} | train loss {'Reaction outcome loss': 0.11293201316813374, 'Total loss': 0.11293201316813374}
2022-12-31 05:28:13,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:13,215 INFO:     Epoch: 77
2022-12-31 05:28:14,831 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37764618123571075, 'Total loss': 0.37764618123571075} | train loss {'Reaction outcome loss': 0.11237256662461469, 'Total loss': 0.11237256662461469}
2022-12-31 05:28:14,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:14,832 INFO:     Epoch: 78
2022-12-31 05:28:16,493 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3287518933415413, 'Total loss': 0.3287518933415413} | train loss {'Reaction outcome loss': 0.11119075397837677, 'Total loss': 0.11119075397837677}
2022-12-31 05:28:16,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:16,493 INFO:     Epoch: 79
2022-12-31 05:28:18,143 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34164601415395734, 'Total loss': 0.34164601415395734} | train loss {'Reaction outcome loss': 0.11109204707593998, 'Total loss': 0.11109204707593998}
2022-12-31 05:28:18,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:18,144 INFO:     Epoch: 80
2022-12-31 05:28:19,760 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35286508897940316, 'Total loss': 0.35286508897940316} | train loss {'Reaction outcome loss': 0.11274328021283798, 'Total loss': 0.11274328021283798}
2022-12-31 05:28:19,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:19,760 INFO:     Epoch: 81
2022-12-31 05:28:21,380 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.31853078777591387, 'Total loss': 0.31853078777591387} | train loss {'Reaction outcome loss': 0.11111551690576733, 'Total loss': 0.11111551690576733}
2022-12-31 05:28:21,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:21,380 INFO:     Epoch: 82
2022-12-31 05:28:23,007 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34850156754255296, 'Total loss': 0.34850156754255296} | train loss {'Reaction outcome loss': 0.10876088439136967, 'Total loss': 0.10876088439136967}
2022-12-31 05:28:23,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:23,008 INFO:     Epoch: 83
2022-12-31 05:28:24,628 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35296647499005, 'Total loss': 0.35296647499005} | train loss {'Reaction outcome loss': 0.11389860198360638, 'Total loss': 0.11389860198360638}
2022-12-31 05:28:24,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:24,629 INFO:     Epoch: 84
2022-12-31 05:28:26,261 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.32592072412371637, 'Total loss': 0.32592072412371637} | train loss {'Reaction outcome loss': 0.11029687614464437, 'Total loss': 0.11029687614464437}
2022-12-31 05:28:26,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:26,261 INFO:     Epoch: 85
2022-12-31 05:28:27,884 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3304528151949247, 'Total loss': 0.3304528151949247} | train loss {'Reaction outcome loss': 0.11058451854995033, 'Total loss': 0.11058451854995033}
2022-12-31 05:28:27,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:27,884 INFO:     Epoch: 86
2022-12-31 05:28:29,496 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3388606905937195, 'Total loss': 0.3388606905937195} | train loss {'Reaction outcome loss': 0.12337617108098947, 'Total loss': 0.12337617108098947}
2022-12-31 05:28:29,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:29,496 INFO:     Epoch: 87
2022-12-31 05:28:31,113 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3344067044556141, 'Total loss': 0.3344067044556141} | train loss {'Reaction outcome loss': 0.11021564078892233, 'Total loss': 0.11021564078892233}
2022-12-31 05:28:31,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:31,113 INFO:     Epoch: 88
2022-12-31 05:28:32,770 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.30025600294272103, 'Total loss': 0.30025600294272103} | train loss {'Reaction outcome loss': 0.10761801454946905, 'Total loss': 0.10761801454946905}
2022-12-31 05:28:32,770 INFO:     Found new best model at epoch 88
2022-12-31 05:28:32,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:32,771 INFO:     Epoch: 89
2022-12-31 05:28:34,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3266473937779665, 'Total loss': 0.3266473937779665} | train loss {'Reaction outcome loss': 0.10203674535032538, 'Total loss': 0.10203674535032538}
2022-12-31 05:28:34,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:34,394 INFO:     Epoch: 90
2022-12-31 05:28:36,023 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3517805924018224, 'Total loss': 0.3517805924018224} | train loss {'Reaction outcome loss': 0.10684241351175486, 'Total loss': 0.10684241351175486}
2022-12-31 05:28:36,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:36,023 INFO:     Epoch: 91
2022-12-31 05:28:37,642 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.33965899497270585, 'Total loss': 0.33965899497270585} | train loss {'Reaction outcome loss': 0.16446086694064643, 'Total loss': 0.16446086694064643}
2022-12-31 05:28:37,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:37,642 INFO:     Epoch: 92
2022-12-31 05:28:39,306 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3332048257191976, 'Total loss': 0.3332048257191976} | train loss {'Reaction outcome loss': 0.11948367742844061, 'Total loss': 0.11948367742844061}
2022-12-31 05:28:39,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:39,306 INFO:     Epoch: 93
2022-12-31 05:28:40,922 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34395138919353485, 'Total loss': 0.34395138919353485} | train loss {'Reaction outcome loss': 0.11198184717487374, 'Total loss': 0.11198184717487374}
2022-12-31 05:28:40,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:40,923 INFO:     Epoch: 94
2022-12-31 05:28:42,536 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3417913645505905, 'Total loss': 0.3417913645505905} | train loss {'Reaction outcome loss': 0.10830506169419833, 'Total loss': 0.10830506169419833}
2022-12-31 05:28:42,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:42,536 INFO:     Epoch: 95
2022-12-31 05:28:44,182 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.33037723898887633, 'Total loss': 0.33037723898887633} | train loss {'Reaction outcome loss': 0.10630521365944161, 'Total loss': 0.10630521365944161}
2022-12-31 05:28:44,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:44,182 INFO:     Epoch: 96
2022-12-31 05:28:45,806 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.30780262847741446, 'Total loss': 0.30780262847741446} | train loss {'Reaction outcome loss': 0.10780847405186396, 'Total loss': 0.10780847405186396}
2022-12-31 05:28:45,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:45,806 INFO:     Epoch: 97
2022-12-31 05:28:47,479 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33733859757582346, 'Total loss': 0.33733859757582346} | train loss {'Reaction outcome loss': 0.10594642044979728, 'Total loss': 0.10594642044979728}
2022-12-31 05:28:47,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:47,480 INFO:     Epoch: 98
2022-12-31 05:28:49,136 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3101377839843432, 'Total loss': 0.3101377839843432} | train loss {'Reaction outcome loss': 0.10597561603071222, 'Total loss': 0.10597561603071222}
2022-12-31 05:28:49,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:49,137 INFO:     Epoch: 99
2022-12-31 05:28:50,761 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33289197434981666, 'Total loss': 0.33289197434981666} | train loss {'Reaction outcome loss': 0.10935147509777723, 'Total loss': 0.10935147509777723}
2022-12-31 05:28:50,761 INFO:     Best model found after epoch 89 of 100.
2022-12-31 05:28:50,761 INFO:   Done with stage: TRAINING
2022-12-31 05:28:50,761 INFO:   Starting stage: EVALUATION
2022-12-31 05:28:50,892 INFO:   Done with stage: EVALUATION
2022-12-31 05:28:50,892 INFO:   Leaving out SEQ value Fold_1
2022-12-31 05:28:50,905 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:28:50,905 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:28:51,551 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:28:51,551 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:28:51,621 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:28:51,621 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:28:51,621 INFO:     No hyperparam tuning for this model
2022-12-31 05:28:51,621 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:28:51,621 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:28:51,622 INFO:     None feature selector for col prot
2022-12-31 05:28:51,622 INFO:     None feature selector for col prot
2022-12-31 05:28:51,622 INFO:     None feature selector for col prot
2022-12-31 05:28:51,623 INFO:     None feature selector for col chem
2022-12-31 05:28:51,623 INFO:     None feature selector for col chem
2022-12-31 05:28:51,623 INFO:     None feature selector for col chem
2022-12-31 05:28:51,623 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:28:51,623 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:28:51,625 INFO:     Number of params in model 224011
2022-12-31 05:28:51,628 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:28:51,628 INFO:   Starting stage: TRAINING
2022-12-31 05:28:51,673 INFO:     Val loss before train {'Reaction outcome loss': 1.0218703707059225, 'Total loss': 1.0218703707059225}
2022-12-31 05:28:51,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:51,673 INFO:     Epoch: 0
2022-12-31 05:28:53,293 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5848037858804067, 'Total loss': 0.5848037858804067} | train loss {'Reaction outcome loss': 0.7783831232699795, 'Total loss': 0.7783831232699795}
2022-12-31 05:28:53,294 INFO:     Found new best model at epoch 0
2022-12-31 05:28:53,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:53,295 INFO:     Epoch: 1
2022-12-31 05:28:54,908 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5037887454032898, 'Total loss': 0.5037887454032898} | train loss {'Reaction outcome loss': 0.5105382758530154, 'Total loss': 0.5105382758530154}
2022-12-31 05:28:54,909 INFO:     Found new best model at epoch 1
2022-12-31 05:28:54,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:54,910 INFO:     Epoch: 2
2022-12-31 05:28:56,524 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45485103825728096, 'Total loss': 0.45485103825728096} | train loss {'Reaction outcome loss': 0.4702178002807541, 'Total loss': 0.4702178002807541}
2022-12-31 05:28:56,524 INFO:     Found new best model at epoch 2
2022-12-31 05:28:56,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:56,525 INFO:     Epoch: 3
2022-12-31 05:28:58,143 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47080394824345906, 'Total loss': 0.47080394824345906} | train loss {'Reaction outcome loss': 0.40696887918950425, 'Total loss': 0.40696887918950425}
2022-12-31 05:28:58,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:58,143 INFO:     Epoch: 4
2022-12-31 05:28:59,804 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44187699556350707, 'Total loss': 0.44187699556350707} | train loss {'Reaction outcome loss': 0.38506984720141557, 'Total loss': 0.38506984720141557}
2022-12-31 05:28:59,804 INFO:     Found new best model at epoch 4
2022-12-31 05:28:59,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:28:59,805 INFO:     Epoch: 5
2022-12-31 05:29:01,420 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43521273533503213, 'Total loss': 0.43521273533503213} | train loss {'Reaction outcome loss': 0.35832475541510445, 'Total loss': 0.35832475541510445}
2022-12-31 05:29:01,420 INFO:     Found new best model at epoch 5
2022-12-31 05:29:01,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:01,421 INFO:     Epoch: 6
2022-12-31 05:29:03,028 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4240841194987297, 'Total loss': 0.4240841194987297} | train loss {'Reaction outcome loss': 0.3446532783867872, 'Total loss': 0.3446532783867872}
2022-12-31 05:29:03,028 INFO:     Found new best model at epoch 6
2022-12-31 05:29:03,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:03,029 INFO:     Epoch: 7
2022-12-31 05:29:04,649 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4407908578713735, 'Total loss': 0.4407908578713735} | train loss {'Reaction outcome loss': 0.3234835132902515, 'Total loss': 0.3234835132902515}
2022-12-31 05:29:04,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:04,649 INFO:     Epoch: 8
2022-12-31 05:29:06,310 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4248163253068924, 'Total loss': 0.4248163253068924} | train loss {'Reaction outcome loss': 0.30792784702540643, 'Total loss': 0.30792784702540643}
2022-12-31 05:29:06,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:06,311 INFO:     Epoch: 9
2022-12-31 05:29:07,923 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41969149112701415, 'Total loss': 0.41969149112701415} | train loss {'Reaction outcome loss': 0.28901137161807605, 'Total loss': 0.28901137161807605}
2022-12-31 05:29:07,924 INFO:     Found new best model at epoch 9
2022-12-31 05:29:07,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:07,925 INFO:     Epoch: 10
2022-12-31 05:29:09,541 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4169514199097951, 'Total loss': 0.4169514199097951} | train loss {'Reaction outcome loss': 0.28239652765509876, 'Total loss': 0.28239652765509876}
2022-12-31 05:29:09,542 INFO:     Found new best model at epoch 10
2022-12-31 05:29:09,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:09,543 INFO:     Epoch: 11
2022-12-31 05:29:11,149 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4076242491602898, 'Total loss': 0.4076242491602898} | train loss {'Reaction outcome loss': 0.2785079212812032, 'Total loss': 0.2785079212812032}
2022-12-31 05:29:11,149 INFO:     Found new best model at epoch 11
2022-12-31 05:29:11,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:11,150 INFO:     Epoch: 12
2022-12-31 05:29:12,767 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3934626877307892, 'Total loss': 0.3934626877307892} | train loss {'Reaction outcome loss': 0.26233702519591356, 'Total loss': 0.26233702519591356}
2022-12-31 05:29:12,767 INFO:     Found new best model at epoch 12
2022-12-31 05:29:12,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:12,768 INFO:     Epoch: 13
2022-12-31 05:29:14,387 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4057836097975572, 'Total loss': 0.4057836097975572} | train loss {'Reaction outcome loss': 0.25050146770706266, 'Total loss': 0.25050146770706266}
2022-12-31 05:29:14,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:14,387 INFO:     Epoch: 14
2022-12-31 05:29:16,049 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41019211411476136, 'Total loss': 0.41019211411476136} | train loss {'Reaction outcome loss': 0.24534606683891322, 'Total loss': 0.24534606683891322}
2022-12-31 05:29:16,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:16,050 INFO:     Epoch: 15
2022-12-31 05:29:17,663 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42678716977437336, 'Total loss': 0.42678716977437336} | train loss {'Reaction outcome loss': 0.23502991688977656, 'Total loss': 0.23502991688977656}
2022-12-31 05:29:17,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:17,663 INFO:     Epoch: 16
2022-12-31 05:29:19,325 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4086380317807198, 'Total loss': 0.4086380317807198} | train loss {'Reaction outcome loss': 0.22882915128265385, 'Total loss': 0.22882915128265385}
2022-12-31 05:29:19,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:19,325 INFO:     Epoch: 17
2022-12-31 05:29:20,972 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4214601248502731, 'Total loss': 0.4214601248502731} | train loss {'Reaction outcome loss': 0.22833643575181817, 'Total loss': 0.22833643575181817}
2022-12-31 05:29:20,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:20,972 INFO:     Epoch: 18
2022-12-31 05:29:22,632 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42211013634999595, 'Total loss': 0.42211013634999595} | train loss {'Reaction outcome loss': 0.2190587178102114, 'Total loss': 0.2190587178102114}
2022-12-31 05:29:22,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:22,632 INFO:     Epoch: 19
2022-12-31 05:29:24,252 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40999740262826284, 'Total loss': 0.40999740262826284} | train loss {'Reaction outcome loss': 0.2083294336047982, 'Total loss': 0.2083294336047982}
2022-12-31 05:29:24,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:24,252 INFO:     Epoch: 20
2022-12-31 05:29:25,880 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40878338118394214, 'Total loss': 0.40878338118394214} | train loss {'Reaction outcome loss': 0.20208646674417768, 'Total loss': 0.20208646674417768}
2022-12-31 05:29:25,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:25,880 INFO:     Epoch: 21
2022-12-31 05:29:27,508 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4036208192507426, 'Total loss': 0.4036208192507426} | train loss {'Reaction outcome loss': 0.19798308191156652, 'Total loss': 0.19798308191156652}
2022-12-31 05:29:27,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:27,508 INFO:     Epoch: 22
2022-12-31 05:29:29,134 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41200396219889324, 'Total loss': 0.41200396219889324} | train loss {'Reaction outcome loss': 0.19329394045474846, 'Total loss': 0.19329394045474846}
2022-12-31 05:29:29,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:29,135 INFO:     Epoch: 23
2022-12-31 05:29:30,818 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41917407761017483, 'Total loss': 0.41917407761017483} | train loss {'Reaction outcome loss': 0.18847622627736596, 'Total loss': 0.18847622627736596}
2022-12-31 05:29:30,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:30,818 INFO:     Epoch: 24
2022-12-31 05:29:32,459 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42464564740657806, 'Total loss': 0.42464564740657806} | train loss {'Reaction outcome loss': 0.18514092132154739, 'Total loss': 0.18514092132154739}
2022-12-31 05:29:32,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:32,459 INFO:     Epoch: 25
2022-12-31 05:29:34,090 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4389115949471792, 'Total loss': 0.4389115949471792} | train loss {'Reaction outcome loss': 0.18121586972678863, 'Total loss': 0.18121586972678863}
2022-12-31 05:29:34,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:34,090 INFO:     Epoch: 26
2022-12-31 05:29:35,722 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3978790948788325, 'Total loss': 0.3978790948788325} | train loss {'Reaction outcome loss': 0.17769415179044817, 'Total loss': 0.17769415179044817}
2022-12-31 05:29:35,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:35,722 INFO:     Epoch: 27
2022-12-31 05:29:37,353 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41391603847344716, 'Total loss': 0.41391603847344716} | train loss {'Reaction outcome loss': 0.1743353090879163, 'Total loss': 0.1743353090879163}
2022-12-31 05:29:37,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:37,353 INFO:     Epoch: 28
2022-12-31 05:29:38,984 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.408447594443957, 'Total loss': 0.408447594443957} | train loss {'Reaction outcome loss': 0.16980938474535912, 'Total loss': 0.16980938474535912}
2022-12-31 05:29:38,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:38,984 INFO:     Epoch: 29
2022-12-31 05:29:40,648 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.404236243168513, 'Total loss': 0.404236243168513} | train loss {'Reaction outcome loss': 0.16973172938552403, 'Total loss': 0.16973172938552403}
2022-12-31 05:29:40,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:40,650 INFO:     Epoch: 30
2022-12-31 05:29:42,277 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41194092979033786, 'Total loss': 0.41194092979033786} | train loss {'Reaction outcome loss': 0.16806149862996012, 'Total loss': 0.16806149862996012}
2022-12-31 05:29:42,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:42,277 INFO:     Epoch: 31
2022-12-31 05:29:43,939 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4063133681813876, 'Total loss': 0.4063133681813876} | train loss {'Reaction outcome loss': 0.16315401178123295, 'Total loss': 0.16315401178123295}
2022-12-31 05:29:43,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:43,939 INFO:     Epoch: 32
2022-12-31 05:29:45,600 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4040961975852648, 'Total loss': 0.4040961975852648} | train loss {'Reaction outcome loss': 0.16133943111365795, 'Total loss': 0.16133943111365795}
2022-12-31 05:29:45,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:45,600 INFO:     Epoch: 33
2022-12-31 05:29:47,262 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4093164990345637, 'Total loss': 0.4093164990345637} | train loss {'Reaction outcome loss': 0.16005947338619633, 'Total loss': 0.16005947338619633}
2022-12-31 05:29:47,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:47,263 INFO:     Epoch: 34
2022-12-31 05:29:48,881 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40426384458939235, 'Total loss': 0.40426384458939235} | train loss {'Reaction outcome loss': 0.15940367264092725, 'Total loss': 0.15940367264092725}
2022-12-31 05:29:48,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:48,881 INFO:     Epoch: 35
2022-12-31 05:29:50,526 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4583285262187322, 'Total loss': 0.4583285262187322} | train loss {'Reaction outcome loss': 0.1741512260989006, 'Total loss': 0.1741512260989006}
2022-12-31 05:29:50,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:50,526 INFO:     Epoch: 36
2022-12-31 05:29:52,154 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45852325558662416, 'Total loss': 0.45852325558662416} | train loss {'Reaction outcome loss': 0.16149952766768957, 'Total loss': 0.16149952766768957}
2022-12-31 05:29:52,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:52,155 INFO:     Epoch: 37
2022-12-31 05:29:53,783 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4475836127996445, 'Total loss': 0.4475836127996445} | train loss {'Reaction outcome loss': 0.1584514180156914, 'Total loss': 0.1584514180156914}
2022-12-31 05:29:53,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:53,783 INFO:     Epoch: 38
2022-12-31 05:29:55,412 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41812956233819326, 'Total loss': 0.41812956233819326} | train loss {'Reaction outcome loss': 0.14921973434655994, 'Total loss': 0.14921973434655994}
2022-12-31 05:29:55,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:55,412 INFO:     Epoch: 39
2022-12-31 05:29:57,033 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46082332034905754, 'Total loss': 0.46082332034905754} | train loss {'Reaction outcome loss': 0.14363977316416043, 'Total loss': 0.14363977316416043}
2022-12-31 05:29:57,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:57,034 INFO:     Epoch: 40
2022-12-31 05:29:58,664 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4213148484627406, 'Total loss': 0.4213148484627406} | train loss {'Reaction outcome loss': 0.14563021498548367, 'Total loss': 0.14563021498548367}
2022-12-31 05:29:58,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:29:58,665 INFO:     Epoch: 41
2022-12-31 05:30:00,297 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4163498351971308, 'Total loss': 0.4163498351971308} | train loss {'Reaction outcome loss': 0.14375967680530596, 'Total loss': 0.14375967680530596}
2022-12-31 05:30:00,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:00,298 INFO:     Epoch: 42
2022-12-31 05:30:01,931 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44282615979512535, 'Total loss': 0.44282615979512535} | train loss {'Reaction outcome loss': 0.14091492639820807, 'Total loss': 0.14091492639820807}
2022-12-31 05:30:01,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:01,931 INFO:     Epoch: 43
2022-12-31 05:30:03,558 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43289408286412556, 'Total loss': 0.43289408286412556} | train loss {'Reaction outcome loss': 0.1410878107484862, 'Total loss': 0.1410878107484862}
2022-12-31 05:30:03,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:03,558 INFO:     Epoch: 44
2022-12-31 05:30:05,183 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44821829597155255, 'Total loss': 0.44821829597155255} | train loss {'Reaction outcome loss': 0.1412254202107273, 'Total loss': 0.1412254202107273}
2022-12-31 05:30:05,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:05,183 INFO:     Epoch: 45
2022-12-31 05:30:06,799 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42628061523040134, 'Total loss': 0.42628061523040134} | train loss {'Reaction outcome loss': 0.1386860652887465, 'Total loss': 0.1386860652887465}
2022-12-31 05:30:06,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:06,799 INFO:     Epoch: 46
2022-12-31 05:30:08,422 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.424978768825531, 'Total loss': 0.424978768825531} | train loss {'Reaction outcome loss': 0.13756139268187564, 'Total loss': 0.13756139268187564}
2022-12-31 05:30:08,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:08,422 INFO:     Epoch: 47
2022-12-31 05:30:10,044 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4318146347999573, 'Total loss': 0.4318146347999573} | train loss {'Reaction outcome loss': 0.13703754033066734, 'Total loss': 0.13703754033066734}
2022-12-31 05:30:10,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:10,045 INFO:     Epoch: 48
2022-12-31 05:30:11,675 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4447765906651815, 'Total loss': 0.4447765906651815} | train loss {'Reaction outcome loss': 0.135489750644964, 'Total loss': 0.135489750644964}
2022-12-31 05:30:11,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:11,676 INFO:     Epoch: 49
2022-12-31 05:30:13,304 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44207448065280913, 'Total loss': 0.44207448065280913} | train loss {'Reaction outcome loss': 0.1337211065300558, 'Total loss': 0.1337211065300558}
2022-12-31 05:30:13,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:13,304 INFO:     Epoch: 50
2022-12-31 05:30:14,925 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4209088866909345, 'Total loss': 0.4209088866909345} | train loss {'Reaction outcome loss': 0.1343380930298683, 'Total loss': 0.1343380930298683}
2022-12-31 05:30:14,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:14,926 INFO:     Epoch: 51
2022-12-31 05:30:16,584 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4504859616359075, 'Total loss': 0.4504859616359075} | train loss {'Reaction outcome loss': 0.13030325389716882, 'Total loss': 0.13030325389716882}
2022-12-31 05:30:16,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:16,585 INFO:     Epoch: 52
2022-12-31 05:30:18,197 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45838008224964144, 'Total loss': 0.45838008224964144} | train loss {'Reaction outcome loss': 0.13370131174493852, 'Total loss': 0.13370131174493852}
2022-12-31 05:30:18,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:18,198 INFO:     Epoch: 53
2022-12-31 05:30:19,816 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4396292597055435, 'Total loss': 0.4396292597055435} | train loss {'Reaction outcome loss': 0.1323462530761561, 'Total loss': 0.1323462530761561}
2022-12-31 05:30:19,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:19,816 INFO:     Epoch: 54
2022-12-31 05:30:21,436 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.439858349164327, 'Total loss': 0.439858349164327} | train loss {'Reaction outcome loss': 0.12836247997989447, 'Total loss': 0.12836247997989447}
2022-12-31 05:30:21,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:21,437 INFO:     Epoch: 55
2022-12-31 05:30:23,102 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4161225497722626, 'Total loss': 0.4161225497722626} | train loss {'Reaction outcome loss': 0.13292548151946612, 'Total loss': 0.13292548151946612}
2022-12-31 05:30:23,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:23,102 INFO:     Epoch: 56
2022-12-31 05:30:24,740 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39203179677327477, 'Total loss': 0.39203179677327477} | train loss {'Reaction outcome loss': 0.1286074487640914, 'Total loss': 0.1286074487640914}
2022-12-31 05:30:24,741 INFO:     Found new best model at epoch 56
2022-12-31 05:30:24,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:24,742 INFO:     Epoch: 57
2022-12-31 05:30:26,369 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4187597095966339, 'Total loss': 0.4187597095966339} | train loss {'Reaction outcome loss': 0.13366694180117716, 'Total loss': 0.13366694180117716}
2022-12-31 05:30:26,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:26,370 INFO:     Epoch: 58
2022-12-31 05:30:27,990 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40502102573712667, 'Total loss': 0.40502102573712667} | train loss {'Reaction outcome loss': 0.1281939402823269, 'Total loss': 0.1281939402823269}
2022-12-31 05:30:27,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:27,991 INFO:     Epoch: 59
2022-12-31 05:30:29,617 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42081233685215313, 'Total loss': 0.42081233685215313} | train loss {'Reaction outcome loss': 0.12841478789957456, 'Total loss': 0.12841478789957456}
2022-12-31 05:30:29,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:29,617 INFO:     Epoch: 60
2022-12-31 05:30:31,245 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44787966112295785, 'Total loss': 0.44787966112295785} | train loss {'Reaction outcome loss': 0.12689393461176593, 'Total loss': 0.12689393461176593}
2022-12-31 05:30:31,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:31,246 INFO:     Epoch: 61
2022-12-31 05:30:32,871 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4419077272216479, 'Total loss': 0.4419077272216479} | train loss {'Reaction outcome loss': 0.12449927263103587, 'Total loss': 0.12449927263103587}
2022-12-31 05:30:32,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:32,871 INFO:     Epoch: 62
2022-12-31 05:30:34,490 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42215403318405154, 'Total loss': 0.42215403318405154} | train loss {'Reaction outcome loss': 0.1238817909818507, 'Total loss': 0.1238817909818507}
2022-12-31 05:30:34,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:34,491 INFO:     Epoch: 63
2022-12-31 05:30:36,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4317649111151695, 'Total loss': 0.4317649111151695} | train loss {'Reaction outcome loss': 0.12480994509363436, 'Total loss': 0.12480994509363436}
2022-12-31 05:30:36,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:36,114 INFO:     Epoch: 64
2022-12-31 05:30:37,779 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4469665288925171, 'Total loss': 0.4469665288925171} | train loss {'Reaction outcome loss': 0.12507569812832103, 'Total loss': 0.12507569812832103}
2022-12-31 05:30:37,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:37,779 INFO:     Epoch: 65
2022-12-31 05:30:39,454 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4448111335436503, 'Total loss': 0.4448111335436503} | train loss {'Reaction outcome loss': 0.1519164056044774, 'Total loss': 0.1519164056044774}
2022-12-31 05:30:39,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:39,455 INFO:     Epoch: 66
2022-12-31 05:30:41,130 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4404584417740504, 'Total loss': 0.4404584417740504} | train loss {'Reaction outcome loss': 0.16244970960711277, 'Total loss': 0.16244970960711277}
2022-12-31 05:30:41,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:41,130 INFO:     Epoch: 67
2022-12-31 05:30:42,807 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42573565542697905, 'Total loss': 0.42573565542697905} | train loss {'Reaction outcome loss': 0.13401668088551125, 'Total loss': 0.13401668088551125}
2022-12-31 05:30:42,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:42,808 INFO:     Epoch: 68
2022-12-31 05:30:44,484 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.433158877491951, 'Total loss': 0.433158877491951} | train loss {'Reaction outcome loss': 0.1216974231917276, 'Total loss': 0.1216974231917276}
2022-12-31 05:30:44,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:44,484 INFO:     Epoch: 69
2022-12-31 05:30:46,145 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4271265208721161, 'Total loss': 0.4271265208721161} | train loss {'Reaction outcome loss': 0.12143193922982365, 'Total loss': 0.12143193922982365}
2022-12-31 05:30:46,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:46,145 INFO:     Epoch: 70
2022-12-31 05:30:47,828 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42367376387119293, 'Total loss': 0.42367376387119293} | train loss {'Reaction outcome loss': 0.11843856804889451, 'Total loss': 0.11843856804889451}
2022-12-31 05:30:47,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:47,829 INFO:     Epoch: 71
2022-12-31 05:30:49,509 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4278811613718669, 'Total loss': 0.4278811613718669} | train loss {'Reaction outcome loss': 0.11804783688855251, 'Total loss': 0.11804783688855251}
2022-12-31 05:30:49,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:49,509 INFO:     Epoch: 72
2022-12-31 05:30:51,190 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42124135854343575, 'Total loss': 0.42124135854343575} | train loss {'Reaction outcome loss': 0.11665610029071552, 'Total loss': 0.11665610029071552}
2022-12-31 05:30:51,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:51,191 INFO:     Epoch: 73
2022-12-31 05:30:52,877 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4394228349129359, 'Total loss': 0.4394228349129359} | train loss {'Reaction outcome loss': 0.11856451501960796, 'Total loss': 0.11856451501960796}
2022-12-31 05:30:52,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:52,877 INFO:     Epoch: 74
2022-12-31 05:30:54,545 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4280936246116956, 'Total loss': 0.4280936246116956} | train loss {'Reaction outcome loss': 0.11815190618727829, 'Total loss': 0.11815190618727829}
2022-12-31 05:30:54,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:54,546 INFO:     Epoch: 75
2022-12-31 05:30:56,211 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44438443183898924, 'Total loss': 0.44438443183898924} | train loss {'Reaction outcome loss': 0.117593662889018, 'Total loss': 0.117593662889018}
2022-12-31 05:30:56,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:56,211 INFO:     Epoch: 76
2022-12-31 05:30:57,888 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4380919585625331, 'Total loss': 0.4380919585625331} | train loss {'Reaction outcome loss': 0.11859669899058645, 'Total loss': 0.11859669899058645}
2022-12-31 05:30:57,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:57,889 INFO:     Epoch: 77
2022-12-31 05:30:59,568 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43486515482266747, 'Total loss': 0.43486515482266747} | train loss {'Reaction outcome loss': 0.12019138977769256, 'Total loss': 0.12019138977769256}
2022-12-31 05:30:59,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:30:59,568 INFO:     Epoch: 78
2022-12-31 05:31:01,197 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4261243383089701, 'Total loss': 0.4261243383089701} | train loss {'Reaction outcome loss': 0.11988254888084433, 'Total loss': 0.11988254888084433}
2022-12-31 05:31:01,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:01,197 INFO:     Epoch: 79
2022-12-31 05:31:02,820 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4279209554195404, 'Total loss': 0.4279209554195404} | train loss {'Reaction outcome loss': 0.11466172438172245, 'Total loss': 0.11466172438172245}
2022-12-31 05:31:02,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:02,821 INFO:     Epoch: 80
2022-12-31 05:31:04,432 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4639815593759219, 'Total loss': 0.4639815593759219} | train loss {'Reaction outcome loss': 0.11529955967281932, 'Total loss': 0.11529955967281932}
2022-12-31 05:31:04,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:04,432 INFO:     Epoch: 81
2022-12-31 05:31:06,053 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4530323475599289, 'Total loss': 0.4530323475599289} | train loss {'Reaction outcome loss': 0.11808241779595002, 'Total loss': 0.11808241779595002}
2022-12-31 05:31:06,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:06,054 INFO:     Epoch: 82
2022-12-31 05:31:07,675 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44710189998149874, 'Total loss': 0.44710189998149874} | train loss {'Reaction outcome loss': 0.1161910624066587, 'Total loss': 0.1161910624066587}
2022-12-31 05:31:07,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:07,675 INFO:     Epoch: 83
2022-12-31 05:31:09,297 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4483161906401316, 'Total loss': 0.4483161906401316} | train loss {'Reaction outcome loss': 0.11294304415840062, 'Total loss': 0.11294304415840062}
2022-12-31 05:31:09,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:09,297 INFO:     Epoch: 84
2022-12-31 05:31:10,841 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4643007745345434, 'Total loss': 0.4643007745345434} | train loss {'Reaction outcome loss': 0.113903507548958, 'Total loss': 0.113903507548958}
2022-12-31 05:31:10,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:10,841 INFO:     Epoch: 85
2022-12-31 05:31:12,204 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46037427882353466, 'Total loss': 0.46037427882353466} | train loss {'Reaction outcome loss': 0.1196762993932347, 'Total loss': 0.1196762993932347}
2022-12-31 05:31:12,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:12,205 INFO:     Epoch: 86
2022-12-31 05:31:13,591 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43647882441679636, 'Total loss': 0.43647882441679636} | train loss {'Reaction outcome loss': 0.11827458859509046, 'Total loss': 0.11827458859509046}
2022-12-31 05:31:13,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:13,592 INFO:     Epoch: 87
2022-12-31 05:31:14,945 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42373184685905774, 'Total loss': 0.42373184685905774} | train loss {'Reaction outcome loss': 0.11330699182935464, 'Total loss': 0.11330699182935464}
2022-12-31 05:31:14,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:14,945 INFO:     Epoch: 88
2022-12-31 05:31:16,567 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44790046066045763, 'Total loss': 0.44790046066045763} | train loss {'Reaction outcome loss': 0.11392870639953627, 'Total loss': 0.11392870639953627}
2022-12-31 05:31:16,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:16,567 INFO:     Epoch: 89
2022-12-31 05:31:18,184 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44363628725210824, 'Total loss': 0.44363628725210824} | train loss {'Reaction outcome loss': 0.12608896505991943, 'Total loss': 0.12608896505991943}
2022-12-31 05:31:18,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:18,184 INFO:     Epoch: 90
2022-12-31 05:31:19,813 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43951247334480287, 'Total loss': 0.43951247334480287} | train loss {'Reaction outcome loss': 0.14182443176632395, 'Total loss': 0.14182443176632395}
2022-12-31 05:31:19,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:19,813 INFO:     Epoch: 91
2022-12-31 05:31:21,493 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45902093350887296, 'Total loss': 0.45902093350887296} | train loss {'Reaction outcome loss': 0.13027416383746362, 'Total loss': 0.13027416383746362}
2022-12-31 05:31:21,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:21,493 INFO:     Epoch: 92
2022-12-31 05:31:23,207 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4525344838698705, 'Total loss': 0.4525344838698705} | train loss {'Reaction outcome loss': 0.1125853481865741, 'Total loss': 0.1125853481865741}
2022-12-31 05:31:23,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:23,209 INFO:     Epoch: 93
2022-12-31 05:31:24,871 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4237399498621623, 'Total loss': 0.4237399498621623} | train loss {'Reaction outcome loss': 0.12011089193148781, 'Total loss': 0.12011089193148781}
2022-12-31 05:31:24,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:24,872 INFO:     Epoch: 94
2022-12-31 05:31:26,534 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43883829886714615, 'Total loss': 0.43883829886714615} | train loss {'Reaction outcome loss': 0.11225952191607971, 'Total loss': 0.11225952191607971}
2022-12-31 05:31:26,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:26,534 INFO:     Epoch: 95
2022-12-31 05:31:28,235 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48387208382288616, 'Total loss': 0.48387208382288616} | train loss {'Reaction outcome loss': 0.11400539294539856, 'Total loss': 0.11400539294539856}
2022-12-31 05:31:28,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:28,235 INFO:     Epoch: 96
2022-12-31 05:31:29,858 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43031968275705973, 'Total loss': 0.43031968275705973} | train loss {'Reaction outcome loss': 0.12791114203097043, 'Total loss': 0.12791114203097043}
2022-12-31 05:31:29,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:29,859 INFO:     Epoch: 97
2022-12-31 05:31:31,478 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.459404023985068, 'Total loss': 0.459404023985068} | train loss {'Reaction outcome loss': 0.10895415854748285, 'Total loss': 0.10895415854748285}
2022-12-31 05:31:31,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:31,479 INFO:     Epoch: 98
2022-12-31 05:31:33,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48177609145641326, 'Total loss': 0.48177609145641326} | train loss {'Reaction outcome loss': 0.10889420776115055, 'Total loss': 0.10889420776115055}
2022-12-31 05:31:33,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:33,096 INFO:     Epoch: 99
2022-12-31 05:31:34,714 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4579707702000936, 'Total loss': 0.4579707702000936} | train loss {'Reaction outcome loss': 0.10551229848449335, 'Total loss': 0.10551229848449335}
2022-12-31 05:31:34,715 INFO:     Best model found after epoch 57 of 100.
2022-12-31 05:31:34,715 INFO:   Done with stage: TRAINING
2022-12-31 05:31:34,715 INFO:   Starting stage: EVALUATION
2022-12-31 05:31:34,844 INFO:   Done with stage: EVALUATION
2022-12-31 05:31:34,844 INFO:   Leaving out SEQ value Fold_2
2022-12-31 05:31:34,857 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 05:31:34,857 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:31:35,499 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:31:35,499 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:31:35,569 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:31:35,569 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:31:35,569 INFO:     No hyperparam tuning for this model
2022-12-31 05:31:35,569 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:31:35,569 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:31:35,570 INFO:     None feature selector for col prot
2022-12-31 05:31:35,570 INFO:     None feature selector for col prot
2022-12-31 05:31:35,570 INFO:     None feature selector for col prot
2022-12-31 05:31:35,570 INFO:     None feature selector for col chem
2022-12-31 05:31:35,571 INFO:     None feature selector for col chem
2022-12-31 05:31:35,571 INFO:     None feature selector for col chem
2022-12-31 05:31:35,571 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:31:35,571 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:31:35,572 INFO:     Number of params in model 224011
2022-12-31 05:31:35,576 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:31:35,576 INFO:   Starting stage: TRAINING
2022-12-31 05:31:35,621 INFO:     Val loss before train {'Reaction outcome loss': 1.0576301058133444, 'Total loss': 1.0576301058133444}
2022-12-31 05:31:35,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:35,621 INFO:     Epoch: 0
2022-12-31 05:31:37,216 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6058804670969645, 'Total loss': 0.6058804670969645} | train loss {'Reaction outcome loss': 0.7590017454091446, 'Total loss': 0.7590017454091446}
2022-12-31 05:31:37,216 INFO:     Found new best model at epoch 0
2022-12-31 05:31:37,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:37,217 INFO:     Epoch: 1
2022-12-31 05:31:38,813 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5195435623327891, 'Total loss': 0.5195435623327891} | train loss {'Reaction outcome loss': 0.5082562111127071, 'Total loss': 0.5082562111127071}
2022-12-31 05:31:38,813 INFO:     Found new best model at epoch 1
2022-12-31 05:31:38,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:38,814 INFO:     Epoch: 2
2022-12-31 05:31:40,443 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48621567686398826, 'Total loss': 0.48621567686398826} | train loss {'Reaction outcome loss': 0.44492897323090513, 'Total loss': 0.44492897323090513}
2022-12-31 05:31:40,443 INFO:     Found new best model at epoch 2
2022-12-31 05:31:40,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:40,444 INFO:     Epoch: 3
2022-12-31 05:31:42,043 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48134762843449913, 'Total loss': 0.48134762843449913} | train loss {'Reaction outcome loss': 0.40403499470634774, 'Total loss': 0.40403499470634774}
2022-12-31 05:31:42,043 INFO:     Found new best model at epoch 3
2022-12-31 05:31:42,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:42,044 INFO:     Epoch: 4
2022-12-31 05:31:43,646 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49156478643417356, 'Total loss': 0.49156478643417356} | train loss {'Reaction outcome loss': 0.3774051592572705, 'Total loss': 0.3774051592572705}
2022-12-31 05:31:43,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:43,646 INFO:     Epoch: 5
2022-12-31 05:31:45,288 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4479513774315516, 'Total loss': 0.4479513774315516} | train loss {'Reaction outcome loss': 0.356642433711679, 'Total loss': 0.356642433711679}
2022-12-31 05:31:45,288 INFO:     Found new best model at epoch 5
2022-12-31 05:31:45,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:45,289 INFO:     Epoch: 6
2022-12-31 05:31:46,912 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45842845539251964, 'Total loss': 0.45842845539251964} | train loss {'Reaction outcome loss': 0.3371304133872846, 'Total loss': 0.3371304133872846}
2022-12-31 05:31:46,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:46,912 INFO:     Epoch: 7
2022-12-31 05:31:48,517 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4375792900721232, 'Total loss': 0.4375792900721232} | train loss {'Reaction outcome loss': 0.31596251200516146, 'Total loss': 0.31596251200516146}
2022-12-31 05:31:48,517 INFO:     Found new best model at epoch 7
2022-12-31 05:31:48,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:48,518 INFO:     Epoch: 8
2022-12-31 05:31:50,120 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44884150226910907, 'Total loss': 0.44884150226910907} | train loss {'Reaction outcome loss': 0.30114116369586286, 'Total loss': 0.30114116369586286}
2022-12-31 05:31:50,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:50,120 INFO:     Epoch: 9
2022-12-31 05:31:51,752 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.452743994196256, 'Total loss': 0.452743994196256} | train loss {'Reaction outcome loss': 0.2864558188033191, 'Total loss': 0.2864558188033191}
2022-12-31 05:31:51,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:51,753 INFO:     Epoch: 10
2022-12-31 05:31:53,352 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44894219040870664, 'Total loss': 0.44894219040870664} | train loss {'Reaction outcome loss': 0.2735844360384749, 'Total loss': 0.2735844360384749}
2022-12-31 05:31:53,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:53,354 INFO:     Epoch: 11
2022-12-31 05:31:55,003 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4390694697697957, 'Total loss': 0.4390694697697957} | train loss {'Reaction outcome loss': 0.2641483906711087, 'Total loss': 0.2641483906711087}
2022-12-31 05:31:55,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:55,003 INFO:     Epoch: 12
2022-12-31 05:31:56,596 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4639318972826004, 'Total loss': 0.4639318972826004} | train loss {'Reaction outcome loss': 0.25356302967110833, 'Total loss': 0.25356302967110833}
2022-12-31 05:31:56,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:56,597 INFO:     Epoch: 13
2022-12-31 05:31:58,207 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45086136932174364, 'Total loss': 0.45086136932174364} | train loss {'Reaction outcome loss': 0.24523936860236056, 'Total loss': 0.24523936860236056}
2022-12-31 05:31:58,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:58,207 INFO:     Epoch: 14
2022-12-31 05:31:59,817 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45756867627302805, 'Total loss': 0.45756867627302805} | train loss {'Reaction outcome loss': 0.24275261443449464, 'Total loss': 0.24275261443449464}
2022-12-31 05:31:59,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:31:59,818 INFO:     Epoch: 15
2022-12-31 05:32:01,417 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4755216916402181, 'Total loss': 0.4755216916402181} | train loss {'Reaction outcome loss': 0.23178691796330742, 'Total loss': 0.23178691796330742}
2022-12-31 05:32:01,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:01,418 INFO:     Epoch: 16
2022-12-31 05:32:03,022 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4436316212018331, 'Total loss': 0.4436316212018331} | train loss {'Reaction outcome loss': 0.22282335995747657, 'Total loss': 0.22282335995747657}
2022-12-31 05:32:03,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:03,023 INFO:     Epoch: 17
2022-12-31 05:32:04,628 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45037695169448855, 'Total loss': 0.45037695169448855} | train loss {'Reaction outcome loss': 0.22015852506030284, 'Total loss': 0.22015852506030284}
2022-12-31 05:32:04,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:04,628 INFO:     Epoch: 18
2022-12-31 05:32:06,269 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47026742895444235, 'Total loss': 0.47026742895444235} | train loss {'Reaction outcome loss': 0.21146413268378147, 'Total loss': 0.21146413268378147}
2022-12-31 05:32:06,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:06,269 INFO:     Epoch: 19
2022-12-31 05:32:07,861 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4883481760819753, 'Total loss': 0.4883481760819753} | train loss {'Reaction outcome loss': 0.21073472880563893, 'Total loss': 0.21073472880563893}
2022-12-31 05:32:07,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:07,861 INFO:     Epoch: 20
2022-12-31 05:32:09,468 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46595378667116166, 'Total loss': 0.46595378667116166} | train loss {'Reaction outcome loss': 0.20571534880078757, 'Total loss': 0.20571534880078757}
2022-12-31 05:32:09,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:09,468 INFO:     Epoch: 21
2022-12-31 05:32:11,074 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4551311502854029, 'Total loss': 0.4551311502854029} | train loss {'Reaction outcome loss': 0.20017437367348662, 'Total loss': 0.20017437367348662}
2022-12-31 05:32:11,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:11,074 INFO:     Epoch: 22
2022-12-31 05:32:12,675 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47611568371454877, 'Total loss': 0.47611568371454877} | train loss {'Reaction outcome loss': 0.1949964699040307, 'Total loss': 0.1949964699040307}
2022-12-31 05:32:12,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:12,676 INFO:     Epoch: 23
2022-12-31 05:32:14,277 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48621804316838585, 'Total loss': 0.48621804316838585} | train loss {'Reaction outcome loss': 0.19157681156345557, 'Total loss': 0.19157681156345557}
2022-12-31 05:32:14,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:14,277 INFO:     Epoch: 24
2022-12-31 05:32:15,933 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5134597539901733, 'Total loss': 0.5134597539901733} | train loss {'Reaction outcome loss': 0.190662264250792, 'Total loss': 0.190662264250792}
2022-12-31 05:32:15,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:15,933 INFO:     Epoch: 25
2022-12-31 05:32:17,531 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48687565128008525, 'Total loss': 0.48687565128008525} | train loss {'Reaction outcome loss': 0.18673107971611258, 'Total loss': 0.18673107971611258}
2022-12-31 05:32:17,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:17,531 INFO:     Epoch: 26
2022-12-31 05:32:19,133 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5099922468264898, 'Total loss': 0.5099922468264898} | train loss {'Reaction outcome loss': 0.1805072446957558, 'Total loss': 0.1805072446957558}
2022-12-31 05:32:19,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:19,133 INFO:     Epoch: 27
2022-12-31 05:32:20,732 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4994334101676941, 'Total loss': 0.4994334101676941} | train loss {'Reaction outcome loss': 0.17658621222872437, 'Total loss': 0.17658621222872437}
2022-12-31 05:32:20,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:20,732 INFO:     Epoch: 28
2022-12-31 05:32:22,424 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5180194795131683, 'Total loss': 0.5180194795131683} | train loss {'Reaction outcome loss': 0.17745137836224648, 'Total loss': 0.17745137836224648}
2022-12-31 05:32:22,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:22,424 INFO:     Epoch: 29
2022-12-31 05:32:24,020 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5178960382938385, 'Total loss': 0.5178960382938385} | train loss {'Reaction outcome loss': 0.17174414391228554, 'Total loss': 0.17174414391228554}
2022-12-31 05:32:24,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:24,021 INFO:     Epoch: 30
2022-12-31 05:32:25,617 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5079590764517585, 'Total loss': 0.5079590764517585} | train loss {'Reaction outcome loss': 0.1691010196321395, 'Total loss': 0.1691010196321395}
2022-12-31 05:32:25,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:25,618 INFO:     Epoch: 31
2022-12-31 05:32:27,310 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5226883093516032, 'Total loss': 0.5226883093516032} | train loss {'Reaction outcome loss': 0.17296072855018652, 'Total loss': 0.17296072855018652}
2022-12-31 05:32:27,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:27,311 INFO:     Epoch: 32
2022-12-31 05:32:28,911 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5184788157542547, 'Total loss': 0.5184788157542547} | train loss {'Reaction outcome loss': 0.1650851374771787, 'Total loss': 0.1650851374771787}
2022-12-31 05:32:28,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:28,911 INFO:     Epoch: 33
2022-12-31 05:32:30,513 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5420986076196035, 'Total loss': 0.5420986076196035} | train loss {'Reaction outcome loss': 0.16211435413022182, 'Total loss': 0.16211435413022182}
2022-12-31 05:32:30,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:30,514 INFO:     Epoch: 34
2022-12-31 05:32:32,115 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5037267724672954, 'Total loss': 0.5037267724672954} | train loss {'Reaction outcome loss': 0.15897361426818912, 'Total loss': 0.15897361426818912}
2022-12-31 05:32:32,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:32,116 INFO:     Epoch: 35
2022-12-31 05:32:33,809 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4955725222826004, 'Total loss': 0.4955725222826004} | train loss {'Reaction outcome loss': 0.15549599324845992, 'Total loss': 0.15549599324845992}
2022-12-31 05:32:33,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:33,809 INFO:     Epoch: 36
2022-12-31 05:32:35,407 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4975092202425003, 'Total loss': 0.4975092202425003} | train loss {'Reaction outcome loss': 0.1564543631316705, 'Total loss': 0.1564543631316705}
2022-12-31 05:32:35,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:35,408 INFO:     Epoch: 37
2022-12-31 05:32:37,060 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5018234550952911, 'Total loss': 0.5018234550952911} | train loss {'Reaction outcome loss': 0.15598743823749242, 'Total loss': 0.15598743823749242}
2022-12-31 05:32:37,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:37,060 INFO:     Epoch: 38
2022-12-31 05:32:38,667 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.531873032450676, 'Total loss': 0.531873032450676} | train loss {'Reaction outcome loss': 0.15002802798640488, 'Total loss': 0.15002802798640488}
2022-12-31 05:32:38,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:38,667 INFO:     Epoch: 39
2022-12-31 05:32:40,309 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49578856527805326, 'Total loss': 0.49578856527805326} | train loss {'Reaction outcome loss': 0.15127665998120776, 'Total loss': 0.15127665998120776}
2022-12-31 05:32:40,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:40,309 INFO:     Epoch: 40
2022-12-31 05:32:41,951 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5170472423235576, 'Total loss': 0.5170472423235576} | train loss {'Reaction outcome loss': 0.1491647013923624, 'Total loss': 0.1491647013923624}
2022-12-31 05:32:41,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:41,951 INFO:     Epoch: 41
2022-12-31 05:32:43,544 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5323482245206833, 'Total loss': 0.5323482245206833} | train loss {'Reaction outcome loss': 0.15147728958736845, 'Total loss': 0.15147728958736845}
2022-12-31 05:32:43,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:43,545 INFO:     Epoch: 42
2022-12-31 05:32:45,150 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5450184543927511, 'Total loss': 0.5450184543927511} | train loss {'Reaction outcome loss': 0.14963276973233008, 'Total loss': 0.14963276973233008}
2022-12-31 05:32:45,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:45,150 INFO:     Epoch: 43
2022-12-31 05:32:46,744 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.528520675500234, 'Total loss': 0.528520675500234} | train loss {'Reaction outcome loss': 0.14548345345785438, 'Total loss': 0.14548345345785438}
2022-12-31 05:32:46,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:46,744 INFO:     Epoch: 44
2022-12-31 05:32:48,334 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47102207529048123, 'Total loss': 0.47102207529048123} | train loss {'Reaction outcome loss': 0.1435267442032258, 'Total loss': 0.1435267442032258}
2022-12-31 05:32:48,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:48,334 INFO:     Epoch: 45
2022-12-31 05:32:49,924 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5159943640232086, 'Total loss': 0.5159943640232086} | train loss {'Reaction outcome loss': 0.1423984910105611, 'Total loss': 0.1423984910105611}
2022-12-31 05:32:49,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:49,924 INFO:     Epoch: 46
2022-12-31 05:32:51,511 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5230238993962606, 'Total loss': 0.5230238993962606} | train loss {'Reaction outcome loss': 0.13691266195596138, 'Total loss': 0.13691266195596138}
2022-12-31 05:32:51,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:51,512 INFO:     Epoch: 47
2022-12-31 05:32:53,097 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5516181617975235, 'Total loss': 0.5516181617975235} | train loss {'Reaction outcome loss': 0.14023996748357684, 'Total loss': 0.14023996748357684}
2022-12-31 05:32:53,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:53,097 INFO:     Epoch: 48
2022-12-31 05:32:54,686 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5139479572574298, 'Total loss': 0.5139479572574298} | train loss {'Reaction outcome loss': 0.13629448529667196, 'Total loss': 0.13629448529667196}
2022-12-31 05:32:54,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:54,687 INFO:     Epoch: 49
2022-12-31 05:32:56,279 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5139026155074438, 'Total loss': 0.5139026155074438} | train loss {'Reaction outcome loss': 0.13610941884977804, 'Total loss': 0.13610941884977804}
2022-12-31 05:32:56,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:56,280 INFO:     Epoch: 50
2022-12-31 05:32:57,869 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5224882811307907, 'Total loss': 0.5224882811307907} | train loss {'Reaction outcome loss': 0.1317574102064806, 'Total loss': 0.1317574102064806}
2022-12-31 05:32:57,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:57,870 INFO:     Epoch: 51
2022-12-31 05:32:59,462 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5259526669979095, 'Total loss': 0.5259526669979095} | train loss {'Reaction outcome loss': 0.13388337879595194, 'Total loss': 0.13388337879595194}
2022-12-31 05:32:59,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:32:59,462 INFO:     Epoch: 52
2022-12-31 05:33:01,101 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5301602343718211, 'Total loss': 0.5301602343718211} | train loss {'Reaction outcome loss': 0.13457654441635197, 'Total loss': 0.13457654441635197}
2022-12-31 05:33:01,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:01,102 INFO:     Epoch: 53
2022-12-31 05:33:02,701 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5660768826802571, 'Total loss': 0.5660768826802571} | train loss {'Reaction outcome loss': 0.13055171245101826, 'Total loss': 0.13055171245101826}
2022-12-31 05:33:02,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:02,702 INFO:     Epoch: 54
2022-12-31 05:33:04,328 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5557768017053604, 'Total loss': 0.5557768017053604} | train loss {'Reaction outcome loss': 0.13399526385262936, 'Total loss': 0.13399526385262936}
2022-12-31 05:33:04,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:04,328 INFO:     Epoch: 55
2022-12-31 05:33:05,927 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5459117154280345, 'Total loss': 0.5459117154280345} | train loss {'Reaction outcome loss': 0.12784292192740754, 'Total loss': 0.12784292192740754}
2022-12-31 05:33:05,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:05,927 INFO:     Epoch: 56
2022-12-31 05:33:07,528 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5659298141797383, 'Total loss': 0.5659298141797383} | train loss {'Reaction outcome loss': 0.12858046693283887, 'Total loss': 0.12858046693283887}
2022-12-31 05:33:07,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:07,528 INFO:     Epoch: 57
2022-12-31 05:33:09,173 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.516872567186753, 'Total loss': 0.516872567186753} | train loss {'Reaction outcome loss': 0.12645695764817053, 'Total loss': 0.12645695764817053}
2022-12-31 05:33:09,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:09,173 INFO:     Epoch: 58
2022-12-31 05:33:10,776 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5313460489114126, 'Total loss': 0.5313460489114126} | train loss {'Reaction outcome loss': 0.12422358544693489, 'Total loss': 0.12422358544693489}
2022-12-31 05:33:10,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:10,776 INFO:     Epoch: 59
2022-12-31 05:33:12,421 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5175498058398564, 'Total loss': 0.5175498058398564} | train loss {'Reaction outcome loss': 0.1265309877559754, 'Total loss': 0.1265309877559754}
2022-12-31 05:33:12,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:12,421 INFO:     Epoch: 60
2022-12-31 05:33:14,009 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5613485078016917, 'Total loss': 0.5613485078016917} | train loss {'Reaction outcome loss': 0.12478666875111417, 'Total loss': 0.12478666875111417}
2022-12-31 05:33:14,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:14,010 INFO:     Epoch: 61
2022-12-31 05:33:15,607 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5285146991411845, 'Total loss': 0.5285146991411845} | train loss {'Reaction outcome loss': 0.12351849789120557, 'Total loss': 0.12351849789120557}
2022-12-31 05:33:15,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:15,608 INFO:     Epoch: 62
2022-12-31 05:33:17,255 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5231368124485016, 'Total loss': 0.5231368124485016} | train loss {'Reaction outcome loss': 0.12707881360475123, 'Total loss': 0.12707881360475123}
2022-12-31 05:33:17,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:17,255 INFO:     Epoch: 63
2022-12-31 05:33:18,855 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5264240423838298, 'Total loss': 0.5264240423838298} | train loss {'Reaction outcome loss': 0.1234542870119678, 'Total loss': 0.1234542870119678}
2022-12-31 05:33:18,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:18,855 INFO:     Epoch: 64
2022-12-31 05:33:20,488 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5904636085033417, 'Total loss': 0.5904636085033417} | train loss {'Reaction outcome loss': 0.12573353107677493, 'Total loss': 0.12573353107677493}
2022-12-31 05:33:20,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:20,489 INFO:     Epoch: 65
2022-12-31 05:33:22,090 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5526896576086681, 'Total loss': 0.5526896576086681} | train loss {'Reaction outcome loss': 0.12099140672944486, 'Total loss': 0.12099140672944486}
2022-12-31 05:33:22,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:22,090 INFO:     Epoch: 66
2022-12-31 05:33:23,725 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5176574001709621, 'Total loss': 0.5176574001709621} | train loss {'Reaction outcome loss': 0.12103882836154065, 'Total loss': 0.12103882836154065}
2022-12-31 05:33:23,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:23,726 INFO:     Epoch: 67
2022-12-31 05:33:25,325 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5073118943721056, 'Total loss': 0.5073118943721056} | train loss {'Reaction outcome loss': 0.12379078004311347, 'Total loss': 0.12379078004311347}
2022-12-31 05:33:25,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:25,327 INFO:     Epoch: 68
2022-12-31 05:33:26,929 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.518549989660581, 'Total loss': 0.518549989660581} | train loss {'Reaction outcome loss': 0.12321847950231161, 'Total loss': 0.12321847950231161}
2022-12-31 05:33:26,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:26,929 INFO:     Epoch: 69
2022-12-31 05:33:28,567 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5177910725275675, 'Total loss': 0.5177910725275675} | train loss {'Reaction outcome loss': 0.12090133576084187, 'Total loss': 0.12090133576084187}
2022-12-31 05:33:28,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:28,567 INFO:     Epoch: 70
2022-12-31 05:33:30,168 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5341490566730499, 'Total loss': 0.5341490566730499} | train loss {'Reaction outcome loss': 0.11604275268881203, 'Total loss': 0.11604275268881203}
2022-12-31 05:33:30,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:30,168 INFO:     Epoch: 71
2022-12-31 05:33:31,796 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5708405882120132, 'Total loss': 0.5708405882120132} | train loss {'Reaction outcome loss': 0.11745618933627566, 'Total loss': 0.11745618933627566}
2022-12-31 05:33:31,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:31,797 INFO:     Epoch: 72
2022-12-31 05:33:33,396 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5445748051007588, 'Total loss': 0.5445748051007588} | train loss {'Reaction outcome loss': 0.12095810402348474, 'Total loss': 0.12095810402348474}
2022-12-31 05:33:33,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:33,396 INFO:     Epoch: 73
2022-12-31 05:33:35,044 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4941767230629921, 'Total loss': 0.4941767230629921} | train loss {'Reaction outcome loss': 0.12306433517465389, 'Total loss': 0.12306433517465389}
2022-12-31 05:33:35,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:35,045 INFO:     Epoch: 74
2022-12-31 05:33:36,693 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5096204370260239, 'Total loss': 0.5096204370260239} | train loss {'Reaction outcome loss': 0.12171756127685472, 'Total loss': 0.12171756127685472}
2022-12-31 05:33:36,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:36,693 INFO:     Epoch: 75
2022-12-31 05:33:38,302 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5277035887042681, 'Total loss': 0.5277035887042681} | train loss {'Reaction outcome loss': 0.122755699925766, 'Total loss': 0.122755699925766}
2022-12-31 05:33:38,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:38,303 INFO:     Epoch: 76
2022-12-31 05:33:39,900 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5354420453310013, 'Total loss': 0.5354420453310013} | train loss {'Reaction outcome loss': 0.11909838566077266, 'Total loss': 0.11909838566077266}
2022-12-31 05:33:39,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:39,900 INFO:     Epoch: 77
2022-12-31 05:33:41,516 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5191011567910512, 'Total loss': 0.5191011567910512} | train loss {'Reaction outcome loss': 0.11878023550490893, 'Total loss': 0.11878023550490893}
2022-12-31 05:33:41,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:41,517 INFO:     Epoch: 78
2022-12-31 05:33:43,125 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5301764170328777, 'Total loss': 0.5301764170328777} | train loss {'Reaction outcome loss': 0.11532608801737809, 'Total loss': 0.11532608801737809}
2022-12-31 05:33:43,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:43,125 INFO:     Epoch: 79
2022-12-31 05:33:44,734 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5189080337683359, 'Total loss': 0.5189080337683359} | train loss {'Reaction outcome loss': 0.11946451356600384, 'Total loss': 0.11946451356600384}
2022-12-31 05:33:44,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:44,735 INFO:     Epoch: 80
2022-12-31 05:33:46,346 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4980920940637589, 'Total loss': 0.4980920940637589} | train loss {'Reaction outcome loss': 0.11793906070060019, 'Total loss': 0.11793906070060019}
2022-12-31 05:33:46,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:46,346 INFO:     Epoch: 81
2022-12-31 05:33:47,933 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5653465449810028, 'Total loss': 0.5653465449810028} | train loss {'Reaction outcome loss': 0.11332598130215273, 'Total loss': 0.11332598130215273}
2022-12-31 05:33:47,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:47,934 INFO:     Epoch: 82
2022-12-31 05:33:49,532 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5401878997683525, 'Total loss': 0.5401878997683525} | train loss {'Reaction outcome loss': 0.11250310540597992, 'Total loss': 0.11250310540597992}
2022-12-31 05:33:49,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:49,533 INFO:     Epoch: 83
2022-12-31 05:33:51,134 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5538641850153605, 'Total loss': 0.5538641850153605} | train loss {'Reaction outcome loss': 0.11432643187993066, 'Total loss': 0.11432643187993066}
2022-12-31 05:33:51,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:51,134 INFO:     Epoch: 84
2022-12-31 05:33:52,781 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4993899354090293, 'Total loss': 0.4993899354090293} | train loss {'Reaction outcome loss': 0.12160697288558761, 'Total loss': 0.12160697288558761}
2022-12-31 05:33:52,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:52,781 INFO:     Epoch: 85
2022-12-31 05:33:54,379 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5365582009156545, 'Total loss': 0.5365582009156545} | train loss {'Reaction outcome loss': 0.11141057826421691, 'Total loss': 0.11141057826421691}
2022-12-31 05:33:54,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:54,380 INFO:     Epoch: 86
2022-12-31 05:33:56,013 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5450742105642955, 'Total loss': 0.5450742105642955} | train loss {'Reaction outcome loss': 0.11636939898283381, 'Total loss': 0.11636939898283381}
2022-12-31 05:33:56,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:56,014 INFO:     Epoch: 87
2022-12-31 05:33:57,609 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5517291560769081, 'Total loss': 0.5517291560769081} | train loss {'Reaction outcome loss': 0.11459194918780591, 'Total loss': 0.11459194918780591}
2022-12-31 05:33:57,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:57,610 INFO:     Epoch: 88
2022-12-31 05:33:59,213 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5402287244796753, 'Total loss': 0.5402287244796753} | train loss {'Reaction outcome loss': 0.11682752019899724, 'Total loss': 0.11682752019899724}
2022-12-31 05:33:59,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:33:59,213 INFO:     Epoch: 89
2022-12-31 05:34:00,861 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5631763900319735, 'Total loss': 0.5631763900319735} | train loss {'Reaction outcome loss': 0.11896060125718078, 'Total loss': 0.11896060125718078}
2022-12-31 05:34:00,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:00,861 INFO:     Epoch: 90
2022-12-31 05:34:02,465 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5365493098894755, 'Total loss': 0.5365493098894755} | train loss {'Reaction outcome loss': 0.10816696603699748, 'Total loss': 0.10816696603699748}
2022-12-31 05:34:02,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:02,466 INFO:     Epoch: 91
2022-12-31 05:34:04,089 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5638539969921113, 'Total loss': 0.5638539969921113} | train loss {'Reaction outcome loss': 0.10878103173716547, 'Total loss': 0.10878103173716547}
2022-12-31 05:34:04,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:04,090 INFO:     Epoch: 92
2022-12-31 05:34:05,696 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5438712656497955, 'Total loss': 0.5438712656497955} | train loss {'Reaction outcome loss': 0.1088410723918619, 'Total loss': 0.1088410723918619}
2022-12-31 05:34:05,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:05,696 INFO:     Epoch: 93
2022-12-31 05:34:07,345 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5375728364568204, 'Total loss': 0.5375728364568204} | train loss {'Reaction outcome loss': 0.10967688002340469, 'Total loss': 0.10967688002340469}
2022-12-31 05:34:07,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:07,345 INFO:     Epoch: 94
2022-12-31 05:34:08,940 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5507849132021269, 'Total loss': 0.5507849132021269} | train loss {'Reaction outcome loss': 0.1065229493092691, 'Total loss': 0.1065229493092691}
2022-12-31 05:34:08,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:08,940 INFO:     Epoch: 95
2022-12-31 05:34:10,588 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5927142302195231, 'Total loss': 0.5927142302195231} | train loss {'Reaction outcome loss': 0.10767926697128012, 'Total loss': 0.10767926697128012}
2022-12-31 05:34:10,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:10,588 INFO:     Epoch: 96
2022-12-31 05:34:12,193 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5779864370822907, 'Total loss': 0.5779864370822907} | train loss {'Reaction outcome loss': 0.11246195680294664, 'Total loss': 0.11246195680294664}
2022-12-31 05:34:12,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:12,194 INFO:     Epoch: 97
2022-12-31 05:34:13,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5980384389559428, 'Total loss': 0.5980384389559428} | train loss {'Reaction outcome loss': 0.10805909241201704, 'Total loss': 0.10805909241201704}
2022-12-31 05:34:13,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:13,843 INFO:     Epoch: 98
2022-12-31 05:34:15,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5638265411059061, 'Total loss': 0.5638265411059061} | train loss {'Reaction outcome loss': 0.11277496714260934, 'Total loss': 0.11277496714260934}
2022-12-31 05:34:15,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:15,439 INFO:     Epoch: 99
2022-12-31 05:34:17,035 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5907362595200538, 'Total loss': 0.5907362595200538} | train loss {'Reaction outcome loss': 0.10929328505838487, 'Total loss': 0.10929328505838487}
2022-12-31 05:34:17,035 INFO:     Best model found after epoch 8 of 100.
2022-12-31 05:34:17,035 INFO:   Done with stage: TRAINING
2022-12-31 05:34:17,035 INFO:   Starting stage: EVALUATION
2022-12-31 05:34:17,176 INFO:   Done with stage: EVALUATION
2022-12-31 05:34:17,176 INFO:   Leaving out SEQ value Fold_3
2022-12-31 05:34:17,189 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:34:17,189 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:34:17,836 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:34:17,837 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:34:17,907 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:34:17,907 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:34:17,907 INFO:     No hyperparam tuning for this model
2022-12-31 05:34:17,907 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:34:17,907 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:34:17,908 INFO:     None feature selector for col prot
2022-12-31 05:34:17,908 INFO:     None feature selector for col prot
2022-12-31 05:34:17,908 INFO:     None feature selector for col prot
2022-12-31 05:34:17,909 INFO:     None feature selector for col chem
2022-12-31 05:34:17,909 INFO:     None feature selector for col chem
2022-12-31 05:34:17,909 INFO:     None feature selector for col chem
2022-12-31 05:34:17,909 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:34:17,909 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:34:17,911 INFO:     Number of params in model 224011
2022-12-31 05:34:17,914 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:34:17,914 INFO:   Starting stage: TRAINING
2022-12-31 05:34:17,960 INFO:     Val loss before train {'Reaction outcome loss': 0.9958834369977315, 'Total loss': 0.9958834369977315}
2022-12-31 05:34:17,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:17,960 INFO:     Epoch: 0
2022-12-31 05:34:19,563 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5630964239438375, 'Total loss': 0.5630964239438375} | train loss {'Reaction outcome loss': 0.7880931010972845, 'Total loss': 0.7880931010972845}
2022-12-31 05:34:19,563 INFO:     Found new best model at epoch 0
2022-12-31 05:34:19,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:19,564 INFO:     Epoch: 1
2022-12-31 05:34:21,168 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4746145874261856, 'Total loss': 0.4746145874261856} | train loss {'Reaction outcome loss': 0.5215523364770152, 'Total loss': 0.5215523364770152}
2022-12-31 05:34:21,169 INFO:     Found new best model at epoch 1
2022-12-31 05:34:21,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:21,170 INFO:     Epoch: 2
2022-12-31 05:34:22,773 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45902383625507354, 'Total loss': 0.45902383625507354} | train loss {'Reaction outcome loss': 0.4548199648295876, 'Total loss': 0.4548199648295876}
2022-12-31 05:34:22,774 INFO:     Found new best model at epoch 2
2022-12-31 05:34:22,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:22,775 INFO:     Epoch: 3
2022-12-31 05:34:24,389 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.463927306731542, 'Total loss': 0.463927306731542} | train loss {'Reaction outcome loss': 0.4105265058685828, 'Total loss': 0.4105265058685828}
2022-12-31 05:34:24,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:24,389 INFO:     Epoch: 4
2022-12-31 05:34:26,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4717812716960907, 'Total loss': 0.4717812716960907} | train loss {'Reaction outcome loss': 0.37728728451868043, 'Total loss': 0.37728728451868043}
2022-12-31 05:34:26,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:26,001 INFO:     Epoch: 5
2022-12-31 05:34:27,653 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4107796549797058, 'Total loss': 0.4107796549797058} | train loss {'Reaction outcome loss': 0.3532784303555088, 'Total loss': 0.3532784303555088}
2022-12-31 05:34:27,653 INFO:     Found new best model at epoch 5
2022-12-31 05:34:27,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:27,654 INFO:     Epoch: 6
2022-12-31 05:34:29,258 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4193879206975301, 'Total loss': 0.4193879206975301} | train loss {'Reaction outcome loss': 0.33255496735337875, 'Total loss': 0.33255496735337875}
2022-12-31 05:34:29,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:29,258 INFO:     Epoch: 7
2022-12-31 05:34:30,867 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44429150025049846, 'Total loss': 0.44429150025049846} | train loss {'Reaction outcome loss': 0.3169058651058343, 'Total loss': 0.3169058651058343}
2022-12-31 05:34:30,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:30,867 INFO:     Epoch: 8
2022-12-31 05:34:32,500 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40913512110710143, 'Total loss': 0.40913512110710143} | train loss {'Reaction outcome loss': 0.3009289253339933, 'Total loss': 0.3009289253339933}
2022-12-31 05:34:32,501 INFO:     Found new best model at epoch 8
2022-12-31 05:34:32,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:32,502 INFO:     Epoch: 9
2022-12-31 05:34:34,119 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43513749639193217, 'Total loss': 0.43513749639193217} | train loss {'Reaction outcome loss': 0.2862660267872967, 'Total loss': 0.2862660267872967}
2022-12-31 05:34:34,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:34,119 INFO:     Epoch: 10
2022-12-31 05:34:35,732 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4208911736806234, 'Total loss': 0.4208911736806234} | train loss {'Reaction outcome loss': 0.27460954486508005, 'Total loss': 0.27460954486508005}
2022-12-31 05:34:35,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:35,732 INFO:     Epoch: 11
2022-12-31 05:34:37,351 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4750143895546595, 'Total loss': 0.4750143895546595} | train loss {'Reaction outcome loss': 0.26097695386703434, 'Total loss': 0.26097695386703434}
2022-12-31 05:34:37,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:37,352 INFO:     Epoch: 12
2022-12-31 05:34:38,973 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41326550344626106, 'Total loss': 0.41326550344626106} | train loss {'Reaction outcome loss': 0.25452089342322665, 'Total loss': 0.25452089342322665}
2022-12-31 05:34:38,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:38,974 INFO:     Epoch: 13
2022-12-31 05:34:40,619 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43244925439357756, 'Total loss': 0.43244925439357756} | train loss {'Reaction outcome loss': 0.24278898401199467, 'Total loss': 0.24278898401199467}
2022-12-31 05:34:40,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:40,619 INFO:     Epoch: 14
2022-12-31 05:34:42,236 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4078929682572683, 'Total loss': 0.4078929682572683} | train loss {'Reaction outcome loss': 0.23618900823495248, 'Total loss': 0.23618900823495248}
2022-12-31 05:34:42,236 INFO:     Found new best model at epoch 14
2022-12-31 05:34:42,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:42,237 INFO:     Epoch: 15
2022-12-31 05:34:43,855 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4406850695610046, 'Total loss': 0.4406850695610046} | train loss {'Reaction outcome loss': 0.2244290738998756, 'Total loss': 0.2244290738998756}
2022-12-31 05:34:43,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:43,856 INFO:     Epoch: 16
2022-12-31 05:34:45,490 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4160484860340754, 'Total loss': 0.4160484860340754} | train loss {'Reaction outcome loss': 0.220472203322897, 'Total loss': 0.220472203322897}
2022-12-31 05:34:45,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:45,491 INFO:     Epoch: 17
2022-12-31 05:34:47,098 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4237970958153407, 'Total loss': 0.4237970958153407} | train loss {'Reaction outcome loss': 0.21366680910416547, 'Total loss': 0.21366680910416547}
2022-12-31 05:34:47,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:47,098 INFO:     Epoch: 18
2022-12-31 05:34:48,748 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4192644596099854, 'Total loss': 0.4192644596099854} | train loss {'Reaction outcome loss': 0.2088324639157657, 'Total loss': 0.2088324639157657}
2022-12-31 05:34:48,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:48,748 INFO:     Epoch: 19
2022-12-31 05:34:50,385 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4115628699461619, 'Total loss': 0.4115628699461619} | train loss {'Reaction outcome loss': 0.20255464554703148, 'Total loss': 0.20255464554703148}
2022-12-31 05:34:50,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:50,385 INFO:     Epoch: 20
2022-12-31 05:34:51,989 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.410190216700236, 'Total loss': 0.410190216700236} | train loss {'Reaction outcome loss': 0.1989527484606, 'Total loss': 0.1989527484606}
2022-12-31 05:34:51,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:51,990 INFO:     Epoch: 21
2022-12-31 05:34:53,595 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41455599168936413, 'Total loss': 0.41455599168936413} | train loss {'Reaction outcome loss': 0.19216072293555866, 'Total loss': 0.19216072293555866}
2022-12-31 05:34:53,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:53,596 INFO:     Epoch: 22
2022-12-31 05:34:55,227 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4241107354561488, 'Total loss': 0.4241107354561488} | train loss {'Reaction outcome loss': 0.186569783877391, 'Total loss': 0.186569783877391}
2022-12-31 05:34:55,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:55,227 INFO:     Epoch: 23
2022-12-31 05:34:56,845 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.429241015513738, 'Total loss': 0.429241015513738} | train loss {'Reaction outcome loss': 0.18526029362628765, 'Total loss': 0.18526029362628765}
2022-12-31 05:34:56,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:56,845 INFO:     Epoch: 24
2022-12-31 05:34:58,463 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42944800754388174, 'Total loss': 0.42944800754388174} | train loss {'Reaction outcome loss': 0.18147732434372832, 'Total loss': 0.18147732434372832}
2022-12-31 05:34:58,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:34:58,463 INFO:     Epoch: 25
2022-12-31 05:35:00,068 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4153900225957235, 'Total loss': 0.4153900225957235} | train loss {'Reaction outcome loss': 0.17664536542129994, 'Total loss': 0.17664536542129994}
2022-12-31 05:35:00,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:00,068 INFO:     Epoch: 26
2022-12-31 05:35:01,682 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4427183230717977, 'Total loss': 0.4427183230717977} | train loss {'Reaction outcome loss': 0.17656960876073932, 'Total loss': 0.17656960876073932}
2022-12-31 05:35:01,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:01,682 INFO:     Epoch: 27
2022-12-31 05:35:03,281 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4630606750647227, 'Total loss': 0.4630606750647227} | train loss {'Reaction outcome loss': 0.1715443256535452, 'Total loss': 0.1715443256535452}
2022-12-31 05:35:03,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:03,282 INFO:     Epoch: 28
2022-12-31 05:35:04,892 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44477435847123464, 'Total loss': 0.44477435847123464} | train loss {'Reaction outcome loss': 0.17091565760681882, 'Total loss': 0.17091565760681882}
2022-12-31 05:35:04,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:04,892 INFO:     Epoch: 29
2022-12-31 05:35:06,504 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4566144227981567, 'Total loss': 0.4566144227981567} | train loss {'Reaction outcome loss': 0.16527631070573617, 'Total loss': 0.16527631070573617}
2022-12-31 05:35:06,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:06,505 INFO:     Epoch: 30
2022-12-31 05:35:08,116 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4133408839503924, 'Total loss': 0.4133408839503924} | train loss {'Reaction outcome loss': 0.169059531487878, 'Total loss': 0.169059531487878}
2022-12-31 05:35:08,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:08,116 INFO:     Epoch: 31
2022-12-31 05:35:09,719 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4430526206890742, 'Total loss': 0.4430526206890742} | train loss {'Reaction outcome loss': 0.15782628382426978, 'Total loss': 0.15782628382426978}
2022-12-31 05:35:09,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:09,720 INFO:     Epoch: 32
2022-12-31 05:35:11,331 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4366840660572052, 'Total loss': 0.4366840660572052} | train loss {'Reaction outcome loss': 0.15779752645940676, 'Total loss': 0.15779752645940676}
2022-12-31 05:35:11,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:11,331 INFO:     Epoch: 33
2022-12-31 05:35:13,016 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4124023526906967, 'Total loss': 0.4124023526906967} | train loss {'Reaction outcome loss': 0.15808292513332553, 'Total loss': 0.15808292513332553}
2022-12-31 05:35:13,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:13,016 INFO:     Epoch: 34
2022-12-31 05:35:14,704 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4411040018002192, 'Total loss': 0.4411040018002192} | train loss {'Reaction outcome loss': 0.15255940757032457, 'Total loss': 0.15255940757032457}
2022-12-31 05:35:14,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:14,704 INFO:     Epoch: 35
2022-12-31 05:35:16,308 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4335721453030904, 'Total loss': 0.4335721453030904} | train loss {'Reaction outcome loss': 0.1515643321467142, 'Total loss': 0.1515643321467142}
2022-12-31 05:35:16,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:16,308 INFO:     Epoch: 36
2022-12-31 05:35:17,916 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46791011492411294, 'Total loss': 0.46791011492411294} | train loss {'Reaction outcome loss': 0.150164588612851, 'Total loss': 0.150164588612851}
2022-12-31 05:35:17,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:17,917 INFO:     Epoch: 37
2022-12-31 05:35:19,518 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4450504104296366, 'Total loss': 0.4450504104296366} | train loss {'Reaction outcome loss': 0.1512632209358968, 'Total loss': 0.1512632209358968}
2022-12-31 05:35:19,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:19,519 INFO:     Epoch: 38
2022-12-31 05:35:21,127 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42573119526108105, 'Total loss': 0.42573119526108105} | train loss {'Reaction outcome loss': 0.14952310382721634, 'Total loss': 0.14952310382721634}
2022-12-31 05:35:21,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:21,128 INFO:     Epoch: 39
2022-12-31 05:35:22,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42578000432501234, 'Total loss': 0.42578000432501234} | train loss {'Reaction outcome loss': 0.1461479440841307, 'Total loss': 0.1461479440841307}
2022-12-31 05:35:22,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:22,735 INFO:     Epoch: 40
2022-12-31 05:35:24,338 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42868082026640575, 'Total loss': 0.42868082026640575} | train loss {'Reaction outcome loss': 0.14949741331778849, 'Total loss': 0.14949741331778849}
2022-12-31 05:35:24,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:24,338 INFO:     Epoch: 41
2022-12-31 05:35:25,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4356008599201838, 'Total loss': 0.4356008599201838} | train loss {'Reaction outcome loss': 0.14101502903308855, 'Total loss': 0.14101502903308855}
2022-12-31 05:35:25,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:25,944 INFO:     Epoch: 42
2022-12-31 05:35:27,544 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4271937678257624, 'Total loss': 0.4271937678257624} | train loss {'Reaction outcome loss': 0.14140358360579414, 'Total loss': 0.14140358360579414}
2022-12-31 05:35:27,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:27,545 INFO:     Epoch: 43
2022-12-31 05:35:29,151 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4419427742560705, 'Total loss': 0.4419427742560705} | train loss {'Reaction outcome loss': 0.13953382437232964, 'Total loss': 0.13953382437232964}
2022-12-31 05:35:29,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:29,152 INFO:     Epoch: 44
2022-12-31 05:35:30,788 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4590055455764135, 'Total loss': 0.4590055455764135} | train loss {'Reaction outcome loss': 0.13891145254546491, 'Total loss': 0.13891145254546491}
2022-12-31 05:35:30,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:30,788 INFO:     Epoch: 45
2022-12-31 05:35:32,439 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4552290091911952, 'Total loss': 0.4552290091911952} | train loss {'Reaction outcome loss': 0.14011380186535582, 'Total loss': 0.14011380186535582}
2022-12-31 05:35:32,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:32,440 INFO:     Epoch: 46
2022-12-31 05:35:34,090 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42728389203548434, 'Total loss': 0.42728389203548434} | train loss {'Reaction outcome loss': 0.13848901011158515, 'Total loss': 0.13848901011158515}
2022-12-31 05:35:34,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:34,092 INFO:     Epoch: 47
2022-12-31 05:35:35,700 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.448325647910436, 'Total loss': 0.448325647910436} | train loss {'Reaction outcome loss': 0.13499450136356764, 'Total loss': 0.13499450136356764}
2022-12-31 05:35:35,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:35,700 INFO:     Epoch: 48
2022-12-31 05:35:37,307 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41783720006545383, 'Total loss': 0.41783720006545383} | train loss {'Reaction outcome loss': 0.13646966996296805, 'Total loss': 0.13646966996296805}
2022-12-31 05:35:37,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:37,308 INFO:     Epoch: 49
2022-12-31 05:35:38,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43926288882891334, 'Total loss': 0.43926288882891334} | train loss {'Reaction outcome loss': 0.1317490535247799, 'Total loss': 0.1317490535247799}
2022-12-31 05:35:38,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:38,922 INFO:     Epoch: 50
2022-12-31 05:35:40,527 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4586496998866399, 'Total loss': 0.4586496998866399} | train loss {'Reaction outcome loss': 0.132037239101627, 'Total loss': 0.132037239101627}
2022-12-31 05:35:40,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:40,528 INFO:     Epoch: 51
2022-12-31 05:35:42,130 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4646127104759216, 'Total loss': 0.4646127104759216} | train loss {'Reaction outcome loss': 0.1304098928014129, 'Total loss': 0.1304098928014129}
2022-12-31 05:35:42,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:42,130 INFO:     Epoch: 52
2022-12-31 05:35:43,785 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4304011126359304, 'Total loss': 0.4304011126359304} | train loss {'Reaction outcome loss': 0.13089694181307607, 'Total loss': 0.13089694181307607}
2022-12-31 05:35:43,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:43,785 INFO:     Epoch: 53
2022-12-31 05:35:45,401 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4395260542631149, 'Total loss': 0.4395260542631149} | train loss {'Reaction outcome loss': 0.12862200088404718, 'Total loss': 0.12862200088404718}
2022-12-31 05:35:45,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:45,402 INFO:     Epoch: 54
2022-12-31 05:35:47,037 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4557503948609034, 'Total loss': 0.4557503948609034} | train loss {'Reaction outcome loss': 0.13443620555803015, 'Total loss': 0.13443620555803015}
2022-12-31 05:35:47,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:47,038 INFO:     Epoch: 55
2022-12-31 05:35:48,660 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48127211232980094, 'Total loss': 0.48127211232980094} | train loss {'Reaction outcome loss': 0.13044328744060965, 'Total loss': 0.13044328744060965}
2022-12-31 05:35:48,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:48,660 INFO:     Epoch: 56
2022-12-31 05:35:50,272 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4721409519513448, 'Total loss': 0.4721409519513448} | train loss {'Reaction outcome loss': 0.13336024935744759, 'Total loss': 0.13336024935744759}
2022-12-31 05:35:50,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:50,272 INFO:     Epoch: 57
2022-12-31 05:35:51,913 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41716717680295307, 'Total loss': 0.41716717680295307} | train loss {'Reaction outcome loss': 0.13025951614249906, 'Total loss': 0.13025951614249906}
2022-12-31 05:35:51,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:51,913 INFO:     Epoch: 58
2022-12-31 05:35:53,518 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44097935358683266, 'Total loss': 0.44097935358683266} | train loss {'Reaction outcome loss': 0.12562174619732927, 'Total loss': 0.12562174619732927}
2022-12-31 05:35:53,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:53,519 INFO:     Epoch: 59
2022-12-31 05:35:55,157 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4237546920776367, 'Total loss': 0.4237546920776367} | train loss {'Reaction outcome loss': 0.12350459095179002, 'Total loss': 0.12350459095179002}
2022-12-31 05:35:55,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:55,158 INFO:     Epoch: 60
2022-12-31 05:35:56,812 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44644264578819276, 'Total loss': 0.44644264578819276} | train loss {'Reaction outcome loss': 0.12187368050217628, 'Total loss': 0.12187368050217628}
2022-12-31 05:35:56,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:56,812 INFO:     Epoch: 61
2022-12-31 05:35:58,429 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4661580165227254, 'Total loss': 0.4661580165227254} | train loss {'Reaction outcome loss': 0.12925993956040835, 'Total loss': 0.12925993956040835}
2022-12-31 05:35:58,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:35:58,430 INFO:     Epoch: 62
2022-12-31 05:36:00,083 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4727708786725998, 'Total loss': 0.4727708786725998} | train loss {'Reaction outcome loss': 0.12700650890283013, 'Total loss': 0.12700650890283013}
2022-12-31 05:36:00,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:00,083 INFO:     Epoch: 63
2022-12-31 05:36:01,738 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46455777287483213, 'Total loss': 0.46455777287483213} | train loss {'Reaction outcome loss': 0.12700208936253712, 'Total loss': 0.12700208936253712}
2022-12-31 05:36:01,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:01,738 INFO:     Epoch: 64
2022-12-31 05:36:03,360 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43782162566979727, 'Total loss': 0.43782162566979727} | train loss {'Reaction outcome loss': 0.12119611343504848, 'Total loss': 0.12119611343504848}
2022-12-31 05:36:03,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:03,360 INFO:     Epoch: 65
2022-12-31 05:36:05,011 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42272649506727855, 'Total loss': 0.42272649506727855} | train loss {'Reaction outcome loss': 0.12053563919540386, 'Total loss': 0.12053563919540386}
2022-12-31 05:36:05,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:05,012 INFO:     Epoch: 66
2022-12-31 05:36:06,615 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45611162583033243, 'Total loss': 0.45611162583033243} | train loss {'Reaction outcome loss': 0.1227704920724415, 'Total loss': 0.1227704920724415}
2022-12-31 05:36:06,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:06,615 INFO:     Epoch: 67
2022-12-31 05:36:08,270 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4303152511517207, 'Total loss': 0.4303152511517207} | train loss {'Reaction outcome loss': 0.12554614459347985, 'Total loss': 0.12554614459347985}
2022-12-31 05:36:08,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:08,270 INFO:     Epoch: 68
2022-12-31 05:36:09,883 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46564528346061707, 'Total loss': 0.46564528346061707} | train loss {'Reaction outcome loss': 0.12589028700302443, 'Total loss': 0.12589028700302443}
2022-12-31 05:36:09,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:09,884 INFO:     Epoch: 69
2022-12-31 05:36:11,538 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43223440448443096, 'Total loss': 0.43223440448443096} | train loss {'Reaction outcome loss': 0.12372228743195751, 'Total loss': 0.12372228743195751}
2022-12-31 05:36:11,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:11,539 INFO:     Epoch: 70
2022-12-31 05:36:13,164 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4226976245641708, 'Total loss': 0.4226976245641708} | train loss {'Reaction outcome loss': 0.11825635924044806, 'Total loss': 0.11825635924044806}
2022-12-31 05:36:13,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:13,165 INFO:     Epoch: 71
2022-12-31 05:36:14,787 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42840091784795126, 'Total loss': 0.42840091784795126} | train loss {'Reaction outcome loss': 0.11895242201871355, 'Total loss': 0.11895242201871355}
2022-12-31 05:36:14,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:14,788 INFO:     Epoch: 72
2022-12-31 05:36:16,399 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4429815948009491, 'Total loss': 0.4429815948009491} | train loss {'Reaction outcome loss': 0.11701205908490793, 'Total loss': 0.11701205908490793}
2022-12-31 05:36:16,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:16,399 INFO:     Epoch: 73
2022-12-31 05:36:18,019 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45064175029595693, 'Total loss': 0.45064175029595693} | train loss {'Reaction outcome loss': 0.1229817494027738, 'Total loss': 0.1229817494027738}
2022-12-31 05:36:18,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:18,019 INFO:     Epoch: 74
2022-12-31 05:36:19,637 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44777254164218905, 'Total loss': 0.44777254164218905} | train loss {'Reaction outcome loss': 0.11700130586281256, 'Total loss': 0.11700130586281256}
2022-12-31 05:36:19,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:19,637 INFO:     Epoch: 75
2022-12-31 05:36:21,256 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43953111370404563, 'Total loss': 0.43953111370404563} | train loss {'Reaction outcome loss': 0.11787471451871369, 'Total loss': 0.11787471451871369}
2022-12-31 05:36:21,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:21,257 INFO:     Epoch: 76
2022-12-31 05:36:22,493 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4413875311613083, 'Total loss': 0.4413875311613083} | train loss {'Reaction outcome loss': 0.116112512106375, 'Total loss': 0.116112512106375}
2022-12-31 05:36:22,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:22,493 INFO:     Epoch: 77
2022-12-31 05:36:23,595 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4480686992406845, 'Total loss': 0.4480686992406845} | train loss {'Reaction outcome loss': 0.11323752984690079, 'Total loss': 0.11323752984690079}
2022-12-31 05:36:23,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:23,596 INFO:     Epoch: 78
2022-12-31 05:36:24,706 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4584434429804484, 'Total loss': 0.4584434429804484} | train loss {'Reaction outcome loss': 0.11699251277052736, 'Total loss': 0.11699251277052736}
2022-12-31 05:36:24,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:24,706 INFO:     Epoch: 79
2022-12-31 05:36:25,800 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42876030802726744, 'Total loss': 0.42876030802726744} | train loss {'Reaction outcome loss': 0.11767913864748757, 'Total loss': 0.11767913864748757}
2022-12-31 05:36:25,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:25,800 INFO:     Epoch: 80
2022-12-31 05:36:27,226 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49995948920647304, 'Total loss': 0.49995948920647304} | train loss {'Reaction outcome loss': 0.1212065669157318, 'Total loss': 0.1212065669157318}
2022-12-31 05:36:27,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:27,227 INFO:     Epoch: 81
2022-12-31 05:36:28,836 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.440682660539945, 'Total loss': 0.440682660539945} | train loss {'Reaction outcome loss': 0.11826901864022506, 'Total loss': 0.11826901864022506}
2022-12-31 05:36:28,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:28,836 INFO:     Epoch: 82
2022-12-31 05:36:30,447 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4670338938633601, 'Total loss': 0.4670338938633601} | train loss {'Reaction outcome loss': 0.11444658462814715, 'Total loss': 0.11444658462814715}
2022-12-31 05:36:30,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:30,447 INFO:     Epoch: 83
2022-12-31 05:36:32,060 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4813023716211319, 'Total loss': 0.4813023716211319} | train loss {'Reaction outcome loss': 0.11265755478754966, 'Total loss': 0.11265755478754966}
2022-12-31 05:36:32,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:32,060 INFO:     Epoch: 84
2022-12-31 05:36:33,674 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44757136702537537, 'Total loss': 0.44757136702537537} | train loss {'Reaction outcome loss': 0.11261532640927573, 'Total loss': 0.11261532640927573}
2022-12-31 05:36:33,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:33,675 INFO:     Epoch: 85
2022-12-31 05:36:35,284 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45488792657852173, 'Total loss': 0.45488792657852173} | train loss {'Reaction outcome loss': 0.11221697100737288, 'Total loss': 0.11221697100737288}
2022-12-31 05:36:35,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:35,285 INFO:     Epoch: 86
2022-12-31 05:36:36,891 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48528397182623545, 'Total loss': 0.48528397182623545} | train loss {'Reaction outcome loss': 0.11111994795025373, 'Total loss': 0.11111994795025373}
2022-12-31 05:36:36,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:36,891 INFO:     Epoch: 87
2022-12-31 05:36:38,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4578505908449491, 'Total loss': 0.4578505908449491} | train loss {'Reaction outcome loss': 0.12491118094890657, 'Total loss': 0.12491118094890657}
2022-12-31 05:36:38,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:38,506 INFO:     Epoch: 88
2022-12-31 05:36:40,118 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48581209480762483, 'Total loss': 0.48581209480762483} | train loss {'Reaction outcome loss': 0.11832684687386355, 'Total loss': 0.11832684687386355}
2022-12-31 05:36:40,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:40,120 INFO:     Epoch: 89
2022-12-31 05:36:41,729 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4472529485821724, 'Total loss': 0.4472529485821724} | train loss {'Reaction outcome loss': 0.10959414484822293, 'Total loss': 0.10959414484822293}
2022-12-31 05:36:41,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:41,729 INFO:     Epoch: 90
2022-12-31 05:36:43,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4347736269235611, 'Total loss': 0.4347736269235611} | train loss {'Reaction outcome loss': 0.10919206115131667, 'Total loss': 0.10919206115131667}
2022-12-31 05:36:43,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:43,345 INFO:     Epoch: 91
2022-12-31 05:36:44,955 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4541440740227699, 'Total loss': 0.4541440740227699} | train loss {'Reaction outcome loss': 0.11054779483807566, 'Total loss': 0.11054779483807566}
2022-12-31 05:36:44,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:44,955 INFO:     Epoch: 92
2022-12-31 05:36:46,576 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46233809093634287, 'Total loss': 0.46233809093634287} | train loss {'Reaction outcome loss': 0.1133130578796658, 'Total loss': 0.1133130578796658}
2022-12-31 05:36:46,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:46,577 INFO:     Epoch: 93
2022-12-31 05:36:48,196 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44736754496892295, 'Total loss': 0.44736754496892295} | train loss {'Reaction outcome loss': 0.11191836507637462, 'Total loss': 0.11191836507637462}
2022-12-31 05:36:48,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:48,197 INFO:     Epoch: 94
2022-12-31 05:36:49,829 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49593480229377745, 'Total loss': 0.49593480229377745} | train loss {'Reaction outcome loss': 0.1133269425719487, 'Total loss': 0.1133269425719487}
2022-12-31 05:36:49,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:49,829 INFO:     Epoch: 95
2022-12-31 05:36:51,474 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45058286090691885, 'Total loss': 0.45058286090691885} | train loss {'Reaction outcome loss': 0.11240388472041074, 'Total loss': 0.11240388472041074}
2022-12-31 05:36:51,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:51,474 INFO:     Epoch: 96
2022-12-31 05:36:53,128 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.486918838818868, 'Total loss': 0.486918838818868} | train loss {'Reaction outcome loss': 0.10818400115359329, 'Total loss': 0.10818400115359329}
2022-12-31 05:36:53,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:53,128 INFO:     Epoch: 97
2022-12-31 05:36:54,740 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44214181900024413, 'Total loss': 0.44214181900024413} | train loss {'Reaction outcome loss': 0.10618289733427937, 'Total loss': 0.10618289733427937}
2022-12-31 05:36:54,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:54,741 INFO:     Epoch: 98
2022-12-31 05:36:56,394 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45930079420407616, 'Total loss': 0.45930079420407616} | train loss {'Reaction outcome loss': 0.10891372828921099, 'Total loss': 0.10891372828921099}
2022-12-31 05:36:56,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:56,395 INFO:     Epoch: 99
2022-12-31 05:36:58,048 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5181991378466289, 'Total loss': 0.5181991378466289} | train loss {'Reaction outcome loss': 0.10990734615050474, 'Total loss': 0.10990734615050474}
2022-12-31 05:36:58,049 INFO:     Best model found after epoch 15 of 100.
2022-12-31 05:36:58,049 INFO:   Done with stage: TRAINING
2022-12-31 05:36:58,049 INFO:   Starting stage: EVALUATION
2022-12-31 05:36:58,184 INFO:   Done with stage: EVALUATION
2022-12-31 05:36:58,184 INFO:   Leaving out SEQ value Fold_4
2022-12-31 05:36:58,197 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 05:36:58,197 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:36:58,843 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:36:58,843 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:36:58,914 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:36:58,914 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:36:58,914 INFO:     No hyperparam tuning for this model
2022-12-31 05:36:58,914 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:36:58,914 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:36:58,915 INFO:     None feature selector for col prot
2022-12-31 05:36:58,915 INFO:     None feature selector for col prot
2022-12-31 05:36:58,915 INFO:     None feature selector for col prot
2022-12-31 05:36:58,915 INFO:     None feature selector for col chem
2022-12-31 05:36:58,916 INFO:     None feature selector for col chem
2022-12-31 05:36:58,916 INFO:     None feature selector for col chem
2022-12-31 05:36:58,916 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:36:58,916 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:36:58,918 INFO:     Number of params in model 224011
2022-12-31 05:36:58,921 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:36:58,921 INFO:   Starting stage: TRAINING
2022-12-31 05:36:58,968 INFO:     Val loss before train {'Reaction outcome loss': 1.019673470656077, 'Total loss': 1.019673470656077}
2022-12-31 05:36:58,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:36:58,968 INFO:     Epoch: 0
2022-12-31 05:37:00,603 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5290208558241526, 'Total loss': 0.5290208558241526} | train loss {'Reaction outcome loss': 0.7721560092265819, 'Total loss': 0.7721560092265819}
2022-12-31 05:37:00,603 INFO:     Found new best model at epoch 0
2022-12-31 05:37:00,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:00,604 INFO:     Epoch: 1
2022-12-31 05:37:02,231 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45250230431556704, 'Total loss': 0.45250230431556704} | train loss {'Reaction outcome loss': 0.5209485496650788, 'Total loss': 0.5209485496650788}
2022-12-31 05:37:02,232 INFO:     Found new best model at epoch 1
2022-12-31 05:37:02,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:02,233 INFO:     Epoch: 2
2022-12-31 05:37:03,880 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43439013957977296, 'Total loss': 0.43439013957977296} | train loss {'Reaction outcome loss': 0.4536415015753701, 'Total loss': 0.4536415015753701}
2022-12-31 05:37:03,880 INFO:     Found new best model at epoch 2
2022-12-31 05:37:03,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:03,881 INFO:     Epoch: 3
2022-12-31 05:37:05,501 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.38273869653542836, 'Total loss': 0.38273869653542836} | train loss {'Reaction outcome loss': 0.42155277054162993, 'Total loss': 0.42155277054162993}
2022-12-31 05:37:05,501 INFO:     Found new best model at epoch 3
2022-12-31 05:37:05,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:05,502 INFO:     Epoch: 4
2022-12-31 05:37:07,125 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.38348066906134287, 'Total loss': 0.38348066906134287} | train loss {'Reaction outcome loss': 0.3968352766512519, 'Total loss': 0.3968352766512519}
2022-12-31 05:37:07,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:07,125 INFO:     Epoch: 5
2022-12-31 05:37:08,756 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3958962251742681, 'Total loss': 0.3958962251742681} | train loss {'Reaction outcome loss': 0.36777684729600296, 'Total loss': 0.36777684729600296}
2022-12-31 05:37:08,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:08,757 INFO:     Epoch: 6
2022-12-31 05:37:10,421 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3937845547993978, 'Total loss': 0.3937845547993978} | train loss {'Reaction outcome loss': 0.3551893522625492, 'Total loss': 0.3551893522625492}
2022-12-31 05:37:10,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:10,423 INFO:     Epoch: 7
2022-12-31 05:37:12,040 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39229736576477686, 'Total loss': 0.39229736576477686} | train loss {'Reaction outcome loss': 0.3262692653081393, 'Total loss': 0.3262692653081393}
2022-12-31 05:37:12,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:12,041 INFO:     Epoch: 8
2022-12-31 05:37:13,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3879706482092539, 'Total loss': 0.3879706482092539} | train loss {'Reaction outcome loss': 0.31563554493629414, 'Total loss': 0.31563554493629414}
2022-12-31 05:37:13,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:13,672 INFO:     Epoch: 9
2022-12-31 05:37:15,307 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3909187028805415, 'Total loss': 0.3909187028805415} | train loss {'Reaction outcome loss': 0.30544028787509253, 'Total loss': 0.30544028787509253}
2022-12-31 05:37:15,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:15,307 INFO:     Epoch: 10
2022-12-31 05:37:16,940 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3795105775197347, 'Total loss': 0.3795105775197347} | train loss {'Reaction outcome loss': 0.29164968986752565, 'Total loss': 0.29164968986752565}
2022-12-31 05:37:16,941 INFO:     Found new best model at epoch 10
2022-12-31 05:37:16,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:16,942 INFO:     Epoch: 11
2022-12-31 05:37:18,594 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3771157294511795, 'Total loss': 0.3771157294511795} | train loss {'Reaction outcome loss': 0.2754753407823138, 'Total loss': 0.2754753407823138}
2022-12-31 05:37:18,594 INFO:     Found new best model at epoch 11
2022-12-31 05:37:18,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:18,595 INFO:     Epoch: 12
2022-12-31 05:37:20,212 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4011310334006945, 'Total loss': 0.4011310334006945} | train loss {'Reaction outcome loss': 0.2629637550743992, 'Total loss': 0.2629637550743992}
2022-12-31 05:37:20,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:20,212 INFO:     Epoch: 13
2022-12-31 05:37:21,855 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3961720700065295, 'Total loss': 0.3961720700065295} | train loss {'Reaction outcome loss': 0.2529408521106656, 'Total loss': 0.2529408521106656}
2022-12-31 05:37:21,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:21,855 INFO:     Epoch: 14
2022-12-31 05:37:23,520 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3757678975661596, 'Total loss': 0.3757678975661596} | train loss {'Reaction outcome loss': 0.25807139038553706, 'Total loss': 0.25807139038553706}
2022-12-31 05:37:23,520 INFO:     Found new best model at epoch 14
2022-12-31 05:37:23,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:23,521 INFO:     Epoch: 15
2022-12-31 05:37:25,134 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4205547074476878, 'Total loss': 0.4205547074476878} | train loss {'Reaction outcome loss': 0.25362596207586635, 'Total loss': 0.25362596207586635}
2022-12-31 05:37:25,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:25,134 INFO:     Epoch: 16
2022-12-31 05:37:26,778 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37833617329597474, 'Total loss': 0.37833617329597474} | train loss {'Reaction outcome loss': 0.2328979789570545, 'Total loss': 0.2328979789570545}
2022-12-31 05:37:26,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:26,778 INFO:     Epoch: 17
2022-12-31 05:37:28,406 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40763823787371317, 'Total loss': 0.40763823787371317} | train loss {'Reaction outcome loss': 0.2250503013568485, 'Total loss': 0.2250503013568485}
2022-12-31 05:37:28,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:28,406 INFO:     Epoch: 18
2022-12-31 05:37:30,028 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41135973383982977, 'Total loss': 0.41135973383982977} | train loss {'Reaction outcome loss': 0.22149207568187537, 'Total loss': 0.22149207568187537}
2022-12-31 05:37:30,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:30,029 INFO:     Epoch: 19
2022-12-31 05:37:31,659 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41559818983078, 'Total loss': 0.41559818983078} | train loss {'Reaction outcome loss': 0.21449454768942128, 'Total loss': 0.21449454768942128}
2022-12-31 05:37:31,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:31,659 INFO:     Epoch: 20
2022-12-31 05:37:33,327 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4320677826801936, 'Total loss': 0.4320677826801936} | train loss {'Reaction outcome loss': 0.20861773092495411, 'Total loss': 0.20861773092495411}
2022-12-31 05:37:33,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:33,327 INFO:     Epoch: 21
2022-12-31 05:37:34,994 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40069375137488045, 'Total loss': 0.40069375137488045} | train loss {'Reaction outcome loss': 0.20368618327800347, 'Total loss': 0.20368618327800347}
2022-12-31 05:37:34,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:34,994 INFO:     Epoch: 22
2022-12-31 05:37:36,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41835750341415406, 'Total loss': 0.41835750341415406} | train loss {'Reaction outcome loss': 0.2107100417547306, 'Total loss': 0.2107100417547306}
2022-12-31 05:37:36,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:36,615 INFO:     Epoch: 23
2022-12-31 05:37:38,280 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4115904957056046, 'Total loss': 0.4115904957056046} | train loss {'Reaction outcome loss': 0.19449910467517548, 'Total loss': 0.19449910467517548}
2022-12-31 05:37:38,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:38,281 INFO:     Epoch: 24
2022-12-31 05:37:39,933 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3970035195350647, 'Total loss': 0.3970035195350647} | train loss {'Reaction outcome loss': 0.18968482555119673, 'Total loss': 0.18968482555119673}
2022-12-31 05:37:39,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:39,934 INFO:     Epoch: 25
2022-12-31 05:37:41,599 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4201546182235082, 'Total loss': 0.4201546182235082} | train loss {'Reaction outcome loss': 0.1871500389952614, 'Total loss': 0.1871500389952614}
2022-12-31 05:37:41,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:41,600 INFO:     Epoch: 26
2022-12-31 05:37:43,265 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37356824378172554, 'Total loss': 0.37356824378172554} | train loss {'Reaction outcome loss': 0.18308854160705526, 'Total loss': 0.18308854160705526}
2022-12-31 05:37:43,265 INFO:     Found new best model at epoch 26
2022-12-31 05:37:43,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:43,266 INFO:     Epoch: 27
2022-12-31 05:37:44,889 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4274505982796351, 'Total loss': 0.4274505982796351} | train loss {'Reaction outcome loss': 0.1787583063772784, 'Total loss': 0.1787583063772784}
2022-12-31 05:37:44,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:44,889 INFO:     Epoch: 28
2022-12-31 05:37:46,521 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4465507626533508, 'Total loss': 0.4465507626533508} | train loss {'Reaction outcome loss': 0.17811856107415963, 'Total loss': 0.17811856107415963}
2022-12-31 05:37:46,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:46,523 INFO:     Epoch: 29
2022-12-31 05:37:48,151 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4140574519832929, 'Total loss': 0.4140574519832929} | train loss {'Reaction outcome loss': 0.17373579232514821, 'Total loss': 0.17373579232514821}
2022-12-31 05:37:48,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:48,151 INFO:     Epoch: 30
2022-12-31 05:37:49,764 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4048518896102905, 'Total loss': 0.4048518896102905} | train loss {'Reaction outcome loss': 0.17443299547290814, 'Total loss': 0.17443299547290814}
2022-12-31 05:37:49,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:49,764 INFO:     Epoch: 31
2022-12-31 05:37:51,430 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4198091914256414, 'Total loss': 0.4198091914256414} | train loss {'Reaction outcome loss': 0.17020876503881047, 'Total loss': 0.17020876503881047}
2022-12-31 05:37:51,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:51,430 INFO:     Epoch: 32
2022-12-31 05:37:53,070 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43181808590888976, 'Total loss': 0.43181808590888976} | train loss {'Reaction outcome loss': 0.17061649324993292, 'Total loss': 0.17061649324993292}
2022-12-31 05:37:53,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:53,071 INFO:     Epoch: 33
2022-12-31 05:37:54,704 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4318949004014333, 'Total loss': 0.4318949004014333} | train loss {'Reaction outcome loss': 0.16823905687256163, 'Total loss': 0.16823905687256163}
2022-12-31 05:37:54,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:54,705 INFO:     Epoch: 34
2022-12-31 05:37:56,371 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4397221575180689, 'Total loss': 0.4397221575180689} | train loss {'Reaction outcome loss': 0.16688511240889953, 'Total loss': 0.16688511240889953}
2022-12-31 05:37:56,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:56,371 INFO:     Epoch: 35
2022-12-31 05:37:58,024 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4065893863638242, 'Total loss': 0.4065893863638242} | train loss {'Reaction outcome loss': 0.16393696747104844, 'Total loss': 0.16393696747104844}
2022-12-31 05:37:58,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:58,024 INFO:     Epoch: 36
2022-12-31 05:37:59,690 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40687629381815593, 'Total loss': 0.40687629381815593} | train loss {'Reaction outcome loss': 0.1581548413960263, 'Total loss': 0.1581548413960263}
2022-12-31 05:37:59,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:37:59,690 INFO:     Epoch: 37
2022-12-31 05:38:01,355 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4325288385152817, 'Total loss': 0.4325288385152817} | train loss {'Reaction outcome loss': 0.15650735910732191, 'Total loss': 0.15650735910732191}
2022-12-31 05:38:01,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:01,356 INFO:     Epoch: 38
2022-12-31 05:38:03,021 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3847282330195109, 'Total loss': 0.3847282330195109} | train loss {'Reaction outcome loss': 0.15897926607884574, 'Total loss': 0.15897926607884574}
2022-12-31 05:38:03,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:03,021 INFO:     Epoch: 39
2022-12-31 05:38:04,641 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43316484491030377, 'Total loss': 0.43316484491030377} | train loss {'Reaction outcome loss': 0.16845621220578533, 'Total loss': 0.16845621220578533}
2022-12-31 05:38:04,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:04,641 INFO:     Epoch: 40
2022-12-31 05:38:06,309 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4210639933745066, 'Total loss': 0.4210639933745066} | train loss {'Reaction outcome loss': 0.1532632467993687, 'Total loss': 0.1532632467993687}
2022-12-31 05:38:06,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:06,310 INFO:     Epoch: 41
2022-12-31 05:38:07,983 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38399993677934013, 'Total loss': 0.38399993677934013} | train loss {'Reaction outcome loss': 0.1489884834369097, 'Total loss': 0.1489884834369097}
2022-12-31 05:38:07,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:07,983 INFO:     Epoch: 42
2022-12-31 05:38:09,612 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4254348923762639, 'Total loss': 0.4254348923762639} | train loss {'Reaction outcome loss': 0.1471675318857088, 'Total loss': 0.1471675318857088}
2022-12-31 05:38:09,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:09,612 INFO:     Epoch: 43
2022-12-31 05:38:11,244 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4185426250100136, 'Total loss': 0.4185426250100136} | train loss {'Reaction outcome loss': 0.14617196108767952, 'Total loss': 0.14617196108767952}
2022-12-31 05:38:11,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:11,244 INFO:     Epoch: 44
2022-12-31 05:38:12,878 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4315423001845678, 'Total loss': 0.4315423001845678} | train loss {'Reaction outcome loss': 0.14408921376035205, 'Total loss': 0.14408921376035205}
2022-12-31 05:38:12,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:12,878 INFO:     Epoch: 45
2022-12-31 05:38:14,501 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4544683039188385, 'Total loss': 0.4544683039188385} | train loss {'Reaction outcome loss': 0.1461399688348098, 'Total loss': 0.1461399688348098}
2022-12-31 05:38:14,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:14,502 INFO:     Epoch: 46
2022-12-31 05:38:16,124 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46418608725070953, 'Total loss': 0.46418608725070953} | train loss {'Reaction outcome loss': 0.1409435033898605, 'Total loss': 0.1409435033898605}
2022-12-31 05:38:16,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:16,124 INFO:     Epoch: 47
2022-12-31 05:38:17,744 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41398310953130324, 'Total loss': 0.41398310953130324} | train loss {'Reaction outcome loss': 0.1413183639558248, 'Total loss': 0.1413183639558248}
2022-12-31 05:38:17,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:17,745 INFO:     Epoch: 48
2022-12-31 05:38:19,369 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4212629318237305, 'Total loss': 0.4212629318237305} | train loss {'Reaction outcome loss': 0.14071542515581392, 'Total loss': 0.14071542515581392}
2022-12-31 05:38:19,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:19,369 INFO:     Epoch: 49
2022-12-31 05:38:20,993 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42458985447883607, 'Total loss': 0.42458985447883607} | train loss {'Reaction outcome loss': 0.13915148125986732, 'Total loss': 0.13915148125986732}
2022-12-31 05:38:20,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:20,993 INFO:     Epoch: 50
2022-12-31 05:38:22,628 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4111427793900172, 'Total loss': 0.4111427793900172} | train loss {'Reaction outcome loss': 0.13822671946389534, 'Total loss': 0.13822671946389534}
2022-12-31 05:38:22,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:22,628 INFO:     Epoch: 51
2022-12-31 05:38:24,255 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4143688718477885, 'Total loss': 0.4143688718477885} | train loss {'Reaction outcome loss': 0.13529525484604613, 'Total loss': 0.13529525484604613}
2022-12-31 05:38:24,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:24,255 INFO:     Epoch: 52
2022-12-31 05:38:25,873 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4501748293638229, 'Total loss': 0.4501748293638229} | train loss {'Reaction outcome loss': 0.130920413337847, 'Total loss': 0.130920413337847}
2022-12-31 05:38:25,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:25,873 INFO:     Epoch: 53
2022-12-31 05:38:27,501 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4164025296767553, 'Total loss': 0.4164025296767553} | train loss {'Reaction outcome loss': 0.1365072296274762, 'Total loss': 0.1365072296274762}
2022-12-31 05:38:27,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:27,502 INFO:     Epoch: 54
2022-12-31 05:38:29,130 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43061270415782926, 'Total loss': 0.43061270415782926} | train loss {'Reaction outcome loss': 0.1334452740729962, 'Total loss': 0.1334452740729962}
2022-12-31 05:38:29,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:29,130 INFO:     Epoch: 55
2022-12-31 05:38:30,753 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4339942097663879, 'Total loss': 0.4339942097663879} | train loss {'Reaction outcome loss': 0.13332211834452776, 'Total loss': 0.13332211834452776}
2022-12-31 05:38:30,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:30,753 INFO:     Epoch: 56
2022-12-31 05:38:32,421 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41546997527281443, 'Total loss': 0.41546997527281443} | train loss {'Reaction outcome loss': 0.13065094727874343, 'Total loss': 0.13065094727874343}
2022-12-31 05:38:32,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:32,421 INFO:     Epoch: 57
2022-12-31 05:38:34,041 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4184375842412313, 'Total loss': 0.4184375842412313} | train loss {'Reaction outcome loss': 0.13433615448192923, 'Total loss': 0.13433615448192923}
2022-12-31 05:38:34,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:34,041 INFO:     Epoch: 58
2022-12-31 05:38:35,666 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.434278937180837, 'Total loss': 0.434278937180837} | train loss {'Reaction outcome loss': 0.1308432926026939, 'Total loss': 0.1308432926026939}
2022-12-31 05:38:35,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:35,666 INFO:     Epoch: 59
2022-12-31 05:38:37,294 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.416622590025266, 'Total loss': 0.416622590025266} | train loss {'Reaction outcome loss': 0.13015384243972486, 'Total loss': 0.13015384243972486}
2022-12-31 05:38:37,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:37,295 INFO:     Epoch: 60
2022-12-31 05:38:38,922 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4263256072998047, 'Total loss': 0.4263256072998047} | train loss {'Reaction outcome loss': 0.1276342163973427, 'Total loss': 0.1276342163973427}
2022-12-31 05:38:38,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:38,922 INFO:     Epoch: 61
2022-12-31 05:38:40,541 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4293930619955063, 'Total loss': 0.4293930619955063} | train loss {'Reaction outcome loss': 0.13034367702051025, 'Total loss': 0.13034367702051025}
2022-12-31 05:38:40,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:40,541 INFO:     Epoch: 62
2022-12-31 05:38:42,168 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4541244546572367, 'Total loss': 0.4541244546572367} | train loss {'Reaction outcome loss': 0.12635930923225597, 'Total loss': 0.12635930923225597}
2022-12-31 05:38:42,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:42,168 INFO:     Epoch: 63
2022-12-31 05:38:43,802 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44005924661954243, 'Total loss': 0.44005924661954243} | train loss {'Reaction outcome loss': 0.12372030559471688, 'Total loss': 0.12372030559471688}
2022-12-31 05:38:43,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:43,802 INFO:     Epoch: 64
2022-12-31 05:38:45,422 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47401917576789854, 'Total loss': 0.47401917576789854} | train loss {'Reaction outcome loss': 0.13235007740719162, 'Total loss': 0.13235007740719162}
2022-12-31 05:38:45,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:45,422 INFO:     Epoch: 65
2022-12-31 05:38:47,041 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.447946198284626, 'Total loss': 0.447946198284626} | train loss {'Reaction outcome loss': 0.14172425723929494, 'Total loss': 0.14172425723929494}
2022-12-31 05:38:47,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:47,041 INFO:     Epoch: 66
2022-12-31 05:38:48,669 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40360206067562104, 'Total loss': 0.40360206067562104} | train loss {'Reaction outcome loss': 0.12722170719970946, 'Total loss': 0.12722170719970946}
2022-12-31 05:38:48,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:48,671 INFO:     Epoch: 67
2022-12-31 05:38:50,289 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4462785025437673, 'Total loss': 0.4462785025437673} | train loss {'Reaction outcome loss': 0.124206497678181, 'Total loss': 0.124206497678181}
2022-12-31 05:38:50,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:50,289 INFO:     Epoch: 68
2022-12-31 05:38:51,917 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4140294035275777, 'Total loss': 0.4140294035275777} | train loss {'Reaction outcome loss': 0.12327649999265239, 'Total loss': 0.12327649999265239}
2022-12-31 05:38:51,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:51,918 INFO:     Epoch: 69
2022-12-31 05:38:53,538 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4195217967033386, 'Total loss': 0.4195217967033386} | train loss {'Reaction outcome loss': 0.14313416900889328, 'Total loss': 0.14313416900889328}
2022-12-31 05:38:53,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:53,539 INFO:     Epoch: 70
2022-12-31 05:38:55,167 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4505967249472936, 'Total loss': 0.4505967249472936} | train loss {'Reaction outcome loss': 0.12405703146014012, 'Total loss': 0.12405703146014012}
2022-12-31 05:38:55,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:55,168 INFO:     Epoch: 71
2022-12-31 05:38:56,797 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4503625671068827, 'Total loss': 0.4503625671068827} | train loss {'Reaction outcome loss': 0.12075550460418605, 'Total loss': 0.12075550460418605}
2022-12-31 05:38:56,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:56,797 INFO:     Epoch: 72
2022-12-31 05:38:58,418 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44681918919086455, 'Total loss': 0.44681918919086455} | train loss {'Reaction outcome loss': 0.12533333344027345, 'Total loss': 0.12533333344027345}
2022-12-31 05:38:58,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:38:58,419 INFO:     Epoch: 73
2022-12-31 05:39:00,047 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4217132717370987, 'Total loss': 0.4217132717370987} | train loss {'Reaction outcome loss': 0.1227510681854229, 'Total loss': 0.1227510681854229}
2022-12-31 05:39:00,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:00,047 INFO:     Epoch: 74
2022-12-31 05:39:01,668 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4382925113042196, 'Total loss': 0.4382925113042196} | train loss {'Reaction outcome loss': 0.11626775769780026, 'Total loss': 0.11626775769780026}
2022-12-31 05:39:01,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:01,668 INFO:     Epoch: 75
2022-12-31 05:39:03,297 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42789005835851035, 'Total loss': 0.42789005835851035} | train loss {'Reaction outcome loss': 0.11851812814922491, 'Total loss': 0.11851812814922491}
2022-12-31 05:39:03,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:03,297 INFO:     Epoch: 76
2022-12-31 05:39:04,926 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42618027329444885, 'Total loss': 0.42618027329444885} | train loss {'Reaction outcome loss': 0.11867721492350372, 'Total loss': 0.11867721492350372}
2022-12-31 05:39:04,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:04,926 INFO:     Epoch: 77
2022-12-31 05:39:06,556 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4461967652042707, 'Total loss': 0.4461967652042707} | train loss {'Reaction outcome loss': 0.11990220187378683, 'Total loss': 0.11990220187378683}
2022-12-31 05:39:06,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:06,556 INFO:     Epoch: 78
2022-12-31 05:39:08,209 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45465386112531025, 'Total loss': 0.45465386112531025} | train loss {'Reaction outcome loss': 0.13267036790595108, 'Total loss': 0.13267036790595108}
2022-12-31 05:39:08,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:08,210 INFO:     Epoch: 79
2022-12-31 05:39:09,834 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45547451376914977, 'Total loss': 0.45547451376914977} | train loss {'Reaction outcome loss': 0.19035900358310598, 'Total loss': 0.19035900358310598}
2022-12-31 05:39:09,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:09,834 INFO:     Epoch: 80
2022-12-31 05:39:11,469 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45032719473044075, 'Total loss': 0.45032719473044075} | train loss {'Reaction outcome loss': 0.13045135420237575, 'Total loss': 0.13045135420237575}
2022-12-31 05:39:11,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:11,469 INFO:     Epoch: 81
2022-12-31 05:39:13,103 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45877726972103117, 'Total loss': 0.45877726972103117} | train loss {'Reaction outcome loss': 0.11900715831417483, 'Total loss': 0.11900715831417483}
2022-12-31 05:39:13,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:13,104 INFO:     Epoch: 82
2022-12-31 05:39:14,738 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4358353833357493, 'Total loss': 0.4358353833357493} | train loss {'Reaction outcome loss': 0.11855087850995334, 'Total loss': 0.11855087850995334}
2022-12-31 05:39:14,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:14,738 INFO:     Epoch: 83
2022-12-31 05:39:16,364 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4432903915643692, 'Total loss': 0.4432903915643692} | train loss {'Reaction outcome loss': 0.1162759151843668, 'Total loss': 0.1162759151843668}
2022-12-31 05:39:16,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:16,364 INFO:     Epoch: 84
2022-12-31 05:39:18,001 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46524802843729657, 'Total loss': 0.46524802843729657} | train loss {'Reaction outcome loss': 0.116878355493416, 'Total loss': 0.116878355493416}
2022-12-31 05:39:18,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:18,001 INFO:     Epoch: 85
2022-12-31 05:39:19,623 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42918002357085544, 'Total loss': 0.42918002357085544} | train loss {'Reaction outcome loss': 0.11550975598346787, 'Total loss': 0.11550975598346787}
2022-12-31 05:39:19,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:19,623 INFO:     Epoch: 86
2022-12-31 05:39:21,243 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4660840004682541, 'Total loss': 0.4660840004682541} | train loss {'Reaction outcome loss': 0.11897384733795964, 'Total loss': 0.11897384733795964}
2022-12-31 05:39:21,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:21,243 INFO:     Epoch: 87
2022-12-31 05:39:22,909 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47699305017789206, 'Total loss': 0.47699305017789206} | train loss {'Reaction outcome loss': 0.12339116681529128, 'Total loss': 0.12339116681529128}
2022-12-31 05:39:22,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:22,910 INFO:     Epoch: 88
2022-12-31 05:39:24,530 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4715038557847341, 'Total loss': 0.4715038557847341} | train loss {'Reaction outcome loss': 0.12454247817381524, 'Total loss': 0.12454247817381524}
2022-12-31 05:39:24,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:24,531 INFO:     Epoch: 89
2022-12-31 05:39:26,151 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4713239406545957, 'Total loss': 0.4713239406545957} | train loss {'Reaction outcome loss': 0.1176214997488031, 'Total loss': 0.1176214997488031}
2022-12-31 05:39:26,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:26,152 INFO:     Epoch: 90
2022-12-31 05:39:27,785 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4405452030400435, 'Total loss': 0.4405452030400435} | train loss {'Reaction outcome loss': 0.11047815207047793, 'Total loss': 0.11047815207047793}
2022-12-31 05:39:27,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:27,785 INFO:     Epoch: 91
2022-12-31 05:39:29,422 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42525638540585836, 'Total loss': 0.42525638540585836} | train loss {'Reaction outcome loss': 0.11224952059084266, 'Total loss': 0.11224952059084266}
2022-12-31 05:39:29,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:29,422 INFO:     Epoch: 92
2022-12-31 05:39:31,089 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4625882267951965, 'Total loss': 0.4625882267951965} | train loss {'Reaction outcome loss': 0.11912153708714829, 'Total loss': 0.11912153708714829}
2022-12-31 05:39:31,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:31,090 INFO:     Epoch: 93
2022-12-31 05:39:32,717 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4617160161336263, 'Total loss': 0.4617160161336263} | train loss {'Reaction outcome loss': 0.11577862921666379, 'Total loss': 0.11577862921666379}
2022-12-31 05:39:32,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:32,717 INFO:     Epoch: 94
2022-12-31 05:39:34,378 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41530649016300836, 'Total loss': 0.41530649016300836} | train loss {'Reaction outcome loss': 0.1140470829821011, 'Total loss': 0.1140470829821011}
2022-12-31 05:39:34,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:34,378 INFO:     Epoch: 95
2022-12-31 05:39:36,004 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45221544404824576, 'Total loss': 0.45221544404824576} | train loss {'Reaction outcome loss': 0.11268660486213934, 'Total loss': 0.11268660486213934}
2022-12-31 05:39:36,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:36,004 INFO:     Epoch: 96
2022-12-31 05:39:37,635 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44508954882621765, 'Total loss': 0.44508954882621765} | train loss {'Reaction outcome loss': 0.11330725315307011, 'Total loss': 0.11330725315307011}
2022-12-31 05:39:37,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:37,635 INFO:     Epoch: 97
2022-12-31 05:39:39,256 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40653584003448484, 'Total loss': 0.40653584003448484} | train loss {'Reaction outcome loss': 0.11613337989336392, 'Total loss': 0.11613337989336392}
2022-12-31 05:39:39,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:39,257 INFO:     Epoch: 98
2022-12-31 05:39:40,888 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48156429727872213, 'Total loss': 0.48156429727872213} | train loss {'Reaction outcome loss': 0.11554669009047507, 'Total loss': 0.11554669009047507}
2022-12-31 05:39:40,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:40,888 INFO:     Epoch: 99
2022-12-31 05:39:42,520 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44270121653874717, 'Total loss': 0.44270121653874717} | train loss {'Reaction outcome loss': 0.11704784822886459, 'Total loss': 0.11704784822886459}
2022-12-31 05:39:42,520 INFO:     Best model found after epoch 27 of 100.
2022-12-31 05:39:42,520 INFO:   Done with stage: TRAINING
2022-12-31 05:39:42,520 INFO:   Starting stage: EVALUATION
2022-12-31 05:39:42,650 INFO:   Done with stage: EVALUATION
2022-12-31 05:39:42,650 INFO:   Leaving out SEQ value Fold_5
2022-12-31 05:39:42,663 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 05:39:42,663 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:39:43,309 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:39:43,310 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:39:43,381 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:39:43,381 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:39:43,382 INFO:     No hyperparam tuning for this model
2022-12-31 05:39:43,382 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:39:43,382 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:39:43,382 INFO:     None feature selector for col prot
2022-12-31 05:39:43,383 INFO:     None feature selector for col prot
2022-12-31 05:39:43,383 INFO:     None feature selector for col prot
2022-12-31 05:39:43,383 INFO:     None feature selector for col chem
2022-12-31 05:39:43,383 INFO:     None feature selector for col chem
2022-12-31 05:39:43,383 INFO:     None feature selector for col chem
2022-12-31 05:39:43,383 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:39:43,383 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:39:43,385 INFO:     Number of params in model 224011
2022-12-31 05:39:43,388 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:39:43,389 INFO:   Starting stage: TRAINING
2022-12-31 05:39:43,432 INFO:     Val loss before train {'Reaction outcome loss': 0.8353338082631429, 'Total loss': 0.8353338082631429}
2022-12-31 05:39:43,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:43,432 INFO:     Epoch: 0
2022-12-31 05:39:45,061 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5148223261038463, 'Total loss': 0.5148223261038463} | train loss {'Reaction outcome loss': 0.7913509208157605, 'Total loss': 0.7913509208157605}
2022-12-31 05:39:45,061 INFO:     Found new best model at epoch 0
2022-12-31 05:39:45,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:45,062 INFO:     Epoch: 1
2022-12-31 05:39:46,722 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.42748610079288485, 'Total loss': 0.42748610079288485} | train loss {'Reaction outcome loss': 0.5164725869786438, 'Total loss': 0.5164725869786438}
2022-12-31 05:39:46,722 INFO:     Found new best model at epoch 1
2022-12-31 05:39:46,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:46,723 INFO:     Epoch: 2
2022-12-31 05:39:48,353 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.380759634077549, 'Total loss': 0.380759634077549} | train loss {'Reaction outcome loss': 0.4457683263595354, 'Total loss': 0.4457683263595354}
2022-12-31 05:39:48,353 INFO:     Found new best model at epoch 2
2022-12-31 05:39:48,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:48,354 INFO:     Epoch: 3
2022-12-31 05:39:49,983 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.389436337351799, 'Total loss': 0.389436337351799} | train loss {'Reaction outcome loss': 0.4048348206905682, 'Total loss': 0.4048348206905682}
2022-12-31 05:39:49,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:49,983 INFO:     Epoch: 4
2022-12-31 05:39:51,655 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.37612437705198926, 'Total loss': 0.37612437705198926} | train loss {'Reaction outcome loss': 0.37807697861956346, 'Total loss': 0.37807697861956346}
2022-12-31 05:39:51,655 INFO:     Found new best model at epoch 4
2022-12-31 05:39:51,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:51,656 INFO:     Epoch: 5
2022-12-31 05:39:53,278 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.37823087672392525, 'Total loss': 0.37823087672392525} | train loss {'Reaction outcome loss': 0.35404135083732624, 'Total loss': 0.35404135083732624}
2022-12-31 05:39:53,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:53,278 INFO:     Epoch: 6
2022-12-31 05:39:54,951 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3668563107649485, 'Total loss': 0.3668563107649485} | train loss {'Reaction outcome loss': 0.33643275701074393, 'Total loss': 0.33643275701074393}
2022-12-31 05:39:54,951 INFO:     Found new best model at epoch 6
2022-12-31 05:39:54,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:54,952 INFO:     Epoch: 7
2022-12-31 05:39:56,583 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.32388595342636106, 'Total loss': 0.32388595342636106} | train loss {'Reaction outcome loss': 0.3180631063071614, 'Total loss': 0.3180631063071614}
2022-12-31 05:39:56,583 INFO:     Found new best model at epoch 7
2022-12-31 05:39:56,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:56,584 INFO:     Epoch: 8
2022-12-31 05:39:58,209 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.34471886456012724, 'Total loss': 0.34471886456012724} | train loss {'Reaction outcome loss': 0.30284875402704475, 'Total loss': 0.30284875402704475}
2022-12-31 05:39:58,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:58,210 INFO:     Epoch: 9
2022-12-31 05:39:59,840 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37540072153011955, 'Total loss': 0.37540072153011955} | train loss {'Reaction outcome loss': 0.2857054175291251, 'Total loss': 0.2857054175291251}
2022-12-31 05:39:59,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:39:59,841 INFO:     Epoch: 10
2022-12-31 05:40:01,468 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.34296650588512423, 'Total loss': 0.34296650588512423} | train loss {'Reaction outcome loss': 0.2779872268572826, 'Total loss': 0.2779872268572826}
2022-12-31 05:40:01,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:01,468 INFO:     Epoch: 11
2022-12-31 05:40:03,091 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34229230880737305, 'Total loss': 0.34229230880737305} | train loss {'Reaction outcome loss': 0.26502920582298767, 'Total loss': 0.26502920582298767}
2022-12-31 05:40:03,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:03,091 INFO:     Epoch: 12
2022-12-31 05:40:04,719 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3608504811922709, 'Total loss': 0.3608504811922709} | train loss {'Reaction outcome loss': 0.2532032283715608, 'Total loss': 0.2532032283715608}
2022-12-31 05:40:04,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:04,719 INFO:     Epoch: 13
2022-12-31 05:40:06,346 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3487836241722107, 'Total loss': 0.3487836241722107} | train loss {'Reaction outcome loss': 0.2459730781776165, 'Total loss': 0.2459730781776165}
2022-12-31 05:40:06,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:06,347 INFO:     Epoch: 14
2022-12-31 05:40:07,996 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3357333928346634, 'Total loss': 0.3357333928346634} | train loss {'Reaction outcome loss': 0.2359245744422885, 'Total loss': 0.2359245744422885}
2022-12-31 05:40:07,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:07,996 INFO:     Epoch: 15
2022-12-31 05:40:09,667 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3443569233020147, 'Total loss': 0.3443569233020147} | train loss {'Reaction outcome loss': 0.2275403442284906, 'Total loss': 0.2275403442284906}
2022-12-31 05:40:09,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:09,668 INFO:     Epoch: 16
2022-12-31 05:40:11,294 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35816354900598524, 'Total loss': 0.35816354900598524} | train loss {'Reaction outcome loss': 0.2204519444236041, 'Total loss': 0.2204519444236041}
2022-12-31 05:40:11,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:11,294 INFO:     Epoch: 17
2022-12-31 05:40:12,965 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.33721581051747, 'Total loss': 0.33721581051747} | train loss {'Reaction outcome loss': 0.21634454771351835, 'Total loss': 0.21634454771351835}
2022-12-31 05:40:12,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:12,965 INFO:     Epoch: 18
2022-12-31 05:40:14,582 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3519627978404363, 'Total loss': 0.3519627978404363} | train loss {'Reaction outcome loss': 0.2084288541227579, 'Total loss': 0.2084288541227579}
2022-12-31 05:40:14,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:14,582 INFO:     Epoch: 19
2022-12-31 05:40:16,206 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3640492955843608, 'Total loss': 0.3640492955843608} | train loss {'Reaction outcome loss': 0.20490176360448992, 'Total loss': 0.20490176360448992}
2022-12-31 05:40:16,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:16,206 INFO:     Epoch: 20
2022-12-31 05:40:17,833 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.33539318417509395, 'Total loss': 0.33539318417509395} | train loss {'Reaction outcome loss': 0.19932298872633317, 'Total loss': 0.19932298872633317}
2022-12-31 05:40:17,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:17,833 INFO:     Epoch: 21
2022-12-31 05:40:19,504 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3444699386755625, 'Total loss': 0.3444699386755625} | train loss {'Reaction outcome loss': 0.19417233759409577, 'Total loss': 0.19417233759409577}
2022-12-31 05:40:19,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:19,505 INFO:     Epoch: 22
2022-12-31 05:40:21,160 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3297217470904191, 'Total loss': 0.3297217470904191} | train loss {'Reaction outcome loss': 0.19037033926480407, 'Total loss': 0.19037033926480407}
2022-12-31 05:40:21,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:21,160 INFO:     Epoch: 23
2022-12-31 05:40:22,779 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36393499076366426, 'Total loss': 0.36393499076366426} | train loss {'Reaction outcome loss': 0.18413157884825007, 'Total loss': 0.18413157884825007}
2022-12-31 05:40:22,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:22,779 INFO:     Epoch: 24
2022-12-31 05:40:24,400 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3541300157705943, 'Total loss': 0.3541300157705943} | train loss {'Reaction outcome loss': 0.18363848134929092, 'Total loss': 0.18363848134929092}
2022-12-31 05:40:24,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:24,400 INFO:     Epoch: 25
2022-12-31 05:40:26,066 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.34254461030165356, 'Total loss': 0.34254461030165356} | train loss {'Reaction outcome loss': 0.1804924383557768, 'Total loss': 0.1804924383557768}
2022-12-31 05:40:26,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:26,067 INFO:     Epoch: 26
2022-12-31 05:40:27,734 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.34333336353302, 'Total loss': 0.34333336353302} | train loss {'Reaction outcome loss': 0.17626157392905722, 'Total loss': 0.17626157392905722}
2022-12-31 05:40:27,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:27,734 INFO:     Epoch: 27
2022-12-31 05:40:29,386 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3392646412054698, 'Total loss': 0.3392646412054698} | train loss {'Reaction outcome loss': 0.16957381264800844, 'Total loss': 0.16957381264800844}
2022-12-31 05:40:29,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:29,387 INFO:     Epoch: 28
2022-12-31 05:40:31,010 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3332678978641828, 'Total loss': 0.3332678978641828} | train loss {'Reaction outcome loss': 0.16741718156162366, 'Total loss': 0.16741718156162366}
2022-12-31 05:40:31,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:31,011 INFO:     Epoch: 29
2022-12-31 05:40:32,630 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3434968988100688, 'Total loss': 0.3434968988100688} | train loss {'Reaction outcome loss': 0.1650837810125054, 'Total loss': 0.1650837810125054}
2022-12-31 05:40:32,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:32,630 INFO:     Epoch: 30
2022-12-31 05:40:34,281 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3599039236704508, 'Total loss': 0.3599039236704508} | train loss {'Reaction outcome loss': 0.16260430760789218, 'Total loss': 0.16260430760789218}
2022-12-31 05:40:34,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:34,282 INFO:     Epoch: 31
2022-12-31 05:40:35,904 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3333571637670199, 'Total loss': 0.3333571637670199} | train loss {'Reaction outcome loss': 0.16125317720111312, 'Total loss': 0.16125317720111312}
2022-12-31 05:40:35,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:35,905 INFO:     Epoch: 32
2022-12-31 05:40:37,586 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3613401085138321, 'Total loss': 0.3613401085138321} | train loss {'Reaction outcome loss': 0.1575338299745956, 'Total loss': 0.1575338299745956}
2022-12-31 05:40:37,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:37,587 INFO:     Epoch: 33
2022-12-31 05:40:39,202 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3609023690223694, 'Total loss': 0.3609023690223694} | train loss {'Reaction outcome loss': 0.15893774014974973, 'Total loss': 0.15893774014974973}
2022-12-31 05:40:39,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:39,202 INFO:     Epoch: 34
2022-12-31 05:40:40,871 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33236614366372425, 'Total loss': 0.33236614366372425} | train loss {'Reaction outcome loss': 0.15520533191927774, 'Total loss': 0.15520533191927774}
2022-12-31 05:40:40,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:40,871 INFO:     Epoch: 35
2022-12-31 05:40:42,525 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36832066675027214, 'Total loss': 0.36832066675027214} | train loss {'Reaction outcome loss': 0.15071060567663896, 'Total loss': 0.15071060567663896}
2022-12-31 05:40:42,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:42,526 INFO:     Epoch: 36
2022-12-31 05:40:44,154 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3894361719489098, 'Total loss': 0.3894361719489098} | train loss {'Reaction outcome loss': 0.14870860513353498, 'Total loss': 0.14870860513353498}
2022-12-31 05:40:44,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:44,154 INFO:     Epoch: 37
2022-12-31 05:40:45,821 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3681589384873708, 'Total loss': 0.3681589384873708} | train loss {'Reaction outcome loss': 0.14807055531143604, 'Total loss': 0.14807055531143604}
2022-12-31 05:40:45,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:45,822 INFO:     Epoch: 38
2022-12-31 05:40:47,479 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3961211860179901, 'Total loss': 0.3961211860179901} | train loss {'Reaction outcome loss': 0.1449562417921553, 'Total loss': 0.1449562417921553}
2022-12-31 05:40:47,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:47,479 INFO:     Epoch: 39
2022-12-31 05:40:49,114 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3597733601927757, 'Total loss': 0.3597733601927757} | train loss {'Reaction outcome loss': 0.14549871932863112, 'Total loss': 0.14549871932863112}
2022-12-31 05:40:49,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:49,114 INFO:     Epoch: 40
2022-12-31 05:40:50,745 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35874083439509075, 'Total loss': 0.35874083439509075} | train loss {'Reaction outcome loss': 0.14378082794086866, 'Total loss': 0.14378082794086866}
2022-12-31 05:40:50,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:50,746 INFO:     Epoch: 41
2022-12-31 05:40:52,371 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3903079072634379, 'Total loss': 0.3903079072634379} | train loss {'Reaction outcome loss': 0.1373511953178511, 'Total loss': 0.1373511953178511}
2022-12-31 05:40:52,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:52,371 INFO:     Epoch: 42
2022-12-31 05:40:54,038 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3767834941546122, 'Total loss': 0.3767834941546122} | train loss {'Reaction outcome loss': 0.13870221625051934, 'Total loss': 0.13870221625051934}
2022-12-31 05:40:54,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:54,038 INFO:     Epoch: 43
2022-12-31 05:40:55,706 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3685714701811473, 'Total loss': 0.3685714701811473} | train loss {'Reaction outcome loss': 0.13665634335190166, 'Total loss': 0.13665634335190166}
2022-12-31 05:40:55,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:55,706 INFO:     Epoch: 44
2022-12-31 05:40:57,354 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3722604920466741, 'Total loss': 0.3722604920466741} | train loss {'Reaction outcome loss': 0.13619904414101736, 'Total loss': 0.13619904414101736}
2022-12-31 05:40:57,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:57,355 INFO:     Epoch: 45
2022-12-31 05:40:59,021 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39154940048853554, 'Total loss': 0.39154940048853554} | train loss {'Reaction outcome loss': 0.13692979882084613, 'Total loss': 0.13692979882084613}
2022-12-31 05:40:59,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:40:59,021 INFO:     Epoch: 46
2022-12-31 05:41:00,646 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3662724686165651, 'Total loss': 0.3662724686165651} | train loss {'Reaction outcome loss': 0.13137115249981843, 'Total loss': 0.13137115249981843}
2022-12-31 05:41:00,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:00,647 INFO:     Epoch: 47
2022-12-31 05:41:02,266 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3726435045401255, 'Total loss': 0.3726435045401255} | train loss {'Reaction outcome loss': 0.1323090352803899, 'Total loss': 0.1323090352803899}
2022-12-31 05:41:02,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:02,267 INFO:     Epoch: 48
2022-12-31 05:41:03,884 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37671991089979806, 'Total loss': 0.37671991089979806} | train loss {'Reaction outcome loss': 0.13161640386483783, 'Total loss': 0.13161640386483783}
2022-12-31 05:41:03,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:03,884 INFO:     Epoch: 49
2022-12-31 05:41:05,504 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37747212251027423, 'Total loss': 0.37747212251027423} | train loss {'Reaction outcome loss': 0.12761691329825925, 'Total loss': 0.12761691329825925}
2022-12-31 05:41:05,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:05,505 INFO:     Epoch: 50
2022-12-31 05:41:07,127 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3923547903696696, 'Total loss': 0.3923547903696696} | train loss {'Reaction outcome loss': 0.12590846124135416, 'Total loss': 0.12590846124135416}
2022-12-31 05:41:07,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:07,128 INFO:     Epoch: 51
2022-12-31 05:41:08,759 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37485615313053133, 'Total loss': 0.37485615313053133} | train loss {'Reaction outcome loss': 0.12968013541342605, 'Total loss': 0.12968013541342605}
2022-12-31 05:41:08,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:08,760 INFO:     Epoch: 52
2022-12-31 05:41:10,369 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41053590377171834, 'Total loss': 0.41053590377171834} | train loss {'Reaction outcome loss': 0.1281783738642568, 'Total loss': 0.1281783738642568}
2022-12-31 05:41:10,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:10,370 INFO:     Epoch: 53
2022-12-31 05:41:11,990 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40909110208352406, 'Total loss': 0.40909110208352406} | train loss {'Reaction outcome loss': 0.12922703506700722, 'Total loss': 0.12922703506700722}
2022-12-31 05:41:11,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:11,990 INFO:     Epoch: 54
2022-12-31 05:41:13,658 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3947166413068771, 'Total loss': 0.3947166413068771} | train loss {'Reaction outcome loss': 0.1260683238136478, 'Total loss': 0.1260683238136478}
2022-12-31 05:41:13,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:13,658 INFO:     Epoch: 55
2022-12-31 05:41:15,304 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3804843266805013, 'Total loss': 0.3804843266805013} | train loss {'Reaction outcome loss': 0.12372762870399907, 'Total loss': 0.12372762870399907}
2022-12-31 05:41:15,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:15,305 INFO:     Epoch: 56
2022-12-31 05:41:16,940 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3990143676598867, 'Total loss': 0.3990143676598867} | train loss {'Reaction outcome loss': 0.11938964463568659, 'Total loss': 0.11938964463568659}
2022-12-31 05:41:16,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:16,941 INFO:     Epoch: 57
2022-12-31 05:41:18,568 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3835462595025698, 'Total loss': 0.3835462595025698} | train loss {'Reaction outcome loss': 0.12162558797962075, 'Total loss': 0.12162558797962075}
2022-12-31 05:41:18,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:18,569 INFO:     Epoch: 58
2022-12-31 05:41:20,236 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3598264714082082, 'Total loss': 0.3598264714082082} | train loss {'Reaction outcome loss': 0.12073201812561668, 'Total loss': 0.12073201812561668}
2022-12-31 05:41:20,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:20,237 INFO:     Epoch: 59
2022-12-31 05:41:21,904 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3871247122685115, 'Total loss': 0.3871247122685115} | train loss {'Reaction outcome loss': 0.12108155898413611, 'Total loss': 0.12108155898413611}
2022-12-31 05:41:21,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:21,904 INFO:     Epoch: 60
2022-12-31 05:41:23,526 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39811860819657646, 'Total loss': 0.39811860819657646} | train loss {'Reaction outcome loss': 0.12282811272855754, 'Total loss': 0.12282811272855754}
2022-12-31 05:41:23,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:23,527 INFO:     Epoch: 61
2022-12-31 05:41:25,152 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4050203134616216, 'Total loss': 0.4050203134616216} | train loss {'Reaction outcome loss': 0.12052062485158604, 'Total loss': 0.12052062485158604}
2022-12-31 05:41:25,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:25,152 INFO:     Epoch: 62
2022-12-31 05:41:26,819 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3852250923713048, 'Total loss': 0.3852250923713048} | train loss {'Reaction outcome loss': 0.12126354714317604, 'Total loss': 0.12126354714317604}
2022-12-31 05:41:26,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:26,819 INFO:     Epoch: 63
2022-12-31 05:41:28,455 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37013516599933305, 'Total loss': 0.37013516599933305} | train loss {'Reaction outcome loss': 0.11804298551867477, 'Total loss': 0.11804298551867477}
2022-12-31 05:41:28,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:28,455 INFO:     Epoch: 64
2022-12-31 05:41:30,096 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37087499449650446, 'Total loss': 0.37087499449650446} | train loss {'Reaction outcome loss': 0.11500150282171283, 'Total loss': 0.11500150282171283}
2022-12-31 05:41:30,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:30,097 INFO:     Epoch: 65
2022-12-31 05:41:31,747 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3628905857602755, 'Total loss': 0.3628905857602755} | train loss {'Reaction outcome loss': 0.1184429354622745, 'Total loss': 0.1184429354622745}
2022-12-31 05:41:31,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:31,747 INFO:     Epoch: 66
2022-12-31 05:41:33,368 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3807031234105428, 'Total loss': 0.3807031234105428} | train loss {'Reaction outcome loss': 0.11637279481395058, 'Total loss': 0.11637279481395058}
2022-12-31 05:41:33,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:33,368 INFO:     Epoch: 67
2022-12-31 05:41:34,993 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.403635577360789, 'Total loss': 0.403635577360789} | train loss {'Reaction outcome loss': 0.12000979853639318, 'Total loss': 0.12000979853639318}
2022-12-31 05:41:34,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:34,993 INFO:     Epoch: 68
2022-12-31 05:41:36,657 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37811843554178876, 'Total loss': 0.37811843554178876} | train loss {'Reaction outcome loss': 0.1260310112101964, 'Total loss': 0.1260310112101964}
2022-12-31 05:41:36,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:36,658 INFO:     Epoch: 69
2022-12-31 05:41:38,278 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38414493401845295, 'Total loss': 0.38414493401845295} | train loss {'Reaction outcome loss': 0.11659714235631675, 'Total loss': 0.11659714235631675}
2022-12-31 05:41:38,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:38,278 INFO:     Epoch: 70
2022-12-31 05:41:39,898 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3659513225158056, 'Total loss': 0.3659513225158056} | train loss {'Reaction outcome loss': 0.11540191281344808, 'Total loss': 0.11540191281344808}
2022-12-31 05:41:39,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:39,898 INFO:     Epoch: 71
2022-12-31 05:41:41,522 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36551434447367986, 'Total loss': 0.36551434447367986} | train loss {'Reaction outcome loss': 0.11476716251845474, 'Total loss': 0.11476716251845474}
2022-12-31 05:41:41,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:41,522 INFO:     Epoch: 72
2022-12-31 05:41:43,150 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3892797480026881, 'Total loss': 0.3892797480026881} | train loss {'Reaction outcome loss': 0.11251521029338132, 'Total loss': 0.11251521029338132}
2022-12-31 05:41:43,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:43,150 INFO:     Epoch: 73
2022-12-31 05:41:44,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39180601835250856, 'Total loss': 0.39180601835250856} | train loss {'Reaction outcome loss': 0.11730350672337983, 'Total loss': 0.11730350672337983}
2022-12-31 05:41:44,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:44,793 INFO:     Epoch: 74
2022-12-31 05:41:46,426 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34605844418207804, 'Total loss': 0.34605844418207804} | train loss {'Reaction outcome loss': 0.11108707979704768, 'Total loss': 0.11108707979704768}
2022-12-31 05:41:46,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:46,426 INFO:     Epoch: 75
2022-12-31 05:41:48,069 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38390260338783266, 'Total loss': 0.38390260338783266} | train loss {'Reaction outcome loss': 0.11051486710940457, 'Total loss': 0.11051486710940457}
2022-12-31 05:41:48,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:48,069 INFO:     Epoch: 76
2022-12-31 05:41:49,712 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3613978177309036, 'Total loss': 0.3613978177309036} | train loss {'Reaction outcome loss': 0.1103417440695816, 'Total loss': 0.1103417440695816}
2022-12-31 05:41:49,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:49,712 INFO:     Epoch: 77
2022-12-31 05:41:51,348 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3755169649918874, 'Total loss': 0.3755169649918874} | train loss {'Reaction outcome loss': 0.11243597257778129, 'Total loss': 0.11243597257778129}
2022-12-31 05:41:51,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:51,349 INFO:     Epoch: 78
2022-12-31 05:41:53,013 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39396962386866413, 'Total loss': 0.39396962386866413} | train loss {'Reaction outcome loss': 0.11463684759175048, 'Total loss': 0.11463684759175048}
2022-12-31 05:41:53,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:53,013 INFO:     Epoch: 79
2022-12-31 05:41:54,676 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39122344156106315, 'Total loss': 0.39122344156106315} | train loss {'Reaction outcome loss': 0.11995121477245746, 'Total loss': 0.11995121477245746}
2022-12-31 05:41:54,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:54,676 INFO:     Epoch: 80
2022-12-31 05:41:56,342 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36692651013533273, 'Total loss': 0.36692651013533273} | train loss {'Reaction outcome loss': 0.11653716570028652, 'Total loss': 0.11653716570028652}
2022-12-31 05:41:56,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:56,343 INFO:     Epoch: 81
2022-12-31 05:41:57,974 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.375173286596934, 'Total loss': 0.375173286596934} | train loss {'Reaction outcome loss': 0.1117430066039268, 'Total loss': 0.1117430066039268}
2022-12-31 05:41:57,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:57,974 INFO:     Epoch: 82
2022-12-31 05:41:59,646 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3917855868736903, 'Total loss': 0.3917855868736903} | train loss {'Reaction outcome loss': 0.11213548420440904, 'Total loss': 0.11213548420440904}
2022-12-31 05:41:59,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:41:59,646 INFO:     Epoch: 83
2022-12-31 05:42:01,270 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3877467776338259, 'Total loss': 0.3877467776338259} | train loss {'Reaction outcome loss': 0.10762203446024565, 'Total loss': 0.10762203446024565}
2022-12-31 05:42:01,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:01,270 INFO:     Epoch: 84
2022-12-31 05:42:02,941 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38486373821894326, 'Total loss': 0.38486373821894326} | train loss {'Reaction outcome loss': 0.11264784990083627, 'Total loss': 0.11264784990083627}
2022-12-31 05:42:02,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:02,941 INFO:     Epoch: 85
2022-12-31 05:42:04,568 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3844016974171003, 'Total loss': 0.3844016974171003} | train loss {'Reaction outcome loss': 0.11292141298040587, 'Total loss': 0.11292141298040587}
2022-12-31 05:42:04,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:04,569 INFO:     Epoch: 86
2022-12-31 05:42:06,211 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3778064136703809, 'Total loss': 0.3778064136703809} | train loss {'Reaction outcome loss': 0.10826515021569193, 'Total loss': 0.10826515021569193}
2022-12-31 05:42:06,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:06,211 INFO:     Epoch: 87
2022-12-31 05:42:07,853 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3863863865534464, 'Total loss': 0.3863863865534464} | train loss {'Reaction outcome loss': 0.10782419187638788, 'Total loss': 0.10782419187638788}
2022-12-31 05:42:07,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:07,853 INFO:     Epoch: 88
2022-12-31 05:42:09,492 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38110713561375936, 'Total loss': 0.38110713561375936} | train loss {'Reaction outcome loss': 0.10913471098138618, 'Total loss': 0.10913471098138618}
2022-12-31 05:42:09,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:09,493 INFO:     Epoch: 89
2022-12-31 05:42:11,122 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4010089178880056, 'Total loss': 0.4010089178880056} | train loss {'Reaction outcome loss': 0.1163028951361103, 'Total loss': 0.1163028951361103}
2022-12-31 05:42:11,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:11,122 INFO:     Epoch: 90
2022-12-31 05:42:12,759 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38947228491306307, 'Total loss': 0.38947228491306307} | train loss {'Reaction outcome loss': 0.11596586352965664, 'Total loss': 0.11596586352965664}
2022-12-31 05:42:12,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:12,761 INFO:     Epoch: 91
2022-12-31 05:42:14,413 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3959719528754552, 'Total loss': 0.3959719528754552} | train loss {'Reaction outcome loss': 0.11369350982581128, 'Total loss': 0.11369350982581128}
2022-12-31 05:42:14,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:14,413 INFO:     Epoch: 92
2022-12-31 05:42:16,080 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3799829492966334, 'Total loss': 0.3799829492966334} | train loss {'Reaction outcome loss': 0.10701802843973202, 'Total loss': 0.10701802843973202}
2022-12-31 05:42:16,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:16,080 INFO:     Epoch: 93
2022-12-31 05:42:17,703 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3895136753718058, 'Total loss': 0.3895136753718058} | train loss {'Reaction outcome loss': 0.10735947547677151, 'Total loss': 0.10735947547677151}
2022-12-31 05:42:17,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:17,704 INFO:     Epoch: 94
2022-12-31 05:42:19,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38187364836533866, 'Total loss': 0.38187364836533866} | train loss {'Reaction outcome loss': 0.10754384360501429, 'Total loss': 0.10754384360501429}
2022-12-31 05:42:19,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:19,319 INFO:     Epoch: 95
2022-12-31 05:42:20,940 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40174924234549203, 'Total loss': 0.40174924234549203} | train loss {'Reaction outcome loss': 0.1067826096220648, 'Total loss': 0.1067826096220648}
2022-12-31 05:42:20,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:20,941 INFO:     Epoch: 96
2022-12-31 05:42:22,567 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3692740221818288, 'Total loss': 0.3692740221818288} | train loss {'Reaction outcome loss': 0.10419194210851934, 'Total loss': 0.10419194210851934}
2022-12-31 05:42:22,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:22,567 INFO:     Epoch: 97
2022-12-31 05:42:24,233 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3856725312769413, 'Total loss': 0.3856725312769413} | train loss {'Reaction outcome loss': 0.10741664205563493, 'Total loss': 0.10741664205563493}
2022-12-31 05:42:24,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:24,233 INFO:     Epoch: 98
2022-12-31 05:42:25,900 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36276237038740267, 'Total loss': 0.36276237038740267} | train loss {'Reaction outcome loss': 0.11605459246078392, 'Total loss': 0.11605459246078392}
2022-12-31 05:42:25,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:25,901 INFO:     Epoch: 99
2022-12-31 05:42:27,522 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3743444343407949, 'Total loss': 0.3743444343407949} | train loss {'Reaction outcome loss': 0.11312441711754467, 'Total loss': 0.11312441711754467}
2022-12-31 05:42:27,522 INFO:     Best model found after epoch 8 of 100.
2022-12-31 05:42:27,523 INFO:   Done with stage: TRAINING
2022-12-31 05:42:27,523 INFO:   Starting stage: EVALUATION
2022-12-31 05:42:27,647 INFO:   Done with stage: EVALUATION
2022-12-31 05:42:27,647 INFO:   Leaving out SEQ value Fold_6
2022-12-31 05:42:27,659 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:42:27,659 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:42:28,299 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:42:28,299 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:42:28,368 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:42:28,369 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:42:28,369 INFO:     No hyperparam tuning for this model
2022-12-31 05:42:28,369 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:42:28,369 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:42:28,370 INFO:     None feature selector for col prot
2022-12-31 05:42:28,370 INFO:     None feature selector for col prot
2022-12-31 05:42:28,370 INFO:     None feature selector for col prot
2022-12-31 05:42:28,371 INFO:     None feature selector for col chem
2022-12-31 05:42:28,371 INFO:     None feature selector for col chem
2022-12-31 05:42:28,371 INFO:     None feature selector for col chem
2022-12-31 05:42:28,371 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:42:28,371 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:42:28,373 INFO:     Number of params in model 224011
2022-12-31 05:42:28,376 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:42:28,376 INFO:   Starting stage: TRAINING
2022-12-31 05:42:28,421 INFO:     Val loss before train {'Reaction outcome loss': 0.9787966807683309, 'Total loss': 0.9787966807683309}
2022-12-31 05:42:28,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:28,421 INFO:     Epoch: 0
2022-12-31 05:42:30,026 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5219350179036458, 'Total loss': 0.5219350179036458} | train loss {'Reaction outcome loss': 0.8119306031913653, 'Total loss': 0.8119306031913653}
2022-12-31 05:42:30,026 INFO:     Found new best model at epoch 0
2022-12-31 05:42:30,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:30,027 INFO:     Epoch: 1
2022-12-31 05:42:31,633 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4303017059961955, 'Total loss': 0.4303017059961955} | train loss {'Reaction outcome loss': 0.5171599762826941, 'Total loss': 0.5171599762826941}
2022-12-31 05:42:31,634 INFO:     Found new best model at epoch 1
2022-12-31 05:42:31,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:31,635 INFO:     Epoch: 2
2022-12-31 05:42:33,245 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41812176406383517, 'Total loss': 0.41812176406383517} | train loss {'Reaction outcome loss': 0.44561604641541075, 'Total loss': 0.44561604641541075}
2022-12-31 05:42:33,245 INFO:     Found new best model at epoch 2
2022-12-31 05:42:33,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:33,246 INFO:     Epoch: 3
2022-12-31 05:42:34,859 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.38657173117001853, 'Total loss': 0.38657173117001853} | train loss {'Reaction outcome loss': 0.4061135986588732, 'Total loss': 0.4061135986588732}
2022-12-31 05:42:34,860 INFO:     Found new best model at epoch 3
2022-12-31 05:42:34,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:34,861 INFO:     Epoch: 4
2022-12-31 05:42:36,469 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3835686524709066, 'Total loss': 0.3835686524709066} | train loss {'Reaction outcome loss': 0.37700963569601087, 'Total loss': 0.37700963569601087}
2022-12-31 05:42:36,469 INFO:     Found new best model at epoch 4
2022-12-31 05:42:36,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:36,471 INFO:     Epoch: 5
2022-12-31 05:42:38,066 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.404477825264136, 'Total loss': 0.404477825264136} | train loss {'Reaction outcome loss': 0.3489143336939551, 'Total loss': 0.3489143336939551}
2022-12-31 05:42:38,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:38,066 INFO:     Epoch: 6
2022-12-31 05:42:39,725 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37568767269452413, 'Total loss': 0.37568767269452413} | train loss {'Reaction outcome loss': 0.3321485661894736, 'Total loss': 0.3321485661894736}
2022-12-31 05:42:39,725 INFO:     Found new best model at epoch 6
2022-12-31 05:42:39,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:39,726 INFO:     Epoch: 7
2022-12-31 05:42:41,324 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3972232351700465, 'Total loss': 0.3972232351700465} | train loss {'Reaction outcome loss': 0.31529821953090437, 'Total loss': 0.31529821953090437}
2022-12-31 05:42:41,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:41,325 INFO:     Epoch: 8
2022-12-31 05:42:42,972 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3417944918076197, 'Total loss': 0.3417944918076197} | train loss {'Reaction outcome loss': 0.3010239072524718, 'Total loss': 0.3010239072524718}
2022-12-31 05:42:42,972 INFO:     Found new best model at epoch 8
2022-12-31 05:42:42,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:42,973 INFO:     Epoch: 9
2022-12-31 05:42:44,582 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3253308003147443, 'Total loss': 0.3253308003147443} | train loss {'Reaction outcome loss': 0.28673351482644566, 'Total loss': 0.28673351482644566}
2022-12-31 05:42:44,583 INFO:     Found new best model at epoch 9
2022-12-31 05:42:44,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:44,584 INFO:     Epoch: 10
2022-12-31 05:42:46,194 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3437409773468971, 'Total loss': 0.3437409773468971} | train loss {'Reaction outcome loss': 0.27214304189177324, 'Total loss': 0.27214304189177324}
2022-12-31 05:42:46,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:46,194 INFO:     Epoch: 11
2022-12-31 05:42:47,843 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3360107799371084, 'Total loss': 0.3360107799371084} | train loss {'Reaction outcome loss': 0.2605515046412275, 'Total loss': 0.2605515046412275}
2022-12-31 05:42:47,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:47,843 INFO:     Epoch: 12
2022-12-31 05:42:49,473 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.32775687525669733, 'Total loss': 0.32775687525669733} | train loss {'Reaction outcome loss': 0.2496931090080825, 'Total loss': 0.2496931090080825}
2022-12-31 05:42:49,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:49,473 INFO:     Epoch: 13
2022-12-31 05:42:51,090 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3465567087133726, 'Total loss': 0.3465567087133726} | train loss {'Reaction outcome loss': 0.2421618838434237, 'Total loss': 0.2421618838434237}
2022-12-31 05:42:51,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:51,091 INFO:     Epoch: 14
2022-12-31 05:42:52,706 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.32382961561282475, 'Total loss': 0.32382961561282475} | train loss {'Reaction outcome loss': 0.23149026018723737, 'Total loss': 0.23149026018723737}
2022-12-31 05:42:52,706 INFO:     Found new best model at epoch 14
2022-12-31 05:42:52,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:52,707 INFO:     Epoch: 15
2022-12-31 05:42:54,323 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.33822091718514763, 'Total loss': 0.33822091718514763} | train loss {'Reaction outcome loss': 0.22692894047792375, 'Total loss': 0.22692894047792375}
2022-12-31 05:42:54,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:54,323 INFO:     Epoch: 16
2022-12-31 05:42:55,930 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3588661223649979, 'Total loss': 0.3588661223649979} | train loss {'Reaction outcome loss': 0.21976399206196087, 'Total loss': 0.21976399206196087}
2022-12-31 05:42:55,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:55,930 INFO:     Epoch: 17
2022-12-31 05:42:57,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3542234510183334, 'Total loss': 0.3542234510183334} | train loss {'Reaction outcome loss': 0.2090840344963065, 'Total loss': 0.2090840344963065}
2022-12-31 05:42:57,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:57,543 INFO:     Epoch: 18
2022-12-31 05:42:59,159 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35362982799609505, 'Total loss': 0.35362982799609505} | train loss {'Reaction outcome loss': 0.2068905117955521, 'Total loss': 0.2068905117955521}
2022-12-31 05:42:59,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:42:59,159 INFO:     Epoch: 19
2022-12-31 05:43:00,772 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.34995122253894806, 'Total loss': 0.34995122253894806} | train loss {'Reaction outcome loss': 0.19747139224578647, 'Total loss': 0.19747139224578647}
2022-12-31 05:43:00,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:00,772 INFO:     Epoch: 20
2022-12-31 05:43:02,386 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3580349589387576, 'Total loss': 0.3580349589387576} | train loss {'Reaction outcome loss': 0.19233277319067152, 'Total loss': 0.19233277319067152}
2022-12-31 05:43:02,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:02,387 INFO:     Epoch: 21
2022-12-31 05:43:04,001 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3382310857375463, 'Total loss': 0.3382310857375463} | train loss {'Reaction outcome loss': 0.1942888786880313, 'Total loss': 0.1942888786880313}
2022-12-31 05:43:04,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:04,002 INFO:     Epoch: 22
2022-12-31 05:43:05,606 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34339527785778046, 'Total loss': 0.34339527785778046} | train loss {'Reaction outcome loss': 0.1893843113288392, 'Total loss': 0.1893843113288392}
2022-12-31 05:43:05,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:05,606 INFO:     Epoch: 23
2022-12-31 05:43:07,206 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3679296612739563, 'Total loss': 0.3679296612739563} | train loss {'Reaction outcome loss': 0.18212869628094627, 'Total loss': 0.18212869628094627}
2022-12-31 05:43:07,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:07,207 INFO:     Epoch: 24
2022-12-31 05:43:08,851 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3556218425432841, 'Total loss': 0.3556218425432841} | train loss {'Reaction outcome loss': 0.17510819779776962, 'Total loss': 0.17510819779776962}
2022-12-31 05:43:08,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:08,852 INFO:     Epoch: 25
2022-12-31 05:43:10,457 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.350781120856603, 'Total loss': 0.350781120856603} | train loss {'Reaction outcome loss': 0.1744961102601875, 'Total loss': 0.1744961102601875}
2022-12-31 05:43:10,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:10,457 INFO:     Epoch: 26
2022-12-31 05:43:12,063 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.34182741940021516, 'Total loss': 0.34182741940021516} | train loss {'Reaction outcome loss': 0.17269221476082058, 'Total loss': 0.17269221476082058}
2022-12-31 05:43:12,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:12,064 INFO:     Epoch: 27
2022-12-31 05:43:13,670 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.356554214656353, 'Total loss': 0.356554214656353} | train loss {'Reaction outcome loss': 0.17051560147563471, 'Total loss': 0.17051560147563471}
2022-12-31 05:43:13,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:13,670 INFO:     Epoch: 28
2022-12-31 05:43:15,292 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38478565911451973, 'Total loss': 0.38478565911451973} | train loss {'Reaction outcome loss': 0.16782369520719143, 'Total loss': 0.16782369520719143}
2022-12-31 05:43:15,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:15,293 INFO:     Epoch: 29
2022-12-31 05:43:16,900 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3800159061948458, 'Total loss': 0.3800159061948458} | train loss {'Reaction outcome loss': 0.16383802083857957, 'Total loss': 0.16383802083857957}
2022-12-31 05:43:16,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:16,901 INFO:     Epoch: 30
2022-12-31 05:43:18,555 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35108466893434526, 'Total loss': 0.35108466893434526} | train loss {'Reaction outcome loss': 0.158729712346256, 'Total loss': 0.158729712346256}
2022-12-31 05:43:18,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:18,555 INFO:     Epoch: 31
2022-12-31 05:43:20,209 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3577118699749311, 'Total loss': 0.3577118699749311} | train loss {'Reaction outcome loss': 0.15835624838071147, 'Total loss': 0.15835624838071147}
2022-12-31 05:43:20,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:20,210 INFO:     Epoch: 32
2022-12-31 05:43:21,813 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3596273918946584, 'Total loss': 0.3596273918946584} | train loss {'Reaction outcome loss': 0.15691571748631933, 'Total loss': 0.15691571748631933}
2022-12-31 05:43:21,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:21,813 INFO:     Epoch: 33
2022-12-31 05:43:23,452 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3684023941556613, 'Total loss': 0.3684023941556613} | train loss {'Reaction outcome loss': 0.15498653429485584, 'Total loss': 0.15498653429485584}
2022-12-31 05:43:23,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:23,452 INFO:     Epoch: 34
2022-12-31 05:43:25,106 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35404310524463656, 'Total loss': 0.35404310524463656} | train loss {'Reaction outcome loss': 0.15721824663915557, 'Total loss': 0.15721824663915557}
2022-12-31 05:43:25,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:25,106 INFO:     Epoch: 35
2022-12-31 05:43:26,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35906327664852145, 'Total loss': 0.35906327664852145} | train loss {'Reaction outcome loss': 0.14975340594707506, 'Total loss': 0.14975340594707506}
2022-12-31 05:43:26,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:26,707 INFO:     Epoch: 36
2022-12-31 05:43:28,311 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3428853804866473, 'Total loss': 0.3428853804866473} | train loss {'Reaction outcome loss': 0.14937276796295043, 'Total loss': 0.14937276796295043}
2022-12-31 05:43:28,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:28,312 INFO:     Epoch: 37
2022-12-31 05:43:29,969 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4010500858227412, 'Total loss': 0.4010500858227412} | train loss {'Reaction outcome loss': 0.14461247316208145, 'Total loss': 0.14461247316208145}
2022-12-31 05:43:29,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:29,969 INFO:     Epoch: 38
2022-12-31 05:43:31,625 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3500798404216766, 'Total loss': 0.3500798404216766} | train loss {'Reaction outcome loss': 0.14448919042394273, 'Total loss': 0.14448919042394273}
2022-12-31 05:43:31,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:31,625 INFO:     Epoch: 39
2022-12-31 05:43:33,234 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37355355521043143, 'Total loss': 0.37355355521043143} | train loss {'Reaction outcome loss': 0.14329603437103167, 'Total loss': 0.14329603437103167}
2022-12-31 05:43:33,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:33,235 INFO:     Epoch: 40
2022-12-31 05:43:34,874 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33562012513478595, 'Total loss': 0.33562012513478595} | train loss {'Reaction outcome loss': 0.14357104728909303, 'Total loss': 0.14357104728909303}
2022-12-31 05:43:34,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:34,875 INFO:     Epoch: 41
2022-12-31 05:43:36,492 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3804482614000638, 'Total loss': 0.3804482614000638} | train loss {'Reaction outcome loss': 0.14336313354531235, 'Total loss': 0.14336313354531235}
2022-12-31 05:43:36,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:36,492 INFO:     Epoch: 42
2022-12-31 05:43:38,147 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3529634912808736, 'Total loss': 0.3529634912808736} | train loss {'Reaction outcome loss': 0.1406670213187535, 'Total loss': 0.1406670213187535}
2022-12-31 05:43:38,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:38,148 INFO:     Epoch: 43
2022-12-31 05:43:39,767 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35549749732017516, 'Total loss': 0.35549749732017516} | train loss {'Reaction outcome loss': 0.1336268015226254, 'Total loss': 0.1336268015226254}
2022-12-31 05:43:39,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:39,768 INFO:     Epoch: 44
2022-12-31 05:43:41,397 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37299461687604585, 'Total loss': 0.37299461687604585} | train loss {'Reaction outcome loss': 0.13441273827364084, 'Total loss': 0.13441273827364084}
2022-12-31 05:43:41,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:41,397 INFO:     Epoch: 45
2022-12-31 05:43:43,023 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3785792842507362, 'Total loss': 0.3785792842507362} | train loss {'Reaction outcome loss': 0.1360444228324604, 'Total loss': 0.1360444228324604}
2022-12-31 05:43:43,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:43,023 INFO:     Epoch: 46
2022-12-31 05:43:44,642 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35710281878709793, 'Total loss': 0.35710281878709793} | train loss {'Reaction outcome loss': 0.13552549229696884, 'Total loss': 0.13552549229696884}
2022-12-31 05:43:44,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:44,642 INFO:     Epoch: 47
2022-12-31 05:43:46,262 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.366970581561327, 'Total loss': 0.366970581561327} | train loss {'Reaction outcome loss': 0.13575320872376218, 'Total loss': 0.13575320872376218}
2022-12-31 05:43:46,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:46,262 INFO:     Epoch: 48
2022-12-31 05:43:47,885 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4004052743315697, 'Total loss': 0.4004052743315697} | train loss {'Reaction outcome loss': 0.13385383554319613, 'Total loss': 0.13385383554319613}
2022-12-31 05:43:47,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:47,886 INFO:     Epoch: 49
2022-12-31 05:43:49,515 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3823946913083394, 'Total loss': 0.3823946913083394} | train loss {'Reaction outcome loss': 0.13077624197573448, 'Total loss': 0.13077624197573448}
2022-12-31 05:43:49,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:49,515 INFO:     Epoch: 50
2022-12-31 05:43:51,139 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39943438867727915, 'Total loss': 0.39943438867727915} | train loss {'Reaction outcome loss': 0.13316198646084126, 'Total loss': 0.13316198646084126}
2022-12-31 05:43:51,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:51,140 INFO:     Epoch: 51
2022-12-31 05:43:52,763 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34842789471149443, 'Total loss': 0.34842789471149443} | train loss {'Reaction outcome loss': 0.13056334294208807, 'Total loss': 0.13056334294208807}
2022-12-31 05:43:52,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:52,763 INFO:     Epoch: 52
2022-12-31 05:43:54,407 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34923429091771446, 'Total loss': 0.34923429091771446} | train loss {'Reaction outcome loss': 0.12745002602281416, 'Total loss': 0.12745002602281416}
2022-12-31 05:43:54,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:54,408 INFO:     Epoch: 53
2022-12-31 05:43:56,060 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4249230141441027, 'Total loss': 0.4249230141441027} | train loss {'Reaction outcome loss': 0.12650098408280064, 'Total loss': 0.12650098408280064}
2022-12-31 05:43:56,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:56,061 INFO:     Epoch: 54
2022-12-31 05:43:57,687 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3622449388106664, 'Total loss': 0.3622449388106664} | train loss {'Reaction outcome loss': 0.12425091123908595, 'Total loss': 0.12425091123908595}
2022-12-31 05:43:57,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:57,688 INFO:     Epoch: 55
2022-12-31 05:43:59,328 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4015722721815109, 'Total loss': 0.4015722721815109} | train loss {'Reaction outcome loss': 0.1247348695854065, 'Total loss': 0.1247348695854065}
2022-12-31 05:43:59,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:43:59,328 INFO:     Epoch: 56
2022-12-31 05:44:00,950 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4007908304532369, 'Total loss': 0.4007908304532369} | train loss {'Reaction outcome loss': 0.12858181752869519, 'Total loss': 0.12858181752869519}
2022-12-31 05:44:00,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:00,950 INFO:     Epoch: 57
2022-12-31 05:44:02,566 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3366797387599945, 'Total loss': 0.3366797387599945} | train loss {'Reaction outcome loss': 0.12636224164654683, 'Total loss': 0.12636224164654683}
2022-12-31 05:44:02,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:02,567 INFO:     Epoch: 58
2022-12-31 05:44:04,188 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3819490144650141, 'Total loss': 0.3819490144650141} | train loss {'Reaction outcome loss': 0.12349632616243224, 'Total loss': 0.12349632616243224}
2022-12-31 05:44:04,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:04,188 INFO:     Epoch: 59
2022-12-31 05:44:05,843 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38609615514675777, 'Total loss': 0.38609615514675777} | train loss {'Reaction outcome loss': 0.12311004668756313, 'Total loss': 0.12311004668756313}
2022-12-31 05:44:05,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:05,843 INFO:     Epoch: 60
2022-12-31 05:44:07,497 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39922553474704425, 'Total loss': 0.39922553474704425} | train loss {'Reaction outcome loss': 0.1255300396740654, 'Total loss': 0.1255300396740654}
2022-12-31 05:44:07,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:07,497 INFO:     Epoch: 61
2022-12-31 05:44:09,100 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36230569928884504, 'Total loss': 0.36230569928884504} | train loss {'Reaction outcome loss': 0.12771601076441796, 'Total loss': 0.12771601076441796}
2022-12-31 05:44:09,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:09,100 INFO:     Epoch: 62
2022-12-31 05:44:10,724 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.385207944487532, 'Total loss': 0.385207944487532} | train loss {'Reaction outcome loss': 0.12537014177476946, 'Total loss': 0.12537014177476946}
2022-12-31 05:44:10,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:10,725 INFO:     Epoch: 63
2022-12-31 05:44:12,346 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3725333847105503, 'Total loss': 0.3725333847105503} | train loss {'Reaction outcome loss': 0.1217126829607453, 'Total loss': 0.1217126829607453}
2022-12-31 05:44:12,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:12,347 INFO:     Epoch: 64
2022-12-31 05:44:13,967 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37330722361803054, 'Total loss': 0.37330722361803054} | train loss {'Reaction outcome loss': 0.1219843706748292, 'Total loss': 0.1219843706748292}
2022-12-31 05:44:13,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:13,967 INFO:     Epoch: 65
2022-12-31 05:44:15,588 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37845114171504973, 'Total loss': 0.37845114171504973} | train loss {'Reaction outcome loss': 0.12224717906346531, 'Total loss': 0.12224717906346531}
2022-12-31 05:44:15,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:15,589 INFO:     Epoch: 66
2022-12-31 05:44:17,208 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3666213189562162, 'Total loss': 0.3666213189562162} | train loss {'Reaction outcome loss': 0.12256569510672487, 'Total loss': 0.12256569510672487}
2022-12-31 05:44:17,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:17,209 INFO:     Epoch: 67
2022-12-31 05:44:18,823 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.377897987763087, 'Total loss': 0.377897987763087} | train loss {'Reaction outcome loss': 0.1193914266768843, 'Total loss': 0.1193914266768843}
2022-12-31 05:44:18,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:18,823 INFO:     Epoch: 68
2022-12-31 05:44:20,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3627523382504781, 'Total loss': 0.3627523382504781} | train loss {'Reaction outcome loss': 0.1174079840042608, 'Total loss': 0.1174079840042608}
2022-12-31 05:44:20,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:20,441 INFO:     Epoch: 69
2022-12-31 05:44:22,048 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3832882394393285, 'Total loss': 0.3832882394393285} | train loss {'Reaction outcome loss': 0.12011195373395119, 'Total loss': 0.12011195373395119}
2022-12-31 05:44:22,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:22,048 INFO:     Epoch: 70
2022-12-31 05:44:23,659 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42087651292483014, 'Total loss': 0.42087651292483014} | train loss {'Reaction outcome loss': 0.11868468886003387, 'Total loss': 0.11868468886003387}
2022-12-31 05:44:23,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:23,659 INFO:     Epoch: 71
2022-12-31 05:44:25,270 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42215555906295776, 'Total loss': 0.42215555906295776} | train loss {'Reaction outcome loss': 0.11904833524956973, 'Total loss': 0.11904833524956973}
2022-12-31 05:44:25,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:25,270 INFO:     Epoch: 72
2022-12-31 05:44:26,883 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37626813898483913, 'Total loss': 0.37626813898483913} | train loss {'Reaction outcome loss': 0.11845036242904998, 'Total loss': 0.11845036242904998}
2022-12-31 05:44:26,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:26,883 INFO:     Epoch: 73
2022-12-31 05:44:28,505 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3723285804192225, 'Total loss': 0.3723285804192225} | train loss {'Reaction outcome loss': 0.12340715378318934, 'Total loss': 0.12340715378318934}
2022-12-31 05:44:28,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:28,505 INFO:     Epoch: 74
2022-12-31 05:44:30,136 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3504132375121117, 'Total loss': 0.3504132375121117} | train loss {'Reaction outcome loss': 0.1175175156464705, 'Total loss': 0.1175175156464705}
2022-12-31 05:44:30,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:30,136 INFO:     Epoch: 75
2022-12-31 05:44:31,760 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3804759293794632, 'Total loss': 0.3804759293794632} | train loss {'Reaction outcome loss': 0.1168714171941698, 'Total loss': 0.1168714171941698}
2022-12-31 05:44:31,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:31,761 INFO:     Epoch: 76
2022-12-31 05:44:33,383 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4381018752853076, 'Total loss': 0.4381018752853076} | train loss {'Reaction outcome loss': 0.11953103671829304, 'Total loss': 0.11953103671829304}
2022-12-31 05:44:33,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:33,383 INFO:     Epoch: 77
2022-12-31 05:44:35,003 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37256922423839567, 'Total loss': 0.37256922423839567} | train loss {'Reaction outcome loss': 0.11616656128708001, 'Total loss': 0.11616656128708001}
2022-12-31 05:44:35,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:35,004 INFO:     Epoch: 78
2022-12-31 05:44:36,635 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37511048316955564, 'Total loss': 0.37511048316955564} | train loss {'Reaction outcome loss': 0.11730712267610985, 'Total loss': 0.11730712267610985}
2022-12-31 05:44:36,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:36,635 INFO:     Epoch: 79
2022-12-31 05:44:38,242 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3982698112726212, 'Total loss': 0.3982698112726212} | train loss {'Reaction outcome loss': 0.11725691751148688, 'Total loss': 0.11725691751148688}
2022-12-31 05:44:38,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:38,243 INFO:     Epoch: 80
2022-12-31 05:44:39,845 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3618521054585775, 'Total loss': 0.3618521054585775} | train loss {'Reaction outcome loss': 0.1198397066620906, 'Total loss': 0.1198397066620906}
2022-12-31 05:44:39,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:39,846 INFO:     Epoch: 81
2022-12-31 05:44:41,454 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4124972879886627, 'Total loss': 0.4124972879886627} | train loss {'Reaction outcome loss': 0.11819178925616408, 'Total loss': 0.11819178925616408}
2022-12-31 05:44:41,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:41,454 INFO:     Epoch: 82
2022-12-31 05:44:43,107 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39757565160592395, 'Total loss': 0.39757565160592395} | train loss {'Reaction outcome loss': 0.11455960161848007, 'Total loss': 0.11455960161848007}
2022-12-31 05:44:43,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:43,107 INFO:     Epoch: 83
2022-12-31 05:44:44,760 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4098777659237385, 'Total loss': 0.4098777659237385} | train loss {'Reaction outcome loss': 0.11309119865610978, 'Total loss': 0.11309119865610978}
2022-12-31 05:44:44,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:44,761 INFO:     Epoch: 84
2022-12-31 05:44:46,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3514079064130783, 'Total loss': 0.3514079064130783} | train loss {'Reaction outcome loss': 0.11118673202649683, 'Total loss': 0.11118673202649683}
2022-12-31 05:44:46,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:46,365 INFO:     Epoch: 85
2022-12-31 05:44:48,006 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3849498222271601, 'Total loss': 0.3849498222271601} | train loss {'Reaction outcome loss': 0.116365500798884, 'Total loss': 0.116365500798884}
2022-12-31 05:44:48,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:48,007 INFO:     Epoch: 86
2022-12-31 05:44:49,616 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38190847424169383, 'Total loss': 0.38190847424169383} | train loss {'Reaction outcome loss': 0.1136606759391725, 'Total loss': 0.1136606759391725}
2022-12-31 05:44:49,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:49,617 INFO:     Epoch: 87
2022-12-31 05:44:51,269 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38349130352338157, 'Total loss': 0.38349130352338157} | train loss {'Reaction outcome loss': 0.11171871394744945, 'Total loss': 0.11171871394744945}
2022-12-31 05:44:51,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:51,270 INFO:     Epoch: 88
2022-12-31 05:44:52,880 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43030789991219837, 'Total loss': 0.43030789991219837} | train loss {'Reaction outcome loss': 0.11465260626095598, 'Total loss': 0.11465260626095598}
2022-12-31 05:44:52,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:52,880 INFO:     Epoch: 89
2022-12-31 05:44:54,509 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38162766421834626, 'Total loss': 0.38162766421834626} | train loss {'Reaction outcome loss': 0.10738312216122112, 'Total loss': 0.10738312216122112}
2022-12-31 05:44:54,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:54,510 INFO:     Epoch: 90
2022-12-31 05:44:56,119 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4086362736920516, 'Total loss': 0.4086362736920516} | train loss {'Reaction outcome loss': 0.10931154679299679, 'Total loss': 0.10931154679299679}
2022-12-31 05:44:56,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:56,119 INFO:     Epoch: 91
2022-12-31 05:44:57,747 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36736080539800847, 'Total loss': 0.36736080539800847} | train loss {'Reaction outcome loss': 0.11208943479497285, 'Total loss': 0.11208943479497285}
2022-12-31 05:44:57,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:57,747 INFO:     Epoch: 92
2022-12-31 05:44:59,369 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39515605916579566, 'Total loss': 0.39515605916579566} | train loss {'Reaction outcome loss': 0.11365643095728147, 'Total loss': 0.11365643095728147}
2022-12-31 05:44:59,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:44:59,369 INFO:     Epoch: 93
2022-12-31 05:45:00,992 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3681933758469919, 'Total loss': 0.3681933758469919} | train loss {'Reaction outcome loss': 0.11015320069030825, 'Total loss': 0.11015320069030825}
2022-12-31 05:45:00,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:00,992 INFO:     Epoch: 94
2022-12-31 05:45:02,614 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4193280190229416, 'Total loss': 0.4193280190229416} | train loss {'Reaction outcome loss': 0.11563579844655877, 'Total loss': 0.11563579844655877}
2022-12-31 05:45:02,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:02,614 INFO:     Epoch: 95
2022-12-31 05:45:04,226 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3910237361987432, 'Total loss': 0.3910237361987432} | train loss {'Reaction outcome loss': 0.11280999854750877, 'Total loss': 0.11280999854750877}
2022-12-31 05:45:04,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:04,226 INFO:     Epoch: 96
2022-12-31 05:45:05,846 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41133722563584646, 'Total loss': 0.41133722563584646} | train loss {'Reaction outcome loss': 0.10971945262493661, 'Total loss': 0.10971945262493661}
2022-12-31 05:45:05,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:05,847 INFO:     Epoch: 97
2022-12-31 05:45:07,460 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4029829025268555, 'Total loss': 0.4029829025268555} | train loss {'Reaction outcome loss': 0.10663985213295414, 'Total loss': 0.10663985213295414}
2022-12-31 05:45:07,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:07,461 INFO:     Epoch: 98
2022-12-31 05:45:09,081 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38863749442001183, 'Total loss': 0.38863749442001183} | train loss {'Reaction outcome loss': 0.11194385357462822, 'Total loss': 0.11194385357462822}
2022-12-31 05:45:09,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:09,081 INFO:     Epoch: 99
2022-12-31 05:45:10,702 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41310363411903384, 'Total loss': 0.41310363411903384} | train loss {'Reaction outcome loss': 0.10826829336090761, 'Total loss': 0.10826829336090761}
2022-12-31 05:45:10,702 INFO:     Best model found after epoch 15 of 100.
2022-12-31 05:45:10,702 INFO:   Done with stage: TRAINING
2022-12-31 05:45:10,702 INFO:   Starting stage: EVALUATION
2022-12-31 05:45:10,838 INFO:   Done with stage: EVALUATION
2022-12-31 05:45:10,838 INFO:   Leaving out SEQ value Fold_7
2022-12-31 05:45:10,851 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:45:10,851 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:45:11,487 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:45:11,487 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:45:11,557 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:45:11,557 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:45:11,557 INFO:     No hyperparam tuning for this model
2022-12-31 05:45:11,557 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:45:11,557 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:45:11,558 INFO:     None feature selector for col prot
2022-12-31 05:45:11,558 INFO:     None feature selector for col prot
2022-12-31 05:45:11,558 INFO:     None feature selector for col prot
2022-12-31 05:45:11,559 INFO:     None feature selector for col chem
2022-12-31 05:45:11,559 INFO:     None feature selector for col chem
2022-12-31 05:45:11,559 INFO:     None feature selector for col chem
2022-12-31 05:45:11,559 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:45:11,559 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:45:11,561 INFO:     Number of params in model 224011
2022-12-31 05:45:11,564 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:45:11,564 INFO:   Starting stage: TRAINING
2022-12-31 05:45:11,610 INFO:     Val loss before train {'Reaction outcome loss': 1.0442899386088054, 'Total loss': 1.0442899386088054}
2022-12-31 05:45:11,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:11,610 INFO:     Epoch: 0
2022-12-31 05:45:13,241 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5655378599961599, 'Total loss': 0.5655378599961599} | train loss {'Reaction outcome loss': 0.7830226065686149, 'Total loss': 0.7830226065686149}
2022-12-31 05:45:13,241 INFO:     Found new best model at epoch 0
2022-12-31 05:45:13,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:13,242 INFO:     Epoch: 1
2022-12-31 05:45:14,845 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4770840843518575, 'Total loss': 0.4770840843518575} | train loss {'Reaction outcome loss': 0.5058333247791241, 'Total loss': 0.5058333247791241}
2022-12-31 05:45:14,846 INFO:     Found new best model at epoch 1
2022-12-31 05:45:14,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:14,847 INFO:     Epoch: 2
2022-12-31 05:45:16,482 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4706750313440959, 'Total loss': 0.4706750313440959} | train loss {'Reaction outcome loss': 0.4447101612378211, 'Total loss': 0.4447101612378211}
2022-12-31 05:45:16,483 INFO:     Found new best model at epoch 2
2022-12-31 05:45:16,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:16,484 INFO:     Epoch: 3
2022-12-31 05:45:18,084 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.442768520116806, 'Total loss': 0.442768520116806} | train loss {'Reaction outcome loss': 0.4125420113984686, 'Total loss': 0.4125420113984686}
2022-12-31 05:45:18,084 INFO:     Found new best model at epoch 3
2022-12-31 05:45:18,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:18,085 INFO:     Epoch: 4
2022-12-31 05:45:19,687 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4293867960572243, 'Total loss': 0.4293867960572243} | train loss {'Reaction outcome loss': 0.3857661407903163, 'Total loss': 0.3857661407903163}
2022-12-31 05:45:19,687 INFO:     Found new best model at epoch 4
2022-12-31 05:45:19,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:19,689 INFO:     Epoch: 5
2022-12-31 05:45:21,291 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3992792179187139, 'Total loss': 0.3992792179187139} | train loss {'Reaction outcome loss': 0.3638152733282016, 'Total loss': 0.3638152733282016}
2022-12-31 05:45:21,291 INFO:     Found new best model at epoch 5
2022-12-31 05:45:21,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:21,292 INFO:     Epoch: 6
2022-12-31 05:45:22,893 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4270409941673279, 'Total loss': 0.4270409941673279} | train loss {'Reaction outcome loss': 0.34356193872590135, 'Total loss': 0.34356193872590135}
2022-12-31 05:45:22,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:22,893 INFO:     Epoch: 7
2022-12-31 05:45:24,533 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39262332022190094, 'Total loss': 0.39262332022190094} | train loss {'Reaction outcome loss': 0.32451897032939603, 'Total loss': 0.32451897032939603}
2022-12-31 05:45:24,533 INFO:     Found new best model at epoch 7
2022-12-31 05:45:24,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:24,534 INFO:     Epoch: 8
2022-12-31 05:45:26,139 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.401247305671374, 'Total loss': 0.401247305671374} | train loss {'Reaction outcome loss': 0.3088318434183615, 'Total loss': 0.3088318434183615}
2022-12-31 05:45:26,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:26,139 INFO:     Epoch: 9
2022-12-31 05:45:27,764 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40910491446654, 'Total loss': 0.40910491446654} | train loss {'Reaction outcome loss': 0.2918554590811042, 'Total loss': 0.2918554590811042}
2022-12-31 05:45:27,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:27,765 INFO:     Epoch: 10
2022-12-31 05:45:29,388 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3788500286638737, 'Total loss': 0.3788500286638737} | train loss {'Reaction outcome loss': 0.27989901333068407, 'Total loss': 0.27989901333068407}
2022-12-31 05:45:29,388 INFO:     Found new best model at epoch 10
2022-12-31 05:45:29,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:29,389 INFO:     Epoch: 11
2022-12-31 05:45:31,004 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38326897819836936, 'Total loss': 0.38326897819836936} | train loss {'Reaction outcome loss': 0.27034661056895326, 'Total loss': 0.27034661056895326}
2022-12-31 05:45:31,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:31,005 INFO:     Epoch: 12
2022-12-31 05:45:32,630 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3886725723743439, 'Total loss': 0.3886725723743439} | train loss {'Reaction outcome loss': 0.26058776266057126, 'Total loss': 0.26058776266057126}
2022-12-31 05:45:32,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:32,630 INFO:     Epoch: 13
2022-12-31 05:45:34,245 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3651060740152995, 'Total loss': 0.3651060740152995} | train loss {'Reaction outcome loss': 0.25250092922390377, 'Total loss': 0.25250092922390377}
2022-12-31 05:45:34,247 INFO:     Found new best model at epoch 13
2022-12-31 05:45:34,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:34,248 INFO:     Epoch: 14
2022-12-31 05:45:35,881 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3871846139431, 'Total loss': 0.3871846139431} | train loss {'Reaction outcome loss': 0.24356302919450903, 'Total loss': 0.24356302919450903}
2022-12-31 05:45:35,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:35,881 INFO:     Epoch: 15
2022-12-31 05:45:37,506 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.375117160876592, 'Total loss': 0.375117160876592} | train loss {'Reaction outcome loss': 0.23278381172431648, 'Total loss': 0.23278381172431648}
2022-12-31 05:45:37,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:37,507 INFO:     Epoch: 16
2022-12-31 05:45:39,130 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40188934008280436, 'Total loss': 0.40188934008280436} | train loss {'Reaction outcome loss': 0.22577829012837614, 'Total loss': 0.22577829012837614}
2022-12-31 05:45:39,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:39,130 INFO:     Epoch: 17
2022-12-31 05:45:40,744 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38410281042257943, 'Total loss': 0.38410281042257943} | train loss {'Reaction outcome loss': 0.22390902087255551, 'Total loss': 0.22390902087255551}
2022-12-31 05:45:40,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:40,744 INFO:     Epoch: 18
2022-12-31 05:45:42,366 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41719953417778016, 'Total loss': 0.41719953417778016} | train loss {'Reaction outcome loss': 0.21404014920720654, 'Total loss': 0.21404014920720654}
2022-12-31 05:45:42,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:42,367 INFO:     Epoch: 19
2022-12-31 05:45:43,975 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39582593937714894, 'Total loss': 0.39582593937714894} | train loss {'Reaction outcome loss': 0.20748195356696192, 'Total loss': 0.20748195356696192}
2022-12-31 05:45:43,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:43,976 INFO:     Epoch: 20
2022-12-31 05:45:45,589 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4084116610387961, 'Total loss': 0.4084116610387961} | train loss {'Reaction outcome loss': 0.20286663310316794, 'Total loss': 0.20286663310316794}
2022-12-31 05:45:45,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:45,590 INFO:     Epoch: 21
2022-12-31 05:45:47,247 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39400114317735035, 'Total loss': 0.39400114317735035} | train loss {'Reaction outcome loss': 0.1998090906286218, 'Total loss': 0.1998090906286218}
2022-12-31 05:45:47,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:47,247 INFO:     Epoch: 22
2022-12-31 05:45:48,855 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42928639849027, 'Total loss': 0.42928639849027} | train loss {'Reaction outcome loss': 0.18714298967979032, 'Total loss': 0.18714298967979032}
2022-12-31 05:45:48,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:48,855 INFO:     Epoch: 23
2022-12-31 05:45:50,508 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38488237957159677, 'Total loss': 0.38488237957159677} | train loss {'Reaction outcome loss': 0.18890250111882487, 'Total loss': 0.18890250111882487}
2022-12-31 05:45:50,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:50,508 INFO:     Epoch: 24
2022-12-31 05:45:52,119 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39020413955052696, 'Total loss': 0.39020413955052696} | train loss {'Reaction outcome loss': 0.1840103209107081, 'Total loss': 0.1840103209107081}
2022-12-31 05:45:52,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:52,119 INFO:     Epoch: 25
2022-12-31 05:45:53,773 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4047796164949735, 'Total loss': 0.4047796164949735} | train loss {'Reaction outcome loss': 0.17997865917936076, 'Total loss': 0.17997865917936076}
2022-12-31 05:45:53,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:53,773 INFO:     Epoch: 26
2022-12-31 05:45:55,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3803809642791748, 'Total loss': 0.3803809642791748} | train loss {'Reaction outcome loss': 0.17697995681533196, 'Total loss': 0.17697995681533196}
2022-12-31 05:45:55,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:55,382 INFO:     Epoch: 27
2022-12-31 05:45:57,034 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39544698397318523, 'Total loss': 0.39544698397318523} | train loss {'Reaction outcome loss': 0.1711145920175923, 'Total loss': 0.1711145920175923}
2022-12-31 05:45:57,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:57,035 INFO:     Epoch: 28
2022-12-31 05:45:58,641 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40184664328893027, 'Total loss': 0.40184664328893027} | train loss {'Reaction outcome loss': 0.16918947938217843, 'Total loss': 0.16918947938217843}
2022-12-31 05:45:58,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:45:58,642 INFO:     Epoch: 29
2022-12-31 05:46:00,294 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4152292067805926, 'Total loss': 0.4152292067805926} | train loss {'Reaction outcome loss': 0.16544793352117612, 'Total loss': 0.16544793352117612}
2022-12-31 05:46:00,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:00,294 INFO:     Epoch: 30
2022-12-31 05:46:01,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42298852403958637, 'Total loss': 0.42298852403958637} | train loss {'Reaction outcome loss': 0.16263465027929874, 'Total loss': 0.16263465027929874}
2022-12-31 05:46:01,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:01,925 INFO:     Epoch: 31
2022-12-31 05:46:03,561 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37484224041303, 'Total loss': 0.37484224041303} | train loss {'Reaction outcome loss': 0.16007341993088922, 'Total loss': 0.16007341993088922}
2022-12-31 05:46:03,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:03,562 INFO:     Epoch: 32
2022-12-31 05:46:05,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3847798297802607, 'Total loss': 0.3847798297802607} | train loss {'Reaction outcome loss': 0.1573229376634542, 'Total loss': 0.1573229376634542}
2022-12-31 05:46:05,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:05,196 INFO:     Epoch: 33
2022-12-31 05:46:06,827 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40301647583643596, 'Total loss': 0.40301647583643596} | train loss {'Reaction outcome loss': 0.15166181885385818, 'Total loss': 0.15166181885385818}
2022-12-31 05:46:06,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:06,827 INFO:     Epoch: 34
2022-12-31 05:46:08,446 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40473852803309757, 'Total loss': 0.40473852803309757} | train loss {'Reaction outcome loss': 0.15707134719713706, 'Total loss': 0.15707134719713706}
2022-12-31 05:46:08,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:08,448 INFO:     Epoch: 35
2022-12-31 05:46:10,067 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4038540561993917, 'Total loss': 0.4038540561993917} | train loss {'Reaction outcome loss': 0.15140529371369765, 'Total loss': 0.15140529371369765}
2022-12-31 05:46:10,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:10,067 INFO:     Epoch: 36
2022-12-31 05:46:11,721 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4245753675699234, 'Total loss': 0.4245753675699234} | train loss {'Reaction outcome loss': 0.1492936066351831, 'Total loss': 0.1492936066351831}
2022-12-31 05:46:11,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:11,721 INFO:     Epoch: 37
2022-12-31 05:46:13,373 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38966584677497546, 'Total loss': 0.38966584677497546} | train loss {'Reaction outcome loss': 0.14576366402711854, 'Total loss': 0.14576366402711854}
2022-12-31 05:46:13,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:13,374 INFO:     Epoch: 38
2022-12-31 05:46:14,977 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38718149786194167, 'Total loss': 0.38718149786194167} | train loss {'Reaction outcome loss': 0.14427613317422625, 'Total loss': 0.14427613317422625}
2022-12-31 05:46:14,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:14,978 INFO:     Epoch: 39
2022-12-31 05:46:16,586 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3782711545626322, 'Total loss': 0.3782711545626322} | train loss {'Reaction outcome loss': 0.14297260398072373, 'Total loss': 0.14297260398072373}
2022-12-31 05:46:16,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:16,586 INFO:     Epoch: 40
2022-12-31 05:46:18,238 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4208565135796865, 'Total loss': 0.4208565135796865} | train loss {'Reaction outcome loss': 0.14498387211185954, 'Total loss': 0.14498387211185954}
2022-12-31 05:46:18,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:18,238 INFO:     Epoch: 41
2022-12-31 05:46:19,862 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39891924560070036, 'Total loss': 0.39891924560070036} | train loss {'Reaction outcome loss': 0.14304017871074434, 'Total loss': 0.14304017871074434}
2022-12-31 05:46:19,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:19,862 INFO:     Epoch: 42
2022-12-31 05:46:21,468 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39221921761830647, 'Total loss': 0.39221921761830647} | train loss {'Reaction outcome loss': 0.1360603377671681, 'Total loss': 0.1360603377671681}
2022-12-31 05:46:21,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:21,468 INFO:     Epoch: 43
2022-12-31 05:46:23,075 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41452459096908567, 'Total loss': 0.41452459096908567} | train loss {'Reaction outcome loss': 0.136441866122866, 'Total loss': 0.136441866122866}
2022-12-31 05:46:23,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:23,075 INFO:     Epoch: 44
2022-12-31 05:46:24,723 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3975196386377017, 'Total loss': 0.3975196386377017} | train loss {'Reaction outcome loss': 0.1377618068261548, 'Total loss': 0.1377618068261548}
2022-12-31 05:46:24,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:24,723 INFO:     Epoch: 45
2022-12-31 05:46:26,106 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4229155411322912, 'Total loss': 0.4229155411322912} | train loss {'Reaction outcome loss': 0.14030173830993908, 'Total loss': 0.14030173830993908}
2022-12-31 05:46:26,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:26,106 INFO:     Epoch: 46
2022-12-31 05:46:27,229 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3780420541763306, 'Total loss': 0.3780420541763306} | train loss {'Reaction outcome loss': 0.13374775166990385, 'Total loss': 0.13374775166990385}
2022-12-31 05:46:27,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:27,230 INFO:     Epoch: 47
2022-12-31 05:46:28,505 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3955164181689421, 'Total loss': 0.3955164181689421} | train loss {'Reaction outcome loss': 0.13072789116613023, 'Total loss': 0.13072789116613023}
2022-12-31 05:46:28,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:28,505 INFO:     Epoch: 48
2022-12-31 05:46:29,631 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3949104865392049, 'Total loss': 0.3949104865392049} | train loss {'Reaction outcome loss': 0.13129286788723493, 'Total loss': 0.13129286788723493}
2022-12-31 05:46:29,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:29,631 INFO:     Epoch: 49
2022-12-31 05:46:31,098 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38911083539326985, 'Total loss': 0.38911083539326985} | train loss {'Reaction outcome loss': 0.13214461956968546, 'Total loss': 0.13214461956968546}
2022-12-31 05:46:31,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:31,099 INFO:     Epoch: 50
2022-12-31 05:46:32,750 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3943796883026759, 'Total loss': 0.3943796883026759} | train loss {'Reaction outcome loss': 0.12957309013365148, 'Total loss': 0.12957309013365148}
2022-12-31 05:46:32,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:32,750 INFO:     Epoch: 51
2022-12-31 05:46:34,402 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4080965692798297, 'Total loss': 0.4080965692798297} | train loss {'Reaction outcome loss': 0.12687781585353244, 'Total loss': 0.12687781585353244}
2022-12-31 05:46:34,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:34,403 INFO:     Epoch: 52
2022-12-31 05:46:36,018 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3745373328526815, 'Total loss': 0.3745373328526815} | train loss {'Reaction outcome loss': 0.1250202034848205, 'Total loss': 0.1250202034848205}
2022-12-31 05:46:36,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:36,018 INFO:     Epoch: 53
2022-12-31 05:46:37,624 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41761163373788196, 'Total loss': 0.41761163373788196} | train loss {'Reaction outcome loss': 0.12516921738257808, 'Total loss': 0.12516921738257808}
2022-12-31 05:46:37,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:37,624 INFO:     Epoch: 54
2022-12-31 05:46:39,232 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3779609327514966, 'Total loss': 0.3779609327514966} | train loss {'Reaction outcome loss': 0.12784989825347914, 'Total loss': 0.12784989825347914}
2022-12-31 05:46:39,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:39,233 INFO:     Epoch: 55
2022-12-31 05:46:40,862 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40899890114863713, 'Total loss': 0.40899890114863713} | train loss {'Reaction outcome loss': 0.12675542824894842, 'Total loss': 0.12675542824894842}
2022-12-31 05:46:40,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:40,862 INFO:     Epoch: 56
2022-12-31 05:46:42,469 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38911053240299226, 'Total loss': 0.38911053240299226} | train loss {'Reaction outcome loss': 0.1279393227883091, 'Total loss': 0.1279393227883091}
2022-12-31 05:46:42,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:42,469 INFO:     Epoch: 57
2022-12-31 05:46:44,074 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3854732528328896, 'Total loss': 0.3854732528328896} | train loss {'Reaction outcome loss': 0.12210994617789168, 'Total loss': 0.12210994617789168}
2022-12-31 05:46:44,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:44,075 INFO:     Epoch: 58
2022-12-31 05:46:45,695 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41119414071242016, 'Total loss': 0.41119414071242016} | train loss {'Reaction outcome loss': 0.12239290955714392, 'Total loss': 0.12239290955714392}
2022-12-31 05:46:45,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:45,696 INFO:     Epoch: 59
2022-12-31 05:46:47,344 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3749815637866656, 'Total loss': 0.3749815637866656} | train loss {'Reaction outcome loss': 0.11938318242335923, 'Total loss': 0.11938318242335923}
2022-12-31 05:46:47,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:47,344 INFO:     Epoch: 60
2022-12-31 05:46:48,954 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3597625116507212, 'Total loss': 0.3597625116507212} | train loss {'Reaction outcome loss': 0.11889387324221269, 'Total loss': 0.11889387324221269}
2022-12-31 05:46:48,954 INFO:     Found new best model at epoch 60
2022-12-31 05:46:48,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:48,955 INFO:     Epoch: 61
2022-12-31 05:46:50,562 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37379548077781993, 'Total loss': 0.37379548077781993} | train loss {'Reaction outcome loss': 0.12376315295730249, 'Total loss': 0.12376315295730249}
2022-12-31 05:46:50,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:50,562 INFO:     Epoch: 62
2022-12-31 05:46:52,168 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40720488627751666, 'Total loss': 0.40720488627751666} | train loss {'Reaction outcome loss': 0.12092912462404011, 'Total loss': 0.12092912462404011}
2022-12-31 05:46:52,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:52,168 INFO:     Epoch: 63
2022-12-31 05:46:53,773 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39288152505954105, 'Total loss': 0.39288152505954105} | train loss {'Reaction outcome loss': 0.12271927678311774, 'Total loss': 0.12271927678311774}
2022-12-31 05:46:53,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:53,773 INFO:     Epoch: 64
2022-12-31 05:46:55,373 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3886045893033346, 'Total loss': 0.3886045893033346} | train loss {'Reaction outcome loss': 0.12120989473013166, 'Total loss': 0.12120989473013166}
2022-12-31 05:46:55,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:55,373 INFO:     Epoch: 65
2022-12-31 05:46:56,986 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3758325616518656, 'Total loss': 0.3758325616518656} | train loss {'Reaction outcome loss': 0.1155400036623443, 'Total loss': 0.1155400036623443}
2022-12-31 05:46:56,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:56,986 INFO:     Epoch: 66
2022-12-31 05:46:58,586 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37706728478272755, 'Total loss': 0.37706728478272755} | train loss {'Reaction outcome loss': 0.11972490926681045, 'Total loss': 0.11972490926681045}
2022-12-31 05:46:58,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:46:58,587 INFO:     Epoch: 67
2022-12-31 05:47:00,197 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34285578479369483, 'Total loss': 0.34285578479369483} | train loss {'Reaction outcome loss': 0.1161347272539049, 'Total loss': 0.1161347272539049}
2022-12-31 05:47:00,197 INFO:     Found new best model at epoch 67
2022-12-31 05:47:00,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:00,199 INFO:     Epoch: 68
2022-12-31 05:47:01,807 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38672084907690685, 'Total loss': 0.38672084907690685} | train loss {'Reaction outcome loss': 0.1168351548581119, 'Total loss': 0.1168351548581119}
2022-12-31 05:47:01,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:01,807 INFO:     Epoch: 69
2022-12-31 05:47:03,406 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37503252973159157, 'Total loss': 0.37503252973159157} | train loss {'Reaction outcome loss': 0.11827567065930007, 'Total loss': 0.11827567065930007}
2022-12-31 05:47:03,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:03,407 INFO:     Epoch: 70
2022-12-31 05:47:05,011 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.398421677450339, 'Total loss': 0.398421677450339} | train loss {'Reaction outcome loss': 0.1158862144084661, 'Total loss': 0.1158862144084661}
2022-12-31 05:47:05,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:05,011 INFO:     Epoch: 71
2022-12-31 05:47:06,646 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3824986290962746, 'Total loss': 0.3824986290962746} | train loss {'Reaction outcome loss': 0.11404304262284652, 'Total loss': 0.11404304262284652}
2022-12-31 05:47:06,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:06,647 INFO:     Epoch: 72
2022-12-31 05:47:08,299 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39584625312127175, 'Total loss': 0.39584625312127175} | train loss {'Reaction outcome loss': 0.11471166248929544, 'Total loss': 0.11471166248929544}
2022-12-31 05:47:08,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:08,299 INFO:     Epoch: 73
2022-12-31 05:47:09,905 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4063080072402954, 'Total loss': 0.4063080072402954} | train loss {'Reaction outcome loss': 0.12275695085889204, 'Total loss': 0.12275695085889204}
2022-12-31 05:47:09,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:09,906 INFO:     Epoch: 74
2022-12-31 05:47:11,509 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38347310622533165, 'Total loss': 0.38347310622533165} | train loss {'Reaction outcome loss': 0.11976378236856502, 'Total loss': 0.11976378236856502}
2022-12-31 05:47:11,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:11,509 INFO:     Epoch: 75
2022-12-31 05:47:13,149 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4022368083397547, 'Total loss': 0.4022368083397547} | train loss {'Reaction outcome loss': 0.11504303502942007, 'Total loss': 0.11504303502942007}
2022-12-31 05:47:13,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:13,149 INFO:     Epoch: 76
2022-12-31 05:47:14,800 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37702497839927673, 'Total loss': 0.37702497839927673} | train loss {'Reaction outcome loss': 0.11025108878813467, 'Total loss': 0.11025108878813467}
2022-12-31 05:47:14,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:14,801 INFO:     Epoch: 77
2022-12-31 05:47:16,407 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36504384080568947, 'Total loss': 0.36504384080568947} | train loss {'Reaction outcome loss': 0.1134359396137569, 'Total loss': 0.1134359396137569}
2022-12-31 05:47:16,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:16,408 INFO:     Epoch: 78
2022-12-31 05:47:18,024 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38785646483302116, 'Total loss': 0.38785646483302116} | train loss {'Reaction outcome loss': 0.11525319140050969, 'Total loss': 0.11525319140050969}
2022-12-31 05:47:18,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:18,025 INFO:     Epoch: 79
2022-12-31 05:47:19,639 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42123002260923387, 'Total loss': 0.42123002260923387} | train loss {'Reaction outcome loss': 0.1130656736229893, 'Total loss': 0.1130656736229893}
2022-12-31 05:47:19,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:19,639 INFO:     Epoch: 80
2022-12-31 05:47:21,242 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3856858655810356, 'Total loss': 0.3856858655810356} | train loss {'Reaction outcome loss': 0.11214603051240726, 'Total loss': 0.11214603051240726}
2022-12-31 05:47:21,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:21,242 INFO:     Epoch: 81
2022-12-31 05:47:22,841 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4032890816529592, 'Total loss': 0.4032890816529592} | train loss {'Reaction outcome loss': 0.11042423702497715, 'Total loss': 0.11042423702497715}
2022-12-31 05:47:22,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:22,841 INFO:     Epoch: 82
2022-12-31 05:47:24,446 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38513335982958474, 'Total loss': 0.38513335982958474} | train loss {'Reaction outcome loss': 0.11202744372957216, 'Total loss': 0.11202744372957216}
2022-12-31 05:47:24,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:24,446 INFO:     Epoch: 83
2022-12-31 05:47:26,062 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4032593150933584, 'Total loss': 0.4032593150933584} | train loss {'Reaction outcome loss': 0.11549207793351562, 'Total loss': 0.11549207793351562}
2022-12-31 05:47:26,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:26,062 INFO:     Epoch: 84
2022-12-31 05:47:27,684 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3868898363783956, 'Total loss': 0.3868898363783956} | train loss {'Reaction outcome loss': 0.11568793444724305, 'Total loss': 0.11568793444724305}
2022-12-31 05:47:27,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:27,684 INFO:     Epoch: 85
2022-12-31 05:47:29,306 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4092995097239812, 'Total loss': 0.4092995097239812} | train loss {'Reaction outcome loss': 0.11789778632835832, 'Total loss': 0.11789778632835832}
2022-12-31 05:47:29,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:29,307 INFO:     Epoch: 86
2022-12-31 05:47:30,916 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40782613555590314, 'Total loss': 0.40782613555590314} | train loss {'Reaction outcome loss': 0.10904448210724024, 'Total loss': 0.10904448210724024}
2022-12-31 05:47:30,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:30,916 INFO:     Epoch: 87
2022-12-31 05:47:32,537 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3878575459122658, 'Total loss': 0.3878575459122658} | train loss {'Reaction outcome loss': 0.10846065290707306, 'Total loss': 0.10846065290707306}
2022-12-31 05:47:32,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:32,538 INFO:     Epoch: 88
2022-12-31 05:47:34,151 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.402672153711319, 'Total loss': 0.402672153711319} | train loss {'Reaction outcome loss': 0.1039882631042809, 'Total loss': 0.1039882631042809}
2022-12-31 05:47:34,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:34,151 INFO:     Epoch: 89
2022-12-31 05:47:35,804 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4059531177083651, 'Total loss': 0.4059531177083651} | train loss {'Reaction outcome loss': 0.10429445754254006, 'Total loss': 0.10429445754254006}
2022-12-31 05:47:35,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:35,804 INFO:     Epoch: 90
2022-12-31 05:47:37,455 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41754571398099266, 'Total loss': 0.41754571398099266} | train loss {'Reaction outcome loss': 0.10607500174881578, 'Total loss': 0.10607500174881578}
2022-12-31 05:47:37,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:37,455 INFO:     Epoch: 91
2022-12-31 05:47:39,108 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3835621081913511, 'Total loss': 0.3835621081913511} | train loss {'Reaction outcome loss': 0.11118632211880147, 'Total loss': 0.11118632211880147}
2022-12-31 05:47:39,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:39,108 INFO:     Epoch: 92
2022-12-31 05:47:40,747 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4150919099648794, 'Total loss': 0.4150919099648794} | train loss {'Reaction outcome loss': 0.11170478069468191, 'Total loss': 0.11170478069468191}
2022-12-31 05:47:40,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:40,748 INFO:     Epoch: 93
2022-12-31 05:47:42,353 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40256635944048563, 'Total loss': 0.40256635944048563} | train loss {'Reaction outcome loss': 0.10646498998003352, 'Total loss': 0.10646498998003352}
2022-12-31 05:47:42,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:42,353 INFO:     Epoch: 94
2022-12-31 05:47:43,992 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38586037456989286, 'Total loss': 0.38586037456989286} | train loss {'Reaction outcome loss': 0.10825504862064374, 'Total loss': 0.10825504862064374}
2022-12-31 05:47:43,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:43,992 INFO:     Epoch: 95
2022-12-31 05:47:45,645 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45015183289845784, 'Total loss': 0.45015183289845784} | train loss {'Reaction outcome loss': 0.10653741862522914, 'Total loss': 0.10653741862522914}
2022-12-31 05:47:45,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:45,645 INFO:     Epoch: 96
2022-12-31 05:47:47,248 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41940827667713165, 'Total loss': 0.41940827667713165} | train loss {'Reaction outcome loss': 0.10813340198428771, 'Total loss': 0.10813340198428771}
2022-12-31 05:47:47,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:47,249 INFO:     Epoch: 97
2022-12-31 05:47:48,849 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41109016773601376, 'Total loss': 0.41109016773601376} | train loss {'Reaction outcome loss': 0.1137968715939698, 'Total loss': 0.1137968715939698}
2022-12-31 05:47:48,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:48,849 INFO:     Epoch: 98
2022-12-31 05:47:50,468 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39939235945542656, 'Total loss': 0.39939235945542656} | train loss {'Reaction outcome loss': 0.10260849656965447, 'Total loss': 0.10260849656965447}
2022-12-31 05:47:50,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:50,469 INFO:     Epoch: 99
2022-12-31 05:47:52,087 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38342621028423307, 'Total loss': 0.38342621028423307} | train loss {'Reaction outcome loss': 0.10447847599972611, 'Total loss': 0.10447847599972611}
2022-12-31 05:47:52,087 INFO:     Best model found after epoch 68 of 100.
2022-12-31 05:47:52,087 INFO:   Done with stage: TRAINING
2022-12-31 05:47:52,087 INFO:   Starting stage: EVALUATION
2022-12-31 05:47:52,222 INFO:   Done with stage: EVALUATION
2022-12-31 05:47:52,222 INFO:   Leaving out SEQ value Fold_8
2022-12-31 05:47:52,235 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 05:47:52,235 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:47:52,878 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:47:52,878 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:47:52,949 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:47:52,949 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:47:52,949 INFO:     No hyperparam tuning for this model
2022-12-31 05:47:52,949 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:47:52,949 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:47:52,950 INFO:     None feature selector for col prot
2022-12-31 05:47:52,950 INFO:     None feature selector for col prot
2022-12-31 05:47:52,950 INFO:     None feature selector for col prot
2022-12-31 05:47:52,951 INFO:     None feature selector for col chem
2022-12-31 05:47:52,951 INFO:     None feature selector for col chem
2022-12-31 05:47:52,951 INFO:     None feature selector for col chem
2022-12-31 05:47:52,951 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:47:52,951 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:47:52,953 INFO:     Number of params in model 224011
2022-12-31 05:47:52,956 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:47:52,956 INFO:   Starting stage: TRAINING
2022-12-31 05:47:53,001 INFO:     Val loss before train {'Reaction outcome loss': 0.8644592483838399, 'Total loss': 0.8644592483838399}
2022-12-31 05:47:53,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:53,001 INFO:     Epoch: 0
2022-12-31 05:47:54,626 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48930843770503996, 'Total loss': 0.48930843770503996} | train loss {'Reaction outcome loss': 0.7896974145935761, 'Total loss': 0.7896974145935761}
2022-12-31 05:47:54,626 INFO:     Found new best model at epoch 0
2022-12-31 05:47:54,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:54,627 INFO:     Epoch: 1
2022-12-31 05:47:56,251 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4395727634429932, 'Total loss': 0.4395727634429932} | train loss {'Reaction outcome loss': 0.525945712297832, 'Total loss': 0.525945712297832}
2022-12-31 05:47:56,251 INFO:     Found new best model at epoch 1
2022-12-31 05:47:56,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:56,252 INFO:     Epoch: 2
2022-12-31 05:47:57,887 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.3957196633021037, 'Total loss': 0.3957196633021037} | train loss {'Reaction outcome loss': 0.4524631786432507, 'Total loss': 0.4524631786432507}
2022-12-31 05:47:57,887 INFO:     Found new best model at epoch 2
2022-12-31 05:47:57,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:57,888 INFO:     Epoch: 3
2022-12-31 05:47:59,517 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3844073663155238, 'Total loss': 0.3844073663155238} | train loss {'Reaction outcome loss': 0.40904815172245357, 'Total loss': 0.40904815172245357}
2022-12-31 05:47:59,518 INFO:     Found new best model at epoch 3
2022-12-31 05:47:59,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:47:59,519 INFO:     Epoch: 4
2022-12-31 05:48:01,136 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.38172484437624615, 'Total loss': 0.38172484437624615} | train loss {'Reaction outcome loss': 0.3776160294075735, 'Total loss': 0.3776160294075735}
2022-12-31 05:48:01,136 INFO:     Found new best model at epoch 4
2022-12-31 05:48:01,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:01,137 INFO:     Epoch: 5
2022-12-31 05:48:02,762 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.37240964074929556, 'Total loss': 0.37240964074929556} | train loss {'Reaction outcome loss': 0.34991283825050623, 'Total loss': 0.34991283825050623}
2022-12-31 05:48:02,762 INFO:     Found new best model at epoch 5
2022-12-31 05:48:02,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:02,763 INFO:     Epoch: 6
2022-12-31 05:48:04,388 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.36483464141686756, 'Total loss': 0.36483464141686756} | train loss {'Reaction outcome loss': 0.3331651653731343, 'Total loss': 0.3331651653731343}
2022-12-31 05:48:04,388 INFO:     Found new best model at epoch 6
2022-12-31 05:48:04,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:04,389 INFO:     Epoch: 7
2022-12-31 05:48:06,009 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37426893909772235, 'Total loss': 0.37426893909772235} | train loss {'Reaction outcome loss': 0.3143495436932636, 'Total loss': 0.3143495436932636}
2022-12-31 05:48:06,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:06,009 INFO:     Epoch: 8
2022-12-31 05:48:07,646 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3641525795062383, 'Total loss': 0.3641525795062383} | train loss {'Reaction outcome loss': 0.29568599678226326, 'Total loss': 0.29568599678226326}
2022-12-31 05:48:07,647 INFO:     Found new best model at epoch 8
2022-12-31 05:48:07,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:07,648 INFO:     Epoch: 9
2022-12-31 05:48:09,281 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4020909368991852, 'Total loss': 0.4020909368991852} | train loss {'Reaction outcome loss': 0.2846060298679107, 'Total loss': 0.2846060298679107}
2022-12-31 05:48:09,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:09,281 INFO:     Epoch: 10
2022-12-31 05:48:10,924 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35713268220424654, 'Total loss': 0.35713268220424654} | train loss {'Reaction outcome loss': 0.2732127765428934, 'Total loss': 0.2732127765428934}
2022-12-31 05:48:10,925 INFO:     Found new best model at epoch 10
2022-12-31 05:48:10,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:10,926 INFO:     Epoch: 11
2022-12-31 05:48:12,596 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3407864431540171, 'Total loss': 0.3407864431540171} | train loss {'Reaction outcome loss': 0.2622470711273837, 'Total loss': 0.2622470711273837}
2022-12-31 05:48:12,597 INFO:     Found new best model at epoch 11
2022-12-31 05:48:12,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:12,598 INFO:     Epoch: 12
2022-12-31 05:48:14,218 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3666032041112582, 'Total loss': 0.3666032041112582} | train loss {'Reaction outcome loss': 0.2508865681339042, 'Total loss': 0.2508865681339042}
2022-12-31 05:48:14,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:14,218 INFO:     Epoch: 13
2022-12-31 05:48:15,836 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.34089499910672505, 'Total loss': 0.34089499910672505} | train loss {'Reaction outcome loss': 0.24076369313341617, 'Total loss': 0.24076369313341617}
2022-12-31 05:48:15,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:15,836 INFO:     Epoch: 14
2022-12-31 05:48:17,472 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37107093036174776, 'Total loss': 0.37107093036174776} | train loss {'Reaction outcome loss': 0.23495258206656264, 'Total loss': 0.23495258206656264}
2022-12-31 05:48:17,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:17,473 INFO:     Epoch: 15
2022-12-31 05:48:19,102 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38453434507052103, 'Total loss': 0.38453434507052103} | train loss {'Reaction outcome loss': 0.2261118090002115, 'Total loss': 0.2261118090002115}
2022-12-31 05:48:19,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:19,103 INFO:     Epoch: 16
2022-12-31 05:48:20,726 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3686324067413807, 'Total loss': 0.3686324067413807} | train loss {'Reaction outcome loss': 0.2229925248274304, 'Total loss': 0.2229925248274304}
2022-12-31 05:48:20,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:20,726 INFO:     Epoch: 17
2022-12-31 05:48:22,397 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36516605218251547, 'Total loss': 0.36516605218251547} | train loss {'Reaction outcome loss': 0.21407199413633304, 'Total loss': 0.21407199413633304}
2022-12-31 05:48:22,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:22,397 INFO:     Epoch: 18
2022-12-31 05:48:24,028 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37917255659898125, 'Total loss': 0.37917255659898125} | train loss {'Reaction outcome loss': 0.20584643862146332, 'Total loss': 0.20584643862146332}
2022-12-31 05:48:24,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:24,028 INFO:     Epoch: 19
2022-12-31 05:48:25,662 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3747729524970055, 'Total loss': 0.3747729524970055} | train loss {'Reaction outcome loss': 0.20414057643647013, 'Total loss': 0.20414057643647013}
2022-12-31 05:48:25,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:25,662 INFO:     Epoch: 20
2022-12-31 05:48:27,297 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3687528130908807, 'Total loss': 0.3687528130908807} | train loss {'Reaction outcome loss': 0.20070023986675678, 'Total loss': 0.20070023986675678}
2022-12-31 05:48:27,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:27,297 INFO:     Epoch: 21
2022-12-31 05:48:28,926 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37094905177752174, 'Total loss': 0.37094905177752174} | train loss {'Reaction outcome loss': 0.1981270137421168, 'Total loss': 0.1981270137421168}
2022-12-31 05:48:28,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:28,926 INFO:     Epoch: 22
2022-12-31 05:48:30,562 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36710783938566843, 'Total loss': 0.36710783938566843} | train loss {'Reaction outcome loss': 0.1928481992825005, 'Total loss': 0.1928481992825005}
2022-12-31 05:48:30,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:30,563 INFO:     Epoch: 23
2022-12-31 05:48:32,205 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39069403111934664, 'Total loss': 0.39069403111934664} | train loss {'Reaction outcome loss': 0.18824333052692216, 'Total loss': 0.18824333052692216}
2022-12-31 05:48:32,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:32,205 INFO:     Epoch: 24
2022-12-31 05:48:33,841 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3731461892525355, 'Total loss': 0.3731461892525355} | train loss {'Reaction outcome loss': 0.1820184651489911, 'Total loss': 0.1820184651489911}
2022-12-31 05:48:33,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:33,841 INFO:     Epoch: 25
2022-12-31 05:48:35,476 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4079686592022578, 'Total loss': 0.4079686592022578} | train loss {'Reaction outcome loss': 0.17640994761529166, 'Total loss': 0.17640994761529166}
2022-12-31 05:48:35,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:35,477 INFO:     Epoch: 26
2022-12-31 05:48:37,111 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3536706417798996, 'Total loss': 0.3536706417798996} | train loss {'Reaction outcome loss': 0.17782933205124057, 'Total loss': 0.17782933205124057}
2022-12-31 05:48:37,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:37,111 INFO:     Epoch: 27
2022-12-31 05:48:38,741 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3652885893980662, 'Total loss': 0.3652885893980662} | train loss {'Reaction outcome loss': 0.1759907524521708, 'Total loss': 0.1759907524521708}
2022-12-31 05:48:38,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:38,741 INFO:     Epoch: 28
2022-12-31 05:48:40,413 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3789676696062088, 'Total loss': 0.3789676696062088} | train loss {'Reaction outcome loss': 0.16984458825809862, 'Total loss': 0.16984458825809862}
2022-12-31 05:48:40,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:40,414 INFO:     Epoch: 29
2022-12-31 05:48:42,047 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.401630495985349, 'Total loss': 0.401630495985349} | train loss {'Reaction outcome loss': 0.16766185812073817, 'Total loss': 0.16766185812073817}
2022-12-31 05:48:42,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:42,047 INFO:     Epoch: 30
2022-12-31 05:48:43,706 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38366620391607287, 'Total loss': 0.38366620391607287} | train loss {'Reaction outcome loss': 0.16662875707816024, 'Total loss': 0.16662875707816024}
2022-12-31 05:48:43,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:43,706 INFO:     Epoch: 31
2022-12-31 05:48:45,343 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38301802674929303, 'Total loss': 0.38301802674929303} | train loss {'Reaction outcome loss': 0.16208562157402615, 'Total loss': 0.16208562157402615}
2022-12-31 05:48:45,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:45,343 INFO:     Epoch: 32
2022-12-31 05:48:46,993 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3938012639681498, 'Total loss': 0.3938012639681498} | train loss {'Reaction outcome loss': 0.1601951363066124, 'Total loss': 0.1601951363066124}
2022-12-31 05:48:46,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:46,995 INFO:     Epoch: 33
2022-12-31 05:48:48,630 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38409724136193596, 'Total loss': 0.38409724136193596} | train loss {'Reaction outcome loss': 0.16133516505427847, 'Total loss': 0.16133516505427847}
2022-12-31 05:48:48,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:48,630 INFO:     Epoch: 34
2022-12-31 05:48:50,268 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39034564793109894, 'Total loss': 0.39034564793109894} | train loss {'Reaction outcome loss': 0.1549969148462376, 'Total loss': 0.1549969148462376}
2022-12-31 05:48:50,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:50,268 INFO:     Epoch: 35
2022-12-31 05:48:51,904 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3736964464187622, 'Total loss': 0.3736964464187622} | train loss {'Reaction outcome loss': 0.15811929370643107, 'Total loss': 0.15811929370643107}
2022-12-31 05:48:51,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:51,904 INFO:     Epoch: 36
2022-12-31 05:48:53,537 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39490964114665983, 'Total loss': 0.39490964114665983} | train loss {'Reaction outcome loss': 0.15052608555243333, 'Total loss': 0.15052608555243333}
2022-12-31 05:48:53,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:53,538 INFO:     Epoch: 37
2022-12-31 05:48:55,162 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42835914666453995, 'Total loss': 0.42835914666453995} | train loss {'Reaction outcome loss': 0.1512541609046315, 'Total loss': 0.1512541609046315}
2022-12-31 05:48:55,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:55,162 INFO:     Epoch: 38
2022-12-31 05:48:56,790 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36941764652729037, 'Total loss': 0.36941764652729037} | train loss {'Reaction outcome loss': 0.14821373064756824, 'Total loss': 0.14821373064756824}
2022-12-31 05:48:56,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:56,791 INFO:     Epoch: 39
2022-12-31 05:48:58,443 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38091398576895397, 'Total loss': 0.38091398576895397} | train loss {'Reaction outcome loss': 0.1500355754407385, 'Total loss': 0.1500355754407385}
2022-12-31 05:48:58,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:48:58,443 INFO:     Epoch: 40
2022-12-31 05:49:00,065 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38749690453211466, 'Total loss': 0.38749690453211466} | train loss {'Reaction outcome loss': 0.1488329921294313, 'Total loss': 0.1488329921294313}
2022-12-31 05:49:00,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:00,065 INFO:     Epoch: 41
2022-12-31 05:49:01,682 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38396923889716467, 'Total loss': 0.38396923889716467} | train loss {'Reaction outcome loss': 0.14283164174359844, 'Total loss': 0.14283164174359844}
2022-12-31 05:49:01,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:01,682 INFO:     Epoch: 42
2022-12-31 05:49:03,309 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3909520089626312, 'Total loss': 0.3909520089626312} | train loss {'Reaction outcome loss': 0.14179317229208857, 'Total loss': 0.14179317229208857}
2022-12-31 05:49:03,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:03,309 INFO:     Epoch: 43
2022-12-31 05:49:04,937 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39998894979556404, 'Total loss': 0.39998894979556404} | train loss {'Reaction outcome loss': 0.14424650992320628, 'Total loss': 0.14424650992320628}
2022-12-31 05:49:04,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:04,937 INFO:     Epoch: 44
2022-12-31 05:49:06,612 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37464775939782463, 'Total loss': 0.37464775939782463} | train loss {'Reaction outcome loss': 0.14095142891038787, 'Total loss': 0.14095142891038787}
2022-12-31 05:49:06,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:06,613 INFO:     Epoch: 45
2022-12-31 05:49:08,248 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3799949129422506, 'Total loss': 0.3799949129422506} | train loss {'Reaction outcome loss': 0.1392284412179075, 'Total loss': 0.1392284412179075}
2022-12-31 05:49:08,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:08,248 INFO:     Epoch: 46
2022-12-31 05:49:09,889 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40767535865306853, 'Total loss': 0.40767535865306853} | train loss {'Reaction outcome loss': 0.1402315903145699, 'Total loss': 0.1402315903145699}
2022-12-31 05:49:09,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:09,889 INFO:     Epoch: 47
2022-12-31 05:49:11,523 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3940950612227122, 'Total loss': 0.3940950612227122} | train loss {'Reaction outcome loss': 0.13368558405901873, 'Total loss': 0.13368558405901873}
2022-12-31 05:49:11,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:11,524 INFO:     Epoch: 48
2022-12-31 05:49:13,160 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3988479961951574, 'Total loss': 0.3988479961951574} | train loss {'Reaction outcome loss': 0.1362306534611899, 'Total loss': 0.1362306534611899}
2022-12-31 05:49:13,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:13,160 INFO:     Epoch: 49
2022-12-31 05:49:14,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.418268816669782, 'Total loss': 0.418268816669782} | train loss {'Reaction outcome loss': 0.13229637082988926, 'Total loss': 0.13229637082988926}
2022-12-31 05:49:14,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:14,795 INFO:     Epoch: 50
2022-12-31 05:49:16,428 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39302625209093095, 'Total loss': 0.39302625209093095} | train loss {'Reaction outcome loss': 0.13271238547598518, 'Total loss': 0.13271238547598518}
2022-12-31 05:49:16,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:16,428 INFO:     Epoch: 51
2022-12-31 05:49:18,067 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40640415201584495, 'Total loss': 0.40640415201584495} | train loss {'Reaction outcome loss': 0.13612519473926793, 'Total loss': 0.13612519473926793}
2022-12-31 05:49:18,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:18,068 INFO:     Epoch: 52
2022-12-31 05:49:19,699 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4063753848274549, 'Total loss': 0.4063753848274549} | train loss {'Reaction outcome loss': 0.13449136706385156, 'Total loss': 0.13449136706385156}
2022-12-31 05:49:19,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:19,699 INFO:     Epoch: 53
2022-12-31 05:49:21,373 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38573158234357835, 'Total loss': 0.38573158234357835} | train loss {'Reaction outcome loss': 0.12758162048130905, 'Total loss': 0.12758162048130905}
2022-12-31 05:49:21,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:21,373 INFO:     Epoch: 54
2022-12-31 05:49:23,006 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38767739981412885, 'Total loss': 0.38767739981412885} | train loss {'Reaction outcome loss': 0.12799825889078584, 'Total loss': 0.12799825889078584}
2022-12-31 05:49:23,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:23,006 INFO:     Epoch: 55
2022-12-31 05:49:24,639 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40823540737231573, 'Total loss': 0.40823540737231573} | train loss {'Reaction outcome loss': 0.1266051809965811, 'Total loss': 0.1266051809965811}
2022-12-31 05:49:24,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:24,640 INFO:     Epoch: 56
2022-12-31 05:49:26,278 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41135065257549286, 'Total loss': 0.41135065257549286} | train loss {'Reaction outcome loss': 0.13033109878455473, 'Total loss': 0.13033109878455473}
2022-12-31 05:49:26,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:26,278 INFO:     Epoch: 57
2022-12-31 05:49:27,916 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3726085379719734, 'Total loss': 0.3726085379719734} | train loss {'Reaction outcome loss': 0.12934657087758022, 'Total loss': 0.12934657087758022}
2022-12-31 05:49:27,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:27,916 INFO:     Epoch: 58
2022-12-31 05:49:29,545 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4051626920700073, 'Total loss': 0.4051626920700073} | train loss {'Reaction outcome loss': 0.12592876992870916, 'Total loss': 0.12592876992870916}
2022-12-31 05:49:29,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:29,545 INFO:     Epoch: 59
2022-12-31 05:49:31,190 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42162473797798156, 'Total loss': 0.42162473797798156} | train loss {'Reaction outcome loss': 0.129774779299886, 'Total loss': 0.129774779299886}
2022-12-31 05:49:31,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:31,190 INFO:     Epoch: 60
2022-12-31 05:49:32,830 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4010256135215362, 'Total loss': 0.4010256135215362} | train loss {'Reaction outcome loss': 0.12262962075347074, 'Total loss': 0.12262962075347074}
2022-12-31 05:49:32,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:32,831 INFO:     Epoch: 61
2022-12-31 05:49:34,465 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3770787172097092, 'Total loss': 0.3770787172097092} | train loss {'Reaction outcome loss': 0.12797339382120795, 'Total loss': 0.12797339382120795}
2022-12-31 05:49:34,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:34,465 INFO:     Epoch: 62
2022-12-31 05:49:36,089 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.418479589621226, 'Total loss': 0.418479589621226} | train loss {'Reaction outcome loss': 0.12429638963616335, 'Total loss': 0.12429638963616335}
2022-12-31 05:49:36,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:36,089 INFO:     Epoch: 63
2022-12-31 05:49:37,744 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.413341615597407, 'Total loss': 0.413341615597407} | train loss {'Reaction outcome loss': 0.12411856262470572, 'Total loss': 0.12411856262470572}
2022-12-31 05:49:37,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:37,745 INFO:     Epoch: 64
2022-12-31 05:49:39,379 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4078221847613653, 'Total loss': 0.4078221847613653} | train loss {'Reaction outcome loss': 0.12327950350967125, 'Total loss': 0.12327950350967125}
2022-12-31 05:49:39,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:39,379 INFO:     Epoch: 65
2022-12-31 05:49:41,012 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41463178594907124, 'Total loss': 0.41463178594907124} | train loss {'Reaction outcome loss': 0.1174285610623335, 'Total loss': 0.1174285610623335}
2022-12-31 05:49:41,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:41,012 INFO:     Epoch: 66
2022-12-31 05:49:42,663 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4032354146242142, 'Total loss': 0.4032354146242142} | train loss {'Reaction outcome loss': 0.12281662860838193, 'Total loss': 0.12281662860838193}
2022-12-31 05:49:42,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:42,664 INFO:     Epoch: 67
2022-12-31 05:49:44,288 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37552764465411503, 'Total loss': 0.37552764465411503} | train loss {'Reaction outcome loss': 0.12253626420865313, 'Total loss': 0.12253626420865313}
2022-12-31 05:49:44,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:44,288 INFO:     Epoch: 68
2022-12-31 05:49:45,957 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4016645977894465, 'Total loss': 0.4016645977894465} | train loss {'Reaction outcome loss': 0.12239443806306012, 'Total loss': 0.12239443806306012}
2022-12-31 05:49:45,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:45,958 INFO:     Epoch: 69
2022-12-31 05:49:47,639 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41594174802303313, 'Total loss': 0.41594174802303313} | train loss {'Reaction outcome loss': 0.1152535298005392, 'Total loss': 0.1152535298005392}
2022-12-31 05:49:47,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:47,639 INFO:     Epoch: 70
2022-12-31 05:49:49,264 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44864822874466576, 'Total loss': 0.44864822874466576} | train loss {'Reaction outcome loss': 0.12140480915440872, 'Total loss': 0.12140480915440872}
2022-12-31 05:49:49,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:49,266 INFO:     Epoch: 71
2022-12-31 05:49:50,893 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4009801236291726, 'Total loss': 0.4009801236291726} | train loss {'Reaction outcome loss': 0.12126654099558719, 'Total loss': 0.12126654099558719}
2022-12-31 05:49:50,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:50,894 INFO:     Epoch: 72
2022-12-31 05:49:52,518 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40507676055034003, 'Total loss': 0.40507676055034003} | train loss {'Reaction outcome loss': 0.11650546991841242, 'Total loss': 0.11650546991841242}
2022-12-31 05:49:52,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:52,519 INFO:     Epoch: 73
2022-12-31 05:49:54,142 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3999725619951884, 'Total loss': 0.3999725619951884} | train loss {'Reaction outcome loss': 0.12018290966150724, 'Total loss': 0.12018290966150724}
2022-12-31 05:49:54,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:54,143 INFO:     Epoch: 74
2022-12-31 05:49:55,766 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40746655662854514, 'Total loss': 0.40746655662854514} | train loss {'Reaction outcome loss': 0.11959047105990431, 'Total loss': 0.11959047105990431}
2022-12-31 05:49:55,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:55,766 INFO:     Epoch: 75
2022-12-31 05:49:57,392 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4010944108168284, 'Total loss': 0.4010944108168284} | train loss {'Reaction outcome loss': 0.1167811439658384, 'Total loss': 0.1167811439658384}
2022-12-31 05:49:57,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:57,393 INFO:     Epoch: 76
2022-12-31 05:49:59,064 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42839518388112385, 'Total loss': 0.42839518388112385} | train loss {'Reaction outcome loss': 0.11635552687294755, 'Total loss': 0.11635552687294755}
2022-12-31 05:49:59,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:49:59,064 INFO:     Epoch: 77
2022-12-31 05:50:00,713 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4205818916360537, 'Total loss': 0.4205818916360537} | train loss {'Reaction outcome loss': 0.11900269995117392, 'Total loss': 0.11900269995117392}
2022-12-31 05:50:00,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:00,714 INFO:     Epoch: 78
2022-12-31 05:50:02,352 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4376740833123525, 'Total loss': 0.4376740833123525} | train loss {'Reaction outcome loss': 0.11771592255076561, 'Total loss': 0.11771592255076561}
2022-12-31 05:50:02,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:02,353 INFO:     Epoch: 79
2022-12-31 05:50:03,986 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41365966697533924, 'Total loss': 0.41365966697533924} | train loss {'Reaction outcome loss': 0.11571249918211991, 'Total loss': 0.11571249918211991}
2022-12-31 05:50:03,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:03,986 INFO:     Epoch: 80
2022-12-31 05:50:05,615 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38907324771086377, 'Total loss': 0.38907324771086377} | train loss {'Reaction outcome loss': 0.11744075393411818, 'Total loss': 0.11744075393411818}
2022-12-31 05:50:05,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:05,615 INFO:     Epoch: 81
2022-12-31 05:50:07,265 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4143452654282252, 'Total loss': 0.4143452654282252} | train loss {'Reaction outcome loss': 0.11523528309834832, 'Total loss': 0.11523528309834832}
2022-12-31 05:50:07,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:07,266 INFO:     Epoch: 82
2022-12-31 05:50:08,885 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4191836595535278, 'Total loss': 0.4191836595535278} | train loss {'Reaction outcome loss': 0.11304988309619982, 'Total loss': 0.11304988309619982}
2022-12-31 05:50:08,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:08,886 INFO:     Epoch: 83
2022-12-31 05:50:10,513 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41377321183681487, 'Total loss': 0.41377321183681487} | train loss {'Reaction outcome loss': 0.11072883298889556, 'Total loss': 0.11072883298889556}
2022-12-31 05:50:10,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:10,513 INFO:     Epoch: 84
2022-12-31 05:50:12,136 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39749223018685975, 'Total loss': 0.39749223018685975} | train loss {'Reaction outcome loss': 0.10796329324446377, 'Total loss': 0.10796329324446377}
2022-12-31 05:50:12,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:12,136 INFO:     Epoch: 85
2022-12-31 05:50:13,768 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.410149917503198, 'Total loss': 0.410149917503198} | train loss {'Reaction outcome loss': 0.11022408241708678, 'Total loss': 0.11022408241708678}
2022-12-31 05:50:13,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:13,768 INFO:     Epoch: 86
2022-12-31 05:50:15,390 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4258579989274343, 'Total loss': 0.4258579989274343} | train loss {'Reaction outcome loss': 0.11041704924366964, 'Total loss': 0.11041704924366964}
2022-12-31 05:50:15,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:15,390 INFO:     Epoch: 87
2022-12-31 05:50:17,064 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4059651804467042, 'Total loss': 0.4059651804467042} | train loss {'Reaction outcome loss': 0.11458544831450639, 'Total loss': 0.11458544831450639}
2022-12-31 05:50:17,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:17,064 INFO:     Epoch: 88
2022-12-31 05:50:18,690 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4175282657146454, 'Total loss': 0.4175282657146454} | train loss {'Reaction outcome loss': 0.11609619542021668, 'Total loss': 0.11609619542021668}
2022-12-31 05:50:18,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:18,690 INFO:     Epoch: 89
2022-12-31 05:50:20,323 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39853315353393554, 'Total loss': 0.39853315353393554} | train loss {'Reaction outcome loss': 0.12330156929004224, 'Total loss': 0.12330156929004224}
2022-12-31 05:50:20,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:20,323 INFO:     Epoch: 90
2022-12-31 05:50:21,959 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3956106980641683, 'Total loss': 0.3956106980641683} | train loss {'Reaction outcome loss': 0.11454146630416494, 'Total loss': 0.11454146630416494}
2022-12-31 05:50:21,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:21,959 INFO:     Epoch: 91
2022-12-31 05:50:23,608 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40784901976585386, 'Total loss': 0.40784901976585386} | train loss {'Reaction outcome loss': 0.11080616007269854, 'Total loss': 0.11080616007269854}
2022-12-31 05:50:23,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:23,608 INFO:     Epoch: 92
2022-12-31 05:50:25,238 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3956826056043307, 'Total loss': 0.3956826056043307} | train loss {'Reaction outcome loss': 0.11496904169525346, 'Total loss': 0.11496904169525346}
2022-12-31 05:50:25,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:25,240 INFO:     Epoch: 93
2022-12-31 05:50:26,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3995301882425944, 'Total loss': 0.3995301882425944} | train loss {'Reaction outcome loss': 0.11459657729314203, 'Total loss': 0.11459657729314203}
2022-12-31 05:50:26,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:26,869 INFO:     Epoch: 94
2022-12-31 05:50:28,496 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42492603162924447, 'Total loss': 0.42492603162924447} | train loss {'Reaction outcome loss': 0.11663759979150436, 'Total loss': 0.11663759979150436}
2022-12-31 05:50:28,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:28,497 INFO:     Epoch: 95
2022-12-31 05:50:30,128 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3914181729157766, 'Total loss': 0.3914181729157766} | train loss {'Reaction outcome loss': 0.11333884085051124, 'Total loss': 0.11333884085051124}
2022-12-31 05:50:30,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:30,129 INFO:     Epoch: 96
2022-12-31 05:50:31,802 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39722969035307565, 'Total loss': 0.39722969035307565} | train loss {'Reaction outcome loss': 0.11294546400008569, 'Total loss': 0.11294546400008569}
2022-12-31 05:50:31,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:31,802 INFO:     Epoch: 97
2022-12-31 05:50:33,434 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4022785097360611, 'Total loss': 0.4022785097360611} | train loss {'Reaction outcome loss': 0.11285143029970195, 'Total loss': 0.11285143029970195}
2022-12-31 05:50:33,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:33,434 INFO:     Epoch: 98
2022-12-31 05:50:35,060 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4153207552929719, 'Total loss': 0.4153207552929719} | train loss {'Reaction outcome loss': 0.10652669125727449, 'Total loss': 0.10652669125727449}
2022-12-31 05:50:35,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:35,060 INFO:     Epoch: 99
2022-12-31 05:50:36,681 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4096908281246821, 'Total loss': 0.4096908281246821} | train loss {'Reaction outcome loss': 0.1084190836573013, 'Total loss': 0.1084190836573013}
2022-12-31 05:50:36,682 INFO:     Best model found after epoch 12 of 100.
2022-12-31 05:50:36,682 INFO:   Done with stage: TRAINING
2022-12-31 05:50:36,682 INFO:   Starting stage: EVALUATION
2022-12-31 05:50:36,804 INFO:   Done with stage: EVALUATION
2022-12-31 05:50:36,805 INFO:   Leaving out SEQ value Fold_9
2022-12-31 05:50:36,817 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:50:36,817 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:50:37,463 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:50:37,464 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:50:37,533 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:50:37,534 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:50:37,534 INFO:     No hyperparam tuning for this model
2022-12-31 05:50:37,534 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:50:37,534 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:50:37,534 INFO:     None feature selector for col prot
2022-12-31 05:50:37,535 INFO:     None feature selector for col prot
2022-12-31 05:50:37,535 INFO:     None feature selector for col prot
2022-12-31 05:50:37,535 INFO:     None feature selector for col chem
2022-12-31 05:50:37,535 INFO:     None feature selector for col chem
2022-12-31 05:50:37,535 INFO:     None feature selector for col chem
2022-12-31 05:50:37,535 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:50:37,535 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:50:37,537 INFO:     Number of params in model 224011
2022-12-31 05:50:37,541 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:50:37,541 INFO:   Starting stage: TRAINING
2022-12-31 05:50:37,585 INFO:     Val loss before train {'Reaction outcome loss': 0.984512201944987, 'Total loss': 0.984512201944987}
2022-12-31 05:50:37,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:37,585 INFO:     Epoch: 0
2022-12-31 05:50:39,191 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5867427984873453, 'Total loss': 0.5867427984873453} | train loss {'Reaction outcome loss': 0.7779410498855758, 'Total loss': 0.7779410498855758}
2022-12-31 05:50:39,191 INFO:     Found new best model at epoch 0
2022-12-31 05:50:39,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:39,192 INFO:     Epoch: 1
2022-12-31 05:50:40,799 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5071473866701126, 'Total loss': 0.5071473866701126} | train loss {'Reaction outcome loss': 0.5163384801062354, 'Total loss': 0.5163384801062354}
2022-12-31 05:50:40,800 INFO:     Found new best model at epoch 1
2022-12-31 05:50:40,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:40,801 INFO:     Epoch: 2
2022-12-31 05:50:42,439 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47253527243932086, 'Total loss': 0.47253527243932086} | train loss {'Reaction outcome loss': 0.4426272391837879, 'Total loss': 0.4426272391837879}
2022-12-31 05:50:42,439 INFO:     Found new best model at epoch 2
2022-12-31 05:50:42,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:42,440 INFO:     Epoch: 3
2022-12-31 05:50:44,044 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4467995454867681, 'Total loss': 0.4467995454867681} | train loss {'Reaction outcome loss': 0.40536318964114154, 'Total loss': 0.40536318964114154}
2022-12-31 05:50:44,044 INFO:     Found new best model at epoch 3
2022-12-31 05:50:44,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:44,045 INFO:     Epoch: 4
2022-12-31 05:50:45,644 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44309521714846295, 'Total loss': 0.44309521714846295} | train loss {'Reaction outcome loss': 0.37220051710623026, 'Total loss': 0.37220051710623026}
2022-12-31 05:50:45,644 INFO:     Found new best model at epoch 4
2022-12-31 05:50:45,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:45,645 INFO:     Epoch: 5
2022-12-31 05:50:47,260 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40727288921674093, 'Total loss': 0.40727288921674093} | train loss {'Reaction outcome loss': 0.34829846258363584, 'Total loss': 0.34829846258363584}
2022-12-31 05:50:47,260 INFO:     Found new best model at epoch 5
2022-12-31 05:50:47,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:47,261 INFO:     Epoch: 6
2022-12-31 05:50:48,866 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40966519713401794, 'Total loss': 0.40966519713401794} | train loss {'Reaction outcome loss': 0.32861754681615934, 'Total loss': 0.32861754681615934}
2022-12-31 05:50:48,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:48,867 INFO:     Epoch: 7
2022-12-31 05:50:50,502 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4207072099049886, 'Total loss': 0.4207072099049886} | train loss {'Reaction outcome loss': 0.3129798000148178, 'Total loss': 0.3129798000148178}
2022-12-31 05:50:50,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:50,502 INFO:     Epoch: 8
2022-12-31 05:50:52,156 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4357633133729299, 'Total loss': 0.4357633133729299} | train loss {'Reaction outcome loss': 0.29609253458733104, 'Total loss': 0.29609253458733104}
2022-12-31 05:50:52,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:52,156 INFO:     Epoch: 9
2022-12-31 05:50:53,808 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4044275542100271, 'Total loss': 0.4044275542100271} | train loss {'Reaction outcome loss': 0.2838634968918823, 'Total loss': 0.2838634968918823}
2022-12-31 05:50:53,808 INFO:     Found new best model at epoch 9
2022-12-31 05:50:53,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:53,809 INFO:     Epoch: 10
2022-12-31 05:50:55,415 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39827067852020265, 'Total loss': 0.39827067852020265} | train loss {'Reaction outcome loss': 0.27000635941206974, 'Total loss': 0.27000635941206974}
2022-12-31 05:50:55,415 INFO:     Found new best model at epoch 10
2022-12-31 05:50:55,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:55,416 INFO:     Epoch: 11
2022-12-31 05:50:57,022 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4144719660282135, 'Total loss': 0.4144719660282135} | train loss {'Reaction outcome loss': 0.2600986434513853, 'Total loss': 0.2600986434513853}
2022-12-31 05:50:57,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:57,022 INFO:     Epoch: 12
2022-12-31 05:50:58,631 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39003887673219045, 'Total loss': 0.39003887673219045} | train loss {'Reaction outcome loss': 0.2526784373080208, 'Total loss': 0.2526784373080208}
2022-12-31 05:50:58,631 INFO:     Found new best model at epoch 12
2022-12-31 05:50:58,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:50:58,632 INFO:     Epoch: 13
2022-12-31 05:51:00,260 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4114454617102941, 'Total loss': 0.4114454617102941} | train loss {'Reaction outcome loss': 0.24361530244078514, 'Total loss': 0.24361530244078514}
2022-12-31 05:51:00,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:00,261 INFO:     Epoch: 14
2022-12-31 05:51:01,882 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38926111633578936, 'Total loss': 0.38926111633578936} | train loss {'Reaction outcome loss': 0.2367156799406792, 'Total loss': 0.2367156799406792}
2022-12-31 05:51:01,882 INFO:     Found new best model at epoch 14
2022-12-31 05:51:01,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:01,883 INFO:     Epoch: 15
2022-12-31 05:51:03,494 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.393326794107755, 'Total loss': 0.393326794107755} | train loss {'Reaction outcome loss': 0.22971290677622722, 'Total loss': 0.22971290677622722}
2022-12-31 05:51:03,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:03,494 INFO:     Epoch: 16
2022-12-31 05:51:05,114 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3869003802537918, 'Total loss': 0.3869003802537918} | train loss {'Reaction outcome loss': 0.2218959836466034, 'Total loss': 0.2218959836466034}
2022-12-31 05:51:05,114 INFO:     Found new best model at epoch 16
2022-12-31 05:51:05,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:05,115 INFO:     Epoch: 17
2022-12-31 05:51:06,731 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3969221423069636, 'Total loss': 0.3969221423069636} | train loss {'Reaction outcome loss': 0.2178882286224487, 'Total loss': 0.2178882286224487}
2022-12-31 05:51:06,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:06,732 INFO:     Epoch: 18
2022-12-31 05:51:08,340 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38268195986747744, 'Total loss': 0.38268195986747744} | train loss {'Reaction outcome loss': 0.2102493658206378, 'Total loss': 0.2102493658206378}
2022-12-31 05:51:08,340 INFO:     Found new best model at epoch 18
2022-12-31 05:51:08,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:08,341 INFO:     Epoch: 19
2022-12-31 05:51:09,945 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40396784047285716, 'Total loss': 0.40396784047285716} | train loss {'Reaction outcome loss': 0.20365177254688782, 'Total loss': 0.20365177254688782}
2022-12-31 05:51:09,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:09,946 INFO:     Epoch: 20
2022-12-31 05:51:11,550 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4095050672690074, 'Total loss': 0.4095050672690074} | train loss {'Reaction outcome loss': 0.19926202391702547, 'Total loss': 0.19926202391702547}
2022-12-31 05:51:11,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:11,550 INFO:     Epoch: 21
2022-12-31 05:51:13,166 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38245507528384526, 'Total loss': 0.38245507528384526} | train loss {'Reaction outcome loss': 0.2009960093202382, 'Total loss': 0.2009960093202382}
2022-12-31 05:51:13,166 INFO:     Found new best model at epoch 21
2022-12-31 05:51:13,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:13,167 INFO:     Epoch: 22
2022-12-31 05:51:14,785 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41861075162887573, 'Total loss': 0.41861075162887573} | train loss {'Reaction outcome loss': 0.19038310218058582, 'Total loss': 0.19038310218058582}
2022-12-31 05:51:14,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:14,786 INFO:     Epoch: 23
2022-12-31 05:51:16,403 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3788997252782186, 'Total loss': 0.3788997252782186} | train loss {'Reaction outcome loss': 0.19132003211926152, 'Total loss': 0.19132003211926152}
2022-12-31 05:51:16,403 INFO:     Found new best model at epoch 23
2022-12-31 05:51:16,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:16,404 INFO:     Epoch: 24
2022-12-31 05:51:18,024 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38210794727007547, 'Total loss': 0.38210794727007547} | train loss {'Reaction outcome loss': 0.18339372549994584, 'Total loss': 0.18339372549994584}
2022-12-31 05:51:18,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:18,025 INFO:     Epoch: 25
2022-12-31 05:51:19,676 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3748924976835648, 'Total loss': 0.3748924976835648} | train loss {'Reaction outcome loss': 0.18199514321656557, 'Total loss': 0.18199514321656557}
2022-12-31 05:51:19,677 INFO:     Found new best model at epoch 25
2022-12-31 05:51:19,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:19,678 INFO:     Epoch: 26
2022-12-31 05:51:21,282 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4029901921749115, 'Total loss': 0.4029901921749115} | train loss {'Reaction outcome loss': 0.18093276508900263, 'Total loss': 0.18093276508900263}
2022-12-31 05:51:21,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:21,282 INFO:     Epoch: 27
2022-12-31 05:51:22,895 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3990958439186215, 'Total loss': 0.3990958439186215} | train loss {'Reaction outcome loss': 0.17622268243427694, 'Total loss': 0.17622268243427694}
2022-12-31 05:51:22,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:22,895 INFO:     Epoch: 28
2022-12-31 05:51:24,513 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39766533772150675, 'Total loss': 0.39766533772150675} | train loss {'Reaction outcome loss': 0.16920953743282136, 'Total loss': 0.16920953743282136}
2022-12-31 05:51:24,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:24,513 INFO:     Epoch: 29
2022-12-31 05:51:26,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3536217711865902, 'Total loss': 0.3536217711865902} | train loss {'Reaction outcome loss': 0.17146309838378734, 'Total loss': 0.17146309838378734}
2022-12-31 05:51:26,132 INFO:     Found new best model at epoch 29
2022-12-31 05:51:26,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:26,133 INFO:     Epoch: 30
2022-12-31 05:51:27,729 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37450423240661623, 'Total loss': 0.37450423240661623} | train loss {'Reaction outcome loss': 0.16785848757632785, 'Total loss': 0.16785848757632785}
2022-12-31 05:51:27,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:27,729 INFO:     Epoch: 31
2022-12-31 05:51:29,341 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3885234216849009, 'Total loss': 0.3885234216849009} | train loss {'Reaction outcome loss': 0.16336882705834224, 'Total loss': 0.16336882705834224}
2022-12-31 05:51:29,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:29,341 INFO:     Epoch: 32
2022-12-31 05:51:30,958 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4050834596157074, 'Total loss': 0.4050834596157074} | train loss {'Reaction outcome loss': 0.1600232760075235, 'Total loss': 0.1600232760075235}
2022-12-31 05:51:30,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:30,959 INFO:     Epoch: 33
2022-12-31 05:51:32,570 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37161971131960553, 'Total loss': 0.37161971131960553} | train loss {'Reaction outcome loss': 0.15918245872509848, 'Total loss': 0.15918245872509848}
2022-12-31 05:51:32,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:32,571 INFO:     Epoch: 34
2022-12-31 05:51:34,184 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40043822427590686, 'Total loss': 0.40043822427590686} | train loss {'Reaction outcome loss': 0.15567355789244175, 'Total loss': 0.15567355789244175}
2022-12-31 05:51:34,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:34,184 INFO:     Epoch: 35
2022-12-31 05:51:35,734 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3896535361806552, 'Total loss': 0.3896535361806552} | train loss {'Reaction outcome loss': 0.15422084203234662, 'Total loss': 0.15422084203234662}
2022-12-31 05:51:35,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:35,734 INFO:     Epoch: 36
2022-12-31 05:51:36,846 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38472735782464346, 'Total loss': 0.38472735782464346} | train loss {'Reaction outcome loss': 0.15219241140383113, 'Total loss': 0.15219241140383113}
2022-12-31 05:51:36,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:36,847 INFO:     Epoch: 37
2022-12-31 05:51:37,955 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3596270571152369, 'Total loss': 0.3596270571152369} | train loss {'Reaction outcome loss': 0.15105636810618758, 'Total loss': 0.15105636810618758}
2022-12-31 05:51:37,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:37,955 INFO:     Epoch: 38
2022-12-31 05:51:39,209 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42463584144910177, 'Total loss': 0.42463584144910177} | train loss {'Reaction outcome loss': 0.15110946431701636, 'Total loss': 0.15110946431701636}
2022-12-31 05:51:39,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:39,209 INFO:     Epoch: 39
2022-12-31 05:51:40,385 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3700667212406794, 'Total loss': 0.3700667212406794} | train loss {'Reaction outcome loss': 0.14810954330040374, 'Total loss': 0.14810954330040374}
2022-12-31 05:51:40,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:40,385 INFO:     Epoch: 40
2022-12-31 05:51:42,016 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3898304561773936, 'Total loss': 0.3898304561773936} | train loss {'Reaction outcome loss': 0.1435793712803156, 'Total loss': 0.1435793712803156}
2022-12-31 05:51:42,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:42,016 INFO:     Epoch: 41
2022-12-31 05:51:43,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39313870668411255, 'Total loss': 0.39313870668411255} | train loss {'Reaction outcome loss': 0.14330049440346276, 'Total loss': 0.14330049440346276}
2022-12-31 05:51:43,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:43,633 INFO:     Epoch: 42
2022-12-31 05:51:45,250 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39090266128381096, 'Total loss': 0.39090266128381096} | train loss {'Reaction outcome loss': 0.14182571741415828, 'Total loss': 0.14182571741415828}
2022-12-31 05:51:45,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:45,251 INFO:     Epoch: 43
2022-12-31 05:51:46,887 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38140837798515953, 'Total loss': 0.38140837798515953} | train loss {'Reaction outcome loss': 0.13999807286028662, 'Total loss': 0.13999807286028662}
2022-12-31 05:51:46,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:46,888 INFO:     Epoch: 44
2022-12-31 05:51:48,506 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3722238590319951, 'Total loss': 0.3722238590319951} | train loss {'Reaction outcome loss': 0.1416906208160204, 'Total loss': 0.1416906208160204}
2022-12-31 05:51:48,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:48,506 INFO:     Epoch: 45
2022-12-31 05:51:50,114 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38608880937099455, 'Total loss': 0.38608880937099455} | train loss {'Reaction outcome loss': 0.13385093377318477, 'Total loss': 0.13385093377318477}
2022-12-31 05:51:50,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:50,114 INFO:     Epoch: 46
2022-12-31 05:51:51,731 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44127829919258754, 'Total loss': 0.44127829919258754} | train loss {'Reaction outcome loss': 0.13441998918921463, 'Total loss': 0.13441998918921463}
2022-12-31 05:51:51,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:51,731 INFO:     Epoch: 47
2022-12-31 05:51:53,389 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40212032993634544, 'Total loss': 0.40212032993634544} | train loss {'Reaction outcome loss': 0.13297715893246398, 'Total loss': 0.13297715893246398}
2022-12-31 05:51:53,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:53,389 INFO:     Epoch: 48
2022-12-31 05:51:55,051 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41512374877929686, 'Total loss': 0.41512374877929686} | train loss {'Reaction outcome loss': 0.13143706921127754, 'Total loss': 0.13143706921127754}
2022-12-31 05:51:55,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:55,051 INFO:     Epoch: 49
2022-12-31 05:51:56,679 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42701816658178965, 'Total loss': 0.42701816658178965} | train loss {'Reaction outcome loss': 0.13159454138575624, 'Total loss': 0.13159454138575624}
2022-12-31 05:51:56,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:56,679 INFO:     Epoch: 50
2022-12-31 05:51:58,300 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37339797417322795, 'Total loss': 0.37339797417322795} | train loss {'Reaction outcome loss': 0.131836884350849, 'Total loss': 0.131836884350849}
2022-12-31 05:51:58,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:58,300 INFO:     Epoch: 51
2022-12-31 05:51:59,911 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37271484831968943, 'Total loss': 0.37271484831968943} | train loss {'Reaction outcome loss': 0.12735646642594986, 'Total loss': 0.12735646642594986}
2022-12-31 05:51:59,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:51:59,911 INFO:     Epoch: 52
2022-12-31 05:52:01,530 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3594833779148757, 'Total loss': 0.3594833779148757} | train loss {'Reaction outcome loss': 0.1250953916953129, 'Total loss': 0.1250953916953129}
2022-12-31 05:52:01,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:01,532 INFO:     Epoch: 53
2022-12-31 05:52:03,140 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3807180106639862, 'Total loss': 0.3807180106639862} | train loss {'Reaction outcome loss': 0.13108204901524323, 'Total loss': 0.13108204901524323}
2022-12-31 05:52:03,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:03,141 INFO:     Epoch: 54
2022-12-31 05:52:04,794 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4152398626009623, 'Total loss': 0.4152398626009623} | train loss {'Reaction outcome loss': 0.12641077019600538, 'Total loss': 0.12641077019600538}
2022-12-31 05:52:04,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:04,794 INFO:     Epoch: 55
2022-12-31 05:52:06,403 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39041918416817983, 'Total loss': 0.39041918416817983} | train loss {'Reaction outcome loss': 0.12108985540103576, 'Total loss': 0.12108985540103576}
2022-12-31 05:52:06,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:06,403 INFO:     Epoch: 56
2022-12-31 05:52:08,044 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3993221233288447, 'Total loss': 0.3993221233288447} | train loss {'Reaction outcome loss': 0.12236654922624465, 'Total loss': 0.12236654922624465}
2022-12-31 05:52:08,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:08,045 INFO:     Epoch: 57
2022-12-31 05:52:09,661 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38094515601793927, 'Total loss': 0.38094515601793927} | train loss {'Reaction outcome loss': 0.12355957037334188, 'Total loss': 0.12355957037334188}
2022-12-31 05:52:09,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:09,662 INFO:     Epoch: 58
2022-12-31 05:52:11,315 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4003367394208908, 'Total loss': 0.4003367394208908} | train loss {'Reaction outcome loss': 0.12100244782198846, 'Total loss': 0.12100244782198846}
2022-12-31 05:52:11,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:11,316 INFO:     Epoch: 59
2022-12-31 05:52:12,970 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43780287181337674, 'Total loss': 0.43780287181337674} | train loss {'Reaction outcome loss': 0.11897053310552436, 'Total loss': 0.11897053310552436}
2022-12-31 05:52:12,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:12,970 INFO:     Epoch: 60
2022-12-31 05:52:14,610 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3733245899279912, 'Total loss': 0.3733245899279912} | train loss {'Reaction outcome loss': 0.12584795983317887, 'Total loss': 0.12584795983317887}
2022-12-31 05:52:14,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:14,610 INFO:     Epoch: 61
2022-12-31 05:52:16,225 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4060867249965668, 'Total loss': 0.4060867249965668} | train loss {'Reaction outcome loss': 0.11664505082651647, 'Total loss': 0.11664505082651647}
2022-12-31 05:52:16,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:16,225 INFO:     Epoch: 62
2022-12-31 05:52:17,853 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3904231548309326, 'Total loss': 0.3904231548309326} | train loss {'Reaction outcome loss': 0.11235038188530853, 'Total loss': 0.11235038188530853}
2022-12-31 05:52:17,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:17,854 INFO:     Epoch: 63
2022-12-31 05:52:19,516 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37810619274775187, 'Total loss': 0.37810619274775187} | train loss {'Reaction outcome loss': 0.11832417637775958, 'Total loss': 0.11832417637775958}
2022-12-31 05:52:19,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:19,516 INFO:     Epoch: 64
2022-12-31 05:52:21,170 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39077073882023494, 'Total loss': 0.39077073882023494} | train loss {'Reaction outcome loss': 0.11905061734337223, 'Total loss': 0.11905061734337223}
2022-12-31 05:52:21,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:21,171 INFO:     Epoch: 65
2022-12-31 05:52:22,787 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38220828076203667, 'Total loss': 0.38220828076203667} | train loss {'Reaction outcome loss': 0.11466454823814115, 'Total loss': 0.11466454823814115}
2022-12-31 05:52:22,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:22,787 INFO:     Epoch: 66
2022-12-31 05:52:24,410 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3942923665046692, 'Total loss': 0.3942923665046692} | train loss {'Reaction outcome loss': 0.11401204975750161, 'Total loss': 0.11401204975750161}
2022-12-31 05:52:24,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:24,410 INFO:     Epoch: 67
2022-12-31 05:52:26,029 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4334875057140986, 'Total loss': 0.4334875057140986} | train loss {'Reaction outcome loss': 0.11721066457396169, 'Total loss': 0.11721066457396169}
2022-12-31 05:52:26,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:26,029 INFO:     Epoch: 68
2022-12-31 05:52:27,669 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3876341789960861, 'Total loss': 0.3876341789960861} | train loss {'Reaction outcome loss': 0.11384111034588712, 'Total loss': 0.11384111034588712}
2022-12-31 05:52:27,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:27,670 INFO:     Epoch: 69
2022-12-31 05:52:29,364 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4477335085471471, 'Total loss': 0.4477335085471471} | train loss {'Reaction outcome loss': 0.115078674802679, 'Total loss': 0.115078674802679}
2022-12-31 05:52:29,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:29,364 INFO:     Epoch: 70
2022-12-31 05:52:31,073 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4359048624833425, 'Total loss': 0.4359048624833425} | train loss {'Reaction outcome loss': 0.11811774332130695, 'Total loss': 0.11811774332130695}
2022-12-31 05:52:31,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:31,073 INFO:     Epoch: 71
2022-12-31 05:52:32,692 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4151714205741882, 'Total loss': 0.4151714205741882} | train loss {'Reaction outcome loss': 0.11221920866621182, 'Total loss': 0.11221920866621182}
2022-12-31 05:52:32,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:32,693 INFO:     Epoch: 72
2022-12-31 05:52:34,311 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35536814232667285, 'Total loss': 0.35536814232667285} | train loss {'Reaction outcome loss': 0.11065797317759508, 'Total loss': 0.11065797317759508}
2022-12-31 05:52:34,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:34,311 INFO:     Epoch: 73
2022-12-31 05:52:35,930 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4269645094871521, 'Total loss': 0.4269645094871521} | train loss {'Reaction outcome loss': 0.10693848789941492, 'Total loss': 0.10693848789941492}
2022-12-31 05:52:35,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:35,930 INFO:     Epoch: 74
2022-12-31 05:52:37,628 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4064849982659022, 'Total loss': 0.4064849982659022} | train loss {'Reaction outcome loss': 0.1121859990458011, 'Total loss': 0.1121859990458011}
2022-12-31 05:52:37,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:37,628 INFO:     Epoch: 75
2022-12-31 05:52:39,335 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42028762002786, 'Total loss': 0.42028762002786} | train loss {'Reaction outcome loss': 0.10973320486547467, 'Total loss': 0.10973320486547467}
2022-12-31 05:52:39,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:39,336 INFO:     Epoch: 76
2022-12-31 05:52:40,943 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3817462568481763, 'Total loss': 0.3817462568481763} | train loss {'Reaction outcome loss': 0.11551904246673314, 'Total loss': 0.11551904246673314}
2022-12-31 05:52:40,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:40,943 INFO:     Epoch: 77
2022-12-31 05:52:42,556 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37059931059678397, 'Total loss': 0.37059931059678397} | train loss {'Reaction outcome loss': 0.1105151783639266, 'Total loss': 0.1105151783639266}
2022-12-31 05:52:42,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:42,556 INFO:     Epoch: 78
2022-12-31 05:52:44,262 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40659160961707436, 'Total loss': 0.40659160961707436} | train loss {'Reaction outcome loss': 0.10831018069582264, 'Total loss': 0.10831018069582264}
2022-12-31 05:52:44,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:44,263 INFO:     Epoch: 79
2022-12-31 05:52:45,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4411078964670499, 'Total loss': 0.4411078964670499} | train loss {'Reaction outcome loss': 0.10885929050736375, 'Total loss': 0.10885929050736375}
2022-12-31 05:52:45,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:45,877 INFO:     Epoch: 80
2022-12-31 05:52:47,581 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40535863637924197, 'Total loss': 0.40535863637924197} | train loss {'Reaction outcome loss': 0.10814608654676916, 'Total loss': 0.10814608654676916}
2022-12-31 05:52:47,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:47,581 INFO:     Epoch: 81
2022-12-31 05:52:49,189 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4005477954943975, 'Total loss': 0.4005477954943975} | train loss {'Reaction outcome loss': 0.10692754691725012, 'Total loss': 0.10692754691725012}
2022-12-31 05:52:49,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:49,189 INFO:     Epoch: 82
2022-12-31 05:52:50,799 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4106568137804667, 'Total loss': 0.4106568137804667} | train loss {'Reaction outcome loss': 0.10959249314253837, 'Total loss': 0.10959249314253837}
2022-12-31 05:52:50,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:50,800 INFO:     Epoch: 83
2022-12-31 05:52:52,411 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40377393215894697, 'Total loss': 0.40377393215894697} | train loss {'Reaction outcome loss': 0.10721880150024174, 'Total loss': 0.10721880150024174}
2022-12-31 05:52:52,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:52,412 INFO:     Epoch: 84
2022-12-31 05:52:54,026 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3994451999664307, 'Total loss': 0.3994451999664307} | train loss {'Reaction outcome loss': 0.10429307306950136, 'Total loss': 0.10429307306950136}
2022-12-31 05:52:54,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:54,027 INFO:     Epoch: 85
2022-12-31 05:52:55,734 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40967066772282124, 'Total loss': 0.40967066772282124} | train loss {'Reaction outcome loss': 0.10491737947343802, 'Total loss': 0.10491737947343802}
2022-12-31 05:52:55,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:55,734 INFO:     Epoch: 86
2022-12-31 05:52:57,347 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4262271602948507, 'Total loss': 0.4262271602948507} | train loss {'Reaction outcome loss': 0.10588212714132846, 'Total loss': 0.10588212714132846}
2022-12-31 05:52:57,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:57,348 INFO:     Epoch: 87
2022-12-31 05:52:58,976 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40637040237585703, 'Total loss': 0.40637040237585703} | train loss {'Reaction outcome loss': 0.10941546516710499, 'Total loss': 0.10941546516710499}
2022-12-31 05:52:58,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:52:58,976 INFO:     Epoch: 88
2022-12-31 05:53:00,598 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42447015742460886, 'Total loss': 0.42447015742460886} | train loss {'Reaction outcome loss': 0.10534089274133426, 'Total loss': 0.10534089274133426}
2022-12-31 05:53:00,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:00,598 INFO:     Epoch: 89
2022-12-31 05:53:02,269 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42037561535835266, 'Total loss': 0.42037561535835266} | train loss {'Reaction outcome loss': 0.1076880167323389, 'Total loss': 0.1076880167323389}
2022-12-31 05:53:02,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:02,270 INFO:     Epoch: 90
2022-12-31 05:53:03,904 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4006897101799647, 'Total loss': 0.4006897101799647} | train loss {'Reaction outcome loss': 0.10581699654249216, 'Total loss': 0.10581699654249216}
2022-12-31 05:53:03,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:03,906 INFO:     Epoch: 91
2022-12-31 05:53:05,525 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4095487912495931, 'Total loss': 0.4095487912495931} | train loss {'Reaction outcome loss': 0.1018525963168197, 'Total loss': 0.1018525963168197}
2022-12-31 05:53:05,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:05,525 INFO:     Epoch: 92
2022-12-31 05:53:07,234 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4338043545683225, 'Total loss': 0.4338043545683225} | train loss {'Reaction outcome loss': 0.10323681052600843, 'Total loss': 0.10323681052600843}
2022-12-31 05:53:07,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:07,234 INFO:     Epoch: 93
2022-12-31 05:53:08,846 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40870561500390373, 'Total loss': 0.40870561500390373} | train loss {'Reaction outcome loss': 0.10497990558875629, 'Total loss': 0.10497990558875629}
2022-12-31 05:53:08,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:08,846 INFO:     Epoch: 94
2022-12-31 05:53:10,507 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40408227195342383, 'Total loss': 0.40408227195342383} | train loss {'Reaction outcome loss': 0.10092258420059064, 'Total loss': 0.10092258420059064}
2022-12-31 05:53:10,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:10,508 INFO:     Epoch: 95
2022-12-31 05:53:12,176 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40296956797440847, 'Total loss': 0.40296956797440847} | train loss {'Reaction outcome loss': 0.10583230032905067, 'Total loss': 0.10583230032905067}
2022-12-31 05:53:12,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:12,176 INFO:     Epoch: 96
2022-12-31 05:53:13,800 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43607175449530283, 'Total loss': 0.43607175449530283} | train loss {'Reaction outcome loss': 0.10320866753918248, 'Total loss': 0.10320866753918248}
2022-12-31 05:53:13,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:13,801 INFO:     Epoch: 97
2022-12-31 05:53:15,453 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40860057771205904, 'Total loss': 0.40860057771205904} | train loss {'Reaction outcome loss': 0.10556880134008281, 'Total loss': 0.10556880134008281}
2022-12-31 05:53:15,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:15,453 INFO:     Epoch: 98
2022-12-31 05:53:17,062 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38874472031990687, 'Total loss': 0.38874472031990687} | train loss {'Reaction outcome loss': 0.10246366054927726, 'Total loss': 0.10246366054927726}
2022-12-31 05:53:17,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:17,062 INFO:     Epoch: 99
2022-12-31 05:53:18,714 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4305727531512578, 'Total loss': 0.4305727531512578} | train loss {'Reaction outcome loss': 0.10184243492387833, 'Total loss': 0.10184243492387833}
2022-12-31 05:53:18,715 INFO:     Best model found after epoch 30 of 100.
2022-12-31 05:53:18,715 INFO:   Done with stage: TRAINING
2022-12-31 05:53:18,715 INFO:   Starting stage: EVALUATION
2022-12-31 05:53:18,849 INFO:   Done with stage: EVALUATION
2022-12-31 05:53:18,857 INFO:   Leaving out SEQ value Fold_0
2022-12-31 05:53:18,870 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 05:53:18,870 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:53:19,507 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:53:19,507 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:53:19,577 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:53:19,577 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:53:19,577 INFO:     No hyperparam tuning for this model
2022-12-31 05:53:19,577 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:53:19,577 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:53:19,578 INFO:     None feature selector for col prot
2022-12-31 05:53:19,578 INFO:     None feature selector for col prot
2022-12-31 05:53:19,578 INFO:     None feature selector for col prot
2022-12-31 05:53:19,579 INFO:     None feature selector for col chem
2022-12-31 05:53:19,579 INFO:     None feature selector for col chem
2022-12-31 05:53:19,579 INFO:     None feature selector for col chem
2022-12-31 05:53:19,579 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:53:19,579 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:53:19,581 INFO:     Number of params in model 224011
2022-12-31 05:53:19,584 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:53:19,584 INFO:   Starting stage: TRAINING
2022-12-31 05:53:19,630 INFO:     Val loss before train {'Reaction outcome loss': 1.043317453066508, 'Total loss': 1.043317453066508}
2022-12-31 05:53:19,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:19,630 INFO:     Epoch: 0
2022-12-31 05:53:21,229 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6175454338391622, 'Total loss': 0.6175454338391622} | train loss {'Reaction outcome loss': 0.7724303886458114, 'Total loss': 0.7724303886458114}
2022-12-31 05:53:21,230 INFO:     Found new best model at epoch 0
2022-12-31 05:53:21,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:21,231 INFO:     Epoch: 1
2022-12-31 05:53:22,850 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5116232891877492, 'Total loss': 0.5116232891877492} | train loss {'Reaction outcome loss': 0.5095947036594698, 'Total loss': 0.5095947036594698}
2022-12-31 05:53:22,850 INFO:     Found new best model at epoch 1
2022-12-31 05:53:22,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:22,851 INFO:     Epoch: 2
2022-12-31 05:53:24,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4902847230434418, 'Total loss': 0.4902847230434418} | train loss {'Reaction outcome loss': 0.4445471771252461, 'Total loss': 0.4445471771252461}
2022-12-31 05:53:24,467 INFO:     Found new best model at epoch 2
2022-12-31 05:53:24,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:24,468 INFO:     Epoch: 3
2022-12-31 05:53:26,081 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4541334052880605, 'Total loss': 0.4541334052880605} | train loss {'Reaction outcome loss': 0.40593769960787707, 'Total loss': 0.40593769960787707}
2022-12-31 05:53:26,081 INFO:     Found new best model at epoch 3
2022-12-31 05:53:26,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:26,082 INFO:     Epoch: 4
2022-12-31 05:53:27,701 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4475445399681727, 'Total loss': 0.4475445399681727} | train loss {'Reaction outcome loss': 0.3771262382576754, 'Total loss': 0.3771262382576754}
2022-12-31 05:53:27,701 INFO:     Found new best model at epoch 4
2022-12-31 05:53:27,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:27,702 INFO:     Epoch: 5
2022-12-31 05:53:29,317 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43390392065048217, 'Total loss': 0.43390392065048217} | train loss {'Reaction outcome loss': 0.3524132656417924, 'Total loss': 0.3524132656417924}
2022-12-31 05:53:29,318 INFO:     Found new best model at epoch 5
2022-12-31 05:53:29,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:29,319 INFO:     Epoch: 6
2022-12-31 05:53:30,927 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4157016744216283, 'Total loss': 0.4157016744216283} | train loss {'Reaction outcome loss': 0.334130377969244, 'Total loss': 0.334130377969244}
2022-12-31 05:53:30,927 INFO:     Found new best model at epoch 6
2022-12-31 05:53:30,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:30,928 INFO:     Epoch: 7
2022-12-31 05:53:32,546 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4486835986375809, 'Total loss': 0.4486835986375809} | train loss {'Reaction outcome loss': 0.3107894546874277, 'Total loss': 0.3107894546874277}
2022-12-31 05:53:32,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:32,546 INFO:     Epoch: 8
2022-12-31 05:53:34,164 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4256123622258504, 'Total loss': 0.4256123622258504} | train loss {'Reaction outcome loss': 0.29568153395975905, 'Total loss': 0.29568153395975905}
2022-12-31 05:53:34,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:34,164 INFO:     Epoch: 9
2022-12-31 05:53:35,781 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41046541233857475, 'Total loss': 0.41046541233857475} | train loss {'Reaction outcome loss': 0.2834658420375197, 'Total loss': 0.2834658420375197}
2022-12-31 05:53:35,781 INFO:     Found new best model at epoch 9
2022-12-31 05:53:35,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:35,782 INFO:     Epoch: 10
2022-12-31 05:53:37,390 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4122370113929113, 'Total loss': 0.4122370113929113} | train loss {'Reaction outcome loss': 0.2687867109223709, 'Total loss': 0.2687867109223709}
2022-12-31 05:53:37,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:37,390 INFO:     Epoch: 11
2022-12-31 05:53:39,011 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39712939808766046, 'Total loss': 0.39712939808766046} | train loss {'Reaction outcome loss': 0.260178184593881, 'Total loss': 0.260178184593881}
2022-12-31 05:53:39,012 INFO:     Found new best model at epoch 11
2022-12-31 05:53:39,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:39,013 INFO:     Epoch: 12
2022-12-31 05:53:40,623 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39301123122374215, 'Total loss': 0.39301123122374215} | train loss {'Reaction outcome loss': 0.2475114348907392, 'Total loss': 0.2475114348907392}
2022-12-31 05:53:40,623 INFO:     Found new best model at epoch 12
2022-12-31 05:53:40,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:40,624 INFO:     Epoch: 13
2022-12-31 05:53:42,244 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43985846936702727, 'Total loss': 0.43985846936702727} | train loss {'Reaction outcome loss': 0.24125204100222378, 'Total loss': 0.24125204100222378}
2022-12-31 05:53:42,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:42,244 INFO:     Epoch: 14
2022-12-31 05:53:43,864 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4234306921561559, 'Total loss': 0.4234306921561559} | train loss {'Reaction outcome loss': 0.2334526408491008, 'Total loss': 0.2334526408491008}
2022-12-31 05:53:43,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:43,864 INFO:     Epoch: 15
2022-12-31 05:53:45,482 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43224363724390663, 'Total loss': 0.43224363724390663} | train loss {'Reaction outcome loss': 0.2244491663798963, 'Total loss': 0.2244491663798963}
2022-12-31 05:53:45,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:45,483 INFO:     Epoch: 16
2022-12-31 05:53:47,093 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4192714422941208, 'Total loss': 0.4192714422941208} | train loss {'Reaction outcome loss': 0.2184294626089461, 'Total loss': 0.2184294626089461}
2022-12-31 05:53:47,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:47,094 INFO:     Epoch: 17
2022-12-31 05:53:48,706 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4412500441074371, 'Total loss': 0.4412500441074371} | train loss {'Reaction outcome loss': 0.2121513630144107, 'Total loss': 0.2121513630144107}
2022-12-31 05:53:48,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:48,707 INFO:     Epoch: 18
2022-12-31 05:53:50,318 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45767516692479454, 'Total loss': 0.45767516692479454} | train loss {'Reaction outcome loss': 0.20841265671746634, 'Total loss': 0.20841265671746634}
2022-12-31 05:53:50,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:50,318 INFO:     Epoch: 19
2022-12-31 05:53:51,939 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4186590890089671, 'Total loss': 0.4186590890089671} | train loss {'Reaction outcome loss': 0.19803168190704598, 'Total loss': 0.19803168190704598}
2022-12-31 05:53:51,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:51,939 INFO:     Epoch: 20
2022-12-31 05:53:53,561 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4180176675319672, 'Total loss': 0.4180176675319672} | train loss {'Reaction outcome loss': 0.19497753664742024, 'Total loss': 0.19497753664742024}
2022-12-31 05:53:53,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:53,561 INFO:     Epoch: 21
2022-12-31 05:53:55,177 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.417035045226415, 'Total loss': 0.417035045226415} | train loss {'Reaction outcome loss': 0.19497674705644885, 'Total loss': 0.19497674705644885}
2022-12-31 05:53:55,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:55,177 INFO:     Epoch: 22
2022-12-31 05:53:56,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41847962836424507, 'Total loss': 0.41847962836424507} | train loss {'Reaction outcome loss': 0.18740336509632977, 'Total loss': 0.18740336509632977}
2022-12-31 05:53:56,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:56,772 INFO:     Epoch: 23
2022-12-31 05:53:58,399 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45681963860988617, 'Total loss': 0.45681963860988617} | train loss {'Reaction outcome loss': 0.18170806822868493, 'Total loss': 0.18170806822868493}
2022-12-31 05:53:58,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:53:58,400 INFO:     Epoch: 24
2022-12-31 05:54:00,017 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4149898240963618, 'Total loss': 0.4149898240963618} | train loss {'Reaction outcome loss': 0.18102669017559989, 'Total loss': 0.18102669017559989}
2022-12-31 05:54:00,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:00,017 INFO:     Epoch: 25
2022-12-31 05:54:01,634 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4109804317355156, 'Total loss': 0.4109804317355156} | train loss {'Reaction outcome loss': 0.17679803894880491, 'Total loss': 0.17679803894880491}
2022-12-31 05:54:01,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:01,634 INFO:     Epoch: 26
2022-12-31 05:54:03,250 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4187790622313817, 'Total loss': 0.4187790622313817} | train loss {'Reaction outcome loss': 0.17216982783224338, 'Total loss': 0.17216982783224338}
2022-12-31 05:54:03,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:03,250 INFO:     Epoch: 27
2022-12-31 05:54:04,856 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.418919504682223, 'Total loss': 0.418919504682223} | train loss {'Reaction outcome loss': 0.16963724134278385, 'Total loss': 0.16963724134278385}
2022-12-31 05:54:04,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:04,857 INFO:     Epoch: 28
2022-12-31 05:54:06,474 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.385781126221021, 'Total loss': 0.385781126221021} | train loss {'Reaction outcome loss': 0.16398363981068462, 'Total loss': 0.16398363981068462}
2022-12-31 05:54:06,474 INFO:     Found new best model at epoch 28
2022-12-31 05:54:06,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:06,475 INFO:     Epoch: 29
2022-12-31 05:54:08,081 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3939854467908541, 'Total loss': 0.3939854467908541} | train loss {'Reaction outcome loss': 0.1660175876992144, 'Total loss': 0.1660175876992144}
2022-12-31 05:54:08,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:08,081 INFO:     Epoch: 30
2022-12-31 05:54:09,697 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3956046249717474, 'Total loss': 0.3956046249717474} | train loss {'Reaction outcome loss': 0.16405397623559057, 'Total loss': 0.16405397623559057}
2022-12-31 05:54:09,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:09,698 INFO:     Epoch: 31
2022-12-31 05:54:11,313 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4114322364330292, 'Total loss': 0.4114322364330292} | train loss {'Reaction outcome loss': 0.16145305336886273, 'Total loss': 0.16145305336886273}
2022-12-31 05:54:11,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:11,313 INFO:     Epoch: 32
2022-12-31 05:54:12,925 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.441096027692159, 'Total loss': 0.441096027692159} | train loss {'Reaction outcome loss': 0.15955710028308434, 'Total loss': 0.15955710028308434}
2022-12-31 05:54:12,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:12,925 INFO:     Epoch: 33
2022-12-31 05:54:14,530 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40417733130355676, 'Total loss': 0.40417733130355676} | train loss {'Reaction outcome loss': 0.15565479706440652, 'Total loss': 0.15565479706440652}
2022-12-31 05:54:14,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:14,530 INFO:     Epoch: 34
2022-12-31 05:54:16,135 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4062460005283356, 'Total loss': 0.4062460005283356} | train loss {'Reaction outcome loss': 0.15521911607079564, 'Total loss': 0.15521911607079564}
2022-12-31 05:54:16,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:16,135 INFO:     Epoch: 35
2022-12-31 05:54:17,733 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39769329875707626, 'Total loss': 0.39769329875707626} | train loss {'Reaction outcome loss': 0.1523428818299657, 'Total loss': 0.1523428818299657}
2022-12-31 05:54:17,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:17,733 INFO:     Epoch: 36
2022-12-31 05:54:19,380 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41869726379712424, 'Total loss': 0.41869726379712424} | train loss {'Reaction outcome loss': 0.1527275013031213, 'Total loss': 0.1527275013031213}
2022-12-31 05:54:19,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:19,380 INFO:     Epoch: 37
2022-12-31 05:54:21,027 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40095560053984325, 'Total loss': 0.40095560053984325} | train loss {'Reaction outcome loss': 0.14779113522891105, 'Total loss': 0.14779113522891105}
2022-12-31 05:54:21,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:21,028 INFO:     Epoch: 38
2022-12-31 05:54:22,627 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39940352241198224, 'Total loss': 0.39940352241198224} | train loss {'Reaction outcome loss': 0.14387914198945403, 'Total loss': 0.14387914198945403}
2022-12-31 05:54:22,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:22,627 INFO:     Epoch: 39
2022-12-31 05:54:24,263 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42685607075691223, 'Total loss': 0.42685607075691223} | train loss {'Reaction outcome loss': 0.14519697411715876, 'Total loss': 0.14519697411715876}
2022-12-31 05:54:24,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:24,263 INFO:     Epoch: 40
2022-12-31 05:54:25,884 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40470493336518604, 'Total loss': 0.40470493336518604} | train loss {'Reaction outcome loss': 0.14606181523957096, 'Total loss': 0.14606181523957096}
2022-12-31 05:54:25,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:25,884 INFO:     Epoch: 41
2022-12-31 05:54:27,496 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.414419773966074, 'Total loss': 0.414419773966074} | train loss {'Reaction outcome loss': 0.1422746237401506, 'Total loss': 0.1422746237401506}
2022-12-31 05:54:27,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:27,496 INFO:     Epoch: 42
2022-12-31 05:54:29,107 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4053338478008906, 'Total loss': 0.4053338478008906} | train loss {'Reaction outcome loss': 0.13876594104821155, 'Total loss': 0.13876594104821155}
2022-12-31 05:54:29,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:29,108 INFO:     Epoch: 43
2022-12-31 05:54:30,718 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40973137070735294, 'Total loss': 0.40973137070735294} | train loss {'Reaction outcome loss': 0.1420314621901815, 'Total loss': 0.1420314621901815}
2022-12-31 05:54:30,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:30,718 INFO:     Epoch: 44
2022-12-31 05:54:32,321 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39616812616586683, 'Total loss': 0.39616812616586683} | train loss {'Reaction outcome loss': 0.13765912890202286, 'Total loss': 0.13765912890202286}
2022-12-31 05:54:32,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:32,321 INFO:     Epoch: 45
2022-12-31 05:54:33,929 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40633903990189235, 'Total loss': 0.40633903990189235} | train loss {'Reaction outcome loss': 0.14032130452698513, 'Total loss': 0.14032130452698513}
2022-12-31 05:54:33,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:33,929 INFO:     Epoch: 46
2022-12-31 05:54:35,565 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.425006906191508, 'Total loss': 0.425006906191508} | train loss {'Reaction outcome loss': 0.1386179247011359, 'Total loss': 0.1386179247011359}
2022-12-31 05:54:35,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:35,566 INFO:     Epoch: 47
2022-12-31 05:54:37,167 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4006664300958315, 'Total loss': 0.4006664300958315} | train loss {'Reaction outcome loss': 0.1356514897930944, 'Total loss': 0.1356514897930944}
2022-12-31 05:54:37,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:37,167 INFO:     Epoch: 48
2022-12-31 05:54:38,814 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42256779273351036, 'Total loss': 0.42256779273351036} | train loss {'Reaction outcome loss': 0.131565649754917, 'Total loss': 0.131565649754917}
2022-12-31 05:54:38,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:38,814 INFO:     Epoch: 49
2022-12-31 05:54:40,416 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4238020966450373, 'Total loss': 0.4238020966450373} | train loss {'Reaction outcome loss': 0.13072299612208438, 'Total loss': 0.13072299612208438}
2022-12-31 05:54:40,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:40,418 INFO:     Epoch: 50
2022-12-31 05:54:42,009 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4190867910782496, 'Total loss': 0.4190867910782496} | train loss {'Reaction outcome loss': 0.1307152782212056, 'Total loss': 0.1307152782212056}
2022-12-31 05:54:42,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:42,010 INFO:     Epoch: 51
2022-12-31 05:54:43,639 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42202980717023214, 'Total loss': 0.42202980717023214} | train loss {'Reaction outcome loss': 0.13529116297208946, 'Total loss': 0.13529116297208946}
2022-12-31 05:54:43,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:43,639 INFO:     Epoch: 52
2022-12-31 05:54:45,237 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39140167236328127, 'Total loss': 0.39140167236328127} | train loss {'Reaction outcome loss': 0.12993403260456227, 'Total loss': 0.12993403260456227}
2022-12-31 05:54:45,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:45,238 INFO:     Epoch: 53
2022-12-31 05:54:46,842 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4199507378041744, 'Total loss': 0.4199507378041744} | train loss {'Reaction outcome loss': 0.1288862998116311, 'Total loss': 0.1288862998116311}
2022-12-31 05:54:46,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:46,842 INFO:     Epoch: 54
2022-12-31 05:54:48,445 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4663368354241053, 'Total loss': 0.4663368354241053} | train loss {'Reaction outcome loss': 0.12833614200831223, 'Total loss': 0.12833614200831223}
2022-12-31 05:54:48,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:48,445 INFO:     Epoch: 55
2022-12-31 05:54:50,088 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3965668344559769, 'Total loss': 0.3965668344559769} | train loss {'Reaction outcome loss': 0.13282473026621308, 'Total loss': 0.13282473026621308}
2022-12-31 05:54:50,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:50,088 INFO:     Epoch: 56
2022-12-31 05:54:51,687 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4211781740188599, 'Total loss': 0.4211781740188599} | train loss {'Reaction outcome loss': 0.12661407159934768, 'Total loss': 0.12661407159934768}
2022-12-31 05:54:51,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:51,687 INFO:     Epoch: 57
2022-12-31 05:54:53,319 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4145643512407939, 'Total loss': 0.4145643512407939} | train loss {'Reaction outcome loss': 0.12704502263118345, 'Total loss': 0.12704502263118345}
2022-12-31 05:54:53,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:53,319 INFO:     Epoch: 58
2022-12-31 05:54:54,967 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4145144323507945, 'Total loss': 0.4145144323507945} | train loss {'Reaction outcome loss': 0.1286828381251612, 'Total loss': 0.1286828381251612}
2022-12-31 05:54:54,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:54,967 INFO:     Epoch: 59
2022-12-31 05:54:56,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40530912776788075, 'Total loss': 0.40530912776788075} | train loss {'Reaction outcome loss': 0.12413906457325641, 'Total loss': 0.12413906457325641}
2022-12-31 05:54:56,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:56,570 INFO:     Epoch: 60
2022-12-31 05:54:58,198 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43921514600515366, 'Total loss': 0.43921514600515366} | train loss {'Reaction outcome loss': 0.12198834290434589, 'Total loss': 0.12198834290434589}
2022-12-31 05:54:58,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:58,199 INFO:     Epoch: 61
2022-12-31 05:54:59,806 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44021567900975545, 'Total loss': 0.44021567900975545} | train loss {'Reaction outcome loss': 0.11991449851106047, 'Total loss': 0.11991449851106047}
2022-12-31 05:54:59,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:54:59,807 INFO:     Epoch: 62
2022-12-31 05:55:01,422 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4042179654041926, 'Total loss': 0.4042179654041926} | train loss {'Reaction outcome loss': 0.12040034450433684, 'Total loss': 0.12040034450433684}
2022-12-31 05:55:01,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:01,422 INFO:     Epoch: 63
2022-12-31 05:55:03,044 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.443276767929395, 'Total loss': 0.443276767929395} | train loss {'Reaction outcome loss': 0.1213623652620166, 'Total loss': 0.1213623652620166}
2022-12-31 05:55:03,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:03,044 INFO:     Epoch: 64
2022-12-31 05:55:04,652 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40335049976905185, 'Total loss': 0.40335049976905185} | train loss {'Reaction outcome loss': 0.11959398574547181, 'Total loss': 0.11959398574547181}
2022-12-31 05:55:04,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:04,653 INFO:     Epoch: 65
2022-12-31 05:55:06,308 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4246404846509298, 'Total loss': 0.4246404846509298} | train loss {'Reaction outcome loss': 0.12090782207801884, 'Total loss': 0.12090782207801884}
2022-12-31 05:55:06,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:06,309 INFO:     Epoch: 66
2022-12-31 05:55:07,906 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4018280655145645, 'Total loss': 0.4018280655145645} | train loss {'Reaction outcome loss': 0.11948661873545224, 'Total loss': 0.11948661873545224}
2022-12-31 05:55:07,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:07,906 INFO:     Epoch: 67
2022-12-31 05:55:09,516 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3964749582732717, 'Total loss': 0.3964749582732717} | train loss {'Reaction outcome loss': 0.1137749125461193, 'Total loss': 0.1137749125461193}
2022-12-31 05:55:09,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:09,516 INFO:     Epoch: 68
2022-12-31 05:55:11,124 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3879174063603083, 'Total loss': 0.3879174063603083} | train loss {'Reaction outcome loss': 0.1179293057976816, 'Total loss': 0.1179293057976816}
2022-12-31 05:55:11,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:11,125 INFO:     Epoch: 69
2022-12-31 05:55:12,741 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39888235926628113, 'Total loss': 0.39888235926628113} | train loss {'Reaction outcome loss': 0.1211359961957913, 'Total loss': 0.1211359961957913}
2022-12-31 05:55:12,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:12,741 INFO:     Epoch: 70
2022-12-31 05:55:14,358 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39570780992507937, 'Total loss': 0.39570780992507937} | train loss {'Reaction outcome loss': 0.12153146055871587, 'Total loss': 0.12153146055871587}
2022-12-31 05:55:14,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:14,359 INFO:     Epoch: 71
2022-12-31 05:55:15,976 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4292855550845464, 'Total loss': 0.4292855550845464} | train loss {'Reaction outcome loss': 0.11598315730012079, 'Total loss': 0.11598315730012079}
2022-12-31 05:55:15,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:15,976 INFO:     Epoch: 72
2022-12-31 05:55:17,585 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3851763014293586, 'Total loss': 0.3851763014293586} | train loss {'Reaction outcome loss': 0.1126988495004128, 'Total loss': 0.1126988495004128}
2022-12-31 05:55:17,586 INFO:     Found new best model at epoch 72
2022-12-31 05:55:17,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:17,587 INFO:     Epoch: 73
2022-12-31 05:55:19,187 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4218047131163379, 'Total loss': 0.4218047131163379} | train loss {'Reaction outcome loss': 0.11624217625441295, 'Total loss': 0.11624217625441295}
2022-12-31 05:55:19,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:19,187 INFO:     Epoch: 74
2022-12-31 05:55:20,807 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4165995309750239, 'Total loss': 0.4165995309750239} | train loss {'Reaction outcome loss': 0.117600749933328, 'Total loss': 0.117600749933328}
2022-12-31 05:55:20,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:20,808 INFO:     Epoch: 75
2022-12-31 05:55:22,423 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40780838976303735, 'Total loss': 0.40780838976303735} | train loss {'Reaction outcome loss': 0.11734183776130962, 'Total loss': 0.11734183776130962}
2022-12-31 05:55:22,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:22,423 INFO:     Epoch: 76
2022-12-31 05:55:24,038 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4148659070332845, 'Total loss': 0.4148659070332845} | train loss {'Reaction outcome loss': 0.11878884740637773, 'Total loss': 0.11878884740637773}
2022-12-31 05:55:24,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:24,038 INFO:     Epoch: 77
2022-12-31 05:55:25,653 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45653284788131715, 'Total loss': 0.45653284788131715} | train loss {'Reaction outcome loss': 0.11552488697682517, 'Total loss': 0.11552488697682517}
2022-12-31 05:55:25,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:25,654 INFO:     Epoch: 78
2022-12-31 05:55:27,258 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4193714867035548, 'Total loss': 0.4193714867035548} | train loss {'Reaction outcome loss': 0.11192607490223024, 'Total loss': 0.11192607490223024}
2022-12-31 05:55:27,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:27,258 INFO:     Epoch: 79
2022-12-31 05:55:28,875 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44925714085499446, 'Total loss': 0.44925714085499446} | train loss {'Reaction outcome loss': 0.1109260788798032, 'Total loss': 0.1109260788798032}
2022-12-31 05:55:28,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:28,876 INFO:     Epoch: 80
2022-12-31 05:55:30,483 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38615850458542506, 'Total loss': 0.38615850458542506} | train loss {'Reaction outcome loss': 0.11609629279594431, 'Total loss': 0.11609629279594431}
2022-12-31 05:55:30,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:30,484 INFO:     Epoch: 81
2022-12-31 05:55:32,097 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4404785225788752, 'Total loss': 0.4404785225788752} | train loss {'Reaction outcome loss': 0.11600872806969334, 'Total loss': 0.11600872806969334}
2022-12-31 05:55:32,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:32,097 INFO:     Epoch: 82
2022-12-31 05:55:33,711 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.406988521416982, 'Total loss': 0.406988521416982} | train loss {'Reaction outcome loss': 0.11371993162752822, 'Total loss': 0.11371993162752822}
2022-12-31 05:55:33,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:33,711 INFO:     Epoch: 83
2022-12-31 05:55:35,326 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3914012312889099, 'Total loss': 0.3914012312889099} | train loss {'Reaction outcome loss': 0.11434024247177109, 'Total loss': 0.11434024247177109}
2022-12-31 05:55:35,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:35,327 INFO:     Epoch: 84
2022-12-31 05:55:36,927 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4146181325117747, 'Total loss': 0.4146181325117747} | train loss {'Reaction outcome loss': 0.1179856271525647, 'Total loss': 0.1179856271525647}
2022-12-31 05:55:36,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:36,927 INFO:     Epoch: 85
2022-12-31 05:55:38,575 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42721013774474464, 'Total loss': 0.42721013774474464} | train loss {'Reaction outcome loss': 0.11373670350490718, 'Total loss': 0.11373670350490718}
2022-12-31 05:55:38,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:38,575 INFO:     Epoch: 86
2022-12-31 05:55:40,222 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42718863089879355, 'Total loss': 0.42718863089879355} | train loss {'Reaction outcome loss': 0.11158157489006663, 'Total loss': 0.11158157489006663}
2022-12-31 05:55:40,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:40,223 INFO:     Epoch: 87
2022-12-31 05:55:41,869 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4150200401743253, 'Total loss': 0.4150200401743253} | train loss {'Reaction outcome loss': 0.11327612423146102, 'Total loss': 0.11327612423146102}
2022-12-31 05:55:41,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:41,871 INFO:     Epoch: 88
2022-12-31 05:55:43,467 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40663743441303574, 'Total loss': 0.40663743441303574} | train loss {'Reaction outcome loss': 0.10754206683657272, 'Total loss': 0.10754206683657272}
2022-12-31 05:55:43,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:43,467 INFO:     Epoch: 89
2022-12-31 05:55:45,063 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4432020525137583, 'Total loss': 0.4432020525137583} | train loss {'Reaction outcome loss': 0.11123529296102268, 'Total loss': 0.11123529296102268}
2022-12-31 05:55:45,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:45,063 INFO:     Epoch: 90
2022-12-31 05:55:46,707 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40286699881156285, 'Total loss': 0.40286699881156285} | train loss {'Reaction outcome loss': 0.11201409633303805, 'Total loss': 0.11201409633303805}
2022-12-31 05:55:46,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:46,708 INFO:     Epoch: 91
2022-12-31 05:55:48,316 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3868106783988575, 'Total loss': 0.3868106783988575} | train loss {'Reaction outcome loss': 0.11197128222109033, 'Total loss': 0.11197128222109033}
2022-12-31 05:55:48,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:48,317 INFO:     Epoch: 92
2022-12-31 05:55:49,911 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42415014902750653, 'Total loss': 0.42415014902750653} | train loss {'Reaction outcome loss': 0.11103964376266733, 'Total loss': 0.11103964376266733}
2022-12-31 05:55:49,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:49,911 INFO:     Epoch: 93
2022-12-31 05:55:51,558 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39030675292015077, 'Total loss': 0.39030675292015077} | train loss {'Reaction outcome loss': 0.11855330696626269, 'Total loss': 0.11855330696626269}
2022-12-31 05:55:51,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:51,558 INFO:     Epoch: 94
2022-12-31 05:55:53,155 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4098052407304446, 'Total loss': 0.4098052407304446} | train loss {'Reaction outcome loss': 0.11131629726556112, 'Total loss': 0.11131629726556112}
2022-12-31 05:55:53,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:53,156 INFO:     Epoch: 95
2022-12-31 05:55:54,780 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4384655793507894, 'Total loss': 0.4384655793507894} | train loss {'Reaction outcome loss': 0.11090645912673065, 'Total loss': 0.11090645912673065}
2022-12-31 05:55:54,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:54,780 INFO:     Epoch: 96
2022-12-31 05:55:56,393 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4250914881626765, 'Total loss': 0.4250914881626765} | train loss {'Reaction outcome loss': 0.10876221958063406, 'Total loss': 0.10876221958063406}
2022-12-31 05:55:56,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:56,393 INFO:     Epoch: 97
2022-12-31 05:55:58,000 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4384385426839193, 'Total loss': 0.4384385426839193} | train loss {'Reaction outcome loss': 0.10586448260045682, 'Total loss': 0.10586448260045682}
2022-12-31 05:55:58,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:58,000 INFO:     Epoch: 98
2022-12-31 05:55:59,616 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3999050279458364, 'Total loss': 0.3999050279458364} | train loss {'Reaction outcome loss': 0.10820108029527432, 'Total loss': 0.10820108029527432}
2022-12-31 05:55:59,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:55:59,616 INFO:     Epoch: 99
2022-12-31 05:56:01,230 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4316220740477244, 'Total loss': 0.4316220740477244} | train loss {'Reaction outcome loss': 0.10755607937786714, 'Total loss': 0.10755607937786714}
2022-12-31 05:56:01,231 INFO:     Best model found after epoch 73 of 100.
2022-12-31 05:56:01,231 INFO:   Done with stage: TRAINING
2022-12-31 05:56:01,231 INFO:   Starting stage: EVALUATION
2022-12-31 05:56:01,374 INFO:   Done with stage: EVALUATION
2022-12-31 05:56:01,374 INFO:   Leaving out SEQ value Fold_1
2022-12-31 05:56:01,386 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 05:56:01,387 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:56:02,020 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:56:02,021 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:56:02,091 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:56:02,091 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:56:02,091 INFO:     No hyperparam tuning for this model
2022-12-31 05:56:02,091 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:56:02,091 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:56:02,092 INFO:     None feature selector for col prot
2022-12-31 05:56:02,092 INFO:     None feature selector for col prot
2022-12-31 05:56:02,092 INFO:     None feature selector for col prot
2022-12-31 05:56:02,093 INFO:     None feature selector for col chem
2022-12-31 05:56:02,093 INFO:     None feature selector for col chem
2022-12-31 05:56:02,093 INFO:     None feature selector for col chem
2022-12-31 05:56:02,093 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:56:02,093 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:56:02,095 INFO:     Number of params in model 224011
2022-12-31 05:56:02,098 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:56:02,098 INFO:   Starting stage: TRAINING
2022-12-31 05:56:02,142 INFO:     Val loss before train {'Reaction outcome loss': 1.0457563360532125, 'Total loss': 1.0457563360532125}
2022-12-31 05:56:02,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:02,143 INFO:     Epoch: 0
2022-12-31 05:56:03,762 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6442762792110444, 'Total loss': 0.6442762792110444} | train loss {'Reaction outcome loss': 0.7886893502334609, 'Total loss': 0.7886893502334609}
2022-12-31 05:56:03,762 INFO:     Found new best model at epoch 0
2022-12-31 05:56:03,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:03,763 INFO:     Epoch: 1
2022-12-31 05:56:05,372 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5547668675581614, 'Total loss': 0.5547668675581614} | train loss {'Reaction outcome loss': 0.522813946334985, 'Total loss': 0.522813946334985}
2022-12-31 05:56:05,372 INFO:     Found new best model at epoch 1
2022-12-31 05:56:05,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:05,373 INFO:     Epoch: 2
2022-12-31 05:56:06,992 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5090023815631867, 'Total loss': 0.5090023815631867} | train loss {'Reaction outcome loss': 0.44491747271840587, 'Total loss': 0.44491747271840587}
2022-12-31 05:56:06,992 INFO:     Found new best model at epoch 2
2022-12-31 05:56:06,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:06,993 INFO:     Epoch: 3
2022-12-31 05:56:08,613 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47767797311147053, 'Total loss': 0.47767797311147053} | train loss {'Reaction outcome loss': 0.40416940296218345, 'Total loss': 0.40416940296218345}
2022-12-31 05:56:08,613 INFO:     Found new best model at epoch 3
2022-12-31 05:56:08,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:08,614 INFO:     Epoch: 4
2022-12-31 05:56:10,233 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4742463886737823, 'Total loss': 0.4742463886737823} | train loss {'Reaction outcome loss': 0.37041637693008367, 'Total loss': 0.37041637693008367}
2022-12-31 05:56:10,234 INFO:     Found new best model at epoch 4
2022-12-31 05:56:10,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:10,235 INFO:     Epoch: 5
2022-12-31 05:56:11,854 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4770499428113302, 'Total loss': 0.4770499428113302} | train loss {'Reaction outcome loss': 0.3443662256926951, 'Total loss': 0.3443662256926951}
2022-12-31 05:56:11,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:11,854 INFO:     Epoch: 6
2022-12-31 05:56:13,457 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4695509155591329, 'Total loss': 0.4695509155591329} | train loss {'Reaction outcome loss': 0.324042911566522, 'Total loss': 0.324042911566522}
2022-12-31 05:56:13,458 INFO:     Found new best model at epoch 6
2022-12-31 05:56:13,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:13,459 INFO:     Epoch: 7
2022-12-31 05:56:15,098 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4616044580936432, 'Total loss': 0.4616044580936432} | train loss {'Reaction outcome loss': 0.30138223922818247, 'Total loss': 0.30138223922818247}
2022-12-31 05:56:15,098 INFO:     Found new best model at epoch 7
2022-12-31 05:56:15,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:15,099 INFO:     Epoch: 8
2022-12-31 05:56:16,708 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42660925835371016, 'Total loss': 0.42660925835371016} | train loss {'Reaction outcome loss': 0.29137533900402757, 'Total loss': 0.29137533900402757}
2022-12-31 05:56:16,708 INFO:     Found new best model at epoch 8
2022-12-31 05:56:16,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:16,709 INFO:     Epoch: 9
2022-12-31 05:56:18,319 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4639058530330658, 'Total loss': 0.4639058530330658} | train loss {'Reaction outcome loss': 0.2777721943320149, 'Total loss': 0.2777721943320149}
2022-12-31 05:56:18,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:18,320 INFO:     Epoch: 10
2022-12-31 05:56:19,973 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4629818896452586, 'Total loss': 0.4629818896452586} | train loss {'Reaction outcome loss': 0.2630353169991587, 'Total loss': 0.2630353169991587}
2022-12-31 05:56:19,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:19,974 INFO:     Epoch: 11
2022-12-31 05:56:21,571 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4589611887931824, 'Total loss': 0.4589611887931824} | train loss {'Reaction outcome loss': 0.25465848143926284, 'Total loss': 0.25465848143926284}
2022-12-31 05:56:21,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:21,571 INFO:     Epoch: 12
2022-12-31 05:56:23,225 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4676111270984014, 'Total loss': 0.4676111270984014} | train loss {'Reaction outcome loss': 0.2457030717093144, 'Total loss': 0.2457030717093144}
2022-12-31 05:56:23,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:23,225 INFO:     Epoch: 13
2022-12-31 05:56:24,839 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4413494775692622, 'Total loss': 0.4413494775692622} | train loss {'Reaction outcome loss': 0.23652249998854893, 'Total loss': 0.23652249998854893}
2022-12-31 05:56:24,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:24,839 INFO:     Epoch: 14
2022-12-31 05:56:26,461 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48619521260261533, 'Total loss': 0.48619521260261533} | train loss {'Reaction outcome loss': 0.22711422639715412, 'Total loss': 0.22711422639715412}
2022-12-31 05:56:26,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:26,462 INFO:     Epoch: 15
2022-12-31 05:56:28,082 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5005029380321503, 'Total loss': 0.5005029380321503} | train loss {'Reaction outcome loss': 0.21852779977812167, 'Total loss': 0.21852779977812167}
2022-12-31 05:56:28,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:28,083 INFO:     Epoch: 16
2022-12-31 05:56:29,704 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4650947660207748, 'Total loss': 0.4650947660207748} | train loss {'Reaction outcome loss': 0.2161475324010762, 'Total loss': 0.2161475324010762}
2022-12-31 05:56:29,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:29,704 INFO:     Epoch: 17
2022-12-31 05:56:31,317 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48585731685161593, 'Total loss': 0.48585731685161593} | train loss {'Reaction outcome loss': 0.20755976608471713, 'Total loss': 0.20755976608471713}
2022-12-31 05:56:31,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:31,317 INFO:     Epoch: 18
2022-12-31 05:56:32,929 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4706205944220225, 'Total loss': 0.4706205944220225} | train loss {'Reaction outcome loss': 0.20601335902745924, 'Total loss': 0.20601335902745924}
2022-12-31 05:56:32,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:32,929 INFO:     Epoch: 19
2022-12-31 05:56:34,551 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4633461207151413, 'Total loss': 0.4633461207151413} | train loss {'Reaction outcome loss': 0.19971145214988803, 'Total loss': 0.19971145214988803}
2022-12-31 05:56:34,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:34,552 INFO:     Epoch: 20
2022-12-31 05:56:36,171 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4862429032723109, 'Total loss': 0.4862429032723109} | train loss {'Reaction outcome loss': 0.194867699155516, 'Total loss': 0.194867699155516}
2022-12-31 05:56:36,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:36,171 INFO:     Epoch: 21
2022-12-31 05:56:37,795 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46909798483053844, 'Total loss': 0.46909798483053844} | train loss {'Reaction outcome loss': 0.1887282504271852, 'Total loss': 0.1887282504271852}
2022-12-31 05:56:37,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:37,795 INFO:     Epoch: 22
2022-12-31 05:56:39,411 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48199502925078075, 'Total loss': 0.48199502925078075} | train loss {'Reaction outcome loss': 0.18670501736720113, 'Total loss': 0.18670501736720113}
2022-12-31 05:56:39,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:39,411 INFO:     Epoch: 23
2022-12-31 05:56:41,042 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4876059090097745, 'Total loss': 0.4876059090097745} | train loss {'Reaction outcome loss': 0.18400223994369272, 'Total loss': 0.18400223994369272}
2022-12-31 05:56:41,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:41,042 INFO:     Epoch: 24
2022-12-31 05:56:42,667 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4861402640740077, 'Total loss': 0.4861402640740077} | train loss {'Reaction outcome loss': 0.18017877668930884, 'Total loss': 0.18017877668930884}
2022-12-31 05:56:42,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:42,667 INFO:     Epoch: 25
2022-12-31 05:56:44,320 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47699129978815713, 'Total loss': 0.47699129978815713} | train loss {'Reaction outcome loss': 0.1761728800377761, 'Total loss': 0.1761728800377761}
2022-12-31 05:56:44,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:44,320 INFO:     Epoch: 26
2022-12-31 05:56:45,973 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4967894583940506, 'Total loss': 0.4967894583940506} | train loss {'Reaction outcome loss': 0.1744604887896265, 'Total loss': 0.1744604887896265}
2022-12-31 05:56:45,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:45,973 INFO:     Epoch: 27
2022-12-31 05:56:47,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46269146328171096, 'Total loss': 0.46269146328171096} | train loss {'Reaction outcome loss': 0.16940219195246914, 'Total loss': 0.16940219195246914}
2022-12-31 05:56:47,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:47,626 INFO:     Epoch: 28
2022-12-31 05:56:49,261 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48418670892715454, 'Total loss': 0.48418670892715454} | train loss {'Reaction outcome loss': 0.1670091603542712, 'Total loss': 0.1670091603542712}
2022-12-31 05:56:49,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:49,263 INFO:     Epoch: 29
2022-12-31 05:56:50,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4972718134522438, 'Total loss': 0.4972718134522438} | train loss {'Reaction outcome loss': 0.16431067476429753, 'Total loss': 0.16431067476429753}
2022-12-31 05:56:50,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:50,873 INFO:     Epoch: 30
2022-12-31 05:56:52,486 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4788599004348119, 'Total loss': 0.4788599004348119} | train loss {'Reaction outcome loss': 0.16235519593826284, 'Total loss': 0.16235519593826284}
2022-12-31 05:56:52,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:52,486 INFO:     Epoch: 31
2022-12-31 05:56:54,105 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5042360464731852, 'Total loss': 0.5042360464731852} | train loss {'Reaction outcome loss': 0.16295908691606273, 'Total loss': 0.16295908691606273}
2022-12-31 05:56:54,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:54,106 INFO:     Epoch: 32
2022-12-31 05:56:55,726 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46097775002320607, 'Total loss': 0.46097775002320607} | train loss {'Reaction outcome loss': 0.1605939048539548, 'Total loss': 0.1605939048539548}
2022-12-31 05:56:55,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:55,727 INFO:     Epoch: 33
2022-12-31 05:56:57,348 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4654903004566828, 'Total loss': 0.4654903004566828} | train loss {'Reaction outcome loss': 0.15741424293454437, 'Total loss': 0.15741424293454437}
2022-12-31 05:56:57,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:57,348 INFO:     Epoch: 34
2022-12-31 05:56:58,957 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47287800113360084, 'Total loss': 0.47287800113360084} | train loss {'Reaction outcome loss': 0.15567357176031074, 'Total loss': 0.15567357176031074}
2022-12-31 05:56:58,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:56:58,957 INFO:     Epoch: 35
2022-12-31 05:57:00,570 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4847861960530281, 'Total loss': 0.4847861960530281} | train loss {'Reaction outcome loss': 0.1552985424208149, 'Total loss': 0.1552985424208149}
2022-12-31 05:57:00,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:00,570 INFO:     Epoch: 36
2022-12-31 05:57:02,191 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46854915221532184, 'Total loss': 0.46854915221532184} | train loss {'Reaction outcome loss': 0.15276678014940914, 'Total loss': 0.15276678014940914}
2022-12-31 05:57:02,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:02,191 INFO:     Epoch: 37
2022-12-31 05:57:03,811 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44815635283788047, 'Total loss': 0.44815635283788047} | train loss {'Reaction outcome loss': 0.14853850704189525, 'Total loss': 0.14853850704189525}
2022-12-31 05:57:03,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:03,812 INFO:     Epoch: 38
2022-12-31 05:57:05,432 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48963083922863004, 'Total loss': 0.48963083922863004} | train loss {'Reaction outcome loss': 0.14969125466190114, 'Total loss': 0.14969125466190114}
2022-12-31 05:57:05,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:05,432 INFO:     Epoch: 39
2022-12-31 05:57:07,043 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5065960109233856, 'Total loss': 0.5065960109233856} | train loss {'Reaction outcome loss': 0.14635024141574646, 'Total loss': 0.14635024141574646}
2022-12-31 05:57:07,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:07,043 INFO:     Epoch: 40
2022-12-31 05:57:08,664 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47034120361010234, 'Total loss': 0.47034120361010234} | train loss {'Reaction outcome loss': 0.14626782351465772, 'Total loss': 0.14626782351465772}
2022-12-31 05:57:08,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:08,665 INFO:     Epoch: 41
2022-12-31 05:57:10,275 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.490922478834788, 'Total loss': 0.490922478834788} | train loss {'Reaction outcome loss': 0.14314225593744948, 'Total loss': 0.14314225593744948}
2022-12-31 05:57:10,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:10,275 INFO:     Epoch: 42
2022-12-31 05:57:11,894 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.455545374751091, 'Total loss': 0.455545374751091} | train loss {'Reaction outcome loss': 0.14189094780216904, 'Total loss': 0.14189094780216904}
2022-12-31 05:57:11,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:11,894 INFO:     Epoch: 43
2022-12-31 05:57:13,515 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46010359103480974, 'Total loss': 0.46010359103480974} | train loss {'Reaction outcome loss': 0.13903489272470457, 'Total loss': 0.13903489272470457}
2022-12-31 05:57:13,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:13,515 INFO:     Epoch: 44
2022-12-31 05:57:15,136 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5196165253718694, 'Total loss': 0.5196165253718694} | train loss {'Reaction outcome loss': 0.14183546617511578, 'Total loss': 0.14183546617511578}
2022-12-31 05:57:15,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:15,137 INFO:     Epoch: 45
2022-12-31 05:57:16,749 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47591057370106377, 'Total loss': 0.47591057370106377} | train loss {'Reaction outcome loss': 0.1441144188152232, 'Total loss': 0.1441144188152232}
2022-12-31 05:57:16,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:16,749 INFO:     Epoch: 46
2022-12-31 05:57:18,363 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4794763634602229, 'Total loss': 0.4794763634602229} | train loss {'Reaction outcome loss': 0.1392731646238996, 'Total loss': 0.1392731646238996}
2022-12-31 05:57:18,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:18,363 INFO:     Epoch: 47
2022-12-31 05:57:19,979 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4770061194896698, 'Total loss': 0.4770061194896698} | train loss {'Reaction outcome loss': 0.13771093052295275, 'Total loss': 0.13771093052295275}
2022-12-31 05:57:19,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:19,979 INFO:     Epoch: 48
2022-12-31 05:57:21,599 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4612736701965332, 'Total loss': 0.4612736701965332} | train loss {'Reaction outcome loss': 0.13696581367947105, 'Total loss': 0.13696581367947105}
2022-12-31 05:57:21,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:21,599 INFO:     Epoch: 49
2022-12-31 05:57:23,217 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5193250894546508, 'Total loss': 0.5193250894546508} | train loss {'Reaction outcome loss': 0.13637105313326864, 'Total loss': 0.13637105313326864}
2022-12-31 05:57:23,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:23,217 INFO:     Epoch: 50
2022-12-31 05:57:24,836 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5013378938039144, 'Total loss': 0.5013378938039144} | train loss {'Reaction outcome loss': 0.1384254234322911, 'Total loss': 0.1384254234322911}
2022-12-31 05:57:24,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:24,837 INFO:     Epoch: 51
2022-12-31 05:57:26,444 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4959058622519175, 'Total loss': 0.4959058622519175} | train loss {'Reaction outcome loss': 0.1312917432251529, 'Total loss': 0.1312917432251529}
2022-12-31 05:57:26,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:26,445 INFO:     Epoch: 52
2022-12-31 05:57:28,058 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5028783808151881, 'Total loss': 0.5028783808151881} | train loss {'Reaction outcome loss': 0.13182570450143874, 'Total loss': 0.13182570450143874}
2022-12-31 05:57:28,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:28,058 INFO:     Epoch: 53
2022-12-31 05:57:29,679 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5066640118757884, 'Total loss': 0.5066640118757884} | train loss {'Reaction outcome loss': 0.13689696585528388, 'Total loss': 0.13689696585528388}
2022-12-31 05:57:29,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:29,679 INFO:     Epoch: 54
2022-12-31 05:57:31,300 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4985164890686671, 'Total loss': 0.4985164890686671} | train loss {'Reaction outcome loss': 0.13418874988182836, 'Total loss': 0.13418874988182836}
2022-12-31 05:57:31,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:31,301 INFO:     Epoch: 55
2022-12-31 05:57:32,922 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5169450054566066, 'Total loss': 0.5169450054566066} | train loss {'Reaction outcome loss': 0.13160697005886285, 'Total loss': 0.13160697005886285}
2022-12-31 05:57:32,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:32,922 INFO:     Epoch: 56
2022-12-31 05:57:34,532 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4917968322833379, 'Total loss': 0.4917968322833379} | train loss {'Reaction outcome loss': 0.13180624371238162, 'Total loss': 0.13180624371238162}
2022-12-31 05:57:34,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:34,532 INFO:     Epoch: 57
2022-12-31 05:57:36,151 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4946450034777323, 'Total loss': 0.4946450034777323} | train loss {'Reaction outcome loss': 0.1291010110540465, 'Total loss': 0.1291010110540465}
2022-12-31 05:57:36,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:36,151 INFO:     Epoch: 58
2022-12-31 05:57:37,787 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5244026402632396, 'Total loss': 0.5244026402632396} | train loss {'Reaction outcome loss': 0.1299398861550148, 'Total loss': 0.1299398861550148}
2022-12-31 05:57:37,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:37,788 INFO:     Epoch: 59
2022-12-31 05:57:39,399 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49825045963128406, 'Total loss': 0.49825045963128406} | train loss {'Reaction outcome loss': 0.12793959344628464, 'Total loss': 0.12793959344628464}
2022-12-31 05:57:39,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:39,399 INFO:     Epoch: 60
2022-12-31 05:57:41,031 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4466181511680285, 'Total loss': 0.4466181511680285} | train loss {'Reaction outcome loss': 0.13068800918200482, 'Total loss': 0.13068800918200482}
2022-12-31 05:57:41,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:41,031 INFO:     Epoch: 61
2022-12-31 05:57:42,641 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4505351682504018, 'Total loss': 0.4505351682504018} | train loss {'Reaction outcome loss': 0.1307675603855347, 'Total loss': 0.1307675603855347}
2022-12-31 05:57:42,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:42,641 INFO:     Epoch: 62
2022-12-31 05:57:44,242 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45902678966522215, 'Total loss': 0.45902678966522215} | train loss {'Reaction outcome loss': 0.12865802458569026, 'Total loss': 0.12865802458569026}
2022-12-31 05:57:44,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:44,243 INFO:     Epoch: 63
2022-12-31 05:57:45,856 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48197539150714874, 'Total loss': 0.48197539150714874} | train loss {'Reaction outcome loss': 0.12313155960597533, 'Total loss': 0.12313155960597533}
2022-12-31 05:57:45,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:45,856 INFO:     Epoch: 64
2022-12-31 05:57:47,507 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5050225953261057, 'Total loss': 0.5050225953261057} | train loss {'Reaction outcome loss': 0.12605774157721358, 'Total loss': 0.12605774157721358}
2022-12-31 05:57:47,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:47,508 INFO:     Epoch: 65
2022-12-31 05:57:49,117 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47712680300076804, 'Total loss': 0.47712680300076804} | train loss {'Reaction outcome loss': 0.1267316590851839, 'Total loss': 0.1267316590851839}
2022-12-31 05:57:49,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:49,118 INFO:     Epoch: 66
2022-12-31 05:57:50,772 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48372417291005454, 'Total loss': 0.48372417291005454} | train loss {'Reaction outcome loss': 0.1225588079422957, 'Total loss': 0.1225588079422957}
2022-12-31 05:57:50,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:50,772 INFO:     Epoch: 67
2022-12-31 05:57:52,381 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4617482364177704, 'Total loss': 0.4617482364177704} | train loss {'Reaction outcome loss': 0.12025884732971118, 'Total loss': 0.12025884732971118}
2022-12-31 05:57:52,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:52,381 INFO:     Epoch: 68
2022-12-31 05:57:54,019 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5025938312212627, 'Total loss': 0.5025938312212627} | train loss {'Reaction outcome loss': 0.12157427034014497, 'Total loss': 0.12157427034014497}
2022-12-31 05:57:54,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:54,020 INFO:     Epoch: 69
2022-12-31 05:57:55,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5012216498454412, 'Total loss': 0.5012216498454412} | train loss {'Reaction outcome loss': 0.12176201397206389, 'Total loss': 0.12176201397206389}
2022-12-31 05:57:55,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:55,647 INFO:     Epoch: 70
2022-12-31 05:57:57,266 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5449643949667613, 'Total loss': 0.5449643949667613} | train loss {'Reaction outcome loss': 0.12340816972695672, 'Total loss': 0.12340816972695672}
2022-12-31 05:57:57,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:57,266 INFO:     Epoch: 71
2022-12-31 05:57:58,884 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5025291989247004, 'Total loss': 0.5025291989247004} | train loss {'Reaction outcome loss': 0.12561838689640872, 'Total loss': 0.12561838689640872}
2022-12-31 05:57:58,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:57:58,885 INFO:     Epoch: 72
2022-12-31 05:58:00,504 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4635839223861694, 'Total loss': 0.4635839223861694} | train loss {'Reaction outcome loss': 0.12119564568678284, 'Total loss': 0.12119564568678284}
2022-12-31 05:58:00,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:00,506 INFO:     Epoch: 73
2022-12-31 05:58:02,109 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.512437226374944, 'Total loss': 0.512437226374944} | train loss {'Reaction outcome loss': 0.1257223758938294, 'Total loss': 0.1257223758938294}
2022-12-31 05:58:02,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:02,109 INFO:     Epoch: 74
2022-12-31 05:58:03,722 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48449651996294657, 'Total loss': 0.48449651996294657} | train loss {'Reaction outcome loss': 0.12067200404245161, 'Total loss': 0.12067200404245161}
2022-12-31 05:58:03,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:03,722 INFO:     Epoch: 75
2022-12-31 05:58:05,329 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5032839906712373, 'Total loss': 0.5032839906712373} | train loss {'Reaction outcome loss': 0.11788420696032444, 'Total loss': 0.11788420696032444}
2022-12-31 05:58:05,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:05,329 INFO:     Epoch: 76
2022-12-31 05:58:06,944 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46928630272547406, 'Total loss': 0.46928630272547406} | train loss {'Reaction outcome loss': 0.12058976318867347, 'Total loss': 0.12058976318867347}
2022-12-31 05:58:06,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:06,945 INFO:     Epoch: 77
2022-12-31 05:58:08,563 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48694083392620086, 'Total loss': 0.48694083392620086} | train loss {'Reaction outcome loss': 0.1173623066436309, 'Total loss': 0.1173623066436309}
2022-12-31 05:58:08,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:08,563 INFO:     Epoch: 78
2022-12-31 05:58:10,182 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5198559592167536, 'Total loss': 0.5198559592167536} | train loss {'Reaction outcome loss': 0.11982642003015553, 'Total loss': 0.11982642003015553}
2022-12-31 05:58:10,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:10,182 INFO:     Epoch: 79
2022-12-31 05:58:11,792 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5224258204301199, 'Total loss': 0.5224258204301199} | train loss {'Reaction outcome loss': 0.11681653249900054, 'Total loss': 0.11681653249900054}
2022-12-31 05:58:11,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:11,793 INFO:     Epoch: 80
2022-12-31 05:58:13,399 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5040916363398235, 'Total loss': 0.5040916363398235} | train loss {'Reaction outcome loss': 0.11628559349702984, 'Total loss': 0.11628559349702984}
2022-12-31 05:58:13,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:13,400 INFO:     Epoch: 81
2022-12-31 05:58:15,015 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.499910831451416, 'Total loss': 0.499910831451416} | train loss {'Reaction outcome loss': 0.11524558312133852, 'Total loss': 0.11524558312133852}
2022-12-31 05:58:15,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:15,015 INFO:     Epoch: 82
2022-12-31 05:58:16,631 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4688445761799812, 'Total loss': 0.4688445761799812} | train loss {'Reaction outcome loss': 0.1213244555541824, 'Total loss': 0.1213244555541824}
2022-12-31 05:58:16,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:16,631 INFO:     Epoch: 83
2022-12-31 05:58:18,247 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4968671123186747, 'Total loss': 0.4968671123186747} | train loss {'Reaction outcome loss': 0.11516161694150609, 'Total loss': 0.11516161694150609}
2022-12-31 05:58:18,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:18,247 INFO:     Epoch: 84
2022-12-31 05:58:19,858 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5352605233589808, 'Total loss': 0.5352605233589808} | train loss {'Reaction outcome loss': 0.11364421775788884, 'Total loss': 0.11364421775788884}
2022-12-31 05:58:19,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:19,859 INFO:     Epoch: 85
2022-12-31 05:58:21,462 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5274488925933838, 'Total loss': 0.5274488925933838} | train loss {'Reaction outcome loss': 0.11365921775908991, 'Total loss': 0.11365921775908991}
2022-12-31 05:58:21,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:21,462 INFO:     Epoch: 86
2022-12-31 05:58:23,090 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4630059907833735, 'Total loss': 0.4630059907833735} | train loss {'Reaction outcome loss': 0.11269453882552466, 'Total loss': 0.11269453882552466}
2022-12-31 05:58:23,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:23,090 INFO:     Epoch: 87
2022-12-31 05:58:24,696 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49614991346995035, 'Total loss': 0.49614991346995035} | train loss {'Reaction outcome loss': 0.11738497598001557, 'Total loss': 0.11738497598001557}
2022-12-31 05:58:24,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:24,696 INFO:     Epoch: 88
2022-12-31 05:58:26,303 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4943649391333262, 'Total loss': 0.4943649391333262} | train loss {'Reaction outcome loss': 0.11184169521324173, 'Total loss': 0.11184169521324173}
2022-12-31 05:58:26,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:26,304 INFO:     Epoch: 89
2022-12-31 05:58:27,930 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49944772919019065, 'Total loss': 0.49944772919019065} | train loss {'Reaction outcome loss': 0.11348458738270195, 'Total loss': 0.11348458738270195}
2022-12-31 05:58:27,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:27,930 INFO:     Epoch: 90
2022-12-31 05:58:29,533 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5068146924177805, 'Total loss': 0.5068146924177805} | train loss {'Reaction outcome loss': 0.11477114282714979, 'Total loss': 0.11477114282714979}
2022-12-31 05:58:29,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:29,533 INFO:     Epoch: 91
2022-12-31 05:58:31,180 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.501595268646876, 'Total loss': 0.501595268646876} | train loss {'Reaction outcome loss': 0.12057513501631083, 'Total loss': 0.12057513501631083}
2022-12-31 05:58:31,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:31,181 INFO:     Epoch: 92
2022-12-31 05:58:32,796 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4577114517490069, 'Total loss': 0.4577114517490069} | train loss {'Reaction outcome loss': 0.1172455860638352, 'Total loss': 0.1172455860638352}
2022-12-31 05:58:32,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:32,796 INFO:     Epoch: 93
2022-12-31 05:58:34,415 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5238492568333943, 'Total loss': 0.5238492568333943} | train loss {'Reaction outcome loss': 0.10895348234819316, 'Total loss': 0.10895348234819316}
2022-12-31 05:58:34,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:34,415 INFO:     Epoch: 94
2022-12-31 05:58:36,034 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4790285140275955, 'Total loss': 0.4790285140275955} | train loss {'Reaction outcome loss': 0.10995926316929505, 'Total loss': 0.10995926316929505}
2022-12-31 05:58:36,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:36,034 INFO:     Epoch: 95
2022-12-31 05:58:37,654 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4730894376834234, 'Total loss': 0.4730894376834234} | train loss {'Reaction outcome loss': 0.11059090456785974, 'Total loss': 0.11059090456785974}
2022-12-31 05:58:37,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:37,655 INFO:     Epoch: 96
2022-12-31 05:58:39,263 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45114694063862165, 'Total loss': 0.45114694063862165} | train loss {'Reaction outcome loss': 0.11057963368931555, 'Total loss': 0.11057963368931555}
2022-12-31 05:58:39,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:39,263 INFO:     Epoch: 97
2022-12-31 05:58:40,866 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.510759977499644, 'Total loss': 0.510759977499644} | train loss {'Reaction outcome loss': 0.1106591878057777, 'Total loss': 0.1106591878057777}
2022-12-31 05:58:40,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:40,866 INFO:     Epoch: 98
2022-12-31 05:58:42,483 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5085781802733739, 'Total loss': 0.5085781802733739} | train loss {'Reaction outcome loss': 0.1067401454928433, 'Total loss': 0.1067401454928433}
2022-12-31 05:58:42,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:42,483 INFO:     Epoch: 99
2022-12-31 05:58:44,099 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46589853763580324, 'Total loss': 0.46589853763580324} | train loss {'Reaction outcome loss': 0.11136864041263768, 'Total loss': 0.11136864041263768}
2022-12-31 05:58:44,099 INFO:     Best model found after epoch 9 of 100.
2022-12-31 05:58:44,099 INFO:   Done with stage: TRAINING
2022-12-31 05:58:44,100 INFO:   Starting stage: EVALUATION
2022-12-31 05:58:44,238 INFO:   Done with stage: EVALUATION
2022-12-31 05:58:44,239 INFO:   Leaving out SEQ value Fold_2
2022-12-31 05:58:44,251 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 05:58:44,251 INFO:   Starting stage: FEATURE SCALING
2022-12-31 05:58:44,890 INFO:   Done with stage: FEATURE SCALING
2022-12-31 05:58:44,890 INFO:   Starting stage: SCALING TARGETS
2022-12-31 05:58:44,961 INFO:   Done with stage: SCALING TARGETS
2022-12-31 05:58:44,961 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:58:44,961 INFO:     No hyperparam tuning for this model
2022-12-31 05:58:44,961 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 05:58:44,961 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 05:58:44,962 INFO:     None feature selector for col prot
2022-12-31 05:58:44,962 INFO:     None feature selector for col prot
2022-12-31 05:58:44,962 INFO:     None feature selector for col prot
2022-12-31 05:58:44,962 INFO:     None feature selector for col chem
2022-12-31 05:58:44,962 INFO:     None feature selector for col chem
2022-12-31 05:58:44,963 INFO:     None feature selector for col chem
2022-12-31 05:58:44,963 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 05:58:44,963 INFO:   Starting stage: BUILD MODEL
2022-12-31 05:58:44,964 INFO:     Number of params in model 224011
2022-12-31 05:58:44,968 INFO:   Done with stage: BUILD MODEL
2022-12-31 05:58:44,968 INFO:   Starting stage: TRAINING
2022-12-31 05:58:45,014 INFO:     Val loss before train {'Reaction outcome loss': 1.0027566572030386, 'Total loss': 1.0027566572030386}
2022-12-31 05:58:45,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:45,014 INFO:     Epoch: 0
2022-12-31 05:58:46,640 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5462348163127899, 'Total loss': 0.5462348163127899} | train loss {'Reaction outcome loss': 0.7620085373029604, 'Total loss': 0.7620085373029604}
2022-12-31 05:58:46,640 INFO:     Found new best model at epoch 0
2022-12-31 05:58:46,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:46,641 INFO:     Epoch: 1
2022-12-31 05:58:48,240 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4914639060695966, 'Total loss': 0.4914639060695966} | train loss {'Reaction outcome loss': 0.501991194014475, 'Total loss': 0.501991194014475}
2022-12-31 05:58:48,241 INFO:     Found new best model at epoch 1
2022-12-31 05:58:48,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:48,242 INFO:     Epoch: 2
2022-12-31 05:58:49,864 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4611032764116923, 'Total loss': 0.4611032764116923} | train loss {'Reaction outcome loss': 0.443036016363364, 'Total loss': 0.443036016363364}
2022-12-31 05:58:49,865 INFO:     Found new best model at epoch 2
2022-12-31 05:58:49,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:49,866 INFO:     Epoch: 3
2022-12-31 05:58:51,474 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4470070779323578, 'Total loss': 0.4470070779323578} | train loss {'Reaction outcome loss': 0.40372851469141224, 'Total loss': 0.40372851469141224}
2022-12-31 05:58:51,474 INFO:     Found new best model at epoch 3
2022-12-31 05:58:51,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:51,475 INFO:     Epoch: 4
2022-12-31 05:58:53,089 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44140389760335286, 'Total loss': 0.44140389760335286} | train loss {'Reaction outcome loss': 0.3731529340420887, 'Total loss': 0.3731529340420887}
2022-12-31 05:58:53,089 INFO:     Found new best model at epoch 4
2022-12-31 05:58:53,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:53,090 INFO:     Epoch: 5
2022-12-31 05:58:54,702 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4791786511739095, 'Total loss': 0.4791786511739095} | train loss {'Reaction outcome loss': 0.3515386545396113, 'Total loss': 0.3515386545396113}
2022-12-31 05:58:54,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:54,702 INFO:     Epoch: 6
2022-12-31 05:58:56,304 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44599559903144836, 'Total loss': 0.44599559903144836} | train loss {'Reaction outcome loss': 0.3362990739745098, 'Total loss': 0.3362990739745098}
2022-12-31 05:58:56,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:56,304 INFO:     Epoch: 7
2022-12-31 05:58:57,908 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4369144082069397, 'Total loss': 0.4369144082069397} | train loss {'Reaction outcome loss': 0.31736304027270595, 'Total loss': 0.31736304027270595}
2022-12-31 05:58:57,908 INFO:     Found new best model at epoch 7
2022-12-31 05:58:57,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:57,909 INFO:     Epoch: 8
2022-12-31 05:58:59,511 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3912659868597984, 'Total loss': 0.3912659868597984} | train loss {'Reaction outcome loss': 0.3030736165551039, 'Total loss': 0.3030736165551039}
2022-12-31 05:58:59,511 INFO:     Found new best model at epoch 8
2022-12-31 05:58:59,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:58:59,512 INFO:     Epoch: 9
2022-12-31 05:59:01,124 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40415183703104657, 'Total loss': 0.40415183703104657} | train loss {'Reaction outcome loss': 0.2872482731992945, 'Total loss': 0.2872482731992945}
2022-12-31 05:59:01,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:01,125 INFO:     Epoch: 10
2022-12-31 05:59:02,738 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4266173472007116, 'Total loss': 0.4266173472007116} | train loss {'Reaction outcome loss': 0.2751286013031399, 'Total loss': 0.2751286013031399}
2022-12-31 05:59:02,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:02,738 INFO:     Epoch: 11
2022-12-31 05:59:04,352 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4307615021864573, 'Total loss': 0.4307615021864573} | train loss {'Reaction outcome loss': 0.2618040771602274, 'Total loss': 0.2618040771602274}
2022-12-31 05:59:04,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:04,352 INFO:     Epoch: 12
2022-12-31 05:59:05,956 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42879047443469365, 'Total loss': 0.42879047443469365} | train loss {'Reaction outcome loss': 0.25190769426606513, 'Total loss': 0.25190769426606513}
2022-12-31 05:59:05,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:05,956 INFO:     Epoch: 13
2022-12-31 05:59:07,562 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4393181264400482, 'Total loss': 0.4393181264400482} | train loss {'Reaction outcome loss': 0.2485780818012608, 'Total loss': 0.2485780818012608}
2022-12-31 05:59:07,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:07,562 INFO:     Epoch: 14
2022-12-31 05:59:09,174 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43190781275431317, 'Total loss': 0.43190781275431317} | train loss {'Reaction outcome loss': 0.23606197647886834, 'Total loss': 0.23606197647886834}
2022-12-31 05:59:09,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:09,174 INFO:     Epoch: 15
2022-12-31 05:59:10,784 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4190072158972422, 'Total loss': 0.4190072158972422} | train loss {'Reaction outcome loss': 0.22518609371377435, 'Total loss': 0.22518609371377435}
2022-12-31 05:59:10,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:10,784 INFO:     Epoch: 16
2022-12-31 05:59:12,433 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4769836167494456, 'Total loss': 0.4769836167494456} | train loss {'Reaction outcome loss': 0.21772822527549204, 'Total loss': 0.21772822527549204}
2022-12-31 05:59:12,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:12,433 INFO:     Epoch: 17
2022-12-31 05:59:14,038 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4355142335096995, 'Total loss': 0.4355142335096995} | train loss {'Reaction outcome loss': 0.20952940483546847, 'Total loss': 0.20952940483546847}
2022-12-31 05:59:14,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:14,038 INFO:     Epoch: 18
2022-12-31 05:59:15,671 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.410760502020518, 'Total loss': 0.410760502020518} | train loss {'Reaction outcome loss': 0.2075199798813888, 'Total loss': 0.2075199798813888}
2022-12-31 05:59:15,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:15,672 INFO:     Epoch: 19
2022-12-31 05:59:17,282 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4034426788489024, 'Total loss': 0.4034426788489024} | train loss {'Reaction outcome loss': 0.20227675866540318, 'Total loss': 0.20227675866540318}
2022-12-31 05:59:17,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:17,283 INFO:     Epoch: 20
2022-12-31 05:59:18,929 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42182670533657074, 'Total loss': 0.42182670533657074} | train loss {'Reaction outcome loss': 0.19851059391889925, 'Total loss': 0.19851059391889925}
2022-12-31 05:59:18,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:18,930 INFO:     Epoch: 21
2022-12-31 05:59:20,540 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4810634036858877, 'Total loss': 0.4810634036858877} | train loss {'Reaction outcome loss': 0.1904169216943093, 'Total loss': 0.1904169216943093}
2022-12-31 05:59:20,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:20,541 INFO:     Epoch: 22
2022-12-31 05:59:22,141 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.436556472380956, 'Total loss': 0.436556472380956} | train loss {'Reaction outcome loss': 0.18766823780787734, 'Total loss': 0.18766823780787734}
2022-12-31 05:59:22,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:22,142 INFO:     Epoch: 23
2022-12-31 05:59:23,773 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4154049555460612, 'Total loss': 0.4154049555460612} | train loss {'Reaction outcome loss': 0.18865756766236091, 'Total loss': 0.18865756766236091}
2022-12-31 05:59:23,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:23,773 INFO:     Epoch: 24
2022-12-31 05:59:25,421 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42659979859987895, 'Total loss': 0.42659979859987895} | train loss {'Reaction outcome loss': 0.17964571566344836, 'Total loss': 0.17964571566344836}
2022-12-31 05:59:25,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:25,421 INFO:     Epoch: 25
2022-12-31 05:59:27,028 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4191157266497612, 'Total loss': 0.4191157266497612} | train loss {'Reaction outcome loss': 0.17542884776525663, 'Total loss': 0.17542884776525663}
2022-12-31 05:59:27,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:27,028 INFO:     Epoch: 26
2022-12-31 05:59:28,676 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4235560109217962, 'Total loss': 0.4235560109217962} | train loss {'Reaction outcome loss': 0.17040709186440858, 'Total loss': 0.17040709186440858}
2022-12-31 05:59:28,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:28,676 INFO:     Epoch: 27
2022-12-31 05:59:30,323 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41919979924956957, 'Total loss': 0.41919979924956957} | train loss {'Reaction outcome loss': 0.17148723402452884, 'Total loss': 0.17148723402452884}
2022-12-31 05:59:30,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:30,323 INFO:     Epoch: 28
2022-12-31 05:59:31,970 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41900036334991453, 'Total loss': 0.41900036334991453} | train loss {'Reaction outcome loss': 0.16899616263240522, 'Total loss': 0.16899616263240522}
2022-12-31 05:59:31,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:31,971 INFO:     Epoch: 29
2022-12-31 05:59:33,589 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4050382971763611, 'Total loss': 0.4050382971763611} | train loss {'Reaction outcome loss': 0.16635610565420364, 'Total loss': 0.16635610565420364}
2022-12-31 05:59:33,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:33,589 INFO:     Epoch: 30
2022-12-31 05:59:35,220 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4416579882303874, 'Total loss': 0.4416579882303874} | train loss {'Reaction outcome loss': 0.16496708485615122, 'Total loss': 0.16496708485615122}
2022-12-31 05:59:35,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:35,221 INFO:     Epoch: 31
2022-12-31 05:59:36,833 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47785037954648335, 'Total loss': 0.47785037954648335} | train loss {'Reaction outcome loss': 0.15964940122086488, 'Total loss': 0.15964940122086488}
2022-12-31 05:59:36,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:36,833 INFO:     Epoch: 32
2022-12-31 05:59:38,446 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4436805774768194, 'Total loss': 0.4436805774768194} | train loss {'Reaction outcome loss': 0.1631211214596508, 'Total loss': 0.1631211214596508}
2022-12-31 05:59:38,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:38,447 INFO:     Epoch: 33
2022-12-31 05:59:40,061 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46194486518700917, 'Total loss': 0.46194486518700917} | train loss {'Reaction outcome loss': 0.1536305015224404, 'Total loss': 0.1536305015224404}
2022-12-31 05:59:40,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:40,061 INFO:     Epoch: 34
2022-12-31 05:59:41,677 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4535481775800387, 'Total loss': 0.4535481775800387} | train loss {'Reaction outcome loss': 0.1540471032063985, 'Total loss': 0.1540471032063985}
2022-12-31 05:59:41,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:41,677 INFO:     Epoch: 35
2022-12-31 05:59:43,282 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44097747405370075, 'Total loss': 0.44097747405370075} | train loss {'Reaction outcome loss': 0.15479265234600276, 'Total loss': 0.15479265234600276}
2022-12-31 05:59:43,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:43,282 INFO:     Epoch: 36
2022-12-31 05:59:44,901 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4171877145767212, 'Total loss': 0.4171877145767212} | train loss {'Reaction outcome loss': 0.1482287876499005, 'Total loss': 0.1482287876499005}
2022-12-31 05:59:44,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:44,902 INFO:     Epoch: 37
2022-12-31 05:59:46,513 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41680801212787627, 'Total loss': 0.41680801212787627} | train loss {'Reaction outcome loss': 0.1502087023962057, 'Total loss': 0.1502087023962057}
2022-12-31 05:59:46,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:46,513 INFO:     Epoch: 38
2022-12-31 05:59:48,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41534357766310376, 'Total loss': 0.41534357766310376} | train loss {'Reaction outcome loss': 0.14578153971145988, 'Total loss': 0.14578153971145988}
2022-12-31 05:59:48,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:48,162 INFO:     Epoch: 39
2022-12-31 05:59:49,765 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40320384154717126, 'Total loss': 0.40320384154717126} | train loss {'Reaction outcome loss': 0.14688313128460787, 'Total loss': 0.14688313128460787}
2022-12-31 05:59:49,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:49,765 INFO:     Epoch: 40
2022-12-31 05:59:51,362 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41945857206980386, 'Total loss': 0.41945857206980386} | train loss {'Reaction outcome loss': 0.14581398160329886, 'Total loss': 0.14581398160329886}
2022-12-31 05:59:51,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:51,362 INFO:     Epoch: 41
2022-12-31 05:59:53,010 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41939029296239216, 'Total loss': 0.41939029296239216} | train loss {'Reaction outcome loss': 0.14038497456707633, 'Total loss': 0.14038497456707633}
2022-12-31 05:59:53,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:53,010 INFO:     Epoch: 42
2022-12-31 05:59:54,615 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.435405162970225, 'Total loss': 0.435405162970225} | train loss {'Reaction outcome loss': 0.14132063516036986, 'Total loss': 0.14132063516036986}
2022-12-31 05:59:54,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:54,615 INFO:     Epoch: 43
2022-12-31 05:59:56,264 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42704955538113915, 'Total loss': 0.42704955538113915} | train loss {'Reaction outcome loss': 0.1378527715982999, 'Total loss': 0.1378527715982999}
2022-12-31 05:59:56,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:56,264 INFO:     Epoch: 44
2022-12-31 05:59:57,913 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4336353878180186, 'Total loss': 0.4336353878180186} | train loss {'Reaction outcome loss': 0.1399888288768711, 'Total loss': 0.1399888288768711}
2022-12-31 05:59:57,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:57,914 INFO:     Epoch: 45
2022-12-31 05:59:59,523 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41848838130633037, 'Total loss': 0.41848838130633037} | train loss {'Reaction outcome loss': 0.1374794445188218, 'Total loss': 0.1374794445188218}
2022-12-31 05:59:59,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 05:59:59,523 INFO:     Epoch: 46
2022-12-31 06:00:01,154 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4318827490011851, 'Total loss': 0.4318827490011851} | train loss {'Reaction outcome loss': 0.13818408679490016, 'Total loss': 0.13818408679490016}
2022-12-31 06:00:01,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:01,154 INFO:     Epoch: 47
2022-12-31 06:00:02,784 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4596240719159444, 'Total loss': 0.4596240719159444} | train loss {'Reaction outcome loss': 0.13574563974391793, 'Total loss': 0.13574563974391793}
2022-12-31 06:00:02,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:02,784 INFO:     Epoch: 48
2022-12-31 06:00:04,389 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46218690474828084, 'Total loss': 0.46218690474828084} | train loss {'Reaction outcome loss': 0.13538956590297022, 'Total loss': 0.13538956590297022}
2022-12-31 06:00:04,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:04,390 INFO:     Epoch: 49
2022-12-31 06:00:05,995 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4471395621697108, 'Total loss': 0.4471395621697108} | train loss {'Reaction outcome loss': 0.13378716521852074, 'Total loss': 0.13378716521852074}
2022-12-31 06:00:05,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:05,996 INFO:     Epoch: 50
2022-12-31 06:00:07,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4584113856156667, 'Total loss': 0.4584113856156667} | train loss {'Reaction outcome loss': 0.1310394988975218, 'Total loss': 0.1310394988975218}
2022-12-31 06:00:07,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:07,601 INFO:     Epoch: 51
2022-12-31 06:00:09,206 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4562910447518031, 'Total loss': 0.4562910447518031} | train loss {'Reaction outcome loss': 0.1294835327677565, 'Total loss': 0.1294835327677565}
2022-12-31 06:00:09,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:09,207 INFO:     Epoch: 52
2022-12-31 06:00:10,808 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4424308647712072, 'Total loss': 0.4424308647712072} | train loss {'Reaction outcome loss': 0.1360366616872286, 'Total loss': 0.1360366616872286}
2022-12-31 06:00:10,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:10,808 INFO:     Epoch: 53
2022-12-31 06:00:12,409 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4271942024429639, 'Total loss': 0.4271942024429639} | train loss {'Reaction outcome loss': 0.12772266042415367, 'Total loss': 0.12772266042415367}
2022-12-31 06:00:12,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:12,409 INFO:     Epoch: 54
2022-12-31 06:00:14,018 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46210769017537434, 'Total loss': 0.46210769017537434} | train loss {'Reaction outcome loss': 0.1283808098790396, 'Total loss': 0.1283808098790396}
2022-12-31 06:00:14,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:14,019 INFO:     Epoch: 55
2022-12-31 06:00:15,627 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45325754086176556, 'Total loss': 0.45325754086176556} | train loss {'Reaction outcome loss': 0.12734304311524927, 'Total loss': 0.12734304311524927}
2022-12-31 06:00:15,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:15,627 INFO:     Epoch: 56
2022-12-31 06:00:17,235 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4645002047220866, 'Total loss': 0.4645002047220866} | train loss {'Reaction outcome loss': 0.12760450401524212, 'Total loss': 0.12760450401524212}
2022-12-31 06:00:17,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:17,235 INFO:     Epoch: 57
2022-12-31 06:00:18,841 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43810128668944043, 'Total loss': 0.43810128668944043} | train loss {'Reaction outcome loss': 0.1252777022019629, 'Total loss': 0.1252777022019629}
2022-12-31 06:00:18,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:18,842 INFO:     Epoch: 58
2022-12-31 06:00:20,441 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4123027801513672, 'Total loss': 0.4123027801513672} | train loss {'Reaction outcome loss': 0.12531673120191464, 'Total loss': 0.12531673120191464}
2022-12-31 06:00:20,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:20,442 INFO:     Epoch: 59
2022-12-31 06:00:22,047 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45285587509473163, 'Total loss': 0.45285587509473163} | train loss {'Reaction outcome loss': 0.1239347619809647, 'Total loss': 0.1239347619809647}
2022-12-31 06:00:22,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:22,047 INFO:     Epoch: 60
2022-12-31 06:00:23,695 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4176456073919932, 'Total loss': 0.4176456073919932} | train loss {'Reaction outcome loss': 0.12481960923932903, 'Total loss': 0.12481960923932903}
2022-12-31 06:00:23,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:23,696 INFO:     Epoch: 61
2022-12-31 06:00:25,321 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40689503649870556, 'Total loss': 0.40689503649870556} | train loss {'Reaction outcome loss': 0.12260531928158287, 'Total loss': 0.12260531928158287}
2022-12-31 06:00:25,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:25,321 INFO:     Epoch: 62
2022-12-31 06:00:26,976 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41564658284187317, 'Total loss': 0.41564658284187317} | train loss {'Reaction outcome loss': 0.12107456306800683, 'Total loss': 0.12107456306800683}
2022-12-31 06:00:26,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:26,976 INFO:     Epoch: 63
2022-12-31 06:00:28,610 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46677369947234787, 'Total loss': 0.46677369947234787} | train loss {'Reaction outcome loss': 0.12352519939336312, 'Total loss': 0.12352519939336312}
2022-12-31 06:00:28,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:28,611 INFO:     Epoch: 64
2022-12-31 06:00:30,225 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4510035788019498, 'Total loss': 0.4510035788019498} | train loss {'Reaction outcome loss': 0.12090789635653774, 'Total loss': 0.12090789635653774}
2022-12-31 06:00:30,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:30,225 INFO:     Epoch: 65
2022-12-31 06:00:31,835 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42579011196891464, 'Total loss': 0.42579011196891464} | train loss {'Reaction outcome loss': 0.11936994205696351, 'Total loss': 0.11936994205696351}
2022-12-31 06:00:31,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:31,835 INFO:     Epoch: 66
2022-12-31 06:00:33,445 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41877632538477577, 'Total loss': 0.41877632538477577} | train loss {'Reaction outcome loss': 0.12045593001374859, 'Total loss': 0.12045593001374859}
2022-12-31 06:00:33,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:33,446 INFO:     Epoch: 67
2022-12-31 06:00:35,056 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4528231034676234, 'Total loss': 0.4528231034676234} | train loss {'Reaction outcome loss': 0.12075098414287899, 'Total loss': 0.12075098414287899}
2022-12-31 06:00:35,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:35,057 INFO:     Epoch: 68
2022-12-31 06:00:36,665 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45719019969304403, 'Total loss': 0.45719019969304403} | train loss {'Reaction outcome loss': 0.11907449028635528, 'Total loss': 0.11907449028635528}
2022-12-31 06:00:36,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:36,666 INFO:     Epoch: 69
2022-12-31 06:00:38,269 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45585546692212425, 'Total loss': 0.45585546692212425} | train loss {'Reaction outcome loss': 0.11755528652719853, 'Total loss': 0.11755528652719853}
2022-12-31 06:00:38,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:38,269 INFO:     Epoch: 70
2022-12-31 06:00:39,863 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4431840906540553, 'Total loss': 0.4431840906540553} | train loss {'Reaction outcome loss': 0.12045450817756082, 'Total loss': 0.12045450817756082}
2022-12-31 06:00:39,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:39,863 INFO:     Epoch: 71
2022-12-31 06:00:41,511 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43631355265776317, 'Total loss': 0.43631355265776317} | train loss {'Reaction outcome loss': 0.12485488200105638, 'Total loss': 0.12485488200105638}
2022-12-31 06:00:41,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:41,511 INFO:     Epoch: 72
2022-12-31 06:00:43,113 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45713187058766686, 'Total loss': 0.45713187058766686} | train loss {'Reaction outcome loss': 0.12086138063905276, 'Total loss': 0.12086138063905276}
2022-12-31 06:00:43,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:43,114 INFO:     Epoch: 73
2022-12-31 06:00:44,761 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41426995297273, 'Total loss': 0.41426995297273} | train loss {'Reaction outcome loss': 0.11593212175350158, 'Total loss': 0.11593212175350158}
2022-12-31 06:00:44,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:44,761 INFO:     Epoch: 74
2022-12-31 06:00:46,366 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39700594345728557, 'Total loss': 0.39700594345728557} | train loss {'Reaction outcome loss': 0.11670993310621097, 'Total loss': 0.11670993310621097}
2022-12-31 06:00:46,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:46,366 INFO:     Epoch: 75
2022-12-31 06:00:48,006 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42097126742204033, 'Total loss': 0.42097126742204033} | train loss {'Reaction outcome loss': 0.11438407001235683, 'Total loss': 0.11438407001235683}
2022-12-31 06:00:48,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:48,006 INFO:     Epoch: 76
2022-12-31 06:00:49,610 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4485365778207779, 'Total loss': 0.4485365778207779} | train loss {'Reaction outcome loss': 0.1181441971020698, 'Total loss': 0.1181441971020698}
2022-12-31 06:00:49,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:49,612 INFO:     Epoch: 77
2022-12-31 06:00:51,222 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4529982874790827, 'Total loss': 0.4529982874790827} | train loss {'Reaction outcome loss': 0.11328224881915477, 'Total loss': 0.11328224881915477}
2022-12-31 06:00:51,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:51,223 INFO:     Epoch: 78
2022-12-31 06:00:52,835 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45484829545021055, 'Total loss': 0.45484829545021055} | train loss {'Reaction outcome loss': 0.11281149423998463, 'Total loss': 0.11281149423998463}
2022-12-31 06:00:52,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:52,835 INFO:     Epoch: 79
2022-12-31 06:00:54,445 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4424497425556183, 'Total loss': 0.4424497425556183} | train loss {'Reaction outcome loss': 0.11994614679112198, 'Total loss': 0.11994614679112198}
2022-12-31 06:00:54,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:54,446 INFO:     Epoch: 80
2022-12-31 06:00:56,048 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4802847236394882, 'Total loss': 0.4802847236394882} | train loss {'Reaction outcome loss': 0.11717924754043202, 'Total loss': 0.11717924754043202}
2022-12-31 06:00:56,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:56,049 INFO:     Epoch: 81
2022-12-31 06:00:57,653 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.453092160820961, 'Total loss': 0.453092160820961} | train loss {'Reaction outcome loss': 0.11993533995871572, 'Total loss': 0.11993533995871572}
2022-12-31 06:00:57,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:57,653 INFO:     Epoch: 82
2022-12-31 06:00:59,295 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42540204028288525, 'Total loss': 0.42540204028288525} | train loss {'Reaction outcome loss': 0.11004241335635576, 'Total loss': 0.11004241335635576}
2022-12-31 06:00:59,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:00:59,296 INFO:     Epoch: 83
2022-12-31 06:01:00,893 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44998191595077514, 'Total loss': 0.44998191595077514} | train loss {'Reaction outcome loss': 0.1132787596997242, 'Total loss': 0.1132787596997242}
2022-12-31 06:01:00,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:00,893 INFO:     Epoch: 84
2022-12-31 06:01:02,541 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4385217189788818, 'Total loss': 0.4385217189788818} | train loss {'Reaction outcome loss': 0.1106175619361738, 'Total loss': 0.1106175619361738}
2022-12-31 06:01:02,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:02,541 INFO:     Epoch: 85
2022-12-31 06:01:04,185 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4662085672219594, 'Total loss': 0.4662085672219594} | train loss {'Reaction outcome loss': 0.11005245934960334, 'Total loss': 0.11005245934960334}
2022-12-31 06:01:04,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:04,185 INFO:     Epoch: 86
2022-12-31 06:01:05,791 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4720978836218516, 'Total loss': 0.4720978836218516} | train loss {'Reaction outcome loss': 0.11189665792735068, 'Total loss': 0.11189665792735068}
2022-12-31 06:01:05,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:05,791 INFO:     Epoch: 87
2022-12-31 06:01:07,419 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4351950137255092, 'Total loss': 0.4351950137255092} | train loss {'Reaction outcome loss': 0.1136111508442546, 'Total loss': 0.1136111508442546}
2022-12-31 06:01:07,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:07,419 INFO:     Epoch: 88
2022-12-31 06:01:09,069 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4214856336514155, 'Total loss': 0.4214856336514155} | train loss {'Reaction outcome loss': 0.11923082580025761, 'Total loss': 0.11923082580025761}
2022-12-31 06:01:09,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:09,070 INFO:     Epoch: 89
2022-12-31 06:01:10,708 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4348839422067006, 'Total loss': 0.4348839422067006} | train loss {'Reaction outcome loss': 0.1141077599990533, 'Total loss': 0.1141077599990533}
2022-12-31 06:01:10,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:10,709 INFO:     Epoch: 90
2022-12-31 06:01:12,355 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47185143729050955, 'Total loss': 0.47185143729050955} | train loss {'Reaction outcome loss': 0.11243630976726611, 'Total loss': 0.11243630976726611}
2022-12-31 06:01:12,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:12,356 INFO:     Epoch: 91
2022-12-31 06:01:13,980 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4328570415576299, 'Total loss': 0.4328570415576299} | train loss {'Reaction outcome loss': 0.11160950277055248, 'Total loss': 0.11160950277055248}
2022-12-31 06:01:13,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:13,980 INFO:     Epoch: 92
2022-12-31 06:01:15,614 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46463052928447723, 'Total loss': 0.46463052928447723} | train loss {'Reaction outcome loss': 0.1089201619739443, 'Total loss': 0.1089201619739443}
2022-12-31 06:01:15,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:15,614 INFO:     Epoch: 93
2022-12-31 06:01:17,213 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4260210444529851, 'Total loss': 0.4260210444529851} | train loss {'Reaction outcome loss': 0.11204758232745987, 'Total loss': 0.11204758232745987}
2022-12-31 06:01:17,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:17,213 INFO:     Epoch: 94
2022-12-31 06:01:18,860 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40946186035871507, 'Total loss': 0.40946186035871507} | train loss {'Reaction outcome loss': 0.1160321902268781, 'Total loss': 0.1160321902268781}
2022-12-31 06:01:18,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:18,861 INFO:     Epoch: 95
2022-12-31 06:01:20,464 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47042088707288104, 'Total loss': 0.47042088707288104} | train loss {'Reaction outcome loss': 0.1173373856129732, 'Total loss': 0.1173373856129732}
2022-12-31 06:01:20,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:20,464 INFO:     Epoch: 96
2022-12-31 06:01:22,112 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5152964035669962, 'Total loss': 0.5152964035669962} | train loss {'Reaction outcome loss': 0.1118333000498278, 'Total loss': 0.1118333000498278}
2022-12-31 06:01:22,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:22,112 INFO:     Epoch: 97
2022-12-31 06:01:23,730 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4207981745402018, 'Total loss': 0.4207981745402018} | train loss {'Reaction outcome loss': 0.10811796175459257, 'Total loss': 0.10811796175459257}
2022-12-31 06:01:23,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:23,731 INFO:     Epoch: 98
2022-12-31 06:01:25,341 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41008645792802173, 'Total loss': 0.41008645792802173} | train loss {'Reaction outcome loss': 0.10666067077310913, 'Total loss': 0.10666067077310913}
2022-12-31 06:01:25,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:25,342 INFO:     Epoch: 99
2022-12-31 06:01:26,961 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44461946884791054, 'Total loss': 0.44461946884791054} | train loss {'Reaction outcome loss': 0.10842685270440447, 'Total loss': 0.10842685270440447}
2022-12-31 06:01:26,961 INFO:     Best model found after epoch 9 of 100.
2022-12-31 06:01:26,961 INFO:   Done with stage: TRAINING
2022-12-31 06:01:26,961 INFO:   Starting stage: EVALUATION
2022-12-31 06:01:27,102 INFO:   Done with stage: EVALUATION
2022-12-31 06:01:27,103 INFO:   Leaving out SEQ value Fold_3
2022-12-31 06:01:27,115 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:01:27,115 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:01:27,755 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:01:27,755 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:01:27,825 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:01:27,825 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:01:27,825 INFO:     No hyperparam tuning for this model
2022-12-31 06:01:27,825 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:01:27,825 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:01:27,826 INFO:     None feature selector for col prot
2022-12-31 06:01:27,826 INFO:     None feature selector for col prot
2022-12-31 06:01:27,826 INFO:     None feature selector for col prot
2022-12-31 06:01:27,826 INFO:     None feature selector for col chem
2022-12-31 06:01:27,826 INFO:     None feature selector for col chem
2022-12-31 06:01:27,827 INFO:     None feature selector for col chem
2022-12-31 06:01:27,827 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:01:27,827 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:01:27,828 INFO:     Number of params in model 224011
2022-12-31 06:01:27,832 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:01:27,832 INFO:   Starting stage: TRAINING
2022-12-31 06:01:27,879 INFO:     Val loss before train {'Reaction outcome loss': 1.0449347138404845, 'Total loss': 1.0449347138404845}
2022-12-31 06:01:27,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:27,879 INFO:     Epoch: 0
2022-12-31 06:01:29,503 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6615163465340932, 'Total loss': 0.6615163465340932} | train loss {'Reaction outcome loss': 0.7997250102297233, 'Total loss': 0.7997250102297233}
2022-12-31 06:01:29,503 INFO:     Found new best model at epoch 0
2022-12-31 06:01:29,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:29,504 INFO:     Epoch: 1
2022-12-31 06:01:31,129 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5000903000434239, 'Total loss': 0.5000903000434239} | train loss {'Reaction outcome loss': 0.5313134448480432, 'Total loss': 0.5313134448480432}
2022-12-31 06:01:31,129 INFO:     Found new best model at epoch 1
2022-12-31 06:01:31,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:31,130 INFO:     Epoch: 2
2022-12-31 06:01:32,761 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4539330263932546, 'Total loss': 0.4539330263932546} | train loss {'Reaction outcome loss': 0.45612132464991, 'Total loss': 0.45612132464991}
2022-12-31 06:01:32,762 INFO:     Found new best model at epoch 2
2022-12-31 06:01:32,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:32,763 INFO:     Epoch: 3
2022-12-31 06:01:34,420 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4174493134021759, 'Total loss': 0.4174493134021759} | train loss {'Reaction outcome loss': 0.41747750265754924, 'Total loss': 0.41747750265754924}
2022-12-31 06:01:34,420 INFO:     Found new best model at epoch 3
2022-12-31 06:01:34,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:34,421 INFO:     Epoch: 4
2022-12-31 06:01:36,077 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4126022905111313, 'Total loss': 0.4126022905111313} | train loss {'Reaction outcome loss': 0.3839200728022269, 'Total loss': 0.3839200728022269}
2022-12-31 06:01:36,078 INFO:     Found new best model at epoch 4
2022-12-31 06:01:36,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:36,079 INFO:     Epoch: 5
2022-12-31 06:01:37,734 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.427890819311142, 'Total loss': 0.427890819311142} | train loss {'Reaction outcome loss': 0.3588265983292656, 'Total loss': 0.3588265983292656}
2022-12-31 06:01:37,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:37,734 INFO:     Epoch: 6
2022-12-31 06:01:39,387 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42863535483678183, 'Total loss': 0.42863535483678183} | train loss {'Reaction outcome loss': 0.3418139024318135, 'Total loss': 0.3418139024318135}
2022-12-31 06:01:39,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:39,387 INFO:     Epoch: 7
2022-12-31 06:01:41,000 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43944919208685557, 'Total loss': 0.43944919208685557} | train loss {'Reaction outcome loss': 0.3234676394856324, 'Total loss': 0.3234676394856324}
2022-12-31 06:01:41,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:41,000 INFO:     Epoch: 8
2022-12-31 06:01:42,142 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41136656602223715, 'Total loss': 0.41136656602223715} | train loss {'Reaction outcome loss': 0.3080139115561534, 'Total loss': 0.3080139115561534}
2022-12-31 06:01:42,142 INFO:     Found new best model at epoch 8
2022-12-31 06:01:42,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:42,144 INFO:     Epoch: 9
2022-12-31 06:01:43,264 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44263868729273476, 'Total loss': 0.44263868729273476} | train loss {'Reaction outcome loss': 0.29151384376098205, 'Total loss': 0.29151384376098205}
2022-12-31 06:01:43,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:43,265 INFO:     Epoch: 10
2022-12-31 06:01:44,369 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45147665143013, 'Total loss': 0.45147665143013} | train loss {'Reaction outcome loss': 0.27819023948896976, 'Total loss': 0.27819023948896976}
2022-12-31 06:01:44,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:44,369 INFO:     Epoch: 11
2022-12-31 06:01:45,473 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4298117409149806, 'Total loss': 0.4298117409149806} | train loss {'Reaction outcome loss': 0.26898998737226437, 'Total loss': 0.26898998737226437}
2022-12-31 06:01:45,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:45,474 INFO:     Epoch: 12
2022-12-31 06:01:47,056 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43704041043917335, 'Total loss': 0.43704041043917335} | train loss {'Reaction outcome loss': 0.2548371617457945, 'Total loss': 0.2548371617457945}
2022-12-31 06:01:47,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:47,056 INFO:     Epoch: 13
2022-12-31 06:01:48,662 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4235300083955129, 'Total loss': 0.4235300083955129} | train loss {'Reaction outcome loss': 0.24539208666414675, 'Total loss': 0.24539208666414675}
2022-12-31 06:01:48,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:48,662 INFO:     Epoch: 14
2022-12-31 06:01:50,296 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4340351829926173, 'Total loss': 0.4340351829926173} | train loss {'Reaction outcome loss': 0.2370118571676477, 'Total loss': 0.2370118571676477}
2022-12-31 06:01:50,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:50,296 INFO:     Epoch: 15
2022-12-31 06:01:51,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4232491860787074, 'Total loss': 0.4232491860787074} | train loss {'Reaction outcome loss': 0.2294909759920879, 'Total loss': 0.2294909759920879}
2022-12-31 06:01:51,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:51,908 INFO:     Epoch: 16
2022-12-31 06:01:53,521 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44053635199864705, 'Total loss': 0.44053635199864705} | train loss {'Reaction outcome loss': 0.22174613006467367, 'Total loss': 0.22174613006467367}
2022-12-31 06:01:53,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:53,522 INFO:     Epoch: 17
2022-12-31 06:01:55,131 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4205017218987147, 'Total loss': 0.4205017218987147} | train loss {'Reaction outcome loss': 0.21312685120497307, 'Total loss': 0.21312685120497307}
2022-12-31 06:01:55,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:55,131 INFO:     Epoch: 18
2022-12-31 06:01:56,783 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4136241654555003, 'Total loss': 0.4136241654555003} | train loss {'Reaction outcome loss': 0.20512774412649393, 'Total loss': 0.20512774412649393}
2022-12-31 06:01:56,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:56,785 INFO:     Epoch: 19
2022-12-31 06:01:58,391 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4485640227794647, 'Total loss': 0.4485640227794647} | train loss {'Reaction outcome loss': 0.19912777268701662, 'Total loss': 0.19912777268701662}
2022-12-31 06:01:58,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:01:58,392 INFO:     Epoch: 20
2022-12-31 06:02:00,010 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4203612248102824, 'Total loss': 0.4203612248102824} | train loss {'Reaction outcome loss': 0.19318955316187908, 'Total loss': 0.19318955316187908}
2022-12-31 06:02:00,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:00,011 INFO:     Epoch: 21
2022-12-31 06:02:01,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4138548975189527, 'Total loss': 0.4138548975189527} | train loss {'Reaction outcome loss': 0.19185542032448916, 'Total loss': 0.19185542032448916}
2022-12-31 06:02:01,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:01,626 INFO:     Epoch: 22
2022-12-31 06:02:03,246 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4307405268152555, 'Total loss': 0.4307405268152555} | train loss {'Reaction outcome loss': 0.1847187398735733, 'Total loss': 0.1847187398735733}
2022-12-31 06:02:03,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:03,247 INFO:     Epoch: 23
2022-12-31 06:02:04,854 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4797572702169418, 'Total loss': 0.4797572702169418} | train loss {'Reaction outcome loss': 0.18136622527287932, 'Total loss': 0.18136622527287932}
2022-12-31 06:02:04,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:04,854 INFO:     Epoch: 24
2022-12-31 06:02:06,470 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4521137254933516, 'Total loss': 0.4521137254933516} | train loss {'Reaction outcome loss': 0.17995866341176478, 'Total loss': 0.17995866341176478}
2022-12-31 06:02:06,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:06,471 INFO:     Epoch: 25
2022-12-31 06:02:08,085 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4345486044883728, 'Total loss': 0.4345486044883728} | train loss {'Reaction outcome loss': 0.17778215391806115, 'Total loss': 0.17778215391806115}
2022-12-31 06:02:08,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:08,086 INFO:     Epoch: 26
2022-12-31 06:02:09,697 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4666775792837143, 'Total loss': 0.4666775792837143} | train loss {'Reaction outcome loss': 0.16847957273346992, 'Total loss': 0.16847957273346992}
2022-12-31 06:02:09,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:09,698 INFO:     Epoch: 27
2022-12-31 06:02:11,313 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4586286400755247, 'Total loss': 0.4586286400755247} | train loss {'Reaction outcome loss': 0.1709260142537473, 'Total loss': 0.1709260142537473}
2022-12-31 06:02:11,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:11,314 INFO:     Epoch: 28
2022-12-31 06:02:12,931 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46466508905092874, 'Total loss': 0.46466508905092874} | train loss {'Reaction outcome loss': 0.16638046375604987, 'Total loss': 0.16638046375604987}
2022-12-31 06:02:12,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:12,931 INFO:     Epoch: 29
2022-12-31 06:02:14,538 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47447972347338996, 'Total loss': 0.47447972347338996} | train loss {'Reaction outcome loss': 0.1639040696917333, 'Total loss': 0.1639040696917333}
2022-12-31 06:02:14,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:14,538 INFO:     Epoch: 30
2022-12-31 06:02:16,192 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46534104148546857, 'Total loss': 0.46534104148546857} | train loss {'Reaction outcome loss': 0.16225369899010245, 'Total loss': 0.16225369899010245}
2022-12-31 06:02:16,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:16,193 INFO:     Epoch: 31
2022-12-31 06:02:17,793 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46614410877227785, 'Total loss': 0.46614410877227785} | train loss {'Reaction outcome loss': 0.15480270824755413, 'Total loss': 0.15480270824755413}
2022-12-31 06:02:17,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:17,793 INFO:     Epoch: 32
2022-12-31 06:02:19,446 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46775979865342376, 'Total loss': 0.46775979865342376} | train loss {'Reaction outcome loss': 0.15199237185815878, 'Total loss': 0.15199237185815878}
2022-12-31 06:02:19,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:19,447 INFO:     Epoch: 33
2022-12-31 06:02:21,099 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4918042560418447, 'Total loss': 0.4918042560418447} | train loss {'Reaction outcome loss': 0.14708588489358496, 'Total loss': 0.14708588489358496}
2022-12-31 06:02:21,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:21,099 INFO:     Epoch: 34
2022-12-31 06:02:22,748 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48948877056439716, 'Total loss': 0.48948877056439716} | train loss {'Reaction outcome loss': 0.1495595191924894, 'Total loss': 0.1495595191924894}
2022-12-31 06:02:22,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:22,749 INFO:     Epoch: 35
2022-12-31 06:02:24,401 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49704131881395974, 'Total loss': 0.49704131881395974} | train loss {'Reaction outcome loss': 0.15027641351028842, 'Total loss': 0.15027641351028842}
2022-12-31 06:02:24,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:24,402 INFO:     Epoch: 36
2022-12-31 06:02:26,054 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47476095259189605, 'Total loss': 0.47476095259189605} | train loss {'Reaction outcome loss': 0.14755344321869696, 'Total loss': 0.14755344321869696}
2022-12-31 06:02:26,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:26,055 INFO:     Epoch: 37
2022-12-31 06:02:27,667 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4527442653973897, 'Total loss': 0.4527442653973897} | train loss {'Reaction outcome loss': 0.14541659955730676, 'Total loss': 0.14541659955730676}
2022-12-31 06:02:27,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:27,668 INFO:     Epoch: 38
2022-12-31 06:02:29,282 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5027831604083379, 'Total loss': 0.5027831604083379} | train loss {'Reaction outcome loss': 0.14218510025228462, 'Total loss': 0.14218510025228462}
2022-12-31 06:02:29,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:29,282 INFO:     Epoch: 39
2022-12-31 06:02:30,896 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4735048075517019, 'Total loss': 0.4735048075517019} | train loss {'Reaction outcome loss': 0.14174989503842308, 'Total loss': 0.14174989503842308}
2022-12-31 06:02:30,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:30,896 INFO:     Epoch: 40
2022-12-31 06:02:32,502 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46981922288735706, 'Total loss': 0.46981922288735706} | train loss {'Reaction outcome loss': 0.14144968148490863, 'Total loss': 0.14144968148490863}
2022-12-31 06:02:32,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:32,503 INFO:     Epoch: 41
2022-12-31 06:02:34,118 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4708884209394455, 'Total loss': 0.4708884209394455} | train loss {'Reaction outcome loss': 0.13941219006155203, 'Total loss': 0.13941219006155203}
2022-12-31 06:02:34,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:34,118 INFO:     Epoch: 42
2022-12-31 06:02:35,726 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.500943323969841, 'Total loss': 0.500943323969841} | train loss {'Reaction outcome loss': 0.13814481559726172, 'Total loss': 0.13814481559726172}
2022-12-31 06:02:35,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:35,727 INFO:     Epoch: 43
2022-12-31 06:02:37,341 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44994634787241616, 'Total loss': 0.44994634787241616} | train loss {'Reaction outcome loss': 0.13648975409914052, 'Total loss': 0.13648975409914052}
2022-12-31 06:02:37,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:37,341 INFO:     Epoch: 44
2022-12-31 06:02:38,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4735165506601334, 'Total loss': 0.4735165506601334} | train loss {'Reaction outcome loss': 0.13386973837920785, 'Total loss': 0.13386973837920785}
2022-12-31 06:02:38,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:38,965 INFO:     Epoch: 45
2022-12-31 06:02:40,568 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46057994266351066, 'Total loss': 0.46057994266351066} | train loss {'Reaction outcome loss': 0.1359546702749429, 'Total loss': 0.1359546702749429}
2022-12-31 06:02:40,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:40,569 INFO:     Epoch: 46
2022-12-31 06:02:42,181 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4735374053319295, 'Total loss': 0.4735374053319295} | train loss {'Reaction outcome loss': 0.13283784131954568, 'Total loss': 0.13283784131954568}
2022-12-31 06:02:42,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:42,181 INFO:     Epoch: 47
2022-12-31 06:02:43,800 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47289916475613913, 'Total loss': 0.47289916475613913} | train loss {'Reaction outcome loss': 0.134982283001113, 'Total loss': 0.134982283001113}
2022-12-31 06:02:43,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:43,800 INFO:     Epoch: 48
2022-12-31 06:02:45,412 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46769794325033825, 'Total loss': 0.46769794325033825} | train loss {'Reaction outcome loss': 0.13346900611803153, 'Total loss': 0.13346900611803153}
2022-12-31 06:02:45,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:45,412 INFO:     Epoch: 49
2022-12-31 06:02:47,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4668485860029856, 'Total loss': 0.4668485860029856} | train loss {'Reaction outcome loss': 0.13207685187744506, 'Total loss': 0.13207685187744506}
2022-12-31 06:02:47,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:47,039 INFO:     Epoch: 50
2022-12-31 06:02:48,655 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46311936577161156, 'Total loss': 0.46311936577161156} | train loss {'Reaction outcome loss': 0.12827690124314578, 'Total loss': 0.12827690124314578}
2022-12-31 06:02:48,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:48,655 INFO:     Epoch: 51
2022-12-31 06:02:50,256 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4768829971551895, 'Total loss': 0.4768829971551895} | train loss {'Reaction outcome loss': 0.1304744587612957, 'Total loss': 0.1304744587612957}
2022-12-31 06:02:50,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:50,256 INFO:     Epoch: 52
2022-12-31 06:02:51,905 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46847543070713676, 'Total loss': 0.46847543070713676} | train loss {'Reaction outcome loss': 0.12834474471581242, 'Total loss': 0.12834474471581242}
2022-12-31 06:02:51,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:51,906 INFO:     Epoch: 53
2022-12-31 06:02:53,509 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4828883171081543, 'Total loss': 0.4828883171081543} | train loss {'Reaction outcome loss': 0.12627505512575, 'Total loss': 0.12627505512575}
2022-12-31 06:02:53,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:53,509 INFO:     Epoch: 54
2022-12-31 06:02:55,122 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4696524242560069, 'Total loss': 0.4696524242560069} | train loss {'Reaction outcome loss': 0.1278657021670582, 'Total loss': 0.1278657021670582}
2022-12-31 06:02:55,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:55,122 INFO:     Epoch: 55
2022-12-31 06:02:56,750 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48408627609411875, 'Total loss': 0.48408627609411875} | train loss {'Reaction outcome loss': 0.12460338492218377, 'Total loss': 0.12460338492218377}
2022-12-31 06:02:56,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:56,751 INFO:     Epoch: 56
2022-12-31 06:02:58,352 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47259463866551715, 'Total loss': 0.47259463866551715} | train loss {'Reaction outcome loss': 0.12654304954760376, 'Total loss': 0.12654304954760376}
2022-12-31 06:02:58,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:58,352 INFO:     Epoch: 57
2022-12-31 06:02:59,978 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4677630767226219, 'Total loss': 0.4677630767226219} | train loss {'Reaction outcome loss': 0.12093347902613671, 'Total loss': 0.12093347902613671}
2022-12-31 06:02:59,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:02:59,979 INFO:     Epoch: 58
2022-12-31 06:03:01,592 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49003014862537386, 'Total loss': 0.49003014862537386} | train loss {'Reaction outcome loss': 0.11984735956571888, 'Total loss': 0.11984735956571888}
2022-12-31 06:03:01,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:01,593 INFO:     Epoch: 59
2022-12-31 06:03:03,201 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4851524104674657, 'Total loss': 0.4851524104674657} | train loss {'Reaction outcome loss': 0.12514937025950337, 'Total loss': 0.12514937025950337}
2022-12-31 06:03:03,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:03,201 INFO:     Epoch: 60
2022-12-31 06:03:04,830 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47942425807317096, 'Total loss': 0.47942425807317096} | train loss {'Reaction outcome loss': 0.12347406537584743, 'Total loss': 0.12347406537584743}
2022-12-31 06:03:04,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:04,830 INFO:     Epoch: 61
2022-12-31 06:03:06,434 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5035818199316661, 'Total loss': 0.5035818199316661} | train loss {'Reaction outcome loss': 0.12272856625843875, 'Total loss': 0.12272856625843875}
2022-12-31 06:03:06,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:06,434 INFO:     Epoch: 62
2022-12-31 06:03:08,031 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45861975451310477, 'Total loss': 0.45861975451310477} | train loss {'Reaction outcome loss': 0.12009844925071038, 'Total loss': 0.12009844925071038}
2022-12-31 06:03:08,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:08,032 INFO:     Epoch: 63
2022-12-31 06:03:09,647 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46834563712279004, 'Total loss': 0.46834563712279004} | train loss {'Reaction outcome loss': 0.1230927486751011, 'Total loss': 0.1230927486751011}
2022-12-31 06:03:09,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:09,648 INFO:     Epoch: 64
2022-12-31 06:03:11,261 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46736922760804495, 'Total loss': 0.46736922760804495} | train loss {'Reaction outcome loss': 0.12266399722247229, 'Total loss': 0.12266399722247229}
2022-12-31 06:03:11,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:11,261 INFO:     Epoch: 65
2022-12-31 06:03:12,867 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47347816030184425, 'Total loss': 0.47347816030184425} | train loss {'Reaction outcome loss': 0.12224506879272959, 'Total loss': 0.12224506879272959}
2022-12-31 06:03:12,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:12,867 INFO:     Epoch: 66
2022-12-31 06:03:14,487 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4795421222845713, 'Total loss': 0.4795421222845713} | train loss {'Reaction outcome loss': 0.11794422909593631, 'Total loss': 0.11794422909593631}
2022-12-31 06:03:14,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:14,488 INFO:     Epoch: 67
2022-12-31 06:03:16,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45513626833756765, 'Total loss': 0.45513626833756765} | train loss {'Reaction outcome loss': 0.11896986002612342, 'Total loss': 0.11896986002612342}
2022-12-31 06:03:16,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:16,091 INFO:     Epoch: 68
2022-12-31 06:03:17,726 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.480830991268158, 'Total loss': 0.480830991268158} | train loss {'Reaction outcome loss': 0.12022211088588203, 'Total loss': 0.12022211088588203}
2022-12-31 06:03:17,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:17,726 INFO:     Epoch: 69
2022-12-31 06:03:19,326 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46228140493234, 'Total loss': 0.46228140493234} | train loss {'Reaction outcome loss': 0.12174590343072413, 'Total loss': 0.12174590343072413}
2022-12-31 06:03:19,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:19,326 INFO:     Epoch: 70
2022-12-31 06:03:20,950 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48704128215710324, 'Total loss': 0.48704128215710324} | train loss {'Reaction outcome loss': 0.11730879634435214, 'Total loss': 0.11730879634435214}
2022-12-31 06:03:20,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:20,951 INFO:     Epoch: 71
2022-12-31 06:03:22,560 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46384724577267966, 'Total loss': 0.46384724577267966} | train loss {'Reaction outcome loss': 0.11688457224789979, 'Total loss': 0.11688457224789979}
2022-12-31 06:03:22,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:22,560 INFO:     Epoch: 72
2022-12-31 06:03:24,171 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5029828449090322, 'Total loss': 0.5029828449090322} | train loss {'Reaction outcome loss': 0.11736620591280397, 'Total loss': 0.11736620591280397}
2022-12-31 06:03:24,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:24,171 INFO:     Epoch: 73
2022-12-31 06:03:25,819 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45562280317147574, 'Total loss': 0.45562280317147574} | train loss {'Reaction outcome loss': 0.11786621141954441, 'Total loss': 0.11786621141954441}
2022-12-31 06:03:25,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:25,819 INFO:     Epoch: 74
2022-12-31 06:03:27,418 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4758585353692373, 'Total loss': 0.4758585353692373} | train loss {'Reaction outcome loss': 0.11911009177123706, 'Total loss': 0.11911009177123706}
2022-12-31 06:03:27,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:27,419 INFO:     Epoch: 75
2022-12-31 06:03:29,021 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4699406971534093, 'Total loss': 0.4699406971534093} | train loss {'Reaction outcome loss': 0.11879263929240949, 'Total loss': 0.11879263929240949}
2022-12-31 06:03:29,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:29,021 INFO:     Epoch: 76
2022-12-31 06:03:30,656 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49157143632570904, 'Total loss': 0.49157143632570904} | train loss {'Reaction outcome loss': 0.11526173563762467, 'Total loss': 0.11526173563762467}
2022-12-31 06:03:30,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:30,656 INFO:     Epoch: 77
2022-12-31 06:03:32,259 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48029145697752634, 'Total loss': 0.48029145697752634} | train loss {'Reaction outcome loss': 0.11460280888475967, 'Total loss': 0.11460280888475967}
2022-12-31 06:03:32,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:32,260 INFO:     Epoch: 78
2022-12-31 06:03:33,863 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4912401249011358, 'Total loss': 0.4912401249011358} | train loss {'Reaction outcome loss': 0.11398154312241686, 'Total loss': 0.11398154312241686}
2022-12-31 06:03:33,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:33,863 INFO:     Epoch: 79
2022-12-31 06:03:35,459 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4702061047156652, 'Total loss': 0.4702061047156652} | train loss {'Reaction outcome loss': 0.11000543736247685, 'Total loss': 0.11000543736247685}
2022-12-31 06:03:35,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:35,459 INFO:     Epoch: 80
2022-12-31 06:03:37,068 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48093050916989644, 'Total loss': 0.48093050916989644} | train loss {'Reaction outcome loss': 0.11571559114602605, 'Total loss': 0.11571559114602605}
2022-12-31 06:03:37,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:37,068 INFO:     Epoch: 81
2022-12-31 06:03:38,676 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49821820358435315, 'Total loss': 0.49821820358435315} | train loss {'Reaction outcome loss': 0.11669236526188924, 'Total loss': 0.11669236526188924}
2022-12-31 06:03:38,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:38,676 INFO:     Epoch: 82
2022-12-31 06:03:40,278 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4418587346871694, 'Total loss': 0.4418587346871694} | train loss {'Reaction outcome loss': 0.11406064499764411, 'Total loss': 0.11406064499764411}
2022-12-31 06:03:40,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:40,278 INFO:     Epoch: 83
2022-12-31 06:03:41,885 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46644940177599586, 'Total loss': 0.46644940177599586} | train loss {'Reaction outcome loss': 0.1138085735108649, 'Total loss': 0.1138085735108649}
2022-12-31 06:03:41,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:41,885 INFO:     Epoch: 84
2022-12-31 06:03:43,495 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5104465266068776, 'Total loss': 0.5104465266068776} | train loss {'Reaction outcome loss': 0.11024170127751673, 'Total loss': 0.11024170127751673}
2022-12-31 06:03:43,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:43,496 INFO:     Epoch: 85
2022-12-31 06:03:45,115 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4923103503882885, 'Total loss': 0.4923103503882885} | train loss {'Reaction outcome loss': 0.1111755804481651, 'Total loss': 0.1111755804481651}
2022-12-31 06:03:45,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:45,116 INFO:     Epoch: 86
2022-12-31 06:03:46,772 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4924004634221395, 'Total loss': 0.4924004634221395} | train loss {'Reaction outcome loss': 0.1161533490717275, 'Total loss': 0.1161533490717275}
2022-12-31 06:03:46,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:46,772 INFO:     Epoch: 87
2022-12-31 06:03:48,412 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.494350699086984, 'Total loss': 0.494350699086984} | train loss {'Reaction outcome loss': 0.11271776691466624, 'Total loss': 0.11271776691466624}
2022-12-31 06:03:48,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:48,412 INFO:     Epoch: 88
2022-12-31 06:03:50,008 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47604832152525584, 'Total loss': 0.47604832152525584} | train loss {'Reaction outcome loss': 0.11371736409292169, 'Total loss': 0.11371736409292169}
2022-12-31 06:03:50,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:50,009 INFO:     Epoch: 89
2022-12-31 06:03:51,610 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4566459129254023, 'Total loss': 0.4566459129254023} | train loss {'Reaction outcome loss': 0.1091589345817665, 'Total loss': 0.1091589345817665}
2022-12-31 06:03:51,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:51,610 INFO:     Epoch: 90
2022-12-31 06:03:53,211 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47008341252803804, 'Total loss': 0.47008341252803804} | train loss {'Reaction outcome loss': 0.11170537286288493, 'Total loss': 0.11170537286288493}
2022-12-31 06:03:53,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:53,211 INFO:     Epoch: 91
2022-12-31 06:03:54,849 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5053881406784058, 'Total loss': 0.5053881406784058} | train loss {'Reaction outcome loss': 0.11063433681397161, 'Total loss': 0.11063433681397161}
2022-12-31 06:03:54,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:54,849 INFO:     Epoch: 92
2022-12-31 06:03:56,449 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4577935754166295, 'Total loss': 0.4577935754166295} | train loss {'Reaction outcome loss': 0.11221826645668025, 'Total loss': 0.11221826645668025}
2022-12-31 06:03:56,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:56,450 INFO:     Epoch: 93
2022-12-31 06:03:58,060 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5160493473211925, 'Total loss': 0.5160493473211925} | train loss {'Reaction outcome loss': 0.10952064166708857, 'Total loss': 0.10952064166708857}
2022-12-31 06:03:58,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:58,060 INFO:     Epoch: 94
2022-12-31 06:03:59,709 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.464204270641009, 'Total loss': 0.464204270641009} | train loss {'Reaction outcome loss': 0.10772911257222703, 'Total loss': 0.10772911257222703}
2022-12-31 06:03:59,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:03:59,709 INFO:     Epoch: 95
2022-12-31 06:04:01,315 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4457191084822019, 'Total loss': 0.4457191084822019} | train loss {'Reaction outcome loss': 0.11226405413739764, 'Total loss': 0.11226405413739764}
2022-12-31 06:04:01,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:01,315 INFO:     Epoch: 96
2022-12-31 06:04:02,924 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48432623545328773, 'Total loss': 0.48432623545328773} | train loss {'Reaction outcome loss': 0.11333691971597472, 'Total loss': 0.11333691971597472}
2022-12-31 06:04:02,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:02,925 INFO:     Epoch: 97
2022-12-31 06:04:04,533 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.472262434164683, 'Total loss': 0.472262434164683} | train loss {'Reaction outcome loss': 0.11028041536528889, 'Total loss': 0.11028041536528889}
2022-12-31 06:04:04,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:04,533 INFO:     Epoch: 98
2022-12-31 06:04:06,144 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.526649096608162, 'Total loss': 0.526649096608162} | train loss {'Reaction outcome loss': 0.10777438982954099, 'Total loss': 0.10777438982954099}
2022-12-31 06:04:06,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:06,144 INFO:     Epoch: 99
2022-12-31 06:04:07,746 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4836922208468119, 'Total loss': 0.4836922208468119} | train loss {'Reaction outcome loss': 0.10937746550826641, 'Total loss': 0.10937746550826641}
2022-12-31 06:04:07,746 INFO:     Best model found after epoch 9 of 100.
2022-12-31 06:04:07,746 INFO:   Done with stage: TRAINING
2022-12-31 06:04:07,747 INFO:   Starting stage: EVALUATION
2022-12-31 06:04:07,882 INFO:   Done with stage: EVALUATION
2022-12-31 06:04:07,882 INFO:   Leaving out SEQ value Fold_4
2022-12-31 06:04:07,895 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:04:07,895 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:04:08,548 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:04:08,549 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:04:08,619 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:04:08,619 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:04:08,619 INFO:     No hyperparam tuning for this model
2022-12-31 06:04:08,619 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:04:08,619 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:04:08,620 INFO:     None feature selector for col prot
2022-12-31 06:04:08,620 INFO:     None feature selector for col prot
2022-12-31 06:04:08,620 INFO:     None feature selector for col prot
2022-12-31 06:04:08,621 INFO:     None feature selector for col chem
2022-12-31 06:04:08,621 INFO:     None feature selector for col chem
2022-12-31 06:04:08,621 INFO:     None feature selector for col chem
2022-12-31 06:04:08,621 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:04:08,621 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:04:08,623 INFO:     Number of params in model 224011
2022-12-31 06:04:08,626 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:04:08,626 INFO:   Starting stage: TRAINING
2022-12-31 06:04:08,671 INFO:     Val loss before train {'Reaction outcome loss': 0.9547424455483754, 'Total loss': 0.9547424455483754}
2022-12-31 06:04:08,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:08,672 INFO:     Epoch: 0
2022-12-31 06:04:10,293 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5660859763622283, 'Total loss': 0.5660859763622283} | train loss {'Reaction outcome loss': 0.8085576902697051, 'Total loss': 0.8085576902697051}
2022-12-31 06:04:10,293 INFO:     Found new best model at epoch 0
2022-12-31 06:04:10,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:10,294 INFO:     Epoch: 1
2022-12-31 06:04:11,917 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4675428460041682, 'Total loss': 0.4675428460041682} | train loss {'Reaction outcome loss': 0.5227884511459969, 'Total loss': 0.5227884511459969}
2022-12-31 06:04:11,917 INFO:     Found new best model at epoch 1
2022-12-31 06:04:11,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:11,918 INFO:     Epoch: 2
2022-12-31 06:04:13,532 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4399756948153178, 'Total loss': 0.4399756948153178} | train loss {'Reaction outcome loss': 0.45087976560698473, 'Total loss': 0.45087976560698473}
2022-12-31 06:04:13,533 INFO:     Found new best model at epoch 2
2022-12-31 06:04:13,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:13,534 INFO:     Epoch: 3
2022-12-31 06:04:15,193 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41283632318178815, 'Total loss': 0.41283632318178815} | train loss {'Reaction outcome loss': 0.4085543719322785, 'Total loss': 0.4085543719322785}
2022-12-31 06:04:15,193 INFO:     Found new best model at epoch 3
2022-12-31 06:04:15,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:15,194 INFO:     Epoch: 4
2022-12-31 06:04:16,820 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40662810305754343, 'Total loss': 0.40662810305754343} | train loss {'Reaction outcome loss': 0.3787960398172879, 'Total loss': 0.3787960398172879}
2022-12-31 06:04:16,820 INFO:     Found new best model at epoch 4
2022-12-31 06:04:16,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:16,821 INFO:     Epoch: 5
2022-12-31 06:04:18,441 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43271165490150454, 'Total loss': 0.43271165490150454} | train loss {'Reaction outcome loss': 0.35459600353235565, 'Total loss': 0.35459600353235565}
2022-12-31 06:04:18,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:18,441 INFO:     Epoch: 6
2022-12-31 06:04:20,108 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4159969657659531, 'Total loss': 0.4159969657659531} | train loss {'Reaction outcome loss': 0.33554259033010475, 'Total loss': 0.33554259033010475}
2022-12-31 06:04:20,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:20,109 INFO:     Epoch: 7
2022-12-31 06:04:21,780 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42032272020975747, 'Total loss': 0.42032272020975747} | train loss {'Reaction outcome loss': 0.3157988716105836, 'Total loss': 0.3157988716105836}
2022-12-31 06:04:21,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:21,781 INFO:     Epoch: 8
2022-12-31 06:04:23,430 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3929176499446233, 'Total loss': 0.3929176499446233} | train loss {'Reaction outcome loss': 0.30089463428484503, 'Total loss': 0.30089463428484503}
2022-12-31 06:04:23,430 INFO:     Found new best model at epoch 8
2022-12-31 06:04:23,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:23,431 INFO:     Epoch: 9
2022-12-31 06:04:25,052 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40879435737927755, 'Total loss': 0.40879435737927755} | train loss {'Reaction outcome loss': 0.2879014102239297, 'Total loss': 0.2879014102239297}
2022-12-31 06:04:25,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:25,052 INFO:     Epoch: 10
2022-12-31 06:04:26,717 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42538088659445444, 'Total loss': 0.42538088659445444} | train loss {'Reaction outcome loss': 0.2742257622286569, 'Total loss': 0.2742257622286569}
2022-12-31 06:04:26,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:26,717 INFO:     Epoch: 11
2022-12-31 06:04:28,362 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39890762070814767, 'Total loss': 0.39890762070814767} | train loss {'Reaction outcome loss': 0.26200841056128993, 'Total loss': 0.26200841056128993}
2022-12-31 06:04:28,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:28,362 INFO:     Epoch: 12
2022-12-31 06:04:30,016 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4190101067225138, 'Total loss': 0.4190101067225138} | train loss {'Reaction outcome loss': 0.24946415354835166, 'Total loss': 0.24946415354835166}
2022-12-31 06:04:30,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:30,016 INFO:     Epoch: 13
2022-12-31 06:04:31,647 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42692694266637166, 'Total loss': 0.42692694266637166} | train loss {'Reaction outcome loss': 0.24376937106886096, 'Total loss': 0.24376937106886096}
2022-12-31 06:04:31,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:31,647 INFO:     Epoch: 14
2022-12-31 06:04:33,276 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4319800247748693, 'Total loss': 0.4319800247748693} | train loss {'Reaction outcome loss': 0.2312471723975067, 'Total loss': 0.2312471723975067}
2022-12-31 06:04:33,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:33,277 INFO:     Epoch: 15
2022-12-31 06:04:34,897 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4421687121192614, 'Total loss': 0.4421687121192614} | train loss {'Reaction outcome loss': 0.22173045406226013, 'Total loss': 0.22173045406226013}
2022-12-31 06:04:34,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:34,897 INFO:     Epoch: 16
2022-12-31 06:04:36,527 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4399840484062831, 'Total loss': 0.4399840484062831} | train loss {'Reaction outcome loss': 0.2179961151551401, 'Total loss': 0.2179961151551401}
2022-12-31 06:04:36,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:36,527 INFO:     Epoch: 17
2022-12-31 06:04:38,156 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41405914127826693, 'Total loss': 0.41405914127826693} | train loss {'Reaction outcome loss': 0.21565536041431926, 'Total loss': 0.21565536041431926}
2022-12-31 06:04:38,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:38,156 INFO:     Epoch: 18
2022-12-31 06:04:39,774 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4017745052774747, 'Total loss': 0.4017745052774747} | train loss {'Reaction outcome loss': 0.21503218386214282, 'Total loss': 0.21503218386214282}
2022-12-31 06:04:39,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:39,775 INFO:     Epoch: 19
2022-12-31 06:04:41,401 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4249089777469635, 'Total loss': 0.4249089777469635} | train loss {'Reaction outcome loss': 0.20042256900932695, 'Total loss': 0.20042256900932695}
2022-12-31 06:04:41,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:41,401 INFO:     Epoch: 20
2022-12-31 06:04:43,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43647480905056, 'Total loss': 0.43647480905056} | train loss {'Reaction outcome loss': 0.19001349085010588, 'Total loss': 0.19001349085010588}
2022-12-31 06:04:43,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:43,019 INFO:     Epoch: 21
2022-12-31 06:04:44,642 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4506160075465838, 'Total loss': 0.4506160075465838} | train loss {'Reaction outcome loss': 0.19314097320202037, 'Total loss': 0.19314097320202037}
2022-12-31 06:04:44,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:44,642 INFO:     Epoch: 22
2022-12-31 06:04:46,270 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4375604530175527, 'Total loss': 0.4375604530175527} | train loss {'Reaction outcome loss': 0.19044876835465877, 'Total loss': 0.19044876835465877}
2022-12-31 06:04:46,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:46,270 INFO:     Epoch: 23
2022-12-31 06:04:47,893 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4467281589905421, 'Total loss': 0.4467281589905421} | train loss {'Reaction outcome loss': 0.1803588847845052, 'Total loss': 0.1803588847845052}
2022-12-31 06:04:47,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:47,893 INFO:     Epoch: 24
2022-12-31 06:04:49,518 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45331506927808124, 'Total loss': 0.45331506927808124} | train loss {'Reaction outcome loss': 0.17230232790923078, 'Total loss': 0.17230232790923078}
2022-12-31 06:04:49,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:49,519 INFO:     Epoch: 25
2022-12-31 06:04:51,164 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4318031492953499, 'Total loss': 0.4318031492953499} | train loss {'Reaction outcome loss': 0.17331887487038647, 'Total loss': 0.17331887487038647}
2022-12-31 06:04:51,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:51,164 INFO:     Epoch: 26
2022-12-31 06:04:52,787 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4355264209210873, 'Total loss': 0.4355264209210873} | train loss {'Reaction outcome loss': 0.1720153246500084, 'Total loss': 0.1720153246500084}
2022-12-31 06:04:52,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:52,788 INFO:     Epoch: 27
2022-12-31 06:04:54,452 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42442271709442136, 'Total loss': 0.42442271709442136} | train loss {'Reaction outcome loss': 0.1642615828119312, 'Total loss': 0.1642615828119312}
2022-12-31 06:04:54,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:54,452 INFO:     Epoch: 28
2022-12-31 06:04:56,071 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45134447266658145, 'Total loss': 0.45134447266658145} | train loss {'Reaction outcome loss': 0.16124006540021452, 'Total loss': 0.16124006540021452}
2022-12-31 06:04:56,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:56,072 INFO:     Epoch: 29
2022-12-31 06:04:57,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4390308476984501, 'Total loss': 0.4390308476984501} | train loss {'Reaction outcome loss': 0.15665894982985396, 'Total loss': 0.15665894982985396}
2022-12-31 06:04:57,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:57,681 INFO:     Epoch: 30
2022-12-31 06:04:59,346 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43972293138504026, 'Total loss': 0.43972293138504026} | train loss {'Reaction outcome loss': 0.16011345445556377, 'Total loss': 0.16011345445556377}
2022-12-31 06:04:59,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:04:59,346 INFO:     Epoch: 31
2022-12-31 06:05:00,964 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4330668901403745, 'Total loss': 0.4330668901403745} | train loss {'Reaction outcome loss': 0.15584235255896667, 'Total loss': 0.15584235255896667}
2022-12-31 06:05:00,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:00,965 INFO:     Epoch: 32
2022-12-31 06:05:02,592 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44071418742338814, 'Total loss': 0.44071418742338814} | train loss {'Reaction outcome loss': 0.1577315426372967, 'Total loss': 0.1577315426372967}
2022-12-31 06:05:02,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:02,592 INFO:     Epoch: 33
2022-12-31 06:05:04,220 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4614401340484619, 'Total loss': 0.4614401340484619} | train loss {'Reaction outcome loss': 0.15260062381363584, 'Total loss': 0.15260062381363584}
2022-12-31 06:05:04,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:04,221 INFO:     Epoch: 34
2022-12-31 06:05:05,846 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4274014761671424, 'Total loss': 0.4274014761671424} | train loss {'Reaction outcome loss': 0.15328743477331716, 'Total loss': 0.15328743477331716}
2022-12-31 06:05:05,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:05,846 INFO:     Epoch: 35
2022-12-31 06:05:07,459 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47460027833779656, 'Total loss': 0.47460027833779656} | train loss {'Reaction outcome loss': 0.15416814607775398, 'Total loss': 0.15416814607775398}
2022-12-31 06:05:07,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:07,460 INFO:     Epoch: 36
2022-12-31 06:05:09,124 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49198773006598157, 'Total loss': 0.49198773006598157} | train loss {'Reaction outcome loss': 0.14560635239257058, 'Total loss': 0.14560635239257058}
2022-12-31 06:05:09,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:09,125 INFO:     Epoch: 37
2022-12-31 06:05:10,748 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44203230539957683, 'Total loss': 0.44203230539957683} | train loss {'Reaction outcome loss': 0.14723257200692888, 'Total loss': 0.14723257200692888}
2022-12-31 06:05:10,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:10,749 INFO:     Epoch: 38
2022-12-31 06:05:12,413 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4390935659408569, 'Total loss': 0.4390935659408569} | train loss {'Reaction outcome loss': 0.14282493194079268, 'Total loss': 0.14282493194079268}
2022-12-31 06:05:12,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:12,413 INFO:     Epoch: 39
2022-12-31 06:05:14,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44553138315677643, 'Total loss': 0.44553138315677643} | train loss {'Reaction outcome loss': 0.14376437916117552, 'Total loss': 0.14376437916117552}
2022-12-31 06:05:14,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:14,079 INFO:     Epoch: 40
2022-12-31 06:05:15,718 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44837096134821575, 'Total loss': 0.44837096134821575} | train loss {'Reaction outcome loss': 0.143656290536139, 'Total loss': 0.143656290536139}
2022-12-31 06:05:15,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:15,718 INFO:     Epoch: 41
2022-12-31 06:05:17,382 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46030665238698326, 'Total loss': 0.46030665238698326} | train loss {'Reaction outcome loss': 0.1421106087811126, 'Total loss': 0.1421106087811126}
2022-12-31 06:05:17,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:17,382 INFO:     Epoch: 42
2022-12-31 06:05:19,047 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4825337529182434, 'Total loss': 0.4825337529182434} | train loss {'Reaction outcome loss': 0.1398795407687852, 'Total loss': 0.1398795407687852}
2022-12-31 06:05:19,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:19,047 INFO:     Epoch: 43
2022-12-31 06:05:20,669 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4464145104090373, 'Total loss': 0.4464145104090373} | train loss {'Reaction outcome loss': 0.1380333946224815, 'Total loss': 0.1380333946224815}
2022-12-31 06:05:20,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:20,671 INFO:     Epoch: 44
2022-12-31 06:05:22,291 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46003251473108925, 'Total loss': 0.46003251473108925} | train loss {'Reaction outcome loss': 0.13667296312487978, 'Total loss': 0.13667296312487978}
2022-12-31 06:05:22,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:22,292 INFO:     Epoch: 45
2022-12-31 06:05:23,956 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46963043610254923, 'Total loss': 0.46963043610254923} | train loss {'Reaction outcome loss': 0.1450001158501845, 'Total loss': 0.1450001158501845}
2022-12-31 06:05:23,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:23,957 INFO:     Epoch: 46
2022-12-31 06:05:25,621 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4641932169596354, 'Total loss': 0.4641932169596354} | train loss {'Reaction outcome loss': 0.14388371272992156, 'Total loss': 0.14388371272992156}
2022-12-31 06:05:25,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:25,621 INFO:     Epoch: 47
2022-12-31 06:05:27,238 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48054579788198076, 'Total loss': 0.48054579788198076} | train loss {'Reaction outcome loss': 0.1353424641917851, 'Total loss': 0.1353424641917851}
2022-12-31 06:05:27,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:27,239 INFO:     Epoch: 48
2022-12-31 06:05:28,863 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4429026951392492, 'Total loss': 0.4429026951392492} | train loss {'Reaction outcome loss': 0.14828609020339395, 'Total loss': 0.14828609020339395}
2022-12-31 06:05:28,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:28,863 INFO:     Epoch: 49
2022-12-31 06:05:30,528 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45894524157047273, 'Total loss': 0.45894524157047273} | train loss {'Reaction outcome loss': 0.13215676706420418, 'Total loss': 0.13215676706420418}
2022-12-31 06:05:30,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:30,528 INFO:     Epoch: 50
2022-12-31 06:05:32,192 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42982100198666257, 'Total loss': 0.42982100198666257} | train loss {'Reaction outcome loss': 0.13077378947038096, 'Total loss': 0.13077378947038096}
2022-12-31 06:05:32,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:32,193 INFO:     Epoch: 51
2022-12-31 06:05:33,840 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4660508801539739, 'Total loss': 0.4660508801539739} | train loss {'Reaction outcome loss': 0.12773102879915657, 'Total loss': 0.12773102879915657}
2022-12-31 06:05:33,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:33,840 INFO:     Epoch: 52
2022-12-31 06:05:35,506 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43908085028330485, 'Total loss': 0.43908085028330485} | train loss {'Reaction outcome loss': 0.12933441666709242, 'Total loss': 0.12933441666709242}
2022-12-31 06:05:35,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:35,506 INFO:     Epoch: 53
2022-12-31 06:05:37,126 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47064846257368725, 'Total loss': 0.47064846257368725} | train loss {'Reaction outcome loss': 0.1289094792313462, 'Total loss': 0.1289094792313462}
2022-12-31 06:05:37,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:37,126 INFO:     Epoch: 54
2022-12-31 06:05:38,756 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45119838913281757, 'Total loss': 0.45119838913281757} | train loss {'Reaction outcome loss': 0.1266190048138041, 'Total loss': 0.1266190048138041}
2022-12-31 06:05:38,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:38,756 INFO:     Epoch: 55
2022-12-31 06:05:40,387 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45962864756584165, 'Total loss': 0.45962864756584165} | train loss {'Reaction outcome loss': 0.1280822444148699, 'Total loss': 0.1280822444148699}
2022-12-31 06:05:40,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:40,388 INFO:     Epoch: 56
2022-12-31 06:05:42,020 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47972511649131777, 'Total loss': 0.47972511649131777} | train loss {'Reaction outcome loss': 0.12775418338845856, 'Total loss': 0.12775418338845856}
2022-12-31 06:05:42,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:42,020 INFO:     Epoch: 57
2022-12-31 06:05:43,642 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44628272553284964, 'Total loss': 0.44628272553284964} | train loss {'Reaction outcome loss': 0.1283809665819981, 'Total loss': 0.1283809665819981}
2022-12-31 06:05:43,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:43,642 INFO:     Epoch: 58
2022-12-31 06:05:45,273 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47742857535680133, 'Total loss': 0.47742857535680133} | train loss {'Reaction outcome loss': 0.12217863187938285, 'Total loss': 0.12217863187938285}
2022-12-31 06:05:45,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:45,273 INFO:     Epoch: 59
2022-12-31 06:05:46,897 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4636839032173157, 'Total loss': 0.4636839032173157} | train loss {'Reaction outcome loss': 0.12177356642897011, 'Total loss': 0.12177356642897011}
2022-12-31 06:05:46,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:46,897 INFO:     Epoch: 60
2022-12-31 06:05:48,525 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43899691129724183, 'Total loss': 0.43899691129724183} | train loss {'Reaction outcome loss': 0.12714964785268618, 'Total loss': 0.12714964785268618}
2022-12-31 06:05:48,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:48,526 INFO:     Epoch: 61
2022-12-31 06:05:50,154 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4357786029577255, 'Total loss': 0.4357786029577255} | train loss {'Reaction outcome loss': 0.12403059348785525, 'Total loss': 0.12403059348785525}
2022-12-31 06:05:50,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:50,155 INFO:     Epoch: 62
2022-12-31 06:05:51,782 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47347197035948435, 'Total loss': 0.47347197035948435} | train loss {'Reaction outcome loss': 0.12257997271523852, 'Total loss': 0.12257997271523852}
2022-12-31 06:05:51,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:51,783 INFO:     Epoch: 63
2022-12-31 06:05:53,401 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45242132196823753, 'Total loss': 0.45242132196823753} | train loss {'Reaction outcome loss': 0.12676402831662767, 'Total loss': 0.12676402831662767}
2022-12-31 06:05:53,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:53,401 INFO:     Epoch: 64
2022-12-31 06:05:55,016 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4479369615515073, 'Total loss': 0.4479369615515073} | train loss {'Reaction outcome loss': 0.12250697392501288, 'Total loss': 0.12250697392501288}
2022-12-31 06:05:55,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:55,016 INFO:     Epoch: 65
2022-12-31 06:05:56,650 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4601581931114197, 'Total loss': 0.4601581931114197} | train loss {'Reaction outcome loss': 0.11965177542246554, 'Total loss': 0.11965177542246554}
2022-12-31 06:05:56,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:56,650 INFO:     Epoch: 66
2022-12-31 06:05:58,279 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47393177648385365, 'Total loss': 0.47393177648385365} | train loss {'Reaction outcome loss': 0.11730267681095806, 'Total loss': 0.11730267681095806}
2022-12-31 06:05:58,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:58,280 INFO:     Epoch: 67
2022-12-31 06:05:59,910 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4826907900472482, 'Total loss': 0.4826907900472482} | train loss {'Reaction outcome loss': 0.11825716926630223, 'Total loss': 0.11825716926630223}
2022-12-31 06:05:59,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:05:59,910 INFO:     Epoch: 68
2022-12-31 06:06:01,543 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47432631651560464, 'Total loss': 0.47432631651560464} | train loss {'Reaction outcome loss': 0.1175596177556039, 'Total loss': 0.1175596177556039}
2022-12-31 06:06:01,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:01,543 INFO:     Epoch: 69
2022-12-31 06:06:03,165 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4436241944630941, 'Total loss': 0.4436241944630941} | train loss {'Reaction outcome loss': 0.11808153093485432, 'Total loss': 0.11808153093485432}
2022-12-31 06:06:03,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:03,165 INFO:     Epoch: 70
2022-12-31 06:06:04,828 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4691275159517924, 'Total loss': 0.4691275159517924} | train loss {'Reaction outcome loss': 0.1204153983463795, 'Total loss': 0.1204153983463795}
2022-12-31 06:06:04,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:04,828 INFO:     Epoch: 71
2022-12-31 06:06:06,449 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4453357179959615, 'Total loss': 0.4453357179959615} | train loss {'Reaction outcome loss': 0.12187621123049884, 'Total loss': 0.12187621123049884}
2022-12-31 06:06:06,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:06,450 INFO:     Epoch: 72
2022-12-31 06:06:08,117 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.468394136428833, 'Total loss': 0.468394136428833} | train loss {'Reaction outcome loss': 0.11873791396320102, 'Total loss': 0.11873791396320102}
2022-12-31 06:06:08,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:08,117 INFO:     Epoch: 73
2022-12-31 06:06:09,740 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44994722803433734, 'Total loss': 0.44994722803433734} | train loss {'Reaction outcome loss': 0.11484420617225756, 'Total loss': 0.11484420617225756}
2022-12-31 06:06:09,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:09,741 INFO:     Epoch: 74
2022-12-31 06:06:11,362 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42264247238636016, 'Total loss': 0.42264247238636016} | train loss {'Reaction outcome loss': 0.11645783255664645, 'Total loss': 0.11645783255664645}
2022-12-31 06:06:11,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:11,363 INFO:     Epoch: 75
2022-12-31 06:06:12,983 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4439128277823329, 'Total loss': 0.4439128277823329} | train loss {'Reaction outcome loss': 0.11337771143007558, 'Total loss': 0.11337771143007558}
2022-12-31 06:06:12,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:12,983 INFO:     Epoch: 76
2022-12-31 06:06:14,624 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46121107240517933, 'Total loss': 0.46121107240517933} | train loss {'Reaction outcome loss': 0.11331780870737482, 'Total loss': 0.11331780870737482}
2022-12-31 06:06:14,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:14,625 INFO:     Epoch: 77
2022-12-31 06:06:16,251 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46983372370402016, 'Total loss': 0.46983372370402016} | train loss {'Reaction outcome loss': 0.1167817030251119, 'Total loss': 0.1167817030251119}
2022-12-31 06:06:16,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:16,251 INFO:     Epoch: 78
2022-12-31 06:06:17,878 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4742953817049662, 'Total loss': 0.4742953817049662} | train loss {'Reaction outcome loss': 0.1169856522600099, 'Total loss': 0.1169856522600099}
2022-12-31 06:06:17,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:17,878 INFO:     Epoch: 79
2022-12-31 06:06:19,499 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4471561486522357, 'Total loss': 0.4471561486522357} | train loss {'Reaction outcome loss': 0.11500897062554334, 'Total loss': 0.11500897062554334}
2022-12-31 06:06:19,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:19,499 INFO:     Epoch: 80
2022-12-31 06:06:21,118 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4577905277411143, 'Total loss': 0.4577905277411143} | train loss {'Reaction outcome loss': 0.11607128631768991, 'Total loss': 0.11607128631768991}
2022-12-31 06:06:21,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:21,118 INFO:     Epoch: 81
2022-12-31 06:06:22,738 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4685177599390348, 'Total loss': 0.4685177599390348} | train loss {'Reaction outcome loss': 0.11500048512243666, 'Total loss': 0.11500048512243666}
2022-12-31 06:06:22,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:22,738 INFO:     Epoch: 82
2022-12-31 06:06:24,358 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4788110921780268, 'Total loss': 0.4788110921780268} | train loss {'Reaction outcome loss': 0.11099681266637491, 'Total loss': 0.11099681266637491}
2022-12-31 06:06:24,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:24,358 INFO:     Epoch: 83
2022-12-31 06:06:25,985 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45257211327552793, 'Total loss': 0.45257211327552793} | train loss {'Reaction outcome loss': 0.10822876291891537, 'Total loss': 0.10822876291891537}
2022-12-31 06:06:25,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:25,985 INFO:     Epoch: 84
2022-12-31 06:06:27,614 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4868326356013616, 'Total loss': 0.4868326356013616} | train loss {'Reaction outcome loss': 0.12282158452190756, 'Total loss': 0.12282158452190756}
2022-12-31 06:06:27,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:27,615 INFO:     Epoch: 85
2022-12-31 06:06:29,233 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4362503543496132, 'Total loss': 0.4362503543496132} | train loss {'Reaction outcome loss': 0.12346127765772837, 'Total loss': 0.12346127765772837}
2022-12-31 06:06:29,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:29,233 INFO:     Epoch: 86
2022-12-31 06:06:30,859 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4752603550752004, 'Total loss': 0.4752603550752004} | train loss {'Reaction outcome loss': 0.10861240371731043, 'Total loss': 0.10861240371731043}
2022-12-31 06:06:30,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:30,859 INFO:     Epoch: 87
2022-12-31 06:06:32,477 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4328419387340546, 'Total loss': 0.4328419387340546} | train loss {'Reaction outcome loss': 0.10838143377074722, 'Total loss': 0.10838143377074722}
2022-12-31 06:06:32,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:32,478 INFO:     Epoch: 88
2022-12-31 06:06:34,097 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45213709572951, 'Total loss': 0.45213709572951} | train loss {'Reaction outcome loss': 0.1091729192437766, 'Total loss': 0.1091729192437766}
2022-12-31 06:06:34,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:34,098 INFO:     Epoch: 89
2022-12-31 06:06:35,717 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4411461432774862, 'Total loss': 0.4411461432774862} | train loss {'Reaction outcome loss': 0.11371517521848032, 'Total loss': 0.11371517521848032}
2022-12-31 06:06:35,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:35,717 INFO:     Epoch: 90
2022-12-31 06:06:37,339 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.460917920867602, 'Total loss': 0.460917920867602} | train loss {'Reaction outcome loss': 0.1105464249579371, 'Total loss': 0.1105464249579371}
2022-12-31 06:06:37,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:37,339 INFO:     Epoch: 91
2022-12-31 06:06:38,995 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4809225171804428, 'Total loss': 0.4809225171804428} | train loss {'Reaction outcome loss': 0.11171807372601757, 'Total loss': 0.11171807372601757}
2022-12-31 06:06:38,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:38,995 INFO:     Epoch: 92
2022-12-31 06:06:40,614 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4553370555241903, 'Total loss': 0.4553370555241903} | train loss {'Reaction outcome loss': 0.1102912060096037, 'Total loss': 0.1102912060096037}
2022-12-31 06:06:40,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:40,614 INFO:     Epoch: 93
2022-12-31 06:06:42,244 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43027909422914185, 'Total loss': 0.43027909422914185} | train loss {'Reaction outcome loss': 0.11044280986981533, 'Total loss': 0.11044280986981533}
2022-12-31 06:06:42,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:42,245 INFO:     Epoch: 94
2022-12-31 06:06:43,871 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44099468340476355, 'Total loss': 0.44099468340476355} | train loss {'Reaction outcome loss': 0.10806726299959178, 'Total loss': 0.10806726299959178}
2022-12-31 06:06:43,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:43,872 INFO:     Epoch: 95
2022-12-31 06:06:45,500 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4683635244766871, 'Total loss': 0.4683635244766871} | train loss {'Reaction outcome loss': 0.10579877483837334, 'Total loss': 0.10579877483837334}
2022-12-31 06:06:45,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:45,500 INFO:     Epoch: 96
2022-12-31 06:06:47,119 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45158260464668276, 'Total loss': 0.45158260464668276} | train loss {'Reaction outcome loss': 0.10642416018020848, 'Total loss': 0.10642416018020848}
2022-12-31 06:06:47,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:47,120 INFO:     Epoch: 97
2022-12-31 06:06:48,747 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.479614516099294, 'Total loss': 0.479614516099294} | train loss {'Reaction outcome loss': 0.11481171346004239, 'Total loss': 0.11481171346004239}
2022-12-31 06:06:48,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:48,748 INFO:     Epoch: 98
2022-12-31 06:06:50,371 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44752469658851624, 'Total loss': 0.44752469658851624} | train loss {'Reaction outcome loss': 0.11084969096776584, 'Total loss': 0.11084969096776584}
2022-12-31 06:06:50,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:50,372 INFO:     Epoch: 99
2022-12-31 06:06:51,490 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4490889032681783, 'Total loss': 0.4490889032681783} | train loss {'Reaction outcome loss': 0.10715964355715213, 'Total loss': 0.10715964355715213}
2022-12-31 06:06:51,491 INFO:     Best model found after epoch 9 of 100.
2022-12-31 06:06:51,491 INFO:   Done with stage: TRAINING
2022-12-31 06:06:51,491 INFO:   Starting stage: EVALUATION
2022-12-31 06:06:51,618 INFO:   Done with stage: EVALUATION
2022-12-31 06:06:51,618 INFO:   Leaving out SEQ value Fold_5
2022-12-31 06:06:51,632 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:06:51,632 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:06:52,273 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:06:52,274 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:06:52,344 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:06:52,344 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:06:52,344 INFO:     No hyperparam tuning for this model
2022-12-31 06:06:52,344 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:06:52,344 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:06:52,345 INFO:     None feature selector for col prot
2022-12-31 06:06:52,345 INFO:     None feature selector for col prot
2022-12-31 06:06:52,345 INFO:     None feature selector for col prot
2022-12-31 06:06:52,346 INFO:     None feature selector for col chem
2022-12-31 06:06:52,346 INFO:     None feature selector for col chem
2022-12-31 06:06:52,346 INFO:     None feature selector for col chem
2022-12-31 06:06:52,346 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:06:52,346 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:06:52,348 INFO:     Number of params in model 224011
2022-12-31 06:06:52,351 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:06:52,351 INFO:   Starting stage: TRAINING
2022-12-31 06:06:52,385 INFO:     Val loss before train {'Reaction outcome loss': 1.03848237991333, 'Total loss': 1.03848237991333}
2022-12-31 06:06:52,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:52,385 INFO:     Epoch: 0
2022-12-31 06:06:53,490 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5950025260448456, 'Total loss': 0.5950025260448456} | train loss {'Reaction outcome loss': 0.775114885849399, 'Total loss': 0.775114885849399}
2022-12-31 06:06:53,490 INFO:     Found new best model at epoch 0
2022-12-31 06:06:53,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:53,491 INFO:     Epoch: 1
2022-12-31 06:06:54,614 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5017826507488886, 'Total loss': 0.5017826507488886} | train loss {'Reaction outcome loss': 0.5008118389468755, 'Total loss': 0.5008118389468755}
2022-12-31 06:06:54,614 INFO:     Found new best model at epoch 1
2022-12-31 06:06:54,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:54,615 INFO:     Epoch: 2
2022-12-31 06:06:56,116 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47828498284022014, 'Total loss': 0.47828498284022014} | train loss {'Reaction outcome loss': 0.4371147007290004, 'Total loss': 0.4371147007290004}
2022-12-31 06:06:56,116 INFO:     Found new best model at epoch 2
2022-12-31 06:06:56,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:56,117 INFO:     Epoch: 3
2022-12-31 06:06:57,722 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4703305502732595, 'Total loss': 0.4703305502732595} | train loss {'Reaction outcome loss': 0.3988561035248626, 'Total loss': 0.3988561035248626}
2022-12-31 06:06:57,722 INFO:     Found new best model at epoch 3
2022-12-31 06:06:57,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:57,723 INFO:     Epoch: 4
2022-12-31 06:06:59,330 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4468899488449097, 'Total loss': 0.4468899488449097} | train loss {'Reaction outcome loss': 0.36471396306634246, 'Total loss': 0.36471396306634246}
2022-12-31 06:06:59,331 INFO:     Found new best model at epoch 4
2022-12-31 06:06:59,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:06:59,332 INFO:     Epoch: 5
2022-12-31 06:07:00,937 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4899906575679779, 'Total loss': 0.4899906575679779} | train loss {'Reaction outcome loss': 0.3399028578246741, 'Total loss': 0.3399028578246741}
2022-12-31 06:07:00,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:00,937 INFO:     Epoch: 6
2022-12-31 06:07:02,583 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47572786211967466, 'Total loss': 0.47572786211967466} | train loss {'Reaction outcome loss': 0.3366312364629213, 'Total loss': 0.3366312364629213}
2022-12-31 06:07:02,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:02,584 INFO:     Epoch: 7
2022-12-31 06:07:04,201 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4251117656628291, 'Total loss': 0.4251117656628291} | train loss {'Reaction outcome loss': 0.31801857778476705, 'Total loss': 0.31801857778476705}
2022-12-31 06:07:04,202 INFO:     Found new best model at epoch 7
2022-12-31 06:07:04,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:04,203 INFO:     Epoch: 8
2022-12-31 06:07:05,829 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43755657970905304, 'Total loss': 0.43755657970905304} | train loss {'Reaction outcome loss': 0.2946997708126403, 'Total loss': 0.2946997708126403}
2022-12-31 06:07:05,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:05,830 INFO:     Epoch: 9
2022-12-31 06:07:07,460 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4517770846684774, 'Total loss': 0.4517770846684774} | train loss {'Reaction outcome loss': 0.27969050464098866, 'Total loss': 0.27969050464098866}
2022-12-31 06:07:07,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:07,460 INFO:     Epoch: 10
2022-12-31 06:07:09,087 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45418886343638104, 'Total loss': 0.45418886343638104} | train loss {'Reaction outcome loss': 0.2663712905773866, 'Total loss': 0.2663712905773866}
2022-12-31 06:07:09,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:09,088 INFO:     Epoch: 11
2022-12-31 06:07:10,715 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44334515233834587, 'Total loss': 0.44334515233834587} | train loss {'Reaction outcome loss': 0.25285646802876066, 'Total loss': 0.25285646802876066}
2022-12-31 06:07:10,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:10,715 INFO:     Epoch: 12
2022-12-31 06:07:12,331 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43646184702714286, 'Total loss': 0.43646184702714286} | train loss {'Reaction outcome loss': 0.2449708517262901, 'Total loss': 0.2449708517262901}
2022-12-31 06:07:12,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:12,331 INFO:     Epoch: 13
2022-12-31 06:07:13,964 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43184638222058613, 'Total loss': 0.43184638222058613} | train loss {'Reaction outcome loss': 0.2397257024489775, 'Total loss': 0.2397257024489775}
2022-12-31 06:07:13,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:13,964 INFO:     Epoch: 14
2022-12-31 06:07:15,624 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4499650855859121, 'Total loss': 0.4499650855859121} | train loss {'Reaction outcome loss': 0.2326557997380471, 'Total loss': 0.2326557997380471}
2022-12-31 06:07:15,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:15,624 INFO:     Epoch: 15
2022-12-31 06:07:17,284 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4574808617432912, 'Total loss': 0.4574808617432912} | train loss {'Reaction outcome loss': 0.21784955432530548, 'Total loss': 0.21784955432530548}
2022-12-31 06:07:17,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:17,284 INFO:     Epoch: 16
2022-12-31 06:07:18,943 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4550654331843058, 'Total loss': 0.4550654331843058} | train loss {'Reaction outcome loss': 0.21400812468525238, 'Total loss': 0.21400812468525238}
2022-12-31 06:07:18,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:18,943 INFO:     Epoch: 17
2022-12-31 06:07:20,598 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44660893579324085, 'Total loss': 0.44660893579324085} | train loss {'Reaction outcome loss': 0.20687898568997998, 'Total loss': 0.20687898568997998}
2022-12-31 06:07:20,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:20,598 INFO:     Epoch: 18
2022-12-31 06:07:22,247 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41924184262752534, 'Total loss': 0.41924184262752534} | train loss {'Reaction outcome loss': 0.20460127008592952, 'Total loss': 0.20460127008592952}
2022-12-31 06:07:22,248 INFO:     Found new best model at epoch 18
2022-12-31 06:07:22,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:22,249 INFO:     Epoch: 19
2022-12-31 06:07:23,904 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44106168548266095, 'Total loss': 0.44106168548266095} | train loss {'Reaction outcome loss': 0.21706657017837616, 'Total loss': 0.21706657017837616}
2022-12-31 06:07:23,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:23,904 INFO:     Epoch: 20
2022-12-31 06:07:25,564 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4255006045103073, 'Total loss': 0.4255006045103073} | train loss {'Reaction outcome loss': 0.204670474146648, 'Total loss': 0.204670474146648}
2022-12-31 06:07:25,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:25,564 INFO:     Epoch: 21
2022-12-31 06:07:27,222 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42537935078144073, 'Total loss': 0.42537935078144073} | train loss {'Reaction outcome loss': 0.18558055874756604, 'Total loss': 0.18558055874756604}
2022-12-31 06:07:27,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:27,223 INFO:     Epoch: 22
2022-12-31 06:07:28,882 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48194579084714256, 'Total loss': 0.48194579084714256} | train loss {'Reaction outcome loss': 0.17950356692291689, 'Total loss': 0.17950356692291689}
2022-12-31 06:07:28,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:28,882 INFO:     Epoch: 23
2022-12-31 06:07:30,516 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47876487572987875, 'Total loss': 0.47876487572987875} | train loss {'Reaction outcome loss': 0.17883925673052453, 'Total loss': 0.17883925673052453}
2022-12-31 06:07:30,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:30,517 INFO:     Epoch: 24
2022-12-31 06:07:32,156 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4288831998904546, 'Total loss': 0.4288831998904546} | train loss {'Reaction outcome loss': 0.18455302335011461, 'Total loss': 0.18455302335011461}
2022-12-31 06:07:32,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:32,156 INFO:     Epoch: 25
2022-12-31 06:07:33,786 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44874874999125797, 'Total loss': 0.44874874999125797} | train loss {'Reaction outcome loss': 0.17197978750669607, 'Total loss': 0.17197978750669607}
2022-12-31 06:07:33,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:33,786 INFO:     Epoch: 26
2022-12-31 06:07:35,415 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45733775198459625, 'Total loss': 0.45733775198459625} | train loss {'Reaction outcome loss': 0.16652297101024052, 'Total loss': 0.16652297101024052}
2022-12-31 06:07:35,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:35,415 INFO:     Epoch: 27
2022-12-31 06:07:37,045 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46064404348532356, 'Total loss': 0.46064404348532356} | train loss {'Reaction outcome loss': 0.17156034433940912, 'Total loss': 0.17156034433940912}
2022-12-31 06:07:37,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:37,045 INFO:     Epoch: 28
2022-12-31 06:07:38,676 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46434593896071114, 'Total loss': 0.46434593896071114} | train loss {'Reaction outcome loss': 0.16249810341864562, 'Total loss': 0.16249810341864562}
2022-12-31 06:07:38,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:38,677 INFO:     Epoch: 29
2022-12-31 06:07:40,296 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4775910139083862, 'Total loss': 0.4775910139083862} | train loss {'Reaction outcome loss': 0.1594452524542525, 'Total loss': 0.1594452524542525}
2022-12-31 06:07:40,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:40,296 INFO:     Epoch: 30
2022-12-31 06:07:41,938 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42983557321131227, 'Total loss': 0.42983557321131227} | train loss {'Reaction outcome loss': 0.16299224826439784, 'Total loss': 0.16299224826439784}
2022-12-31 06:07:41,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:41,938 INFO:     Epoch: 31
2022-12-31 06:07:43,601 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5075099229812622, 'Total loss': 0.5075099229812622} | train loss {'Reaction outcome loss': 0.16267175063409883, 'Total loss': 0.16267175063409883}
2022-12-31 06:07:43,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:43,601 INFO:     Epoch: 32
2022-12-31 06:07:45,265 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45462029576301577, 'Total loss': 0.45462029576301577} | train loss {'Reaction outcome loss': 0.1772476180196753, 'Total loss': 0.1772476180196753}
2022-12-31 06:07:45,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:45,266 INFO:     Epoch: 33
2022-12-31 06:07:46,929 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45101165572802226, 'Total loss': 0.45101165572802226} | train loss {'Reaction outcome loss': 0.15425344017010345, 'Total loss': 0.15425344017010345}
2022-12-31 06:07:46,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:46,929 INFO:     Epoch: 34
2022-12-31 06:07:48,580 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4576658735672633, 'Total loss': 0.4576658735672633} | train loss {'Reaction outcome loss': 0.15273299937987336, 'Total loss': 0.15273299937987336}
2022-12-31 06:07:48,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:48,580 INFO:     Epoch: 35
2022-12-31 06:07:50,248 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4606143653392792, 'Total loss': 0.4606143653392792} | train loss {'Reaction outcome loss': 0.1457955817239818, 'Total loss': 0.1457955817239818}
2022-12-31 06:07:50,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:50,248 INFO:     Epoch: 36
2022-12-31 06:07:51,907 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4418635567029317, 'Total loss': 0.4418635567029317} | train loss {'Reaction outcome loss': 0.1481055322506438, 'Total loss': 0.1481055322506438}
2022-12-31 06:07:51,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:51,907 INFO:     Epoch: 37
2022-12-31 06:07:53,576 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46395378013451893, 'Total loss': 0.46395378013451893} | train loss {'Reaction outcome loss': 0.14278005619459125, 'Total loss': 0.14278005619459125}
2022-12-31 06:07:53,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:53,576 INFO:     Epoch: 38
2022-12-31 06:07:55,239 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49388588070869444, 'Total loss': 0.49388588070869444} | train loss {'Reaction outcome loss': 0.1442104283116245, 'Total loss': 0.1442104283116245}
2022-12-31 06:07:55,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:55,240 INFO:     Epoch: 39
2022-12-31 06:07:56,905 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42769260903199513, 'Total loss': 0.42769260903199513} | train loss {'Reaction outcome loss': 0.14535462164802584, 'Total loss': 0.14535462164802584}
2022-12-31 06:07:56,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:56,905 INFO:     Epoch: 40
2022-12-31 06:07:58,554 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4499258160591125, 'Total loss': 0.4499258160591125} | train loss {'Reaction outcome loss': 0.1427908383805028, 'Total loss': 0.1427908383805028}
2022-12-31 06:07:58,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:07:58,555 INFO:     Epoch: 41
2022-12-31 06:08:00,220 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47310846572120985, 'Total loss': 0.47310846572120985} | train loss {'Reaction outcome loss': 0.14119398369381297, 'Total loss': 0.14119398369381297}
2022-12-31 06:08:00,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:00,220 INFO:     Epoch: 42
2022-12-31 06:08:01,884 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4700505127509435, 'Total loss': 0.4700505127509435} | train loss {'Reaction outcome loss': 0.13598037953825964, 'Total loss': 0.13598037953825964}
2022-12-31 06:08:01,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:01,884 INFO:     Epoch: 43
2022-12-31 06:08:03,553 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4655154267946879, 'Total loss': 0.4655154267946879} | train loss {'Reaction outcome loss': 0.14000847314826492, 'Total loss': 0.14000847314826492}
2022-12-31 06:08:03,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:03,553 INFO:     Epoch: 44
2022-12-31 06:08:05,222 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4863028856615225, 'Total loss': 0.4863028856615225} | train loss {'Reaction outcome loss': 0.1362254708293762, 'Total loss': 0.1362254708293762}
2022-12-31 06:08:05,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:05,222 INFO:     Epoch: 45
2022-12-31 06:08:06,880 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48489340345064796, 'Total loss': 0.48489340345064796} | train loss {'Reaction outcome loss': 0.1350890467391751, 'Total loss': 0.1350890467391751}
2022-12-31 06:08:06,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:06,880 INFO:     Epoch: 46
2022-12-31 06:08:08,493 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4631656726201375, 'Total loss': 0.4631656726201375} | train loss {'Reaction outcome loss': 0.13400056652144354, 'Total loss': 0.13400056652144354}
2022-12-31 06:08:08,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:08,494 INFO:     Epoch: 47
2022-12-31 06:08:10,119 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4553951799869537, 'Total loss': 0.4553951799869537} | train loss {'Reaction outcome loss': 0.13042215342832514, 'Total loss': 0.13042215342832514}
2022-12-31 06:08:10,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:10,121 INFO:     Epoch: 48
2022-12-31 06:08:11,753 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44025215953588487, 'Total loss': 0.44025215953588487} | train loss {'Reaction outcome loss': 0.13329416528733048, 'Total loss': 0.13329416528733048}
2022-12-31 06:08:11,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:11,753 INFO:     Epoch: 49
2022-12-31 06:08:13,385 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4607857902844747, 'Total loss': 0.4607857902844747} | train loss {'Reaction outcome loss': 0.1312014132677375, 'Total loss': 0.1312014132677375}
2022-12-31 06:08:13,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:13,385 INFO:     Epoch: 50
2022-12-31 06:08:15,018 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4728279282649358, 'Total loss': 0.4728279282649358} | train loss {'Reaction outcome loss': 0.131522441692431, 'Total loss': 0.131522441692431}
2022-12-31 06:08:15,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:15,018 INFO:     Epoch: 51
2022-12-31 06:08:16,641 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4482034395138423, 'Total loss': 0.4482034395138423} | train loss {'Reaction outcome loss': 0.1330242390656655, 'Total loss': 0.1330242390656655}
2022-12-31 06:08:16,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:16,642 INFO:     Epoch: 52
2022-12-31 06:08:18,273 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4556656648715337, 'Total loss': 0.4556656648715337} | train loss {'Reaction outcome loss': 0.13015688195878614, 'Total loss': 0.13015688195878614}
2022-12-31 06:08:18,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:18,273 INFO:     Epoch: 53
2022-12-31 06:08:19,896 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48124694426854453, 'Total loss': 0.48124694426854453} | train loss {'Reaction outcome loss': 0.12656456975357444, 'Total loss': 0.12656456975357444}
2022-12-31 06:08:19,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:19,897 INFO:     Epoch: 54
2022-12-31 06:08:21,560 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4608503778775533, 'Total loss': 0.4608503778775533} | train loss {'Reaction outcome loss': 0.12890168779325695, 'Total loss': 0.12890168779325695}
2022-12-31 06:08:21,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:21,561 INFO:     Epoch: 55
2022-12-31 06:08:23,224 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4771200815836589, 'Total loss': 0.4771200815836589} | train loss {'Reaction outcome loss': 0.12454391938218327, 'Total loss': 0.12454391938218327}
2022-12-31 06:08:23,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:23,225 INFO:     Epoch: 56
2022-12-31 06:08:24,888 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.443477580572168, 'Total loss': 0.443477580572168} | train loss {'Reaction outcome loss': 0.12650931435907126, 'Total loss': 0.12650931435907126}
2022-12-31 06:08:24,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:24,888 INFO:     Epoch: 57
2022-12-31 06:08:26,536 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5032999813556671, 'Total loss': 0.5032999813556671} | train loss {'Reaction outcome loss': 0.12147358159173577, 'Total loss': 0.12147358159173577}
2022-12-31 06:08:26,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:26,536 INFO:     Epoch: 58
2022-12-31 06:08:28,158 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4695976972579956, 'Total loss': 0.4695976972579956} | train loss {'Reaction outcome loss': 0.12100898315564837, 'Total loss': 0.12100898315564837}
2022-12-31 06:08:28,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:28,158 INFO:     Epoch: 59
2022-12-31 06:08:29,789 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4740938305854797, 'Total loss': 0.4740938305854797} | train loss {'Reaction outcome loss': 0.12729512934448142, 'Total loss': 0.12729512934448142}
2022-12-31 06:08:29,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:29,790 INFO:     Epoch: 60
2022-12-31 06:08:31,420 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47628835737705233, 'Total loss': 0.47628835737705233} | train loss {'Reaction outcome loss': 0.12249132363478855, 'Total loss': 0.12249132363478855}
2022-12-31 06:08:31,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:31,420 INFO:     Epoch: 61
2022-12-31 06:08:33,051 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45633798154691857, 'Total loss': 0.45633798154691857} | train loss {'Reaction outcome loss': 0.12102601117626562, 'Total loss': 0.12102601117626562}
2022-12-31 06:08:33,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:33,052 INFO:     Epoch: 62
2022-12-31 06:08:34,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.467598815759023, 'Total loss': 0.467598815759023} | train loss {'Reaction outcome loss': 0.12106537325897976, 'Total loss': 0.12106537325897976}
2022-12-31 06:08:34,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:34,671 INFO:     Epoch: 63
2022-12-31 06:08:36,322 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47132060130437214, 'Total loss': 0.47132060130437214} | train loss {'Reaction outcome loss': 0.12232578603594658, 'Total loss': 0.12232578603594658}
2022-12-31 06:08:36,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:36,322 INFO:     Epoch: 64
2022-12-31 06:08:37,986 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4540281131863594, 'Total loss': 0.4540281131863594} | train loss {'Reaction outcome loss': 0.12533571312129768, 'Total loss': 0.12533571312129768}
2022-12-31 06:08:37,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:37,986 INFO:     Epoch: 65
2022-12-31 06:08:39,650 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45364451309045156, 'Total loss': 0.45364451309045156} | train loss {'Reaction outcome loss': 0.1255038108042293, 'Total loss': 0.1255038108042293}
2022-12-31 06:08:39,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:39,650 INFO:     Epoch: 66
2022-12-31 06:08:41,314 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44670683244864146, 'Total loss': 0.44670683244864146} | train loss {'Reaction outcome loss': 0.12392616749064578, 'Total loss': 0.12392616749064578}
2022-12-31 06:08:41,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:41,314 INFO:     Epoch: 67
2022-12-31 06:08:42,978 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43859965006510415, 'Total loss': 0.43859965006510415} | train loss {'Reaction outcome loss': 0.11677161537859913, 'Total loss': 0.11677161537859913}
2022-12-31 06:08:42,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:42,978 INFO:     Epoch: 68
2022-12-31 06:08:44,588 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4504558483759562, 'Total loss': 0.4504558483759562} | train loss {'Reaction outcome loss': 0.11830636676977915, 'Total loss': 0.11830636676977915}
2022-12-31 06:08:44,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:44,589 INFO:     Epoch: 69
2022-12-31 06:08:46,216 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4686680227518082, 'Total loss': 0.4686680227518082} | train loss {'Reaction outcome loss': 0.11737369944803767, 'Total loss': 0.11737369944803767}
2022-12-31 06:08:46,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:46,217 INFO:     Epoch: 70
2022-12-31 06:08:47,840 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44777210702498754, 'Total loss': 0.44777210702498754} | train loss {'Reaction outcome loss': 0.11997403162261606, 'Total loss': 0.11997403162261606}
2022-12-31 06:08:47,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:47,841 INFO:     Epoch: 71
2022-12-31 06:08:49,466 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4563564330339432, 'Total loss': 0.4563564330339432} | train loss {'Reaction outcome loss': 0.11914586363886685, 'Total loss': 0.11914586363886685}
2022-12-31 06:08:49,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:49,467 INFO:     Epoch: 72
2022-12-31 06:08:51,093 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44623615344365436, 'Total loss': 0.44623615344365436} | train loss {'Reaction outcome loss': 0.11893367849710479, 'Total loss': 0.11893367849710479}
2022-12-31 06:08:51,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:51,093 INFO:     Epoch: 73
2022-12-31 06:08:52,718 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5011484156052272, 'Total loss': 0.5011484156052272} | train loss {'Reaction outcome loss': 0.11613665255727951, 'Total loss': 0.11613665255727951}
2022-12-31 06:08:52,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:52,719 INFO:     Epoch: 74
2022-12-31 06:08:54,364 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.473951663573583, 'Total loss': 0.473951663573583} | train loss {'Reaction outcome loss': 0.11475919211111234, 'Total loss': 0.11475919211111234}
2022-12-31 06:08:54,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:54,364 INFO:     Epoch: 75
2022-12-31 06:08:55,982 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4630719140172005, 'Total loss': 0.4630719140172005} | train loss {'Reaction outcome loss': 0.11597690949945347, 'Total loss': 0.11597690949945347}
2022-12-31 06:08:55,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:55,982 INFO:     Epoch: 76
2022-12-31 06:08:57,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4847371518611908, 'Total loss': 0.4847371518611908} | train loss {'Reaction outcome loss': 0.11388068818959637, 'Total loss': 0.11388068818959637}
2022-12-31 06:08:57,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:57,599 INFO:     Epoch: 77
2022-12-31 06:08:59,215 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4852420339981715, 'Total loss': 0.4852420339981715} | train loss {'Reaction outcome loss': 0.11948682808661429, 'Total loss': 0.11948682808661429}
2022-12-31 06:08:59,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:08:59,215 INFO:     Epoch: 78
2022-12-31 06:09:00,880 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49444731026887895, 'Total loss': 0.49444731026887895} | train loss {'Reaction outcome loss': 0.11479776073922066, 'Total loss': 0.11479776073922066}
2022-12-31 06:09:00,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:00,880 INFO:     Epoch: 79
2022-12-31 06:09:02,501 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4667093187570572, 'Total loss': 0.4667093187570572} | train loss {'Reaction outcome loss': 0.11467985829481683, 'Total loss': 0.11467985829481683}
2022-12-31 06:09:02,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:02,501 INFO:     Epoch: 80
2022-12-31 06:09:04,133 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49918779333432517, 'Total loss': 0.49918779333432517} | train loss {'Reaction outcome loss': 0.11332575732545144, 'Total loss': 0.11332575732545144}
2022-12-31 06:09:04,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:04,133 INFO:     Epoch: 81
2022-12-31 06:09:05,752 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4684189011653264, 'Total loss': 0.4684189011653264} | train loss {'Reaction outcome loss': 0.1144775102346076, 'Total loss': 0.1144775102346076}
2022-12-31 06:09:05,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:05,753 INFO:     Epoch: 82
2022-12-31 06:09:07,367 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46000383496284486, 'Total loss': 0.46000383496284486} | train loss {'Reaction outcome loss': 0.11415170581161103, 'Total loss': 0.11415170581161103}
2022-12-31 06:09:07,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:07,367 INFO:     Epoch: 83
2022-12-31 06:09:08,984 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43170763850212096, 'Total loss': 0.43170763850212096} | train loss {'Reaction outcome loss': 0.11539287096335708, 'Total loss': 0.11539287096335708}
2022-12-31 06:09:08,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:08,984 INFO:     Epoch: 84
2022-12-31 06:09:10,601 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46045136749744414, 'Total loss': 0.46045136749744414} | train loss {'Reaction outcome loss': 0.11176466093773184, 'Total loss': 0.11176466093773184}
2022-12-31 06:09:10,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:10,602 INFO:     Epoch: 85
2022-12-31 06:09:12,248 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44755971829096475, 'Total loss': 0.44755971829096475} | train loss {'Reaction outcome loss': 0.1147849274895397, 'Total loss': 0.1147849274895397}
2022-12-31 06:09:12,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:12,248 INFO:     Epoch: 86
2022-12-31 06:09:13,869 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4718952278296153, 'Total loss': 0.4718952278296153} | train loss {'Reaction outcome loss': 0.1123687282290674, 'Total loss': 0.1123687282290674}
2022-12-31 06:09:13,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:13,869 INFO:     Epoch: 87
2022-12-31 06:09:15,501 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47534205118815104, 'Total loss': 0.47534205118815104} | train loss {'Reaction outcome loss': 0.11104823020286858, 'Total loss': 0.11104823020286858}
2022-12-31 06:09:15,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:15,501 INFO:     Epoch: 88
2022-12-31 06:09:17,133 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4548502067724864, 'Total loss': 0.4548502067724864} | train loss {'Reaction outcome loss': 0.11270473733547724, 'Total loss': 0.11270473733547724}
2022-12-31 06:09:17,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:17,133 INFO:     Epoch: 89
2022-12-31 06:09:18,762 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46213494340578715, 'Total loss': 0.46213494340578715} | train loss {'Reaction outcome loss': 0.10962537582963705, 'Total loss': 0.10962537582963705}
2022-12-31 06:09:18,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:18,762 INFO:     Epoch: 90
2022-12-31 06:09:20,379 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4518515273928642, 'Total loss': 0.4518515273928642} | train loss {'Reaction outcome loss': 0.10553436119263769, 'Total loss': 0.10553436119263769}
2022-12-31 06:09:20,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:20,380 INFO:     Epoch: 91
2022-12-31 06:09:22,023 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4843880027532578, 'Total loss': 0.4843880027532578} | train loss {'Reaction outcome loss': 0.10871947634344299, 'Total loss': 0.10871947634344299}
2022-12-31 06:09:22,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:22,024 INFO:     Epoch: 92
2022-12-31 06:09:23,652 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4753557821114858, 'Total loss': 0.4753557821114858} | train loss {'Reaction outcome loss': 0.11216759614045799, 'Total loss': 0.11216759614045799}
2022-12-31 06:09:23,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:23,653 INFO:     Epoch: 93
2022-12-31 06:09:25,280 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.488024773200353, 'Total loss': 0.488024773200353} | train loss {'Reaction outcome loss': 0.1108290805473782, 'Total loss': 0.1108290805473782}
2022-12-31 06:09:25,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:25,280 INFO:     Epoch: 94
2022-12-31 06:09:26,908 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4673223584890366, 'Total loss': 0.4673223584890366} | train loss {'Reaction outcome loss': 0.10746867903693835, 'Total loss': 0.10746867903693835}
2022-12-31 06:09:26,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:26,909 INFO:     Epoch: 95
2022-12-31 06:09:28,538 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47695281555255253, 'Total loss': 0.47695281555255253} | train loss {'Reaction outcome loss': 0.10696103990620401, 'Total loss': 0.10696103990620401}
2022-12-31 06:09:28,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:28,539 INFO:     Epoch: 96
2022-12-31 06:09:30,179 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4612425774335861, 'Total loss': 0.4612425774335861} | train loss {'Reaction outcome loss': 0.11210507357601023, 'Total loss': 0.11210507357601023}
2022-12-31 06:09:30,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:30,179 INFO:     Epoch: 97
2022-12-31 06:09:31,801 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47961514194806415, 'Total loss': 0.47961514194806415} | train loss {'Reaction outcome loss': 0.10890616495263479, 'Total loss': 0.10890616495263479}
2022-12-31 06:09:31,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:31,801 INFO:     Epoch: 98
2022-12-31 06:09:33,433 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47470244467258454, 'Total loss': 0.47470244467258454} | train loss {'Reaction outcome loss': 0.11155266505596481, 'Total loss': 0.11155266505596481}
2022-12-31 06:09:33,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:33,433 INFO:     Epoch: 99
2022-12-31 06:09:35,065 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48138413230578103, 'Total loss': 0.48138413230578103} | train loss {'Reaction outcome loss': 0.1113128183262787, 'Total loss': 0.1113128183262787}
2022-12-31 06:09:35,065 INFO:     Best model found after epoch 19 of 100.
2022-12-31 06:09:35,065 INFO:   Done with stage: TRAINING
2022-12-31 06:09:35,065 INFO:   Starting stage: EVALUATION
2022-12-31 06:09:35,196 INFO:   Done with stage: EVALUATION
2022-12-31 06:09:35,196 INFO:   Leaving out SEQ value Fold_6
2022-12-31 06:09:35,209 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 06:09:35,209 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:09:35,853 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:09:35,853 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:09:35,924 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:09:35,924 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:09:35,924 INFO:     No hyperparam tuning for this model
2022-12-31 06:09:35,924 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:09:35,924 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:09:35,925 INFO:     None feature selector for col prot
2022-12-31 06:09:35,925 INFO:     None feature selector for col prot
2022-12-31 06:09:35,925 INFO:     None feature selector for col prot
2022-12-31 06:09:35,925 INFO:     None feature selector for col chem
2022-12-31 06:09:35,925 INFO:     None feature selector for col chem
2022-12-31 06:09:35,926 INFO:     None feature selector for col chem
2022-12-31 06:09:35,926 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:09:35,926 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:09:35,927 INFO:     Number of params in model 224011
2022-12-31 06:09:35,931 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:09:35,931 INFO:   Starting stage: TRAINING
2022-12-31 06:09:35,978 INFO:     Val loss before train {'Reaction outcome loss': 0.9433523297309876, 'Total loss': 0.9433523297309876}
2022-12-31 06:09:35,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:35,978 INFO:     Epoch: 0
2022-12-31 06:09:37,611 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5973206122716268, 'Total loss': 0.5973206122716268} | train loss {'Reaction outcome loss': 0.7729543282882402, 'Total loss': 0.7729543282882402}
2022-12-31 06:09:37,611 INFO:     Found new best model at epoch 0
2022-12-31 06:09:37,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:37,612 INFO:     Epoch: 1
2022-12-31 06:09:39,238 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49753825465838114, 'Total loss': 0.49753825465838114} | train loss {'Reaction outcome loss': 0.5175814900533817, 'Total loss': 0.5175814900533817}
2022-12-31 06:09:39,239 INFO:     Found new best model at epoch 1
2022-12-31 06:09:39,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:39,240 INFO:     Epoch: 2
2022-12-31 06:09:40,892 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4504069109757741, 'Total loss': 0.4504069109757741} | train loss {'Reaction outcome loss': 0.4538030407058633, 'Total loss': 0.4538030407058633}
2022-12-31 06:09:40,892 INFO:     Found new best model at epoch 2
2022-12-31 06:09:40,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:40,894 INFO:     Epoch: 3
2022-12-31 06:09:42,518 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4458088835080465, 'Total loss': 0.4458088835080465} | train loss {'Reaction outcome loss': 0.4140429039509288, 'Total loss': 0.4140429039509288}
2022-12-31 06:09:42,518 INFO:     Found new best model at epoch 3
2022-12-31 06:09:42,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:42,519 INFO:     Epoch: 4
2022-12-31 06:09:44,142 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43680787483851113, 'Total loss': 0.43680787483851113} | train loss {'Reaction outcome loss': 0.38535408966162576, 'Total loss': 0.38535408966162576}
2022-12-31 06:09:44,142 INFO:     Found new best model at epoch 4
2022-12-31 06:09:44,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:44,143 INFO:     Epoch: 5
2022-12-31 06:09:45,766 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43157917161782583, 'Total loss': 0.43157917161782583} | train loss {'Reaction outcome loss': 0.3617357638284618, 'Total loss': 0.3617357638284618}
2022-12-31 06:09:45,766 INFO:     Found new best model at epoch 5
2022-12-31 06:09:45,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:45,767 INFO:     Epoch: 6
2022-12-31 06:09:47,381 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42759042978286743, 'Total loss': 0.42759042978286743} | train loss {'Reaction outcome loss': 0.33776550016463447, 'Total loss': 0.33776550016463447}
2022-12-31 06:09:47,381 INFO:     Found new best model at epoch 6
2022-12-31 06:09:47,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:47,382 INFO:     Epoch: 7
2022-12-31 06:09:49,007 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42212416728337604, 'Total loss': 0.42212416728337604} | train loss {'Reaction outcome loss': 0.32054550805892323, 'Total loss': 0.32054550805892323}
2022-12-31 06:09:49,007 INFO:     Found new best model at epoch 7
2022-12-31 06:09:49,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:49,008 INFO:     Epoch: 8
2022-12-31 06:09:50,632 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.399442246556282, 'Total loss': 0.399442246556282} | train loss {'Reaction outcome loss': 0.3067691211558421, 'Total loss': 0.3067691211558421}
2022-12-31 06:09:50,633 INFO:     Found new best model at epoch 8
2022-12-31 06:09:50,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:50,634 INFO:     Epoch: 9
2022-12-31 06:09:52,258 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4294521639744441, 'Total loss': 0.4294521639744441} | train loss {'Reaction outcome loss': 0.2890120258332913, 'Total loss': 0.2890120258332913}
2022-12-31 06:09:52,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:52,258 INFO:     Epoch: 10
2022-12-31 06:09:53,929 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4327010601758957, 'Total loss': 0.4327010601758957} | train loss {'Reaction outcome loss': 0.2801282159876522, 'Total loss': 0.2801282159876522}
2022-12-31 06:09:53,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:53,929 INFO:     Epoch: 11
2022-12-31 06:09:55,552 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40366303486128646, 'Total loss': 0.40366303486128646} | train loss {'Reaction outcome loss': 0.274471140227916, 'Total loss': 0.274471140227916}
2022-12-31 06:09:55,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:55,553 INFO:     Epoch: 12
2022-12-31 06:09:57,179 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4200180242458979, 'Total loss': 0.4200180242458979} | train loss {'Reaction outcome loss': 0.2606607025980089, 'Total loss': 0.2606607025980089}
2022-12-31 06:09:57,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:57,180 INFO:     Epoch: 13
2022-12-31 06:09:58,799 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4466957052548726, 'Total loss': 0.4466957052548726} | train loss {'Reaction outcome loss': 0.25104185008185004, 'Total loss': 0.25104185008185004}
2022-12-31 06:09:58,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:09:58,799 INFO:     Epoch: 14
2022-12-31 06:10:00,469 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4218559876084328, 'Total loss': 0.4218559876084328} | train loss {'Reaction outcome loss': 0.24418754153464675, 'Total loss': 0.24418754153464675}
2022-12-31 06:10:00,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:00,469 INFO:     Epoch: 15
2022-12-31 06:10:02,095 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4260817686716715, 'Total loss': 0.4260817686716715} | train loss {'Reaction outcome loss': 0.23656954426681523, 'Total loss': 0.23656954426681523}
2022-12-31 06:10:02,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:02,095 INFO:     Epoch: 16
2022-12-31 06:10:03,714 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4707052479187647, 'Total loss': 0.4707052479187647} | train loss {'Reaction outcome loss': 0.22893870198285537, 'Total loss': 0.22893870198285537}
2022-12-31 06:10:03,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:03,714 INFO:     Epoch: 17
2022-12-31 06:10:05,339 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4267652998367945, 'Total loss': 0.4267652998367945} | train loss {'Reaction outcome loss': 0.22276181339652745, 'Total loss': 0.22276181339652745}
2022-12-31 06:10:05,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:05,339 INFO:     Epoch: 18
2022-12-31 06:10:06,966 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46269014378388723, 'Total loss': 0.46269014378388723} | train loss {'Reaction outcome loss': 0.21909920438209596, 'Total loss': 0.21909920438209596}
2022-12-31 06:10:06,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:06,966 INFO:     Epoch: 19
2022-12-31 06:10:08,595 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45576203962167106, 'Total loss': 0.45576203962167106} | train loss {'Reaction outcome loss': 0.21164684931643388, 'Total loss': 0.21164684931643388}
2022-12-31 06:10:08,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:08,595 INFO:     Epoch: 20
2022-12-31 06:10:10,265 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4456023693084717, 'Total loss': 0.4456023693084717} | train loss {'Reaction outcome loss': 0.20982320036483584, 'Total loss': 0.20982320036483584}
2022-12-31 06:10:10,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:10,265 INFO:     Epoch: 21
2022-12-31 06:10:11,934 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4706017275651296, 'Total loss': 0.4706017275651296} | train loss {'Reaction outcome loss': 0.20213286212178128, 'Total loss': 0.20213286212178128}
2022-12-31 06:10:11,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:11,934 INFO:     Epoch: 22
2022-12-31 06:10:13,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4388811528682709, 'Total loss': 0.4388811528682709} | train loss {'Reaction outcome loss': 0.1991306002712422, 'Total loss': 0.1991306002712422}
2022-12-31 06:10:13,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:13,605 INFO:     Epoch: 23
2022-12-31 06:10:15,229 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4668659657239914, 'Total loss': 0.4668659657239914} | train loss {'Reaction outcome loss': 0.19446238524377993, 'Total loss': 0.19446238524377993}
2022-12-31 06:10:15,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:15,229 INFO:     Epoch: 24
2022-12-31 06:10:16,869 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4241470843553543, 'Total loss': 0.4241470843553543} | train loss {'Reaction outcome loss': 0.190897541228238, 'Total loss': 0.190897541228238}
2022-12-31 06:10:16,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:16,870 INFO:     Epoch: 25
2022-12-31 06:10:18,508 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4488152970870336, 'Total loss': 0.4488152970870336} | train loss {'Reaction outcome loss': 0.1877723041827713, 'Total loss': 0.1877723041827713}
2022-12-31 06:10:18,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:18,508 INFO:     Epoch: 26
2022-12-31 06:10:20,145 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4582401245832443, 'Total loss': 0.4582401245832443} | train loss {'Reaction outcome loss': 0.18639494125001696, 'Total loss': 0.18639494125001696}
2022-12-31 06:10:20,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:20,145 INFO:     Epoch: 27
2022-12-31 06:10:21,784 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43419559200604757, 'Total loss': 0.43419559200604757} | train loss {'Reaction outcome loss': 0.18323572431203475, 'Total loss': 0.18323572431203475}
2022-12-31 06:10:21,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:21,784 INFO:     Epoch: 28
2022-12-31 06:10:23,420 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4610754986604055, 'Total loss': 0.4610754986604055} | train loss {'Reaction outcome loss': 0.1765771589245284, 'Total loss': 0.1765771589245284}
2022-12-31 06:10:23,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:23,420 INFO:     Epoch: 29
2022-12-31 06:10:25,046 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4869057943423589, 'Total loss': 0.4869057943423589} | train loss {'Reaction outcome loss': 0.17671481242894266, 'Total loss': 0.17671481242894266}
2022-12-31 06:10:25,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:25,046 INFO:     Epoch: 30
2022-12-31 06:10:26,676 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47160168886184695, 'Total loss': 0.47160168886184695} | train loss {'Reaction outcome loss': 0.16937891765756513, 'Total loss': 0.16937891765756513}
2022-12-31 06:10:26,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:26,676 INFO:     Epoch: 31
2022-12-31 06:10:28,314 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4585440536340078, 'Total loss': 0.4585440536340078} | train loss {'Reaction outcome loss': 0.16703036301752505, 'Total loss': 0.16703036301752505}
2022-12-31 06:10:28,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:28,315 INFO:     Epoch: 32
2022-12-31 06:10:29,954 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4481396049261093, 'Total loss': 0.4481396049261093} | train loss {'Reaction outcome loss': 0.16545374315595154, 'Total loss': 0.16545374315595154}
2022-12-31 06:10:29,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:29,954 INFO:     Epoch: 33
2022-12-31 06:10:31,593 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.450622895359993, 'Total loss': 0.450622895359993} | train loss {'Reaction outcome loss': 0.16128692828414673, 'Total loss': 0.16128692828414673}
2022-12-31 06:10:31,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:31,594 INFO:     Epoch: 34
2022-12-31 06:10:33,222 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46768093208471934, 'Total loss': 0.46768093208471934} | train loss {'Reaction outcome loss': 0.15786868159319628, 'Total loss': 0.15786868159319628}
2022-12-31 06:10:33,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:33,223 INFO:     Epoch: 35
2022-12-31 06:10:34,861 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4625309656063716, 'Total loss': 0.4625309656063716} | train loss {'Reaction outcome loss': 0.15606481798786656, 'Total loss': 0.15606481798786656}
2022-12-31 06:10:34,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:34,862 INFO:     Epoch: 36
2022-12-31 06:10:36,487 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4536318769057592, 'Total loss': 0.4536318769057592} | train loss {'Reaction outcome loss': 0.15388853905809916, 'Total loss': 0.15388853905809916}
2022-12-31 06:10:36,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:36,487 INFO:     Epoch: 37
2022-12-31 06:10:38,156 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4792659322420756, 'Total loss': 0.4792659322420756} | train loss {'Reaction outcome loss': 0.15215695660144413, 'Total loss': 0.15215695660144413}
2022-12-31 06:10:38,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:38,157 INFO:     Epoch: 38
2022-12-31 06:10:39,780 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44645647406578065, 'Total loss': 0.44645647406578065} | train loss {'Reaction outcome loss': 0.14975236534453687, 'Total loss': 0.14975236534453687}
2022-12-31 06:10:39,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:39,781 INFO:     Epoch: 39
2022-12-31 06:10:41,450 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4627199500799179, 'Total loss': 0.4627199500799179} | train loss {'Reaction outcome loss': 0.1511239897432848, 'Total loss': 0.1511239897432848}
2022-12-31 06:10:41,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:41,450 INFO:     Epoch: 40
2022-12-31 06:10:43,064 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5178488671779633, 'Total loss': 0.5178488671779633} | train loss {'Reaction outcome loss': 0.1521354294634199, 'Total loss': 0.1521354294634199}
2022-12-31 06:10:43,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:43,064 INFO:     Epoch: 41
2022-12-31 06:10:44,691 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4781305442253749, 'Total loss': 0.4781305442253749} | train loss {'Reaction outcome loss': 0.14683912211982028, 'Total loss': 0.14683912211982028}
2022-12-31 06:10:44,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:44,691 INFO:     Epoch: 42
2022-12-31 06:10:46,357 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.465042112270991, 'Total loss': 0.465042112270991} | train loss {'Reaction outcome loss': 0.14333569643084323, 'Total loss': 0.14333569643084323}
2022-12-31 06:10:46,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:46,357 INFO:     Epoch: 43
2022-12-31 06:10:48,027 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5091483116149902, 'Total loss': 0.5091483116149902} | train loss {'Reaction outcome loss': 0.14402514098662655, 'Total loss': 0.14402514098662655}
2022-12-31 06:10:48,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:48,028 INFO:     Epoch: 44
2022-12-31 06:10:49,649 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4765999009211858, 'Total loss': 0.4765999009211858} | train loss {'Reaction outcome loss': 0.1413577701896429, 'Total loss': 0.1413577701896429}
2022-12-31 06:10:49,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:49,649 INFO:     Epoch: 45
2022-12-31 06:10:51,307 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4789808968702952, 'Total loss': 0.4789808968702952} | train loss {'Reaction outcome loss': 0.14069623591896105, 'Total loss': 0.14069623591896105}
2022-12-31 06:10:51,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:51,308 INFO:     Epoch: 46
2022-12-31 06:10:52,960 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48920424034198123, 'Total loss': 0.48920424034198123} | train loss {'Reaction outcome loss': 0.1380634837168595, 'Total loss': 0.1380634837168595}
2022-12-31 06:10:52,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:52,961 INFO:     Epoch: 47
2022-12-31 06:10:54,580 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4744755188624064, 'Total loss': 0.4744755188624064} | train loss {'Reaction outcome loss': 0.13962458912955616, 'Total loss': 0.13962458912955616}
2022-12-31 06:10:54,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:54,581 INFO:     Epoch: 48
2022-12-31 06:10:56,250 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47941860953966775, 'Total loss': 0.47941860953966775} | train loss {'Reaction outcome loss': 0.13526774488981236, 'Total loss': 0.13526774488981236}
2022-12-31 06:10:56,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:56,251 INFO:     Epoch: 49
2022-12-31 06:10:57,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4727586567401886, 'Total loss': 0.4727586567401886} | train loss {'Reaction outcome loss': 0.13778961545683524, 'Total loss': 0.13778961545683524}
2022-12-31 06:10:57,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:57,921 INFO:     Epoch: 50
2022-12-31 06:10:59,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4655019730329514, 'Total loss': 0.4655019730329514} | train loss {'Reaction outcome loss': 0.13370047018792655, 'Total loss': 0.13370047018792655}
2022-12-31 06:10:59,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:10:59,592 INFO:     Epoch: 51
2022-12-31 06:11:01,215 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5063598453998566, 'Total loss': 0.5063598453998566} | train loss {'Reaction outcome loss': 0.13363578909544094, 'Total loss': 0.13363578909544094}
2022-12-31 06:11:01,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:01,215 INFO:     Epoch: 52
2022-12-31 06:11:02,874 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4826586902141571, 'Total loss': 0.4826586902141571} | train loss {'Reaction outcome loss': 0.13174382008491117, 'Total loss': 0.13174382008491117}
2022-12-31 06:11:02,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:02,874 INFO:     Epoch: 53
2022-12-31 06:11:04,494 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4620746632417043, 'Total loss': 0.4620746632417043} | train loss {'Reaction outcome loss': 0.13078436782307895, 'Total loss': 0.13078436782307895}
2022-12-31 06:11:04,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:04,495 INFO:     Epoch: 54
2022-12-31 06:11:06,114 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.458535229600966, 'Total loss': 0.458535229600966} | train loss {'Reaction outcome loss': 0.13159506148507394, 'Total loss': 0.13159506148507394}
2022-12-31 06:11:06,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:06,114 INFO:     Epoch: 55
2022-12-31 06:11:07,784 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46852814356486, 'Total loss': 0.46852814356486} | train loss {'Reaction outcome loss': 0.131386754967084, 'Total loss': 0.131386754967084}
2022-12-31 06:11:07,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:07,784 INFO:     Epoch: 56
2022-12-31 06:11:09,406 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.476291298866272, 'Total loss': 0.476291298866272} | train loss {'Reaction outcome loss': 0.13036099407781548, 'Total loss': 0.13036099407781548}
2022-12-31 06:11:09,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:09,406 INFO:     Epoch: 57
2022-12-31 06:11:11,024 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46897870898246763, 'Total loss': 0.46897870898246763} | train loss {'Reaction outcome loss': 0.1291594181868789, 'Total loss': 0.1291594181868789}
2022-12-31 06:11:11,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:11,025 INFO:     Epoch: 58
2022-12-31 06:11:12,650 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4881291011969248, 'Total loss': 0.4881291011969248} | train loss {'Reaction outcome loss': 0.12457001513535904, 'Total loss': 0.12457001513535904}
2022-12-31 06:11:12,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:12,650 INFO:     Epoch: 59
2022-12-31 06:11:14,319 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.512191625436147, 'Total loss': 0.512191625436147} | train loss {'Reaction outcome loss': 0.1281711890358841, 'Total loss': 0.1281711890358841}
2022-12-31 06:11:14,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:14,319 INFO:     Epoch: 60
2022-12-31 06:11:15,989 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.453593435883522, 'Total loss': 0.453593435883522} | train loss {'Reaction outcome loss': 0.12511353876226539, 'Total loss': 0.12511353876226539}
2022-12-31 06:11:15,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:15,990 INFO:     Epoch: 61
2022-12-31 06:11:17,617 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4707326869169871, 'Total loss': 0.4707326869169871} | train loss {'Reaction outcome loss': 0.12620935838884717, 'Total loss': 0.12620935838884717}
2022-12-31 06:11:17,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:17,617 INFO:     Epoch: 62
2022-12-31 06:11:19,273 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48104275862375895, 'Total loss': 0.48104275862375895} | train loss {'Reaction outcome loss': 0.12444585562929081, 'Total loss': 0.12444585562929081}
2022-12-31 06:11:19,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:19,274 INFO:     Epoch: 63
2022-12-31 06:11:20,914 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4498808551579714, 'Total loss': 0.4498808551579714} | train loss {'Reaction outcome loss': 0.12118009754392699, 'Total loss': 0.12118009754392699}
2022-12-31 06:11:20,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:20,914 INFO:     Epoch: 64
2022-12-31 06:11:22,552 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49256730178991953, 'Total loss': 0.49256730178991953} | train loss {'Reaction outcome loss': 0.12374276707254835, 'Total loss': 0.12374276707254835}
2022-12-31 06:11:22,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:22,552 INFO:     Epoch: 65
2022-12-31 06:11:24,190 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4649031817913055, 'Total loss': 0.4649031817913055} | train loss {'Reaction outcome loss': 0.1290712704065017, 'Total loss': 0.1290712704065017}
2022-12-31 06:11:24,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:24,191 INFO:     Epoch: 66
2022-12-31 06:11:25,828 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4568992376327515, 'Total loss': 0.4568992376327515} | train loss {'Reaction outcome loss': 0.12363131497969804, 'Total loss': 0.12363131497969804}
2022-12-31 06:11:25,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:25,829 INFO:     Epoch: 67
2022-12-31 06:11:27,465 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45981301764647164, 'Total loss': 0.45981301764647164} | train loss {'Reaction outcome loss': 0.1232610250443274, 'Total loss': 0.1232610250443274}
2022-12-31 06:11:27,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:27,466 INFO:     Epoch: 68
2022-12-31 06:11:29,086 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4700937221447627, 'Total loss': 0.4700937221447627} | train loss {'Reaction outcome loss': 0.12021800944336189, 'Total loss': 0.12021800944336189}
2022-12-31 06:11:29,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:29,086 INFO:     Epoch: 69
2022-12-31 06:11:30,746 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45856554210186007, 'Total loss': 0.45856554210186007} | train loss {'Reaction outcome loss': 0.12498242323142258, 'Total loss': 0.12498242323142258}
2022-12-31 06:11:30,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:30,746 INFO:     Epoch: 70
2022-12-31 06:11:32,365 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45712478856245675, 'Total loss': 0.45712478856245675} | train loss {'Reaction outcome loss': 0.12647699792987066, 'Total loss': 0.12647699792987066}
2022-12-31 06:11:32,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:32,365 INFO:     Epoch: 71
2022-12-31 06:11:33,991 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.481203293800354, 'Total loss': 0.481203293800354} | train loss {'Reaction outcome loss': 0.12154155839839782, 'Total loss': 0.12154155839839782}
2022-12-31 06:11:33,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:33,991 INFO:     Epoch: 72
2022-12-31 06:11:35,616 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4651687810818354, 'Total loss': 0.4651687810818354} | train loss {'Reaction outcome loss': 0.11735877250775104, 'Total loss': 0.11735877250775104}
2022-12-31 06:11:35,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:35,616 INFO:     Epoch: 73
2022-12-31 06:11:37,230 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4662929266691208, 'Total loss': 0.4662929266691208} | train loss {'Reaction outcome loss': 0.11780934338710046, 'Total loss': 0.11780934338710046}
2022-12-31 06:11:37,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:37,230 INFO:     Epoch: 74
2022-12-31 06:11:38,858 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45325025568405786, 'Total loss': 0.45325025568405786} | train loss {'Reaction outcome loss': 0.11829244158741772, 'Total loss': 0.11829244158741772}
2022-12-31 06:11:38,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:38,859 INFO:     Epoch: 75
2022-12-31 06:11:40,480 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4998795280853907, 'Total loss': 0.4998795280853907} | train loss {'Reaction outcome loss': 0.11597817988951929, 'Total loss': 0.11597817988951929}
2022-12-31 06:11:40,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:40,480 INFO:     Epoch: 76
2022-12-31 06:11:42,104 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4851971725622813, 'Total loss': 0.4851971725622813} | train loss {'Reaction outcome loss': 0.11991587225919327, 'Total loss': 0.11991587225919327}
2022-12-31 06:11:42,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:42,104 INFO:     Epoch: 77
2022-12-31 06:11:43,729 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.467452809214592, 'Total loss': 0.467452809214592} | train loss {'Reaction outcome loss': 0.11959022145788942, 'Total loss': 0.11959022145788942}
2022-12-31 06:11:43,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:43,729 INFO:     Epoch: 78
2022-12-31 06:11:45,359 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5167318269610405, 'Total loss': 0.5167318269610405} | train loss {'Reaction outcome loss': 0.11608636672087418, 'Total loss': 0.11608636672087418}
2022-12-31 06:11:45,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:45,360 INFO:     Epoch: 79
2022-12-31 06:11:46,985 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5069630006949107, 'Total loss': 0.5069630006949107} | train loss {'Reaction outcome loss': 0.11927359901193785, 'Total loss': 0.11927359901193785}
2022-12-31 06:11:46,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:46,986 INFO:     Epoch: 80
2022-12-31 06:11:48,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5005980352560679, 'Total loss': 0.5005980352560679} | train loss {'Reaction outcome loss': 0.11617057851182855, 'Total loss': 0.11617057851182855}
2022-12-31 06:11:48,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:48,621 INFO:     Epoch: 81
2022-12-31 06:11:50,253 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4570681840181351, 'Total loss': 0.4570681840181351} | train loss {'Reaction outcome loss': 0.11438320540496912, 'Total loss': 0.11438320540496912}
2022-12-31 06:11:50,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:50,253 INFO:     Epoch: 82
2022-12-31 06:11:51,924 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5008592466513316, 'Total loss': 0.5008592466513316} | train loss {'Reaction outcome loss': 0.11473907456339912, 'Total loss': 0.11473907456339912}
2022-12-31 06:11:51,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:51,925 INFO:     Epoch: 83
2022-12-31 06:11:53,596 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47849167585372926, 'Total loss': 0.47849167585372926} | train loss {'Reaction outcome loss': 0.11498928257845853, 'Total loss': 0.11498928257845853}
2022-12-31 06:11:53,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:53,597 INFO:     Epoch: 84
2022-12-31 06:11:55,225 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44175720810890196, 'Total loss': 0.44175720810890196} | train loss {'Reaction outcome loss': 0.11652572419400249, 'Total loss': 0.11652572419400249}
2022-12-31 06:11:55,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:55,225 INFO:     Epoch: 85
2022-12-31 06:11:56,845 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44266995787620544, 'Total loss': 0.44266995787620544} | train loss {'Reaction outcome loss': 0.11507090615505346, 'Total loss': 0.11507090615505346}
2022-12-31 06:11:56,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:56,845 INFO:     Epoch: 86
2022-12-31 06:11:58,480 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48220026940107347, 'Total loss': 0.48220026940107347} | train loss {'Reaction outcome loss': 0.11294394494152026, 'Total loss': 0.11294394494152026}
2022-12-31 06:11:58,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:11:58,481 INFO:     Epoch: 87
2022-12-31 06:12:00,115 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45920673410097756, 'Total loss': 0.45920673410097756} | train loss {'Reaction outcome loss': 0.12048870104193579, 'Total loss': 0.12048870104193579}
2022-12-31 06:12:00,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:00,115 INFO:     Epoch: 88
2022-12-31 06:12:01,747 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4387826591730118, 'Total loss': 0.4387826591730118} | train loss {'Reaction outcome loss': 0.12065811152990222, 'Total loss': 0.12065811152990222}
2022-12-31 06:12:01,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:01,747 INFO:     Epoch: 89
2022-12-31 06:12:03,380 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47384501496950787, 'Total loss': 0.47384501496950787} | train loss {'Reaction outcome loss': 0.11661252123555875, 'Total loss': 0.11661252123555875}
2022-12-31 06:12:03,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:03,380 INFO:     Epoch: 90
2022-12-31 06:12:05,005 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47450993458429974, 'Total loss': 0.47450993458429974} | train loss {'Reaction outcome loss': 0.11010952710614469, 'Total loss': 0.11010952710614469}
2022-12-31 06:12:05,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:05,006 INFO:     Epoch: 91
2022-12-31 06:12:06,640 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4588247835636139, 'Total loss': 0.4588247835636139} | train loss {'Reaction outcome loss': 0.11139851475356395, 'Total loss': 0.11139851475356395}
2022-12-31 06:12:06,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:06,640 INFO:     Epoch: 92
2022-12-31 06:12:08,366 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48290694057941436, 'Total loss': 0.48290694057941436} | train loss {'Reaction outcome loss': 0.1114396797375424, 'Total loss': 0.1114396797375424}
2022-12-31 06:12:08,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:08,366 INFO:     Epoch: 93
2022-12-31 06:12:09,991 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5023025929927826, 'Total loss': 0.5023025929927826} | train loss {'Reaction outcome loss': 0.11021090259385508, 'Total loss': 0.11021090259385508}
2022-12-31 06:12:09,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:09,992 INFO:     Epoch: 94
2022-12-31 06:12:11,617 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4688962481915951, 'Total loss': 0.4688962481915951} | train loss {'Reaction outcome loss': 0.11516564593075469, 'Total loss': 0.11516564593075469}
2022-12-31 06:12:11,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:11,618 INFO:     Epoch: 95
2022-12-31 06:12:13,242 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4588325853149096, 'Total loss': 0.4588325853149096} | train loss {'Reaction outcome loss': 0.11548280515304568, 'Total loss': 0.11548280515304568}
2022-12-31 06:12:13,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:13,243 INFO:     Epoch: 96
2022-12-31 06:12:14,865 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5133277157942454, 'Total loss': 0.5133277157942454} | train loss {'Reaction outcome loss': 0.11861943730761697, 'Total loss': 0.11861943730761697}
2022-12-31 06:12:14,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:14,866 INFO:     Epoch: 97
2022-12-31 06:12:16,492 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4734516193469365, 'Total loss': 0.4734516193469365} | train loss {'Reaction outcome loss': 0.11684993485035879, 'Total loss': 0.11684993485035879}
2022-12-31 06:12:16,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:16,492 INFO:     Epoch: 98
2022-12-31 06:12:18,119 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4674070586760839, 'Total loss': 0.4674070586760839} | train loss {'Reaction outcome loss': 0.10781992508085034, 'Total loss': 0.10781992508085034}
2022-12-31 06:12:18,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:18,119 INFO:     Epoch: 99
2022-12-31 06:12:19,742 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4682976866761843, 'Total loss': 0.4682976866761843} | train loss {'Reaction outcome loss': 0.10854072386183733, 'Total loss': 0.10854072386183733}
2022-12-31 06:12:19,743 INFO:     Best model found after epoch 9 of 100.
2022-12-31 06:12:19,743 INFO:   Done with stage: TRAINING
2022-12-31 06:12:19,743 INFO:   Starting stage: EVALUATION
2022-12-31 06:12:19,866 INFO:   Done with stage: EVALUATION
2022-12-31 06:12:19,867 INFO:   Leaving out SEQ value Fold_7
2022-12-31 06:12:19,879 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 06:12:19,879 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:12:20,523 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:12:20,523 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:12:20,594 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:12:20,595 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:12:20,595 INFO:     No hyperparam tuning for this model
2022-12-31 06:12:20,595 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:12:20,595 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:12:20,595 INFO:     None feature selector for col prot
2022-12-31 06:12:20,596 INFO:     None feature selector for col prot
2022-12-31 06:12:20,596 INFO:     None feature selector for col prot
2022-12-31 06:12:20,596 INFO:     None feature selector for col chem
2022-12-31 06:12:20,596 INFO:     None feature selector for col chem
2022-12-31 06:12:20,596 INFO:     None feature selector for col chem
2022-12-31 06:12:20,596 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:12:20,597 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:12:20,598 INFO:     Number of params in model 224011
2022-12-31 06:12:20,602 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:12:20,602 INFO:   Starting stage: TRAINING
2022-12-31 06:12:20,646 INFO:     Val loss before train {'Reaction outcome loss': 1.0252731561660766, 'Total loss': 1.0252731561660766}
2022-12-31 06:12:20,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:20,646 INFO:     Epoch: 0
2022-12-31 06:12:22,260 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6127213974793752, 'Total loss': 0.6127213974793752} | train loss {'Reaction outcome loss': 0.7801859451975633, 'Total loss': 0.7801859451975633}
2022-12-31 06:12:22,261 INFO:     Found new best model at epoch 0
2022-12-31 06:12:22,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:22,262 INFO:     Epoch: 1
2022-12-31 06:12:23,910 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5406073172887166, 'Total loss': 0.5406073172887166} | train loss {'Reaction outcome loss': 0.5088780157617714, 'Total loss': 0.5088780157617714}
2022-12-31 06:12:23,910 INFO:     Found new best model at epoch 1
2022-12-31 06:12:23,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:23,911 INFO:     Epoch: 2
2022-12-31 06:12:25,535 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.517869986097018, 'Total loss': 0.517869986097018} | train loss {'Reaction outcome loss': 0.442080752029746, 'Total loss': 0.442080752029746}
2022-12-31 06:12:25,536 INFO:     Found new best model at epoch 2
2022-12-31 06:12:25,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:25,537 INFO:     Epoch: 3
2022-12-31 06:12:27,159 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49987077713012695, 'Total loss': 0.49987077713012695} | train loss {'Reaction outcome loss': 0.4016777888101791, 'Total loss': 0.4016777888101791}
2022-12-31 06:12:27,160 INFO:     Found new best model at epoch 3
2022-12-31 06:12:27,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:27,161 INFO:     Epoch: 4
2022-12-31 06:12:28,785 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5163841406504314, 'Total loss': 0.5163841406504314} | train loss {'Reaction outcome loss': 0.3700107217157791, 'Total loss': 0.3700107217157791}
2022-12-31 06:12:28,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:28,785 INFO:     Epoch: 5
2022-12-31 06:12:30,407 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.484798926115036, 'Total loss': 0.484798926115036} | train loss {'Reaction outcome loss': 0.34358282231251686, 'Total loss': 0.34358282231251686}
2022-12-31 06:12:30,408 INFO:     Found new best model at epoch 5
2022-12-31 06:12:30,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:30,409 INFO:     Epoch: 6
2022-12-31 06:12:32,033 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4901895562807719, 'Total loss': 0.4901895562807719} | train loss {'Reaction outcome loss': 0.32506371138866197, 'Total loss': 0.32506371138866197}
2022-12-31 06:12:32,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:32,033 INFO:     Epoch: 7
2022-12-31 06:12:33,684 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5038568178812662, 'Total loss': 0.5038568178812662} | train loss {'Reaction outcome loss': 0.3063004747275196, 'Total loss': 0.3063004747275196}
2022-12-31 06:12:33,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:33,684 INFO:     Epoch: 8
2022-12-31 06:12:35,309 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5008979757626851, 'Total loss': 0.5008979757626851} | train loss {'Reaction outcome loss': 0.2897934417109197, 'Total loss': 0.2897934417109197}
2022-12-31 06:12:35,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:35,310 INFO:     Epoch: 9
2022-12-31 06:12:36,934 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47391184866428376, 'Total loss': 0.47391184866428376} | train loss {'Reaction outcome loss': 0.2785839872562498, 'Total loss': 0.2785839872562498}
2022-12-31 06:12:36,935 INFO:     Found new best model at epoch 9
2022-12-31 06:12:36,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:36,936 INFO:     Epoch: 10
2022-12-31 06:12:38,559 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4668916940689087, 'Total loss': 0.4668916940689087} | train loss {'Reaction outcome loss': 0.2668877234514332, 'Total loss': 0.2668877234514332}
2022-12-31 06:12:38,559 INFO:     Found new best model at epoch 10
2022-12-31 06:12:38,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:38,560 INFO:     Epoch: 11
2022-12-31 06:12:40,182 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4808494448661804, 'Total loss': 0.4808494448661804} | train loss {'Reaction outcome loss': 0.2566632329072763, 'Total loss': 0.2566632329072763}
2022-12-31 06:12:40,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:40,182 INFO:     Epoch: 12
2022-12-31 06:12:41,796 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48213955760002136, 'Total loss': 0.48213955760002136} | train loss {'Reaction outcome loss': 0.24517563247669905, 'Total loss': 0.24517563247669905}
2022-12-31 06:12:41,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:41,796 INFO:     Epoch: 13
2022-12-31 06:12:43,420 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4859588702519735, 'Total loss': 0.4859588702519735} | train loss {'Reaction outcome loss': 0.23817260462508305, 'Total loss': 0.23817260462508305}
2022-12-31 06:12:43,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:43,420 INFO:     Epoch: 14
2022-12-31 06:12:45,045 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4816749821106593, 'Total loss': 0.4816749821106593} | train loss {'Reaction outcome loss': 0.2267857182649929, 'Total loss': 0.2267857182649929}
2022-12-31 06:12:45,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:45,045 INFO:     Epoch: 15
2022-12-31 06:12:46,670 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48688710331916807, 'Total loss': 0.48688710331916807} | train loss {'Reaction outcome loss': 0.22401555723070238, 'Total loss': 0.22401555723070238}
2022-12-31 06:12:46,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:46,671 INFO:     Epoch: 16
2022-12-31 06:12:48,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5007111628850301, 'Total loss': 0.5007111628850301} | train loss {'Reaction outcome loss': 0.21591835222896255, 'Total loss': 0.21591835222896255}
2022-12-31 06:12:48,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:48,297 INFO:     Epoch: 17
2022-12-31 06:12:49,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4944012070695559, 'Total loss': 0.4944012070695559} | train loss {'Reaction outcome loss': 0.21136864403847752, 'Total loss': 0.21136864403847752}
2022-12-31 06:12:49,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:49,927 INFO:     Epoch: 18
2022-12-31 06:12:51,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48408127824465436, 'Total loss': 0.48408127824465436} | train loss {'Reaction outcome loss': 0.20364891514451064, 'Total loss': 0.20364891514451064}
2022-12-31 06:12:51,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:51,568 INFO:     Epoch: 19
2022-12-31 06:12:53,206 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5170854618151982, 'Total loss': 0.5170854618151982} | train loss {'Reaction outcome loss': 0.19526537488944265, 'Total loss': 0.19526537488944265}
2022-12-31 06:12:53,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:53,206 INFO:     Epoch: 20
2022-12-31 06:12:54,845 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4857287844022115, 'Total loss': 0.4857287844022115} | train loss {'Reaction outcome loss': 0.19491455443405178, 'Total loss': 0.19491455443405178}
2022-12-31 06:12:54,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:54,845 INFO:     Epoch: 21
2022-12-31 06:12:56,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45995263854662577, 'Total loss': 0.45995263854662577} | train loss {'Reaction outcome loss': 0.1919492913362997, 'Total loss': 0.1919492913362997}
2022-12-31 06:12:56,485 INFO:     Found new best model at epoch 21
2022-12-31 06:12:56,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:56,486 INFO:     Epoch: 22
2022-12-31 06:12:58,123 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5071948081254959, 'Total loss': 0.5071948081254959} | train loss {'Reaction outcome loss': 0.18415789061061205, 'Total loss': 0.18415789061061205}
2022-12-31 06:12:58,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:58,124 INFO:     Epoch: 23
2022-12-31 06:12:59,743 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5070035914580028, 'Total loss': 0.5070035914580028} | train loss {'Reaction outcome loss': 0.18069450008524884, 'Total loss': 0.18069450008524884}
2022-12-31 06:12:59,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:12:59,743 INFO:     Epoch: 24
2022-12-31 06:13:01,369 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5087325970331827, 'Total loss': 0.5087325970331827} | train loss {'Reaction outcome loss': 0.17546700284436398, 'Total loss': 0.17546700284436398}
2022-12-31 06:13:01,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:01,369 INFO:     Epoch: 25
2022-12-31 06:13:02,994 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49253675440947214, 'Total loss': 0.49253675440947214} | train loss {'Reaction outcome loss': 0.17850438939467986, 'Total loss': 0.17850438939467986}
2022-12-31 06:13:02,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:02,994 INFO:     Epoch: 26
2022-12-31 06:13:04,619 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5053110336263974, 'Total loss': 0.5053110336263974} | train loss {'Reaction outcome loss': 0.1700421386341218, 'Total loss': 0.1700421386341218}
2022-12-31 06:13:04,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:04,619 INFO:     Epoch: 27
2022-12-31 06:13:06,244 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48498063286145526, 'Total loss': 0.48498063286145526} | train loss {'Reaction outcome loss': 0.16999863971710635, 'Total loss': 0.16999863971710635}
2022-12-31 06:13:06,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:06,244 INFO:     Epoch: 28
2022-12-31 06:13:07,868 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5121449947357177, 'Total loss': 0.5121449947357177} | train loss {'Reaction outcome loss': 0.1644629077104993, 'Total loss': 0.1644629077104993}
2022-12-31 06:13:07,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:07,868 INFO:     Epoch: 29
2022-12-31 06:13:09,496 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5135158479213715, 'Total loss': 0.5135158479213715} | train loss {'Reaction outcome loss': 0.1651725163851404, 'Total loss': 0.1651725163851404}
2022-12-31 06:13:09,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:09,496 INFO:     Epoch: 30
2022-12-31 06:13:11,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5643953839937846, 'Total loss': 0.5643953839937846} | train loss {'Reaction outcome loss': 0.16003149033386246, 'Total loss': 0.16003149033386246}
2022-12-31 06:13:11,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:11,130 INFO:     Epoch: 31
2022-12-31 06:13:12,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.504835573832194, 'Total loss': 0.504835573832194} | train loss {'Reaction outcome loss': 0.15855672457238612, 'Total loss': 0.15855672457238612}
2022-12-31 06:13:12,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:12,767 INFO:     Epoch: 32
2022-12-31 06:13:14,403 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5356908301512401, 'Total loss': 0.5356908301512401} | train loss {'Reaction outcome loss': 0.15526182338635736, 'Total loss': 0.15526182338635736}
2022-12-31 06:13:14,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:14,404 INFO:     Epoch: 33
2022-12-31 06:13:16,040 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5289311746756236, 'Total loss': 0.5289311746756236} | train loss {'Reaction outcome loss': 0.15215617702056786, 'Total loss': 0.15215617702056786}
2022-12-31 06:13:16,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:16,040 INFO:     Epoch: 34
2022-12-31 06:13:17,655 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5235781013965607, 'Total loss': 0.5235781013965607} | train loss {'Reaction outcome loss': 0.15307502123100233, 'Total loss': 0.15307502123100233}
2022-12-31 06:13:17,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:17,656 INFO:     Epoch: 35
2022-12-31 06:13:19,290 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5090162555376688, 'Total loss': 0.5090162555376688} | train loss {'Reaction outcome loss': 0.14823692284914453, 'Total loss': 0.14823692284914453}
2022-12-31 06:13:19,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:19,290 INFO:     Epoch: 36
2022-12-31 06:13:20,949 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5193279584248861, 'Total loss': 0.5193279584248861} | train loss {'Reaction outcome loss': 0.14504575385755794, 'Total loss': 0.14504575385755794}
2022-12-31 06:13:20,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:20,949 INFO:     Epoch: 37
2022-12-31 06:13:22,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5026913583278656, 'Total loss': 0.5026913583278656} | train loss {'Reaction outcome loss': 0.14174487518099563, 'Total loss': 0.14174487518099563}
2022-12-31 06:13:22,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:22,575 INFO:     Epoch: 38
2022-12-31 06:13:24,200 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5403695811827978, 'Total loss': 0.5403695811827978} | train loss {'Reaction outcome loss': 0.14256968754696717, 'Total loss': 0.14256968754696717}
2022-12-31 06:13:24,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:24,200 INFO:     Epoch: 39
2022-12-31 06:13:25,818 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5292617718378703, 'Total loss': 0.5292617718378703} | train loss {'Reaction outcome loss': 0.14142590995192098, 'Total loss': 0.14142590995192098}
2022-12-31 06:13:25,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:25,818 INFO:     Epoch: 40
2022-12-31 06:13:27,433 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5018587350845337, 'Total loss': 0.5018587350845337} | train loss {'Reaction outcome loss': 0.14119743031957305, 'Total loss': 0.14119743031957305}
2022-12-31 06:13:27,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:27,434 INFO:     Epoch: 41
2022-12-31 06:13:29,057 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47354387665788333, 'Total loss': 0.47354387665788333} | train loss {'Reaction outcome loss': 0.13925875131955323, 'Total loss': 0.13925875131955323}
2022-12-31 06:13:29,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:29,057 INFO:     Epoch: 42
2022-12-31 06:13:30,679 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.531383453309536, 'Total loss': 0.531383453309536} | train loss {'Reaction outcome loss': 0.1378900566598945, 'Total loss': 0.1378900566598945}
2022-12-31 06:13:30,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:30,679 INFO:     Epoch: 43
2022-12-31 06:13:32,306 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5260224481423695, 'Total loss': 0.5260224481423695} | train loss {'Reaction outcome loss': 0.13422185140880435, 'Total loss': 0.13422185140880435}
2022-12-31 06:13:32,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:32,306 INFO:     Epoch: 44
2022-12-31 06:13:33,930 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5100709001223246, 'Total loss': 0.5100709001223246} | train loss {'Reaction outcome loss': 0.1353927804829573, 'Total loss': 0.1353927804829573}
2022-12-31 06:13:33,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:33,931 INFO:     Epoch: 45
2022-12-31 06:13:35,565 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5324349582195282, 'Total loss': 0.5324349582195282} | train loss {'Reaction outcome loss': 0.1396008028097397, 'Total loss': 0.1396008028097397}
2022-12-31 06:13:35,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:35,565 INFO:     Epoch: 46
2022-12-31 06:13:37,185 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5554612368345261, 'Total loss': 0.5554612368345261} | train loss {'Reaction outcome loss': 0.1348977351278766, 'Total loss': 0.1348977351278766}
2022-12-31 06:13:37,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:37,185 INFO:     Epoch: 47
2022-12-31 06:13:38,798 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5121294021606445, 'Total loss': 0.5121294021606445} | train loss {'Reaction outcome loss': 0.13352855002601707, 'Total loss': 0.13352855002601707}
2022-12-31 06:13:38,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:38,799 INFO:     Epoch: 48
2022-12-31 06:13:40,430 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5357080588738123, 'Total loss': 0.5357080588738123} | train loss {'Reaction outcome loss': 0.12809070116009846, 'Total loss': 0.12809070116009846}
2022-12-31 06:13:40,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:40,430 INFO:     Epoch: 49
2022-12-31 06:13:42,055 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5501977642377217, 'Total loss': 0.5501977642377217} | train loss {'Reaction outcome loss': 0.13126906677273636, 'Total loss': 0.13126906677273636}
2022-12-31 06:13:42,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:42,055 INFO:     Epoch: 50
2022-12-31 06:13:43,724 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5337615331013997, 'Total loss': 0.5337615331013997} | train loss {'Reaction outcome loss': 0.13172185184124735, 'Total loss': 0.13172185184124735}
2022-12-31 06:13:43,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:43,724 INFO:     Epoch: 51
2022-12-31 06:13:45,336 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5053858329852422, 'Total loss': 0.5053858329852422} | train loss {'Reaction outcome loss': 0.12883320624102915, 'Total loss': 0.12883320624102915}
2022-12-31 06:13:45,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:45,336 INFO:     Epoch: 52
2022-12-31 06:13:46,983 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5184256732463837, 'Total loss': 0.5184256732463837} | train loss {'Reaction outcome loss': 0.13091881863187851, 'Total loss': 0.13091881863187851}
2022-12-31 06:13:46,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:46,984 INFO:     Epoch: 53
2022-12-31 06:13:48,610 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5416505972544352, 'Total loss': 0.5416505972544352} | train loss {'Reaction outcome loss': 0.12491283438333213, 'Total loss': 0.12491283438333213}
2022-12-31 06:13:48,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:48,610 INFO:     Epoch: 54
2022-12-31 06:13:50,236 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5258110562960306, 'Total loss': 0.5258110562960306} | train loss {'Reaction outcome loss': 0.12271168654858527, 'Total loss': 0.12271168654858527}
2022-12-31 06:13:50,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:50,236 INFO:     Epoch: 55
2022-12-31 06:13:51,862 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5315604239702225, 'Total loss': 0.5315604239702225} | train loss {'Reaction outcome loss': 0.12112628056126434, 'Total loss': 0.12112628056126434}
2022-12-31 06:13:51,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:51,862 INFO:     Epoch: 56
2022-12-31 06:13:53,519 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5478908856709798, 'Total loss': 0.5478908856709798} | train loss {'Reaction outcome loss': 0.12027467150133547, 'Total loss': 0.12027467150133547}
2022-12-31 06:13:53,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:53,519 INFO:     Epoch: 57
2022-12-31 06:13:55,135 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5029906739791234, 'Total loss': 0.5029906739791234} | train loss {'Reaction outcome loss': 0.12641346813868798, 'Total loss': 0.12641346813868798}
2022-12-31 06:13:55,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:55,135 INFO:     Epoch: 58
2022-12-31 06:13:56,759 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5434482435385386, 'Total loss': 0.5434482435385386} | train loss {'Reaction outcome loss': 0.12498492407124988, 'Total loss': 0.12498492407124988}
2022-12-31 06:13:56,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:56,760 INFO:     Epoch: 59
2022-12-31 06:13:58,384 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5369335591793061, 'Total loss': 0.5369335591793061} | train loss {'Reaction outcome loss': 0.12372733242742529, 'Total loss': 0.12372733242742529}
2022-12-31 06:13:58,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:13:58,384 INFO:     Epoch: 60
2022-12-31 06:14:00,017 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5361543436845143, 'Total loss': 0.5361543436845143} | train loss {'Reaction outcome loss': 0.11729343705945093, 'Total loss': 0.11729343705945093}
2022-12-31 06:14:00,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:00,017 INFO:     Epoch: 61
2022-12-31 06:14:01,678 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49188578923543297, 'Total loss': 0.49188578923543297} | train loss {'Reaction outcome loss': 0.11695964165563133, 'Total loss': 0.11695964165563133}
2022-12-31 06:14:01,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:01,678 INFO:     Epoch: 62
2022-12-31 06:14:03,325 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5083952804406484, 'Total loss': 0.5083952804406484} | train loss {'Reaction outcome loss': 0.12160185534365825, 'Total loss': 0.12160185534365825}
2022-12-31 06:14:03,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:03,327 INFO:     Epoch: 63
2022-12-31 06:14:04,947 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5002857069174449, 'Total loss': 0.5002857069174449} | train loss {'Reaction outcome loss': 0.12162012859106414, 'Total loss': 0.12162012859106414}
2022-12-31 06:14:04,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:04,947 INFO:     Epoch: 64
2022-12-31 06:14:06,568 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5121142268180847, 'Total loss': 0.5121142268180847} | train loss {'Reaction outcome loss': 0.11835278817603788, 'Total loss': 0.11835278817603788}
2022-12-31 06:14:06,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:06,569 INFO:     Epoch: 65
2022-12-31 06:14:08,239 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5370700468619665, 'Total loss': 0.5370700468619665} | train loss {'Reaction outcome loss': 0.12055486099649934, 'Total loss': 0.12055486099649934}
2022-12-31 06:14:08,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:08,239 INFO:     Epoch: 66
2022-12-31 06:14:09,856 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5088434082766374, 'Total loss': 0.5088434082766374} | train loss {'Reaction outcome loss': 0.1166375188227568, 'Total loss': 0.1166375188227568}
2022-12-31 06:14:09,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:09,857 INFO:     Epoch: 67
2022-12-31 06:14:11,479 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5181452651818593, 'Total loss': 0.5181452651818593} | train loss {'Reaction outcome loss': 0.11509745992175455, 'Total loss': 0.11509745992175455}
2022-12-31 06:14:11,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:11,480 INFO:     Epoch: 68
2022-12-31 06:14:13,105 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5270274261633555, 'Total loss': 0.5270274261633555} | train loss {'Reaction outcome loss': 0.11403491861684524, 'Total loss': 0.11403491861684524}
2022-12-31 06:14:13,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:13,106 INFO:     Epoch: 69
2022-12-31 06:14:14,739 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5162935301661491, 'Total loss': 0.5162935301661491} | train loss {'Reaction outcome loss': 0.11546211732074027, 'Total loss': 0.11546211732074027}
2022-12-31 06:14:14,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:14,739 INFO:     Epoch: 70
2022-12-31 06:14:16,373 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5615340143442153, 'Total loss': 0.5615340143442153} | train loss {'Reaction outcome loss': 0.11447373166888791, 'Total loss': 0.11447373166888791}
2022-12-31 06:14:16,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:16,374 INFO:     Epoch: 71
2022-12-31 06:14:18,010 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.546883616844813, 'Total loss': 0.546883616844813} | train loss {'Reaction outcome loss': 0.11411659084159599, 'Total loss': 0.11411659084159599}
2022-12-31 06:14:18,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:18,011 INFO:     Epoch: 72
2022-12-31 06:14:19,647 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5310544431209564, 'Total loss': 0.5310544431209564} | train loss {'Reaction outcome loss': 0.1139095108006284, 'Total loss': 0.1139095108006284}
2022-12-31 06:14:19,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:19,647 INFO:     Epoch: 73
2022-12-31 06:14:21,270 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5372309486071268, 'Total loss': 0.5372309486071268} | train loss {'Reaction outcome loss': 0.11527339483288516, 'Total loss': 0.11527339483288516}
2022-12-31 06:14:21,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:21,271 INFO:     Epoch: 74
2022-12-31 06:14:22,889 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5363903204600017, 'Total loss': 0.5363903204600017} | train loss {'Reaction outcome loss': 0.11613198612742665, 'Total loss': 0.11613198612742665}
2022-12-31 06:14:22,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:22,890 INFO:     Epoch: 75
2022-12-31 06:14:24,513 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4871414601802826, 'Total loss': 0.4871414601802826} | train loss {'Reaction outcome loss': 0.11014466900008626, 'Total loss': 0.11014466900008626}
2022-12-31 06:14:24,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:24,513 INFO:     Epoch: 76
2022-12-31 06:14:26,139 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5491613169511159, 'Total loss': 0.5491613169511159} | train loss {'Reaction outcome loss': 0.10798837141628084, 'Total loss': 0.10798837141628084}
2022-12-31 06:14:26,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:26,139 INFO:     Epoch: 77
2022-12-31 06:14:27,811 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5107405076424281, 'Total loss': 0.5107405076424281} | train loss {'Reaction outcome loss': 0.1135335078686543, 'Total loss': 0.1135335078686543}
2022-12-31 06:14:27,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:27,811 INFO:     Epoch: 78
2022-12-31 06:14:29,442 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5010392596324285, 'Total loss': 0.5010392596324285} | train loss {'Reaction outcome loss': 0.11065288489627305, 'Total loss': 0.11065288489627305}
2022-12-31 06:14:29,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:29,442 INFO:     Epoch: 79
2022-12-31 06:14:31,116 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4969270279010137, 'Total loss': 0.4969270279010137} | train loss {'Reaction outcome loss': 0.11310462698185755, 'Total loss': 0.11310462698185755}
2022-12-31 06:14:31,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:31,117 INFO:     Epoch: 80
2022-12-31 06:14:32,788 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5201722924908002, 'Total loss': 0.5201722924908002} | train loss {'Reaction outcome loss': 0.11508285226838307, 'Total loss': 0.11508285226838307}
2022-12-31 06:14:32,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:32,788 INFO:     Epoch: 81
2022-12-31 06:14:34,444 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49778204460938774, 'Total loss': 0.49778204460938774} | train loss {'Reaction outcome loss': 0.11295429581317325, 'Total loss': 0.11295429581317325}
2022-12-31 06:14:34,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:34,445 INFO:     Epoch: 82
2022-12-31 06:14:36,069 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49291104475657144, 'Total loss': 0.49291104475657144} | train loss {'Reaction outcome loss': 0.11044542610120794, 'Total loss': 0.11044542610120794}
2022-12-31 06:14:36,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:36,069 INFO:     Epoch: 83
2022-12-31 06:14:37,693 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4983520895242691, 'Total loss': 0.4983520895242691} | train loss {'Reaction outcome loss': 0.1074177648314016, 'Total loss': 0.1074177648314016}
2022-12-31 06:14:37,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:37,694 INFO:     Epoch: 84
2022-12-31 06:14:39,331 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5068759212891261, 'Total loss': 0.5068759212891261} | train loss {'Reaction outcome loss': 0.1108654317637697, 'Total loss': 0.1108654317637697}
2022-12-31 06:14:39,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:39,332 INFO:     Epoch: 85
2022-12-31 06:14:40,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49794412553310397, 'Total loss': 0.49794412553310397} | train loss {'Reaction outcome loss': 0.11538154389019989, 'Total loss': 0.11538154389019989}
2022-12-31 06:14:40,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:40,966 INFO:     Epoch: 86
2022-12-31 06:14:42,636 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5041268746058146, 'Total loss': 0.5041268746058146} | train loss {'Reaction outcome loss': 0.10814365233371996, 'Total loss': 0.10814365233371996}
2022-12-31 06:14:42,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:42,636 INFO:     Epoch: 87
2022-12-31 06:14:44,308 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5120076020558675, 'Total loss': 0.5120076020558675} | train loss {'Reaction outcome loss': 0.10781584237954354, 'Total loss': 0.10781584237954354}
2022-12-31 06:14:44,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:44,308 INFO:     Epoch: 88
2022-12-31 06:14:45,940 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5381138801574707, 'Total loss': 0.5381138801574707} | train loss {'Reaction outcome loss': 0.10673862392930078, 'Total loss': 0.10673862392930078}
2022-12-31 06:14:45,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:45,940 INFO:     Epoch: 89
2022-12-31 06:14:47,608 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5207692195971807, 'Total loss': 0.5207692195971807} | train loss {'Reaction outcome loss': 0.1102236149999034, 'Total loss': 0.1102236149999034}
2022-12-31 06:14:47,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:47,608 INFO:     Epoch: 90
2022-12-31 06:14:49,244 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48856916228930153, 'Total loss': 0.48856916228930153} | train loss {'Reaction outcome loss': 0.10699478967118645, 'Total loss': 0.10699478967118645}
2022-12-31 06:14:49,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:49,245 INFO:     Epoch: 91
2022-12-31 06:14:50,870 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4959122836589813, 'Total loss': 0.4959122836589813} | train loss {'Reaction outcome loss': 0.10825733208376578, 'Total loss': 0.10825733208376578}
2022-12-31 06:14:50,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:50,871 INFO:     Epoch: 92
2022-12-31 06:14:52,496 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5334828247626623, 'Total loss': 0.5334828247626623} | train loss {'Reaction outcome loss': 0.10915845038036442, 'Total loss': 0.10915845038036442}
2022-12-31 06:14:52,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:52,497 INFO:     Epoch: 93
2022-12-31 06:14:54,123 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5387627204259237, 'Total loss': 0.5387627204259237} | train loss {'Reaction outcome loss': 0.11345418236329345, 'Total loss': 0.11345418236329345}
2022-12-31 06:14:54,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:54,123 INFO:     Epoch: 94
2022-12-31 06:14:55,752 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5576256195704142, 'Total loss': 0.5576256195704142} | train loss {'Reaction outcome loss': 0.11538648617702674, 'Total loss': 0.11538648617702674}
2022-12-31 06:14:55,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:55,753 INFO:     Epoch: 95
2022-12-31 06:14:57,374 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5511676172415415, 'Total loss': 0.5511676172415415} | train loss {'Reaction outcome loss': 0.10701111713188972, 'Total loss': 0.10701111713188972}
2022-12-31 06:14:57,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:57,374 INFO:     Epoch: 96
2022-12-31 06:14:58,997 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5133303493261338, 'Total loss': 0.5133303493261338} | train loss {'Reaction outcome loss': 0.1023979245858193, 'Total loss': 0.1023979245858193}
2022-12-31 06:14:58,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:14:58,998 INFO:     Epoch: 97
2022-12-31 06:15:00,631 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.52794375816981, 'Total loss': 0.52794375816981} | train loss {'Reaction outcome loss': 0.10854646110140621, 'Total loss': 0.10854646110140621}
2022-12-31 06:15:00,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:00,632 INFO:     Epoch: 98
2022-12-31 06:15:02,266 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5431462784608205, 'Total loss': 0.5431462784608205} | train loss {'Reaction outcome loss': 0.10851853391717084, 'Total loss': 0.10851853391717084}
2022-12-31 06:15:02,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:02,267 INFO:     Epoch: 99
2022-12-31 06:15:03,901 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5555812468131384, 'Total loss': 0.5555812468131384} | train loss {'Reaction outcome loss': 0.10758439666046912, 'Total loss': 0.10758439666046912}
2022-12-31 06:15:03,901 INFO:     Best model found after epoch 22 of 100.
2022-12-31 06:15:03,901 INFO:   Done with stage: TRAINING
2022-12-31 06:15:03,901 INFO:   Starting stage: EVALUATION
2022-12-31 06:15:04,024 INFO:   Done with stage: EVALUATION
2022-12-31 06:15:04,024 INFO:   Leaving out SEQ value Fold_8
2022-12-31 06:15:04,037 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 06:15:04,037 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:15:04,685 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:15:04,685 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:15:04,756 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:15:04,756 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:15:04,756 INFO:     No hyperparam tuning for this model
2022-12-31 06:15:04,756 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:15:04,756 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:15:04,757 INFO:     None feature selector for col prot
2022-12-31 06:15:04,757 INFO:     None feature selector for col prot
2022-12-31 06:15:04,757 INFO:     None feature selector for col prot
2022-12-31 06:15:04,758 INFO:     None feature selector for col chem
2022-12-31 06:15:04,758 INFO:     None feature selector for col chem
2022-12-31 06:15:04,758 INFO:     None feature selector for col chem
2022-12-31 06:15:04,758 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:15:04,758 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:15:04,760 INFO:     Number of params in model 224011
2022-12-31 06:15:04,763 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:15:04,763 INFO:   Starting stage: TRAINING
2022-12-31 06:15:04,808 INFO:     Val loss before train {'Reaction outcome loss': 0.9654233654340109, 'Total loss': 0.9654233654340109}
2022-12-31 06:15:04,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:04,808 INFO:     Epoch: 0
2022-12-31 06:15:06,436 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5833390831947327, 'Total loss': 0.5833390831947327} | train loss {'Reaction outcome loss': 0.7717781981406229, 'Total loss': 0.7717781981406229}
2022-12-31 06:15:06,436 INFO:     Found new best model at epoch 0
2022-12-31 06:15:06,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:06,437 INFO:     Epoch: 1
2022-12-31 06:15:08,050 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49848869840304055, 'Total loss': 0.49848869840304055} | train loss {'Reaction outcome loss': 0.5130922028304007, 'Total loss': 0.5130922028304007}
2022-12-31 06:15:08,050 INFO:     Found new best model at epoch 1
2022-12-31 06:15:08,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:08,051 INFO:     Epoch: 2
2022-12-31 06:15:09,672 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45526470641295114, 'Total loss': 0.45526470641295114} | train loss {'Reaction outcome loss': 0.4407127751878022, 'Total loss': 0.4407127751878022}
2022-12-31 06:15:09,672 INFO:     Found new best model at epoch 2
2022-12-31 06:15:09,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:09,673 INFO:     Epoch: 3
2022-12-31 06:15:11,296 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44585723876953126, 'Total loss': 0.44585723876953126} | train loss {'Reaction outcome loss': 0.39763470908579845, 'Total loss': 0.39763470908579845}
2022-12-31 06:15:11,296 INFO:     Found new best model at epoch 3
2022-12-31 06:15:11,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:11,297 INFO:     Epoch: 4
2022-12-31 06:15:12,920 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4397927761077881, 'Total loss': 0.4397927761077881} | train loss {'Reaction outcome loss': 0.3689063262691997, 'Total loss': 0.3689063262691997}
2022-12-31 06:15:12,921 INFO:     Found new best model at epoch 4
2022-12-31 06:15:12,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:12,922 INFO:     Epoch: 5
2022-12-31 06:15:14,546 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40419490734736124, 'Total loss': 0.40419490734736124} | train loss {'Reaction outcome loss': 0.34436167308569815, 'Total loss': 0.34436167308569815}
2022-12-31 06:15:14,547 INFO:     Found new best model at epoch 5
2022-12-31 06:15:14,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:14,548 INFO:     Epoch: 6
2022-12-31 06:15:16,166 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38495392849047977, 'Total loss': 0.38495392849047977} | train loss {'Reaction outcome loss': 0.32462834074609115, 'Total loss': 0.32462834074609115}
2022-12-31 06:15:16,166 INFO:     Found new best model at epoch 6
2022-12-31 06:15:16,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:16,167 INFO:     Epoch: 7
2022-12-31 06:15:17,790 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3826954185962677, 'Total loss': 0.3826954185962677} | train loss {'Reaction outcome loss': 0.3103930973229318, 'Total loss': 0.3103930973229318}
2022-12-31 06:15:17,790 INFO:     Found new best model at epoch 7
2022-12-31 06:15:17,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:17,791 INFO:     Epoch: 8
2022-12-31 06:15:19,438 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40492408275604247, 'Total loss': 0.40492408275604247} | train loss {'Reaction outcome loss': 0.29650960464555004, 'Total loss': 0.29650960464555004}
2022-12-31 06:15:19,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:19,438 INFO:     Epoch: 9
2022-12-31 06:15:21,078 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3813548674186071, 'Total loss': 0.3813548674186071} | train loss {'Reaction outcome loss': 0.28551524581676785, 'Total loss': 0.28551524581676785}
2022-12-31 06:15:21,079 INFO:     Found new best model at epoch 9
2022-12-31 06:15:21,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:21,080 INFO:     Epoch: 10
2022-12-31 06:15:22,701 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3805673509836197, 'Total loss': 0.3805673509836197} | train loss {'Reaction outcome loss': 0.26808022406449816, 'Total loss': 0.26808022406449816}
2022-12-31 06:15:22,702 INFO:     Found new best model at epoch 10
2022-12-31 06:15:22,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:22,703 INFO:     Epoch: 11
2022-12-31 06:15:24,317 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3670224756002426, 'Total loss': 0.3670224756002426} | train loss {'Reaction outcome loss': 0.2572901896217885, 'Total loss': 0.2572901896217885}
2022-12-31 06:15:24,317 INFO:     Found new best model at epoch 11
2022-12-31 06:15:24,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:24,318 INFO:     Epoch: 12
2022-12-31 06:15:25,943 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39510739743709566, 'Total loss': 0.39510739743709566} | train loss {'Reaction outcome loss': 0.2501749256121445, 'Total loss': 0.2501749256121445}
2022-12-31 06:15:25,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:25,943 INFO:     Epoch: 13
2022-12-31 06:15:27,601 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39561889270941414, 'Total loss': 0.39561889270941414} | train loss {'Reaction outcome loss': 0.23750539238325954, 'Total loss': 0.23750539238325954}
2022-12-31 06:15:27,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:27,602 INFO:     Epoch: 14
2022-12-31 06:15:29,273 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3836763560771942, 'Total loss': 0.3836763560771942} | train loss {'Reaction outcome loss': 0.23282937057289405, 'Total loss': 0.23282937057289405}
2022-12-31 06:15:29,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:29,273 INFO:     Epoch: 15
2022-12-31 06:15:30,926 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3771589795748393, 'Total loss': 0.3771589795748393} | train loss {'Reaction outcome loss': 0.22710249090183943, 'Total loss': 0.22710249090183943}
2022-12-31 06:15:30,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:30,926 INFO:     Epoch: 16
2022-12-31 06:15:32,555 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3752509554227193, 'Total loss': 0.3752509554227193} | train loss {'Reaction outcome loss': 0.21505519071264387, 'Total loss': 0.21505519071264387}
2022-12-31 06:15:32,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:32,555 INFO:     Epoch: 17
2022-12-31 06:15:34,171 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39297169347604116, 'Total loss': 0.39297169347604116} | train loss {'Reaction outcome loss': 0.21494378571798656, 'Total loss': 0.21494378571798656}
2022-12-31 06:15:34,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:34,172 INFO:     Epoch: 18
2022-12-31 06:15:35,801 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38309200207392374, 'Total loss': 0.38309200207392374} | train loss {'Reaction outcome loss': 0.2049427274143868, 'Total loss': 0.2049427274143868}
2022-12-31 06:15:35,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:35,801 INFO:     Epoch: 19
2022-12-31 06:15:37,429 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.388941290974617, 'Total loss': 0.388941290974617} | train loss {'Reaction outcome loss': 0.19973333058239967, 'Total loss': 0.19973333058239967}
2022-12-31 06:15:37,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:37,430 INFO:     Epoch: 20
2022-12-31 06:15:39,101 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38583432336648305, 'Total loss': 0.38583432336648305} | train loss {'Reaction outcome loss': 0.19896917510441495, 'Total loss': 0.19896917510441495}
2022-12-31 06:15:39,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:39,101 INFO:     Epoch: 21
2022-12-31 06:15:40,771 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3971921225388845, 'Total loss': 0.3971921225388845} | train loss {'Reaction outcome loss': 0.19213521918315535, 'Total loss': 0.19213521918315535}
2022-12-31 06:15:40,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:40,772 INFO:     Epoch: 22
2022-12-31 06:15:42,432 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3815126200517019, 'Total loss': 0.3815126200517019} | train loss {'Reaction outcome loss': 0.18530022666288626, 'Total loss': 0.18530022666288626}
2022-12-31 06:15:42,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:42,432 INFO:     Epoch: 23
2022-12-31 06:15:44,049 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36330977976322176, 'Total loss': 0.36330977976322176} | train loss {'Reaction outcome loss': 0.18801114959675913, 'Total loss': 0.18801114959675913}
2022-12-31 06:15:44,049 INFO:     Found new best model at epoch 23
2022-12-31 06:15:44,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:44,050 INFO:     Epoch: 24
2022-12-31 06:15:45,673 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3751906077067057, 'Total loss': 0.3751906077067057} | train loss {'Reaction outcome loss': 0.18128447582279517, 'Total loss': 0.18128447582279517}
2022-12-31 06:15:45,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:45,674 INFO:     Epoch: 25
2022-12-31 06:15:47,296 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37774995565414426, 'Total loss': 0.37774995565414426} | train loss {'Reaction outcome loss': 0.1754663784211562, 'Total loss': 0.1754663784211562}
2022-12-31 06:15:47,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:47,296 INFO:     Epoch: 26
2022-12-31 06:15:48,920 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39514102339744567, 'Total loss': 0.39514102339744567} | train loss {'Reaction outcome loss': 0.17350576368130285, 'Total loss': 0.17350576368130285}
2022-12-31 06:15:48,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:48,920 INFO:     Epoch: 27
2022-12-31 06:15:50,544 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38045638700326284, 'Total loss': 0.38045638700326284} | train loss {'Reaction outcome loss': 0.17092212935781867, 'Total loss': 0.17092212935781867}
2022-12-31 06:15:50,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:50,545 INFO:     Epoch: 28
2022-12-31 06:15:52,170 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39381809482971825, 'Total loss': 0.39381809482971825} | train loss {'Reaction outcome loss': 0.16817777087770752, 'Total loss': 0.16817777087770752}
2022-12-31 06:15:52,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:52,171 INFO:     Epoch: 29
2022-12-31 06:15:53,828 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37718658447265624, 'Total loss': 0.37718658447265624} | train loss {'Reaction outcome loss': 0.16192231997040635, 'Total loss': 0.16192231997040635}
2022-12-31 06:15:53,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:53,828 INFO:     Epoch: 30
2022-12-31 06:15:55,452 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4427719642718633, 'Total loss': 0.4427719642718633} | train loss {'Reaction outcome loss': 0.16620720352049553, 'Total loss': 0.16620720352049553}
2022-12-31 06:15:55,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:55,452 INFO:     Epoch: 31
2022-12-31 06:15:57,075 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39474429935216904, 'Total loss': 0.39474429935216904} | train loss {'Reaction outcome loss': 0.16103038046549373, 'Total loss': 0.16103038046549373}
2022-12-31 06:15:57,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:57,075 INFO:     Epoch: 32
2022-12-31 06:15:58,699 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4016271938880285, 'Total loss': 0.4016271938880285} | train loss {'Reaction outcome loss': 0.1577547033139192, 'Total loss': 0.1577547033139192}
2022-12-31 06:15:58,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:15:58,700 INFO:     Epoch: 33
2022-12-31 06:16:00,321 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3905481144785881, 'Total loss': 0.3905481144785881} | train loss {'Reaction outcome loss': 0.15563308307732915, 'Total loss': 0.15563308307732915}
2022-12-31 06:16:00,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:00,322 INFO:     Epoch: 34
2022-12-31 06:16:01,933 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39462582767009735, 'Total loss': 0.39462582767009735} | train loss {'Reaction outcome loss': 0.15668302673900278, 'Total loss': 0.15668302673900278}
2022-12-31 06:16:01,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:01,933 INFO:     Epoch: 35
2022-12-31 06:16:03,558 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39915187160174054, 'Total loss': 0.39915187160174054} | train loss {'Reaction outcome loss': 0.15314349419830722, 'Total loss': 0.15314349419830722}
2022-12-31 06:16:03,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:03,559 INFO:     Epoch: 36
2022-12-31 06:16:05,185 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3849625696738561, 'Total loss': 0.3849625696738561} | train loss {'Reaction outcome loss': 0.14830605892820908, 'Total loss': 0.14830605892820908}
2022-12-31 06:16:05,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:05,186 INFO:     Epoch: 37
2022-12-31 06:16:06,812 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3918450256188711, 'Total loss': 0.3918450256188711} | train loss {'Reaction outcome loss': 0.14914341252095434, 'Total loss': 0.14914341252095434}
2022-12-31 06:16:06,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:06,812 INFO:     Epoch: 38
2022-12-31 06:16:08,438 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38806986808776855, 'Total loss': 0.38806986808776855} | train loss {'Reaction outcome loss': 0.14570048418810544, 'Total loss': 0.14570048418810544}
2022-12-31 06:16:08,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:08,438 INFO:     Epoch: 39
2022-12-31 06:16:10,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4060600196321805, 'Total loss': 0.4060600196321805} | train loss {'Reaction outcome loss': 0.14221088494769288, 'Total loss': 0.14221088494769288}
2022-12-31 06:16:10,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:10,078 INFO:     Epoch: 40
2022-12-31 06:16:11,697 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3991516619920731, 'Total loss': 0.3991516619920731} | train loss {'Reaction outcome loss': 0.14447876225336578, 'Total loss': 0.14447876225336578}
2022-12-31 06:16:11,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:11,697 INFO:     Epoch: 41
2022-12-31 06:16:13,322 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3996400862932205, 'Total loss': 0.3996400862932205} | train loss {'Reaction outcome loss': 0.1418136393244543, 'Total loss': 0.1418136393244543}
2022-12-31 06:16:13,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:13,323 INFO:     Epoch: 42
2022-12-31 06:16:14,953 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4143734723329544, 'Total loss': 0.4143734723329544} | train loss {'Reaction outcome loss': 0.1426433322594807, 'Total loss': 0.1426433322594807}
2022-12-31 06:16:14,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:14,953 INFO:     Epoch: 43
2022-12-31 06:16:16,586 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3715686152378718, 'Total loss': 0.3715686152378718} | train loss {'Reaction outcome loss': 0.14086564624890524, 'Total loss': 0.14086564624890524}
2022-12-31 06:16:16,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:16,586 INFO:     Epoch: 44
2022-12-31 06:16:18,217 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3915247569481532, 'Total loss': 0.3915247569481532} | train loss {'Reaction outcome loss': 0.13768992935801563, 'Total loss': 0.13768992935801563}
2022-12-31 06:16:18,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:18,217 INFO:     Epoch: 45
2022-12-31 06:16:19,843 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3968227078517278, 'Total loss': 0.3968227078517278} | train loss {'Reaction outcome loss': 0.13672455456881155, 'Total loss': 0.13672455456881155}
2022-12-31 06:16:19,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:19,843 INFO:     Epoch: 46
2022-12-31 06:16:21,476 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4116814432044824, 'Total loss': 0.4116814432044824} | train loss {'Reaction outcome loss': 0.13421877572104496, 'Total loss': 0.13421877572104496}
2022-12-31 06:16:21,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:21,477 INFO:     Epoch: 47
2022-12-31 06:16:23,107 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3878428419431051, 'Total loss': 0.3878428419431051} | train loss {'Reaction outcome loss': 0.13211561422223486, 'Total loss': 0.13211561422223486}
2022-12-31 06:16:23,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:23,107 INFO:     Epoch: 48
2022-12-31 06:16:24,778 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4269778271516164, 'Total loss': 0.4269778271516164} | train loss {'Reaction outcome loss': 0.13446698458495446, 'Total loss': 0.13446698458495446}
2022-12-31 06:16:24,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:24,778 INFO:     Epoch: 49
2022-12-31 06:16:26,409 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4312133143345515, 'Total loss': 0.4312133143345515} | train loss {'Reaction outcome loss': 0.13053103467106603, 'Total loss': 0.13053103467106603}
2022-12-31 06:16:26,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:26,409 INFO:     Epoch: 50
2022-12-31 06:16:28,044 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3791807999213537, 'Total loss': 0.3791807999213537} | train loss {'Reaction outcome loss': 0.13230359443002768, 'Total loss': 0.13230359443002768}
2022-12-31 06:16:28,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:28,045 INFO:     Epoch: 51
2022-12-31 06:16:29,668 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4223624805609385, 'Total loss': 0.4223624805609385} | train loss {'Reaction outcome loss': 0.13104540068279644, 'Total loss': 0.13104540068279644}
2022-12-31 06:16:29,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:29,669 INFO:     Epoch: 52
2022-12-31 06:16:31,302 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41610573331514994, 'Total loss': 0.41610573331514994} | train loss {'Reaction outcome loss': 0.12975109616018804, 'Total loss': 0.12975109616018804}
2022-12-31 06:16:31,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:31,303 INFO:     Epoch: 53
2022-12-31 06:16:32,936 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4098748465379079, 'Total loss': 0.4098748465379079} | train loss {'Reaction outcome loss': 0.1301137277241191, 'Total loss': 0.1301137277241191}
2022-12-31 06:16:32,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:32,937 INFO:     Epoch: 54
2022-12-31 06:16:34,569 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41104175299406054, 'Total loss': 0.41104175299406054} | train loss {'Reaction outcome loss': 0.12544819357929354, 'Total loss': 0.12544819357929354}
2022-12-31 06:16:34,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:34,569 INFO:     Epoch: 55
2022-12-31 06:16:36,203 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.380255164951086, 'Total loss': 0.380255164951086} | train loss {'Reaction outcome loss': 0.12664660809743167, 'Total loss': 0.12664660809743167}
2022-12-31 06:16:36,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:36,204 INFO:     Epoch: 56
2022-12-31 06:16:37,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42828174208601316, 'Total loss': 0.42828174208601316} | train loss {'Reaction outcome loss': 0.12234260597088062, 'Total loss': 0.12234260597088062}
2022-12-31 06:16:37,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:37,824 INFO:     Epoch: 57
2022-12-31 06:16:39,445 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.426963538924853, 'Total loss': 0.426963538924853} | train loss {'Reaction outcome loss': 0.12682535169504933, 'Total loss': 0.12682535169504933}
2022-12-31 06:16:39,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:39,445 INFO:     Epoch: 58
2022-12-31 06:16:41,071 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39378296534220375, 'Total loss': 0.39378296534220375} | train loss {'Reaction outcome loss': 0.12738246453878896, 'Total loss': 0.12738246453878896}
2022-12-31 06:16:41,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:41,072 INFO:     Epoch: 59
2022-12-31 06:16:42,693 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39454521934191383, 'Total loss': 0.39454521934191383} | train loss {'Reaction outcome loss': 0.12650679913433505, 'Total loss': 0.12650679913433505}
2022-12-31 06:16:42,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:42,694 INFO:     Epoch: 60
2022-12-31 06:16:44,316 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43935468792915344, 'Total loss': 0.43935468792915344} | train loss {'Reaction outcome loss': 0.12310782113761409, 'Total loss': 0.12310782113761409}
2022-12-31 06:16:44,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:44,317 INFO:     Epoch: 61
2022-12-31 06:16:45,940 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4388917859022816, 'Total loss': 0.4388917859022816} | train loss {'Reaction outcome loss': 0.12439982689217755, 'Total loss': 0.12439982689217755}
2022-12-31 06:16:45,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:45,940 INFO:     Epoch: 62
2022-12-31 06:16:47,581 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4180070181687673, 'Total loss': 0.4180070181687673} | train loss {'Reaction outcome loss': 0.1229571189684289, 'Total loss': 0.1229571189684289}
2022-12-31 06:16:47,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:47,581 INFO:     Epoch: 63
2022-12-31 06:16:49,207 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41499044249455136, 'Total loss': 0.41499044249455136} | train loss {'Reaction outcome loss': 0.11955949158108514, 'Total loss': 0.11955949158108514}
2022-12-31 06:16:49,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:49,208 INFO:     Epoch: 64
2022-12-31 06:16:50,830 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4024428149064382, 'Total loss': 0.4024428149064382} | train loss {'Reaction outcome loss': 0.11782304297658591, 'Total loss': 0.11782304297658591}
2022-12-31 06:16:50,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:50,831 INFO:     Epoch: 65
2022-12-31 06:16:52,500 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4030071039994558, 'Total loss': 0.4030071039994558} | train loss {'Reaction outcome loss': 0.11878499081055718, 'Total loss': 0.11878499081055718}
2022-12-31 06:16:52,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:52,500 INFO:     Epoch: 66
2022-12-31 06:16:54,171 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42607985238234203, 'Total loss': 0.42607985238234203} | train loss {'Reaction outcome loss': 0.1213414916055889, 'Total loss': 0.1213414916055889}
2022-12-31 06:16:54,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:54,171 INFO:     Epoch: 67
2022-12-31 06:16:55,591 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3956668516000112, 'Total loss': 0.3956668516000112} | train loss {'Reaction outcome loss': 0.11617402757084273, 'Total loss': 0.11617402757084273}
2022-12-31 06:16:55,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:55,591 INFO:     Epoch: 68
2022-12-31 06:16:56,726 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38936406473318735, 'Total loss': 0.38936406473318735} | train loss {'Reaction outcome loss': 0.12255418035016809, 'Total loss': 0.12255418035016809}
2022-12-31 06:16:56,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:56,727 INFO:     Epoch: 69
2022-12-31 06:16:57,845 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42353442708651223, 'Total loss': 0.42353442708651223} | train loss {'Reaction outcome loss': 0.1225281766672965, 'Total loss': 0.1225281766672965}
2022-12-31 06:16:57,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:57,845 INFO:     Epoch: 70
2022-12-31 06:16:58,964 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4153157005707423, 'Total loss': 0.4153157005707423} | train loss {'Reaction outcome loss': 0.12039593560116817, 'Total loss': 0.12039593560116817}
2022-12-31 06:16:58,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:16:58,965 INFO:     Epoch: 71
2022-12-31 06:17:00,315 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3946041648586591, 'Total loss': 0.3946041648586591} | train loss {'Reaction outcome loss': 0.11605656489608843, 'Total loss': 0.11605656489608843}
2022-12-31 06:17:00,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:00,316 INFO:     Epoch: 72
2022-12-31 06:17:01,985 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4204199274381002, 'Total loss': 0.4204199274381002} | train loss {'Reaction outcome loss': 0.11440733813475616, 'Total loss': 0.11440733813475616}
2022-12-31 06:17:01,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:01,985 INFO:     Epoch: 73
2022-12-31 06:17:03,612 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41227453475197157, 'Total loss': 0.41227453475197157} | train loss {'Reaction outcome loss': 0.11281153160258321, 'Total loss': 0.11281153160258321}
2022-12-31 06:17:03,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:03,613 INFO:     Epoch: 74
2022-12-31 06:17:05,235 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40817311108112336, 'Total loss': 0.40817311108112336} | train loss {'Reaction outcome loss': 0.11546236854500477, 'Total loss': 0.11546236854500477}
2022-12-31 06:17:05,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:05,236 INFO:     Epoch: 75
2022-12-31 06:17:06,898 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4469119985898336, 'Total loss': 0.4469119985898336} | train loss {'Reaction outcome loss': 0.11494756969102131, 'Total loss': 0.11494756969102131}
2022-12-31 06:17:06,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:06,898 INFO:     Epoch: 76
2022-12-31 06:17:08,522 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3983770648638407, 'Total loss': 0.3983770648638407} | train loss {'Reaction outcome loss': 0.12051957918647072, 'Total loss': 0.12051957918647072}
2022-12-31 06:17:08,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:08,523 INFO:     Epoch: 77
2022-12-31 06:17:10,178 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44027095238367714, 'Total loss': 0.44027095238367714} | train loss {'Reaction outcome loss': 0.1164387427320845, 'Total loss': 0.1164387427320845}
2022-12-31 06:17:10,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:10,178 INFO:     Epoch: 78
2022-12-31 06:17:11,799 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4232942561308543, 'Total loss': 0.4232942561308543} | train loss {'Reaction outcome loss': 0.11117518943354542, 'Total loss': 0.11117518943354542}
2022-12-31 06:17:11,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:11,799 INFO:     Epoch: 79
2022-12-31 06:17:13,456 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40415716022253034, 'Total loss': 0.40415716022253034} | train loss {'Reaction outcome loss': 0.11260946669585546, 'Total loss': 0.11260946669585546}
2022-12-31 06:17:13,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:13,456 INFO:     Epoch: 80
2022-12-31 06:17:15,081 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43791412909825644, 'Total loss': 0.43791412909825644} | train loss {'Reaction outcome loss': 0.11902591052871964, 'Total loss': 0.11902591052871964}
2022-12-31 06:17:15,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:15,082 INFO:     Epoch: 81
2022-12-31 06:17:16,752 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4113539674008886, 'Total loss': 0.4113539674008886} | train loss {'Reaction outcome loss': 0.11646721889147206, 'Total loss': 0.11646721889147206}
2022-12-31 06:17:16,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:16,753 INFO:     Epoch: 82
2022-12-31 06:17:18,370 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44780279596646627, 'Total loss': 0.44780279596646627} | train loss {'Reaction outcome loss': 0.11299553882441608, 'Total loss': 0.11299553882441608}
2022-12-31 06:17:18,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:18,370 INFO:     Epoch: 83
2022-12-31 06:17:20,040 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4571359694004059, 'Total loss': 0.4571359694004059} | train loss {'Reaction outcome loss': 0.11038101634804146, 'Total loss': 0.11038101634804146}
2022-12-31 06:17:20,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:20,040 INFO:     Epoch: 84
2022-12-31 06:17:21,690 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4435574432214101, 'Total loss': 0.4435574432214101} | train loss {'Reaction outcome loss': 0.11004754666336526, 'Total loss': 0.11004754666336526}
2022-12-31 06:17:21,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:21,690 INFO:     Epoch: 85
2022-12-31 06:17:23,319 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42685600866874057, 'Total loss': 0.42685600866874057} | train loss {'Reaction outcome loss': 0.1112105424401589, 'Total loss': 0.1112105424401589}
2022-12-31 06:17:23,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:23,320 INFO:     Epoch: 86
2022-12-31 06:17:24,948 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4225351949532827, 'Total loss': 0.4225351949532827} | train loss {'Reaction outcome loss': 0.10970320280251306, 'Total loss': 0.10970320280251306}
2022-12-31 06:17:24,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:24,949 INFO:     Epoch: 87
2022-12-31 06:17:26,576 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4421777665615082, 'Total loss': 0.4421777665615082} | train loss {'Reaction outcome loss': 0.11120864349528341, 'Total loss': 0.11120864349528341}
2022-12-31 06:17:26,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:26,577 INFO:     Epoch: 88
2022-12-31 06:17:28,220 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40054164628187816, 'Total loss': 0.40054164628187816} | train loss {'Reaction outcome loss': 0.11218348565252519, 'Total loss': 0.11218348565252519}
2022-12-31 06:17:28,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:28,220 INFO:     Epoch: 89
2022-12-31 06:17:29,846 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43275283376375834, 'Total loss': 0.43275283376375834} | train loss {'Reaction outcome loss': 0.11547202151184666, 'Total loss': 0.11547202151184666}
2022-12-31 06:17:29,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:29,847 INFO:     Epoch: 90
2022-12-31 06:17:31,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4179381171862284, 'Total loss': 0.4179381171862284} | train loss {'Reaction outcome loss': 0.11049802402969086, 'Total loss': 0.11049802402969086}
2022-12-31 06:17:31,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:31,468 INFO:     Epoch: 91
2022-12-31 06:17:33,103 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42042192816734314, 'Total loss': 0.42042192816734314} | train loss {'Reaction outcome loss': 0.1081733802427615, 'Total loss': 0.1081733802427615}
2022-12-31 06:17:33,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:33,104 INFO:     Epoch: 92
2022-12-31 06:17:34,735 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42350544532140094, 'Total loss': 0.42350544532140094} | train loss {'Reaction outcome loss': 0.10975177461257883, 'Total loss': 0.10975177461257883}
2022-12-31 06:17:34,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:34,735 INFO:     Epoch: 93
2022-12-31 06:17:36,367 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4059916992982229, 'Total loss': 0.4059916992982229} | train loss {'Reaction outcome loss': 0.10851689772545915, 'Total loss': 0.10851689772545915}
2022-12-31 06:17:36,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:36,367 INFO:     Epoch: 94
2022-12-31 06:17:38,038 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41178515801827115, 'Total loss': 0.41178515801827115} | train loss {'Reaction outcome loss': 0.1077744816026452, 'Total loss': 0.1077744816026452}
2022-12-31 06:17:38,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:38,038 INFO:     Epoch: 95
2022-12-31 06:17:39,672 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.446214896440506, 'Total loss': 0.446214896440506} | train loss {'Reaction outcome loss': 0.10916173622845958, 'Total loss': 0.10916173622845958}
2022-12-31 06:17:39,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:39,673 INFO:     Epoch: 96
2022-12-31 06:17:41,302 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4535449246565501, 'Total loss': 0.4535449246565501} | train loss {'Reaction outcome loss': 0.11462890489753134, 'Total loss': 0.11462890489753134}
2022-12-31 06:17:41,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:41,302 INFO:     Epoch: 97
2022-12-31 06:17:42,972 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42157475352287294, 'Total loss': 0.42157475352287294} | train loss {'Reaction outcome loss': 0.11189146960550912, 'Total loss': 0.11189146960550912}
2022-12-31 06:17:42,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:42,973 INFO:     Epoch: 98
2022-12-31 06:17:44,601 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4367265462875366, 'Total loss': 0.4367265462875366} | train loss {'Reaction outcome loss': 0.1118285968586204, 'Total loss': 0.1118285968586204}
2022-12-31 06:17:44,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:44,601 INFO:     Epoch: 99
2022-12-31 06:17:46,235 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41660505135854087, 'Total loss': 0.41660505135854087} | train loss {'Reaction outcome loss': 0.10929831565989834, 'Total loss': 0.10929831565989834}
2022-12-31 06:17:46,235 INFO:     Best model found after epoch 24 of 100.
2022-12-31 06:17:46,236 INFO:   Done with stage: TRAINING
2022-12-31 06:17:46,236 INFO:   Starting stage: EVALUATION
2022-12-31 06:17:46,359 INFO:   Done with stage: EVALUATION
2022-12-31 06:17:46,359 INFO:   Leaving out SEQ value Fold_9
2022-12-31 06:17:46,371 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:17:46,372 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:17:47,010 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:17:47,010 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:17:47,080 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:17:47,080 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:17:47,080 INFO:     No hyperparam tuning for this model
2022-12-31 06:17:47,080 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:17:47,080 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:17:47,081 INFO:     None feature selector for col prot
2022-12-31 06:17:47,081 INFO:     None feature selector for col prot
2022-12-31 06:17:47,081 INFO:     None feature selector for col prot
2022-12-31 06:17:47,081 INFO:     None feature selector for col chem
2022-12-31 06:17:47,081 INFO:     None feature selector for col chem
2022-12-31 06:17:47,082 INFO:     None feature selector for col chem
2022-12-31 06:17:47,082 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:17:47,082 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:17:47,084 INFO:     Number of params in model 224011
2022-12-31 06:17:47,087 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:17:47,087 INFO:   Starting stage: TRAINING
2022-12-31 06:17:47,132 INFO:     Val loss before train {'Reaction outcome loss': 0.959437092145284, 'Total loss': 0.959437092145284}
2022-12-31 06:17:47,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:47,132 INFO:     Epoch: 0
2022-12-31 06:17:48,741 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5459064265092214, 'Total loss': 0.5459064265092214} | train loss {'Reaction outcome loss': 0.7975191961239724, 'Total loss': 0.7975191961239724}
2022-12-31 06:17:48,741 INFO:     Found new best model at epoch 0
2022-12-31 06:17:48,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:48,742 INFO:     Epoch: 1
2022-12-31 06:17:50,346 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48400853474934896, 'Total loss': 0.48400853474934896} | train loss {'Reaction outcome loss': 0.5176012507864158, 'Total loss': 0.5176012507864158}
2022-12-31 06:17:50,347 INFO:     Found new best model at epoch 1
2022-12-31 06:17:50,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:50,348 INFO:     Epoch: 2
2022-12-31 06:17:51,957 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4356804351011912, 'Total loss': 0.4356804351011912} | train loss {'Reaction outcome loss': 0.44538791091555224, 'Total loss': 0.44538791091555224}
2022-12-31 06:17:51,958 INFO:     Found new best model at epoch 2
2022-12-31 06:17:51,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:51,959 INFO:     Epoch: 3
2022-12-31 06:17:53,564 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42787734071413674, 'Total loss': 0.42787734071413674} | train loss {'Reaction outcome loss': 0.40443221890252, 'Total loss': 0.40443221890252}
2022-12-31 06:17:53,564 INFO:     Found new best model at epoch 3
2022-12-31 06:17:53,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:53,565 INFO:     Epoch: 4
2022-12-31 06:17:55,187 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40669192870457965, 'Total loss': 0.40669192870457965} | train loss {'Reaction outcome loss': 0.37213264188192186, 'Total loss': 0.37213264188192186}
2022-12-31 06:17:55,187 INFO:     Found new best model at epoch 4
2022-12-31 06:17:55,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:55,188 INFO:     Epoch: 5
2022-12-31 06:17:56,804 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4291702558596929, 'Total loss': 0.4291702558596929} | train loss {'Reaction outcome loss': 0.3471127709333044, 'Total loss': 0.3471127709333044}
2022-12-31 06:17:56,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:56,804 INFO:     Epoch: 6
2022-12-31 06:17:58,413 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4436439315478007, 'Total loss': 0.4436439315478007} | train loss {'Reaction outcome loss': 0.32633995338186733, 'Total loss': 0.32633995338186733}
2022-12-31 06:17:58,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:17:58,413 INFO:     Epoch: 7
2022-12-31 06:18:00,031 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3988413155078888, 'Total loss': 0.3988413155078888} | train loss {'Reaction outcome loss': 0.30738013599367037, 'Total loss': 0.30738013599367037}
2022-12-31 06:18:00,031 INFO:     Found new best model at epoch 7
2022-12-31 06:18:00,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:00,032 INFO:     Epoch: 8
2022-12-31 06:18:01,648 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4040654261906942, 'Total loss': 0.4040654261906942} | train loss {'Reaction outcome loss': 0.2897998409712837, 'Total loss': 0.2897998409712837}
2022-12-31 06:18:01,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:01,648 INFO:     Epoch: 9
2022-12-31 06:18:03,289 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3935002287228902, 'Total loss': 0.3935002287228902} | train loss {'Reaction outcome loss': 0.28197715379787186, 'Total loss': 0.28197715379787186}
2022-12-31 06:18:03,289 INFO:     Found new best model at epoch 9
2022-12-31 06:18:03,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:03,290 INFO:     Epoch: 10
2022-12-31 06:18:04,896 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41268473366896313, 'Total loss': 0.41268473366896313} | train loss {'Reaction outcome loss': 0.2677558787357416, 'Total loss': 0.2677558787357416}
2022-12-31 06:18:04,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:04,897 INFO:     Epoch: 11
2022-12-31 06:18:06,534 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4077629258235296, 'Total loss': 0.4077629258235296} | train loss {'Reaction outcome loss': 0.2560247593443759, 'Total loss': 0.2560247593443759}
2022-12-31 06:18:06,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:06,534 INFO:     Epoch: 12
2022-12-31 06:18:08,151 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39022357563177745, 'Total loss': 0.39022357563177745} | train loss {'Reaction outcome loss': 0.2464057889760193, 'Total loss': 0.2464057889760193}
2022-12-31 06:18:08,153 INFO:     Found new best model at epoch 12
2022-12-31 06:18:08,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:08,154 INFO:     Epoch: 13
2022-12-31 06:18:09,768 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3874608198801676, 'Total loss': 0.3874608198801676} | train loss {'Reaction outcome loss': 0.23885314186939793, 'Total loss': 0.23885314186939793}
2022-12-31 06:18:09,768 INFO:     Found new best model at epoch 13
2022-12-31 06:18:09,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:09,769 INFO:     Epoch: 14
2022-12-31 06:18:11,386 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3753488620122274, 'Total loss': 0.3753488620122274} | train loss {'Reaction outcome loss': 0.2294986175821863, 'Total loss': 0.2294986175821863}
2022-12-31 06:18:11,386 INFO:     Found new best model at epoch 14
2022-12-31 06:18:11,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:11,387 INFO:     Epoch: 15
2022-12-31 06:18:12,994 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38528170784314475, 'Total loss': 0.38528170784314475} | train loss {'Reaction outcome loss': 0.2205873670967391, 'Total loss': 0.2205873670967391}
2022-12-31 06:18:12,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:12,994 INFO:     Epoch: 16
2022-12-31 06:18:14,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3897594600915909, 'Total loss': 0.3897594600915909} | train loss {'Reaction outcome loss': 0.21286721881071147, 'Total loss': 0.21286721881071147}
2022-12-31 06:18:14,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:14,612 INFO:     Epoch: 17
2022-12-31 06:18:16,219 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4020509372154872, 'Total loss': 0.4020509372154872} | train loss {'Reaction outcome loss': 0.20637449752675355, 'Total loss': 0.20637449752675355}
2022-12-31 06:18:16,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:16,219 INFO:     Epoch: 18
2022-12-31 06:18:17,826 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41736137866973877, 'Total loss': 0.41736137866973877} | train loss {'Reaction outcome loss': 0.1976282944508495, 'Total loss': 0.1976282944508495}
2022-12-31 06:18:17,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:17,827 INFO:     Epoch: 19
2022-12-31 06:18:19,434 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37796706010897957, 'Total loss': 0.37796706010897957} | train loss {'Reaction outcome loss': 0.1963264752233768, 'Total loss': 0.1963264752233768}
2022-12-31 06:18:19,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:19,434 INFO:     Epoch: 20
2022-12-31 06:18:21,049 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3791447828213374, 'Total loss': 0.3791447828213374} | train loss {'Reaction outcome loss': 0.19207013324650862, 'Total loss': 0.19207013324650862}
2022-12-31 06:18:21,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:21,050 INFO:     Epoch: 21
2022-12-31 06:18:22,655 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41562284926573434, 'Total loss': 0.41562284926573434} | train loss {'Reaction outcome loss': 0.18901044842753098, 'Total loss': 0.18901044842753098}
2022-12-31 06:18:22,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:22,656 INFO:     Epoch: 22
2022-12-31 06:18:24,271 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45746736526489257, 'Total loss': 0.45746736526489257} | train loss {'Reaction outcome loss': 0.18037680342766274, 'Total loss': 0.18037680342766274}
2022-12-31 06:18:24,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:24,272 INFO:     Epoch: 23
2022-12-31 06:18:25,878 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4043298085530599, 'Total loss': 0.4043298085530599} | train loss {'Reaction outcome loss': 0.18026436329989212, 'Total loss': 0.18026436329989212}
2022-12-31 06:18:25,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:25,878 INFO:     Epoch: 24
2022-12-31 06:18:27,494 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3990843007961909, 'Total loss': 0.3990843007961909} | train loss {'Reaction outcome loss': 0.17467394947026768, 'Total loss': 0.17467394947026768}
2022-12-31 06:18:27,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:27,495 INFO:     Epoch: 25
2022-12-31 06:18:29,110 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36244524344801904, 'Total loss': 0.36244524344801904} | train loss {'Reaction outcome loss': 0.16775954604475168, 'Total loss': 0.16775954604475168}
2022-12-31 06:18:29,110 INFO:     Found new best model at epoch 25
2022-12-31 06:18:29,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:29,111 INFO:     Epoch: 26
2022-12-31 06:18:30,716 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42732495864232384, 'Total loss': 0.42732495864232384} | train loss {'Reaction outcome loss': 0.16474817407378642, 'Total loss': 0.16474817407378642}
2022-12-31 06:18:30,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:30,716 INFO:     Epoch: 27
2022-12-31 06:18:32,333 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42233859846989313, 'Total loss': 0.42233859846989313} | train loss {'Reaction outcome loss': 0.16366218311379044, 'Total loss': 0.16366218311379044}
2022-12-31 06:18:32,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:32,333 INFO:     Epoch: 28
2022-12-31 06:18:33,942 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.399577385187149, 'Total loss': 0.399577385187149} | train loss {'Reaction outcome loss': 0.15928070806646652, 'Total loss': 0.15928070806646652}
2022-12-31 06:18:33,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:33,942 INFO:     Epoch: 29
2022-12-31 06:18:35,558 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39663994510968525, 'Total loss': 0.39663994510968525} | train loss {'Reaction outcome loss': 0.16078992248478816, 'Total loss': 0.16078992248478816}
2022-12-31 06:18:35,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:35,559 INFO:     Epoch: 30
2022-12-31 06:18:37,176 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37676564703385035, 'Total loss': 0.37676564703385035} | train loss {'Reaction outcome loss': 0.15720081261026053, 'Total loss': 0.15720081261026053}
2022-12-31 06:18:37,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:37,176 INFO:     Epoch: 31
2022-12-31 06:18:38,795 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38782972743113836, 'Total loss': 0.38782972743113836} | train loss {'Reaction outcome loss': 0.15332203635089373, 'Total loss': 0.15332203635089373}
2022-12-31 06:18:38,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:38,796 INFO:     Epoch: 32
2022-12-31 06:18:40,399 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44537380437056223, 'Total loss': 0.44537380437056223} | train loss {'Reaction outcome loss': 0.15041604059931896, 'Total loss': 0.15041604059931896}
2022-12-31 06:18:40,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:40,399 INFO:     Epoch: 33
2022-12-31 06:18:42,053 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39792282780011495, 'Total loss': 0.39792282780011495} | train loss {'Reaction outcome loss': 0.14778291261041143, 'Total loss': 0.14778291261041143}
2022-12-31 06:18:42,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:42,053 INFO:     Epoch: 34
2022-12-31 06:18:43,665 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3986120671033859, 'Total loss': 0.3986120671033859} | train loss {'Reaction outcome loss': 0.14653495160087834, 'Total loss': 0.14653495160087834}
2022-12-31 06:18:43,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:43,665 INFO:     Epoch: 35
2022-12-31 06:18:45,319 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3859585851430893, 'Total loss': 0.3859585851430893} | train loss {'Reaction outcome loss': 0.14577805665899476, 'Total loss': 0.14577805665899476}
2022-12-31 06:18:45,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:45,320 INFO:     Epoch: 36
2022-12-31 06:18:46,930 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41920802295207976, 'Total loss': 0.41920802295207976} | train loss {'Reaction outcome loss': 0.14351752013593477, 'Total loss': 0.14351752013593477}
2022-12-31 06:18:46,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:46,930 INFO:     Epoch: 37
2022-12-31 06:18:48,583 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39566267331441246, 'Total loss': 0.39566267331441246} | train loss {'Reaction outcome loss': 0.14164423966018932, 'Total loss': 0.14164423966018932}
2022-12-31 06:18:48,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:48,584 INFO:     Epoch: 38
2022-12-31 06:18:50,224 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.372501615434885, 'Total loss': 0.372501615434885} | train loss {'Reaction outcome loss': 0.13933707060577877, 'Total loss': 0.13933707060577877}
2022-12-31 06:18:50,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:50,224 INFO:     Epoch: 39
2022-12-31 06:18:51,831 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41173716882864636, 'Total loss': 0.41173716882864636} | train loss {'Reaction outcome loss': 0.13695470617581024, 'Total loss': 0.13695470617581024}
2022-12-31 06:18:51,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:51,832 INFO:     Epoch: 40
2022-12-31 06:18:53,491 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3985317180554072, 'Total loss': 0.3985317180554072} | train loss {'Reaction outcome loss': 0.13688724101555064, 'Total loss': 0.13688724101555064}
2022-12-31 06:18:53,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:53,491 INFO:     Epoch: 41
2022-12-31 06:18:55,105 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3986189395189285, 'Total loss': 0.3986189395189285} | train loss {'Reaction outcome loss': 0.13201362026233335, 'Total loss': 0.13201362026233335}
2022-12-31 06:18:55,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:55,105 INFO:     Epoch: 42
2022-12-31 06:18:56,720 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39424039125442506, 'Total loss': 0.39424039125442506} | train loss {'Reaction outcome loss': 0.13385887716958014, 'Total loss': 0.13385887716958014}
2022-12-31 06:18:56,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:56,721 INFO:     Epoch: 43
2022-12-31 06:18:58,327 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4153814375400543, 'Total loss': 0.4153814375400543} | train loss {'Reaction outcome loss': 0.13642238823860123, 'Total loss': 0.13642238823860123}
2022-12-31 06:18:58,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:58,327 INFO:     Epoch: 44
2022-12-31 06:18:59,940 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3991446942090988, 'Total loss': 0.3991446942090988} | train loss {'Reaction outcome loss': 0.13633047108178156, 'Total loss': 0.13633047108178156}
2022-12-31 06:18:59,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:18:59,941 INFO:     Epoch: 45
2022-12-31 06:19:01,549 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3857638930281003, 'Total loss': 0.3857638930281003} | train loss {'Reaction outcome loss': 0.13043764278795705, 'Total loss': 0.13043764278795705}
2022-12-31 06:19:01,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:01,549 INFO:     Epoch: 46
2022-12-31 06:19:03,161 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41853234519561133, 'Total loss': 0.41853234519561133} | train loss {'Reaction outcome loss': 0.13007293151263283, 'Total loss': 0.13007293151263283}
2022-12-31 06:19:03,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:03,161 INFO:     Epoch: 47
2022-12-31 06:19:04,773 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4011304040749868, 'Total loss': 0.4011304040749868} | train loss {'Reaction outcome loss': 0.1278735647695207, 'Total loss': 0.1278735647695207}
2022-12-31 06:19:04,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:04,774 INFO:     Epoch: 48
2022-12-31 06:19:06,387 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4273310666282972, 'Total loss': 0.4273310666282972} | train loss {'Reaction outcome loss': 0.12856717019708977, 'Total loss': 0.12856717019708977}
2022-12-31 06:19:06,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:06,387 INFO:     Epoch: 49
2022-12-31 06:19:07,993 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3987543672323227, 'Total loss': 0.3987543672323227} | train loss {'Reaction outcome loss': 0.12902816690259825, 'Total loss': 0.12902816690259825}
2022-12-31 06:19:07,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:07,994 INFO:     Epoch: 50
2022-12-31 06:19:09,608 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3727369785308838, 'Total loss': 0.3727369785308838} | train loss {'Reaction outcome loss': 0.12618820740583006, 'Total loss': 0.12618820740583006}
2022-12-31 06:19:09,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:09,609 INFO:     Epoch: 51
2022-12-31 06:19:11,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4182592689990997, 'Total loss': 0.4182592689990997} | train loss {'Reaction outcome loss': 0.12458763487405912, 'Total loss': 0.12458763487405912}
2022-12-31 06:19:11,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:11,212 INFO:     Epoch: 52
2022-12-31 06:19:12,823 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39856851597627, 'Total loss': 0.39856851597627} | train loss {'Reaction outcome loss': 0.12292973514829837, 'Total loss': 0.12292973514829837}
2022-12-31 06:19:12,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:12,824 INFO:     Epoch: 53
2022-12-31 06:19:14,436 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42913176616032916, 'Total loss': 0.42913176616032916} | train loss {'Reaction outcome loss': 0.12421517608428959, 'Total loss': 0.12421517608428959}
2022-12-31 06:19:14,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:14,437 INFO:     Epoch: 54
2022-12-31 06:19:16,044 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4307615598042806, 'Total loss': 0.4307615598042806} | train loss {'Reaction outcome loss': 0.12201203427780556, 'Total loss': 0.12201203427780556}
2022-12-31 06:19:16,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:16,045 INFO:     Epoch: 55
2022-12-31 06:19:17,643 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41746072272459667, 'Total loss': 0.41746072272459667} | train loss {'Reaction outcome loss': 0.12001959717132314, 'Total loss': 0.12001959717132314}
2022-12-31 06:19:17,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:17,644 INFO:     Epoch: 56
2022-12-31 06:19:19,282 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4135326733191808, 'Total loss': 0.4135326733191808} | train loss {'Reaction outcome loss': 0.11940428566010873, 'Total loss': 0.11940428566010873}
2022-12-31 06:19:19,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:19,283 INFO:     Epoch: 57
2022-12-31 06:19:20,896 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4253215715289116, 'Total loss': 0.4253215715289116} | train loss {'Reaction outcome loss': 0.1209675126155009, 'Total loss': 0.1209675126155009}
2022-12-31 06:19:20,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:20,897 INFO:     Epoch: 58
2022-12-31 06:19:22,510 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37716762721538544, 'Total loss': 0.37716762721538544} | train loss {'Reaction outcome loss': 0.11661494934054459, 'Total loss': 0.11661494934054459}
2022-12-31 06:19:22,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:22,510 INFO:     Epoch: 59
2022-12-31 06:19:24,124 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42754795352617897, 'Total loss': 0.42754795352617897} | train loss {'Reaction outcome loss': 0.11824910530487388, 'Total loss': 0.11824910530487388}
2022-12-31 06:19:24,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:24,124 INFO:     Epoch: 60
2022-12-31 06:19:25,729 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4126288811365763, 'Total loss': 0.4126288811365763} | train loss {'Reaction outcome loss': 0.11881059059791647, 'Total loss': 0.11881059059791647}
2022-12-31 06:19:25,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:25,729 INFO:     Epoch: 61
2022-12-31 06:19:27,344 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41572502901156744, 'Total loss': 0.41572502901156744} | train loss {'Reaction outcome loss': 0.1190244895219123, 'Total loss': 0.1190244895219123}
2022-12-31 06:19:27,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:27,344 INFO:     Epoch: 62
2022-12-31 06:19:28,964 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41487242877483366, 'Total loss': 0.41487242877483366} | train loss {'Reaction outcome loss': 0.11634218925355261, 'Total loss': 0.11634218925355261}
2022-12-31 06:19:28,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:28,965 INFO:     Epoch: 63
2022-12-31 06:19:30,572 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40430961847305297, 'Total loss': 0.40430961847305297} | train loss {'Reaction outcome loss': 0.12083886743584363, 'Total loss': 0.12083886743584363}
2022-12-31 06:19:30,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:30,572 INFO:     Epoch: 64
2022-12-31 06:19:32,183 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4025669942299525, 'Total loss': 0.4025669942299525} | train loss {'Reaction outcome loss': 0.12044479576513906, 'Total loss': 0.12044479576513906}
2022-12-31 06:19:32,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:32,183 INFO:     Epoch: 65
2022-12-31 06:19:33,792 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43142800430456796, 'Total loss': 0.43142800430456796} | train loss {'Reaction outcome loss': 0.11458936148581442, 'Total loss': 0.11458936148581442}
2022-12-31 06:19:33,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:33,792 INFO:     Epoch: 66
2022-12-31 06:19:35,400 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.477772910396258, 'Total loss': 0.477772910396258} | train loss {'Reaction outcome loss': 0.11637778388060983, 'Total loss': 0.11637778388060983}
2022-12-31 06:19:35,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:35,400 INFO:     Epoch: 67
2022-12-31 06:19:37,063 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38191782832145693, 'Total loss': 0.38191782832145693} | train loss {'Reaction outcome loss': 0.11369552973990947, 'Total loss': 0.11369552973990947}
2022-12-31 06:19:37,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:37,064 INFO:     Epoch: 68
2022-12-31 06:19:38,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3735278531908989, 'Total loss': 0.3735278531908989} | train loss {'Reaction outcome loss': 0.11091822902264115, 'Total loss': 0.11091822902264115}
2022-12-31 06:19:38,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:38,678 INFO:     Epoch: 69
2022-12-31 06:19:40,291 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4115904629230499, 'Total loss': 0.4115904629230499} | train loss {'Reaction outcome loss': 0.1140775295589663, 'Total loss': 0.1140775295589663}
2022-12-31 06:19:40,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:40,292 INFO:     Epoch: 70
2022-12-31 06:19:41,906 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43503741125265755, 'Total loss': 0.43503741125265755} | train loss {'Reaction outcome loss': 0.11110001884869905, 'Total loss': 0.11110001884869905}
2022-12-31 06:19:41,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:41,906 INFO:     Epoch: 71
2022-12-31 06:19:43,521 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43000959356625873, 'Total loss': 0.43000959356625873} | train loss {'Reaction outcome loss': 0.11560056638312492, 'Total loss': 0.11560056638312492}
2022-12-31 06:19:43,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:43,522 INFO:     Epoch: 72
2022-12-31 06:19:45,136 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43908632223804794, 'Total loss': 0.43908632223804794} | train loss {'Reaction outcome loss': 0.11319954413750692, 'Total loss': 0.11319954413750692}
2022-12-31 06:19:45,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:45,136 INFO:     Epoch: 73
2022-12-31 06:19:46,746 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38530673533678056, 'Total loss': 0.38530673533678056} | train loss {'Reaction outcome loss': 0.11454086354253881, 'Total loss': 0.11454086354253881}
2022-12-31 06:19:46,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:46,747 INFO:     Epoch: 74
2022-12-31 06:19:48,367 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4094015051921209, 'Total loss': 0.4094015051921209} | train loss {'Reaction outcome loss': 0.11053516997031215, 'Total loss': 0.11053516997031215}
2022-12-31 06:19:48,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:48,367 INFO:     Epoch: 75
2022-12-31 06:19:49,986 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44416311035553613, 'Total loss': 0.44416311035553613} | train loss {'Reaction outcome loss': 0.10932680788062459, 'Total loss': 0.10932680788062459}
2022-12-31 06:19:49,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:49,987 INFO:     Epoch: 76
2022-12-31 06:19:51,605 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40170978009700775, 'Total loss': 0.40170978009700775} | train loss {'Reaction outcome loss': 0.1096943706141472, 'Total loss': 0.1096943706141472}
2022-12-31 06:19:51,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:51,606 INFO:     Epoch: 77
2022-12-31 06:19:53,229 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4232624590396881, 'Total loss': 0.4232624590396881} | train loss {'Reaction outcome loss': 0.11246644340482724, 'Total loss': 0.11246644340482724}
2022-12-31 06:19:53,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:53,229 INFO:     Epoch: 78
2022-12-31 06:19:54,881 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43236180146535236, 'Total loss': 0.43236180146535236} | train loss {'Reaction outcome loss': 0.11640350864418395, 'Total loss': 0.11640350864418395}
2022-12-31 06:19:54,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:54,881 INFO:     Epoch: 79
2022-12-31 06:19:56,481 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41473223666350045, 'Total loss': 0.41473223666350045} | train loss {'Reaction outcome loss': 0.11022237998715527, 'Total loss': 0.11022237998715527}
2022-12-31 06:19:56,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:56,482 INFO:     Epoch: 80
2022-12-31 06:19:58,088 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4305101916193962, 'Total loss': 0.4305101916193962} | train loss {'Reaction outcome loss': 0.1105957052748596, 'Total loss': 0.1105957052748596}
2022-12-31 06:19:58,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:58,089 INFO:     Epoch: 81
2022-12-31 06:19:59,740 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42442914893229805, 'Total loss': 0.42442914893229805} | train loss {'Reaction outcome loss': 0.10983803440871084, 'Total loss': 0.10983803440871084}
2022-12-31 06:19:59,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:19:59,741 INFO:     Epoch: 82
2022-12-31 06:20:01,346 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41380023608605065, 'Total loss': 0.41380023608605065} | train loss {'Reaction outcome loss': 0.11283462311066415, 'Total loss': 0.11283462311066415}
2022-12-31 06:20:01,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:01,346 INFO:     Epoch: 83
2022-12-31 06:20:02,959 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3995998094479243, 'Total loss': 0.3995998094479243} | train loss {'Reaction outcome loss': 0.108068011711304, 'Total loss': 0.108068011711304}
2022-12-31 06:20:02,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:02,960 INFO:     Epoch: 84
2022-12-31 06:20:04,578 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4073168555895487, 'Total loss': 0.4073168555895487} | train loss {'Reaction outcome loss': 0.10851139532755652, 'Total loss': 0.10851139532755652}
2022-12-31 06:20:04,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:04,578 INFO:     Epoch: 85
2022-12-31 06:20:06,223 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.403470445300142, 'Total loss': 0.403470445300142} | train loss {'Reaction outcome loss': 0.10877753507573647, 'Total loss': 0.10877753507573647}
2022-12-31 06:20:06,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:06,223 INFO:     Epoch: 86
2022-12-31 06:20:07,831 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4152831961711248, 'Total loss': 0.4152831961711248} | train loss {'Reaction outcome loss': 0.10863997427794239, 'Total loss': 0.10863997427794239}
2022-12-31 06:20:07,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:07,832 INFO:     Epoch: 87
2022-12-31 06:20:09,486 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3893359368046125, 'Total loss': 0.3893359368046125} | train loss {'Reaction outcome loss': 0.11394651065730102, 'Total loss': 0.11394651065730102}
2022-12-31 06:20:09,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:09,487 INFO:     Epoch: 88
2022-12-31 06:20:11,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46316562294960023, 'Total loss': 0.46316562294960023} | train loss {'Reaction outcome loss': 0.10653713171414514, 'Total loss': 0.10653713171414514}
2022-12-31 06:20:11,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:11,130 INFO:     Epoch: 89
2022-12-31 06:20:12,783 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39789113303025564, 'Total loss': 0.39789113303025564} | train loss {'Reaction outcome loss': 0.1079740789447007, 'Total loss': 0.1079740789447007}
2022-12-31 06:20:12,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:12,783 INFO:     Epoch: 90
2022-12-31 06:20:14,426 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40664329131444293, 'Total loss': 0.40664329131444293} | train loss {'Reaction outcome loss': 0.10741451898730789, 'Total loss': 0.10741451898730789}
2022-12-31 06:20:14,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:14,426 INFO:     Epoch: 91
2022-12-31 06:20:16,032 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4244354675213496, 'Total loss': 0.4244354675213496} | train loss {'Reaction outcome loss': 0.10830645851219875, 'Total loss': 0.10830645851219875}
2022-12-31 06:20:16,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:16,033 INFO:     Epoch: 92
2022-12-31 06:20:17,638 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4331958323717117, 'Total loss': 0.4331958323717117} | train loss {'Reaction outcome loss': 0.10619767868031414, 'Total loss': 0.10619767868031414}
2022-12-31 06:20:17,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:17,639 INFO:     Epoch: 93
2022-12-31 06:20:19,292 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4310530255238215, 'Total loss': 0.4310530255238215} | train loss {'Reaction outcome loss': 0.10436271240146164, 'Total loss': 0.10436271240146164}
2022-12-31 06:20:19,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:19,292 INFO:     Epoch: 94
2022-12-31 06:20:20,911 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40256434182326, 'Total loss': 0.40256434182326} | train loss {'Reaction outcome loss': 0.10874329715708855, 'Total loss': 0.10874329715708855}
2022-12-31 06:20:20,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:20,911 INFO:     Epoch: 95
2022-12-31 06:20:22,565 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4296569307645162, 'Total loss': 0.4296569307645162} | train loss {'Reaction outcome loss': 0.10894830984974375, 'Total loss': 0.10894830984974375}
2022-12-31 06:20:22,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:22,565 INFO:     Epoch: 96
2022-12-31 06:20:24,176 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45132028857866924, 'Total loss': 0.45132028857866924} | train loss {'Reaction outcome loss': 0.10687758416331707, 'Total loss': 0.10687758416331707}
2022-12-31 06:20:24,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:24,176 INFO:     Epoch: 97
2022-12-31 06:20:25,829 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3968283548951149, 'Total loss': 0.3968283548951149} | train loss {'Reaction outcome loss': 0.10765581336688168, 'Total loss': 0.10765581336688168}
2022-12-31 06:20:25,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:25,830 INFO:     Epoch: 98
2022-12-31 06:20:27,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3996482158700625, 'Total loss': 0.3996482158700625} | train loss {'Reaction outcome loss': 0.10782368095374129, 'Total loss': 0.10782368095374129}
2022-12-31 06:20:27,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:27,439 INFO:     Epoch: 99
2022-12-31 06:20:29,046 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38963135158022244, 'Total loss': 0.38963135158022244} | train loss {'Reaction outcome loss': 0.10487064716480944, 'Total loss': 0.10487064716480944}
2022-12-31 06:20:29,046 INFO:     Best model found after epoch 26 of 100.
2022-12-31 06:20:29,046 INFO:   Done with stage: TRAINING
2022-12-31 06:20:29,046 INFO:   Starting stage: EVALUATION
2022-12-31 06:20:29,180 INFO:   Done with stage: EVALUATION
2022-12-31 06:20:29,188 INFO:   Leaving out SEQ value Fold_0
2022-12-31 06:20:29,201 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:20:29,201 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:20:29,845 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:20:29,845 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:20:29,916 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:20:29,916 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:20:29,916 INFO:     No hyperparam tuning for this model
2022-12-31 06:20:29,916 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:20:29,916 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:20:29,917 INFO:     None feature selector for col prot
2022-12-31 06:20:29,917 INFO:     None feature selector for col prot
2022-12-31 06:20:29,917 INFO:     None feature selector for col prot
2022-12-31 06:20:29,917 INFO:     None feature selector for col chem
2022-12-31 06:20:29,918 INFO:     None feature selector for col chem
2022-12-31 06:20:29,918 INFO:     None feature selector for col chem
2022-12-31 06:20:29,918 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:20:29,918 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:20:29,920 INFO:     Number of params in model 224011
2022-12-31 06:20:29,923 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:20:29,923 INFO:   Starting stage: TRAINING
2022-12-31 06:20:29,967 INFO:     Val loss before train {'Reaction outcome loss': 1.079469652970632, 'Total loss': 1.079469652970632}
2022-12-31 06:20:29,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:29,968 INFO:     Epoch: 0
2022-12-31 06:20:31,575 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6315378745396932, 'Total loss': 0.6315378745396932} | train loss {'Reaction outcome loss': 0.761952773389155, 'Total loss': 0.761952773389155}
2022-12-31 06:20:31,576 INFO:     Found new best model at epoch 0
2022-12-31 06:20:31,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:31,577 INFO:     Epoch: 1
2022-12-31 06:20:33,191 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5317109902699788, 'Total loss': 0.5317109902699788} | train loss {'Reaction outcome loss': 0.49858499497827824, 'Total loss': 0.49858499497827824}
2022-12-31 06:20:33,191 INFO:     Found new best model at epoch 1
2022-12-31 06:20:33,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:33,192 INFO:     Epoch: 2
2022-12-31 06:20:34,807 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5110580186049144, 'Total loss': 0.5110580186049144} | train loss {'Reaction outcome loss': 0.4256969679989954, 'Total loss': 0.4256969679989954}
2022-12-31 06:20:34,808 INFO:     Found new best model at epoch 2
2022-12-31 06:20:34,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:34,810 INFO:     Epoch: 3
2022-12-31 06:20:36,468 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5410868446032207, 'Total loss': 0.5410868446032207} | train loss {'Reaction outcome loss': 0.3835677179868204, 'Total loss': 0.3835677179868204}
2022-12-31 06:20:36,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:36,468 INFO:     Epoch: 4
2022-12-31 06:20:38,108 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4915120253960292, 'Total loss': 0.4915120253960292} | train loss {'Reaction outcome loss': 0.36047616048994724, 'Total loss': 0.36047616048994724}
2022-12-31 06:20:38,108 INFO:     Found new best model at epoch 4
2022-12-31 06:20:38,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:38,109 INFO:     Epoch: 5
2022-12-31 06:20:39,726 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4958321670691172, 'Total loss': 0.4958321670691172} | train loss {'Reaction outcome loss': 0.3347211659607226, 'Total loss': 0.3347211659607226}
2022-12-31 06:20:39,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:39,726 INFO:     Epoch: 6
2022-12-31 06:20:41,339 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4698438545068105, 'Total loss': 0.4698438545068105} | train loss {'Reaction outcome loss': 0.3168316158690374, 'Total loss': 0.3168316158690374}
2022-12-31 06:20:41,339 INFO:     Found new best model at epoch 6
2022-12-31 06:20:41,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:41,340 INFO:     Epoch: 7
2022-12-31 06:20:42,951 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4689935505390167, 'Total loss': 0.4689935505390167} | train loss {'Reaction outcome loss': 0.29829445984350506, 'Total loss': 0.29829445984350506}
2022-12-31 06:20:42,951 INFO:     Found new best model at epoch 7
2022-12-31 06:20:42,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:42,952 INFO:     Epoch: 8
2022-12-31 06:20:44,562 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4598029951254527, 'Total loss': 0.4598029951254527} | train loss {'Reaction outcome loss': 0.28814267552029477, 'Total loss': 0.28814267552029477}
2022-12-31 06:20:44,562 INFO:     Found new best model at epoch 8
2022-12-31 06:20:44,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:44,563 INFO:     Epoch: 9
2022-12-31 06:20:46,174 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46263762513796486, 'Total loss': 0.46263762513796486} | train loss {'Reaction outcome loss': 0.2725213672965765, 'Total loss': 0.2725213672965765}
2022-12-31 06:20:46,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:46,174 INFO:     Epoch: 10
2022-12-31 06:20:47,796 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4504735991358757, 'Total loss': 0.4504735991358757} | train loss {'Reaction outcome loss': 0.2601319665809835, 'Total loss': 0.2601319665809835}
2022-12-31 06:20:47,796 INFO:     Found new best model at epoch 10
2022-12-31 06:20:47,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:47,797 INFO:     Epoch: 11
2022-12-31 06:20:49,401 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47670577665170033, 'Total loss': 0.47670577665170033} | train loss {'Reaction outcome loss': 0.2502871588633878, 'Total loss': 0.2502871588633878}
2022-12-31 06:20:49,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:49,401 INFO:     Epoch: 12
2022-12-31 06:20:51,020 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49668131619691847, 'Total loss': 0.49668131619691847} | train loss {'Reaction outcome loss': 0.2361755380882834, 'Total loss': 0.2361755380882834}
2022-12-31 06:20:51,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:51,020 INFO:     Epoch: 13
2022-12-31 06:20:52,637 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47728207310040793, 'Total loss': 0.47728207310040793} | train loss {'Reaction outcome loss': 0.23115062580382736, 'Total loss': 0.23115062580382736}
2022-12-31 06:20:52,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:52,637 INFO:     Epoch: 14
2022-12-31 06:20:54,254 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5137544711430867, 'Total loss': 0.5137544711430867} | train loss {'Reaction outcome loss': 0.22318890807728697, 'Total loss': 0.22318890807728697}
2022-12-31 06:20:54,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:54,254 INFO:     Epoch: 15
2022-12-31 06:20:55,871 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4907966464757919, 'Total loss': 0.4907966464757919} | train loss {'Reaction outcome loss': 0.2185016007291792, 'Total loss': 0.2185016007291792}
2022-12-31 06:20:55,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:55,871 INFO:     Epoch: 16
2022-12-31 06:20:57,479 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4931983242432276, 'Total loss': 0.4931983242432276} | train loss {'Reaction outcome loss': 0.2067833841730752, 'Total loss': 0.2067833841730752}
2022-12-31 06:20:57,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:57,481 INFO:     Epoch: 17
2022-12-31 06:20:59,094 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5125042428572972, 'Total loss': 0.5125042428572972} | train loss {'Reaction outcome loss': 0.20075982216283353, 'Total loss': 0.20075982216283353}
2022-12-31 06:20:59,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:20:59,094 INFO:     Epoch: 18
2022-12-31 06:21:00,704 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5277074446280797, 'Total loss': 0.5277074446280797} | train loss {'Reaction outcome loss': 0.19813320539674184, 'Total loss': 0.19813320539674184}
2022-12-31 06:21:00,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:00,704 INFO:     Epoch: 19
2022-12-31 06:21:02,320 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5330669363339742, 'Total loss': 0.5330669363339742} | train loss {'Reaction outcome loss': 0.19000320755162814, 'Total loss': 0.19000320755162814}
2022-12-31 06:21:02,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:02,320 INFO:     Epoch: 20
2022-12-31 06:21:03,934 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5312511046727498, 'Total loss': 0.5312511046727498} | train loss {'Reaction outcome loss': 0.1872105796406739, 'Total loss': 0.1872105796406739}
2022-12-31 06:21:03,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:03,935 INFO:     Epoch: 21
2022-12-31 06:21:05,539 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4866378645102183, 'Total loss': 0.4866378645102183} | train loss {'Reaction outcome loss': 0.18287087323647128, 'Total loss': 0.18287087323647128}
2022-12-31 06:21:05,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:05,539 INFO:     Epoch: 22
2022-12-31 06:21:07,156 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49401839872201286, 'Total loss': 0.49401839872201286} | train loss {'Reaction outcome loss': 0.1779153162110461, 'Total loss': 0.1779153162110461}
2022-12-31 06:21:07,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:07,156 INFO:     Epoch: 23
2022-12-31 06:21:08,760 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5050420651833216, 'Total loss': 0.5050420651833216} | train loss {'Reaction outcome loss': 0.17386038422951625, 'Total loss': 0.17386038422951625}
2022-12-31 06:21:08,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:08,760 INFO:     Epoch: 24
2022-12-31 06:21:10,413 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5246790885925293, 'Total loss': 0.5246790885925293} | train loss {'Reaction outcome loss': 0.16824947200362048, 'Total loss': 0.16824947200362048}
2022-12-31 06:21:10,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:10,413 INFO:     Epoch: 25
2022-12-31 06:21:12,021 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5495585779349009, 'Total loss': 0.5495585779349009} | train loss {'Reaction outcome loss': 0.16559282869753175, 'Total loss': 0.16559282869753175}
2022-12-31 06:21:12,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:12,022 INFO:     Epoch: 26
2022-12-31 06:21:13,628 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5417706708113352, 'Total loss': 0.5417706708113352} | train loss {'Reaction outcome loss': 0.16050199499816029, 'Total loss': 0.16050199499816029}
2022-12-31 06:21:13,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:13,628 INFO:     Epoch: 27
2022-12-31 06:21:15,247 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5317409435907999, 'Total loss': 0.5317409435907999} | train loss {'Reaction outcome loss': 0.16003672701449398, 'Total loss': 0.16003672701449398}
2022-12-31 06:21:15,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:15,247 INFO:     Epoch: 28
2022-12-31 06:21:16,901 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5395262976487477, 'Total loss': 0.5395262976487477} | train loss {'Reaction outcome loss': 0.1633369718256821, 'Total loss': 0.1633369718256821}
2022-12-31 06:21:16,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:16,901 INFO:     Epoch: 29
2022-12-31 06:21:18,513 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5112900257110595, 'Total loss': 0.5112900257110595} | train loss {'Reaction outcome loss': 0.15618757186049637, 'Total loss': 0.15618757186049637}
2022-12-31 06:21:18,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:18,513 INFO:     Epoch: 30
2022-12-31 06:21:20,166 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5112438976764679, 'Total loss': 0.5112438976764679} | train loss {'Reaction outcome loss': 0.15021636451247836, 'Total loss': 0.15021636451247836}
2022-12-31 06:21:20,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:20,166 INFO:     Epoch: 31
2022-12-31 06:21:21,819 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5334018031756084, 'Total loss': 0.5334018031756084} | train loss {'Reaction outcome loss': 0.154852255470167, 'Total loss': 0.154852255470167}
2022-12-31 06:21:21,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:21,819 INFO:     Epoch: 32
2022-12-31 06:21:23,472 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5585425434013208, 'Total loss': 0.5585425434013208} | train loss {'Reaction outcome loss': 0.1491256266438069, 'Total loss': 0.1491256266438069}
2022-12-31 06:21:23,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:23,472 INFO:     Epoch: 33
2022-12-31 06:21:25,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5542967855930329, 'Total loss': 0.5542967855930329} | train loss {'Reaction outcome loss': 0.14791637216524703, 'Total loss': 0.14791637216524703}
2022-12-31 06:21:25,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:25,076 INFO:     Epoch: 34
2022-12-31 06:21:26,713 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5560648322105408, 'Total loss': 0.5560648322105408} | train loss {'Reaction outcome loss': 0.14660406100094645, 'Total loss': 0.14660406100094645}
2022-12-31 06:21:26,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:26,713 INFO:     Epoch: 35
2022-12-31 06:21:28,329 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5202477266391118, 'Total loss': 0.5202477266391118} | train loss {'Reaction outcome loss': 0.14552200630810247, 'Total loss': 0.14552200630810247}
2022-12-31 06:21:28,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:28,331 INFO:     Epoch: 36
2022-12-31 06:21:29,946 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5572182595729828, 'Total loss': 0.5572182595729828} | train loss {'Reaction outcome loss': 0.14448973761334416, 'Total loss': 0.14448973761334416}
2022-12-31 06:21:29,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:29,946 INFO:     Epoch: 37
2022-12-31 06:21:31,566 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5863614628712336, 'Total loss': 0.5863614628712336} | train loss {'Reaction outcome loss': 0.14493766914624856, 'Total loss': 0.14493766914624856}
2022-12-31 06:21:31,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:31,566 INFO:     Epoch: 38
2022-12-31 06:21:33,177 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5552085747321447, 'Total loss': 0.5552085747321447} | train loss {'Reaction outcome loss': 0.140570102862837, 'Total loss': 0.140570102862837}
2022-12-31 06:21:33,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:33,178 INFO:     Epoch: 39
2022-12-31 06:21:34,789 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5432244112094243, 'Total loss': 0.5432244112094243} | train loss {'Reaction outcome loss': 0.1388164455220647, 'Total loss': 0.1388164455220647}
2022-12-31 06:21:34,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:34,790 INFO:     Epoch: 40
2022-12-31 06:21:36,397 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5550415297349294, 'Total loss': 0.5550415297349294} | train loss {'Reaction outcome loss': 0.13925931003814848, 'Total loss': 0.13925931003814848}
2022-12-31 06:21:36,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:36,398 INFO:     Epoch: 41
2022-12-31 06:21:38,015 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5228659396370252, 'Total loss': 0.5228659396370252} | train loss {'Reaction outcome loss': 0.14152511038620325, 'Total loss': 0.14152511038620325}
2022-12-31 06:21:38,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:38,016 INFO:     Epoch: 42
2022-12-31 06:21:39,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5532567242781321, 'Total loss': 0.5532567242781321} | train loss {'Reaction outcome loss': 0.13648645039036, 'Total loss': 0.13648645039036}
2022-12-31 06:21:39,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:39,634 INFO:     Epoch: 43
2022-12-31 06:21:41,250 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5518536269664764, 'Total loss': 0.5518536269664764} | train loss {'Reaction outcome loss': 0.1343285015777406, 'Total loss': 0.1343285015777406}
2022-12-31 06:21:41,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:41,250 INFO:     Epoch: 44
2022-12-31 06:21:42,877 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5493581394354502, 'Total loss': 0.5493581394354502} | train loss {'Reaction outcome loss': 0.13335598285231795, 'Total loss': 0.13335598285231795}
2022-12-31 06:21:42,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:42,877 INFO:     Epoch: 45
2022-12-31 06:21:44,485 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5374209324518839, 'Total loss': 0.5374209324518839} | train loss {'Reaction outcome loss': 0.13285502565032156, 'Total loss': 0.13285502565032156}
2022-12-31 06:21:44,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:44,486 INFO:     Epoch: 46
2022-12-31 06:21:46,124 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5510609110196432, 'Total loss': 0.5510609110196432} | train loss {'Reaction outcome loss': 0.13096827351620732, 'Total loss': 0.13096827351620732}
2022-12-31 06:21:46,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:46,125 INFO:     Epoch: 47
2022-12-31 06:21:47,733 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5456848074992497, 'Total loss': 0.5456848074992497} | train loss {'Reaction outcome loss': 0.13173772933056754, 'Total loss': 0.13173772933056754}
2022-12-31 06:21:47,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:47,734 INFO:     Epoch: 48
2022-12-31 06:21:49,341 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5185864533763379, 'Total loss': 0.5185864533763379} | train loss {'Reaction outcome loss': 0.12891465563150326, 'Total loss': 0.12891465563150326}
2022-12-31 06:21:49,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:49,341 INFO:     Epoch: 49
2022-12-31 06:21:50,990 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5170743415753046, 'Total loss': 0.5170743415753046} | train loss {'Reaction outcome loss': 0.1305861910023339, 'Total loss': 0.1305861910023339}
2022-12-31 06:21:50,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:50,991 INFO:     Epoch: 50
2022-12-31 06:21:52,598 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5299090365568797, 'Total loss': 0.5299090365568797} | train loss {'Reaction outcome loss': 0.12716668029825617, 'Total loss': 0.12716668029825617}
2022-12-31 06:21:52,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:52,598 INFO:     Epoch: 51
2022-12-31 06:21:54,205 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5273157825072606, 'Total loss': 0.5273157825072606} | train loss {'Reaction outcome loss': 0.12788582670699505, 'Total loss': 0.12788582670699505}
2022-12-31 06:21:54,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:54,205 INFO:     Epoch: 52
2022-12-31 06:21:55,822 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5460933317740758, 'Total loss': 0.5460933317740758} | train loss {'Reaction outcome loss': 0.13024132775931355, 'Total loss': 0.13024132775931355}
2022-12-31 06:21:55,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:55,822 INFO:     Epoch: 53
2022-12-31 06:21:57,438 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5575111170609792, 'Total loss': 0.5575111170609792} | train loss {'Reaction outcome loss': 0.1244375214990174, 'Total loss': 0.1244375214990174}
2022-12-31 06:21:57,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:57,438 INFO:     Epoch: 54
2022-12-31 06:21:59,055 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5238703986008962, 'Total loss': 0.5238703986008962} | train loss {'Reaction outcome loss': 0.12223068874390511, 'Total loss': 0.12223068874390511}
2022-12-31 06:21:59,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:21:59,056 INFO:     Epoch: 55
2022-12-31 06:22:00,672 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5479923347632091, 'Total loss': 0.5479923347632091} | train loss {'Reaction outcome loss': 0.12113075226249621, 'Total loss': 0.12113075226249621}
2022-12-31 06:22:00,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:00,672 INFO:     Epoch: 56
2022-12-31 06:22:02,325 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5000951999798418, 'Total loss': 0.5000951999798418} | train loss {'Reaction outcome loss': 0.12297956036560129, 'Total loss': 0.12297956036560129}
2022-12-31 06:22:02,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:02,325 INFO:     Epoch: 57
2022-12-31 06:22:03,830 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.529739847779274, 'Total loss': 0.529739847779274} | train loss {'Reaction outcome loss': 0.12256612792869445, 'Total loss': 0.12256612792869445}
2022-12-31 06:22:03,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:03,830 INFO:     Epoch: 58
2022-12-31 06:22:05,004 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.602394555012385, 'Total loss': 0.602394555012385} | train loss {'Reaction outcome loss': 0.12309772034012542, 'Total loss': 0.12309772034012542}
2022-12-31 06:22:05,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:05,004 INFO:     Epoch: 59
2022-12-31 06:22:06,104 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5412660936514536, 'Total loss': 0.5412660936514536} | train loss {'Reaction outcome loss': 0.12082364000499003, 'Total loss': 0.12082364000499003}
2022-12-31 06:22:06,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:06,105 INFO:     Epoch: 60
2022-12-31 06:22:07,203 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.51959271778663, 'Total loss': 0.51959271778663} | train loss {'Reaction outcome loss': 0.11938213217531052, 'Total loss': 0.11938213217531052}
2022-12-31 06:22:07,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:07,203 INFO:     Epoch: 61
2022-12-31 06:22:08,640 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5569370855887731, 'Total loss': 0.5569370855887731} | train loss {'Reaction outcome loss': 0.11890815375678676, 'Total loss': 0.11890815375678676}
2022-12-31 06:22:08,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:08,640 INFO:     Epoch: 62
2022-12-31 06:22:10,292 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5314563135306041, 'Total loss': 0.5314563135306041} | train loss {'Reaction outcome loss': 0.11938630707432808, 'Total loss': 0.11938630707432808}
2022-12-31 06:22:10,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:10,292 INFO:     Epoch: 63
2022-12-31 06:22:11,944 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5561175843079885, 'Total loss': 0.5561175843079885} | train loss {'Reaction outcome loss': 0.1199796521699695, 'Total loss': 0.1199796521699695}
2022-12-31 06:22:11,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:11,944 INFO:     Epoch: 64
2022-12-31 06:22:13,595 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5176095048586528, 'Total loss': 0.5176095048586528} | train loss {'Reaction outcome loss': 0.11975467559222104, 'Total loss': 0.11975467559222104}
2022-12-31 06:22:13,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:13,596 INFO:     Epoch: 65
2022-12-31 06:22:15,247 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5487980087598164, 'Total loss': 0.5487980087598164} | train loss {'Reaction outcome loss': 0.11813752919122794, 'Total loss': 0.11813752919122794}
2022-12-31 06:22:15,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:15,248 INFO:     Epoch: 66
2022-12-31 06:22:16,860 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5391005615393321, 'Total loss': 0.5391005615393321} | train loss {'Reaction outcome loss': 0.11659733324488421, 'Total loss': 0.11659733324488421}
2022-12-31 06:22:16,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:16,861 INFO:     Epoch: 67
2022-12-31 06:22:18,468 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.536676240960757, 'Total loss': 0.536676240960757} | train loss {'Reaction outcome loss': 0.11979675750472467, 'Total loss': 0.11979675750472467}
2022-12-31 06:22:18,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:18,469 INFO:     Epoch: 68
2022-12-31 06:22:20,078 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5262326002120972, 'Total loss': 0.5262326002120972} | train loss {'Reaction outcome loss': 0.11630172262573275, 'Total loss': 0.11630172262573275}
2022-12-31 06:22:20,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:20,078 INFO:     Epoch: 69
2022-12-31 06:22:21,730 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5573990066846212, 'Total loss': 0.5573990066846212} | train loss {'Reaction outcome loss': 0.11529235128418672, 'Total loss': 0.11529235128418672}
2022-12-31 06:22:21,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:21,731 INFO:     Epoch: 70
2022-12-31 06:22:23,327 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5023543278376261, 'Total loss': 0.5023543278376261} | train loss {'Reaction outcome loss': 0.1146654218578045, 'Total loss': 0.1146654218578045}
2022-12-31 06:22:23,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:23,327 INFO:     Epoch: 71
2022-12-31 06:22:24,932 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5405757248401641, 'Total loss': 0.5405757248401641} | train loss {'Reaction outcome loss': 0.11443258783895605, 'Total loss': 0.11443258783895605}
2022-12-31 06:22:24,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:24,932 INFO:     Epoch: 72
2022-12-31 06:22:26,534 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5361556986967723, 'Total loss': 0.5361556986967723} | train loss {'Reaction outcome loss': 0.11276300284199171, 'Total loss': 0.11276300284199171}
2022-12-31 06:22:26,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:26,534 INFO:     Epoch: 73
2022-12-31 06:22:28,185 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5370229303836822, 'Total loss': 0.5370229303836822} | train loss {'Reaction outcome loss': 0.11033435341949663, 'Total loss': 0.11033435341949663}
2022-12-31 06:22:28,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:28,186 INFO:     Epoch: 74
2022-12-31 06:22:29,838 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5304991607864697, 'Total loss': 0.5304991607864697} | train loss {'Reaction outcome loss': 0.11603741402513464, 'Total loss': 0.11603741402513464}
2022-12-31 06:22:29,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:29,839 INFO:     Epoch: 75
2022-12-31 06:22:31,440 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5885686626036962, 'Total loss': 0.5885686626036962} | train loss {'Reaction outcome loss': 0.11311316555943748, 'Total loss': 0.11311316555943748}
2022-12-31 06:22:31,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:31,440 INFO:     Epoch: 76
2022-12-31 06:22:33,048 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5811949789524078, 'Total loss': 0.5811949789524078} | train loss {'Reaction outcome loss': 0.11636190728223236, 'Total loss': 0.11636190728223236}
2022-12-31 06:22:33,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:33,049 INFO:     Epoch: 77
2022-12-31 06:22:34,657 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5462948093811671, 'Total loss': 0.5462948093811671} | train loss {'Reaction outcome loss': 0.1132813575575604, 'Total loss': 0.1132813575575604}
2022-12-31 06:22:34,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:34,658 INFO:     Epoch: 78
2022-12-31 06:22:36,260 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5278932303966334, 'Total loss': 0.5278932303966334} | train loss {'Reaction outcome loss': 0.11534299819482097, 'Total loss': 0.11534299819482097}
2022-12-31 06:22:36,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:36,261 INFO:     Epoch: 79
2022-12-31 06:22:37,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5440965660770113, 'Total loss': 0.5440965660770113} | train loss {'Reaction outcome loss': 0.10897874705923422, 'Total loss': 0.10897874705923422}
2022-12-31 06:22:37,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:37,877 INFO:     Epoch: 80
2022-12-31 06:22:39,491 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5609320521354675, 'Total loss': 0.5609320521354675} | train loss {'Reaction outcome loss': 0.11157807801938514, 'Total loss': 0.11157807801938514}
2022-12-31 06:22:39,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:39,491 INFO:     Epoch: 81
2022-12-31 06:22:41,106 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5260884990294774, 'Total loss': 0.5260884990294774} | train loss {'Reaction outcome loss': 0.11389408554256397, 'Total loss': 0.11389408554256397}
2022-12-31 06:22:41,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:41,107 INFO:     Epoch: 82
2022-12-31 06:22:42,722 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5460190792878469, 'Total loss': 0.5460190792878469} | train loss {'Reaction outcome loss': 0.10819368282108684, 'Total loss': 0.10819368282108684}
2022-12-31 06:22:42,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:42,723 INFO:     Epoch: 83
2022-12-31 06:22:44,318 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5191349188486735, 'Total loss': 0.5191349188486735} | train loss {'Reaction outcome loss': 0.10963420477954086, 'Total loss': 0.10963420477954086}
2022-12-31 06:22:44,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:44,318 INFO:     Epoch: 84
2022-12-31 06:22:45,928 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5332924425601959, 'Total loss': 0.5332924425601959} | train loss {'Reaction outcome loss': 0.10937756542660242, 'Total loss': 0.10937756542660242}
2022-12-31 06:22:45,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:45,929 INFO:     Epoch: 85
2022-12-31 06:22:47,580 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5464796960353852, 'Total loss': 0.5464796960353852} | train loss {'Reaction outcome loss': 0.11043191319467487, 'Total loss': 0.11043191319467487}
2022-12-31 06:22:47,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:47,580 INFO:     Epoch: 86
2022-12-31 06:22:49,187 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5333836336930593, 'Total loss': 0.5333836336930593} | train loss {'Reaction outcome loss': 0.11416361784820792, 'Total loss': 0.11416361784820792}
2022-12-31 06:22:49,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:49,188 INFO:     Epoch: 87
2022-12-31 06:22:50,795 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.533331549167633, 'Total loss': 0.533331549167633} | train loss {'Reaction outcome loss': 0.10901955678807504, 'Total loss': 0.10901955678807504}
2022-12-31 06:22:50,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:50,796 INFO:     Epoch: 88
2022-12-31 06:22:52,448 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.541109299659729, 'Total loss': 0.541109299659729} | train loss {'Reaction outcome loss': 0.10674200698403628, 'Total loss': 0.10674200698403628}
2022-12-31 06:22:52,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:52,448 INFO:     Epoch: 89
2022-12-31 06:22:54,037 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5443120568990707, 'Total loss': 0.5443120568990707} | train loss {'Reaction outcome loss': 0.11056862490074913, 'Total loss': 0.11056862490074913}
2022-12-31 06:22:54,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:54,037 INFO:     Epoch: 90
2022-12-31 06:22:55,689 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5698552578687668, 'Total loss': 0.5698552578687668} | train loss {'Reaction outcome loss': 0.1075990881590703, 'Total loss': 0.1075990881590703}
2022-12-31 06:22:55,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:55,689 INFO:     Epoch: 91
2022-12-31 06:22:57,292 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5323960502942403, 'Total loss': 0.5323960502942403} | train loss {'Reaction outcome loss': 0.1103007418433218, 'Total loss': 0.1103007418433218}
2022-12-31 06:22:57,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:57,293 INFO:     Epoch: 92
2022-12-31 06:22:58,896 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5493795375029246, 'Total loss': 0.5493795375029246} | train loss {'Reaction outcome loss': 0.10731458714925242, 'Total loss': 0.10731458714925242}
2022-12-31 06:22:58,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:22:58,896 INFO:     Epoch: 93
2022-12-31 06:23:00,548 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5744886567195256, 'Total loss': 0.5744886567195256} | train loss {'Reaction outcome loss': 0.1072151791287355, 'Total loss': 0.1072151791287355}
2022-12-31 06:23:00,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:00,550 INFO:     Epoch: 94
2022-12-31 06:23:02,153 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5662889858086904, 'Total loss': 0.5662889858086904} | train loss {'Reaction outcome loss': 0.10651433714631482, 'Total loss': 0.10651433714631482}
2022-12-31 06:23:02,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:02,153 INFO:     Epoch: 95
2022-12-31 06:23:03,746 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5596482525269191, 'Total loss': 0.5596482525269191} | train loss {'Reaction outcome loss': 0.10786474902135232, 'Total loss': 0.10786474902135232}
2022-12-31 06:23:03,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:03,747 INFO:     Epoch: 96
2022-12-31 06:23:05,398 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5391809185345967, 'Total loss': 0.5391809185345967} | train loss {'Reaction outcome loss': 0.10829258640636656, 'Total loss': 0.10829258640636656}
2022-12-31 06:23:05,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:05,399 INFO:     Epoch: 97
2022-12-31 06:23:07,052 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5574371452132861, 'Total loss': 0.5574371452132861} | train loss {'Reaction outcome loss': 0.10495673656297072, 'Total loss': 0.10495673656297072}
2022-12-31 06:23:07,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:07,053 INFO:     Epoch: 98
2022-12-31 06:23:08,663 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5216567407051722, 'Total loss': 0.5216567407051722} | train loss {'Reaction outcome loss': 0.10621085283550413, 'Total loss': 0.10621085283550413}
2022-12-31 06:23:08,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:08,663 INFO:     Epoch: 99
2022-12-31 06:23:10,317 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.57161745429039, 'Total loss': 0.57161745429039} | train loss {'Reaction outcome loss': 0.10376522801374595, 'Total loss': 0.10376522801374595}
2022-12-31 06:23:10,317 INFO:     Best model found after epoch 11 of 100.
2022-12-31 06:23:10,317 INFO:   Done with stage: TRAINING
2022-12-31 06:23:10,317 INFO:   Starting stage: EVALUATION
2022-12-31 06:23:10,453 INFO:   Done with stage: EVALUATION
2022-12-31 06:23:10,453 INFO:   Leaving out SEQ value Fold_1
2022-12-31 06:23:10,466 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:23:10,466 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:23:11,109 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:23:11,109 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:23:11,179 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:23:11,179 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:23:11,180 INFO:     No hyperparam tuning for this model
2022-12-31 06:23:11,180 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:23:11,180 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:23:11,180 INFO:     None feature selector for col prot
2022-12-31 06:23:11,180 INFO:     None feature selector for col prot
2022-12-31 06:23:11,181 INFO:     None feature selector for col prot
2022-12-31 06:23:11,181 INFO:     None feature selector for col chem
2022-12-31 06:23:11,181 INFO:     None feature selector for col chem
2022-12-31 06:23:11,181 INFO:     None feature selector for col chem
2022-12-31 06:23:11,181 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:23:11,181 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:23:11,183 INFO:     Number of params in model 224011
2022-12-31 06:23:11,186 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:23:11,187 INFO:   Starting stage: TRAINING
2022-12-31 06:23:11,231 INFO:     Val loss before train {'Reaction outcome loss': 1.0113160888353983, 'Total loss': 1.0113160888353983}
2022-12-31 06:23:11,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:11,232 INFO:     Epoch: 0
2022-12-31 06:23:12,882 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5238128403822581, 'Total loss': 0.5238128403822581} | train loss {'Reaction outcome loss': 0.7694402514970389, 'Total loss': 0.7694402514970389}
2022-12-31 06:23:12,882 INFO:     Found new best model at epoch 0
2022-12-31 06:23:12,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:12,883 INFO:     Epoch: 1
2022-12-31 06:23:14,497 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.43949169119199116, 'Total loss': 0.43949169119199116} | train loss {'Reaction outcome loss': 0.5071790087816265, 'Total loss': 0.5071790087816265}
2022-12-31 06:23:14,497 INFO:     Found new best model at epoch 1
2022-12-31 06:23:14,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:14,498 INFO:     Epoch: 2
2022-12-31 06:23:16,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41181703209877013, 'Total loss': 0.41181703209877013} | train loss {'Reaction outcome loss': 0.44103587783225207, 'Total loss': 0.44103587783225207}
2022-12-31 06:23:16,111 INFO:     Found new best model at epoch 2
2022-12-31 06:23:16,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:16,112 INFO:     Epoch: 3
2022-12-31 06:23:17,725 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3924506147702535, 'Total loss': 0.3924506147702535} | train loss {'Reaction outcome loss': 0.4055651982544341, 'Total loss': 0.4055651982544341}
2022-12-31 06:23:17,725 INFO:     Found new best model at epoch 3
2022-12-31 06:23:17,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:17,726 INFO:     Epoch: 4
2022-12-31 06:23:19,339 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.387764236330986, 'Total loss': 0.387764236330986} | train loss {'Reaction outcome loss': 0.375832677801963, 'Total loss': 0.375832677801963}
2022-12-31 06:23:19,339 INFO:     Found new best model at epoch 4
2022-12-31 06:23:19,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:19,340 INFO:     Epoch: 5
2022-12-31 06:23:20,930 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3572830905516942, 'Total loss': 0.3572830905516942} | train loss {'Reaction outcome loss': 0.3491116120763447, 'Total loss': 0.3491116120763447}
2022-12-31 06:23:20,930 INFO:     Found new best model at epoch 5
2022-12-31 06:23:20,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:20,931 INFO:     Epoch: 6
2022-12-31 06:23:22,559 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37247578501701356, 'Total loss': 0.37247578501701356} | train loss {'Reaction outcome loss': 0.32876984406586574, 'Total loss': 0.32876984406586574}
2022-12-31 06:23:22,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:22,559 INFO:     Epoch: 7
2022-12-31 06:23:24,190 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3569334854682287, 'Total loss': 0.3569334854682287} | train loss {'Reaction outcome loss': 0.31089440813335334, 'Total loss': 0.31089440813335334}
2022-12-31 06:23:24,190 INFO:     Found new best model at epoch 7
2022-12-31 06:23:24,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:24,191 INFO:     Epoch: 8
2022-12-31 06:23:25,821 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3845957030852636, 'Total loss': 0.3845957030852636} | train loss {'Reaction outcome loss': 0.29491908983629034, 'Total loss': 0.29491908983629034}
2022-12-31 06:23:25,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:25,822 INFO:     Epoch: 9
2022-12-31 06:23:27,453 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3643641144037247, 'Total loss': 0.3643641144037247} | train loss {'Reaction outcome loss': 0.2795184568731465, 'Total loss': 0.2795184568731465}
2022-12-31 06:23:27,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:27,453 INFO:     Epoch: 10
2022-12-31 06:23:29,082 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39040318528811135, 'Total loss': 0.39040318528811135} | train loss {'Reaction outcome loss': 0.2714696980192852, 'Total loss': 0.2714696980192852}
2022-12-31 06:23:29,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:29,082 INFO:     Epoch: 11
2022-12-31 06:23:30,687 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4002442717552185, 'Total loss': 0.4002442717552185} | train loss {'Reaction outcome loss': 0.25536724470852723, 'Total loss': 0.25536724470852723}
2022-12-31 06:23:30,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:30,687 INFO:     Epoch: 12
2022-12-31 06:23:32,316 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36000228524208067, 'Total loss': 0.36000228524208067} | train loss {'Reaction outcome loss': 0.2492864994413179, 'Total loss': 0.2492864994413179}
2022-12-31 06:23:32,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:32,317 INFO:     Epoch: 13
2022-12-31 06:23:33,947 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3896714647610982, 'Total loss': 0.3896714647610982} | train loss {'Reaction outcome loss': 0.23678531626828245, 'Total loss': 0.23678531626828245}
2022-12-31 06:23:33,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:33,947 INFO:     Epoch: 14
2022-12-31 06:23:35,576 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3676023801167806, 'Total loss': 0.3676023801167806} | train loss {'Reaction outcome loss': 0.22839296616165075, 'Total loss': 0.22839296616165075}
2022-12-31 06:23:35,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:35,577 INFO:     Epoch: 15
2022-12-31 06:23:37,205 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3824042638142904, 'Total loss': 0.3824042638142904} | train loss {'Reaction outcome loss': 0.21929518173219284, 'Total loss': 0.21929518173219284}
2022-12-31 06:23:37,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:37,206 INFO:     Epoch: 16
2022-12-31 06:23:38,803 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37492649505535763, 'Total loss': 0.37492649505535763} | train loss {'Reaction outcome loss': 0.21228545812756647, 'Total loss': 0.21228545812756647}
2022-12-31 06:23:38,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:38,804 INFO:     Epoch: 17
2022-12-31 06:23:40,424 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3925668199857076, 'Total loss': 0.3925668199857076} | train loss {'Reaction outcome loss': 0.20787178145289636, 'Total loss': 0.20787178145289636}
2022-12-31 06:23:40,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:40,424 INFO:     Epoch: 18
2022-12-31 06:23:42,088 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4082101215918859, 'Total loss': 0.4082101215918859} | train loss {'Reaction outcome loss': 0.203115133261578, 'Total loss': 0.203115133261578}
2022-12-31 06:23:42,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:42,088 INFO:     Epoch: 19
2022-12-31 06:23:43,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.372428172826767, 'Total loss': 0.372428172826767} | train loss {'Reaction outcome loss': 0.19696833525085822, 'Total loss': 0.19696833525085822}
2022-12-31 06:23:43,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:43,753 INFO:     Epoch: 20
2022-12-31 06:23:45,371 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42345812991261483, 'Total loss': 0.42345812991261483} | train loss {'Reaction outcome loss': 0.20654277594598092, 'Total loss': 0.20654277594598092}
2022-12-31 06:23:45,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:45,372 INFO:     Epoch: 21
2022-12-31 06:23:47,032 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3986500412225723, 'Total loss': 0.3986500412225723} | train loss {'Reaction outcome loss': 0.21338448616206998, 'Total loss': 0.21338448616206998}
2022-12-31 06:23:47,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:47,032 INFO:     Epoch: 22
2022-12-31 06:23:48,647 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3929019033908844, 'Total loss': 0.3929019033908844} | train loss {'Reaction outcome loss': 0.1894004862330368, 'Total loss': 0.1894004862330368}
2022-12-31 06:23:48,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:48,647 INFO:     Epoch: 23
2022-12-31 06:23:50,276 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3935754865407944, 'Total loss': 0.3935754865407944} | train loss {'Reaction outcome loss': 0.18299654525264777, 'Total loss': 0.18299654525264777}
2022-12-31 06:23:50,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:50,276 INFO:     Epoch: 24
2022-12-31 06:23:51,905 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4244907970229785, 'Total loss': 0.4244907970229785} | train loss {'Reaction outcome loss': 0.17166076152993218, 'Total loss': 0.17166076152993218}
2022-12-31 06:23:51,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:51,906 INFO:     Epoch: 25
2022-12-31 06:23:53,535 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3924987037976583, 'Total loss': 0.3924987037976583} | train loss {'Reaction outcome loss': 0.17116990511346122, 'Total loss': 0.17116990511346122}
2022-12-31 06:23:53,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:53,535 INFO:     Epoch: 26
2022-12-31 06:23:55,163 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38098450005054474, 'Total loss': 0.38098450005054474} | train loss {'Reaction outcome loss': 0.17174551186363332, 'Total loss': 0.17174551186363332}
2022-12-31 06:23:55,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:55,163 INFO:     Epoch: 27
2022-12-31 06:23:56,783 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41167060534159344, 'Total loss': 0.41167060534159344} | train loss {'Reaction outcome loss': 0.16100317690659827, 'Total loss': 0.16100317690659827}
2022-12-31 06:23:56,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:56,783 INFO:     Epoch: 28
2022-12-31 06:23:58,386 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40738603174686433, 'Total loss': 0.40738603174686433} | train loss {'Reaction outcome loss': 0.16287438730047882, 'Total loss': 0.16287438730047882}
2022-12-31 06:23:58,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:23:58,386 INFO:     Epoch: 29
2022-12-31 06:24:00,016 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39595942993958794, 'Total loss': 0.39595942993958794} | train loss {'Reaction outcome loss': 0.17258632273971697, 'Total loss': 0.17258632273971697}
2022-12-31 06:24:00,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:00,016 INFO:     Epoch: 30
2022-12-31 06:24:01,645 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3843362718820572, 'Total loss': 0.3843362718820572} | train loss {'Reaction outcome loss': 0.15781409311508152, 'Total loss': 0.15781409311508152}
2022-12-31 06:24:01,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:01,645 INFO:     Epoch: 31
2022-12-31 06:24:03,274 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38260508328676224, 'Total loss': 0.38260508328676224} | train loss {'Reaction outcome loss': 0.15268405568381044, 'Total loss': 0.15268405568381044}
2022-12-31 06:24:03,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:03,275 INFO:     Epoch: 32
2022-12-31 06:24:04,906 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40315066774686176, 'Total loss': 0.40315066774686176} | train loss {'Reaction outcome loss': 0.1500101034677979, 'Total loss': 0.1500101034677979}
2022-12-31 06:24:04,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:04,907 INFO:     Epoch: 33
2022-12-31 06:24:06,496 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3819730261961619, 'Total loss': 0.3819730261961619} | train loss {'Reaction outcome loss': 0.1518500745882773, 'Total loss': 0.1518500745882773}
2022-12-31 06:24:06,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:06,496 INFO:     Epoch: 34
2022-12-31 06:24:08,122 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40508066763480505, 'Total loss': 0.40508066763480505} | train loss {'Reaction outcome loss': 0.14598045496529885, 'Total loss': 0.14598045496529885}
2022-12-31 06:24:08,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:08,122 INFO:     Epoch: 35
2022-12-31 06:24:09,746 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36739982292056084, 'Total loss': 0.36739982292056084} | train loss {'Reaction outcome loss': 0.1481888320649623, 'Total loss': 0.1481888320649623}
2022-12-31 06:24:09,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:09,747 INFO:     Epoch: 36
2022-12-31 06:24:11,366 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43607142170270285, 'Total loss': 0.43607142170270285} | train loss {'Reaction outcome loss': 0.14537213850185188, 'Total loss': 0.14537213850185188}
2022-12-31 06:24:11,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:11,366 INFO:     Epoch: 37
2022-12-31 06:24:12,987 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3941904753446579, 'Total loss': 0.3941904753446579} | train loss {'Reaction outcome loss': 0.14327958767851512, 'Total loss': 0.14327958767851512}
2022-12-31 06:24:12,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:12,987 INFO:     Epoch: 38
2022-12-31 06:24:14,606 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3902937650680542, 'Total loss': 0.3902937650680542} | train loss {'Reaction outcome loss': 0.14003969717937845, 'Total loss': 0.14003969717937845}
2022-12-31 06:24:14,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:14,606 INFO:     Epoch: 39
2022-12-31 06:24:16,170 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39242859482765197, 'Total loss': 0.39242859482765197} | train loss {'Reaction outcome loss': 0.1418277122128055, 'Total loss': 0.1418277122128055}
2022-12-31 06:24:16,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:16,170 INFO:     Epoch: 40
2022-12-31 06:24:17,783 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3733265310525894, 'Total loss': 0.3733265310525894} | train loss {'Reaction outcome loss': 0.141337707559051, 'Total loss': 0.141337707559051}
2022-12-31 06:24:17,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:17,783 INFO:     Epoch: 41
2022-12-31 06:24:19,398 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4115642656882604, 'Total loss': 0.4115642656882604} | train loss {'Reaction outcome loss': 0.14204710031787027, 'Total loss': 0.14204710031787027}
2022-12-31 06:24:19,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:19,398 INFO:     Epoch: 42
2022-12-31 06:24:21,011 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37735513945420585, 'Total loss': 0.37735513945420585} | train loss {'Reaction outcome loss': 0.13808110749780916, 'Total loss': 0.13808110749780916}
2022-12-31 06:24:21,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:21,012 INFO:     Epoch: 43
2022-12-31 06:24:22,625 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44703555703163145, 'Total loss': 0.44703555703163145} | train loss {'Reaction outcome loss': 0.13929055686500194, 'Total loss': 0.13929055686500194}
2022-12-31 06:24:22,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:22,626 INFO:     Epoch: 44
2022-12-31 06:24:24,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3779002964496613, 'Total loss': 0.3779002964496613} | train loss {'Reaction outcome loss': 0.1348542870035854, 'Total loss': 0.1348542870035854}
2022-12-31 06:24:24,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:24,201 INFO:     Epoch: 45
2022-12-31 06:24:25,826 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4073161500816544, 'Total loss': 0.4073161500816544} | train loss {'Reaction outcome loss': 0.13533035765188592, 'Total loss': 0.13533035765188592}
2022-12-31 06:24:25,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:25,827 INFO:     Epoch: 46
2022-12-31 06:24:27,450 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3745566442608833, 'Total loss': 0.3745566442608833} | train loss {'Reaction outcome loss': 0.13146682188549227, 'Total loss': 0.13146682188549227}
2022-12-31 06:24:27,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:27,451 INFO:     Epoch: 47
2022-12-31 06:24:29,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3722870270411173, 'Total loss': 0.3722870270411173} | train loss {'Reaction outcome loss': 0.1307886962666458, 'Total loss': 0.1307886962666458}
2022-12-31 06:24:29,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:29,073 INFO:     Epoch: 48
2022-12-31 06:24:30,738 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3910103718439738, 'Total loss': 0.3910103718439738} | train loss {'Reaction outcome loss': 0.13569988216108142, 'Total loss': 0.13569988216108142}
2022-12-31 06:24:30,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:30,738 INFO:     Epoch: 49
2022-12-31 06:24:32,402 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3905104013780753, 'Total loss': 0.3905104013780753} | train loss {'Reaction outcome loss': 0.13546238836083238, 'Total loss': 0.13546238836083238}
2022-12-31 06:24:32,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:32,402 INFO:     Epoch: 50
2022-12-31 06:24:33,999 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4478240191936493, 'Total loss': 0.4478240191936493} | train loss {'Reaction outcome loss': 0.1326172728461814, 'Total loss': 0.1326172728461814}
2022-12-31 06:24:34,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:34,000 INFO:     Epoch: 51
2022-12-31 06:24:35,630 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37934547166029614, 'Total loss': 0.37934547166029614} | train loss {'Reaction outcome loss': 0.1310594262927159, 'Total loss': 0.1310594262927159}
2022-12-31 06:24:35,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:35,630 INFO:     Epoch: 52
2022-12-31 06:24:37,296 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4142827024062475, 'Total loss': 0.4142827024062475} | train loss {'Reaction outcome loss': 0.13204758426518706, 'Total loss': 0.13204758426518706}
2022-12-31 06:24:37,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:37,296 INFO:     Epoch: 53
2022-12-31 06:24:38,925 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4131957600514094, 'Total loss': 0.4131957600514094} | train loss {'Reaction outcome loss': 0.13080921563776762, 'Total loss': 0.13080921563776762}
2022-12-31 06:24:38,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:38,926 INFO:     Epoch: 54
2022-12-31 06:24:40,591 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37731710175673167, 'Total loss': 0.37731710175673167} | train loss {'Reaction outcome loss': 0.12402008337464751, 'Total loss': 0.12402008337464751}
2022-12-31 06:24:40,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:40,591 INFO:     Epoch: 55
2022-12-31 06:24:42,216 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3670339365800222, 'Total loss': 0.3670339365800222} | train loss {'Reaction outcome loss': 0.12256201564782648, 'Total loss': 0.12256201564782648}
2022-12-31 06:24:42,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:42,216 INFO:     Epoch: 56
2022-12-31 06:24:43,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38934077819188434, 'Total loss': 0.38934077819188434} | train loss {'Reaction outcome loss': 0.12350125945058475, 'Total loss': 0.12350125945058475}
2022-12-31 06:24:43,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:43,823 INFO:     Epoch: 57
2022-12-31 06:24:45,438 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3804570158322652, 'Total loss': 0.3804570158322652} | train loss {'Reaction outcome loss': 0.1318867273006143, 'Total loss': 0.1318867273006143}
2022-12-31 06:24:45,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:45,439 INFO:     Epoch: 58
2022-12-31 06:24:47,082 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3890264759461085, 'Total loss': 0.3890264759461085} | train loss {'Reaction outcome loss': 0.14582340122538828, 'Total loss': 0.14582340122538828}
2022-12-31 06:24:47,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:47,082 INFO:     Epoch: 59
2022-12-31 06:24:48,698 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3942779223124186, 'Total loss': 0.3942779223124186} | train loss {'Reaction outcome loss': 0.1252256116333782, 'Total loss': 0.1252256116333782}
2022-12-31 06:24:48,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:48,699 INFO:     Epoch: 60
2022-12-31 06:24:50,317 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4206772670149803, 'Total loss': 0.4206772670149803} | train loss {'Reaction outcome loss': 0.12589600851820054, 'Total loss': 0.12589600851820054}
2022-12-31 06:24:50,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:50,318 INFO:     Epoch: 61
2022-12-31 06:24:51,885 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4025466506679853, 'Total loss': 0.4025466506679853} | train loss {'Reaction outcome loss': 0.12075907259226158, 'Total loss': 0.12075907259226158}
2022-12-31 06:24:51,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:51,885 INFO:     Epoch: 62
2022-12-31 06:24:53,550 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4054350326458613, 'Total loss': 0.4054350326458613} | train loss {'Reaction outcome loss': 0.1192256743310268, 'Total loss': 0.1192256743310268}
2022-12-31 06:24:53,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:53,551 INFO:     Epoch: 63
2022-12-31 06:24:55,168 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3820630371570587, 'Total loss': 0.3820630371570587} | train loss {'Reaction outcome loss': 0.11862633519458408, 'Total loss': 0.11862633519458408}
2022-12-31 06:24:55,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:55,168 INFO:     Epoch: 64
2022-12-31 06:24:56,786 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38944998060663544, 'Total loss': 0.38944998060663544} | train loss {'Reaction outcome loss': 0.11972444494882517, 'Total loss': 0.11972444494882517}
2022-12-31 06:24:56,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:56,786 INFO:     Epoch: 65
2022-12-31 06:24:58,406 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40941303223371506, 'Total loss': 0.40941303223371506} | train loss {'Reaction outcome loss': 0.11987237493377652, 'Total loss': 0.11987237493377652}
2022-12-31 06:24:58,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:24:58,406 INFO:     Epoch: 66
2022-12-31 06:25:00,072 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39629821181297303, 'Total loss': 0.39629821181297303} | train loss {'Reaction outcome loss': 0.11647879087452209, 'Total loss': 0.11647879087452209}
2022-12-31 06:25:00,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:00,072 INFO:     Epoch: 67
2022-12-31 06:25:01,653 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4122571443518003, 'Total loss': 0.4122571443518003} | train loss {'Reaction outcome loss': 0.12114737087383706, 'Total loss': 0.12114737087383706}
2022-12-31 06:25:01,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:01,653 INFO:     Epoch: 68
2022-12-31 06:25:03,272 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.368014661471049, 'Total loss': 0.368014661471049} | train loss {'Reaction outcome loss': 0.12389495872944742, 'Total loss': 0.12389495872944742}
2022-12-31 06:25:03,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:03,272 INFO:     Epoch: 69
2022-12-31 06:25:04,888 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3915195067723592, 'Total loss': 0.3915195067723592} | train loss {'Reaction outcome loss': 0.12124366318280606, 'Total loss': 0.12124366318280606}
2022-12-31 06:25:04,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:04,888 INFO:     Epoch: 70
2022-12-31 06:25:06,508 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36824323792631425, 'Total loss': 0.36824323792631425} | train loss {'Reaction outcome loss': 0.11291578032018995, 'Total loss': 0.11291578032018995}
2022-12-31 06:25:06,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:06,508 INFO:     Epoch: 71
2022-12-31 06:25:08,129 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3776035398244858, 'Total loss': 0.3776035398244858} | train loss {'Reaction outcome loss': 0.11442468221387084, 'Total loss': 0.11442468221387084}
2022-12-31 06:25:08,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:08,129 INFO:     Epoch: 72
2022-12-31 06:25:09,702 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41148948669433594, 'Total loss': 0.41148948669433594} | train loss {'Reaction outcome loss': 0.11898748429856547, 'Total loss': 0.11898748429856547}
2022-12-31 06:25:09,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:09,703 INFO:     Epoch: 73
2022-12-31 06:25:11,323 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41268486380577085, 'Total loss': 0.41268486380577085} | train loss {'Reaction outcome loss': 0.16349765639513836, 'Total loss': 0.16349765639513836}
2022-12-31 06:25:11,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:11,323 INFO:     Epoch: 74
2022-12-31 06:25:12,948 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3864517678817113, 'Total loss': 0.3864517678817113} | train loss {'Reaction outcome loss': 0.12008681086603168, 'Total loss': 0.12008681086603168}
2022-12-31 06:25:12,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:12,949 INFO:     Epoch: 75
2022-12-31 06:25:14,575 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36799713522195815, 'Total loss': 0.36799713522195815} | train loss {'Reaction outcome loss': 0.11248311503584484, 'Total loss': 0.11248311503584484}
2022-12-31 06:25:14,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:14,575 INFO:     Epoch: 76
2022-12-31 06:25:16,200 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39247057487567266, 'Total loss': 0.39247057487567266} | train loss {'Reaction outcome loss': 0.11307496370653203, 'Total loss': 0.11307496370653203}
2022-12-31 06:25:16,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:16,201 INFO:     Epoch: 77
2022-12-31 06:25:17,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4035385956366857, 'Total loss': 0.4035385956366857} | train loss {'Reaction outcome loss': 0.11165159738469073, 'Total loss': 0.11165159738469073}
2022-12-31 06:25:17,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:17,825 INFO:     Epoch: 78
2022-12-31 06:25:19,381 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37554181218147276, 'Total loss': 0.37554181218147276} | train loss {'Reaction outcome loss': 0.11378214251295582, 'Total loss': 0.11378214251295582}
2022-12-31 06:25:19,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:19,382 INFO:     Epoch: 79
2022-12-31 06:25:21,007 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3873134583234787, 'Total loss': 0.3873134583234787} | train loss {'Reaction outcome loss': 0.11179446436395613, 'Total loss': 0.11179446436395613}
2022-12-31 06:25:21,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:21,007 INFO:     Epoch: 80
2022-12-31 06:25:22,631 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3915651758511861, 'Total loss': 0.3915651758511861} | train loss {'Reaction outcome loss': 0.11328146859322906, 'Total loss': 0.11328146859322906}
2022-12-31 06:25:22,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:22,632 INFO:     Epoch: 81
2022-12-31 06:25:24,256 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3835298220316569, 'Total loss': 0.3835298220316569} | train loss {'Reaction outcome loss': 0.11502645149037403, 'Total loss': 0.11502645149037403}
2022-12-31 06:25:24,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:24,256 INFO:     Epoch: 82
2022-12-31 06:25:25,879 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39814665416876477, 'Total loss': 0.39814665416876477} | train loss {'Reaction outcome loss': 0.12146717839219702, 'Total loss': 0.12146717839219702}
2022-12-31 06:25:25,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:25,879 INFO:     Epoch: 83
2022-12-31 06:25:27,504 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40677903095881146, 'Total loss': 0.40677903095881146} | train loss {'Reaction outcome loss': 0.11320339942840357, 'Total loss': 0.11320339942840357}
2022-12-31 06:25:27,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:27,504 INFO:     Epoch: 84
2022-12-31 06:25:29,050 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4003744294246038, 'Total loss': 0.4003744294246038} | train loss {'Reaction outcome loss': 0.11165198100143639, 'Total loss': 0.11165198100143639}
2022-12-31 06:25:29,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:29,051 INFO:     Epoch: 85
2022-12-31 06:25:30,671 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3900147567192713, 'Total loss': 0.3900147567192713} | train loss {'Reaction outcome loss': 0.10980478605568456, 'Total loss': 0.10980478605568456}
2022-12-31 06:25:30,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:30,672 INFO:     Epoch: 86
2022-12-31 06:25:32,295 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3651157279809316, 'Total loss': 0.3651157279809316} | train loss {'Reaction outcome loss': 0.11008668174980667, 'Total loss': 0.11008668174980667}
2022-12-31 06:25:32,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:32,295 INFO:     Epoch: 87
2022-12-31 06:25:33,913 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36977799038092296, 'Total loss': 0.36977799038092296} | train loss {'Reaction outcome loss': 0.10992884399119235, 'Total loss': 0.10992884399119235}
2022-12-31 06:25:33,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:33,913 INFO:     Epoch: 88
2022-12-31 06:25:35,533 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3665414164463679, 'Total loss': 0.3665414164463679} | train loss {'Reaction outcome loss': 0.11165008772619278, 'Total loss': 0.11165008772619278}
2022-12-31 06:25:35,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:35,533 INFO:     Epoch: 89
2022-12-31 06:25:37,088 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38600431084632875, 'Total loss': 0.38600431084632875} | train loss {'Reaction outcome loss': 0.11049472936297272, 'Total loss': 0.11049472936297272}
2022-12-31 06:25:37,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:37,088 INFO:     Epoch: 90
2022-12-31 06:25:38,753 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3864445298910141, 'Total loss': 0.3864445298910141} | train loss {'Reaction outcome loss': 0.10863621416923495, 'Total loss': 0.10863621416923495}
2022-12-31 06:25:38,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:38,753 INFO:     Epoch: 91
2022-12-31 06:25:40,372 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3968016554911931, 'Total loss': 0.3968016554911931} | train loss {'Reaction outcome loss': 0.1154428114136006, 'Total loss': 0.1154428114136006}
2022-12-31 06:25:40,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:40,373 INFO:     Epoch: 92
2022-12-31 06:25:42,037 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3980705956617991, 'Total loss': 0.3980705956617991} | train loss {'Reaction outcome loss': 0.10917933751931043, 'Total loss': 0.10917933751931043}
2022-12-31 06:25:42,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:42,037 INFO:     Epoch: 93
2022-12-31 06:25:43,701 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37208735446135205, 'Total loss': 0.37208735446135205} | train loss {'Reaction outcome loss': 0.11647192275225846, 'Total loss': 0.11647192275225846}
2022-12-31 06:25:43,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:43,701 INFO:     Epoch: 94
2022-12-31 06:25:45,329 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4365301648775736, 'Total loss': 0.4365301648775736} | train loss {'Reaction outcome loss': 0.11680349683476801, 'Total loss': 0.11680349683476801}
2022-12-31 06:25:45,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:45,329 INFO:     Epoch: 95
2022-12-31 06:25:46,931 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4055047223965327, 'Total loss': 0.4055047223965327} | train loss {'Reaction outcome loss': 0.11819406415072634, 'Total loss': 0.11819406415072634}
2022-12-31 06:25:46,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:46,933 INFO:     Epoch: 96
2022-12-31 06:25:48,550 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39455946286519367, 'Total loss': 0.39455946286519367} | train loss {'Reaction outcome loss': 0.10955574171342616, 'Total loss': 0.10955574171342616}
2022-12-31 06:25:48,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:48,550 INFO:     Epoch: 97
2022-12-31 06:25:50,214 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3991640860835711, 'Total loss': 0.3991640860835711} | train loss {'Reaction outcome loss': 0.10586688747318239, 'Total loss': 0.10586688747318239}
2022-12-31 06:25:50,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:50,215 INFO:     Epoch: 98
2022-12-31 06:25:51,868 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39316480259100595, 'Total loss': 0.39316480259100595} | train loss {'Reaction outcome loss': 0.10561199404769533, 'Total loss': 0.10561199404769533}
2022-12-31 06:25:51,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:51,868 INFO:     Epoch: 99
2022-12-31 06:25:53,532 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37070382038752236, 'Total loss': 0.37070382038752236} | train loss {'Reaction outcome loss': 0.10687551911299427, 'Total loss': 0.10687551911299427}
2022-12-31 06:25:53,533 INFO:     Best model found after epoch 8 of 100.
2022-12-31 06:25:53,533 INFO:   Done with stage: TRAINING
2022-12-31 06:25:53,533 INFO:   Starting stage: EVALUATION
2022-12-31 06:25:53,661 INFO:   Done with stage: EVALUATION
2022-12-31 06:25:53,661 INFO:   Leaving out SEQ value Fold_2
2022-12-31 06:25:53,674 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:25:53,674 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:25:54,314 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:25:54,314 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:25:54,385 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:25:54,385 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:25:54,385 INFO:     No hyperparam tuning for this model
2022-12-31 06:25:54,385 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:25:54,385 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:25:54,386 INFO:     None feature selector for col prot
2022-12-31 06:25:54,386 INFO:     None feature selector for col prot
2022-12-31 06:25:54,386 INFO:     None feature selector for col prot
2022-12-31 06:25:54,387 INFO:     None feature selector for col chem
2022-12-31 06:25:54,387 INFO:     None feature selector for col chem
2022-12-31 06:25:54,387 INFO:     None feature selector for col chem
2022-12-31 06:25:54,387 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:25:54,387 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:25:54,389 INFO:     Number of params in model 224011
2022-12-31 06:25:54,392 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:25:54,392 INFO:   Starting stage: TRAINING
2022-12-31 06:25:54,437 INFO:     Val loss before train {'Reaction outcome loss': 0.9640694499015808, 'Total loss': 0.9640694499015808}
2022-12-31 06:25:54,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:54,438 INFO:     Epoch: 0
2022-12-31 06:25:55,984 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.4856017450491587, 'Total loss': 0.4856017450491587} | train loss {'Reaction outcome loss': 0.7671646181031735, 'Total loss': 0.7671646181031735}
2022-12-31 06:25:55,985 INFO:     Found new best model at epoch 0
2022-12-31 06:25:55,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:55,986 INFO:     Epoch: 1
2022-12-31 06:25:57,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.41043301820755007, 'Total loss': 0.41043301820755007} | train loss {'Reaction outcome loss': 0.5089891124924604, 'Total loss': 0.5089891124924604}
2022-12-31 06:25:57,591 INFO:     Found new best model at epoch 1
2022-12-31 06:25:57,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:57,592 INFO:     Epoch: 2
2022-12-31 06:25:59,197 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.3849592765172323, 'Total loss': 0.3849592765172323} | train loss {'Reaction outcome loss': 0.4432971880492503, 'Total loss': 0.4432971880492503}
2022-12-31 06:25:59,197 INFO:     Found new best model at epoch 2
2022-12-31 06:25:59,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:25:59,198 INFO:     Epoch: 3
2022-12-31 06:26:00,803 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.36794791420300804, 'Total loss': 0.36794791420300804} | train loss {'Reaction outcome loss': 0.40379441388114523, 'Total loss': 0.40379441388114523}
2022-12-31 06:26:00,803 INFO:     Found new best model at epoch 3
2022-12-31 06:26:00,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:00,804 INFO:     Epoch: 4
2022-12-31 06:26:02,411 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.35284070620934166, 'Total loss': 0.35284070620934166} | train loss {'Reaction outcome loss': 0.36883039916627597, 'Total loss': 0.36883039916627597}
2022-12-31 06:26:02,411 INFO:     Found new best model at epoch 4
2022-12-31 06:26:02,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:02,412 INFO:     Epoch: 5
2022-12-31 06:26:03,980 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3348870406548182, 'Total loss': 0.3348870406548182} | train loss {'Reaction outcome loss': 0.3474983516128829, 'Total loss': 0.3474983516128829}
2022-12-31 06:26:03,980 INFO:     Found new best model at epoch 5
2022-12-31 06:26:03,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:03,981 INFO:     Epoch: 6
2022-12-31 06:26:05,586 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.32512159993251166, 'Total loss': 0.32512159993251166} | train loss {'Reaction outcome loss': 0.32659129749466903, 'Total loss': 0.32659129749466903}
2022-12-31 06:26:05,586 INFO:     Found new best model at epoch 6
2022-12-31 06:26:05,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:05,587 INFO:     Epoch: 7
2022-12-31 06:26:07,195 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3157291799783707, 'Total loss': 0.3157291799783707} | train loss {'Reaction outcome loss': 0.3100176813611149, 'Total loss': 0.3100176813611149}
2022-12-31 06:26:07,195 INFO:     Found new best model at epoch 7
2022-12-31 06:26:07,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:07,196 INFO:     Epoch: 8
2022-12-31 06:26:08,803 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3307056377331416, 'Total loss': 0.3307056377331416} | train loss {'Reaction outcome loss': 0.29927752819592063, 'Total loss': 0.29927752819592063}
2022-12-31 06:26:08,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:08,803 INFO:     Epoch: 9
2022-12-31 06:26:10,409 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.32682475745677947, 'Total loss': 0.32682475745677947} | train loss {'Reaction outcome loss': 0.2790112906291972, 'Total loss': 0.2790112906291972}
2022-12-31 06:26:10,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:10,409 INFO:     Epoch: 10
2022-12-31 06:26:12,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3052364597717921, 'Total loss': 0.3052364597717921} | train loss {'Reaction outcome loss': 0.2673464889373005, 'Total loss': 0.2673464889373005}
2022-12-31 06:26:12,061 INFO:     Found new best model at epoch 10
2022-12-31 06:26:12,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:12,062 INFO:     Epoch: 11
2022-12-31 06:26:13,614 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.2939679379264514, 'Total loss': 0.2939679379264514} | train loss {'Reaction outcome loss': 0.2557562909014251, 'Total loss': 0.2557562909014251}
2022-12-31 06:26:13,614 INFO:     Found new best model at epoch 11
2022-12-31 06:26:13,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:13,615 INFO:     Epoch: 12
2022-12-31 06:26:15,222 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3164475147922834, 'Total loss': 0.3164475147922834} | train loss {'Reaction outcome loss': 0.24753184487404178, 'Total loss': 0.24753184487404178}
2022-12-31 06:26:15,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:15,222 INFO:     Epoch: 13
2022-12-31 06:26:16,875 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3443084999918938, 'Total loss': 0.3443084999918938} | train loss {'Reaction outcome loss': 0.2362787048638302, 'Total loss': 0.2362787048638302}
2022-12-31 06:26:16,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:16,875 INFO:     Epoch: 14
2022-12-31 06:26:18,529 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34119563897450766, 'Total loss': 0.34119563897450766} | train loss {'Reaction outcome loss': 0.22965451503974676, 'Total loss': 0.22965451503974676}
2022-12-31 06:26:18,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:18,529 INFO:     Epoch: 15
2022-12-31 06:26:20,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.30880065659681954, 'Total loss': 0.30880065659681954} | train loss {'Reaction outcome loss': 0.2200646932325224, 'Total loss': 0.2200646932325224}
2022-12-31 06:26:20,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:20,161 INFO:     Epoch: 16
2022-12-31 06:26:21,772 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.33987997770309447, 'Total loss': 0.33987997770309447} | train loss {'Reaction outcome loss': 0.20849670495933098, 'Total loss': 0.20849670495933098}
2022-12-31 06:26:21,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:21,773 INFO:     Epoch: 17
2022-12-31 06:26:23,341 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.31907442907492317, 'Total loss': 0.31907442907492317} | train loss {'Reaction outcome loss': 0.2108580363492896, 'Total loss': 0.2108580363492896}
2022-12-31 06:26:23,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:23,341 INFO:     Epoch: 18
2022-12-31 06:26:24,994 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3299848983685176, 'Total loss': 0.3299848983685176} | train loss {'Reaction outcome loss': 0.2026625151208935, 'Total loss': 0.2026625151208935}
2022-12-31 06:26:24,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:24,994 INFO:     Epoch: 19
2022-12-31 06:26:26,598 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3310518225034078, 'Total loss': 0.3310518225034078} | train loss {'Reaction outcome loss': 0.1994944156086358, 'Total loss': 0.1994944156086358}
2022-12-31 06:26:26,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:26,598 INFO:     Epoch: 20
2022-12-31 06:26:28,201 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.32195654114087424, 'Total loss': 0.32195654114087424} | train loss {'Reaction outcome loss': 0.19304631485257054, 'Total loss': 0.19304631485257054}
2022-12-31 06:26:28,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:28,202 INFO:     Epoch: 21
2022-12-31 06:26:29,805 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.340098974108696, 'Total loss': 0.340098974108696} | train loss {'Reaction outcome loss': 0.18747619304969146, 'Total loss': 0.18747619304969146}
2022-12-31 06:26:29,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:29,806 INFO:     Epoch: 22
2022-12-31 06:26:31,370 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34736929535865785, 'Total loss': 0.34736929535865785} | train loss {'Reaction outcome loss': 0.18631644468808914, 'Total loss': 0.18631644468808914}
2022-12-31 06:26:31,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:31,370 INFO:     Epoch: 23
2022-12-31 06:26:33,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.31571391100684804, 'Total loss': 0.31571391100684804} | train loss {'Reaction outcome loss': 0.1873457575842303, 'Total loss': 0.1873457575842303}
2022-12-31 06:26:33,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:33,016 INFO:     Epoch: 24
2022-12-31 06:26:34,623 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35880714158217114, 'Total loss': 0.35880714158217114} | train loss {'Reaction outcome loss': 0.176861699456417, 'Total loss': 0.176861699456417}
2022-12-31 06:26:34,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:34,624 INFO:     Epoch: 25
2022-12-31 06:26:36,276 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3800295715530713, 'Total loss': 0.3800295715530713} | train loss {'Reaction outcome loss': 0.17353825478127946, 'Total loss': 0.17353825478127946}
2022-12-31 06:26:36,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:36,277 INFO:     Epoch: 26
2022-12-31 06:26:37,881 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.34339102655649184, 'Total loss': 0.34339102655649184} | train loss {'Reaction outcome loss': 0.17457204825673117, 'Total loss': 0.17457204825673117}
2022-12-31 06:26:37,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:37,882 INFO:     Epoch: 27
2022-12-31 06:26:39,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3394812822341919, 'Total loss': 0.3394812822341919} | train loss {'Reaction outcome loss': 0.16839706081978595, 'Total loss': 0.16839706081978595}
2022-12-31 06:26:39,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:39,491 INFO:     Epoch: 28
2022-12-31 06:26:41,079 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35266416519880295, 'Total loss': 0.35266416519880295} | train loss {'Reaction outcome loss': 0.1680188806333246, 'Total loss': 0.1680188806333246}
2022-12-31 06:26:41,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:41,080 INFO:     Epoch: 29
2022-12-31 06:26:42,689 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.325197896361351, 'Total loss': 0.325197896361351} | train loss {'Reaction outcome loss': 0.16708337943865, 'Total loss': 0.16708337943865}
2022-12-31 06:26:42,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:42,689 INFO:     Epoch: 30
2022-12-31 06:26:44,342 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35356878439585365, 'Total loss': 0.35356878439585365} | train loss {'Reaction outcome loss': 0.16523466547135346, 'Total loss': 0.16523466547135346}
2022-12-31 06:26:44,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:44,342 INFO:     Epoch: 31
2022-12-31 06:26:45,948 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3394148101409276, 'Total loss': 0.3394148101409276} | train loss {'Reaction outcome loss': 0.16210671660769052, 'Total loss': 0.16210671660769052}
2022-12-31 06:26:45,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:45,948 INFO:     Epoch: 32
2022-12-31 06:26:47,599 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3715030441681544, 'Total loss': 0.3715030441681544} | train loss {'Reaction outcome loss': 0.15881049223788027, 'Total loss': 0.15881049223788027}
2022-12-31 06:26:47,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:47,600 INFO:     Epoch: 33
2022-12-31 06:26:49,251 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3519455388188362, 'Total loss': 0.3519455388188362} | train loss {'Reaction outcome loss': 0.15468637387261447, 'Total loss': 0.15468637387261447}
2022-12-31 06:26:49,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:49,251 INFO:     Epoch: 34
2022-12-31 06:26:50,814 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.32461808025836947, 'Total loss': 0.32461808025836947} | train loss {'Reaction outcome loss': 0.15730234330016984, 'Total loss': 0.15730234330016984}
2022-12-31 06:26:50,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:50,814 INFO:     Epoch: 35
2022-12-31 06:26:52,467 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3334192633628845, 'Total loss': 0.3334192633628845} | train loss {'Reaction outcome loss': 0.15203598821127828, 'Total loss': 0.15203598821127828}
2022-12-31 06:26:52,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:52,468 INFO:     Epoch: 36
2022-12-31 06:26:54,067 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.34909459253152214, 'Total loss': 0.34909459253152214} | train loss {'Reaction outcome loss': 0.15166944539323993, 'Total loss': 0.15166944539323993}
2022-12-31 06:26:54,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:54,068 INFO:     Epoch: 37
2022-12-31 06:26:55,706 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3452635146677494, 'Total loss': 0.3452635146677494} | train loss {'Reaction outcome loss': 0.15228206228913507, 'Total loss': 0.15228206228913507}
2022-12-31 06:26:55,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:55,706 INFO:     Epoch: 38
2022-12-31 06:26:57,327 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3484577606121699, 'Total loss': 0.3484577606121699} | train loss {'Reaction outcome loss': 0.14999483107677558, 'Total loss': 0.14999483107677558}
2022-12-31 06:26:57,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:57,327 INFO:     Epoch: 39
2022-12-31 06:26:58,888 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.31015441144506134, 'Total loss': 0.31015441144506134} | train loss {'Reaction outcome loss': 0.1450899770911647, 'Total loss': 0.1450899770911647}
2022-12-31 06:26:58,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:26:58,889 INFO:     Epoch: 40
2022-12-31 06:27:00,508 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3450563718875249, 'Total loss': 0.3450563718875249} | train loss {'Reaction outcome loss': 0.14612164897130409, 'Total loss': 0.14612164897130409}
2022-12-31 06:27:00,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:00,508 INFO:     Epoch: 41
2022-12-31 06:27:02,127 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35224088927110037, 'Total loss': 0.35224088927110037} | train loss {'Reaction outcome loss': 0.1432754707617862, 'Total loss': 0.1432754707617862}
2022-12-31 06:27:02,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:02,128 INFO:     Epoch: 42
2022-12-31 06:27:03,746 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.32477386072278025, 'Total loss': 0.32477386072278025} | train loss {'Reaction outcome loss': 0.14191891774909068, 'Total loss': 0.14191891774909068}
2022-12-31 06:27:03,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:03,746 INFO:     Epoch: 43
2022-12-31 06:27:05,365 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3412910670042038, 'Total loss': 0.3412910670042038} | train loss {'Reaction outcome loss': 0.1392952677705427, 'Total loss': 0.1392952677705427}
2022-12-31 06:27:05,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:05,365 INFO:     Epoch: 44
2022-12-31 06:27:06,985 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34486341923475267, 'Total loss': 0.34486341923475267} | train loss {'Reaction outcome loss': 0.14082264455280055, 'Total loss': 0.14082264455280055}
2022-12-31 06:27:06,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:06,985 INFO:     Epoch: 45
2022-12-31 06:27:08,557 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3613175868988037, 'Total loss': 0.3613175868988037} | train loss {'Reaction outcome loss': 0.14063640562800458, 'Total loss': 0.14063640562800458}
2022-12-31 06:27:08,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:08,558 INFO:     Epoch: 46
2022-12-31 06:27:10,161 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33109215199947356, 'Total loss': 0.33109215199947356} | train loss {'Reaction outcome loss': 0.13778615031258823, 'Total loss': 0.13778615031258823}
2022-12-31 06:27:10,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:10,161 INFO:     Epoch: 47
2022-12-31 06:27:11,814 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3360982249180476, 'Total loss': 0.3360982249180476} | train loss {'Reaction outcome loss': 0.13736776912068255, 'Total loss': 0.13736776912068255}
2022-12-31 06:27:11,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:11,815 INFO:     Epoch: 48
2022-12-31 06:27:13,420 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.32817944685618083, 'Total loss': 0.32817944685618083} | train loss {'Reaction outcome loss': 0.13782814536821505, 'Total loss': 0.13782814536821505}
2022-12-31 06:27:13,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:13,420 INFO:     Epoch: 49
2022-12-31 06:27:15,072 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33336148659388226, 'Total loss': 0.33336148659388226} | train loss {'Reaction outcome loss': 0.13516710033932577, 'Total loss': 0.13516710033932577}
2022-12-31 06:27:15,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:15,072 INFO:     Epoch: 50
2022-12-31 06:27:16,680 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35853588382403057, 'Total loss': 0.35853588382403057} | train loss {'Reaction outcome loss': 0.13499390148646095, 'Total loss': 0.13499390148646095}
2022-12-31 06:27:16,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:16,680 INFO:     Epoch: 51
2022-12-31 06:27:18,244 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.32612880567709607, 'Total loss': 0.32612880567709607} | train loss {'Reaction outcome loss': 0.1345759586679212, 'Total loss': 0.1345759586679212}
2022-12-31 06:27:18,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:18,245 INFO:     Epoch: 52
2022-12-31 06:27:19,898 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35549205044905346, 'Total loss': 0.35549205044905346} | train loss {'Reaction outcome loss': 0.13073761191688152, 'Total loss': 0.13073761191688152}
2022-12-31 06:27:19,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:19,898 INFO:     Epoch: 53
2022-12-31 06:27:21,506 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36815061966578166, 'Total loss': 0.36815061966578166} | train loss {'Reaction outcome loss': 0.13050746303187669, 'Total loss': 0.13050746303187669}
2022-12-31 06:27:21,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:21,507 INFO:     Epoch: 54
2022-12-31 06:27:23,159 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3665031850337982, 'Total loss': 0.3665031850337982} | train loss {'Reaction outcome loss': 0.12951433328388218, 'Total loss': 0.12951433328388218}
2022-12-31 06:27:23,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:23,161 INFO:     Epoch: 55
2022-12-31 06:27:24,766 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3658345262209574, 'Total loss': 0.3658345262209574} | train loss {'Reaction outcome loss': 0.12821843760788276, 'Total loss': 0.12821843760788276}
2022-12-31 06:27:24,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:24,767 INFO:     Epoch: 56
2022-12-31 06:27:26,362 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36193998356660206, 'Total loss': 0.36193998356660206} | train loss {'Reaction outcome loss': 0.12748839835174056, 'Total loss': 0.12748839835174056}
2022-12-31 06:27:26,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:26,363 INFO:     Epoch: 57
2022-12-31 06:27:28,013 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.343274520834287, 'Total loss': 0.343274520834287} | train loss {'Reaction outcome loss': 0.12999832142572715, 'Total loss': 0.12999832142572715}
2022-12-31 06:27:28,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:28,014 INFO:     Epoch: 58
2022-12-31 06:27:29,628 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3658390204111735, 'Total loss': 0.3658390204111735} | train loss {'Reaction outcome loss': 0.12564085324695945, 'Total loss': 0.12564085324695945}
2022-12-31 06:27:29,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:29,629 INFO:     Epoch: 59
2022-12-31 06:27:31,238 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3420979678630829, 'Total loss': 0.3420979678630829} | train loss {'Reaction outcome loss': 0.12469352131546305, 'Total loss': 0.12469352131546305}
2022-12-31 06:27:31,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:31,238 INFO:     Epoch: 60
2022-12-31 06:27:32,891 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33356188734372455, 'Total loss': 0.33356188734372455} | train loss {'Reaction outcome loss': 0.12727076449791772, 'Total loss': 0.12727076449791772}
2022-12-31 06:27:32,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:32,891 INFO:     Epoch: 61
2022-12-31 06:27:34,502 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3209607560498019, 'Total loss': 0.3209607560498019} | train loss {'Reaction outcome loss': 0.12318661568786636, 'Total loss': 0.12318661568786636}
2022-12-31 06:27:34,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:34,502 INFO:     Epoch: 62
2022-12-31 06:27:36,083 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3385541299978892, 'Total loss': 0.3385541299978892} | train loss {'Reaction outcome loss': 0.12479326747065532, 'Total loss': 0.12479326747065532}
2022-12-31 06:27:36,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:36,084 INFO:     Epoch: 63
2022-12-31 06:27:37,738 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37630495727062224, 'Total loss': 0.37630495727062224} | train loss {'Reaction outcome loss': 0.12189514327702541, 'Total loss': 0.12189514327702541}
2022-12-31 06:27:37,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:37,738 INFO:     Epoch: 64
2022-12-31 06:27:39,391 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34658453091979025, 'Total loss': 0.34658453091979025} | train loss {'Reaction outcome loss': 0.12224340254447702, 'Total loss': 0.12224340254447702}
2022-12-31 06:27:39,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:39,391 INFO:     Epoch: 65
2022-12-31 06:27:41,002 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3495206298927466, 'Total loss': 0.3495206298927466} | train loss {'Reaction outcome loss': 0.12194422645711878, 'Total loss': 0.12194422645711878}
2022-12-31 06:27:41,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:41,002 INFO:     Epoch: 66
2022-12-31 06:27:42,657 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35399824182192485, 'Total loss': 0.35399824182192485} | train loss {'Reaction outcome loss': 0.11989253259817968, 'Total loss': 0.11989253259817968}
2022-12-31 06:27:42,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:42,658 INFO:     Epoch: 67
2022-12-31 06:27:44,260 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35429032616472494, 'Total loss': 0.35429032616472494} | train loss {'Reaction outcome loss': 0.1196569850443978, 'Total loss': 0.1196569850443978}
2022-12-31 06:27:44,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:44,260 INFO:     Epoch: 68
2022-12-31 06:27:45,862 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4188898021976153, 'Total loss': 0.4188898021976153} | train loss {'Reaction outcome loss': 0.12926279287870265, 'Total loss': 0.12926279287870265}
2022-12-31 06:27:45,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:45,862 INFO:     Epoch: 69
2022-12-31 06:27:47,484 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38462709163626035, 'Total loss': 0.38462709163626035} | train loss {'Reaction outcome loss': 0.12473730860536333, 'Total loss': 0.12473730860536333}
2022-12-31 06:27:47,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:47,485 INFO:     Epoch: 70
2022-12-31 06:27:49,110 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.369631353020668, 'Total loss': 0.369631353020668} | train loss {'Reaction outcome loss': 0.1155726109770718, 'Total loss': 0.1155726109770718}
2022-12-31 06:27:49,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:49,110 INFO:     Epoch: 71
2022-12-31 06:27:50,734 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37138430823882423, 'Total loss': 0.37138430823882423} | train loss {'Reaction outcome loss': 0.12283379782456905, 'Total loss': 0.12283379782456905}
2022-12-31 06:27:50,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:50,734 INFO:     Epoch: 72
2022-12-31 06:27:52,358 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35926799923181535, 'Total loss': 0.35926799923181535} | train loss {'Reaction outcome loss': 0.11595763611338733, 'Total loss': 0.11595763611338733}
2022-12-31 06:27:52,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:52,359 INFO:     Epoch: 73
2022-12-31 06:27:53,959 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39177689055601755, 'Total loss': 0.39177689055601755} | train loss {'Reaction outcome loss': 0.117165059412075, 'Total loss': 0.117165059412075}
2022-12-31 06:27:53,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:53,960 INFO:     Epoch: 74
2022-12-31 06:27:55,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35067298312981926, 'Total loss': 0.35067298312981926} | train loss {'Reaction outcome loss': 0.12157270000197239, 'Total loss': 0.12157270000197239}
2022-12-31 06:27:55,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:55,587 INFO:     Epoch: 75
2022-12-31 06:27:57,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3575113919874032, 'Total loss': 0.3575113919874032} | train loss {'Reaction outcome loss': 0.12205845071597664, 'Total loss': 0.12205845071597664}
2022-12-31 06:27:57,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:57,208 INFO:     Epoch: 76
2022-12-31 06:27:58,829 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3703635131319364, 'Total loss': 0.3703635131319364} | train loss {'Reaction outcome loss': 0.11871050213239272, 'Total loss': 0.11871050213239272}
2022-12-31 06:27:58,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:27:58,830 INFO:     Epoch: 77
2022-12-31 06:28:00,451 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3338078737258911, 'Total loss': 0.3338078737258911} | train loss {'Reaction outcome loss': 0.11920357426504408, 'Total loss': 0.11920357426504408}
2022-12-31 06:28:00,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:00,452 INFO:     Epoch: 78
2022-12-31 06:28:02,074 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3517478366692861, 'Total loss': 0.3517478366692861} | train loss {'Reaction outcome loss': 0.11309387316896723, 'Total loss': 0.11309387316896723}
2022-12-31 06:28:02,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:02,075 INFO:     Epoch: 79
2022-12-31 06:28:03,670 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3528267885247866, 'Total loss': 0.3528267885247866} | train loss {'Reaction outcome loss': 0.11630652679630087, 'Total loss': 0.11630652679630087}
2022-12-31 06:28:03,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:03,670 INFO:     Epoch: 80
2022-12-31 06:28:05,270 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3527009695768356, 'Total loss': 0.3527009695768356} | train loss {'Reaction outcome loss': 0.1168262073200835, 'Total loss': 0.1168262073200835}
2022-12-31 06:28:05,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:05,271 INFO:     Epoch: 81
2022-12-31 06:28:06,872 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35404685338338215, 'Total loss': 0.35404685338338215} | train loss {'Reaction outcome loss': 0.11712280190702745, 'Total loss': 0.11712280190702745}
2022-12-31 06:28:06,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:06,873 INFO:     Epoch: 82
2022-12-31 06:28:08,473 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36236805270115535, 'Total loss': 0.36236805270115535} | train loss {'Reaction outcome loss': 0.11303628050640606, 'Total loss': 0.11303628050640606}
2022-12-31 06:28:08,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:08,474 INFO:     Epoch: 83
2022-12-31 06:28:10,073 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34912147629850854, 'Total loss': 0.34912147629850854} | train loss {'Reaction outcome loss': 0.11376803759638437, 'Total loss': 0.11376803759638437}
2022-12-31 06:28:10,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:10,073 INFO:     Epoch: 84
2022-12-31 06:28:11,725 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35682558103774986, 'Total loss': 0.35682558103774986} | train loss {'Reaction outcome loss': 0.1165600236629333, 'Total loss': 0.1165600236629333}
2022-12-31 06:28:11,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:11,725 INFO:     Epoch: 85
2022-12-31 06:28:13,301 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33665701697270073, 'Total loss': 0.33665701697270073} | train loss {'Reaction outcome loss': 0.11890005691055154, 'Total loss': 0.11890005691055154}
2022-12-31 06:28:13,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:13,302 INFO:     Epoch: 86
2022-12-31 06:28:14,903 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35952820678551994, 'Total loss': 0.35952820678551994} | train loss {'Reaction outcome loss': 0.11780998395946231, 'Total loss': 0.11780998395946231}
2022-12-31 06:28:14,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:14,903 INFO:     Epoch: 87
2022-12-31 06:28:16,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3585646336277326, 'Total loss': 0.3585646336277326} | train loss {'Reaction outcome loss': 0.11412224128679202, 'Total loss': 0.11412224128679202}
2022-12-31 06:28:16,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:16,506 INFO:     Epoch: 88
2022-12-31 06:28:18,158 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.34115012536446254, 'Total loss': 0.34115012536446254} | train loss {'Reaction outcome loss': 0.11605516730987868, 'Total loss': 0.11605516730987868}
2022-12-31 06:28:18,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:18,159 INFO:     Epoch: 89
2022-12-31 06:28:19,759 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3289356917142868, 'Total loss': 0.3289356917142868} | train loss {'Reaction outcome loss': 0.11482966507370346, 'Total loss': 0.11482966507370346}
2022-12-31 06:28:19,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:19,760 INFO:     Epoch: 90
2022-12-31 06:28:21,339 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3436592608690262, 'Total loss': 0.3436592608690262} | train loss {'Reaction outcome loss': 0.1105959157962488, 'Total loss': 0.1105959157962488}
2022-12-31 06:28:21,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:21,340 INFO:     Epoch: 91
2022-12-31 06:28:22,996 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3200587316105763, 'Total loss': 0.3200587316105763} | train loss {'Reaction outcome loss': 0.11197356695401053, 'Total loss': 0.11197356695401053}
2022-12-31 06:28:22,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:22,997 INFO:     Epoch: 92
2022-12-31 06:28:24,651 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3653914620478948, 'Total loss': 0.3653914620478948} | train loss {'Reaction outcome loss': 0.11749134727508971, 'Total loss': 0.11749134727508971}
2022-12-31 06:28:24,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:24,652 INFO:     Epoch: 93
2022-12-31 06:28:26,246 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36635662813981373, 'Total loss': 0.36635662813981373} | train loss {'Reaction outcome loss': 0.11967135658045809, 'Total loss': 0.11967135658045809}
2022-12-31 06:28:26,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:26,247 INFO:     Epoch: 94
2022-12-31 06:28:27,900 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3778781021634738, 'Total loss': 0.3778781021634738} | train loss {'Reaction outcome loss': 0.1141246127042865, 'Total loss': 0.1141246127042865}
2022-12-31 06:28:27,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:27,900 INFO:     Epoch: 95
2022-12-31 06:28:29,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3565494159857432, 'Total loss': 0.3565494159857432} | train loss {'Reaction outcome loss': 0.11647600284097784, 'Total loss': 0.11647600284097784}
2022-12-31 06:28:29,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:29,501 INFO:     Epoch: 96
2022-12-31 06:28:31,097 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37479685644308725, 'Total loss': 0.37479685644308725} | train loss {'Reaction outcome loss': 0.11125681938494753, 'Total loss': 0.11125681938494753}
2022-12-31 06:28:31,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:31,098 INFO:     Epoch: 97
2022-12-31 06:28:32,718 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3486950318018595, 'Total loss': 0.3486950318018595} | train loss {'Reaction outcome loss': 0.11111665384701189, 'Total loss': 0.11111665384701189}
2022-12-31 06:28:32,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:32,718 INFO:     Epoch: 98
2022-12-31 06:28:34,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33825424015522004, 'Total loss': 0.33825424015522004} | train loss {'Reaction outcome loss': 0.11253802552751273, 'Total loss': 0.11253802552751273}
2022-12-31 06:28:34,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:34,338 INFO:     Epoch: 99
2022-12-31 06:28:35,958 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38374702135721844, 'Total loss': 0.38374702135721844} | train loss {'Reaction outcome loss': 0.11452010954750606, 'Total loss': 0.11452010954750606}
2022-12-31 06:28:35,958 INFO:     Best model found after epoch 12 of 100.
2022-12-31 06:28:35,958 INFO:   Done with stage: TRAINING
2022-12-31 06:28:35,958 INFO:   Starting stage: EVALUATION
2022-12-31 06:28:36,096 INFO:   Done with stage: EVALUATION
2022-12-31 06:28:36,096 INFO:   Leaving out SEQ value Fold_3
2022-12-31 06:28:36,109 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 06:28:36,109 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:28:36,741 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:28:36,741 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:28:36,811 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:28:36,811 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:28:36,811 INFO:     No hyperparam tuning for this model
2022-12-31 06:28:36,811 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:28:36,811 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:28:36,812 INFO:     None feature selector for col prot
2022-12-31 06:28:36,812 INFO:     None feature selector for col prot
2022-12-31 06:28:36,812 INFO:     None feature selector for col prot
2022-12-31 06:28:36,813 INFO:     None feature selector for col chem
2022-12-31 06:28:36,813 INFO:     None feature selector for col chem
2022-12-31 06:28:36,813 INFO:     None feature selector for col chem
2022-12-31 06:28:36,813 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:28:36,813 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:28:36,815 INFO:     Number of params in model 224011
2022-12-31 06:28:36,818 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:28:36,818 INFO:   Starting stage: TRAINING
2022-12-31 06:28:36,862 INFO:     Val loss before train {'Reaction outcome loss': 1.0409328619639078, 'Total loss': 1.0409328619639078}
2022-12-31 06:28:36,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:36,862 INFO:     Epoch: 0
2022-12-31 06:28:38,474 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5820075015227, 'Total loss': 0.5820075015227} | train loss {'Reaction outcome loss': 0.7853007260914687, 'Total loss': 0.7853007260914687}
2022-12-31 06:28:38,474 INFO:     Found new best model at epoch 0
2022-12-31 06:28:38,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:38,475 INFO:     Epoch: 1
2022-12-31 06:28:40,075 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4862562507390976, 'Total loss': 0.4862562507390976} | train loss {'Reaction outcome loss': 0.5095324159323514, 'Total loss': 0.5095324159323514}
2022-12-31 06:28:40,075 INFO:     Found new best model at epoch 1
2022-12-31 06:28:40,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:40,076 INFO:     Epoch: 2
2022-12-31 06:28:41,723 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4625676184892654, 'Total loss': 0.4625676184892654} | train loss {'Reaction outcome loss': 0.4380000917029468, 'Total loss': 0.4380000917029468}
2022-12-31 06:28:41,723 INFO:     Found new best model at epoch 2
2022-12-31 06:28:41,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:41,724 INFO:     Epoch: 3
2022-12-31 06:28:43,316 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45544787247975665, 'Total loss': 0.45544787247975665} | train loss {'Reaction outcome loss': 0.3974695812378611, 'Total loss': 0.3974695812378611}
2022-12-31 06:28:43,317 INFO:     Found new best model at epoch 3
2022-12-31 06:28:43,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:43,318 INFO:     Epoch: 4
2022-12-31 06:28:44,911 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44516194264094033, 'Total loss': 0.44516194264094033} | train loss {'Reaction outcome loss': 0.3710106857421197, 'Total loss': 0.3710106857421197}
2022-12-31 06:28:44,911 INFO:     Found new best model at epoch 4
2022-12-31 06:28:44,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:44,912 INFO:     Epoch: 5
2022-12-31 06:28:46,520 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43972371915976205, 'Total loss': 0.43972371915976205} | train loss {'Reaction outcome loss': 0.34888991627555627, 'Total loss': 0.34888991627555627}
2022-12-31 06:28:46,520 INFO:     Found new best model at epoch 5
2022-12-31 06:28:46,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:46,521 INFO:     Epoch: 6
2022-12-31 06:28:48,120 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4508510132630666, 'Total loss': 0.4508510132630666} | train loss {'Reaction outcome loss': 0.3277536553122622, 'Total loss': 0.3277536553122622}
2022-12-31 06:28:48,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:48,120 INFO:     Epoch: 7
2022-12-31 06:28:49,692 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44817429780960083, 'Total loss': 0.44817429780960083} | train loss {'Reaction outcome loss': 0.31519789330579423, 'Total loss': 0.31519789330579423}
2022-12-31 06:28:49,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:49,693 INFO:     Epoch: 8
2022-12-31 06:28:51,339 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43128814697265627, 'Total loss': 0.43128814697265627} | train loss {'Reaction outcome loss': 0.2999760300030202, 'Total loss': 0.2999760300030202}
2022-12-31 06:28:51,339 INFO:     Found new best model at epoch 8
2022-12-31 06:28:51,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:51,340 INFO:     Epoch: 9
2022-12-31 06:28:52,938 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.446983336408933, 'Total loss': 0.446983336408933} | train loss {'Reaction outcome loss': 0.28585188251821114, 'Total loss': 0.28585188251821114}
2022-12-31 06:28:52,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:52,939 INFO:     Epoch: 10
2022-12-31 06:28:54,585 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.422173265616099, 'Total loss': 0.422173265616099} | train loss {'Reaction outcome loss': 0.27306171484810093, 'Total loss': 0.27306171484810093}
2022-12-31 06:28:54,585 INFO:     Found new best model at epoch 10
2022-12-31 06:28:54,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:54,586 INFO:     Epoch: 11
2022-12-31 06:28:56,185 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43938114245732623, 'Total loss': 0.43938114245732623} | train loss {'Reaction outcome loss': 0.265015217287964, 'Total loss': 0.265015217287964}
2022-12-31 06:28:56,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:56,186 INFO:     Epoch: 12
2022-12-31 06:28:57,774 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41181735644737877, 'Total loss': 0.41181735644737877} | train loss {'Reaction outcome loss': 0.25580861058509174, 'Total loss': 0.25580861058509174}
2022-12-31 06:28:57,774 INFO:     Found new best model at epoch 12
2022-12-31 06:28:57,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:57,775 INFO:     Epoch: 13
2022-12-31 06:28:59,421 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43566425939400993, 'Total loss': 0.43566425939400993} | train loss {'Reaction outcome loss': 0.2356134753933538, 'Total loss': 0.2356134753933538}
2022-12-31 06:28:59,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:28:59,422 INFO:     Epoch: 14
2022-12-31 06:29:01,019 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44471013446648916, 'Total loss': 0.44471013446648916} | train loss {'Reaction outcome loss': 0.23073783436373912, 'Total loss': 0.23073783436373912}
2022-12-31 06:29:01,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:01,019 INFO:     Epoch: 15
2022-12-31 06:29:02,666 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46745921969413756, 'Total loss': 0.46745921969413756} | train loss {'Reaction outcome loss': 0.22187990015679662, 'Total loss': 0.22187990015679662}
2022-12-31 06:29:02,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:02,667 INFO:     Epoch: 16
2022-12-31 06:29:04,261 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44362787405649823, 'Total loss': 0.44362787405649823} | train loss {'Reaction outcome loss': 0.21977947610038104, 'Total loss': 0.21977947610038104}
2022-12-31 06:29:04,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:04,261 INFO:     Epoch: 17
2022-12-31 06:29:05,908 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4613889714082082, 'Total loss': 0.4613889714082082} | train loss {'Reaction outcome loss': 0.20924391963215538, 'Total loss': 0.20924391963215538}
2022-12-31 06:29:05,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:05,908 INFO:     Epoch: 18
2022-12-31 06:29:07,507 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43749111195405327, 'Total loss': 0.43749111195405327} | train loss {'Reaction outcome loss': 0.2037278507041298, 'Total loss': 0.2037278507041298}
2022-12-31 06:29:07,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:07,507 INFO:     Epoch: 19
2022-12-31 06:29:09,121 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42783003946145376, 'Total loss': 0.42783003946145376} | train loss {'Reaction outcome loss': 0.19960662924800573, 'Total loss': 0.19960662924800573}
2022-12-31 06:29:09,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:09,121 INFO:     Epoch: 20
2022-12-31 06:29:10,733 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43225207428137463, 'Total loss': 0.43225207428137463} | train loss {'Reaction outcome loss': 0.18985782716518793, 'Total loss': 0.18985782716518793}
2022-12-31 06:29:10,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:10,733 INFO:     Epoch: 21
2022-12-31 06:29:12,365 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4427300125360489, 'Total loss': 0.4427300125360489} | train loss {'Reaction outcome loss': 0.1912555561363424, 'Total loss': 0.1912555561363424}
2022-12-31 06:29:12,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:12,365 INFO:     Epoch: 22
2022-12-31 06:29:13,967 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42502386023600897, 'Total loss': 0.42502386023600897} | train loss {'Reaction outcome loss': 0.18608530225819012, 'Total loss': 0.18608530225819012}
2022-12-31 06:29:13,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:13,967 INFO:     Epoch: 23
2022-12-31 06:29:15,607 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43863820532957715, 'Total loss': 0.43863820532957715} | train loss {'Reaction outcome loss': 0.1818766173234571, 'Total loss': 0.1818766173234571}
2022-12-31 06:29:15,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:15,608 INFO:     Epoch: 24
2022-12-31 06:29:17,226 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4700381269057592, 'Total loss': 0.4700381269057592} | train loss {'Reaction outcome loss': 0.17751822000430836, 'Total loss': 0.17751822000430836}
2022-12-31 06:29:17,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:17,226 INFO:     Epoch: 25
2022-12-31 06:29:18,873 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4962667385737101, 'Total loss': 0.4962667385737101} | train loss {'Reaction outcome loss': 0.17547434487127642, 'Total loss': 0.17547434487127642}
2022-12-31 06:29:18,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:18,873 INFO:     Epoch: 26
2022-12-31 06:29:20,521 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4718040108680725, 'Total loss': 0.4718040108680725} | train loss {'Reaction outcome loss': 0.17438933701551224, 'Total loss': 0.17438933701551224}
2022-12-31 06:29:20,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:20,521 INFO:     Epoch: 27
2022-12-31 06:29:22,121 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47877780397733055, 'Total loss': 0.47877780397733055} | train loss {'Reaction outcome loss': 0.1690094876358961, 'Total loss': 0.1690094876358961}
2022-12-31 06:29:22,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:22,121 INFO:     Epoch: 28
2022-12-31 06:29:23,767 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4761867334445318, 'Total loss': 0.4761867334445318} | train loss {'Reaction outcome loss': 0.1674555395473982, 'Total loss': 0.1674555395473982}
2022-12-31 06:29:23,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:23,767 INFO:     Epoch: 29
2022-12-31 06:29:25,381 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5079679270585378, 'Total loss': 0.5079679270585378} | train loss {'Reaction outcome loss': 0.16445458469223298, 'Total loss': 0.16445458469223298}
2022-12-31 06:29:25,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:25,381 INFO:     Epoch: 30
2022-12-31 06:29:27,029 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4658585488796234, 'Total loss': 0.4658585488796234} | train loss {'Reaction outcome loss': 0.1616815980285024, 'Total loss': 0.1616815980285024}
2022-12-31 06:29:27,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:27,031 INFO:     Epoch: 31
2022-12-31 06:29:28,632 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47714215914408364, 'Total loss': 0.47714215914408364} | train loss {'Reaction outcome loss': 0.15667950464310226, 'Total loss': 0.15667950464310226}
2022-12-31 06:29:28,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:28,632 INFO:     Epoch: 32
2022-12-31 06:29:30,280 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49449042081832884, 'Total loss': 0.49449042081832884} | train loss {'Reaction outcome loss': 0.16114984511060046, 'Total loss': 0.16114984511060046}
2022-12-31 06:29:30,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:30,280 INFO:     Epoch: 33
2022-12-31 06:29:31,881 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4780593867103259, 'Total loss': 0.4780593867103259} | train loss {'Reaction outcome loss': 0.15971821056330923, 'Total loss': 0.15971821056330923}
2022-12-31 06:29:31,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:31,881 INFO:     Epoch: 34
2022-12-31 06:29:33,483 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4811113548775514, 'Total loss': 0.4811113548775514} | train loss {'Reaction outcome loss': 0.1522310385651095, 'Total loss': 0.1522310385651095}
2022-12-31 06:29:33,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:33,484 INFO:     Epoch: 35
2022-12-31 06:29:35,090 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4607694645722707, 'Total loss': 0.4607694645722707} | train loss {'Reaction outcome loss': 0.148631751585936, 'Total loss': 0.148631751585936}
2022-12-31 06:29:35,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:35,091 INFO:     Epoch: 36
2022-12-31 06:29:36,702 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4574865867694219, 'Total loss': 0.4574865867694219} | train loss {'Reaction outcome loss': 0.14704402857852397, 'Total loss': 0.14704402857852397}
2022-12-31 06:29:36,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:36,702 INFO:     Epoch: 37
2022-12-31 06:29:38,312 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46076554159323374, 'Total loss': 0.46076554159323374} | train loss {'Reaction outcome loss': 0.14569043724596392, 'Total loss': 0.14569043724596392}
2022-12-31 06:29:38,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:38,312 INFO:     Epoch: 38
2022-12-31 06:29:39,924 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47547156910101573, 'Total loss': 0.47547156910101573} | train loss {'Reaction outcome loss': 0.1431572384238516, 'Total loss': 0.1431572384238516}
2022-12-31 06:29:39,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:39,924 INFO:     Epoch: 39
2022-12-31 06:29:41,537 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49035553534825643, 'Total loss': 0.49035553534825643} | train loss {'Reaction outcome loss': 0.14409753629910477, 'Total loss': 0.14409753629910477}
2022-12-31 06:29:41,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:41,537 INFO:     Epoch: 40
2022-12-31 06:29:43,142 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4649758001168569, 'Total loss': 0.4649758001168569} | train loss {'Reaction outcome loss': 0.1445803581668753, 'Total loss': 0.1445803581668753}
2022-12-31 06:29:43,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:43,143 INFO:     Epoch: 41
2022-12-31 06:29:44,738 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49300142129262287, 'Total loss': 0.49300142129262287} | train loss {'Reaction outcome loss': 0.13766904320352927, 'Total loss': 0.13766904320352927}
2022-12-31 06:29:44,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:44,739 INFO:     Epoch: 42
2022-12-31 06:29:46,385 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43658686776955924, 'Total loss': 0.43658686776955924} | train loss {'Reaction outcome loss': 0.1336213767207859, 'Total loss': 0.1336213767207859}
2022-12-31 06:29:46,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:46,385 INFO:     Epoch: 43
2022-12-31 06:29:48,002 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47478650013605755, 'Total loss': 0.47478650013605755} | train loss {'Reaction outcome loss': 0.1373674353147983, 'Total loss': 0.1373674353147983}
2022-12-31 06:29:48,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:48,002 INFO:     Epoch: 44
2022-12-31 06:29:49,613 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44209458424399295, 'Total loss': 0.44209458424399295} | train loss {'Reaction outcome loss': 0.13851811845647, 'Total loss': 0.13851811845647}
2022-12-31 06:29:49,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:49,613 INFO:     Epoch: 45
2022-12-31 06:29:51,242 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4341510007778803, 'Total loss': 0.4341510007778803} | train loss {'Reaction outcome loss': 0.13350512103720025, 'Total loss': 0.13350512103720025}
2022-12-31 06:29:51,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:51,242 INFO:     Epoch: 46
2022-12-31 06:29:52,868 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4763058483600616, 'Total loss': 0.4763058483600616} | train loss {'Reaction outcome loss': 0.1339327834321411, 'Total loss': 0.1339327834321411}
2022-12-31 06:29:52,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:52,869 INFO:     Epoch: 47
2022-12-31 06:29:54,516 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4462740043799082, 'Total loss': 0.4462740043799082} | train loss {'Reaction outcome loss': 0.13125107017594762, 'Total loss': 0.13125107017594762}
2022-12-31 06:29:54,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:54,516 INFO:     Epoch: 48
2022-12-31 06:29:56,114 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4641523897647858, 'Total loss': 0.4641523897647858} | train loss {'Reaction outcome loss': 0.13033079177366344, 'Total loss': 0.13033079177366344}
2022-12-31 06:29:56,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:56,114 INFO:     Epoch: 49
2022-12-31 06:29:57,714 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48331056038538617, 'Total loss': 0.48331056038538617} | train loss {'Reaction outcome loss': 0.13292795780537847, 'Total loss': 0.13292795780537847}
2022-12-31 06:29:57,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:57,716 INFO:     Epoch: 50
2022-12-31 06:29:59,314 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4288683782021205, 'Total loss': 0.4288683782021205} | train loss {'Reaction outcome loss': 0.12675132783941734, 'Total loss': 0.12675132783941734}
2022-12-31 06:29:59,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:29:59,314 INFO:     Epoch: 51
2022-12-31 06:30:00,963 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49493350386619567, 'Total loss': 0.49493350386619567} | train loss {'Reaction outcome loss': 0.12668642631626173, 'Total loss': 0.12668642631626173}
2022-12-31 06:30:00,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:00,963 INFO:     Epoch: 52
2022-12-31 06:30:02,552 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45064919379850227, 'Total loss': 0.45064919379850227} | train loss {'Reaction outcome loss': 0.12306659059230607, 'Total loss': 0.12306659059230607}
2022-12-31 06:30:02,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:02,552 INFO:     Epoch: 53
2022-12-31 06:30:04,152 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44275044488410153, 'Total loss': 0.44275044488410153} | train loss {'Reaction outcome loss': 0.12955493309906932, 'Total loss': 0.12955493309906932}
2022-12-31 06:30:04,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:04,153 INFO:     Epoch: 54
2022-12-31 06:30:05,759 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4558493157227834, 'Total loss': 0.4558493157227834} | train loss {'Reaction outcome loss': 0.12826858963919702, 'Total loss': 0.12826858963919702}
2022-12-31 06:30:05,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:05,759 INFO:     Epoch: 55
2022-12-31 06:30:07,411 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44287995994091034, 'Total loss': 0.44287995994091034} | train loss {'Reaction outcome loss': 0.12633097025262185, 'Total loss': 0.12633097025262185}
2022-12-31 06:30:07,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:07,411 INFO:     Epoch: 56
2022-12-31 06:30:09,018 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45552223126093544, 'Total loss': 0.45552223126093544} | train loss {'Reaction outcome loss': 0.12242202537011478, 'Total loss': 0.12242202537011478}
2022-12-31 06:30:09,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:09,018 INFO:     Epoch: 57
2022-12-31 06:30:10,632 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4925490816434224, 'Total loss': 0.4925490816434224} | train loss {'Reaction outcome loss': 0.11925812545761248, 'Total loss': 0.11925812545761248}
2022-12-31 06:30:10,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:10,633 INFO:     Epoch: 58
2022-12-31 06:30:12,272 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5165248314539591, 'Total loss': 0.5165248314539591} | train loss {'Reaction outcome loss': 0.12280028558680754, 'Total loss': 0.12280028558680754}
2022-12-31 06:30:12,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:12,272 INFO:     Epoch: 59
2022-12-31 06:30:13,877 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4824555695056915, 'Total loss': 0.4824555695056915} | train loss {'Reaction outcome loss': 0.12169697316663661, 'Total loss': 0.12169697316663661}
2022-12-31 06:30:13,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:13,877 INFO:     Epoch: 60
2022-12-31 06:30:15,525 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4735003511110942, 'Total loss': 0.4735003511110942} | train loss {'Reaction outcome loss': 0.12170631182635878, 'Total loss': 0.12170631182635878}
2022-12-31 06:30:15,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:15,525 INFO:     Epoch: 61
2022-12-31 06:30:17,127 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47564254303773246, 'Total loss': 0.47564254303773246} | train loss {'Reaction outcome loss': 0.12459306325337034, 'Total loss': 0.12459306325337034}
2022-12-31 06:30:17,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:17,128 INFO:     Epoch: 62
2022-12-31 06:30:18,731 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4533604231973489, 'Total loss': 0.4533604231973489} | train loss {'Reaction outcome loss': 0.12139571017514054, 'Total loss': 0.12139571017514054}
2022-12-31 06:30:18,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:18,731 INFO:     Epoch: 63
2022-12-31 06:30:20,355 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4617922534545263, 'Total loss': 0.4617922534545263} | train loss {'Reaction outcome loss': 0.11984455846582673, 'Total loss': 0.11984455846582673}
2022-12-31 06:30:20,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:20,355 INFO:     Epoch: 64
2022-12-31 06:30:21,955 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4684960981210073, 'Total loss': 0.4684960981210073} | train loss {'Reaction outcome loss': 0.11911324418965222, 'Total loss': 0.11911324418965222}
2022-12-31 06:30:21,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:21,955 INFO:     Epoch: 65
2022-12-31 06:30:23,604 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4422815332189202, 'Total loss': 0.4422815332189202} | train loss {'Reaction outcome loss': 0.11953371372363861, 'Total loss': 0.11953371372363861}
2022-12-31 06:30:23,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:23,604 INFO:     Epoch: 66
2022-12-31 06:30:25,254 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48475232621033987, 'Total loss': 0.48475232621033987} | train loss {'Reaction outcome loss': 0.11383032009616194, 'Total loss': 0.11383032009616194}
2022-12-31 06:30:25,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:25,254 INFO:     Epoch: 67
2022-12-31 06:30:26,857 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5009673813978831, 'Total loss': 0.5009673813978831} | train loss {'Reaction outcome loss': 0.11542514083572687, 'Total loss': 0.11542514083572687}
2022-12-31 06:30:26,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:26,857 INFO:     Epoch: 68
2022-12-31 06:30:28,458 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4695483885705471, 'Total loss': 0.4695483885705471} | train loss {'Reaction outcome loss': 0.11721911275377259, 'Total loss': 0.11721911275377259}
2022-12-31 06:30:28,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:28,460 INFO:     Epoch: 69
2022-12-31 06:30:30,057 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.500817064444224, 'Total loss': 0.500817064444224} | train loss {'Reaction outcome loss': 0.11813478232378434, 'Total loss': 0.11813478232378434}
2022-12-31 06:30:30,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:30,057 INFO:     Epoch: 70
2022-12-31 06:30:31,705 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4965963969628016, 'Total loss': 0.4965963969628016} | train loss {'Reaction outcome loss': 0.11708638546715452, 'Total loss': 0.11708638546715452}
2022-12-31 06:30:31,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:31,706 INFO:     Epoch: 71
2022-12-31 06:30:33,307 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4962829679250717, 'Total loss': 0.4962829679250717} | train loss {'Reaction outcome loss': 0.1153413565563304, 'Total loss': 0.1153413565563304}
2022-12-31 06:30:33,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:33,307 INFO:     Epoch: 72
2022-12-31 06:30:34,954 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42724961986144383, 'Total loss': 0.42724961986144383} | train loss {'Reaction outcome loss': 0.11865851042567047, 'Total loss': 0.11865851042567047}
2022-12-31 06:30:34,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:34,955 INFO:     Epoch: 73
2022-12-31 06:30:36,555 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48620411852995554, 'Total loss': 0.48620411852995554} | train loss {'Reaction outcome loss': 0.11676837350395354, 'Total loss': 0.11676837350395354}
2022-12-31 06:30:36,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:36,556 INFO:     Epoch: 74
2022-12-31 06:30:38,150 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4989960268139839, 'Total loss': 0.4989960268139839} | train loss {'Reaction outcome loss': 0.11063526149399087, 'Total loss': 0.11063526149399087}
2022-12-31 06:30:38,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:38,150 INFO:     Epoch: 75
2022-12-31 06:30:39,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48465169668197633, 'Total loss': 0.48465169668197633} | train loss {'Reaction outcome loss': 0.11039357262854584, 'Total loss': 0.11039357262854584}
2022-12-31 06:30:39,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:39,754 INFO:     Epoch: 76
2022-12-31 06:30:41,350 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45338278313477837, 'Total loss': 0.45338278313477837} | train loss {'Reaction outcome loss': 0.10720934246533684, 'Total loss': 0.10720934246533684}
2022-12-31 06:30:41,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:41,351 INFO:     Epoch: 77
2022-12-31 06:30:42,997 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45633556743462883, 'Total loss': 0.45633556743462883} | train loss {'Reaction outcome loss': 0.10770898318300262, 'Total loss': 0.10770898318300262}
2022-12-31 06:30:42,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:42,997 INFO:     Epoch: 78
2022-12-31 06:30:44,599 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5397479315598805, 'Total loss': 0.5397479315598805} | train loss {'Reaction outcome loss': 0.10834677692847293, 'Total loss': 0.10834677692847293}
2022-12-31 06:30:44,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:44,599 INFO:     Epoch: 79
2022-12-31 06:30:46,247 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47664429917931556, 'Total loss': 0.47664429917931556} | train loss {'Reaction outcome loss': 0.11117941097717991, 'Total loss': 0.11117941097717991}
2022-12-31 06:30:46,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:46,247 INFO:     Epoch: 80
2022-12-31 06:30:47,849 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5215124746163686, 'Total loss': 0.5215124746163686} | train loss {'Reaction outcome loss': 0.11643265144244491, 'Total loss': 0.11643265144244491}
2022-12-31 06:30:47,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:47,850 INFO:     Epoch: 81
2022-12-31 06:30:49,452 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5212474624315898, 'Total loss': 0.5212474624315898} | train loss {'Reaction outcome loss': 0.11451859079939296, 'Total loss': 0.11451859079939296}
2022-12-31 06:30:49,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:49,452 INFO:     Epoch: 82
2022-12-31 06:30:51,056 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4627822528282801, 'Total loss': 0.4627822528282801} | train loss {'Reaction outcome loss': 0.11320538924079075, 'Total loss': 0.11320538924079075}
2022-12-31 06:30:51,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:51,056 INFO:     Epoch: 83
2022-12-31 06:30:52,660 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4823914736509323, 'Total loss': 0.4823914736509323} | train loss {'Reaction outcome loss': 0.1127643012015265, 'Total loss': 0.1127643012015265}
2022-12-31 06:30:52,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:52,660 INFO:     Epoch: 84
2022-12-31 06:30:54,309 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45051567753156024, 'Total loss': 0.45051567753156024} | train loss {'Reaction outcome loss': 0.10657734120684256, 'Total loss': 0.10657734120684256}
2022-12-31 06:30:54,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:54,309 INFO:     Epoch: 85
2022-12-31 06:30:55,912 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46255049606164295, 'Total loss': 0.46255049606164295} | train loss {'Reaction outcome loss': 0.10767237227171278, 'Total loss': 0.10767237227171278}
2022-12-31 06:30:55,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:55,913 INFO:     Epoch: 86
2022-12-31 06:30:57,515 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4750012228886286, 'Total loss': 0.4750012228886286} | train loss {'Reaction outcome loss': 0.105522129087685, 'Total loss': 0.105522129087685}
2022-12-31 06:30:57,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:57,515 INFO:     Epoch: 87
2022-12-31 06:30:59,129 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5278834760189056, 'Total loss': 0.5278834760189056} | train loss {'Reaction outcome loss': 0.10581689871909035, 'Total loss': 0.10581689871909035}
2022-12-31 06:30:59,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:30:59,130 INFO:     Epoch: 88
2022-12-31 06:31:00,742 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4561915868272384, 'Total loss': 0.4561915868272384} | train loss {'Reaction outcome loss': 0.10666473800377858, 'Total loss': 0.10666473800377858}
2022-12-31 06:31:00,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:00,742 INFO:     Epoch: 89
2022-12-31 06:31:02,356 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48936425149440765, 'Total loss': 0.48936425149440765} | train loss {'Reaction outcome loss': 0.11248981010257489, 'Total loss': 0.11248981010257489}
2022-12-31 06:31:02,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:02,356 INFO:     Epoch: 90
2022-12-31 06:31:03,972 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4510246977210045, 'Total loss': 0.4510246977210045} | train loss {'Reaction outcome loss': 0.10899787824754449, 'Total loss': 0.10899787824754449}
2022-12-31 06:31:03,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:03,972 INFO:     Epoch: 91
2022-12-31 06:31:05,579 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48125295639038085, 'Total loss': 0.48125295639038085} | train loss {'Reaction outcome loss': 0.10917754901399078, 'Total loss': 0.10917754901399078}
2022-12-31 06:31:05,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:05,579 INFO:     Epoch: 92
2022-12-31 06:31:07,197 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5012617627779643, 'Total loss': 0.5012617627779643} | train loss {'Reaction outcome loss': 0.11272501519748143, 'Total loss': 0.11272501519748143}
2022-12-31 06:31:07,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:07,197 INFO:     Epoch: 93
2022-12-31 06:31:08,815 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.508108600974083, 'Total loss': 0.508108600974083} | train loss {'Reaction outcome loss': 0.10375674340307658, 'Total loss': 0.10375674340307658}
2022-12-31 06:31:08,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:08,815 INFO:     Epoch: 94
2022-12-31 06:31:10,432 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47289714018503826, 'Total loss': 0.47289714018503826} | train loss {'Reaction outcome loss': 0.10481839916999741, 'Total loss': 0.10481839916999741}
2022-12-31 06:31:10,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:10,433 INFO:     Epoch: 95
2022-12-31 06:31:12,048 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5035603294769923, 'Total loss': 0.5035603294769923} | train loss {'Reaction outcome loss': 0.10543038155593579, 'Total loss': 0.10543038155593579}
2022-12-31 06:31:12,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:12,049 INFO:     Epoch: 96
2022-12-31 06:31:13,668 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48290901879469555, 'Total loss': 0.48290901879469555} | train loss {'Reaction outcome loss': 0.10399618581015849, 'Total loss': 0.10399618581015849}
2022-12-31 06:31:13,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:13,668 INFO:     Epoch: 97
2022-12-31 06:31:15,267 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46918939650058744, 'Total loss': 0.46918939650058744} | train loss {'Reaction outcome loss': 0.10846849408464664, 'Total loss': 0.10846849408464664}
2022-12-31 06:31:15,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:15,267 INFO:     Epoch: 98
2022-12-31 06:31:16,879 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4878139436244965, 'Total loss': 0.4878139436244965} | train loss {'Reaction outcome loss': 0.108136534405149, 'Total loss': 0.108136534405149}
2022-12-31 06:31:16,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:16,879 INFO:     Epoch: 99
2022-12-31 06:31:18,490 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46640455623467764, 'Total loss': 0.46640455623467764} | train loss {'Reaction outcome loss': 0.1102854607297592, 'Total loss': 0.1102854607297592}
2022-12-31 06:31:18,490 INFO:     Best model found after epoch 13 of 100.
2022-12-31 06:31:18,491 INFO:   Done with stage: TRAINING
2022-12-31 06:31:18,491 INFO:   Starting stage: EVALUATION
2022-12-31 06:31:18,634 INFO:   Done with stage: EVALUATION
2022-12-31 06:31:18,634 INFO:   Leaving out SEQ value Fold_4
2022-12-31 06:31:18,646 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:31:18,646 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:31:19,291 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:31:19,292 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:31:19,362 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:31:19,362 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:31:19,362 INFO:     No hyperparam tuning for this model
2022-12-31 06:31:19,362 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:31:19,362 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:31:19,363 INFO:     None feature selector for col prot
2022-12-31 06:31:19,363 INFO:     None feature selector for col prot
2022-12-31 06:31:19,363 INFO:     None feature selector for col prot
2022-12-31 06:31:19,364 INFO:     None feature selector for col chem
2022-12-31 06:31:19,364 INFO:     None feature selector for col chem
2022-12-31 06:31:19,364 INFO:     None feature selector for col chem
2022-12-31 06:31:19,364 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:31:19,364 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:31:19,366 INFO:     Number of params in model 224011
2022-12-31 06:31:19,369 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:31:19,369 INFO:   Starting stage: TRAINING
2022-12-31 06:31:19,415 INFO:     Val loss before train {'Reaction outcome loss': 1.0442839821179708, 'Total loss': 1.0442839821179708}
2022-12-31 06:31:19,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:19,415 INFO:     Epoch: 0
2022-12-31 06:31:21,028 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.569593592484792, 'Total loss': 0.569593592484792} | train loss {'Reaction outcome loss': 0.7823877254689949, 'Total loss': 0.7823877254689949}
2022-12-31 06:31:21,029 INFO:     Found new best model at epoch 0
2022-12-31 06:31:21,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:21,030 INFO:     Epoch: 1
2022-12-31 06:31:22,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4740679959456126, 'Total loss': 0.4740679959456126} | train loss {'Reaction outcome loss': 0.5152643904666943, 'Total loss': 0.5152643904666943}
2022-12-31 06:31:22,644 INFO:     Found new best model at epoch 1
2022-12-31 06:31:22,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:22,645 INFO:     Epoch: 2
2022-12-31 06:31:24,265 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4275454044342041, 'Total loss': 0.4275454044342041} | train loss {'Reaction outcome loss': 0.4481140373252434, 'Total loss': 0.4481140373252434}
2022-12-31 06:31:24,265 INFO:     Found new best model at epoch 2
2022-12-31 06:31:24,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:24,266 INFO:     Epoch: 3
2022-12-31 06:31:25,879 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4030673990646998, 'Total loss': 0.4030673990646998} | train loss {'Reaction outcome loss': 0.40714854618831386, 'Total loss': 0.40714854618831386}
2022-12-31 06:31:25,879 INFO:     Found new best model at epoch 3
2022-12-31 06:31:25,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:25,880 INFO:     Epoch: 4
2022-12-31 06:31:27,494 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3858582486708959, 'Total loss': 0.3858582486708959} | train loss {'Reaction outcome loss': 0.3779236564439708, 'Total loss': 0.3779236564439708}
2022-12-31 06:31:27,494 INFO:     Found new best model at epoch 4
2022-12-31 06:31:27,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:27,495 INFO:     Epoch: 5
2022-12-31 06:31:29,109 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.37149334996938704, 'Total loss': 0.37149334996938704} | train loss {'Reaction outcome loss': 0.3598924562793927, 'Total loss': 0.3598924562793927}
2022-12-31 06:31:29,109 INFO:     Found new best model at epoch 5
2022-12-31 06:31:29,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:29,110 INFO:     Epoch: 6
2022-12-31 06:31:30,727 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3998421768347422, 'Total loss': 0.3998421768347422} | train loss {'Reaction outcome loss': 0.3315625265409387, 'Total loss': 0.3315625265409387}
2022-12-31 06:31:30,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:30,728 INFO:     Epoch: 7
2022-12-31 06:31:32,344 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.373632816473643, 'Total loss': 0.373632816473643} | train loss {'Reaction outcome loss': 0.3148688139744859, 'Total loss': 0.3148688139744859}
2022-12-31 06:31:32,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:32,344 INFO:     Epoch: 8
2022-12-31 06:31:33,954 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.34178861087809004, 'Total loss': 0.34178861087809004} | train loss {'Reaction outcome loss': 0.29534818424404924, 'Total loss': 0.29534818424404924}
2022-12-31 06:31:33,954 INFO:     Found new best model at epoch 8
2022-12-31 06:31:33,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:33,955 INFO:     Epoch: 9
2022-12-31 06:31:35,571 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36820563475290935, 'Total loss': 0.36820563475290935} | train loss {'Reaction outcome loss': 0.28232217114524194, 'Total loss': 0.28232217114524194}
2022-12-31 06:31:35,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:35,571 INFO:     Epoch: 10
2022-12-31 06:31:37,233 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.36407826443513236, 'Total loss': 0.36407826443513236} | train loss {'Reaction outcome loss': 0.2694715821762788, 'Total loss': 0.2694715821762788}
2022-12-31 06:31:37,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:37,234 INFO:     Epoch: 11
2022-12-31 06:31:38,853 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39710903763771055, 'Total loss': 0.39710903763771055} | train loss {'Reaction outcome loss': 0.25991116019735194, 'Total loss': 0.25991116019735194}
2022-12-31 06:31:38,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:38,853 INFO:     Epoch: 12
2022-12-31 06:31:40,515 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3941398233175278, 'Total loss': 0.3941398233175278} | train loss {'Reaction outcome loss': 0.25374687469793833, 'Total loss': 0.25374687469793833}
2022-12-31 06:31:40,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:40,515 INFO:     Epoch: 13
2022-12-31 06:31:42,200 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3737332264582316, 'Total loss': 0.3737332264582316} | train loss {'Reaction outcome loss': 0.24779493540362624, 'Total loss': 0.24779493540362624}
2022-12-31 06:31:42,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:42,201 INFO:     Epoch: 14
2022-12-31 06:31:43,861 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3743335945531726, 'Total loss': 0.3743335945531726} | train loss {'Reaction outcome loss': 0.2339961823899353, 'Total loss': 0.2339961823899353}
2022-12-31 06:31:43,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:43,862 INFO:     Epoch: 15
2022-12-31 06:31:45,523 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3653085605551799, 'Total loss': 0.3653085605551799} | train loss {'Reaction outcome loss': 0.22651144928649825, 'Total loss': 0.22651144928649825}
2022-12-31 06:31:45,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:45,523 INFO:     Epoch: 16
2022-12-31 06:31:47,150 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3535634487867355, 'Total loss': 0.3535634487867355} | train loss {'Reaction outcome loss': 0.21861318651159914, 'Total loss': 0.21861318651159914}
2022-12-31 06:31:47,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:47,150 INFO:     Epoch: 17
2022-12-31 06:31:48,811 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.337583926320076, 'Total loss': 0.337583926320076} | train loss {'Reaction outcome loss': 0.2144231652247085, 'Total loss': 0.2144231652247085}
2022-12-31 06:31:48,811 INFO:     Found new best model at epoch 17
2022-12-31 06:31:48,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:48,812 INFO:     Epoch: 18
2022-12-31 06:31:50,428 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3624069899320602, 'Total loss': 0.3624069899320602} | train loss {'Reaction outcome loss': 0.20935525778696645, 'Total loss': 0.20935525778696645}
2022-12-31 06:31:50,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:50,429 INFO:     Epoch: 19
2022-12-31 06:31:52,068 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37668465574582416, 'Total loss': 0.37668465574582416} | train loss {'Reaction outcome loss': 0.20342879333664945, 'Total loss': 0.20342879333664945}
2022-12-31 06:31:52,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:52,068 INFO:     Epoch: 20
2022-12-31 06:31:53,681 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38808978696664176, 'Total loss': 0.38808978696664176} | train loss {'Reaction outcome loss': 0.1925059289787896, 'Total loss': 0.1925059289787896}
2022-12-31 06:31:53,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:53,681 INFO:     Epoch: 21
2022-12-31 06:31:55,342 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38969393720229467, 'Total loss': 0.38969393720229467} | train loss {'Reaction outcome loss': 0.1923470912686463, 'Total loss': 0.1923470912686463}
2022-12-31 06:31:55,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:55,342 INFO:     Epoch: 22
2022-12-31 06:31:57,002 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37920927902062734, 'Total loss': 0.37920927902062734} | train loss {'Reaction outcome loss': 0.18782495600643798, 'Total loss': 0.18782495600643798}
2022-12-31 06:31:57,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:57,003 INFO:     Epoch: 23
2022-12-31 06:31:58,613 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36835157324870427, 'Total loss': 0.36835157324870427} | train loss {'Reaction outcome loss': 0.18978007516378295, 'Total loss': 0.18978007516378295}
2022-12-31 06:31:58,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:31:58,614 INFO:     Epoch: 24
2022-12-31 06:32:00,250 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34700925648212433, 'Total loss': 0.34700925648212433} | train loss {'Reaction outcome loss': 0.17622388261910257, 'Total loss': 0.17622388261910257}
2022-12-31 06:32:00,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:00,250 INFO:     Epoch: 25
2022-12-31 06:32:01,864 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3624555210272471, 'Total loss': 0.3624555210272471} | train loss {'Reaction outcome loss': 0.17769657620089635, 'Total loss': 0.17769657620089635}
2022-12-31 06:32:01,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:01,864 INFO:     Epoch: 26
2022-12-31 06:32:03,525 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.34948463483403125, 'Total loss': 0.34948463483403125} | train loss {'Reaction outcome loss': 0.16977213335770142, 'Total loss': 0.16977213335770142}
2022-12-31 06:32:03,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:03,525 INFO:     Epoch: 27
2022-12-31 06:32:05,184 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3757592499256134, 'Total loss': 0.3757592499256134} | train loss {'Reaction outcome loss': 0.16844291478712653, 'Total loss': 0.16844291478712653}
2022-12-31 06:32:05,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:05,185 INFO:     Epoch: 28
2022-12-31 06:32:06,846 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36938128918409346, 'Total loss': 0.36938128918409346} | train loss {'Reaction outcome loss': 0.1671907528177236, 'Total loss': 0.1671907528177236}
2022-12-31 06:32:06,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:06,847 INFO:     Epoch: 29
2022-12-31 06:32:08,462 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36918374747037885, 'Total loss': 0.36918374747037885} | train loss {'Reaction outcome loss': 0.16058216430752983, 'Total loss': 0.16058216430752983}
2022-12-31 06:32:08,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:08,462 INFO:     Epoch: 30
2022-12-31 06:32:09,906 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3601977323492368, 'Total loss': 0.3601977323492368} | train loss {'Reaction outcome loss': 0.1669034423151364, 'Total loss': 0.1669034423151364}
2022-12-31 06:32:09,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:09,906 INFO:     Epoch: 31
2022-12-31 06:32:11,022 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3748859544595083, 'Total loss': 0.3748859544595083} | train loss {'Reaction outcome loss': 0.18816048084830772, 'Total loss': 0.18816048084830772}
2022-12-31 06:32:11,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:11,023 INFO:     Epoch: 32
2022-12-31 06:32:12,134 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3644571840763092, 'Total loss': 0.3644571840763092} | train loss {'Reaction outcome loss': 0.1553432206979198, 'Total loss': 0.1553432206979198}
2022-12-31 06:32:12,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:12,135 INFO:     Epoch: 33
2022-12-31 06:32:13,253 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.33056423713763555, 'Total loss': 0.33056423713763555} | train loss {'Reaction outcome loss': 0.15313072512314344, 'Total loss': 0.15313072512314344}
2022-12-31 06:32:13,254 INFO:     Found new best model at epoch 33
2022-12-31 06:32:13,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:13,255 INFO:     Epoch: 34
2022-12-31 06:32:14,544 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35131711363792417, 'Total loss': 0.35131711363792417} | train loss {'Reaction outcome loss': 0.15163542493499574, 'Total loss': 0.15163542493499574}
2022-12-31 06:32:14,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:14,545 INFO:     Epoch: 35
2022-12-31 06:32:16,160 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3521966407696406, 'Total loss': 0.3521966407696406} | train loss {'Reaction outcome loss': 0.1473776562564561, 'Total loss': 0.1473776562564561}
2022-12-31 06:32:16,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:16,160 INFO:     Epoch: 36
2022-12-31 06:32:17,778 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3760110765695572, 'Total loss': 0.3760110765695572} | train loss {'Reaction outcome loss': 0.1566678016409413, 'Total loss': 0.1566678016409413}
2022-12-31 06:32:17,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:17,779 INFO:     Epoch: 37
2022-12-31 06:32:19,409 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34553770869970324, 'Total loss': 0.34553770869970324} | train loss {'Reaction outcome loss': 0.14982719693132135, 'Total loss': 0.14982719693132135}
2022-12-31 06:32:19,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:19,409 INFO:     Epoch: 38
2022-12-31 06:32:21,028 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3566018005212148, 'Total loss': 0.3566018005212148} | train loss {'Reaction outcome loss': 0.14518269637440992, 'Total loss': 0.14518269637440992}
2022-12-31 06:32:21,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:21,028 INFO:     Epoch: 39
2022-12-31 06:32:22,647 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34917818705240883, 'Total loss': 0.34917818705240883} | train loss {'Reaction outcome loss': 0.14521316598251544, 'Total loss': 0.14521316598251544}
2022-12-31 06:32:22,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:22,647 INFO:     Epoch: 40
2022-12-31 06:32:24,270 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3452050154407819, 'Total loss': 0.3452050154407819} | train loss {'Reaction outcome loss': 0.1404908983922328, 'Total loss': 0.1404908983922328}
2022-12-31 06:32:24,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:24,270 INFO:     Epoch: 41
2022-12-31 06:32:25,892 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3751933832963308, 'Total loss': 0.3751933832963308} | train loss {'Reaction outcome loss': 0.14103230853040746, 'Total loss': 0.14103230853040746}
2022-12-31 06:32:25,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:25,893 INFO:     Epoch: 42
2022-12-31 06:32:27,522 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3776669710874557, 'Total loss': 0.3776669710874557} | train loss {'Reaction outcome loss': 0.14012904077174096, 'Total loss': 0.14012904077174096}
2022-12-31 06:32:27,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:27,523 INFO:     Epoch: 43
2022-12-31 06:32:29,156 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3666584988435109, 'Total loss': 0.3666584988435109} | train loss {'Reaction outcome loss': 0.13738933545950652, 'Total loss': 0.13738933545950652}
2022-12-31 06:32:29,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:29,156 INFO:     Epoch: 44
2022-12-31 06:32:30,787 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3963294337193171, 'Total loss': 0.3963294337193171} | train loss {'Reaction outcome loss': 0.1352563661690194, 'Total loss': 0.1352563661690194}
2022-12-31 06:32:30,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:30,787 INFO:     Epoch: 45
2022-12-31 06:32:32,428 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38955924759308497, 'Total loss': 0.38955924759308497} | train loss {'Reaction outcome loss': 0.1391571279773455, 'Total loss': 0.1391571279773455}
2022-12-31 06:32:32,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:32,428 INFO:     Epoch: 46
2022-12-31 06:32:34,059 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3530006835858027, 'Total loss': 0.3530006835858027} | train loss {'Reaction outcome loss': 0.13891958971204155, 'Total loss': 0.13891958971204155}
2022-12-31 06:32:34,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:34,060 INFO:     Epoch: 47
2022-12-31 06:32:35,682 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38298554221789044, 'Total loss': 0.38298554221789044} | train loss {'Reaction outcome loss': 0.13855791777161253, 'Total loss': 0.13855791777161253}
2022-12-31 06:32:35,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:35,682 INFO:     Epoch: 48
2022-12-31 06:32:37,315 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37317300513386725, 'Total loss': 0.37317300513386725} | train loss {'Reaction outcome loss': 0.13217673356136758, 'Total loss': 0.13217673356136758}
2022-12-31 06:32:37,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:37,315 INFO:     Epoch: 49
2022-12-31 06:32:38,948 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3530640661716461, 'Total loss': 0.3530640661716461} | train loss {'Reaction outcome loss': 0.13163039898970147, 'Total loss': 0.13163039898970147}
2022-12-31 06:32:38,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:38,948 INFO:     Epoch: 50
2022-12-31 06:32:40,581 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3622255831956863, 'Total loss': 0.3622255831956863} | train loss {'Reaction outcome loss': 0.13486228868187292, 'Total loss': 0.13486228868187292}
2022-12-31 06:32:40,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:40,581 INFO:     Epoch: 51
2022-12-31 06:32:42,219 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3840925008058548, 'Total loss': 0.3840925008058548} | train loss {'Reaction outcome loss': 0.12858348786392235, 'Total loss': 0.12858348786392235}
2022-12-31 06:32:42,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:42,220 INFO:     Epoch: 52
2022-12-31 06:32:43,846 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3703417629003525, 'Total loss': 0.3703417629003525} | train loss {'Reaction outcome loss': 0.15687244475333684, 'Total loss': 0.15687244475333684}
2022-12-31 06:32:43,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:43,846 INFO:     Epoch: 53
2022-12-31 06:32:45,484 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37044694523016614, 'Total loss': 0.37044694523016614} | train loss {'Reaction outcome loss': 0.1401202337971578, 'Total loss': 0.1401202337971578}
2022-12-31 06:32:45,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:45,485 INFO:     Epoch: 54
2022-12-31 06:32:47,108 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37118684202432634, 'Total loss': 0.37118684202432634} | train loss {'Reaction outcome loss': 0.13651497395545922, 'Total loss': 0.13651497395545922}
2022-12-31 06:32:47,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:47,108 INFO:     Epoch: 55
2022-12-31 06:32:48,731 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3758410553137461, 'Total loss': 0.3758410553137461} | train loss {'Reaction outcome loss': 0.13109993957745694, 'Total loss': 0.13109993957745694}
2022-12-31 06:32:48,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:48,732 INFO:     Epoch: 56
2022-12-31 06:32:50,355 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3656595081090927, 'Total loss': 0.3656595081090927} | train loss {'Reaction outcome loss': 0.12499602319186796, 'Total loss': 0.12499602319186796}
2022-12-31 06:32:50,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:50,355 INFO:     Epoch: 57
2022-12-31 06:32:51,973 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37041257321834564, 'Total loss': 0.37041257321834564} | train loss {'Reaction outcome loss': 0.1248259230140821, 'Total loss': 0.1248259230140821}
2022-12-31 06:32:51,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:51,973 INFO:     Epoch: 58
2022-12-31 06:32:53,592 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34865196148554484, 'Total loss': 0.34865196148554484} | train loss {'Reaction outcome loss': 0.12766767980402632, 'Total loss': 0.12766767980402632}
2022-12-31 06:32:53,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:53,593 INFO:     Epoch: 59
2022-12-31 06:32:55,216 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36261108616987864, 'Total loss': 0.36261108616987864} | train loss {'Reaction outcome loss': 0.12362500887041054, 'Total loss': 0.12362500887041054}
2022-12-31 06:32:55,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:55,216 INFO:     Epoch: 60
2022-12-31 06:32:56,840 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3945714150865873, 'Total loss': 0.3945714150865873} | train loss {'Reaction outcome loss': 0.12621763861481694, 'Total loss': 0.12621763861481694}
2022-12-31 06:32:56,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:56,840 INFO:     Epoch: 61
2022-12-31 06:32:58,462 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3551947146654129, 'Total loss': 0.3551947146654129} | train loss {'Reaction outcome loss': 0.12789096132568692, 'Total loss': 0.12789096132568692}
2022-12-31 06:32:58,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:32:58,462 INFO:     Epoch: 62
2022-12-31 06:33:00,086 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3744482100009918, 'Total loss': 0.3744482100009918} | train loss {'Reaction outcome loss': 0.1207142405079482, 'Total loss': 0.1207142405079482}
2022-12-31 06:33:00,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:00,087 INFO:     Epoch: 63
2022-12-31 06:33:01,701 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37212273478507996, 'Total loss': 0.37212273478507996} | train loss {'Reaction outcome loss': 0.12092229816725181, 'Total loss': 0.12092229816725181}
2022-12-31 06:33:01,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:01,702 INFO:     Epoch: 64
2022-12-31 06:33:03,326 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35492919584115346, 'Total loss': 0.35492919584115346} | train loss {'Reaction outcome loss': 0.12476135697890667, 'Total loss': 0.12476135697890667}
2022-12-31 06:33:03,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:03,326 INFO:     Epoch: 65
2022-12-31 06:33:04,951 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3676372011502584, 'Total loss': 0.3676372011502584} | train loss {'Reaction outcome loss': 0.11960565919002546, 'Total loss': 0.11960565919002546}
2022-12-31 06:33:04,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:04,952 INFO:     Epoch: 66
2022-12-31 06:33:06,576 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.364535436530908, 'Total loss': 0.364535436530908} | train loss {'Reaction outcome loss': 0.12614604767472687, 'Total loss': 0.12614604767472687}
2022-12-31 06:33:06,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:06,576 INFO:     Epoch: 67
2022-12-31 06:33:08,201 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35888744542996087, 'Total loss': 0.35888744542996087} | train loss {'Reaction outcome loss': 0.1261428844237571, 'Total loss': 0.1261428844237571}
2022-12-31 06:33:08,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:08,201 INFO:     Epoch: 68
2022-12-31 06:33:09,819 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3688912570476532, 'Total loss': 0.3688912570476532} | train loss {'Reaction outcome loss': 0.12245936054207868, 'Total loss': 0.12245936054207868}
2022-12-31 06:33:09,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:09,819 INFO:     Epoch: 69
2022-12-31 06:33:11,432 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4075078149636587, 'Total loss': 0.4075078149636587} | train loss {'Reaction outcome loss': 0.11929121752758004, 'Total loss': 0.11929121752758004}
2022-12-31 06:33:11,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:11,432 INFO:     Epoch: 70
2022-12-31 06:33:13,056 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.380518231789271, 'Total loss': 0.380518231789271} | train loss {'Reaction outcome loss': 0.11682282862596143, 'Total loss': 0.11682282862596143}
2022-12-31 06:33:13,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:13,057 INFO:     Epoch: 71
2022-12-31 06:33:14,680 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37472209632396697, 'Total loss': 0.37472209632396697} | train loss {'Reaction outcome loss': 0.11821641152103742, 'Total loss': 0.11821641152103742}
2022-12-31 06:33:14,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:14,680 INFO:     Epoch: 72
2022-12-31 06:33:16,304 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3770444874962171, 'Total loss': 0.3770444874962171} | train loss {'Reaction outcome loss': 0.11906684511869452, 'Total loss': 0.11906684511869452}
2022-12-31 06:33:16,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:16,304 INFO:     Epoch: 73
2022-12-31 06:33:17,921 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3777246944606304, 'Total loss': 0.3777246944606304} | train loss {'Reaction outcome loss': 0.12343004532327093, 'Total loss': 0.12343004532327093}
2022-12-31 06:33:17,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:17,922 INFO:     Epoch: 74
2022-12-31 06:33:19,554 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3726449308296045, 'Total loss': 0.3726449308296045} | train loss {'Reaction outcome loss': 0.12554682186379543, 'Total loss': 0.12554682186379543}
2022-12-31 06:33:19,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:19,554 INFO:     Epoch: 75
2022-12-31 06:33:21,172 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3718824289739132, 'Total loss': 0.3718824289739132} | train loss {'Reaction outcome loss': 0.125282595190557, 'Total loss': 0.125282595190557}
2022-12-31 06:33:21,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:21,172 INFO:     Epoch: 76
2022-12-31 06:33:22,793 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3561303794539223, 'Total loss': 0.3561303794539223} | train loss {'Reaction outcome loss': 0.11900762436435679, 'Total loss': 0.11900762436435679}
2022-12-31 06:33:22,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:22,793 INFO:     Epoch: 77
2022-12-31 06:33:24,420 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37712194323539733, 'Total loss': 0.37712194323539733} | train loss {'Reaction outcome loss': 0.11675152598605643, 'Total loss': 0.11675152598605643}
2022-12-31 06:33:24,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:24,421 INFO:     Epoch: 78
2022-12-31 06:33:26,044 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.369475382566452, 'Total loss': 0.369475382566452} | train loss {'Reaction outcome loss': 0.11753424666686982, 'Total loss': 0.11753424666686982}
2022-12-31 06:33:26,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:26,044 INFO:     Epoch: 79
2022-12-31 06:33:27,680 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3977926989396413, 'Total loss': 0.3977926989396413} | train loss {'Reaction outcome loss': 0.1189596688371608, 'Total loss': 0.1189596688371608}
2022-12-31 06:33:27,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:27,680 INFO:     Epoch: 80
2022-12-31 06:33:29,332 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36412738462289174, 'Total loss': 0.36412738462289174} | train loss {'Reaction outcome loss': 0.12015264103884228, 'Total loss': 0.12015264103884228}
2022-12-31 06:33:29,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:29,333 INFO:     Epoch: 81
2022-12-31 06:33:30,952 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3805979202191035, 'Total loss': 0.3805979202191035} | train loss {'Reaction outcome loss': 0.11649124930018856, 'Total loss': 0.11649124930018856}
2022-12-31 06:33:30,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:30,953 INFO:     Epoch: 82
2022-12-31 06:33:32,619 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36006317337354027, 'Total loss': 0.36006317337354027} | train loss {'Reaction outcome loss': 0.11346016669446818, 'Total loss': 0.11346016669446818}
2022-12-31 06:33:32,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:32,619 INFO:     Epoch: 83
2022-12-31 06:33:34,237 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3454503426949183, 'Total loss': 0.3454503426949183} | train loss {'Reaction outcome loss': 0.11095833220157225, 'Total loss': 0.11095833220157225}
2022-12-31 06:33:34,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:34,238 INFO:     Epoch: 84
2022-12-31 06:33:35,904 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37296597262223563, 'Total loss': 0.37296597262223563} | train loss {'Reaction outcome loss': 0.11520583135838472, 'Total loss': 0.11520583135838472}
2022-12-31 06:33:35,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:35,904 INFO:     Epoch: 85
2022-12-31 06:33:37,555 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3838351880510648, 'Total loss': 0.3838351880510648} | train loss {'Reaction outcome loss': 0.11659458715281368, 'Total loss': 0.11659458715281368}
2022-12-31 06:33:37,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:37,556 INFO:     Epoch: 86
2022-12-31 06:33:39,168 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33997200479110085, 'Total loss': 0.33997200479110085} | train loss {'Reaction outcome loss': 0.11484373687003888, 'Total loss': 0.11484373687003888}
2022-12-31 06:33:39,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:39,168 INFO:     Epoch: 87
2022-12-31 06:33:40,785 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36890148123105365, 'Total loss': 0.36890148123105365} | train loss {'Reaction outcome loss': 0.12161964523311906, 'Total loss': 0.12161964523311906}
2022-12-31 06:33:40,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:40,785 INFO:     Epoch: 88
2022-12-31 06:33:42,403 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3836024045944214, 'Total loss': 0.3836024045944214} | train loss {'Reaction outcome loss': 0.12119886248315132, 'Total loss': 0.12119886248315132}
2022-12-31 06:33:42,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:42,404 INFO:     Epoch: 89
2022-12-31 06:33:44,020 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3740836330999931, 'Total loss': 0.3740836330999931} | train loss {'Reaction outcome loss': 0.11238684744500813, 'Total loss': 0.11238684744500813}
2022-12-31 06:33:44,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:44,020 INFO:     Epoch: 90
2022-12-31 06:33:45,639 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36916759858528775, 'Total loss': 0.36916759858528775} | train loss {'Reaction outcome loss': 0.11352485005298386, 'Total loss': 0.11352485005298386}
2022-12-31 06:33:45,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:45,639 INFO:     Epoch: 91
2022-12-31 06:33:47,272 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3854786783456802, 'Total loss': 0.3854786783456802} | train loss {'Reaction outcome loss': 0.11347165657376088, 'Total loss': 0.11347165657376088}
2022-12-31 06:33:47,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:47,272 INFO:     Epoch: 92
2022-12-31 06:33:48,916 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3754688968261083, 'Total loss': 0.3754688968261083} | train loss {'Reaction outcome loss': 0.11618686820366893, 'Total loss': 0.11618686820366893}
2022-12-31 06:33:48,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:48,917 INFO:     Epoch: 93
2022-12-31 06:33:50,546 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3898893316586812, 'Total loss': 0.3898893316586812} | train loss {'Reaction outcome loss': 0.1110855083510667, 'Total loss': 0.1110855083510667}
2022-12-31 06:33:50,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:50,547 INFO:     Epoch: 94
2022-12-31 06:33:52,175 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3807529325907429, 'Total loss': 0.3807529325907429} | train loss {'Reaction outcome loss': 0.107554794863656, 'Total loss': 0.107554794863656}
2022-12-31 06:33:52,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:52,175 INFO:     Epoch: 95
2022-12-31 06:33:53,803 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3773141105969747, 'Total loss': 0.3773141105969747} | train loss {'Reaction outcome loss': 0.10695644177368208, 'Total loss': 0.10695644177368208}
2022-12-31 06:33:53,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:53,803 INFO:     Epoch: 96
2022-12-31 06:33:55,423 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3947356041986495, 'Total loss': 0.3947356041986495} | train loss {'Reaction outcome loss': 0.10817973032902481, 'Total loss': 0.10817973032902481}
2022-12-31 06:33:55,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:55,424 INFO:     Epoch: 97
2022-12-31 06:33:57,042 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3858896791934967, 'Total loss': 0.3858896791934967} | train loss {'Reaction outcome loss': 0.11479603245886434, 'Total loss': 0.11479603245886434}
2022-12-31 06:33:57,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:57,043 INFO:     Epoch: 98
2022-12-31 06:33:58,672 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3444079560538133, 'Total loss': 0.3444079560538133} | train loss {'Reaction outcome loss': 0.11684379194512208, 'Total loss': 0.11684379194512208}
2022-12-31 06:33:58,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:33:58,673 INFO:     Epoch: 99
2022-12-31 06:34:00,302 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4043960233529409, 'Total loss': 0.4043960233529409} | train loss {'Reaction outcome loss': 0.1134660860187833, 'Total loss': 0.1134660860187833}
2022-12-31 06:34:00,302 INFO:     Best model found after epoch 34 of 100.
2022-12-31 06:34:00,302 INFO:   Done with stage: TRAINING
2022-12-31 06:34:00,302 INFO:   Starting stage: EVALUATION
2022-12-31 06:34:00,432 INFO:   Done with stage: EVALUATION
2022-12-31 06:34:00,432 INFO:   Leaving out SEQ value Fold_5
2022-12-31 06:34:00,445 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:34:00,445 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:34:01,084 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:34:01,084 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:34:01,154 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:34:01,155 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:34:01,155 INFO:     No hyperparam tuning for this model
2022-12-31 06:34:01,155 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:34:01,155 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:34:01,156 INFO:     None feature selector for col prot
2022-12-31 06:34:01,156 INFO:     None feature selector for col prot
2022-12-31 06:34:01,156 INFO:     None feature selector for col prot
2022-12-31 06:34:01,156 INFO:     None feature selector for col chem
2022-12-31 06:34:01,156 INFO:     None feature selector for col chem
2022-12-31 06:34:01,156 INFO:     None feature selector for col chem
2022-12-31 06:34:01,156 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:34:01,157 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:34:01,158 INFO:     Number of params in model 224011
2022-12-31 06:34:01,162 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:34:01,162 INFO:   Starting stage: TRAINING
2022-12-31 06:34:01,208 INFO:     Val loss before train {'Reaction outcome loss': 1.0295028289159138, 'Total loss': 1.0295028289159138}
2022-12-31 06:34:01,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:01,209 INFO:     Epoch: 0
2022-12-31 06:34:02,841 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.4930298447608948, 'Total loss': 0.4930298447608948} | train loss {'Reaction outcome loss': 0.7836026170871396, 'Total loss': 0.7836026170871396}
2022-12-31 06:34:02,842 INFO:     Found new best model at epoch 0
2022-12-31 06:34:02,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:02,843 INFO:     Epoch: 1
2022-12-31 06:34:04,455 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4195093015829722, 'Total loss': 0.4195093015829722} | train loss {'Reaction outcome loss': 0.5113479874866165, 'Total loss': 0.5113479874866165}
2022-12-31 06:34:04,455 INFO:     Found new best model at epoch 1
2022-12-31 06:34:04,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:04,456 INFO:     Epoch: 2
2022-12-31 06:34:06,074 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.3952108244101206, 'Total loss': 0.3952108244101206} | train loss {'Reaction outcome loss': 0.4435352993643154, 'Total loss': 0.4435352993643154}
2022-12-31 06:34:06,074 INFO:     Found new best model at epoch 2
2022-12-31 06:34:06,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:06,075 INFO:     Epoch: 3
2022-12-31 06:34:07,695 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.36478810807069145, 'Total loss': 0.36478810807069145} | train loss {'Reaction outcome loss': 0.40647315120567445, 'Total loss': 0.40647315120567445}
2022-12-31 06:34:07,696 INFO:     Found new best model at epoch 3
2022-12-31 06:34:07,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:07,697 INFO:     Epoch: 4
2022-12-31 06:34:09,316 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39034106930096946, 'Total loss': 0.39034106930096946} | train loss {'Reaction outcome loss': 0.37761540873844235, 'Total loss': 0.37761540873844235}
2022-12-31 06:34:09,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:09,316 INFO:     Epoch: 5
2022-12-31 06:34:10,979 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38928706049919126, 'Total loss': 0.38928706049919126} | train loss {'Reaction outcome loss': 0.356096143240406, 'Total loss': 0.356096143240406}
2022-12-31 06:34:10,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:10,979 INFO:     Epoch: 6
2022-12-31 06:34:12,613 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.372310933470726, 'Total loss': 0.372310933470726} | train loss {'Reaction outcome loss': 0.33670597313565837, 'Total loss': 0.33670597313565837}
2022-12-31 06:34:12,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:12,613 INFO:     Epoch: 7
2022-12-31 06:34:14,272 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3382356598973274, 'Total loss': 0.3382356598973274} | train loss {'Reaction outcome loss': 0.3291648026231838, 'Total loss': 0.3291648026231838}
2022-12-31 06:34:14,272 INFO:     Found new best model at epoch 7
2022-12-31 06:34:14,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:14,273 INFO:     Epoch: 8
2022-12-31 06:34:15,898 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3695611039797465, 'Total loss': 0.3695611039797465} | train loss {'Reaction outcome loss': 0.3163460831603278, 'Total loss': 0.3163460831603278}
2022-12-31 06:34:15,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:15,899 INFO:     Epoch: 9
2022-12-31 06:34:17,529 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.35091825624307, 'Total loss': 0.35091825624307} | train loss {'Reaction outcome loss': 0.2957238454668634, 'Total loss': 0.2957238454668634}
2022-12-31 06:34:17,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:17,530 INFO:     Epoch: 10
2022-12-31 06:34:19,159 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35308501025040945, 'Total loss': 0.35308501025040945} | train loss {'Reaction outcome loss': 0.2813756859863845, 'Total loss': 0.2813756859863845}
2022-12-31 06:34:19,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:19,160 INFO:     Epoch: 11
2022-12-31 06:34:20,787 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34941604832808176, 'Total loss': 0.34941604832808176} | train loss {'Reaction outcome loss': 0.26905511045481323, 'Total loss': 0.26905511045481323}
2022-12-31 06:34:20,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:20,787 INFO:     Epoch: 12
2022-12-31 06:34:22,406 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.33228136599063873, 'Total loss': 0.33228136599063873} | train loss {'Reaction outcome loss': 0.2571646997619056, 'Total loss': 0.2571646997619056}
2022-12-31 06:34:22,406 INFO:     Found new best model at epoch 12
2022-12-31 06:34:22,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:22,407 INFO:     Epoch: 13
2022-12-31 06:34:24,026 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3589940816164017, 'Total loss': 0.3589940816164017} | train loss {'Reaction outcome loss': 0.24755822089343343, 'Total loss': 0.24755822089343343}
2022-12-31 06:34:24,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:24,027 INFO:     Epoch: 14
2022-12-31 06:34:25,676 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3286844636003176, 'Total loss': 0.3286844636003176} | train loss {'Reaction outcome loss': 0.23939598706193213, 'Total loss': 0.23939598706193213}
2022-12-31 06:34:25,676 INFO:     Found new best model at epoch 14
2022-12-31 06:34:25,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:25,677 INFO:     Epoch: 15
2022-12-31 06:34:27,320 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3744839131832123, 'Total loss': 0.3744839131832123} | train loss {'Reaction outcome loss': 0.23266645682678497, 'Total loss': 0.23266645682678497}
2022-12-31 06:34:27,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:27,320 INFO:     Epoch: 16
2022-12-31 06:34:28,938 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37025628487269086, 'Total loss': 0.37025628487269086} | train loss {'Reaction outcome loss': 0.2276635219282268, 'Total loss': 0.2276635219282268}
2022-12-31 06:34:28,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:28,938 INFO:     Epoch: 17
2022-12-31 06:34:30,601 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36149009267489113, 'Total loss': 0.36149009267489113} | train loss {'Reaction outcome loss': 0.2175759043902213, 'Total loss': 0.2175759043902213}
2022-12-31 06:34:30,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:30,602 INFO:     Epoch: 18
2022-12-31 06:34:32,230 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.357857953508695, 'Total loss': 0.357857953508695} | train loss {'Reaction outcome loss': 0.2102692948672853, 'Total loss': 0.2102692948672853}
2022-12-31 06:34:32,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:32,231 INFO:     Epoch: 19
2022-12-31 06:34:33,879 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35771555403868355, 'Total loss': 0.35771555403868355} | train loss {'Reaction outcome loss': 0.20810543728884365, 'Total loss': 0.20810543728884365}
2022-12-31 06:34:33,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:33,880 INFO:     Epoch: 20
2022-12-31 06:34:35,502 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3651423441867034, 'Total loss': 0.3651423441867034} | train loss {'Reaction outcome loss': 0.19936231123991066, 'Total loss': 0.19936231123991066}
2022-12-31 06:34:35,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:35,502 INFO:     Epoch: 21
2022-12-31 06:34:37,129 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.34895810633897784, 'Total loss': 0.34895810633897784} | train loss {'Reaction outcome loss': 0.19447090101185377, 'Total loss': 0.19447090101185377}
2022-12-31 06:34:37,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:37,129 INFO:     Epoch: 22
2022-12-31 06:34:38,750 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34109511226415634, 'Total loss': 0.34109511226415634} | train loss {'Reaction outcome loss': 0.19005512171323694, 'Total loss': 0.19005512171323694}
2022-12-31 06:34:38,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:38,751 INFO:     Epoch: 23
2022-12-31 06:34:40,379 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3635262240966161, 'Total loss': 0.3635262240966161} | train loss {'Reaction outcome loss': 0.19017345660393112, 'Total loss': 0.19017345660393112}
2022-12-31 06:34:40,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:40,379 INFO:     Epoch: 24
2022-12-31 06:34:42,002 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35530641426642734, 'Total loss': 0.35530641426642734} | train loss {'Reaction outcome loss': 0.2025766789544529, 'Total loss': 0.2025766789544529}
2022-12-31 06:34:42,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:42,003 INFO:     Epoch: 25
2022-12-31 06:34:43,627 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3888929973045985, 'Total loss': 0.3888929973045985} | train loss {'Reaction outcome loss': 0.17955501783686434, 'Total loss': 0.17955501783686434}
2022-12-31 06:34:43,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:43,628 INFO:     Epoch: 26
2022-12-31 06:34:45,254 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38168470164140067, 'Total loss': 0.38168470164140067} | train loss {'Reaction outcome loss': 0.1751598351486567, 'Total loss': 0.1751598351486567}
2022-12-31 06:34:45,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:45,254 INFO:     Epoch: 27
2022-12-31 06:34:46,914 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3675730923811595, 'Total loss': 0.3675730923811595} | train loss {'Reaction outcome loss': 0.17289875693660323, 'Total loss': 0.17289875693660323}
2022-12-31 06:34:46,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:46,914 INFO:     Epoch: 28
2022-12-31 06:34:48,542 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38328871006766957, 'Total loss': 0.38328871006766957} | train loss {'Reaction outcome loss': 0.17972257103689987, 'Total loss': 0.17972257103689987}
2022-12-31 06:34:48,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:48,543 INFO:     Epoch: 29
2022-12-31 06:34:50,165 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42972058008114494, 'Total loss': 0.42972058008114494} | train loss {'Reaction outcome loss': 0.2449722257780208, 'Total loss': 0.2449722257780208}
2022-12-31 06:34:50,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:50,166 INFO:     Epoch: 30
2022-12-31 06:34:51,792 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37836459974447884, 'Total loss': 0.37836459974447884} | train loss {'Reaction outcome loss': 0.18688433777382327, 'Total loss': 0.18688433777382327}
2022-12-31 06:34:51,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:51,792 INFO:     Epoch: 31
2022-12-31 06:34:53,418 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37194158832232155, 'Total loss': 0.37194158832232155} | train loss {'Reaction outcome loss': 0.16599527365368608, 'Total loss': 0.16599527365368608}
2022-12-31 06:34:53,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:53,418 INFO:     Epoch: 32
2022-12-31 06:34:55,046 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3694338142871857, 'Total loss': 0.3694338142871857} | train loss {'Reaction outcome loss': 0.16207425664786412, 'Total loss': 0.16207425664786412}
2022-12-31 06:34:55,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:55,047 INFO:     Epoch: 33
2022-12-31 06:34:56,666 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37496383984883624, 'Total loss': 0.37496383984883624} | train loss {'Reaction outcome loss': 0.158392116062991, 'Total loss': 0.158392116062991}
2022-12-31 06:34:56,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:56,666 INFO:     Epoch: 34
2022-12-31 06:34:58,288 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3547736858328184, 'Total loss': 0.3547736858328184} | train loss {'Reaction outcome loss': 0.1541621711584267, 'Total loss': 0.1541621711584267}
2022-12-31 06:34:58,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:58,288 INFO:     Epoch: 35
2022-12-31 06:34:59,899 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.374041294803222, 'Total loss': 0.374041294803222} | train loss {'Reaction outcome loss': 0.15210475631528939, 'Total loss': 0.15210475631528939}
2022-12-31 06:34:59,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:34:59,900 INFO:     Epoch: 36
2022-12-31 06:35:01,521 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40649471879005433, 'Total loss': 0.40649471879005433} | train loss {'Reaction outcome loss': 0.15046822393449713, 'Total loss': 0.15046822393449713}
2022-12-31 06:35:01,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:01,522 INFO:     Epoch: 37
2022-12-31 06:35:03,150 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36038182030121485, 'Total loss': 0.36038182030121485} | train loss {'Reaction outcome loss': 0.14959541013703911, 'Total loss': 0.14959541013703911}
2022-12-31 06:35:03,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:03,151 INFO:     Epoch: 38
2022-12-31 06:35:04,781 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39377774596214293, 'Total loss': 0.39377774596214293} | train loss {'Reaction outcome loss': 0.14657362805429738, 'Total loss': 0.14657362805429738}
2022-12-31 06:35:04,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:04,781 INFO:     Epoch: 39
2022-12-31 06:35:06,412 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3638603647549947, 'Total loss': 0.3638603647549947} | train loss {'Reaction outcome loss': 0.14600934624415485, 'Total loss': 0.14600934624415485}
2022-12-31 06:35:06,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:06,412 INFO:     Epoch: 40
2022-12-31 06:35:08,038 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3488696905473868, 'Total loss': 0.3488696905473868} | train loss {'Reaction outcome loss': 0.1564562946871814, 'Total loss': 0.1564562946871814}
2022-12-31 06:35:08,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:08,039 INFO:     Epoch: 41
2022-12-31 06:35:09,662 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36730081935723624, 'Total loss': 0.36730081935723624} | train loss {'Reaction outcome loss': 0.14425602072755073, 'Total loss': 0.14425602072755073}
2022-12-31 06:35:09,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:09,662 INFO:     Epoch: 42
2022-12-31 06:35:11,293 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3795261720816294, 'Total loss': 0.3795261720816294} | train loss {'Reaction outcome loss': 0.14044858129404864, 'Total loss': 0.14044858129404864}
2022-12-31 06:35:11,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:11,294 INFO:     Epoch: 43
2022-12-31 06:35:12,923 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37120988219976425, 'Total loss': 0.37120988219976425} | train loss {'Reaction outcome loss': 0.13791377040747582, 'Total loss': 0.13791377040747582}
2022-12-31 06:35:12,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:12,923 INFO:     Epoch: 44
2022-12-31 06:35:14,555 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.368939811984698, 'Total loss': 0.368939811984698} | train loss {'Reaction outcome loss': 0.14114551275502046, 'Total loss': 0.14114551275502046}
2022-12-31 06:35:14,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:14,556 INFO:     Epoch: 45
2022-12-31 06:35:16,180 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4019300808509191, 'Total loss': 0.4019300808509191} | train loss {'Reaction outcome loss': 0.13694148332865883, 'Total loss': 0.13694148332865883}
2022-12-31 06:35:16,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:16,180 INFO:     Epoch: 46
2022-12-31 06:35:17,800 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38483606924613317, 'Total loss': 0.38483606924613317} | train loss {'Reaction outcome loss': 0.13529367360752076, 'Total loss': 0.13529367360752076}
2022-12-31 06:35:17,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:17,800 INFO:     Epoch: 47
2022-12-31 06:35:19,423 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3744441121816635, 'Total loss': 0.3744441121816635} | train loss {'Reaction outcome loss': 0.1319498188753167, 'Total loss': 0.1319498188753167}
2022-12-31 06:35:19,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:19,423 INFO:     Epoch: 48
2022-12-31 06:35:21,055 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34098698099454244, 'Total loss': 0.34098698099454244} | train loss {'Reaction outcome loss': 0.13100880770471648, 'Total loss': 0.13100880770471648}
2022-12-31 06:35:21,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:21,055 INFO:     Epoch: 49
2022-12-31 06:35:22,690 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37212943136692045, 'Total loss': 0.37212943136692045} | train loss {'Reaction outcome loss': 0.13749232166531106, 'Total loss': 0.13749232166531106}
2022-12-31 06:35:22,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:22,690 INFO:     Epoch: 50
2022-12-31 06:35:24,354 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3663421283165614, 'Total loss': 0.3663421283165614} | train loss {'Reaction outcome loss': 0.13453749733541728, 'Total loss': 0.13453749733541728}
2022-12-31 06:35:24,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:24,355 INFO:     Epoch: 51
2022-12-31 06:35:25,976 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37213934858640035, 'Total loss': 0.37213934858640035} | train loss {'Reaction outcome loss': 0.12945091261750297, 'Total loss': 0.12945091261750297}
2022-12-31 06:35:25,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:25,977 INFO:     Epoch: 52
2022-12-31 06:35:27,592 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4079560538132985, 'Total loss': 0.4079560538132985} | train loss {'Reaction outcome loss': 0.13198152463449503, 'Total loss': 0.13198152463449503}
2022-12-31 06:35:27,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:27,593 INFO:     Epoch: 53
2022-12-31 06:35:29,222 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3853765002141396, 'Total loss': 0.3853765002141396} | train loss {'Reaction outcome loss': 0.1351429636461957, 'Total loss': 0.1351429636461957}
2022-12-31 06:35:29,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:29,222 INFO:     Epoch: 54
2022-12-31 06:35:30,852 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34653567150235176, 'Total loss': 0.34653567150235176} | train loss {'Reaction outcome loss': 0.15068384315953523, 'Total loss': 0.15068384315953523}
2022-12-31 06:35:30,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:30,852 INFO:     Epoch: 55
2022-12-31 06:35:32,483 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3930505822102229, 'Total loss': 0.3930505822102229} | train loss {'Reaction outcome loss': 0.1344441793867388, 'Total loss': 0.1344441793867388}
2022-12-31 06:35:32,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:32,484 INFO:     Epoch: 56
2022-12-31 06:35:34,114 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34971122443675995, 'Total loss': 0.34971122443675995} | train loss {'Reaction outcome loss': 0.12698129223392005, 'Total loss': 0.12698129223392005}
2022-12-31 06:35:34,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:34,114 INFO:     Epoch: 57
2022-12-31 06:35:35,736 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38701556126276654, 'Total loss': 0.38701556126276654} | train loss {'Reaction outcome loss': 0.13822428087292213, 'Total loss': 0.13822428087292213}
2022-12-31 06:35:35,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:35,736 INFO:     Epoch: 58
2022-12-31 06:35:37,345 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3664320861299833, 'Total loss': 0.3664320861299833} | train loss {'Reaction outcome loss': 0.14886295729524715, 'Total loss': 0.14886295729524715}
2022-12-31 06:35:37,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:37,345 INFO:     Epoch: 59
2022-12-31 06:35:38,962 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39189299841721853, 'Total loss': 0.39189299841721853} | train loss {'Reaction outcome loss': 0.13023658819008194, 'Total loss': 0.13023658819008194}
2022-12-31 06:35:38,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:38,962 INFO:     Epoch: 60
2022-12-31 06:35:40,579 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3728832284609477, 'Total loss': 0.3728832284609477} | train loss {'Reaction outcome loss': 0.12687019021604615, 'Total loss': 0.12687019021604615}
2022-12-31 06:35:40,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:40,579 INFO:     Epoch: 61
2022-12-31 06:35:42,193 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3898543410003185, 'Total loss': 0.3898543410003185} | train loss {'Reaction outcome loss': 0.12222384462739169, 'Total loss': 0.12222384462739169}
2022-12-31 06:35:42,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:42,194 INFO:     Epoch: 62
2022-12-31 06:35:43,851 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3656847914059957, 'Total loss': 0.3656847914059957} | train loss {'Reaction outcome loss': 0.12416381136801277, 'Total loss': 0.12416381136801277}
2022-12-31 06:35:43,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:43,851 INFO:     Epoch: 63
2022-12-31 06:35:45,471 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3705096830924352, 'Total loss': 0.3705096830924352} | train loss {'Reaction outcome loss': 0.1192577044007719, 'Total loss': 0.1192577044007719}
2022-12-31 06:35:45,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:45,472 INFO:     Epoch: 64
2022-12-31 06:35:47,115 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3942210207382838, 'Total loss': 0.3942210207382838} | train loss {'Reaction outcome loss': 0.12459083354400903, 'Total loss': 0.12459083354400903}
2022-12-31 06:35:47,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:47,115 INFO:     Epoch: 65
2022-12-31 06:35:48,750 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37425804436206817, 'Total loss': 0.37425804436206817} | train loss {'Reaction outcome loss': 0.14317416851375037, 'Total loss': 0.14317416851375037}
2022-12-31 06:35:48,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:48,750 INFO:     Epoch: 66
2022-12-31 06:35:50,388 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3623661617437998, 'Total loss': 0.3623661617437998} | train loss {'Reaction outcome loss': 0.12605370541775524, 'Total loss': 0.12605370541775524}
2022-12-31 06:35:50,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:50,388 INFO:     Epoch: 67
2022-12-31 06:35:52,032 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3681742856899897, 'Total loss': 0.3681742856899897} | train loss {'Reaction outcome loss': 0.1196143695993089, 'Total loss': 0.1196143695993089}
2022-12-31 06:35:52,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:52,032 INFO:     Epoch: 68
2022-12-31 06:35:53,655 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38420679966608684, 'Total loss': 0.38420679966608684} | train loss {'Reaction outcome loss': 0.11598253248093501, 'Total loss': 0.11598253248093501}
2022-12-31 06:35:53,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:53,655 INFO:     Epoch: 69
2022-12-31 06:35:55,279 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3471007814009984, 'Total loss': 0.3471007814009984} | train loss {'Reaction outcome loss': 0.11605638572591884, 'Total loss': 0.11605638572591884}
2022-12-31 06:35:55,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:55,279 INFO:     Epoch: 70
2022-12-31 06:35:56,911 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39123200873533887, 'Total loss': 0.39123200873533887} | train loss {'Reaction outcome loss': 0.11852613913124778, 'Total loss': 0.11852613913124778}
2022-12-31 06:35:56,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:56,912 INFO:     Epoch: 71
2022-12-31 06:35:58,543 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3936385025580724, 'Total loss': 0.3936385025580724} | train loss {'Reaction outcome loss': 0.1193682068942936, 'Total loss': 0.1193682068942936}
2022-12-31 06:35:58,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:35:58,543 INFO:     Epoch: 72
2022-12-31 06:36:00,175 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37652103205521903, 'Total loss': 0.37652103205521903} | train loss {'Reaction outcome loss': 0.11632399516796452, 'Total loss': 0.11632399516796452}
2022-12-31 06:36:00,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:00,175 INFO:     Epoch: 73
2022-12-31 06:36:01,802 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.365217025578022, 'Total loss': 0.365217025578022} | train loss {'Reaction outcome loss': 0.11797479630373689, 'Total loss': 0.11797479630373689}
2022-12-31 06:36:01,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:01,803 INFO:     Epoch: 74
2022-12-31 06:36:03,475 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3868523180484772, 'Total loss': 0.3868523180484772} | train loss {'Reaction outcome loss': 0.11480170444575259, 'Total loss': 0.11480170444575259}
2022-12-31 06:36:03,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:03,476 INFO:     Epoch: 75
2022-12-31 06:36:05,126 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36675991117954254, 'Total loss': 0.36675991117954254} | train loss {'Reaction outcome loss': 0.11540051356027159, 'Total loss': 0.11540051356027159}
2022-12-31 06:36:05,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:05,126 INFO:     Epoch: 76
2022-12-31 06:36:06,783 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38119408388932546, 'Total loss': 0.38119408388932546} | train loss {'Reaction outcome loss': 0.10975741549478851, 'Total loss': 0.10975741549478851}
2022-12-31 06:36:06,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:06,783 INFO:     Epoch: 77
2022-12-31 06:36:08,448 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3680066503584385, 'Total loss': 0.3680066503584385} | train loss {'Reaction outcome loss': 0.11149010105620381, 'Total loss': 0.11149010105620381}
2022-12-31 06:36:08,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:08,449 INFO:     Epoch: 78
2022-12-31 06:36:10,114 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39789226055145266, 'Total loss': 0.39789226055145266} | train loss {'Reaction outcome loss': 0.11024394653814733, 'Total loss': 0.11024394653814733}
2022-12-31 06:36:10,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:10,115 INFO:     Epoch: 79
2022-12-31 06:36:11,767 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39791342814763386, 'Total loss': 0.39791342814763386} | train loss {'Reaction outcome loss': 0.11302918452585728, 'Total loss': 0.11302918452585728}
2022-12-31 06:36:11,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:11,767 INFO:     Epoch: 80
2022-12-31 06:36:13,404 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38522402246793114, 'Total loss': 0.38522402246793114} | train loss {'Reaction outcome loss': 0.11384276592095698, 'Total loss': 0.11384276592095698}
2022-12-31 06:36:13,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:13,404 INFO:     Epoch: 81
2022-12-31 06:36:15,022 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36275048156579337, 'Total loss': 0.36275048156579337} | train loss {'Reaction outcome loss': 0.11116705205592776, 'Total loss': 0.11116705205592776}
2022-12-31 06:36:15,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:15,022 INFO:     Epoch: 82
2022-12-31 06:36:16,687 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3830266401171684, 'Total loss': 0.3830266401171684} | train loss {'Reaction outcome loss': 0.10911433804026076, 'Total loss': 0.10911433804026076}
2022-12-31 06:36:16,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:16,688 INFO:     Epoch: 83
2022-12-31 06:36:18,302 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4016755595803261, 'Total loss': 0.4016755595803261} | train loss {'Reaction outcome loss': 0.10904997692431198, 'Total loss': 0.10904997692431198}
2022-12-31 06:36:18,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:18,302 INFO:     Epoch: 84
2022-12-31 06:36:19,920 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.384878267844518, 'Total loss': 0.384878267844518} | train loss {'Reaction outcome loss': 0.11730917640364867, 'Total loss': 0.11730917640364867}
2022-12-31 06:36:19,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:19,920 INFO:     Epoch: 85
2022-12-31 06:36:21,542 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3863342568278313, 'Total loss': 0.3863342568278313} | train loss {'Reaction outcome loss': 0.10909635352162286, 'Total loss': 0.10909635352162286}
2022-12-31 06:36:21,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:21,543 INFO:     Epoch: 86
2022-12-31 06:36:23,151 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3785195571680864, 'Total loss': 0.3785195571680864} | train loss {'Reaction outcome loss': 0.10589384673537848, 'Total loss': 0.10589384673537848}
2022-12-31 06:36:23,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:23,151 INFO:     Epoch: 87
2022-12-31 06:36:24,816 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4179211348295212, 'Total loss': 0.4179211348295212} | train loss {'Reaction outcome loss': 0.10654677265980697, 'Total loss': 0.10654677265980697}
2022-12-31 06:36:24,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:24,816 INFO:     Epoch: 88
2022-12-31 06:36:26,433 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3489564816157023, 'Total loss': 0.3489564816157023} | train loss {'Reaction outcome loss': 0.11212358423137525, 'Total loss': 0.11212358423137525}
2022-12-31 06:36:26,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:26,433 INFO:     Epoch: 89
2022-12-31 06:36:28,099 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38993012011051176, 'Total loss': 0.38993012011051176} | train loss {'Reaction outcome loss': 0.11100673045207193, 'Total loss': 0.11100673045207193}
2022-12-31 06:36:28,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:28,099 INFO:     Epoch: 90
2022-12-31 06:36:29,718 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3626001626253128, 'Total loss': 0.3626001626253128} | train loss {'Reaction outcome loss': 0.12085404023409997, 'Total loss': 0.12085404023409997}
2022-12-31 06:36:29,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:29,718 INFO:     Epoch: 91
2022-12-31 06:36:31,368 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38031473954518635, 'Total loss': 0.38031473954518635} | train loss {'Reaction outcome loss': 0.12816438090163318, 'Total loss': 0.12816438090163318}
2022-12-31 06:36:31,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:31,368 INFO:     Epoch: 92
2022-12-31 06:36:33,033 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3777180790901184, 'Total loss': 0.3777180790901184} | train loss {'Reaction outcome loss': 0.10663428891153223, 'Total loss': 0.10663428891153223}
2022-12-31 06:36:33,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:33,035 INFO:     Epoch: 93
2022-12-31 06:36:34,652 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36104775244990983, 'Total loss': 0.36104775244990983} | train loss {'Reaction outcome loss': 0.10539694491139465, 'Total loss': 0.10539694491139465}
2022-12-31 06:36:34,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:34,652 INFO:     Epoch: 94
2022-12-31 06:36:36,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37486429115136466, 'Total loss': 0.37486429115136466} | train loss {'Reaction outcome loss': 0.10316663334308124, 'Total loss': 0.10316663334308124}
2022-12-31 06:36:36,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:36,318 INFO:     Epoch: 95
2022-12-31 06:36:37,934 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34187358568112053, 'Total loss': 0.34187358568112053} | train loss {'Reaction outcome loss': 0.1018005422556071, 'Total loss': 0.1018005422556071}
2022-12-31 06:36:37,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:37,935 INFO:     Epoch: 96
2022-12-31 06:36:39,562 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37362851202487946, 'Total loss': 0.37362851202487946} | train loss {'Reaction outcome loss': 0.10581522543372188, 'Total loss': 0.10581522543372188}
2022-12-31 06:36:39,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:39,562 INFO:     Epoch: 97
2022-12-31 06:36:41,184 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38030538658301033, 'Total loss': 0.38030538658301033} | train loss {'Reaction outcome loss': 0.10374325323926684, 'Total loss': 0.10374325323926684}
2022-12-31 06:36:41,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:41,185 INFO:     Epoch: 98
2022-12-31 06:36:42,812 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38239845633506775, 'Total loss': 0.38239845633506775} | train loss {'Reaction outcome loss': 0.10417541995211387, 'Total loss': 0.10417541995211387}
2022-12-31 06:36:42,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:42,812 INFO:     Epoch: 99
2022-12-31 06:36:44,440 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3579271733760834, 'Total loss': 0.3579271733760834} | train loss {'Reaction outcome loss': 0.10919755240963465, 'Total loss': 0.10919755240963465}
2022-12-31 06:36:44,440 INFO:     Best model found after epoch 15 of 100.
2022-12-31 06:36:44,441 INFO:   Done with stage: TRAINING
2022-12-31 06:36:44,441 INFO:   Starting stage: EVALUATION
2022-12-31 06:36:44,572 INFO:   Done with stage: EVALUATION
2022-12-31 06:36:44,572 INFO:   Leaving out SEQ value Fold_6
2022-12-31 06:36:44,584 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:36:44,584 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:36:45,220 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:36:45,220 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:36:45,290 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:36:45,290 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:36:45,290 INFO:     No hyperparam tuning for this model
2022-12-31 06:36:45,290 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:36:45,290 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:36:45,291 INFO:     None feature selector for col prot
2022-12-31 06:36:45,291 INFO:     None feature selector for col prot
2022-12-31 06:36:45,291 INFO:     None feature selector for col prot
2022-12-31 06:36:45,292 INFO:     None feature selector for col chem
2022-12-31 06:36:45,292 INFO:     None feature selector for col chem
2022-12-31 06:36:45,292 INFO:     None feature selector for col chem
2022-12-31 06:36:45,292 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:36:45,292 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:36:45,294 INFO:     Number of params in model 224011
2022-12-31 06:36:45,297 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:36:45,297 INFO:   Starting stage: TRAINING
2022-12-31 06:36:45,342 INFO:     Val loss before train {'Reaction outcome loss': 0.9933391253153483, 'Total loss': 0.9933391253153483}
2022-12-31 06:36:45,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:45,342 INFO:     Epoch: 0
2022-12-31 06:36:46,962 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6069094995657603, 'Total loss': 0.6069094995657603} | train loss {'Reaction outcome loss': 0.7786614422174339, 'Total loss': 0.7786614422174339}
2022-12-31 06:36:46,962 INFO:     Found new best model at epoch 0
2022-12-31 06:36:46,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:46,963 INFO:     Epoch: 1
2022-12-31 06:36:48,611 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5232479651769002, 'Total loss': 0.5232479651769002} | train loss {'Reaction outcome loss': 0.5249121171840723, 'Total loss': 0.5249121171840723}
2022-12-31 06:36:48,611 INFO:     Found new best model at epoch 1
2022-12-31 06:36:48,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:48,612 INFO:     Epoch: 2
2022-12-31 06:36:50,228 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49472015698750815, 'Total loss': 0.49472015698750815} | train loss {'Reaction outcome loss': 0.46666278641508974, 'Total loss': 0.46666278641508974}
2022-12-31 06:36:50,228 INFO:     Found new best model at epoch 2
2022-12-31 06:36:50,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:50,229 INFO:     Epoch: 3
2022-12-31 06:36:51,858 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48071250716845193, 'Total loss': 0.48071250716845193} | train loss {'Reaction outcome loss': 0.4224246686579241, 'Total loss': 0.4224246686579241}
2022-12-31 06:36:51,859 INFO:     Found new best model at epoch 3
2022-12-31 06:36:51,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:51,860 INFO:     Epoch: 4
2022-12-31 06:36:53,489 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4799391945203145, 'Total loss': 0.4799391945203145} | train loss {'Reaction outcome loss': 0.3885672751652158, 'Total loss': 0.3885672751652158}
2022-12-31 06:36:53,490 INFO:     Found new best model at epoch 4
2022-12-31 06:36:53,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:53,491 INFO:     Epoch: 5
2022-12-31 06:36:55,119 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4774035394191742, 'Total loss': 0.4774035394191742} | train loss {'Reaction outcome loss': 0.3630165983180421, 'Total loss': 0.3630165983180421}
2022-12-31 06:36:55,119 INFO:     Found new best model at epoch 5
2022-12-31 06:36:55,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:55,120 INFO:     Epoch: 6
2022-12-31 06:36:56,736 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4861922562122345, 'Total loss': 0.4861922562122345} | train loss {'Reaction outcome loss': 0.3509616552163725, 'Total loss': 0.3509616552163725}
2022-12-31 06:36:56,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:56,736 INFO:     Epoch: 7
2022-12-31 06:36:58,396 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4556701471408208, 'Total loss': 0.4556701471408208} | train loss {'Reaction outcome loss': 0.3415306997013049, 'Total loss': 0.3415306997013049}
2022-12-31 06:36:58,396 INFO:     Found new best model at epoch 7
2022-12-31 06:36:58,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:36:58,397 INFO:     Epoch: 8
2022-12-31 06:37:00,018 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47233657439549764, 'Total loss': 0.47233657439549764} | train loss {'Reaction outcome loss': 0.3189751587646163, 'Total loss': 0.3189751587646163}
2022-12-31 06:37:00,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:00,018 INFO:     Epoch: 9
2022-12-31 06:37:01,684 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4654698570569356, 'Total loss': 0.4654698570569356} | train loss {'Reaction outcome loss': 0.32033344299407623, 'Total loss': 0.32033344299407623}
2022-12-31 06:37:01,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:01,685 INFO:     Epoch: 10
2022-12-31 06:37:03,350 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43970275223255156, 'Total loss': 0.43970275223255156} | train loss {'Reaction outcome loss': 0.28968536000415357, 'Total loss': 0.28968536000415357}
2022-12-31 06:37:03,350 INFO:     Found new best model at epoch 10
2022-12-31 06:37:03,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:03,351 INFO:     Epoch: 11
2022-12-31 06:37:04,968 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46261996527512866, 'Total loss': 0.46261996527512866} | train loss {'Reaction outcome loss': 0.27254126147633634, 'Total loss': 0.27254126147633634}
2022-12-31 06:37:04,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:04,968 INFO:     Epoch: 12
2022-12-31 06:37:06,598 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44943180978298186, 'Total loss': 0.44943180978298186} | train loss {'Reaction outcome loss': 0.26166081226728094, 'Total loss': 0.26166081226728094}
2022-12-31 06:37:06,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:06,598 INFO:     Epoch: 13
2022-12-31 06:37:08,235 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4428035855293274, 'Total loss': 0.4428035855293274} | train loss {'Reaction outcome loss': 0.2575643187383716, 'Total loss': 0.2575643187383716}
2022-12-31 06:37:08,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:08,237 INFO:     Epoch: 14
2022-12-31 06:37:09,856 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43920058012008667, 'Total loss': 0.43920058012008667} | train loss {'Reaction outcome loss': 0.24717493052404557, 'Total loss': 0.24717493052404557}
2022-12-31 06:37:09,856 INFO:     Found new best model at epoch 14
2022-12-31 06:37:09,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:09,857 INFO:     Epoch: 15
2022-12-31 06:37:11,474 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4361197531223297, 'Total loss': 0.4361197531223297} | train loss {'Reaction outcome loss': 0.2430952642142707, 'Total loss': 0.2430952642142707}
2022-12-31 06:37:11,474 INFO:     Found new best model at epoch 15
2022-12-31 06:37:11,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:11,475 INFO:     Epoch: 16
2022-12-31 06:37:13,094 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45320078829924265, 'Total loss': 0.45320078829924265} | train loss {'Reaction outcome loss': 0.2316730210639408, 'Total loss': 0.2316730210639408}
2022-12-31 06:37:13,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:13,094 INFO:     Epoch: 17
2022-12-31 06:37:14,714 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4591990053653717, 'Total loss': 0.4591990053653717} | train loss {'Reaction outcome loss': 0.22680993967325144, 'Total loss': 0.22680993967325144}
2022-12-31 06:37:14,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:14,715 INFO:     Epoch: 18
2022-12-31 06:37:16,329 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44936591188112895, 'Total loss': 0.44936591188112895} | train loss {'Reaction outcome loss': 0.2215802910563914, 'Total loss': 0.2215802910563914}
2022-12-31 06:37:16,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:16,329 INFO:     Epoch: 19
2022-12-31 06:37:17,556 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4279850492874781, 'Total loss': 0.4279850492874781} | train loss {'Reaction outcome loss': 0.2155759525080414, 'Total loss': 0.2155759525080414}
2022-12-31 06:37:17,556 INFO:     Found new best model at epoch 19
2022-12-31 06:37:17,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:17,557 INFO:     Epoch: 20
2022-12-31 06:37:18,668 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4391048153241475, 'Total loss': 0.4391048153241475} | train loss {'Reaction outcome loss': 0.20987108157124315, 'Total loss': 0.20987108157124315}
2022-12-31 06:37:18,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:18,668 INFO:     Epoch: 21
2022-12-31 06:37:19,778 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4446658526857694, 'Total loss': 0.4446658526857694} | train loss {'Reaction outcome loss': 0.20240918228022486, 'Total loss': 0.20240918228022486}
2022-12-31 06:37:19,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:19,778 INFO:     Epoch: 22
2022-12-31 06:37:20,884 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4465826878945033, 'Total loss': 0.4465826878945033} | train loss {'Reaction outcome loss': 0.21657837325356144, 'Total loss': 0.21657837325356144}
2022-12-31 06:37:20,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:20,885 INFO:     Epoch: 23
2022-12-31 06:37:22,422 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.443778137365977, 'Total loss': 0.443778137365977} | train loss {'Reaction outcome loss': 0.23074456957930006, 'Total loss': 0.23074456957930006}
2022-12-31 06:37:22,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:22,422 INFO:     Epoch: 24
2022-12-31 06:37:24,098 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43843755722045896, 'Total loss': 0.43843755722045896} | train loss {'Reaction outcome loss': 0.19840647991999952, 'Total loss': 0.19840647991999952}
2022-12-31 06:37:24,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:24,098 INFO:     Epoch: 25
2022-12-31 06:37:25,769 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43076932926972705, 'Total loss': 0.43076932926972705} | train loss {'Reaction outcome loss': 0.19407349048128378, 'Total loss': 0.19407349048128378}
2022-12-31 06:37:25,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:25,769 INFO:     Epoch: 26
2022-12-31 06:37:27,444 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4575928211212158, 'Total loss': 0.4575928211212158} | train loss {'Reaction outcome loss': 0.18976145338474718, 'Total loss': 0.18976145338474718}
2022-12-31 06:37:27,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:27,445 INFO:     Epoch: 27
2022-12-31 06:37:29,115 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45550333460172016, 'Total loss': 0.45550333460172016} | train loss {'Reaction outcome loss': 0.18554243704900306, 'Total loss': 0.18554243704900306}
2022-12-31 06:37:29,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:29,115 INFO:     Epoch: 28
2022-12-31 06:37:30,741 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42838672002156575, 'Total loss': 0.42838672002156575} | train loss {'Reaction outcome loss': 0.17931026966476382, 'Total loss': 0.17931026966476382}
2022-12-31 06:37:30,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:30,741 INFO:     Epoch: 29
2022-12-31 06:37:32,374 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4429842139283816, 'Total loss': 0.4429842139283816} | train loss {'Reaction outcome loss': 0.1788984983484598, 'Total loss': 0.1788984983484598}
2022-12-31 06:37:32,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:32,374 INFO:     Epoch: 30
2022-12-31 06:37:34,038 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4324352522691091, 'Total loss': 0.4324352522691091} | train loss {'Reaction outcome loss': 0.17496974160388598, 'Total loss': 0.17496974160388598}
2022-12-31 06:37:34,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:34,039 INFO:     Epoch: 31
2022-12-31 06:37:35,703 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43927903870741525, 'Total loss': 0.43927903870741525} | train loss {'Reaction outcome loss': 0.17535216699774459, 'Total loss': 0.17535216699774459}
2022-12-31 06:37:35,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:35,704 INFO:     Epoch: 32
2022-12-31 06:37:37,368 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42560875515143076, 'Total loss': 0.42560875515143076} | train loss {'Reaction outcome loss': 0.17511330808970935, 'Total loss': 0.17511330808970935}
2022-12-31 06:37:37,368 INFO:     Found new best model at epoch 32
2022-12-31 06:37:37,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:37,369 INFO:     Epoch: 33
2022-12-31 06:37:38,990 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4365455498298009, 'Total loss': 0.4365455498298009} | train loss {'Reaction outcome loss': 0.16753877677947984, 'Total loss': 0.16753877677947984}
2022-12-31 06:37:38,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:38,991 INFO:     Epoch: 34
2022-12-31 06:37:40,611 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42773822049299876, 'Total loss': 0.42773822049299876} | train loss {'Reaction outcome loss': 0.17029887161544943, 'Total loss': 0.17029887161544943}
2022-12-31 06:37:40,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:40,611 INFO:     Epoch: 35
2022-12-31 06:37:42,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44159518082936605, 'Total loss': 0.44159518082936605} | train loss {'Reaction outcome loss': 0.164527042961234, 'Total loss': 0.164527042961234}
2022-12-31 06:37:42,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:42,242 INFO:     Epoch: 36
2022-12-31 06:37:43,871 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44021467765172323, 'Total loss': 0.44021467765172323} | train loss {'Reaction outcome loss': 0.16377746544616378, 'Total loss': 0.16377746544616378}
2022-12-31 06:37:43,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:43,871 INFO:     Epoch: 37
2022-12-31 06:37:45,500 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.417871634165446, 'Total loss': 0.417871634165446} | train loss {'Reaction outcome loss': 0.1627018682843102, 'Total loss': 0.1627018682843102}
2022-12-31 06:37:45,501 INFO:     Found new best model at epoch 37
2022-12-31 06:37:45,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:45,502 INFO:     Epoch: 38
2022-12-31 06:37:47,151 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4546708027521769, 'Total loss': 0.4546708027521769} | train loss {'Reaction outcome loss': 0.16546916317167706, 'Total loss': 0.16546916317167706}
2022-12-31 06:37:47,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:47,151 INFO:     Epoch: 39
2022-12-31 06:37:48,772 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46633985539277395, 'Total loss': 0.46633985539277395} | train loss {'Reaction outcome loss': 0.19509400085856518, 'Total loss': 0.19509400085856518}
2022-12-31 06:37:48,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:48,772 INFO:     Epoch: 40
2022-12-31 06:37:50,397 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45536813338597615, 'Total loss': 0.45536813338597615} | train loss {'Reaction outcome loss': 0.15888934537951424, 'Total loss': 0.15888934537951424}
2022-12-31 06:37:50,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:50,397 INFO:     Epoch: 41
2022-12-31 06:37:52,026 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4461385617653529, 'Total loss': 0.4461385617653529} | train loss {'Reaction outcome loss': 0.15432197511773152, 'Total loss': 0.15432197511773152}
2022-12-31 06:37:52,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:52,027 INFO:     Epoch: 42
2022-12-31 06:37:53,657 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4485598663489024, 'Total loss': 0.4485598663489024} | train loss {'Reaction outcome loss': 0.15224075495380152, 'Total loss': 0.15224075495380152}
2022-12-31 06:37:53,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:53,657 INFO:     Epoch: 43
2022-12-31 06:37:55,288 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46298999587694806, 'Total loss': 0.46298999587694806} | train loss {'Reaction outcome loss': 0.14973625514413352, 'Total loss': 0.14973625514413352}
2022-12-31 06:37:55,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:55,288 INFO:     Epoch: 44
2022-12-31 06:37:56,918 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4770185430844625, 'Total loss': 0.4770185430844625} | train loss {'Reaction outcome loss': 0.1473252602754906, 'Total loss': 0.1473252602754906}
2022-12-31 06:37:56,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:56,918 INFO:     Epoch: 45
2022-12-31 06:37:58,545 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4228983049591382, 'Total loss': 0.4228983049591382} | train loss {'Reaction outcome loss': 0.14334665921479176, 'Total loss': 0.14334665921479176}
2022-12-31 06:37:58,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:37:58,546 INFO:     Epoch: 46
2022-12-31 06:38:00,164 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4253355930248896, 'Total loss': 0.4253355930248896} | train loss {'Reaction outcome loss': 0.15241165196293613, 'Total loss': 0.15241165196293613}
2022-12-31 06:38:00,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:00,164 INFO:     Epoch: 47
2022-12-31 06:38:01,779 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.461882076660792, 'Total loss': 0.461882076660792} | train loss {'Reaction outcome loss': 0.17244902111090504, 'Total loss': 0.17244902111090504}
2022-12-31 06:38:01,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:01,780 INFO:     Epoch: 48
2022-12-31 06:38:03,445 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4398134857416153, 'Total loss': 0.4398134857416153} | train loss {'Reaction outcome loss': 0.1647820768850869, 'Total loss': 0.1647820768850869}
2022-12-31 06:38:03,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:03,445 INFO:     Epoch: 49
2022-12-31 06:38:05,060 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42228420277436574, 'Total loss': 0.42228420277436574} | train loss {'Reaction outcome loss': 0.1446648789443197, 'Total loss': 0.1446648789443197}
2022-12-31 06:38:05,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:05,060 INFO:     Epoch: 50
2022-12-31 06:38:06,675 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44232881466547647, 'Total loss': 0.44232881466547647} | train loss {'Reaction outcome loss': 0.13895907269529678, 'Total loss': 0.13895907269529678}
2022-12-31 06:38:06,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:06,675 INFO:     Epoch: 51
2022-12-31 06:38:08,300 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4577988266944885, 'Total loss': 0.4577988266944885} | train loss {'Reaction outcome loss': 0.13738477869175267, 'Total loss': 0.13738477869175267}
2022-12-31 06:38:08,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:08,300 INFO:     Epoch: 52
2022-12-31 06:38:09,909 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46898370087146757, 'Total loss': 0.46898370087146757} | train loss {'Reaction outcome loss': 0.13859240286241192, 'Total loss': 0.13859240286241192}
2022-12-31 06:38:09,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:09,910 INFO:     Epoch: 53
2022-12-31 06:38:11,525 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4433934859931469, 'Total loss': 0.4433934859931469} | train loss {'Reaction outcome loss': 0.13684146799504812, 'Total loss': 0.13684146799504812}
2022-12-31 06:38:11,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:11,525 INFO:     Epoch: 54
2022-12-31 06:38:13,141 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4619800557692846, 'Total loss': 0.4619800557692846} | train loss {'Reaction outcome loss': 0.13887796194488317, 'Total loss': 0.13887796194488317}
2022-12-31 06:38:13,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:13,142 INFO:     Epoch: 55
2022-12-31 06:38:14,757 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4507277116179466, 'Total loss': 0.4507277116179466} | train loss {'Reaction outcome loss': 0.13473491949374927, 'Total loss': 0.13473491949374927}
2022-12-31 06:38:14,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:14,757 INFO:     Epoch: 56
2022-12-31 06:38:16,371 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4273643429080645, 'Total loss': 0.4273643429080645} | train loss {'Reaction outcome loss': 0.13396658240125744, 'Total loss': 0.13396658240125744}
2022-12-31 06:38:16,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:16,371 INFO:     Epoch: 57
2022-12-31 06:38:17,986 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4248273316770792, 'Total loss': 0.4248273316770792} | train loss {'Reaction outcome loss': 0.13080248058342503, 'Total loss': 0.13080248058342503}
2022-12-31 06:38:17,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:17,986 INFO:     Epoch: 58
2022-12-31 06:38:19,652 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4706986129283905, 'Total loss': 0.4706986129283905} | train loss {'Reaction outcome loss': 0.13436167790658385, 'Total loss': 0.13436167790658385}
2022-12-31 06:38:19,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:19,653 INFO:     Epoch: 59
2022-12-31 06:38:21,318 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43827945391337075, 'Total loss': 0.43827945391337075} | train loss {'Reaction outcome loss': 0.13371558336940073, 'Total loss': 0.13371558336940073}
2022-12-31 06:38:21,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:21,319 INFO:     Epoch: 60
2022-12-31 06:38:22,953 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4477552980184555, 'Total loss': 0.4477552980184555} | train loss {'Reaction outcome loss': 0.13017989608351196, 'Total loss': 0.13017989608351196}
2022-12-31 06:38:22,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:22,953 INFO:     Epoch: 61
2022-12-31 06:38:24,586 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45051887532075247, 'Total loss': 0.45051887532075247} | train loss {'Reaction outcome loss': 0.1284087480822379, 'Total loss': 0.1284087480822379}
2022-12-31 06:38:24,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:24,586 INFO:     Epoch: 62
2022-12-31 06:38:26,203 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4611380120118459, 'Total loss': 0.4611380120118459} | train loss {'Reaction outcome loss': 0.12865944090077866, 'Total loss': 0.12865944090077866}
2022-12-31 06:38:26,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:26,203 INFO:     Epoch: 63
2022-12-31 06:38:27,837 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4216280291477839, 'Total loss': 0.4216280291477839} | train loss {'Reaction outcome loss': 0.12834557088891693, 'Total loss': 0.12834557088891693}
2022-12-31 06:38:27,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:27,837 INFO:     Epoch: 64
2022-12-31 06:38:29,466 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43613142569859825, 'Total loss': 0.43613142569859825} | train loss {'Reaction outcome loss': 0.12920688812016085, 'Total loss': 0.12920688812016085}
2022-12-31 06:38:29,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:29,467 INFO:     Epoch: 65
2022-12-31 06:38:31,092 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4564082644879818, 'Total loss': 0.4564082644879818} | train loss {'Reaction outcome loss': 0.12538634242314467, 'Total loss': 0.12538634242314467}
2022-12-31 06:38:31,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:31,093 INFO:     Epoch: 66
2022-12-31 06:38:32,715 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4475549856821696, 'Total loss': 0.4475549856821696} | train loss {'Reaction outcome loss': 0.1280003768236687, 'Total loss': 0.1280003768236687}
2022-12-31 06:38:32,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:32,715 INFO:     Epoch: 67
2022-12-31 06:38:34,337 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4651458978652954, 'Total loss': 0.4651458978652954} | train loss {'Reaction outcome loss': 0.1293803903669038, 'Total loss': 0.1293803903669038}
2022-12-31 06:38:34,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:34,338 INFO:     Epoch: 68
2022-12-31 06:38:35,948 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46509164571762085, 'Total loss': 0.46509164571762085} | train loss {'Reaction outcome loss': 0.1346831889198823, 'Total loss': 0.1346831889198823}
2022-12-31 06:38:35,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:35,949 INFO:     Epoch: 69
2022-12-31 06:38:37,571 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47082112431526185, 'Total loss': 0.47082112431526185} | train loss {'Reaction outcome loss': 0.12780395957984644, 'Total loss': 0.12780395957984644}
2022-12-31 06:38:37,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:37,572 INFO:     Epoch: 70
2022-12-31 06:38:39,198 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48308710058530174, 'Total loss': 0.48308710058530174} | train loss {'Reaction outcome loss': 0.12425246408573636, 'Total loss': 0.12425246408573636}
2022-12-31 06:38:39,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:39,198 INFO:     Epoch: 71
2022-12-31 06:38:40,824 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4529275119304657, 'Total loss': 0.4529275119304657} | train loss {'Reaction outcome loss': 0.1213935280485611, 'Total loss': 0.1213935280485611}
2022-12-31 06:38:40,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:40,824 INFO:     Epoch: 72
2022-12-31 06:38:42,448 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4481655597686768, 'Total loss': 0.4481655597686768} | train loss {'Reaction outcome loss': 0.12327193954810803, 'Total loss': 0.12327193954810803}
2022-12-31 06:38:42,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:42,448 INFO:     Epoch: 73
2022-12-31 06:38:44,080 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4908165822426478, 'Total loss': 0.4908165822426478} | train loss {'Reaction outcome loss': 0.11945716174702375, 'Total loss': 0.11945716174702375}
2022-12-31 06:38:44,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:44,080 INFO:     Epoch: 74
2022-12-31 06:38:45,734 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4545602242151896, 'Total loss': 0.4545602242151896} | train loss {'Reaction outcome loss': 0.12221469159197548, 'Total loss': 0.12221469159197548}
2022-12-31 06:38:45,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:45,736 INFO:     Epoch: 75
2022-12-31 06:38:47,392 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43766923348108927, 'Total loss': 0.43766923348108927} | train loss {'Reaction outcome loss': 0.12442716134274383, 'Total loss': 0.12442716134274383}
2022-12-31 06:38:47,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:47,392 INFO:     Epoch: 76
2022-12-31 06:38:49,017 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43398122290770214, 'Total loss': 0.43398122290770214} | train loss {'Reaction outcome loss': 0.11747925998216435, 'Total loss': 0.11747925998216435}
2022-12-31 06:38:49,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:49,017 INFO:     Epoch: 77
2022-12-31 06:38:50,683 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45105825265248617, 'Total loss': 0.45105825265248617} | train loss {'Reaction outcome loss': 0.11938835737490318, 'Total loss': 0.11938835737490318}
2022-12-31 06:38:50,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:50,684 INFO:     Epoch: 78
2022-12-31 06:38:52,350 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4977082838614782, 'Total loss': 0.4977082838614782} | train loss {'Reaction outcome loss': 0.12180518971139911, 'Total loss': 0.12180518971139911}
2022-12-31 06:38:52,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:52,350 INFO:     Epoch: 79
2022-12-31 06:38:53,975 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47408180236816405, 'Total loss': 0.47408180236816405} | train loss {'Reaction outcome loss': 0.12237881183408308, 'Total loss': 0.12237881183408308}
2022-12-31 06:38:53,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:53,975 INFO:     Epoch: 80
2022-12-31 06:38:55,600 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4797394375006358, 'Total loss': 0.4797394375006358} | train loss {'Reaction outcome loss': 0.12188434692612593, 'Total loss': 0.12188434692612593}
2022-12-31 06:38:55,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:55,600 INFO:     Epoch: 81
2022-12-31 06:38:57,226 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5026217559973399, 'Total loss': 0.5026217559973399} | train loss {'Reaction outcome loss': 0.12213668816147602, 'Total loss': 0.12213668816147602}
2022-12-31 06:38:57,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:57,226 INFO:     Epoch: 82
2022-12-31 06:38:58,847 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4642634491125743, 'Total loss': 0.4642634491125743} | train loss {'Reaction outcome loss': 0.11832251394187789, 'Total loss': 0.11832251394187789}
2022-12-31 06:38:58,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:38:58,848 INFO:     Epoch: 83
2022-12-31 06:39:00,471 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46274560491244, 'Total loss': 0.46274560491244} | train loss {'Reaction outcome loss': 0.11724581711156212, 'Total loss': 0.11724581711156212}
2022-12-31 06:39:00,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:00,472 INFO:     Epoch: 84
2022-12-31 06:39:02,099 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47735939820607504, 'Total loss': 0.47735939820607504} | train loss {'Reaction outcome loss': 0.11271375342756443, 'Total loss': 0.11271375342756443}
2022-12-31 06:39:02,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:02,100 INFO:     Epoch: 85
2022-12-31 06:39:03,717 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4921062966187795, 'Total loss': 0.4921062966187795} | train loss {'Reaction outcome loss': 0.11157407532108124, 'Total loss': 0.11157407532108124}
2022-12-31 06:39:03,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:03,717 INFO:     Epoch: 86
2022-12-31 06:39:05,328 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45540555119514464, 'Total loss': 0.45540555119514464} | train loss {'Reaction outcome loss': 0.11438926878537936, 'Total loss': 0.11438926878537936}
2022-12-31 06:39:05,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:05,329 INFO:     Epoch: 87
2022-12-31 06:39:06,943 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4680172817160686, 'Total loss': 0.4680172817160686} | train loss {'Reaction outcome loss': 0.11719169327293259, 'Total loss': 0.11719169327293259}
2022-12-31 06:39:06,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:06,943 INFO:     Epoch: 88
2022-12-31 06:39:08,561 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48690646688143413, 'Total loss': 0.48690646688143413} | train loss {'Reaction outcome loss': 0.1151219439011386, 'Total loss': 0.1151219439011386}
2022-12-31 06:39:08,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:08,561 INFO:     Epoch: 89
2022-12-31 06:39:10,178 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4468496302763621, 'Total loss': 0.4468496302763621} | train loss {'Reaction outcome loss': 0.11217117217116222, 'Total loss': 0.11217117217116222}
2022-12-31 06:39:10,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:10,179 INFO:     Epoch: 90
2022-12-31 06:39:11,791 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44764919641117257, 'Total loss': 0.44764919641117257} | train loss {'Reaction outcome loss': 0.1154575227337946, 'Total loss': 0.1154575227337946}
2022-12-31 06:39:11,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:11,792 INFO:     Epoch: 91
2022-12-31 06:39:13,418 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.495635978380839, 'Total loss': 0.495635978380839} | train loss {'Reaction outcome loss': 0.11199819775504073, 'Total loss': 0.11199819775504073}
2022-12-31 06:39:13,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:13,418 INFO:     Epoch: 92
2022-12-31 06:39:15,086 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46249471803506215, 'Total loss': 0.46249471803506215} | train loss {'Reaction outcome loss': 0.11519559715626478, 'Total loss': 0.11519559715626478}
2022-12-31 06:39:15,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:15,087 INFO:     Epoch: 93
2022-12-31 06:39:16,707 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4617564886808395, 'Total loss': 0.4617564886808395} | train loss {'Reaction outcome loss': 0.11059377062222178, 'Total loss': 0.11059377062222178}
2022-12-31 06:39:16,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:16,707 INFO:     Epoch: 94
2022-12-31 06:39:18,328 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4713397612174352, 'Total loss': 0.4713397612174352} | train loss {'Reaction outcome loss': 0.11304278478312722, 'Total loss': 0.11304278478312722}
2022-12-31 06:39:18,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:18,328 INFO:     Epoch: 95
2022-12-31 06:39:19,954 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48151406248410544, 'Total loss': 0.48151406248410544} | train loss {'Reaction outcome loss': 0.11072295476755033, 'Total loss': 0.11072295476755033}
2022-12-31 06:39:19,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:19,954 INFO:     Epoch: 96
2022-12-31 06:39:21,573 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4679298635572195, 'Total loss': 0.4679298635572195} | train loss {'Reaction outcome loss': 0.1107968414603881, 'Total loss': 0.1107968414603881}
2022-12-31 06:39:21,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:21,575 INFO:     Epoch: 97
2022-12-31 06:39:23,195 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46219627261161805, 'Total loss': 0.46219627261161805} | train loss {'Reaction outcome loss': 0.11212479161037918, 'Total loss': 0.11212479161037918}
2022-12-31 06:39:23,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:23,196 INFO:     Epoch: 98
2022-12-31 06:39:24,862 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47631847659746807, 'Total loss': 0.47631847659746807} | train loss {'Reaction outcome loss': 0.1113949736809709, 'Total loss': 0.1113949736809709}
2022-12-31 06:39:24,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:24,863 INFO:     Epoch: 99
2022-12-31 06:39:26,530 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4461654313529531, 'Total loss': 0.4461654313529531} | train loss {'Reaction outcome loss': 0.1147341733271985, 'Total loss': 0.1147341733271985}
2022-12-31 06:39:26,530 INFO:     Best model found after epoch 38 of 100.
2022-12-31 06:39:26,531 INFO:   Done with stage: TRAINING
2022-12-31 06:39:26,531 INFO:   Starting stage: EVALUATION
2022-12-31 06:39:26,661 INFO:   Done with stage: EVALUATION
2022-12-31 06:39:26,661 INFO:   Leaving out SEQ value Fold_7
2022-12-31 06:39:26,674 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 06:39:26,674 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:39:27,341 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:39:27,341 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:39:27,413 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:39:27,413 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:39:27,413 INFO:     No hyperparam tuning for this model
2022-12-31 06:39:27,413 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:39:27,413 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:39:27,414 INFO:     None feature selector for col prot
2022-12-31 06:39:27,414 INFO:     None feature selector for col prot
2022-12-31 06:39:27,414 INFO:     None feature selector for col prot
2022-12-31 06:39:27,415 INFO:     None feature selector for col chem
2022-12-31 06:39:27,415 INFO:     None feature selector for col chem
2022-12-31 06:39:27,415 INFO:     None feature selector for col chem
2022-12-31 06:39:27,415 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:39:27,415 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:39:27,417 INFO:     Number of params in model 224011
2022-12-31 06:39:27,421 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:39:27,421 INFO:   Starting stage: TRAINING
2022-12-31 06:39:27,466 INFO:     Val loss before train {'Reaction outcome loss': 1.0491484959920248, 'Total loss': 1.0491484959920248}
2022-12-31 06:39:27,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:27,466 INFO:     Epoch: 0
2022-12-31 06:39:29,099 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.584835426012675, 'Total loss': 0.584835426012675} | train loss {'Reaction outcome loss': 0.7774120717702789, 'Total loss': 0.7774120717702789}
2022-12-31 06:39:29,100 INFO:     Found new best model at epoch 0
2022-12-31 06:39:29,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:29,101 INFO:     Epoch: 1
2022-12-31 06:39:30,729 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5113347987333934, 'Total loss': 0.5113347987333934} | train loss {'Reaction outcome loss': 0.5082214096500555, 'Total loss': 0.5082214096500555}
2022-12-31 06:39:30,729 INFO:     Found new best model at epoch 1
2022-12-31 06:39:30,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:30,730 INFO:     Epoch: 2
2022-12-31 06:39:32,360 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48274524410565695, 'Total loss': 0.48274524410565695} | train loss {'Reaction outcome loss': 0.4405399658296943, 'Total loss': 0.4405399658296943}
2022-12-31 06:39:32,360 INFO:     Found new best model at epoch 2
2022-12-31 06:39:32,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:32,361 INFO:     Epoch: 3
2022-12-31 06:39:33,992 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44585204124450684, 'Total loss': 0.44585204124450684} | train loss {'Reaction outcome loss': 0.40702808269094476, 'Total loss': 0.40702808269094476}
2022-12-31 06:39:33,992 INFO:     Found new best model at epoch 3
2022-12-31 06:39:33,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:33,993 INFO:     Epoch: 4
2022-12-31 06:39:35,623 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46036525766054787, 'Total loss': 0.46036525766054787} | train loss {'Reaction outcome loss': 0.37754383484163867, 'Total loss': 0.37754383484163867}
2022-12-31 06:39:35,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:35,623 INFO:     Epoch: 5
2022-12-31 06:39:37,271 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4415854533513387, 'Total loss': 0.4415854533513387} | train loss {'Reaction outcome loss': 0.3533611601817048, 'Total loss': 0.3533611601817048}
2022-12-31 06:39:37,271 INFO:     Found new best model at epoch 5
2022-12-31 06:39:37,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:37,273 INFO:     Epoch: 6
2022-12-31 06:39:38,899 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4212622672319412, 'Total loss': 0.4212622672319412} | train loss {'Reaction outcome loss': 0.33440652562285156, 'Total loss': 0.33440652562285156}
2022-12-31 06:39:38,899 INFO:     Found new best model at epoch 6
2022-12-31 06:39:38,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:38,900 INFO:     Epoch: 7
2022-12-31 06:39:40,532 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43302385906378427, 'Total loss': 0.43302385906378427} | train loss {'Reaction outcome loss': 0.31780581894441634, 'Total loss': 0.31780581894441634}
2022-12-31 06:39:40,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:40,532 INFO:     Epoch: 8
2022-12-31 06:39:42,162 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3975994388262431, 'Total loss': 0.3975994388262431} | train loss {'Reaction outcome loss': 0.29950995681410664, 'Total loss': 0.29950995681410664}
2022-12-31 06:39:42,163 INFO:     Found new best model at epoch 8
2022-12-31 06:39:42,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:42,164 INFO:     Epoch: 9
2022-12-31 06:39:43,836 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40732571482658386, 'Total loss': 0.40732571482658386} | train loss {'Reaction outcome loss': 0.2869505186561858, 'Total loss': 0.2869505186561858}
2022-12-31 06:39:43,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:43,837 INFO:     Epoch: 10
2022-12-31 06:39:45,456 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4092542380094528, 'Total loss': 0.4092542380094528} | train loss {'Reaction outcome loss': 0.2735418229219285, 'Total loss': 0.2735418229219285}
2022-12-31 06:39:45,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:45,457 INFO:     Epoch: 11
2022-12-31 06:39:47,080 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42964937587579094, 'Total loss': 0.42964937587579094} | train loss {'Reaction outcome loss': 0.2634605375599345, 'Total loss': 0.2634605375599345}
2022-12-31 06:39:47,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:47,080 INFO:     Epoch: 12
2022-12-31 06:39:48,707 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39831223686536155, 'Total loss': 0.39831223686536155} | train loss {'Reaction outcome loss': 0.25072082072254337, 'Total loss': 0.25072082072254337}
2022-12-31 06:39:48,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:48,707 INFO:     Epoch: 13
2022-12-31 06:39:50,341 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4164115528265635, 'Total loss': 0.4164115528265635} | train loss {'Reaction outcome loss': 0.24260952526750548, 'Total loss': 0.24260952526750548}
2022-12-31 06:39:50,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:50,341 INFO:     Epoch: 14
2022-12-31 06:39:51,976 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3968599870800972, 'Total loss': 0.3968599870800972} | train loss {'Reaction outcome loss': 0.23313376962439247, 'Total loss': 0.23313376962439247}
2022-12-31 06:39:51,976 INFO:     Found new best model at epoch 14
2022-12-31 06:39:51,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:51,977 INFO:     Epoch: 15
2022-12-31 06:39:53,609 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3985442688067754, 'Total loss': 0.3985442688067754} | train loss {'Reaction outcome loss': 0.2276949577154558, 'Total loss': 0.2276949577154558}
2022-12-31 06:39:53,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:53,609 INFO:     Epoch: 16
2022-12-31 06:39:55,244 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42200827499230703, 'Total loss': 0.42200827499230703} | train loss {'Reaction outcome loss': 0.2197509352655725, 'Total loss': 0.2197509352655725}
2022-12-31 06:39:55,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:55,245 INFO:     Epoch: 17
2022-12-31 06:39:56,874 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.397241668899854, 'Total loss': 0.397241668899854} | train loss {'Reaction outcome loss': 0.21400009776173085, 'Total loss': 0.21400009776173085}
2022-12-31 06:39:56,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:56,875 INFO:     Epoch: 18
2022-12-31 06:39:58,532 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39284933507442477, 'Total loss': 0.39284933507442477} | train loss {'Reaction outcome loss': 0.20783874792608328, 'Total loss': 0.20783874792608328}
2022-12-31 06:39:58,532 INFO:     Found new best model at epoch 18
2022-12-31 06:39:58,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:39:58,533 INFO:     Epoch: 19
2022-12-31 06:40:00,168 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.400613941748937, 'Total loss': 0.400613941748937} | train loss {'Reaction outcome loss': 0.20121309902882104, 'Total loss': 0.20121309902882104}
2022-12-31 06:40:00,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:00,168 INFO:     Epoch: 20
2022-12-31 06:40:01,810 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41050197978814446, 'Total loss': 0.41050197978814446} | train loss {'Reaction outcome loss': 0.19803746482391005, 'Total loss': 0.19803746482391005}
2022-12-31 06:40:01,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:01,811 INFO:     Epoch: 21
2022-12-31 06:40:03,482 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3849583834409714, 'Total loss': 0.3849583834409714} | train loss {'Reaction outcome loss': 0.1914490622801148, 'Total loss': 0.1914490622801148}
2022-12-31 06:40:03,483 INFO:     Found new best model at epoch 21
2022-12-31 06:40:03,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:03,484 INFO:     Epoch: 22
2022-12-31 06:40:05,115 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4305881321430206, 'Total loss': 0.4305881321430206} | train loss {'Reaction outcome loss': 0.18791986228595572, 'Total loss': 0.18791986228595572}
2022-12-31 06:40:05,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:05,115 INFO:     Epoch: 23
2022-12-31 06:40:06,741 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3989273846149445, 'Total loss': 0.3989273846149445} | train loss {'Reaction outcome loss': 0.18210988614829224, 'Total loss': 0.18210988614829224}
2022-12-31 06:40:06,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:06,741 INFO:     Epoch: 24
2022-12-31 06:40:08,367 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4090494294961294, 'Total loss': 0.4090494294961294} | train loss {'Reaction outcome loss': 0.17857526677462277, 'Total loss': 0.17857526677462277}
2022-12-31 06:40:08,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:08,368 INFO:     Epoch: 25
2022-12-31 06:40:10,038 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3970633347829183, 'Total loss': 0.3970633347829183} | train loss {'Reaction outcome loss': 0.17225509321162416, 'Total loss': 0.17225509321162416}
2022-12-31 06:40:10,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:10,038 INFO:     Epoch: 26
2022-12-31 06:40:11,709 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41825766762097677, 'Total loss': 0.41825766762097677} | train loss {'Reaction outcome loss': 0.17098576118934242, 'Total loss': 0.17098576118934242}
2022-12-31 06:40:11,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:11,709 INFO:     Epoch: 27
2022-12-31 06:40:13,336 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43224263985951744, 'Total loss': 0.43224263985951744} | train loss {'Reaction outcome loss': 0.16963273059872622, 'Total loss': 0.16963273059872622}
2022-12-31 06:40:13,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:13,336 INFO:     Epoch: 28
2022-12-31 06:40:14,972 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4303403968612353, 'Total loss': 0.4303403968612353} | train loss {'Reaction outcome loss': 0.16528599522671653, 'Total loss': 0.16528599522671653}
2022-12-31 06:40:14,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:14,973 INFO:     Epoch: 29
2022-12-31 06:40:16,634 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4123653163512548, 'Total loss': 0.4123653163512548} | train loss {'Reaction outcome loss': 0.1610148236733804, 'Total loss': 0.1610148236733804}
2022-12-31 06:40:16,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:16,635 INFO:     Epoch: 30
2022-12-31 06:40:18,259 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.417212442557017, 'Total loss': 0.417212442557017} | train loss {'Reaction outcome loss': 0.16035937548140972, 'Total loss': 0.16035937548140972}
2022-12-31 06:40:18,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:18,259 INFO:     Epoch: 31
2022-12-31 06:40:19,883 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4231356958548228, 'Total loss': 0.4231356958548228} | train loss {'Reaction outcome loss': 0.15956346650981085, 'Total loss': 0.15956346650981085}
2022-12-31 06:40:19,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:19,884 INFO:     Epoch: 32
2022-12-31 06:40:21,554 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4383875419696172, 'Total loss': 0.4383875419696172} | train loss {'Reaction outcome loss': 0.1540484809474717, 'Total loss': 0.1540484809474717}
2022-12-31 06:40:21,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:21,554 INFO:     Epoch: 33
2022-12-31 06:40:23,224 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44767229855060575, 'Total loss': 0.44767229855060575} | train loss {'Reaction outcome loss': 0.1532112859855221, 'Total loss': 0.1532112859855221}
2022-12-31 06:40:23,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:23,224 INFO:     Epoch: 34
2022-12-31 06:40:24,857 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45178913374741875, 'Total loss': 0.45178913374741875} | train loss {'Reaction outcome loss': 0.1502299029111109, 'Total loss': 0.1502299029111109}
2022-12-31 06:40:24,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:24,857 INFO:     Epoch: 35
2022-12-31 06:40:26,494 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43892208735148114, 'Total loss': 0.43892208735148114} | train loss {'Reaction outcome loss': 0.14657101651741064, 'Total loss': 0.14657101651741064}
2022-12-31 06:40:26,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:26,494 INFO:     Epoch: 36
2022-12-31 06:40:28,132 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4109560956557592, 'Total loss': 0.4109560956557592} | train loss {'Reaction outcome loss': 0.1440529511999406, 'Total loss': 0.1440529511999406}
2022-12-31 06:40:28,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:28,133 INFO:     Epoch: 37
2022-12-31 06:40:29,784 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43007156054178874, 'Total loss': 0.43007156054178874} | train loss {'Reaction outcome loss': 0.14556380656181367, 'Total loss': 0.14556380656181367}
2022-12-31 06:40:29,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:29,785 INFO:     Epoch: 38
2022-12-31 06:40:31,416 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4373376061518987, 'Total loss': 0.4373376061518987} | train loss {'Reaction outcome loss': 0.1432252187644962, 'Total loss': 0.1432252187644962}
2022-12-31 06:40:31,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:31,417 INFO:     Epoch: 39
2022-12-31 06:40:33,041 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42761645118395486, 'Total loss': 0.42761645118395486} | train loss {'Reaction outcome loss': 0.1380517391373642, 'Total loss': 0.1380517391373642}
2022-12-31 06:40:33,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:33,041 INFO:     Epoch: 40
2022-12-31 06:40:34,660 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44038036465644836, 'Total loss': 0.44038036465644836} | train loss {'Reaction outcome loss': 0.13838553680308727, 'Total loss': 0.13838553680308727}
2022-12-31 06:40:34,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:34,661 INFO:     Epoch: 41
2022-12-31 06:40:36,285 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4578774183988571, 'Total loss': 0.4578774183988571} | train loss {'Reaction outcome loss': 0.1337110212203855, 'Total loss': 0.1337110212203855}
2022-12-31 06:40:36,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:36,285 INFO:     Epoch: 42
2022-12-31 06:40:38,009 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4534983277320862, 'Total loss': 0.4534983277320862} | train loss {'Reaction outcome loss': 0.13769017306529657, 'Total loss': 0.13769017306529657}
2022-12-31 06:40:38,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:38,009 INFO:     Epoch: 43
2022-12-31 06:40:39,695 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44521775941054026, 'Total loss': 0.44521775941054026} | train loss {'Reaction outcome loss': 0.13406320468989952, 'Total loss': 0.13406320468989952}
2022-12-31 06:40:39,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:39,695 INFO:     Epoch: 44
2022-12-31 06:40:41,366 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4633297691742579, 'Total loss': 0.4633297691742579} | train loss {'Reaction outcome loss': 0.13534700283814316, 'Total loss': 0.13534700283814316}
2022-12-31 06:40:41,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:41,367 INFO:     Epoch: 45
2022-12-31 06:40:42,990 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44545017182826996, 'Total loss': 0.44545017182826996} | train loss {'Reaction outcome loss': 0.1323487236255289, 'Total loss': 0.1323487236255289}
2022-12-31 06:40:42,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:42,990 INFO:     Epoch: 46
2022-12-31 06:40:44,660 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4633967071771622, 'Total loss': 0.4633967071771622} | train loss {'Reaction outcome loss': 0.12890353260581996, 'Total loss': 0.12890353260581996}
2022-12-31 06:40:44,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:44,660 INFO:     Epoch: 47
2022-12-31 06:40:46,332 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4223808611432711, 'Total loss': 0.4223808611432711} | train loss {'Reaction outcome loss': 0.13323384329057988, 'Total loss': 0.13323384329057988}
2022-12-31 06:40:46,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:46,333 INFO:     Epoch: 48
2022-12-31 06:40:47,958 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4380287806193034, 'Total loss': 0.4380287806193034} | train loss {'Reaction outcome loss': 0.12536454292700125, 'Total loss': 0.12536454292700125}
2022-12-31 06:40:47,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:47,959 INFO:     Epoch: 49
2022-12-31 06:40:49,582 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43768200973669685, 'Total loss': 0.43768200973669685} | train loss {'Reaction outcome loss': 0.12499861527799161, 'Total loss': 0.12499861527799161}
2022-12-31 06:40:49,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:49,582 INFO:     Epoch: 50
2022-12-31 06:40:51,236 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4278329585989316, 'Total loss': 0.4278329585989316} | train loss {'Reaction outcome loss': 0.12393798420393994, 'Total loss': 0.12393798420393994}
2022-12-31 06:40:51,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:51,237 INFO:     Epoch: 51
2022-12-31 06:40:52,868 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4192653179168701, 'Total loss': 0.4192653179168701} | train loss {'Reaction outcome loss': 0.12506217684929632, 'Total loss': 0.12506217684929632}
2022-12-31 06:40:52,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:52,868 INFO:     Epoch: 52
2022-12-31 06:40:54,538 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4620899985233943, 'Total loss': 0.4620899985233943} | train loss {'Reaction outcome loss': 0.12327385296883728, 'Total loss': 0.12327385296883728}
2022-12-31 06:40:54,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:54,538 INFO:     Epoch: 53
2022-12-31 06:40:56,163 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.438528315226237, 'Total loss': 0.438528315226237} | train loss {'Reaction outcome loss': 0.12309223696394464, 'Total loss': 0.12309223696394464}
2022-12-31 06:40:56,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:56,163 INFO:     Epoch: 54
2022-12-31 06:40:57,833 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4384630759557088, 'Total loss': 0.4384630759557088} | train loss {'Reaction outcome loss': 0.12279319171440731, 'Total loss': 0.12279319171440731}
2022-12-31 06:40:57,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:57,833 INFO:     Epoch: 55
2022-12-31 06:40:59,502 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4441321164369583, 'Total loss': 0.4441321164369583} | train loss {'Reaction outcome loss': 0.1231248579820154, 'Total loss': 0.1231248579820154}
2022-12-31 06:40:59,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:40:59,503 INFO:     Epoch: 56
2022-12-31 06:41:01,126 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43452697694301606, 'Total loss': 0.43452697694301606} | train loss {'Reaction outcome loss': 0.1266541506301625, 'Total loss': 0.1266541506301625}
2022-12-31 06:41:01,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:01,127 INFO:     Epoch: 57
2022-12-31 06:41:02,770 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42968002557754514, 'Total loss': 0.42968002557754514} | train loss {'Reaction outcome loss': 0.11931336362970596, 'Total loss': 0.11931336362970596}
2022-12-31 06:41:02,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:02,770 INFO:     Epoch: 58
2022-12-31 06:41:04,449 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42287122309207914, 'Total loss': 0.42287122309207914} | train loss {'Reaction outcome loss': 0.12059639263158456, 'Total loss': 0.12059639263158456}
2022-12-31 06:41:04,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:04,450 INFO:     Epoch: 59
2022-12-31 06:41:06,074 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44793680012226106, 'Total loss': 0.44793680012226106} | train loss {'Reaction outcome loss': 0.11732352644016812, 'Total loss': 0.11732352644016812}
2022-12-31 06:41:06,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:06,074 INFO:     Epoch: 60
2022-12-31 06:41:07,746 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4410755048195521, 'Total loss': 0.4410755048195521} | train loss {'Reaction outcome loss': 0.11644911203224091, 'Total loss': 0.11644911203224091}
2022-12-31 06:41:07,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:07,746 INFO:     Epoch: 61
2022-12-31 06:41:09,370 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4474285582701365, 'Total loss': 0.4474285582701365} | train loss {'Reaction outcome loss': 0.11645619488079167, 'Total loss': 0.11645619488079167}
2022-12-31 06:41:09,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:09,370 INFO:     Epoch: 62
2022-12-31 06:41:10,998 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4509385019540787, 'Total loss': 0.4509385019540787} | train loss {'Reaction outcome loss': 0.12021572543736816, 'Total loss': 0.12021572543736816}
2022-12-31 06:41:10,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:10,998 INFO:     Epoch: 63
2022-12-31 06:41:12,631 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44594976206620535, 'Total loss': 0.44594976206620535} | train loss {'Reaction outcome loss': 0.11610255592304285, 'Total loss': 0.11610255592304285}
2022-12-31 06:41:12,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:12,631 INFO:     Epoch: 64
2022-12-31 06:41:14,259 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41913594702879586, 'Total loss': 0.41913594702879586} | train loss {'Reaction outcome loss': 0.11843543008494356, 'Total loss': 0.11843543008494356}
2022-12-31 06:41:14,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:14,260 INFO:     Epoch: 65
2022-12-31 06:41:15,893 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47770330707232156, 'Total loss': 0.47770330707232156} | train loss {'Reaction outcome loss': 0.11550204087526197, 'Total loss': 0.11550204087526197}
2022-12-31 06:41:15,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:15,893 INFO:     Epoch: 66
2022-12-31 06:41:17,517 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4564182403186957, 'Total loss': 0.4564182403186957} | train loss {'Reaction outcome loss': 0.11481874256599896, 'Total loss': 0.11481874256599896}
2022-12-31 06:41:17,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:17,517 INFO:     Epoch: 67
2022-12-31 06:41:19,142 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45408510863780976, 'Total loss': 0.45408510863780976} | train loss {'Reaction outcome loss': 0.11011008600896016, 'Total loss': 0.11011008600896016}
2022-12-31 06:41:19,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:19,142 INFO:     Epoch: 68
2022-12-31 06:41:20,806 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46166323373715085, 'Total loss': 0.46166323373715085} | train loss {'Reaction outcome loss': 0.11273489696636042, 'Total loss': 0.11273489696636042}
2022-12-31 06:41:20,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:20,806 INFO:     Epoch: 69
2022-12-31 06:41:22,430 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4660365402698517, 'Total loss': 0.4660365402698517} | train loss {'Reaction outcome loss': 0.1135847064454633, 'Total loss': 0.1135847064454633}
2022-12-31 06:41:22,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:22,430 INFO:     Epoch: 70
2022-12-31 06:41:24,100 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.447723122437795, 'Total loss': 0.447723122437795} | train loss {'Reaction outcome loss': 0.11259200884237724, 'Total loss': 0.11259200884237724}
2022-12-31 06:41:24,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:24,101 INFO:     Epoch: 71
2022-12-31 06:41:25,719 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4573740651210149, 'Total loss': 0.4573740651210149} | train loss {'Reaction outcome loss': 0.11163640476507723, 'Total loss': 0.11163640476507723}
2022-12-31 06:41:25,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:25,719 INFO:     Epoch: 72
2022-12-31 06:41:27,344 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41471483012040455, 'Total loss': 0.41471483012040455} | train loss {'Reaction outcome loss': 0.11539866377192715, 'Total loss': 0.11539866377192715}
2022-12-31 06:41:27,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:27,345 INFO:     Epoch: 73
2022-12-31 06:41:28,964 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4811018337806066, 'Total loss': 0.4811018337806066} | train loss {'Reaction outcome loss': 0.11373922586380521, 'Total loss': 0.11373922586380521}
2022-12-31 06:41:28,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:28,964 INFO:     Epoch: 74
2022-12-31 06:41:30,597 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4670155813296636, 'Total loss': 0.4670155813296636} | train loss {'Reaction outcome loss': 0.11144353666289, 'Total loss': 0.11144353666289}
2022-12-31 06:41:30,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:30,597 INFO:     Epoch: 75
2022-12-31 06:41:32,228 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4538525541623433, 'Total loss': 0.4538525541623433} | train loss {'Reaction outcome loss': 0.11665442870721382, 'Total loss': 0.11665442870721382}
2022-12-31 06:41:32,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:32,228 INFO:     Epoch: 76
2022-12-31 06:41:33,859 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46057851910591124, 'Total loss': 0.46057851910591124} | train loss {'Reaction outcome loss': 0.11184768945429245, 'Total loss': 0.11184768945429245}
2022-12-31 06:41:33,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:33,859 INFO:     Epoch: 77
2022-12-31 06:41:35,491 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4396312743425369, 'Total loss': 0.4396312743425369} | train loss {'Reaction outcome loss': 0.11088214036151228, 'Total loss': 0.11088214036151228}
2022-12-31 06:41:35,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:35,491 INFO:     Epoch: 78
2022-12-31 06:41:37,117 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4850457365314166, 'Total loss': 0.4850457365314166} | train loss {'Reaction outcome loss': 0.10920465740439102, 'Total loss': 0.10920465740439102}
2022-12-31 06:41:37,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:37,117 INFO:     Epoch: 79
2022-12-31 06:41:38,738 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4132896766066551, 'Total loss': 0.4132896766066551} | train loss {'Reaction outcome loss': 0.10686325387094534, 'Total loss': 0.10686325387094534}
2022-12-31 06:41:38,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:38,738 INFO:     Epoch: 80
2022-12-31 06:41:40,371 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4452422658602397, 'Total loss': 0.4452422658602397} | train loss {'Reaction outcome loss': 0.10884541940508874, 'Total loss': 0.10884541940508874}
2022-12-31 06:41:40,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:40,372 INFO:     Epoch: 81
2022-12-31 06:41:42,005 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47123520622650783, 'Total loss': 0.47123520622650783} | train loss {'Reaction outcome loss': 0.11423285244476548, 'Total loss': 0.11423285244476548}
2022-12-31 06:41:42,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:42,005 INFO:     Epoch: 82
2022-12-31 06:41:43,638 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46166048844655355, 'Total loss': 0.46166048844655355} | train loss {'Reaction outcome loss': 0.11434452895945886, 'Total loss': 0.11434452895945886}
2022-12-31 06:41:43,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:43,638 INFO:     Epoch: 83
2022-12-31 06:41:45,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4491947015126546, 'Total loss': 0.4491947015126546} | train loss {'Reaction outcome loss': 0.11417262757277714, 'Total loss': 0.11417262757277714}
2022-12-31 06:41:45,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:45,272 INFO:     Epoch: 84
2022-12-31 06:41:46,891 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44571908513704933, 'Total loss': 0.44571908513704933} | train loss {'Reaction outcome loss': 0.11024593099756738, 'Total loss': 0.11024593099756738}
2022-12-31 06:41:46,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:46,892 INFO:     Epoch: 85
2022-12-31 06:41:48,528 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4607484926780065, 'Total loss': 0.4607484926780065} | train loss {'Reaction outcome loss': 0.10685258034435151, 'Total loss': 0.10685258034435151}
2022-12-31 06:41:48,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:48,528 INFO:     Epoch: 86
2022-12-31 06:41:50,165 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44912073413530984, 'Total loss': 0.44912073413530984} | train loss {'Reaction outcome loss': 0.10864615119701178, 'Total loss': 0.10864615119701178}
2022-12-31 06:41:50,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:50,165 INFO:     Epoch: 87
2022-12-31 06:41:51,802 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4889605085055033, 'Total loss': 0.4889605085055033} | train loss {'Reaction outcome loss': 0.10570073856329983, 'Total loss': 0.10570073856329983}
2022-12-31 06:41:51,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:51,802 INFO:     Epoch: 88
2022-12-31 06:41:53,439 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43253897279500964, 'Total loss': 0.43253897279500964} | train loss {'Reaction outcome loss': 0.10996753585000357, 'Total loss': 0.10996753585000357}
2022-12-31 06:41:53,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:53,439 INFO:     Epoch: 89
2022-12-31 06:41:55,069 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4701077342033386, 'Total loss': 0.4701077342033386} | train loss {'Reaction outcome loss': 0.11668782995590127, 'Total loss': 0.11668782995590127}
2022-12-31 06:41:55,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:55,069 INFO:     Epoch: 90
2022-12-31 06:41:56,696 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48651105066140493, 'Total loss': 0.48651105066140493} | train loss {'Reaction outcome loss': 0.1094820660090121, 'Total loss': 0.1094820660090121}
2022-12-31 06:41:56,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:56,696 INFO:     Epoch: 91
2022-12-31 06:41:58,335 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4848126272360484, 'Total loss': 0.4848126272360484} | train loss {'Reaction outcome loss': 0.10928826143339761, 'Total loss': 0.10928826143339761}
2022-12-31 06:41:58,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:58,336 INFO:     Epoch: 92
2022-12-31 06:41:59,983 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4387897451718648, 'Total loss': 0.4387897451718648} | train loss {'Reaction outcome loss': 0.11290955131735639, 'Total loss': 0.11290955131735639}
2022-12-31 06:41:59,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:41:59,984 INFO:     Epoch: 93
2022-12-31 06:42:01,605 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45322502702474593, 'Total loss': 0.45322502702474593} | train loss {'Reaction outcome loss': 0.11321217408370132, 'Total loss': 0.11321217408370132}
2022-12-31 06:42:01,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:01,605 INFO:     Epoch: 94
2022-12-31 06:42:03,227 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43948675990104674, 'Total loss': 0.43948675990104674} | train loss {'Reaction outcome loss': 0.10607809866509578, 'Total loss': 0.10607809866509578}
2022-12-31 06:42:03,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:03,227 INFO:     Epoch: 95
2022-12-31 06:42:04,843 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42979819774627687, 'Total loss': 0.42979819774627687} | train loss {'Reaction outcome loss': 0.10629842387569484, 'Total loss': 0.10629842387569484}
2022-12-31 06:42:04,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:04,843 INFO:     Epoch: 96
2022-12-31 06:42:06,516 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4470013121763865, 'Total loss': 0.4470013121763865} | train loss {'Reaction outcome loss': 0.10517885235376952, 'Total loss': 0.10517885235376952}
2022-12-31 06:42:06,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:06,516 INFO:     Epoch: 97
2022-12-31 06:42:08,201 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45171486735343935, 'Total loss': 0.45171486735343935} | train loss {'Reaction outcome loss': 0.10690295970107729, 'Total loss': 0.10690295970107729}
2022-12-31 06:42:08,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:08,201 INFO:     Epoch: 98
2022-12-31 06:42:09,831 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40167524069547655, 'Total loss': 0.40167524069547655} | train loss {'Reaction outcome loss': 0.10130083820188338, 'Total loss': 0.10130083820188338}
2022-12-31 06:42:09,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:09,831 INFO:     Epoch: 99
2022-12-31 06:42:11,554 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42331305940945946, 'Total loss': 0.42331305940945946} | train loss {'Reaction outcome loss': 0.10314976160930611, 'Total loss': 0.10314976160930611}
2022-12-31 06:42:11,554 INFO:     Best model found after epoch 22 of 100.
2022-12-31 06:42:11,554 INFO:   Done with stage: TRAINING
2022-12-31 06:42:11,554 INFO:   Starting stage: EVALUATION
2022-12-31 06:42:11,679 INFO:   Done with stage: EVALUATION
2022-12-31 06:42:11,679 INFO:   Leaving out SEQ value Fold_8
2022-12-31 06:42:11,692 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 06:42:11,692 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:42:12,334 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:42:12,334 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:42:12,406 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:42:12,407 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:42:12,407 INFO:     No hyperparam tuning for this model
2022-12-31 06:42:12,407 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:42:12,407 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:42:12,408 INFO:     None feature selector for col prot
2022-12-31 06:42:12,408 INFO:     None feature selector for col prot
2022-12-31 06:42:12,408 INFO:     None feature selector for col prot
2022-12-31 06:42:12,408 INFO:     None feature selector for col chem
2022-12-31 06:42:12,408 INFO:     None feature selector for col chem
2022-12-31 06:42:12,408 INFO:     None feature selector for col chem
2022-12-31 06:42:12,408 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:42:12,409 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:42:12,410 INFO:     Number of params in model 224011
2022-12-31 06:42:12,414 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:42:12,414 INFO:   Starting stage: TRAINING
2022-12-31 06:42:12,459 INFO:     Val loss before train {'Reaction outcome loss': 1.0329017559687297, 'Total loss': 1.0329017559687297}
2022-12-31 06:42:12,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:12,459 INFO:     Epoch: 0
2022-12-31 06:42:14,074 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5769932786623637, 'Total loss': 0.5769932786623637} | train loss {'Reaction outcome loss': 0.7857808750191014, 'Total loss': 0.7857808750191014}
2022-12-31 06:42:14,074 INFO:     Found new best model at epoch 0
2022-12-31 06:42:14,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:14,075 INFO:     Epoch: 1
2022-12-31 06:42:15,686 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49102952678998313, 'Total loss': 0.49102952678998313} | train loss {'Reaction outcome loss': 0.5189944295001118, 'Total loss': 0.5189944295001118}
2022-12-31 06:42:15,687 INFO:     Found new best model at epoch 1
2022-12-31 06:42:15,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:15,688 INFO:     Epoch: 2
2022-12-31 06:42:17,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4420283198356628, 'Total loss': 0.4420283198356628} | train loss {'Reaction outcome loss': 0.4519952315386835, 'Total loss': 0.4519952315386835}
2022-12-31 06:42:17,298 INFO:     Found new best model at epoch 2
2022-12-31 06:42:17,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:17,299 INFO:     Epoch: 3
2022-12-31 06:42:18,910 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47790072361628216, 'Total loss': 0.47790072361628216} | train loss {'Reaction outcome loss': 0.4113532938472517, 'Total loss': 0.4113532938472517}
2022-12-31 06:42:18,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:18,911 INFO:     Epoch: 4
2022-12-31 06:42:20,524 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.431939971446991, 'Total loss': 0.431939971446991} | train loss {'Reaction outcome loss': 0.3844151931367951, 'Total loss': 0.3844151931367951}
2022-12-31 06:42:20,524 INFO:     Found new best model at epoch 4
2022-12-31 06:42:20,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:20,525 INFO:     Epoch: 5
2022-12-31 06:42:22,133 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4131489594777425, 'Total loss': 0.4131489594777425} | train loss {'Reaction outcome loss': 0.3595437636196395, 'Total loss': 0.3595437636196395}
2022-12-31 06:42:22,133 INFO:     Found new best model at epoch 5
2022-12-31 06:42:22,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:22,135 INFO:     Epoch: 6
2022-12-31 06:42:23,735 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3733300050099691, 'Total loss': 0.3733300050099691} | train loss {'Reaction outcome loss': 0.34056783251928324, 'Total loss': 0.34056783251928324}
2022-12-31 06:42:23,735 INFO:     Found new best model at epoch 6
2022-12-31 06:42:23,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:23,736 INFO:     Epoch: 7
2022-12-31 06:42:25,344 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3776519854863485, 'Total loss': 0.3776519854863485} | train loss {'Reaction outcome loss': 0.3261103887697716, 'Total loss': 0.3261103887697716}
2022-12-31 06:42:25,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:25,344 INFO:     Epoch: 8
2022-12-31 06:42:26,993 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37815334300200143, 'Total loss': 0.37815334300200143} | train loss {'Reaction outcome loss': 0.30649960193878567, 'Total loss': 0.30649960193878567}
2022-12-31 06:42:26,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:26,993 INFO:     Epoch: 9
2022-12-31 06:42:28,642 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3662400558590889, 'Total loss': 0.3662400558590889} | train loss {'Reaction outcome loss': 0.295037574383802, 'Total loss': 0.295037574383802}
2022-12-31 06:42:28,642 INFO:     Found new best model at epoch 9
2022-12-31 06:42:28,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:28,643 INFO:     Epoch: 10
2022-12-31 06:42:30,254 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39305943648020425, 'Total loss': 0.39305943648020425} | train loss {'Reaction outcome loss': 0.28145954725179045, 'Total loss': 0.28145954725179045}
2022-12-31 06:42:30,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:30,254 INFO:     Epoch: 11
2022-12-31 06:42:31,870 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3685202121734619, 'Total loss': 0.3685202121734619} | train loss {'Reaction outcome loss': 0.2724012763618113, 'Total loss': 0.2724012763618113}
2022-12-31 06:42:31,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:31,870 INFO:     Epoch: 12
2022-12-31 06:42:33,472 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35509030322233837, 'Total loss': 0.35509030322233837} | train loss {'Reaction outcome loss': 0.26142090706209287, 'Total loss': 0.26142090706209287}
2022-12-31 06:42:33,472 INFO:     Found new best model at epoch 12
2022-12-31 06:42:33,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:33,473 INFO:     Epoch: 13
2022-12-31 06:42:35,082 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3613637392719587, 'Total loss': 0.3613637392719587} | train loss {'Reaction outcome loss': 0.2567940474702762, 'Total loss': 0.2567940474702762}
2022-12-31 06:42:35,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:35,083 INFO:     Epoch: 14
2022-12-31 06:42:36,694 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37806570529937744, 'Total loss': 0.37806570529937744} | train loss {'Reaction outcome loss': 0.24791557894466998, 'Total loss': 0.24791557894466998}
2022-12-31 06:42:36,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:36,694 INFO:     Epoch: 15
2022-12-31 06:42:38,304 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3683434893687566, 'Total loss': 0.3683434893687566} | train loss {'Reaction outcome loss': 0.23791553939764315, 'Total loss': 0.23791553939764315}
2022-12-31 06:42:38,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:38,304 INFO:     Epoch: 16
2022-12-31 06:42:39,915 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38128441472848257, 'Total loss': 0.38128441472848257} | train loss {'Reaction outcome loss': 0.23122594977691496, 'Total loss': 0.23122594977691496}
2022-12-31 06:42:39,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:39,915 INFO:     Epoch: 17
2022-12-31 06:42:41,508 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3705636739730835, 'Total loss': 0.3705636739730835} | train loss {'Reaction outcome loss': 0.22609626689086576, 'Total loss': 0.22609626689086576}
2022-12-31 06:42:41,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:41,508 INFO:     Epoch: 18
2022-12-31 06:42:43,118 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37630709211031593, 'Total loss': 0.37630709211031593} | train loss {'Reaction outcome loss': 0.2199637439893388, 'Total loss': 0.2199637439893388}
2022-12-31 06:42:43,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:43,118 INFO:     Epoch: 19
2022-12-31 06:42:44,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35276722808678945, 'Total loss': 0.35276722808678945} | train loss {'Reaction outcome loss': 0.2158759760810233, 'Total loss': 0.2158759760810233}
2022-12-31 06:42:44,729 INFO:     Found new best model at epoch 19
2022-12-31 06:42:44,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:44,730 INFO:     Epoch: 20
2022-12-31 06:42:46,339 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37358744541803995, 'Total loss': 0.37358744541803995} | train loss {'Reaction outcome loss': 0.20869509570024253, 'Total loss': 0.20869509570024253}
2022-12-31 06:42:46,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:46,340 INFO:     Epoch: 21
2022-12-31 06:42:47,948 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39741194297870003, 'Total loss': 0.39741194297870003} | train loss {'Reaction outcome loss': 0.2032816476928882, 'Total loss': 0.2032816476928882}
2022-12-31 06:42:47,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:47,949 INFO:     Epoch: 22
2022-12-31 06:42:49,551 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35150465269883474, 'Total loss': 0.35150465269883474} | train loss {'Reaction outcome loss': 0.1978236356026906, 'Total loss': 0.1978236356026906}
2022-12-31 06:42:49,551 INFO:     Found new best model at epoch 22
2022-12-31 06:42:49,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:49,552 INFO:     Epoch: 23
2022-12-31 06:42:51,151 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3638153026501338, 'Total loss': 0.3638153026501338} | train loss {'Reaction outcome loss': 0.19162394117304693, 'Total loss': 0.19162394117304693}
2022-12-31 06:42:51,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:51,152 INFO:     Epoch: 24
2022-12-31 06:42:52,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39526758790016175, 'Total loss': 0.39526758790016175} | train loss {'Reaction outcome loss': 0.19151499905306232, 'Total loss': 0.19151499905306232}
2022-12-31 06:42:52,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:52,763 INFO:     Epoch: 25
2022-12-31 06:42:54,372 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3529045512278875, 'Total loss': 0.3529045512278875} | train loss {'Reaction outcome loss': 0.19191639884050948, 'Total loss': 0.19191639884050948}
2022-12-31 06:42:54,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:54,373 INFO:     Epoch: 26
2022-12-31 06:42:56,019 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.371118692557017, 'Total loss': 0.371118692557017} | train loss {'Reaction outcome loss': 0.18703536114113017, 'Total loss': 0.18703536114113017}
2022-12-31 06:42:56,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:56,019 INFO:     Epoch: 27
2022-12-31 06:42:57,618 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.362505674858888, 'Total loss': 0.362505674858888} | train loss {'Reaction outcome loss': 0.1819942223979331, 'Total loss': 0.1819942223979331}
2022-12-31 06:42:57,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:57,618 INFO:     Epoch: 28
2022-12-31 06:42:59,245 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36857713187734287, 'Total loss': 0.36857713187734287} | train loss {'Reaction outcome loss': 0.1766657478827642, 'Total loss': 0.1766657478827642}
2022-12-31 06:42:59,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:42:59,245 INFO:     Epoch: 29
2022-12-31 06:43:00,842 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40096504588921866, 'Total loss': 0.40096504588921866} | train loss {'Reaction outcome loss': 0.17560398172000388, 'Total loss': 0.17560398172000388}
2022-12-31 06:43:00,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:00,842 INFO:     Epoch: 30
2022-12-31 06:43:02,492 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3758467028538386, 'Total loss': 0.3758467028538386} | train loss {'Reaction outcome loss': 0.17516018617420626, 'Total loss': 0.17516018617420626}
2022-12-31 06:43:02,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:02,492 INFO:     Epoch: 31
2022-12-31 06:43:04,140 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36868655184904736, 'Total loss': 0.36868655184904736} | train loss {'Reaction outcome loss': 0.17784068408684853, 'Total loss': 0.17784068408684853}
2022-12-31 06:43:04,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:04,140 INFO:     Epoch: 32
2022-12-31 06:43:05,790 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3716672986745834, 'Total loss': 0.3716672986745834} | train loss {'Reaction outcome loss': 0.16456356291205454, 'Total loss': 0.16456356291205454}
2022-12-31 06:43:05,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:05,791 INFO:     Epoch: 33
2022-12-31 06:43:07,391 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39577612777551013, 'Total loss': 0.39577612777551013} | train loss {'Reaction outcome loss': 0.1647826134373908, 'Total loss': 0.1647826134373908}
2022-12-31 06:43:07,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:07,391 INFO:     Epoch: 34
2022-12-31 06:43:08,986 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37649105489254, 'Total loss': 0.37649105489254} | train loss {'Reaction outcome loss': 0.16214836442556518, 'Total loss': 0.16214836442556518}
2022-12-31 06:43:08,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:08,986 INFO:     Epoch: 35
2022-12-31 06:43:10,598 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3690706044435501, 'Total loss': 0.3690706044435501} | train loss {'Reaction outcome loss': 0.16375096455462032, 'Total loss': 0.16375096455462032}
2022-12-31 06:43:10,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:10,598 INFO:     Epoch: 36
2022-12-31 06:43:12,211 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4174446533123652, 'Total loss': 0.4174446533123652} | train loss {'Reaction outcome loss': 0.16314811569607848, 'Total loss': 0.16314811569607848}
2022-12-31 06:43:12,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:12,211 INFO:     Epoch: 37
2022-12-31 06:43:13,824 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3660880317290624, 'Total loss': 0.3660880317290624} | train loss {'Reaction outcome loss': 0.16061301864751856, 'Total loss': 0.16061301864751856}
2022-12-31 06:43:13,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:13,824 INFO:     Epoch: 38
2022-12-31 06:43:15,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3791757846872012, 'Total loss': 0.3791757846872012} | train loss {'Reaction outcome loss': 0.15747981136084804, 'Total loss': 0.15747981136084804}
2022-12-31 06:43:15,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:15,434 INFO:     Epoch: 39
2022-12-31 06:43:17,066 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3647471308708191, 'Total loss': 0.3647471308708191} | train loss {'Reaction outcome loss': 0.15769547224385944, 'Total loss': 0.15769547224385944}
2022-12-31 06:43:17,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:17,066 INFO:     Epoch: 40
2022-12-31 06:43:18,757 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4278071562449137, 'Total loss': 0.4278071562449137} | train loss {'Reaction outcome loss': 0.15059076677393782, 'Total loss': 0.15059076677393782}
2022-12-31 06:43:18,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:18,757 INFO:     Epoch: 41
2022-12-31 06:43:20,460 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38815028220415115, 'Total loss': 0.38815028220415115} | train loss {'Reaction outcome loss': 0.15273234334300126, 'Total loss': 0.15273234334300126}
2022-12-31 06:43:20,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:20,460 INFO:     Epoch: 42
2022-12-31 06:43:22,163 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3652797405918439, 'Total loss': 0.3652797405918439} | train loss {'Reaction outcome loss': 0.14853663409585918, 'Total loss': 0.14853663409585918}
2022-12-31 06:43:22,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:22,164 INFO:     Epoch: 43
2022-12-31 06:43:23,766 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40010685175657273, 'Total loss': 0.40010685175657273} | train loss {'Reaction outcome loss': 0.151548725989521, 'Total loss': 0.151548725989521}
2022-12-31 06:43:23,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:23,766 INFO:     Epoch: 44
2022-12-31 06:43:25,469 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3785533557335536, 'Total loss': 0.3785533557335536} | train loss {'Reaction outcome loss': 0.14668259140608947, 'Total loss': 0.14668259140608947}
2022-12-31 06:43:25,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:25,469 INFO:     Epoch: 45
2022-12-31 06:43:27,077 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3879378020763397, 'Total loss': 0.3879378020763397} | train loss {'Reaction outcome loss': 0.14470890446842372, 'Total loss': 0.14470890446842372}
2022-12-31 06:43:27,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:27,077 INFO:     Epoch: 46
2022-12-31 06:43:28,684 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.381309778491656, 'Total loss': 0.381309778491656} | train loss {'Reaction outcome loss': 0.1387129903979081, 'Total loss': 0.1387129903979081}
2022-12-31 06:43:28,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:28,685 INFO:     Epoch: 47
2022-12-31 06:43:30,290 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3848247408866882, 'Total loss': 0.3848247408866882} | train loss {'Reaction outcome loss': 0.14457954548899726, 'Total loss': 0.14457954548899726}
2022-12-31 06:43:30,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:30,290 INFO:     Epoch: 48
2022-12-31 06:43:31,994 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3823357343673706, 'Total loss': 0.3823357343673706} | train loss {'Reaction outcome loss': 0.14166706609420288, 'Total loss': 0.14166706609420288}
2022-12-31 06:43:31,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:31,994 INFO:     Epoch: 49
2022-12-31 06:43:33,595 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3765568782885869, 'Total loss': 0.3765568782885869} | train loss {'Reaction outcome loss': 0.14287773067738874, 'Total loss': 0.14287773067738874}
2022-12-31 06:43:33,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:33,595 INFO:     Epoch: 50
2022-12-31 06:43:35,288 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39528220891952515, 'Total loss': 0.39528220891952515} | train loss {'Reaction outcome loss': 0.14094089464397058, 'Total loss': 0.14094089464397058}
2022-12-31 06:43:35,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:35,288 INFO:     Epoch: 51
2022-12-31 06:43:36,946 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3982721358537674, 'Total loss': 0.3982721358537674} | train loss {'Reaction outcome loss': 0.14172523513081528, 'Total loss': 0.14172523513081528}
2022-12-31 06:43:36,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:36,947 INFO:     Epoch: 52
2022-12-31 06:43:38,649 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39098676045735675, 'Total loss': 0.39098676045735675} | train loss {'Reaction outcome loss': 0.14359713152337533, 'Total loss': 0.14359713152337533}
2022-12-31 06:43:38,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:38,649 INFO:     Epoch: 53
2022-12-31 06:43:40,352 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3831993296742439, 'Total loss': 0.3831993296742439} | train loss {'Reaction outcome loss': 0.13809395561441642, 'Total loss': 0.13809395561441642}
2022-12-31 06:43:40,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:40,352 INFO:     Epoch: 54
2022-12-31 06:43:42,053 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3771412735184034, 'Total loss': 0.3771412735184034} | train loss {'Reaction outcome loss': 0.13769454674474596, 'Total loss': 0.13769454674474596}
2022-12-31 06:43:42,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:42,054 INFO:     Epoch: 55
2022-12-31 06:43:43,659 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37834968566894533, 'Total loss': 0.37834968566894533} | train loss {'Reaction outcome loss': 0.135484216855873, 'Total loss': 0.135484216855873}
2022-12-31 06:43:43,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:43,660 INFO:     Epoch: 56
2022-12-31 06:43:45,352 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3620695766992867, 'Total loss': 0.3620695766992867} | train loss {'Reaction outcome loss': 0.13147205369369613, 'Total loss': 0.13147205369369613}
2022-12-31 06:43:45,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:45,353 INFO:     Epoch: 57
2022-12-31 06:43:46,975 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.418776602546374, 'Total loss': 0.418776602546374} | train loss {'Reaction outcome loss': 0.13372993961508786, 'Total loss': 0.13372993961508786}
2022-12-31 06:43:46,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:46,975 INFO:     Epoch: 58
2022-12-31 06:43:48,677 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3997737651069959, 'Total loss': 0.3997737651069959} | train loss {'Reaction outcome loss': 0.13660584148633612, 'Total loss': 0.13660584148633612}
2022-12-31 06:43:48,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:48,678 INFO:     Epoch: 59
2022-12-31 06:43:50,381 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3718546353280544, 'Total loss': 0.3718546353280544} | train loss {'Reaction outcome loss': 0.12935970785120168, 'Total loss': 0.12935970785120168}
2022-12-31 06:43:50,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:50,381 INFO:     Epoch: 60
2022-12-31 06:43:51,987 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4128674586613973, 'Total loss': 0.4128674586613973} | train loss {'Reaction outcome loss': 0.13106127417451896, 'Total loss': 0.13106127417451896}
2022-12-31 06:43:51,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:51,988 INFO:     Epoch: 61
2022-12-31 06:43:53,590 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3743530903942883, 'Total loss': 0.3743530903942883} | train loss {'Reaction outcome loss': 0.1312124600869368, 'Total loss': 0.1312124600869368}
2022-12-31 06:43:53,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:53,590 INFO:     Epoch: 62
2022-12-31 06:43:55,272 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4121632968386014, 'Total loss': 0.4121632968386014} | train loss {'Reaction outcome loss': 0.1310310337808488, 'Total loss': 0.1310310337808488}
2022-12-31 06:43:55,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:55,272 INFO:     Epoch: 63
2022-12-31 06:43:56,872 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36828941653172176, 'Total loss': 0.36828941653172176} | train loss {'Reaction outcome loss': 0.1289608634175944, 'Total loss': 0.1289608634175944}
2022-12-31 06:43:56,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:56,872 INFO:     Epoch: 64
2022-12-31 06:43:58,574 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39235934416453044, 'Total loss': 0.39235934416453044} | train loss {'Reaction outcome loss': 0.1259923963790466, 'Total loss': 0.1259923963790466}
2022-12-31 06:43:58,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:43:58,575 INFO:     Epoch: 65
2022-12-31 06:44:00,182 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4219683388868968, 'Total loss': 0.4219683388868968} | train loss {'Reaction outcome loss': 0.12491586178732224, 'Total loss': 0.12491586178732224}
2022-12-31 06:44:00,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:00,182 INFO:     Epoch: 66
2022-12-31 06:44:01,883 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3800791591405869, 'Total loss': 0.3800791591405869} | train loss {'Reaction outcome loss': 0.1246863618141702, 'Total loss': 0.1246863618141702}
2022-12-31 06:44:01,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:01,884 INFO:     Epoch: 67
2022-12-31 06:44:03,569 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38655764162540435, 'Total loss': 0.38655764162540435} | train loss {'Reaction outcome loss': 0.12523070201038933, 'Total loss': 0.12523070201038933}
2022-12-31 06:44:03,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:03,569 INFO:     Epoch: 68
2022-12-31 06:44:05,176 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42094222207864124, 'Total loss': 0.42094222207864124} | train loss {'Reaction outcome loss': 0.13013338818190953, 'Total loss': 0.13013338818190953}
2022-12-31 06:44:05,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:05,176 INFO:     Epoch: 69
2022-12-31 06:44:06,877 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39476533606648445, 'Total loss': 0.39476533606648445} | train loss {'Reaction outcome loss': 0.12915807931160303, 'Total loss': 0.12915807931160303}
2022-12-31 06:44:06,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:06,878 INFO:     Epoch: 70
2022-12-31 06:44:08,578 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39849973370631536, 'Total loss': 0.39849973370631536} | train loss {'Reaction outcome loss': 0.12126199292503434, 'Total loss': 0.12126199292503434}
2022-12-31 06:44:08,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:08,578 INFO:     Epoch: 71
2022-12-31 06:44:10,283 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41328472743431727, 'Total loss': 0.41328472743431727} | train loss {'Reaction outcome loss': 0.1233834962790402, 'Total loss': 0.1233834962790402}
2022-12-31 06:44:10,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:10,283 INFO:     Epoch: 72
2022-12-31 06:44:11,985 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4090498740474383, 'Total loss': 0.4090498740474383} | train loss {'Reaction outcome loss': 0.12523270849882193, 'Total loss': 0.12523270849882193}
2022-12-31 06:44:11,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:11,986 INFO:     Epoch: 73
2022-12-31 06:44:13,596 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39133484760920206, 'Total loss': 0.39133484760920206} | train loss {'Reaction outcome loss': 0.12142617172338137, 'Total loss': 0.12142617172338137}
2022-12-31 06:44:13,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:13,596 INFO:     Epoch: 74
2022-12-31 06:44:15,227 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3931075096130371, 'Total loss': 0.3931075096130371} | train loss {'Reaction outcome loss': 0.12436562552604646, 'Total loss': 0.12436562552604646}
2022-12-31 06:44:15,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:15,228 INFO:     Epoch: 75
2022-12-31 06:44:16,928 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41798556248346963, 'Total loss': 0.41798556248346963} | train loss {'Reaction outcome loss': 0.12293038376514892, 'Total loss': 0.12293038376514892}
2022-12-31 06:44:16,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:16,928 INFO:     Epoch: 76
2022-12-31 06:44:18,628 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4130203078190486, 'Total loss': 0.4130203078190486} | train loss {'Reaction outcome loss': 0.12122735337118853, 'Total loss': 0.12122735337118853}
2022-12-31 06:44:18,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:18,629 INFO:     Epoch: 77
2022-12-31 06:44:20,329 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4152911672989527, 'Total loss': 0.4152911672989527} | train loss {'Reaction outcome loss': 0.11709306518131042, 'Total loss': 0.11709306518131042}
2022-12-31 06:44:20,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:20,329 INFO:     Epoch: 78
2022-12-31 06:44:21,932 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3672909220059713, 'Total loss': 0.3672909220059713} | train loss {'Reaction outcome loss': 0.11888561202656656, 'Total loss': 0.11888561202656656}
2022-12-31 06:44:21,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:21,933 INFO:     Epoch: 79
2022-12-31 06:44:23,616 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41978535850842796, 'Total loss': 0.41978535850842796} | train loss {'Reaction outcome loss': 0.11956704991797988, 'Total loss': 0.11956704991797988}
2022-12-31 06:44:23,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:23,616 INFO:     Epoch: 80
2022-12-31 06:44:25,218 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40439899961153664, 'Total loss': 0.40439899961153664} | train loss {'Reaction outcome loss': 0.11698178794736472, 'Total loss': 0.11698178794736472}
2022-12-31 06:44:25,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:25,218 INFO:     Epoch: 81
2022-12-31 06:44:26,877 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4237463653087616, 'Total loss': 0.4237463653087616} | train loss {'Reaction outcome loss': 0.12259030837272276, 'Total loss': 0.12259030837272276}
2022-12-31 06:44:26,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:26,878 INFO:     Epoch: 82
2022-12-31 06:44:28,478 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3990988820791245, 'Total loss': 0.3990988820791245} | train loss {'Reaction outcome loss': 0.122721112752845, 'Total loss': 0.122721112752845}
2022-12-31 06:44:28,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:28,480 INFO:     Epoch: 83
2022-12-31 06:44:30,080 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4105691929658254, 'Total loss': 0.4105691929658254} | train loss {'Reaction outcome loss': 0.12142664946584993, 'Total loss': 0.12142664946584993}
2022-12-31 06:44:30,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:30,081 INFO:     Epoch: 84
2022-12-31 06:44:31,718 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3585331638654073, 'Total loss': 0.3585331638654073} | train loss {'Reaction outcome loss': 0.11412959066884858, 'Total loss': 0.11412959066884858}
2022-12-31 06:44:31,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:31,718 INFO:     Epoch: 85
2022-12-31 06:44:33,311 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4285300672054291, 'Total loss': 0.4285300672054291} | train loss {'Reaction outcome loss': 0.11721635049536497, 'Total loss': 0.11721635049536497}
2022-12-31 06:44:33,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:33,311 INFO:     Epoch: 86
2022-12-31 06:44:34,960 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40479055990775425, 'Total loss': 0.40479055990775425} | train loss {'Reaction outcome loss': 0.11972919536495219, 'Total loss': 0.11972919536495219}
2022-12-31 06:44:34,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:34,961 INFO:     Epoch: 87
2022-12-31 06:44:36,566 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.400588225821654, 'Total loss': 0.400588225821654} | train loss {'Reaction outcome loss': 0.1178748906434824, 'Total loss': 0.1178748906434824}
2022-12-31 06:44:36,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:36,566 INFO:     Epoch: 88
2022-12-31 06:44:38,215 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3845796634753545, 'Total loss': 0.3845796634753545} | train loss {'Reaction outcome loss': 0.11660392238415655, 'Total loss': 0.11660392238415655}
2022-12-31 06:44:38,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:38,215 INFO:     Epoch: 89
2022-12-31 06:44:39,864 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40158047477404274, 'Total loss': 0.40158047477404274} | train loss {'Reaction outcome loss': 0.11904136020853952, 'Total loss': 0.11904136020853952}
2022-12-31 06:44:39,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:39,864 INFO:     Epoch: 90
2022-12-31 06:44:41,487 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3906736562649409, 'Total loss': 0.3906736562649409} | train loss {'Reaction outcome loss': 0.11713822818814944, 'Total loss': 0.11713822818814944}
2022-12-31 06:44:41,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:41,487 INFO:     Epoch: 91
2022-12-31 06:44:43,084 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4204500784476598, 'Total loss': 0.4204500784476598} | train loss {'Reaction outcome loss': 0.11445749092219404, 'Total loss': 0.11445749092219404}
2022-12-31 06:44:43,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:43,085 INFO:     Epoch: 92
2022-12-31 06:44:44,689 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3929230650266012, 'Total loss': 0.3929230650266012} | train loss {'Reaction outcome loss': 0.11506153198194455, 'Total loss': 0.11506153198194455}
2022-12-31 06:44:44,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:44,689 INFO:     Epoch: 93
2022-12-31 06:44:46,296 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44461479087670647, 'Total loss': 0.44461479087670647} | train loss {'Reaction outcome loss': 0.11450312377530195, 'Total loss': 0.11450312377530195}
2022-12-31 06:44:46,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:46,296 INFO:     Epoch: 94
2022-12-31 06:44:47,899 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3823652279873689, 'Total loss': 0.3823652279873689} | train loss {'Reaction outcome loss': 0.11500344706542326, 'Total loss': 0.11500344706542326}
2022-12-31 06:44:47,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:47,900 INFO:     Epoch: 95
2022-12-31 06:44:49,542 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38677882626652715, 'Total loss': 0.38677882626652715} | train loss {'Reaction outcome loss': 0.11394633784644552, 'Total loss': 0.11394633784644552}
2022-12-31 06:44:49,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:49,542 INFO:     Epoch: 96
2022-12-31 06:44:51,150 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40656458934148154, 'Total loss': 0.40656458934148154} | train loss {'Reaction outcome loss': 0.11287245611172347, 'Total loss': 0.11287245611172347}
2022-12-31 06:44:51,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:51,150 INFO:     Epoch: 97
2022-12-31 06:44:52,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3954276685913404, 'Total loss': 0.3954276685913404} | train loss {'Reaction outcome loss': 0.11011900173136863, 'Total loss': 0.11011900173136863}
2022-12-31 06:44:52,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:52,789 INFO:     Epoch: 98
2022-12-31 06:44:54,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4127374948312839, 'Total loss': 0.4127374948312839} | train loss {'Reaction outcome loss': 0.1118942327019605, 'Total loss': 0.1118942327019605}
2022-12-31 06:44:54,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:54,439 INFO:     Epoch: 99
2022-12-31 06:44:56,088 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38928170800209044, 'Total loss': 0.38928170800209044} | train loss {'Reaction outcome loss': 0.10764572573075201, 'Total loss': 0.10764572573075201}
2022-12-31 06:44:56,088 INFO:     Best model found after epoch 23 of 100.
2022-12-31 06:44:56,088 INFO:   Done with stage: TRAINING
2022-12-31 06:44:56,088 INFO:   Starting stage: EVALUATION
2022-12-31 06:44:56,229 INFO:   Done with stage: EVALUATION
2022-12-31 06:44:56,229 INFO:   Leaving out SEQ value Fold_9
2022-12-31 06:44:56,242 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 06:44:56,242 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:44:56,890 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:44:56,890 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:44:56,962 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:44:56,962 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:44:56,962 INFO:     No hyperparam tuning for this model
2022-12-31 06:44:56,962 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:44:56,962 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:44:56,963 INFO:     None feature selector for col prot
2022-12-31 06:44:56,963 INFO:     None feature selector for col prot
2022-12-31 06:44:56,963 INFO:     None feature selector for col prot
2022-12-31 06:44:56,963 INFO:     None feature selector for col chem
2022-12-31 06:44:56,964 INFO:     None feature selector for col chem
2022-12-31 06:44:56,964 INFO:     None feature selector for col chem
2022-12-31 06:44:56,964 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:44:56,964 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:44:56,965 INFO:     Number of params in model 224011
2022-12-31 06:44:56,969 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:44:56,969 INFO:   Starting stage: TRAINING
2022-12-31 06:44:57,013 INFO:     Val loss before train {'Reaction outcome loss': 0.9647672375043234, 'Total loss': 0.9647672375043234}
2022-12-31 06:44:57,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:57,013 INFO:     Epoch: 0
2022-12-31 06:44:58,642 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5684706350167592, 'Total loss': 0.5684706350167592} | train loss {'Reaction outcome loss': 0.795308135960937, 'Total loss': 0.795308135960937}
2022-12-31 06:44:58,643 INFO:     Found new best model at epoch 0
2022-12-31 06:44:58,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:44:58,644 INFO:     Epoch: 1
2022-12-31 06:45:00,272 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47369609673817953, 'Total loss': 0.47369609673817953} | train loss {'Reaction outcome loss': 0.5250880491755069, 'Total loss': 0.5250880491755069}
2022-12-31 06:45:00,272 INFO:     Found new best model at epoch 1
2022-12-31 06:45:00,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:00,273 INFO:     Epoch: 2
2022-12-31 06:45:01,918 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4442275583744049, 'Total loss': 0.4442275583744049} | train loss {'Reaction outcome loss': 0.45397467228049404, 'Total loss': 0.45397467228049404}
2022-12-31 06:45:01,918 INFO:     Found new best model at epoch 2
2022-12-31 06:45:01,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:01,919 INFO:     Epoch: 3
2022-12-31 06:45:03,550 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4166256328423818, 'Total loss': 0.4166256328423818} | train loss {'Reaction outcome loss': 0.41216730226893716, 'Total loss': 0.41216730226893716}
2022-12-31 06:45:03,550 INFO:     Found new best model at epoch 3
2022-12-31 06:45:03,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:03,551 INFO:     Epoch: 4
2022-12-31 06:45:05,194 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.393967737754186, 'Total loss': 0.393967737754186} | train loss {'Reaction outcome loss': 0.3866410889134941, 'Total loss': 0.3866410889134941}
2022-12-31 06:45:05,195 INFO:     Found new best model at epoch 4
2022-12-31 06:45:05,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:05,196 INFO:     Epoch: 5
2022-12-31 06:45:06,866 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3745088865359624, 'Total loss': 0.3745088865359624} | train loss {'Reaction outcome loss': 0.3601245075087685, 'Total loss': 0.3601245075087685}
2022-12-31 06:45:06,866 INFO:     Found new best model at epoch 5
2022-12-31 06:45:06,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:06,867 INFO:     Epoch: 6
2022-12-31 06:45:08,491 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3885177344083786, 'Total loss': 0.3885177344083786} | train loss {'Reaction outcome loss': 0.34205835582923805, 'Total loss': 0.34205835582923805}
2022-12-31 06:45:08,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:08,491 INFO:     Epoch: 7
2022-12-31 06:45:10,124 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37217163244883217, 'Total loss': 0.37217163244883217} | train loss {'Reaction outcome loss': 0.3282796887660715, 'Total loss': 0.3282796887660715}
2022-12-31 06:45:10,124 INFO:     Found new best model at epoch 7
2022-12-31 06:45:10,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:10,125 INFO:     Epoch: 8
2022-12-31 06:45:11,754 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.36406168540318806, 'Total loss': 0.36406168540318806} | train loss {'Reaction outcome loss': 0.3123039897759899, 'Total loss': 0.3123039897759899}
2022-12-31 06:45:11,754 INFO:     Found new best model at epoch 8
2022-12-31 06:45:11,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:11,755 INFO:     Epoch: 9
2022-12-31 06:45:13,387 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3468902816375097, 'Total loss': 0.3468902816375097} | train loss {'Reaction outcome loss': 0.29782711887994395, 'Total loss': 0.29782711887994395}
2022-12-31 06:45:13,387 INFO:     Found new best model at epoch 9
2022-12-31 06:45:13,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:13,388 INFO:     Epoch: 10
2022-12-31 06:45:15,030 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3659940669933955, 'Total loss': 0.3659940669933955} | train loss {'Reaction outcome loss': 0.2862210870596046, 'Total loss': 0.2862210870596046}
2022-12-31 06:45:15,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:15,030 INFO:     Epoch: 11
2022-12-31 06:45:16,656 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3461373746395111, 'Total loss': 0.3461373746395111} | train loss {'Reaction outcome loss': 0.27752508966769984, 'Total loss': 0.27752508966769984}
2022-12-31 06:45:16,656 INFO:     Found new best model at epoch 11
2022-12-31 06:45:16,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:16,657 INFO:     Epoch: 12
2022-12-31 06:45:18,306 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3398520708084106, 'Total loss': 0.3398520708084106} | train loss {'Reaction outcome loss': 0.27084862314406716, 'Total loss': 0.27084862314406716}
2022-12-31 06:45:18,307 INFO:     Found new best model at epoch 12
2022-12-31 06:45:18,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:18,308 INFO:     Epoch: 13
2022-12-31 06:45:19,937 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.33779290815194446, 'Total loss': 0.33779290815194446} | train loss {'Reaction outcome loss': 0.26143044652921626, 'Total loss': 0.26143044652921626}
2022-12-31 06:45:19,937 INFO:     Found new best model at epoch 13
2022-12-31 06:45:19,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:19,938 INFO:     Epoch: 14
2022-12-31 06:45:21,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35737469295660657, 'Total loss': 0.35737469295660657} | train loss {'Reaction outcome loss': 0.24934441952660197, 'Total loss': 0.24934441952660197}
2022-12-31 06:45:21,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:21,566 INFO:     Epoch: 15
2022-12-31 06:45:23,238 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.354413104057312, 'Total loss': 0.354413104057312} | train loss {'Reaction outcome loss': 0.2436811540289261, 'Total loss': 0.2436811540289261}
2022-12-31 06:45:23,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:23,238 INFO:     Epoch: 16
2022-12-31 06:45:24,868 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.33899072209993997, 'Total loss': 0.33899072209993997} | train loss {'Reaction outcome loss': 0.23787378201039258, 'Total loss': 0.23787378201039258}
2022-12-31 06:45:24,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:24,868 INFO:     Epoch: 17
2022-12-31 06:45:26,502 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3556130568186442, 'Total loss': 0.3556130568186442} | train loss {'Reaction outcome loss': 0.2285401592374063, 'Total loss': 0.2285401592374063}
2022-12-31 06:45:26,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:26,502 INFO:     Epoch: 18
2022-12-31 06:45:28,142 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35926147202650704, 'Total loss': 0.35926147202650704} | train loss {'Reaction outcome loss': 0.22317754013282298, 'Total loss': 0.22317754013282298}
2022-12-31 06:45:28,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:28,143 INFO:     Epoch: 19
2022-12-31 06:45:29,812 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.33153400172789893, 'Total loss': 0.33153400172789893} | train loss {'Reaction outcome loss': 0.2186233580300739, 'Total loss': 0.2186233580300739}
2022-12-31 06:45:29,813 INFO:     Found new best model at epoch 19
2022-12-31 06:45:29,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:29,814 INFO:     Epoch: 20
2022-12-31 06:45:31,433 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.33406847417354585, 'Total loss': 0.33406847417354585} | train loss {'Reaction outcome loss': 0.21276395521815933, 'Total loss': 0.21276395521815933}
2022-12-31 06:45:31,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:31,433 INFO:     Epoch: 21
2022-12-31 06:45:33,100 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36221247017383573, 'Total loss': 0.36221247017383573} | train loss {'Reaction outcome loss': 0.20904759092370742, 'Total loss': 0.20904759092370742}
2022-12-31 06:45:33,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:33,101 INFO:     Epoch: 22
2022-12-31 06:45:34,722 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3463656504948934, 'Total loss': 0.3463656504948934} | train loss {'Reaction outcome loss': 0.20580102171453005, 'Total loss': 0.20580102171453005}
2022-12-31 06:45:34,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:34,723 INFO:     Epoch: 23
2022-12-31 06:45:36,339 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36499872207641604, 'Total loss': 0.36499872207641604} | train loss {'Reaction outcome loss': 0.201165838429321, 'Total loss': 0.201165838429321}
2022-12-31 06:45:36,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:36,340 INFO:     Epoch: 24
2022-12-31 06:45:37,958 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3832704265912374, 'Total loss': 0.3832704265912374} | train loss {'Reaction outcome loss': 0.19503031561440293, 'Total loss': 0.19503031561440293}
2022-12-31 06:45:37,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:37,958 INFO:     Epoch: 25
2022-12-31 06:45:39,587 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3413773794968923, 'Total loss': 0.3413773794968923} | train loss {'Reaction outcome loss': 0.19499711990221957, 'Total loss': 0.19499711990221957}
2022-12-31 06:45:39,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:39,587 INFO:     Epoch: 26
2022-12-31 06:45:41,260 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3542291780312856, 'Total loss': 0.3542291780312856} | train loss {'Reaction outcome loss': 0.1893312823807397, 'Total loss': 0.1893312823807397}
2022-12-31 06:45:41,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:41,260 INFO:     Epoch: 27
2022-12-31 06:45:42,887 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3523967981338501, 'Total loss': 0.3523967981338501} | train loss {'Reaction outcome loss': 0.18669978825086292, 'Total loss': 0.18669978825086292}
2022-12-31 06:45:42,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:42,887 INFO:     Epoch: 28
2022-12-31 06:45:44,532 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3638408660888672, 'Total loss': 0.3638408660888672} | train loss {'Reaction outcome loss': 0.18377651831652927, 'Total loss': 0.18377651831652927}
2022-12-31 06:45:44,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:44,533 INFO:     Epoch: 29
2022-12-31 06:45:46,161 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3430283909042676, 'Total loss': 0.3430283909042676} | train loss {'Reaction outcome loss': 0.17746380397155612, 'Total loss': 0.17746380397155612}
2022-12-31 06:45:46,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:46,161 INFO:     Epoch: 30
2022-12-31 06:45:47,780 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3452468951543172, 'Total loss': 0.3452468951543172} | train loss {'Reaction outcome loss': 0.1791859835130751, 'Total loss': 0.1791859835130751}
2022-12-31 06:45:47,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:47,780 INFO:     Epoch: 31
2022-12-31 06:45:49,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.32941808154185614, 'Total loss': 0.32941808154185614} | train loss {'Reaction outcome loss': 0.1764989973513228, 'Total loss': 0.1764989973513228}
2022-12-31 06:45:49,402 INFO:     Found new best model at epoch 31
2022-12-31 06:45:49,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:49,403 INFO:     Epoch: 32
2022-12-31 06:45:51,074 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34586822738250095, 'Total loss': 0.34586822738250095} | train loss {'Reaction outcome loss': 0.17389850953210562, 'Total loss': 0.17389850953210562}
2022-12-31 06:45:51,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:51,074 INFO:     Epoch: 33
2022-12-31 06:45:52,696 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3284848878781001, 'Total loss': 0.3284848878781001} | train loss {'Reaction outcome loss': 0.17056806515969525, 'Total loss': 0.17056806515969525}
2022-12-31 06:45:52,697 INFO:     Found new best model at epoch 33
2022-12-31 06:45:52,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:52,698 INFO:     Epoch: 34
2022-12-31 06:45:54,323 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3404221832752228, 'Total loss': 0.3404221832752228} | train loss {'Reaction outcome loss': 0.16716999650028425, 'Total loss': 0.16716999650028425}
2022-12-31 06:45:54,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:54,324 INFO:     Epoch: 35
2022-12-31 06:45:55,976 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34433233936627705, 'Total loss': 0.34433233936627705} | train loss {'Reaction outcome loss': 0.16463267113105645, 'Total loss': 0.16463267113105645}
2022-12-31 06:45:55,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:55,977 INFO:     Epoch: 36
2022-12-31 06:45:57,644 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38476110200087227, 'Total loss': 0.38476110200087227} | train loss {'Reaction outcome loss': 0.16687720524490096, 'Total loss': 0.16687720524490096}
2022-12-31 06:45:57,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:57,644 INFO:     Epoch: 37
2022-12-31 06:45:59,266 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3445462292060256, 'Total loss': 0.3445462292060256} | train loss {'Reaction outcome loss': 0.16401910321914762, 'Total loss': 0.16401910321914762}
2022-12-31 06:45:59,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:45:59,266 INFO:     Epoch: 38
2022-12-31 06:46:00,887 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3503434474269549, 'Total loss': 0.3503434474269549} | train loss {'Reaction outcome loss': 0.15846772137222415, 'Total loss': 0.15846772137222415}
2022-12-31 06:46:00,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:00,889 INFO:     Epoch: 39
2022-12-31 06:46:02,502 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3656959553559621, 'Total loss': 0.3656959553559621} | train loss {'Reaction outcome loss': 0.1602993179516134, 'Total loss': 0.1602993179516134}
2022-12-31 06:46:02,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:02,502 INFO:     Epoch: 40
2022-12-31 06:46:04,125 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3403989111383756, 'Total loss': 0.3403989111383756} | train loss {'Reaction outcome loss': 0.16294340130499824, 'Total loss': 0.16294340130499824}
2022-12-31 06:46:04,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:04,125 INFO:     Epoch: 41
2022-12-31 06:46:05,793 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37018480002880094, 'Total loss': 0.37018480002880094} | train loss {'Reaction outcome loss': 0.15694074711295025, 'Total loss': 0.15694074711295025}
2022-12-31 06:46:05,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:05,793 INFO:     Epoch: 42
2022-12-31 06:46:07,415 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3446546971797943, 'Total loss': 0.3446546971797943} | train loss {'Reaction outcome loss': 0.15393990603366375, 'Total loss': 0.15393990603366375}
2022-12-31 06:46:07,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:07,416 INFO:     Epoch: 43
2022-12-31 06:46:09,036 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34212022423744204, 'Total loss': 0.34212022423744204} | train loss {'Reaction outcome loss': 0.1513829109282485, 'Total loss': 0.1513829109282485}
2022-12-31 06:46:09,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:09,037 INFO:     Epoch: 44
2022-12-31 06:46:10,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3421770880619685, 'Total loss': 0.3421770880619685} | train loss {'Reaction outcome loss': 0.14959491221133336, 'Total loss': 0.14959491221133336}
2022-12-31 06:46:10,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:10,661 INFO:     Epoch: 45
2022-12-31 06:46:12,285 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3396723528703054, 'Total loss': 0.3396723528703054} | train loss {'Reaction outcome loss': 0.148368910842639, 'Total loss': 0.148368910842639}
2022-12-31 06:46:12,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:12,286 INFO:     Epoch: 46
2022-12-31 06:46:13,930 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3349331468343735, 'Total loss': 0.3349331468343735} | train loss {'Reaction outcome loss': 0.14730220498342322, 'Total loss': 0.14730220498342322}
2022-12-31 06:46:13,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:13,930 INFO:     Epoch: 47
2022-12-31 06:46:15,549 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3488565802574158, 'Total loss': 0.3488565802574158} | train loss {'Reaction outcome loss': 0.14844574072038494, 'Total loss': 0.14844574072038494}
2022-12-31 06:46:15,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:15,549 INFO:     Epoch: 48
2022-12-31 06:46:17,216 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35092580169439314, 'Total loss': 0.35092580169439314} | train loss {'Reaction outcome loss': 0.14891306073858743, 'Total loss': 0.14891306073858743}
2022-12-31 06:46:17,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:17,216 INFO:     Epoch: 49
2022-12-31 06:46:18,883 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34753585159778594, 'Total loss': 0.34753585159778594} | train loss {'Reaction outcome loss': 0.1436183060341202, 'Total loss': 0.1436183060341202}
2022-12-31 06:46:18,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:18,884 INFO:     Epoch: 50
2022-12-31 06:46:20,501 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3638698036472003, 'Total loss': 0.3638698036472003} | train loss {'Reaction outcome loss': 0.1420517411311611, 'Total loss': 0.1420517411311611}
2022-12-31 06:46:20,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:20,502 INFO:     Epoch: 51
2022-12-31 06:46:22,117 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3602132757504781, 'Total loss': 0.3602132757504781} | train loss {'Reaction outcome loss': 0.1405399909364026, 'Total loss': 0.1405399909364026}
2022-12-31 06:46:22,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:22,117 INFO:     Epoch: 52
2022-12-31 06:46:23,752 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3779248376687368, 'Total loss': 0.3779248376687368} | train loss {'Reaction outcome loss': 0.14281117849199887, 'Total loss': 0.14281117849199887}
2022-12-31 06:46:23,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:23,752 INFO:     Epoch: 53
2022-12-31 06:46:25,388 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38831258316834766, 'Total loss': 0.38831258316834766} | train loss {'Reaction outcome loss': 0.13641139195008128, 'Total loss': 0.13641139195008128}
2022-12-31 06:46:25,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:25,388 INFO:     Epoch: 54
2022-12-31 06:46:27,024 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3698599179585775, 'Total loss': 0.3698599179585775} | train loss {'Reaction outcome loss': 0.13885435905805132, 'Total loss': 0.13885435905805132}
2022-12-31 06:46:27,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:27,025 INFO:     Epoch: 55
2022-12-31 06:46:28,661 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34096251328786215, 'Total loss': 0.34096251328786215} | train loss {'Reaction outcome loss': 0.13815794294592437, 'Total loss': 0.13815794294592437}
2022-12-31 06:46:28,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:28,661 INFO:     Epoch: 56
2022-12-31 06:46:30,287 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34036840200424195, 'Total loss': 0.34036840200424195} | train loss {'Reaction outcome loss': 0.13690976401461483, 'Total loss': 0.13690976401461483}
2022-12-31 06:46:30,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:30,287 INFO:     Epoch: 57
2022-12-31 06:46:31,925 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3802981744209925, 'Total loss': 0.3802981744209925} | train loss {'Reaction outcome loss': 0.135321651027279, 'Total loss': 0.135321651027279}
2022-12-31 06:46:31,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:31,925 INFO:     Epoch: 58
2022-12-31 06:46:33,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37455733815828957, 'Total loss': 0.37455733815828957} | train loss {'Reaction outcome loss': 0.1400580351873022, 'Total loss': 0.1400580351873022}
2022-12-31 06:46:33,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:33,552 INFO:     Epoch: 59
2022-12-31 06:46:35,220 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37397310336430867, 'Total loss': 0.37397310336430867} | train loss {'Reaction outcome loss': 0.13201114667969543, 'Total loss': 0.13201114667969543}
2022-12-31 06:46:35,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:35,221 INFO:     Epoch: 60
2022-12-31 06:46:36,884 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.32666395008564, 'Total loss': 0.32666395008564} | train loss {'Reaction outcome loss': 0.13327063870740657, 'Total loss': 0.13327063870740657}
2022-12-31 06:46:36,885 INFO:     Found new best model at epoch 60
2022-12-31 06:46:36,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:36,886 INFO:     Epoch: 61
2022-12-31 06:46:38,554 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3303746908903122, 'Total loss': 0.3303746908903122} | train loss {'Reaction outcome loss': 0.13108273510340374, 'Total loss': 0.13108273510340374}
2022-12-31 06:46:38,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:38,554 INFO:     Epoch: 62
2022-12-31 06:46:40,184 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3408253381649653, 'Total loss': 0.3408253381649653} | train loss {'Reaction outcome loss': 0.1298319465827049, 'Total loss': 0.1298319465827049}
2022-12-31 06:46:40,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:40,184 INFO:     Epoch: 63
2022-12-31 06:46:41,804 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3427671164274216, 'Total loss': 0.3427671164274216} | train loss {'Reaction outcome loss': 0.1307954232289123, 'Total loss': 0.1307954232289123}
2022-12-31 06:46:41,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:41,804 INFO:     Epoch: 64
2022-12-31 06:46:43,433 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3497249980767568, 'Total loss': 0.3497249980767568} | train loss {'Reaction outcome loss': 0.13002888491000672, 'Total loss': 0.13002888491000672}
2022-12-31 06:46:43,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:43,434 INFO:     Epoch: 65
2022-12-31 06:46:45,057 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34335002998510994, 'Total loss': 0.34335002998510994} | train loss {'Reaction outcome loss': 0.13096932894029126, 'Total loss': 0.13096932894029126}
2022-12-31 06:46:45,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:45,058 INFO:     Epoch: 66
2022-12-31 06:46:46,728 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3281746675570806, 'Total loss': 0.3281746675570806} | train loss {'Reaction outcome loss': 0.12950910587832062, 'Total loss': 0.12950910587832062}
2022-12-31 06:46:46,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:46,728 INFO:     Epoch: 67
2022-12-31 06:46:48,377 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3409926061828931, 'Total loss': 0.3409926061828931} | train loss {'Reaction outcome loss': 0.12400613201358474, 'Total loss': 0.12400613201358474}
2022-12-31 06:46:48,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:48,377 INFO:     Epoch: 68
2022-12-31 06:46:49,998 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33965280950069426, 'Total loss': 0.33965280950069426} | train loss {'Reaction outcome loss': 0.128916198559213, 'Total loss': 0.128916198559213}
2022-12-31 06:46:49,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:49,998 INFO:     Epoch: 69
2022-12-31 06:46:51,623 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34250968048969904, 'Total loss': 0.34250968048969904} | train loss {'Reaction outcome loss': 0.12703545453927953, 'Total loss': 0.12703545453927953}
2022-12-31 06:46:51,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:51,623 INFO:     Epoch: 70
2022-12-31 06:46:53,248 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34752144739031793, 'Total loss': 0.34752144739031793} | train loss {'Reaction outcome loss': 0.12614378338135, 'Total loss': 0.12614378338135}
2022-12-31 06:46:53,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:53,248 INFO:     Epoch: 71
2022-12-31 06:46:54,872 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3612932433684667, 'Total loss': 0.3612932433684667} | train loss {'Reaction outcome loss': 0.12000618241004485, 'Total loss': 0.12000618241004485}
2022-12-31 06:46:54,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:54,873 INFO:     Epoch: 72
2022-12-31 06:46:56,543 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3614974816640218, 'Total loss': 0.3614974816640218} | train loss {'Reaction outcome loss': 0.12220432983361695, 'Total loss': 0.12220432983361695}
2022-12-31 06:46:56,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:56,544 INFO:     Epoch: 73
2022-12-31 06:46:58,158 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35201516648133596, 'Total loss': 0.35201516648133596} | train loss {'Reaction outcome loss': 0.12328164179436191, 'Total loss': 0.12328164179436191}
2022-12-31 06:46:58,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:58,158 INFO:     Epoch: 74
2022-12-31 06:46:59,783 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34197237094243366, 'Total loss': 0.34197237094243366} | train loss {'Reaction outcome loss': 0.12538351627261737, 'Total loss': 0.12538351627261737}
2022-12-31 06:46:59,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:46:59,783 INFO:     Epoch: 75
2022-12-31 06:47:01,407 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3198249604552984, 'Total loss': 0.3198249604552984} | train loss {'Reaction outcome loss': 0.12232245814680569, 'Total loss': 0.12232245814680569}
2022-12-31 06:47:01,408 INFO:     Found new best model at epoch 75
2022-12-31 06:47:01,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:01,409 INFO:     Epoch: 76
2022-12-31 06:47:03,032 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3314665246754885, 'Total loss': 0.3314665246754885} | train loss {'Reaction outcome loss': 0.12260125458260682, 'Total loss': 0.12260125458260682}
2022-12-31 06:47:03,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:03,032 INFO:     Epoch: 77
2022-12-31 06:47:04,656 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.352191457649072, 'Total loss': 0.352191457649072} | train loss {'Reaction outcome loss': 0.1170906789923618, 'Total loss': 0.1170906789923618}
2022-12-31 06:47:04,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:04,656 INFO:     Epoch: 78
2022-12-31 06:47:06,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3239944651722908, 'Total loss': 0.3239944651722908} | train loss {'Reaction outcome loss': 0.12030265355879434, 'Total loss': 0.12030265355879434}
2022-12-31 06:47:06,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:06,272 INFO:     Epoch: 79
2022-12-31 06:47:07,899 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33166575953364374, 'Total loss': 0.33166575953364374} | train loss {'Reaction outcome loss': 0.12257061113976614, 'Total loss': 0.12257061113976614}
2022-12-31 06:47:07,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:07,899 INFO:     Epoch: 80
2022-12-31 06:47:09,553 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35971224506696065, 'Total loss': 0.35971224506696065} | train loss {'Reaction outcome loss': 0.12420855278303908, 'Total loss': 0.12420855278303908}
2022-12-31 06:47:09,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:09,553 INFO:     Epoch: 81
2022-12-31 06:47:11,175 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3387237975994746, 'Total loss': 0.3387237975994746} | train loss {'Reaction outcome loss': 0.12134726683101499, 'Total loss': 0.12134726683101499}
2022-12-31 06:47:11,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:11,176 INFO:     Epoch: 82
2022-12-31 06:47:12,797 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3491238539417585, 'Total loss': 0.3491238539417585} | train loss {'Reaction outcome loss': 0.12108022430810796, 'Total loss': 0.12108022430810796}
2022-12-31 06:47:12,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:12,799 INFO:     Epoch: 83
2022-12-31 06:47:14,422 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34586893717447914, 'Total loss': 0.34586893717447914} | train loss {'Reaction outcome loss': 0.12033864701946774, 'Total loss': 0.12033864701946774}
2022-12-31 06:47:14,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:14,422 INFO:     Epoch: 84
2022-12-31 06:47:16,055 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.32848666521410147, 'Total loss': 0.32848666521410147} | train loss {'Reaction outcome loss': 0.11871354215331241, 'Total loss': 0.11871354215331241}
2022-12-31 06:47:16,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:16,055 INFO:     Epoch: 85
2022-12-31 06:47:17,681 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35514203359683355, 'Total loss': 0.35514203359683355} | train loss {'Reaction outcome loss': 0.12019531912967187, 'Total loss': 0.12019531912967187}
2022-12-31 06:47:17,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:17,681 INFO:     Epoch: 86
2022-12-31 06:47:19,302 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37070149183273315, 'Total loss': 0.37070149183273315} | train loss {'Reaction outcome loss': 0.11876505308882047, 'Total loss': 0.11876505308882047}
2022-12-31 06:47:19,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:19,303 INFO:     Epoch: 87
2022-12-31 06:47:20,922 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3817341903845469, 'Total loss': 0.3817341903845469} | train loss {'Reaction outcome loss': 0.12105823105994598, 'Total loss': 0.12105823105994598}
2022-12-31 06:47:20,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:20,923 INFO:     Epoch: 88
2022-12-31 06:47:22,545 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38809435764948524, 'Total loss': 0.38809435764948524} | train loss {'Reaction outcome loss': 0.11857412189971454, 'Total loss': 0.11857412189971454}
2022-12-31 06:47:22,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:22,546 INFO:     Epoch: 89
2022-12-31 06:47:24,166 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3681915242224932, 'Total loss': 0.3681915242224932} | train loss {'Reaction outcome loss': 0.1164366732064016, 'Total loss': 0.1164366732064016}
2022-12-31 06:47:24,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:24,166 INFO:     Epoch: 90
2022-12-31 06:47:25,780 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33812098304430643, 'Total loss': 0.33812098304430643} | train loss {'Reaction outcome loss': 0.11709543352859222, 'Total loss': 0.11709543352859222}
2022-12-31 06:47:25,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:25,780 INFO:     Epoch: 91
2022-12-31 06:47:26,909 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3496337672074636, 'Total loss': 0.3496337672074636} | train loss {'Reaction outcome loss': 0.11297257222396587, 'Total loss': 0.11297257222396587}
2022-12-31 06:47:26,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:26,909 INFO:     Epoch: 92
2022-12-31 06:47:28,026 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3614822159210841, 'Total loss': 0.3614822159210841} | train loss {'Reaction outcome loss': 0.11516623252108424, 'Total loss': 0.11516623252108424}
2022-12-31 06:47:28,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:28,026 INFO:     Epoch: 93
2022-12-31 06:47:29,140 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3889071896672249, 'Total loss': 0.3889071896672249} | train loss {'Reaction outcome loss': 0.1171830237165618, 'Total loss': 0.1171830237165618}
2022-12-31 06:47:29,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:29,140 INFO:     Epoch: 94
2022-12-31 06:47:30,253 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36784707605838773, 'Total loss': 0.36784707605838773} | train loss {'Reaction outcome loss': 0.11915247570151725, 'Total loss': 0.11915247570151725}
2022-12-31 06:47:30,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:30,253 INFO:     Epoch: 95
2022-12-31 06:47:31,878 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37066399256388344, 'Total loss': 0.37066399256388344} | train loss {'Reaction outcome loss': 0.1163741365488659, 'Total loss': 0.1163741365488659}
2022-12-31 06:47:31,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:31,879 INFO:     Epoch: 96
2022-12-31 06:47:33,499 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3436283538738886, 'Total loss': 0.3436283538738886} | train loss {'Reaction outcome loss': 0.11439304182386624, 'Total loss': 0.11439304182386624}
2022-12-31 06:47:33,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:33,500 INFO:     Epoch: 97
2022-12-31 06:47:35,167 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3444840600093206, 'Total loss': 0.3444840600093206} | train loss {'Reaction outcome loss': 0.11471842707467639, 'Total loss': 0.11471842707467639}
2022-12-31 06:47:35,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:35,167 INFO:     Epoch: 98
2022-12-31 06:47:36,835 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3176899602015813, 'Total loss': 0.3176899602015813} | train loss {'Reaction outcome loss': 0.11011794956891868, 'Total loss': 0.11011794956891868}
2022-12-31 06:47:36,835 INFO:     Found new best model at epoch 98
2022-12-31 06:47:36,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:36,836 INFO:     Epoch: 99
2022-12-31 06:47:38,460 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3601458887259165, 'Total loss': 0.3601458887259165} | train loss {'Reaction outcome loss': 0.1124149588254425, 'Total loss': 0.1124149588254425}
2022-12-31 06:47:38,460 INFO:     Best model found after epoch 99 of 100.
2022-12-31 06:47:38,460 INFO:   Done with stage: TRAINING
2022-12-31 06:47:38,460 INFO:   Starting stage: EVALUATION
2022-12-31 06:47:38,582 INFO:   Done with stage: EVALUATION
2022-12-31 06:47:38,591 INFO:   Leaving out SEQ value Fold_0
2022-12-31 06:47:38,604 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:47:38,604 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:47:39,261 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:47:39,261 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:47:39,331 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:47:39,331 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:47:39,331 INFO:     No hyperparam tuning for this model
2022-12-31 06:47:39,331 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:47:39,331 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:47:39,332 INFO:     None feature selector for col prot
2022-12-31 06:47:39,332 INFO:     None feature selector for col prot
2022-12-31 06:47:39,332 INFO:     None feature selector for col prot
2022-12-31 06:47:39,333 INFO:     None feature selector for col chem
2022-12-31 06:47:39,333 INFO:     None feature selector for col chem
2022-12-31 06:47:39,334 INFO:     None feature selector for col chem
2022-12-31 06:47:39,334 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:47:39,334 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:47:39,336 INFO:     Number of params in model 224011
2022-12-31 06:47:39,339 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:47:39,339 INFO:   Starting stage: TRAINING
2022-12-31 06:47:39,383 INFO:     Val loss before train {'Reaction outcome loss': 0.9538452625274658, 'Total loss': 0.9538452625274658}
2022-12-31 06:47:39,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:39,383 INFO:     Epoch: 0
2022-12-31 06:47:40,998 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5308313548564911, 'Total loss': 0.5308313548564911} | train loss {'Reaction outcome loss': 0.7744910090729811, 'Total loss': 0.7744910090729811}
2022-12-31 06:47:40,998 INFO:     Found new best model at epoch 0
2022-12-31 06:47:40,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:40,999 INFO:     Epoch: 1
2022-12-31 06:47:42,674 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4699804941813151, 'Total loss': 0.4699804941813151} | train loss {'Reaction outcome loss': 0.5206286462860695, 'Total loss': 0.5206286462860695}
2022-12-31 06:47:42,674 INFO:     Found new best model at epoch 1
2022-12-31 06:47:42,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:42,675 INFO:     Epoch: 2
2022-12-31 06:47:44,288 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4555356204509735, 'Total loss': 0.4555356204509735} | train loss {'Reaction outcome loss': 0.4544505939095119, 'Total loss': 0.4544505939095119}
2022-12-31 06:47:44,288 INFO:     Found new best model at epoch 2
2022-12-31 06:47:44,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:44,289 INFO:     Epoch: 3
2022-12-31 06:47:45,904 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3984244947632154, 'Total loss': 0.3984244947632154} | train loss {'Reaction outcome loss': 0.41129957954736723, 'Total loss': 0.41129957954736723}
2022-12-31 06:47:45,904 INFO:     Found new best model at epoch 3
2022-12-31 06:47:45,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:45,905 INFO:     Epoch: 4
2022-12-31 06:47:47,520 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4255024621884028, 'Total loss': 0.4255024621884028} | train loss {'Reaction outcome loss': 0.38456188782246487, 'Total loss': 0.38456188782246487}
2022-12-31 06:47:47,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:47,521 INFO:     Epoch: 5
2022-12-31 06:47:49,129 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3782203545173009, 'Total loss': 0.3782203545173009} | train loss {'Reaction outcome loss': 0.35416845812374115, 'Total loss': 0.35416845812374115}
2022-12-31 06:47:49,129 INFO:     Found new best model at epoch 5
2022-12-31 06:47:49,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:49,130 INFO:     Epoch: 6
2022-12-31 06:47:50,749 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.385206738114357, 'Total loss': 0.385206738114357} | train loss {'Reaction outcome loss': 0.3397331302040729, 'Total loss': 0.3397331302040729}
2022-12-31 06:47:50,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:50,749 INFO:     Epoch: 7
2022-12-31 06:47:52,365 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37707268198331195, 'Total loss': 0.37707268198331195} | train loss {'Reaction outcome loss': 0.31622650206807756, 'Total loss': 0.31622650206807756}
2022-12-31 06:47:52,365 INFO:     Found new best model at epoch 7
2022-12-31 06:47:52,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:52,366 INFO:     Epoch: 8
2022-12-31 06:47:53,979 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3909341832002004, 'Total loss': 0.3909341832002004} | train loss {'Reaction outcome loss': 0.3034327983842704, 'Total loss': 0.3034327983842704}
2022-12-31 06:47:53,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:53,980 INFO:     Epoch: 9
2022-12-31 06:47:55,592 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3697689491013686, 'Total loss': 0.3697689491013686} | train loss {'Reaction outcome loss': 0.28774816696059663, 'Total loss': 0.28774816696059663}
2022-12-31 06:47:55,592 INFO:     Found new best model at epoch 9
2022-12-31 06:47:55,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:55,593 INFO:     Epoch: 10
2022-12-31 06:47:57,203 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.36652148167292276, 'Total loss': 0.36652148167292276} | train loss {'Reaction outcome loss': 0.276743669141623, 'Total loss': 0.276743669141623}
2022-12-31 06:47:57,204 INFO:     Found new best model at epoch 10
2022-12-31 06:47:57,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:57,205 INFO:     Epoch: 11
2022-12-31 06:47:58,815 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3733024924993515, 'Total loss': 0.3733024924993515} | train loss {'Reaction outcome loss': 0.26024524028711626, 'Total loss': 0.26024524028711626}
2022-12-31 06:47:58,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:47:58,815 INFO:     Epoch: 12
2022-12-31 06:48:00,485 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40455519954363506, 'Total loss': 0.40455519954363506} | train loss {'Reaction outcome loss': 0.280430778834051, 'Total loss': 0.280430778834051}
2022-12-31 06:48:00,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:00,485 INFO:     Epoch: 13
2022-12-31 06:48:02,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38103744586308796, 'Total loss': 0.38103744586308796} | train loss {'Reaction outcome loss': 0.2490331324751542, 'Total loss': 0.2490331324751542}
2022-12-31 06:48:02,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:02,117 INFO:     Epoch: 14
2022-12-31 06:48:03,749 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4043180932601293, 'Total loss': 0.4043180932601293} | train loss {'Reaction outcome loss': 0.23719547485318576, 'Total loss': 0.23719547485318576}
2022-12-31 06:48:03,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:03,749 INFO:     Epoch: 15
2022-12-31 06:48:05,376 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38785250385602316, 'Total loss': 0.38785250385602316} | train loss {'Reaction outcome loss': 0.22952868960345624, 'Total loss': 0.22952868960345624}
2022-12-31 06:48:05,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:05,376 INFO:     Epoch: 16
2022-12-31 06:48:07,014 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3742017149925232, 'Total loss': 0.3742017149925232} | train loss {'Reaction outcome loss': 0.22375551122325082, 'Total loss': 0.22375551122325082}
2022-12-31 06:48:07,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:07,015 INFO:     Epoch: 17
2022-12-31 06:48:08,639 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3583407426873843, 'Total loss': 0.3583407426873843} | train loss {'Reaction outcome loss': 0.21512747651338915, 'Total loss': 0.21512747651338915}
2022-12-31 06:48:08,639 INFO:     Found new best model at epoch 17
2022-12-31 06:48:08,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:08,640 INFO:     Epoch: 18
2022-12-31 06:48:10,269 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4023940364519755, 'Total loss': 0.4023940364519755} | train loss {'Reaction outcome loss': 0.21297267375031378, 'Total loss': 0.21297267375031378}
2022-12-31 06:48:10,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:10,269 INFO:     Epoch: 19
2022-12-31 06:48:11,900 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36927841007709505, 'Total loss': 0.36927841007709505} | train loss {'Reaction outcome loss': 0.20399166247470008, 'Total loss': 0.20399166247470008}
2022-12-31 06:48:11,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:11,901 INFO:     Epoch: 20
2022-12-31 06:48:13,530 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3560411068300406, 'Total loss': 0.3560411068300406} | train loss {'Reaction outcome loss': 0.22384161990729795, 'Total loss': 0.22384161990729795}
2022-12-31 06:48:13,530 INFO:     Found new best model at epoch 20
2022-12-31 06:48:13,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:13,532 INFO:     Epoch: 21
2022-12-31 06:48:15,154 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3783192167679469, 'Total loss': 0.3783192167679469} | train loss {'Reaction outcome loss': 0.20950186665784026, 'Total loss': 0.20950186665784026}
2022-12-31 06:48:15,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:15,154 INFO:     Epoch: 22
2022-12-31 06:48:16,773 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3715914765993754, 'Total loss': 0.3715914765993754} | train loss {'Reaction outcome loss': 0.1945753870194481, 'Total loss': 0.1945753870194481}
2022-12-31 06:48:16,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:16,773 INFO:     Epoch: 23
2022-12-31 06:48:18,398 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3714001998305321, 'Total loss': 0.3714001998305321} | train loss {'Reaction outcome loss': 0.1883434424374212, 'Total loss': 0.1883434424374212}
2022-12-31 06:48:18,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:18,398 INFO:     Epoch: 24
2022-12-31 06:48:20,030 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36175234417120616, 'Total loss': 0.36175234417120616} | train loss {'Reaction outcome loss': 0.18223611064343498, 'Total loss': 0.18223611064343498}
2022-12-31 06:48:20,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:20,030 INFO:     Epoch: 25
2022-12-31 06:48:21,668 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3839199523131053, 'Total loss': 0.3839199523131053} | train loss {'Reaction outcome loss': 0.17761602763346382, 'Total loss': 0.17761602763346382}
2022-12-31 06:48:21,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:21,668 INFO:     Epoch: 26
2022-12-31 06:48:23,303 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39402322272459667, 'Total loss': 0.39402322272459667} | train loss {'Reaction outcome loss': 0.17530182919184933, 'Total loss': 0.17530182919184933}
2022-12-31 06:48:23,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:23,305 INFO:     Epoch: 27
2022-12-31 06:48:24,919 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3692739168802897, 'Total loss': 0.3692739168802897} | train loss {'Reaction outcome loss': 0.1722415985970946, 'Total loss': 0.1722415985970946}
2022-12-31 06:48:24,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:24,919 INFO:     Epoch: 28
2022-12-31 06:48:26,549 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4075952351093292, 'Total loss': 0.4075952351093292} | train loss {'Reaction outcome loss': 0.16841936438425403, 'Total loss': 0.16841936438425403}
2022-12-31 06:48:26,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:26,549 INFO:     Epoch: 29
2022-12-31 06:48:28,195 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4135980357726415, 'Total loss': 0.4135980357726415} | train loss {'Reaction outcome loss': 0.1859722795754509, 'Total loss': 0.1859722795754509}
2022-12-31 06:48:28,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:28,196 INFO:     Epoch: 30
2022-12-31 06:48:29,847 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4457270473241806, 'Total loss': 0.4457270473241806} | train loss {'Reaction outcome loss': 0.16562886655995407, 'Total loss': 0.16562886655995407}
2022-12-31 06:48:29,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:29,847 INFO:     Epoch: 31
2022-12-31 06:48:31,486 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38073785495944323, 'Total loss': 0.38073785495944323} | train loss {'Reaction outcome loss': 0.15790420477160427, 'Total loss': 0.15790420477160427}
2022-12-31 06:48:31,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:31,486 INFO:     Epoch: 32
2022-12-31 06:48:33,140 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4068158487478892, 'Total loss': 0.4068158487478892} | train loss {'Reaction outcome loss': 0.15987706385836328, 'Total loss': 0.15987706385836328}
2022-12-31 06:48:33,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:33,140 INFO:     Epoch: 33
2022-12-31 06:48:34,776 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4057491679986318, 'Total loss': 0.4057491679986318} | train loss {'Reaction outcome loss': 0.15754473255103643, 'Total loss': 0.15754473255103643}
2022-12-31 06:48:34,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:34,776 INFO:     Epoch: 34
2022-12-31 06:48:36,393 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3891316741704941, 'Total loss': 0.3891316741704941} | train loss {'Reaction outcome loss': 0.15709852312516043, 'Total loss': 0.15709852312516043}
2022-12-31 06:48:36,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:36,394 INFO:     Epoch: 35
2022-12-31 06:48:38,007 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42986317177613576, 'Total loss': 0.42986317177613576} | train loss {'Reaction outcome loss': 0.19269869139674667, 'Total loss': 0.19269869139674667}
2022-12-31 06:48:38,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:38,008 INFO:     Epoch: 36
2022-12-31 06:48:39,626 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4319026112556458, 'Total loss': 0.4319026112556458} | train loss {'Reaction outcome loss': 0.1587532222257468, 'Total loss': 0.1587532222257468}
2022-12-31 06:48:39,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:39,626 INFO:     Epoch: 37
2022-12-31 06:48:41,250 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40477626423041024, 'Total loss': 0.40477626423041024} | train loss {'Reaction outcome loss': 0.16707954723286725, 'Total loss': 0.16707954723286725}
2022-12-31 06:48:41,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:41,250 INFO:     Epoch: 38
2022-12-31 06:48:42,882 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37184615681568783, 'Total loss': 0.37184615681568783} | train loss {'Reaction outcome loss': 0.18675697851332201, 'Total loss': 0.18675697851332201}
2022-12-31 06:48:42,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:42,883 INFO:     Epoch: 39
2022-12-31 06:48:44,528 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41159833818674085, 'Total loss': 0.41159833818674085} | train loss {'Reaction outcome loss': 0.15841254215244946, 'Total loss': 0.15841254215244946}
2022-12-31 06:48:44,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:44,528 INFO:     Epoch: 40
2022-12-31 06:48:46,166 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3890050639708837, 'Total loss': 0.3890050639708837} | train loss {'Reaction outcome loss': 0.1443924540097056, 'Total loss': 0.1443924540097056}
2022-12-31 06:48:46,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:46,166 INFO:     Epoch: 41
2022-12-31 06:48:47,810 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38697853485743205, 'Total loss': 0.38697853485743205} | train loss {'Reaction outcome loss': 0.14573709641421295, 'Total loss': 0.14573709641421295}
2022-12-31 06:48:47,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:47,810 INFO:     Epoch: 42
2022-12-31 06:48:49,447 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4018490642309189, 'Total loss': 0.4018490642309189} | train loss {'Reaction outcome loss': 0.13895398068732745, 'Total loss': 0.13895398068732745}
2022-12-31 06:48:49,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:49,447 INFO:     Epoch: 43
2022-12-31 06:48:51,070 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3946342887977759, 'Total loss': 0.3946342887977759} | train loss {'Reaction outcome loss': 0.13569609275101105, 'Total loss': 0.13569609275101105}
2022-12-31 06:48:51,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:51,070 INFO:     Epoch: 44
2022-12-31 06:48:52,707 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4006723349293073, 'Total loss': 0.4006723349293073} | train loss {'Reaction outcome loss': 0.1358599241492271, 'Total loss': 0.1358599241492271}
2022-12-31 06:48:52,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:52,708 INFO:     Epoch: 45
2022-12-31 06:48:54,329 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40972470392783483, 'Total loss': 0.40972470392783483} | train loss {'Reaction outcome loss': 0.13968230171111287, 'Total loss': 0.13968230171111287}
2022-12-31 06:48:54,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:54,329 INFO:     Epoch: 46
2022-12-31 06:48:55,958 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37778073151906333, 'Total loss': 0.37778073151906333} | train loss {'Reaction outcome loss': 0.13899450439899025, 'Total loss': 0.13899450439899025}
2022-12-31 06:48:55,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:55,958 INFO:     Epoch: 47
2022-12-31 06:48:57,585 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4112380340695381, 'Total loss': 0.4112380340695381} | train loss {'Reaction outcome loss': 0.1355068784954631, 'Total loss': 0.1355068784954631}
2022-12-31 06:48:57,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:57,586 INFO:     Epoch: 48
2022-12-31 06:48:59,211 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38887949685255685, 'Total loss': 0.38887949685255685} | train loss {'Reaction outcome loss': 0.13680519739105163, 'Total loss': 0.13680519739105163}
2022-12-31 06:48:59,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:48:59,213 INFO:     Epoch: 49
2022-12-31 06:49:00,842 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3996020962794622, 'Total loss': 0.3996020962794622} | train loss {'Reaction outcome loss': 0.13456521163986865, 'Total loss': 0.13456521163986865}
2022-12-31 06:49:00,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:00,842 INFO:     Epoch: 50
2022-12-31 06:49:02,465 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4123790949583054, 'Total loss': 0.4123790949583054} | train loss {'Reaction outcome loss': 0.13473285693317597, 'Total loss': 0.13473285693317597}
2022-12-31 06:49:02,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:02,465 INFO:     Epoch: 51
2022-12-31 06:49:04,088 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41354631185531615, 'Total loss': 0.41354631185531615} | train loss {'Reaction outcome loss': 0.1340576518107981, 'Total loss': 0.1340576518107981}
2022-12-31 06:49:04,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:04,088 INFO:     Epoch: 52
2022-12-31 06:49:05,721 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45202184120814004, 'Total loss': 0.45202184120814004} | train loss {'Reaction outcome loss': 0.13168252832627436, 'Total loss': 0.13168252832627436}
2022-12-31 06:49:05,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:05,722 INFO:     Epoch: 53
2022-12-31 06:49:07,348 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4142576942841212, 'Total loss': 0.4142576942841212} | train loss {'Reaction outcome loss': 0.13446084077841605, 'Total loss': 0.13446084077841605}
2022-12-31 06:49:07,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:07,348 INFO:     Epoch: 54
2022-12-31 06:49:09,010 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4696948528289795, 'Total loss': 0.4696948528289795} | train loss {'Reaction outcome loss': 0.13337791150442554, 'Total loss': 0.13337791150442554}
2022-12-31 06:49:09,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:09,010 INFO:     Epoch: 55
2022-12-31 06:49:10,644 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41842766205469767, 'Total loss': 0.41842766205469767} | train loss {'Reaction outcome loss': 0.13468135746054188, 'Total loss': 0.13468135746054188}
2022-12-31 06:49:10,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:10,644 INFO:     Epoch: 56
2022-12-31 06:49:12,270 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4210039714972178, 'Total loss': 0.4210039714972178} | train loss {'Reaction outcome loss': 0.1560215967491377, 'Total loss': 0.1560215967491377}
2022-12-31 06:49:12,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:12,270 INFO:     Epoch: 57
2022-12-31 06:49:13,933 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42893566687901813, 'Total loss': 0.42893566687901813} | train loss {'Reaction outcome loss': 0.13559885946833478, 'Total loss': 0.13559885946833478}
2022-12-31 06:49:13,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:13,933 INFO:     Epoch: 58
2022-12-31 06:49:15,559 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4159117708603541, 'Total loss': 0.4159117708603541} | train loss {'Reaction outcome loss': 0.1268590608868154, 'Total loss': 0.1268590608868154}
2022-12-31 06:49:15,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:15,559 INFO:     Epoch: 59
2022-12-31 06:49:17,221 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4411423017581304, 'Total loss': 0.4411423017581304} | train loss {'Reaction outcome loss': 0.12932455378395916, 'Total loss': 0.12932455378395916}
2022-12-31 06:49:17,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:17,221 INFO:     Epoch: 60
2022-12-31 06:49:18,843 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4292152057091395, 'Total loss': 0.4292152057091395} | train loss {'Reaction outcome loss': 0.13485408642842178, 'Total loss': 0.13485408642842178}
2022-12-31 06:49:18,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:18,844 INFO:     Epoch: 61
2022-12-31 06:49:20,470 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4389045387506485, 'Total loss': 0.4389045387506485} | train loss {'Reaction outcome loss': 0.1563454237433346, 'Total loss': 0.1563454237433346}
2022-12-31 06:49:20,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:20,470 INFO:     Epoch: 62
2022-12-31 06:49:22,099 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4527864674727122, 'Total loss': 0.4527864674727122} | train loss {'Reaction outcome loss': 0.13072408556405024, 'Total loss': 0.13072408556405024}
2022-12-31 06:49:22,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:22,100 INFO:     Epoch: 63
2022-12-31 06:49:23,734 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40687034875154493, 'Total loss': 0.40687034875154493} | train loss {'Reaction outcome loss': 0.12855911855518387, 'Total loss': 0.12855911855518387}
2022-12-31 06:49:23,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:23,734 INFO:     Epoch: 64
2022-12-31 06:49:25,366 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4225072721640269, 'Total loss': 0.4225072721640269} | train loss {'Reaction outcome loss': 0.13586772190562138, 'Total loss': 0.13586772190562138}
2022-12-31 06:49:25,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:25,367 INFO:     Epoch: 65
2022-12-31 06:49:27,001 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4222917914390564, 'Total loss': 0.4222917914390564} | train loss {'Reaction outcome loss': 0.12277130475137012, 'Total loss': 0.12277130475137012}
2022-12-31 06:49:27,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:27,001 INFO:     Epoch: 66
2022-12-31 06:49:28,625 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43757574359575907, 'Total loss': 0.43757574359575907} | train loss {'Reaction outcome loss': 0.12149956231123592, 'Total loss': 0.12149956231123592}
2022-12-31 06:49:28,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:28,625 INFO:     Epoch: 67
2022-12-31 06:49:30,242 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4515533397595088, 'Total loss': 0.4515533397595088} | train loss {'Reaction outcome loss': 0.12286505095940758, 'Total loss': 0.12286505095940758}
2022-12-31 06:49:30,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:30,242 INFO:     Epoch: 68
2022-12-31 06:49:31,867 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4393984456857046, 'Total loss': 0.4393984456857046} | train loss {'Reaction outcome loss': 0.11841592170379084, 'Total loss': 0.11841592170379084}
2022-12-31 06:49:31,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:31,867 INFO:     Epoch: 69
2022-12-31 06:49:33,491 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4270836045344671, 'Total loss': 0.4270836045344671} | train loss {'Reaction outcome loss': 0.12131731746384226, 'Total loss': 0.12131731746384226}
2022-12-31 06:49:33,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:33,492 INFO:     Epoch: 70
2022-12-31 06:49:35,115 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41972612142562865, 'Total loss': 0.41972612142562865} | train loss {'Reaction outcome loss': 0.12482373495565655, 'Total loss': 0.12482373495565655}
2022-12-31 06:49:35,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:35,117 INFO:     Epoch: 71
2022-12-31 06:49:36,740 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41059523622194927, 'Total loss': 0.41059523622194927} | train loss {'Reaction outcome loss': 0.12072929088455989, 'Total loss': 0.12072929088455989}
2022-12-31 06:49:36,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:36,740 INFO:     Epoch: 72
2022-12-31 06:49:38,352 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.387280224232624, 'Total loss': 0.387280224232624} | train loss {'Reaction outcome loss': 0.12072742592705332, 'Total loss': 0.12072742592705332}
2022-12-31 06:49:38,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:38,353 INFO:     Epoch: 73
2022-12-31 06:49:39,965 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41474875851223864, 'Total loss': 0.41474875851223864} | train loss {'Reaction outcome loss': 0.14320124101831808, 'Total loss': 0.14320124101831808}
2022-12-31 06:49:39,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:39,965 INFO:     Epoch: 74
2022-12-31 06:49:41,584 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4296614915132523, 'Total loss': 0.4296614915132523} | train loss {'Reaction outcome loss': 0.12939222318758423, 'Total loss': 0.12939222318758423}
2022-12-31 06:49:41,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:41,585 INFO:     Epoch: 75
2022-12-31 06:49:43,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43739693562189735, 'Total loss': 0.43739693562189735} | train loss {'Reaction outcome loss': 0.11922314642604602, 'Total loss': 0.11922314642604602}
2022-12-31 06:49:43,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:43,201 INFO:     Epoch: 76
2022-12-31 06:49:44,814 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42242838243643444, 'Total loss': 0.42242838243643444} | train loss {'Reaction outcome loss': 0.11394096651047617, 'Total loss': 0.11394096651047617}
2022-12-31 06:49:44,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:44,815 INFO:     Epoch: 77
2022-12-31 06:49:46,429 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4345407356818517, 'Total loss': 0.4345407356818517} | train loss {'Reaction outcome loss': 0.11781232663317655, 'Total loss': 0.11781232663317655}
2022-12-31 06:49:46,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:46,429 INFO:     Epoch: 78
2022-12-31 06:49:48,036 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4384039988120397, 'Total loss': 0.4384039988120397} | train loss {'Reaction outcome loss': 0.11524244960057094, 'Total loss': 0.11524244960057094}
2022-12-31 06:49:48,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:48,036 INFO:     Epoch: 79
2022-12-31 06:49:49,665 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4337419966856639, 'Total loss': 0.4337419966856639} | train loss {'Reaction outcome loss': 0.11640752976898616, 'Total loss': 0.11640752976898616}
2022-12-31 06:49:49,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:49,665 INFO:     Epoch: 80
2022-12-31 06:49:51,295 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40086362808942794, 'Total loss': 0.40086362808942794} | train loss {'Reaction outcome loss': 0.1179981081195233, 'Total loss': 0.1179981081195233}
2022-12-31 06:49:51,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:51,295 INFO:     Epoch: 81
2022-12-31 06:49:52,918 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43664070864518484, 'Total loss': 0.43664070864518484} | train loss {'Reaction outcome loss': 0.11859351921990258, 'Total loss': 0.11859351921990258}
2022-12-31 06:49:52,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:52,918 INFO:     Epoch: 82
2022-12-31 06:49:54,547 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46944896280765536, 'Total loss': 0.46944896280765536} | train loss {'Reaction outcome loss': 0.11631752162044733, 'Total loss': 0.11631752162044733}
2022-12-31 06:49:54,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:54,548 INFO:     Epoch: 83
2022-12-31 06:49:56,167 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41058940887451173, 'Total loss': 0.41058940887451173} | train loss {'Reaction outcome loss': 0.1290390472572324, 'Total loss': 0.1290390472572324}
2022-12-31 06:49:56,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:56,167 INFO:     Epoch: 84
2022-12-31 06:49:57,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4127059658368429, 'Total loss': 0.4127059658368429} | train loss {'Reaction outcome loss': 0.13162184210807976, 'Total loss': 0.13162184210807976}
2022-12-31 06:49:57,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:57,784 INFO:     Epoch: 85
2022-12-31 06:49:59,412 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4083309193452199, 'Total loss': 0.4083309193452199} | train loss {'Reaction outcome loss': 0.11387265751313796, 'Total loss': 0.11387265751313796}
2022-12-31 06:49:59,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:49:59,412 INFO:     Epoch: 86
2022-12-31 06:50:01,037 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45248739860641457, 'Total loss': 0.45248739860641457} | train loss {'Reaction outcome loss': 0.11404078812346848, 'Total loss': 0.11404078812346848}
2022-12-31 06:50:01,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:01,037 INFO:     Epoch: 87
2022-12-31 06:50:02,661 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4327653040488561, 'Total loss': 0.4327653040488561} | train loss {'Reaction outcome loss': 0.11659609732083956, 'Total loss': 0.11659609732083956}
2022-12-31 06:50:02,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:02,661 INFO:     Epoch: 88
2022-12-31 06:50:04,285 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44746033747990926, 'Total loss': 0.44746033747990926} | train loss {'Reaction outcome loss': 0.11208920789700326, 'Total loss': 0.11208920789700326}
2022-12-31 06:50:04,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:04,285 INFO:     Epoch: 89
2022-12-31 06:50:05,912 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41382458110650383, 'Total loss': 0.41382458110650383} | train loss {'Reaction outcome loss': 0.11341590352147224, 'Total loss': 0.11341590352147224}
2022-12-31 06:50:05,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:05,912 INFO:     Epoch: 90
2022-12-31 06:50:07,541 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4159051388502121, 'Total loss': 0.4159051388502121} | train loss {'Reaction outcome loss': 0.11221291024053968, 'Total loss': 0.11221291024053968}
2022-12-31 06:50:07,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:07,541 INFO:     Epoch: 91
2022-12-31 06:50:09,168 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44476729035377505, 'Total loss': 0.44476729035377505} | train loss {'Reaction outcome loss': 0.11490498493895243, 'Total loss': 0.11490498493895243}
2022-12-31 06:50:09,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:09,169 INFO:     Epoch: 92
2022-12-31 06:50:10,832 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41263062953948976, 'Total loss': 0.41263062953948976} | train loss {'Reaction outcome loss': 0.11069065389228458, 'Total loss': 0.11069065389228458}
2022-12-31 06:50:10,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:10,833 INFO:     Epoch: 93
2022-12-31 06:50:12,462 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4195598152776559, 'Total loss': 0.4195598152776559} | train loss {'Reaction outcome loss': 0.11490911908913404, 'Total loss': 0.11490911908913404}
2022-12-31 06:50:12,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:12,463 INFO:     Epoch: 94
2022-12-31 06:50:14,109 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4674911469221115, 'Total loss': 0.4674911469221115} | train loss {'Reaction outcome loss': 0.13693659463424937, 'Total loss': 0.13693659463424937}
2022-12-31 06:50:14,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:14,109 INFO:     Epoch: 95
2022-12-31 06:50:15,737 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4199342538913091, 'Total loss': 0.4199342538913091} | train loss {'Reaction outcome loss': 0.13839179392530437, 'Total loss': 0.13839179392530437}
2022-12-31 06:50:15,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:15,738 INFO:     Epoch: 96
2022-12-31 06:50:17,362 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42797895123561225, 'Total loss': 0.42797895123561225} | train loss {'Reaction outcome loss': 0.11365422309482591, 'Total loss': 0.11365422309482591}
2022-12-31 06:50:17,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:17,363 INFO:     Epoch: 97
2022-12-31 06:50:18,987 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44317502280076343, 'Total loss': 0.44317502280076343} | train loss {'Reaction outcome loss': 0.10796034216637844, 'Total loss': 0.10796034216637844}
2022-12-31 06:50:18,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:18,987 INFO:     Epoch: 98
2022-12-31 06:50:20,658 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44893014828364053, 'Total loss': 0.44893014828364053} | train loss {'Reaction outcome loss': 0.11102408809634601, 'Total loss': 0.11102408809634601}
2022-12-31 06:50:20,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:20,658 INFO:     Epoch: 99
2022-12-31 06:50:22,321 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4301673193772634, 'Total loss': 0.4301673193772634} | train loss {'Reaction outcome loss': 0.10922291806133032, 'Total loss': 0.10922291806133032}
2022-12-31 06:50:22,321 INFO:     Best model found after epoch 21 of 100.
2022-12-31 06:50:22,321 INFO:   Done with stage: TRAINING
2022-12-31 06:50:22,321 INFO:   Starting stage: EVALUATION
2022-12-31 06:50:22,451 INFO:   Done with stage: EVALUATION
2022-12-31 06:50:22,451 INFO:   Leaving out SEQ value Fold_1
2022-12-31 06:50:22,463 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 06:50:22,463 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:50:23,115 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:50:23,115 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:50:23,185 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:50:23,185 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:50:23,185 INFO:     No hyperparam tuning for this model
2022-12-31 06:50:23,185 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:50:23,185 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:50:23,186 INFO:     None feature selector for col prot
2022-12-31 06:50:23,186 INFO:     None feature selector for col prot
2022-12-31 06:50:23,186 INFO:     None feature selector for col prot
2022-12-31 06:50:23,186 INFO:     None feature selector for col chem
2022-12-31 06:50:23,187 INFO:     None feature selector for col chem
2022-12-31 06:50:23,187 INFO:     None feature selector for col chem
2022-12-31 06:50:23,187 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:50:23,187 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:50:23,189 INFO:     Number of params in model 224011
2022-12-31 06:50:23,192 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:50:23,192 INFO:   Starting stage: TRAINING
2022-12-31 06:50:23,236 INFO:     Val loss before train {'Reaction outcome loss': 1.102585212389628, 'Total loss': 1.102585212389628}
2022-12-31 06:50:23,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:23,236 INFO:     Epoch: 0
2022-12-31 06:50:24,840 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6778280735015869, 'Total loss': 0.6778280735015869} | train loss {'Reaction outcome loss': 0.798490393975564, 'Total loss': 0.798490393975564}
2022-12-31 06:50:24,840 INFO:     Found new best model at epoch 0
2022-12-31 06:50:24,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:24,841 INFO:     Epoch: 1
2022-12-31 06:50:26,436 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5314208447933197, 'Total loss': 0.5314208447933197} | train loss {'Reaction outcome loss': 0.5268752680493457, 'Total loss': 0.5268752680493457}
2022-12-31 06:50:26,436 INFO:     Found new best model at epoch 1
2022-12-31 06:50:26,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:26,437 INFO:     Epoch: 2
2022-12-31 06:50:28,033 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5021012514829636, 'Total loss': 0.5021012514829636} | train loss {'Reaction outcome loss': 0.45726188247494154, 'Total loss': 0.45726188247494154}
2022-12-31 06:50:28,034 INFO:     Found new best model at epoch 2
2022-12-31 06:50:28,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:28,035 INFO:     Epoch: 3
2022-12-31 06:50:29,653 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4818384657303492, 'Total loss': 0.4818384657303492} | train loss {'Reaction outcome loss': 0.4109696261722223, 'Total loss': 0.4109696261722223}
2022-12-31 06:50:29,654 INFO:     Found new best model at epoch 3
2022-12-31 06:50:29,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:29,655 INFO:     Epoch: 4
2022-12-31 06:50:31,251 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5038094013929367, 'Total loss': 0.5038094013929367} | train loss {'Reaction outcome loss': 0.3840439607186511, 'Total loss': 0.3840439607186511}
2022-12-31 06:50:31,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:31,252 INFO:     Epoch: 5
2022-12-31 06:50:32,859 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4815436025460561, 'Total loss': 0.4815436025460561} | train loss {'Reaction outcome loss': 0.3636074402125559, 'Total loss': 0.3636074402125559}
2022-12-31 06:50:32,859 INFO:     Found new best model at epoch 5
2022-12-31 06:50:32,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:32,860 INFO:     Epoch: 6
2022-12-31 06:50:34,456 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4411262621482213, 'Total loss': 0.4411262621482213} | train loss {'Reaction outcome loss': 0.3432401846750636, 'Total loss': 0.3432401846750636}
2022-12-31 06:50:34,457 INFO:     Found new best model at epoch 6
2022-12-31 06:50:34,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:34,458 INFO:     Epoch: 7
2022-12-31 06:50:36,055 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4434846619764964, 'Total loss': 0.4434846619764964} | train loss {'Reaction outcome loss': 0.326741994279557, 'Total loss': 0.326741994279557}
2022-12-31 06:50:36,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:36,055 INFO:     Epoch: 8
2022-12-31 06:50:37,657 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42071203092734016, 'Total loss': 0.42071203092734016} | train loss {'Reaction outcome loss': 0.304486793950475, 'Total loss': 0.304486793950475}
2022-12-31 06:50:37,657 INFO:     Found new best model at epoch 8
2022-12-31 06:50:37,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:37,658 INFO:     Epoch: 9
2022-12-31 06:50:39,258 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4243790149688721, 'Total loss': 0.4243790149688721} | train loss {'Reaction outcome loss': 0.2951491861105845, 'Total loss': 0.2951491861105845}
2022-12-31 06:50:39,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:39,258 INFO:     Epoch: 10
2022-12-31 06:50:40,851 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46086670259634654, 'Total loss': 0.46086670259634654} | train loss {'Reaction outcome loss': 0.28299299059813754, 'Total loss': 0.28299299059813754}
2022-12-31 06:50:40,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:40,851 INFO:     Epoch: 11
2022-12-31 06:50:42,423 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40440467819571496, 'Total loss': 0.40440467819571496} | train loss {'Reaction outcome loss': 0.27311431808995146, 'Total loss': 0.27311431808995146}
2022-12-31 06:50:42,423 INFO:     Found new best model at epoch 11
2022-12-31 06:50:42,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:42,424 INFO:     Epoch: 12
2022-12-31 06:50:44,007 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42951189080874125, 'Total loss': 0.42951189080874125} | train loss {'Reaction outcome loss': 0.26160711363452827, 'Total loss': 0.26160711363452827}
2022-12-31 06:50:44,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:44,007 INFO:     Epoch: 13
2022-12-31 06:50:45,640 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4119623710711797, 'Total loss': 0.4119623710711797} | train loss {'Reaction outcome loss': 0.25484490507313245, 'Total loss': 0.25484490507313245}
2022-12-31 06:50:45,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:45,640 INFO:     Epoch: 14
2022-12-31 06:50:47,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39834360281626385, 'Total loss': 0.39834360281626385} | train loss {'Reaction outcome loss': 0.24215530594501547, 'Total loss': 0.24215530594501547}
2022-12-31 06:50:47,276 INFO:     Found new best model at epoch 14
2022-12-31 06:50:47,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:47,277 INFO:     Epoch: 15
2022-12-31 06:50:48,912 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38511065145333606, 'Total loss': 0.38511065145333606} | train loss {'Reaction outcome loss': 0.2391528192618896, 'Total loss': 0.2391528192618896}
2022-12-31 06:50:48,912 INFO:     Found new best model at epoch 15
2022-12-31 06:50:48,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:48,913 INFO:     Epoch: 16
2022-12-31 06:50:50,500 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3946759661038717, 'Total loss': 0.3946759661038717} | train loss {'Reaction outcome loss': 0.22785035733862116, 'Total loss': 0.22785035733862116}
2022-12-31 06:50:50,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:50,500 INFO:     Epoch: 17
2022-12-31 06:50:52,116 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39439804553985597, 'Total loss': 0.39439804553985597} | train loss {'Reaction outcome loss': 0.22550619315232298, 'Total loss': 0.22550619315232298}
2022-12-31 06:50:52,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:52,116 INFO:     Epoch: 18
2022-12-31 06:50:53,751 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42820407648881276, 'Total loss': 0.42820407648881276} | train loss {'Reaction outcome loss': 0.21727771379356015, 'Total loss': 0.21727771379356015}
2022-12-31 06:50:53,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:53,752 INFO:     Epoch: 19
2022-12-31 06:50:55,342 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3860620880809923, 'Total loss': 0.3860620880809923} | train loss {'Reaction outcome loss': 0.2159812505807164, 'Total loss': 0.2159812505807164}
2022-12-31 06:50:55,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:55,342 INFO:     Epoch: 20
2022-12-31 06:50:56,976 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38456546266873676, 'Total loss': 0.38456546266873676} | train loss {'Reaction outcome loss': 0.20807110687298527, 'Total loss': 0.20807110687298527}
2022-12-31 06:50:56,976 INFO:     Found new best model at epoch 20
2022-12-31 06:50:56,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:56,977 INFO:     Epoch: 21
2022-12-31 06:50:58,561 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40892132620016736, 'Total loss': 0.40892132620016736} | train loss {'Reaction outcome loss': 0.2021535019015694, 'Total loss': 0.2021535019015694}
2022-12-31 06:50:58,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:50:58,561 INFO:     Epoch: 22
2022-12-31 06:51:00,176 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39675190846125286, 'Total loss': 0.39675190846125286} | train loss {'Reaction outcome loss': 0.19632464449687748, 'Total loss': 0.19632464449687748}
2022-12-31 06:51:00,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:00,176 INFO:     Epoch: 23
2022-12-31 06:51:01,762 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3761088122924169, 'Total loss': 0.3761088122924169} | train loss {'Reaction outcome loss': 0.1958804385688472, 'Total loss': 0.1958804385688472}
2022-12-31 06:51:01,762 INFO:     Found new best model at epoch 23
2022-12-31 06:51:01,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:01,764 INFO:     Epoch: 24
2022-12-31 06:51:03,352 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40383802304665245, 'Total loss': 0.40383802304665245} | train loss {'Reaction outcome loss': 0.18930319247842936, 'Total loss': 0.18930319247842936}
2022-12-31 06:51:03,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:03,352 INFO:     Epoch: 25
2022-12-31 06:51:04,938 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39932989279429115, 'Total loss': 0.39932989279429115} | train loss {'Reaction outcome loss': 0.185138950035031, 'Total loss': 0.185138950035031}
2022-12-31 06:51:04,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:04,938 INFO:     Epoch: 26
2022-12-31 06:51:06,524 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38703194657961526, 'Total loss': 0.38703194657961526} | train loss {'Reaction outcome loss': 0.182718567660154, 'Total loss': 0.182718567660154}
2022-12-31 06:51:06,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:06,524 INFO:     Epoch: 27
2022-12-31 06:51:08,111 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3841473291317622, 'Total loss': 0.3841473291317622} | train loss {'Reaction outcome loss': 0.1809618285757479, 'Total loss': 0.1809618285757479}
2022-12-31 06:51:08,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:08,111 INFO:     Epoch: 28
2022-12-31 06:51:09,691 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3895491696894169, 'Total loss': 0.3895491696894169} | train loss {'Reaction outcome loss': 0.1760136286016705, 'Total loss': 0.1760136286016705}
2022-12-31 06:51:09,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:09,692 INFO:     Epoch: 29
2022-12-31 06:51:11,288 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40357993841171264, 'Total loss': 0.40357993841171264} | train loss {'Reaction outcome loss': 0.1736293012668066, 'Total loss': 0.1736293012668066}
2022-12-31 06:51:11,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:11,288 INFO:     Epoch: 30
2022-12-31 06:51:12,884 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42627546389897664, 'Total loss': 0.42627546389897664} | train loss {'Reaction outcome loss': 0.16845769272271777, 'Total loss': 0.16845769272271777}
2022-12-31 06:51:12,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:12,884 INFO:     Epoch: 31
2022-12-31 06:51:14,478 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40118648211161295, 'Total loss': 0.40118648211161295} | train loss {'Reaction outcome loss': 0.16680334287101053, 'Total loss': 0.16680334287101053}
2022-12-31 06:51:14,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:14,478 INFO:     Epoch: 32
2022-12-31 06:51:16,073 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3571581614514192, 'Total loss': 0.3571581614514192} | train loss {'Reaction outcome loss': 0.16807316762921004, 'Total loss': 0.16807316762921004}
2022-12-31 06:51:16,073 INFO:     Found new best model at epoch 32
2022-12-31 06:51:16,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:16,074 INFO:     Epoch: 33
2022-12-31 06:51:17,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42506163120269774, 'Total loss': 0.42506163120269774} | train loss {'Reaction outcome loss': 0.1592684310939974, 'Total loss': 0.1592684310939974}
2022-12-31 06:51:17,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:17,662 INFO:     Epoch: 34
2022-12-31 06:51:19,260 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41060693860054015, 'Total loss': 0.41060693860054015} | train loss {'Reaction outcome loss': 0.16186446317461253, 'Total loss': 0.16186446317461253}
2022-12-31 06:51:19,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:19,260 INFO:     Epoch: 35
2022-12-31 06:51:20,853 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38007041613260906, 'Total loss': 0.38007041613260906} | train loss {'Reaction outcome loss': 0.16155809654967646, 'Total loss': 0.16155809654967646}
2022-12-31 06:51:20,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:20,854 INFO:     Epoch: 36
2022-12-31 06:51:22,489 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3925689409176509, 'Total loss': 0.3925689409176509} | train loss {'Reaction outcome loss': 0.15765424641330358, 'Total loss': 0.15765424641330358}
2022-12-31 06:51:22,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:22,489 INFO:     Epoch: 37
2022-12-31 06:51:24,124 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38379824347794056, 'Total loss': 0.38379824347794056} | train loss {'Reaction outcome loss': 0.15508589701816386, 'Total loss': 0.15508589701816386}
2022-12-31 06:51:24,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:24,125 INFO:     Epoch: 38
2022-12-31 06:51:25,716 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37636313289403917, 'Total loss': 0.37636313289403917} | train loss {'Reaction outcome loss': 0.15243841814756998, 'Total loss': 0.15243841814756998}
2022-12-31 06:51:25,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:25,717 INFO:     Epoch: 39
2022-12-31 06:51:27,315 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4172249312202136, 'Total loss': 0.4172249312202136} | train loss {'Reaction outcome loss': 0.15406266968985985, 'Total loss': 0.15406266968985985}
2022-12-31 06:51:27,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:27,315 INFO:     Epoch: 40
2022-12-31 06:51:28,905 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41693909267584484, 'Total loss': 0.41693909267584484} | train loss {'Reaction outcome loss': 0.15127119709947232, 'Total loss': 0.15127119709947232}
2022-12-31 06:51:28,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:28,905 INFO:     Epoch: 41
2022-12-31 06:51:30,499 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35648682415485383, 'Total loss': 0.35648682415485383} | train loss {'Reaction outcome loss': 0.14798796334822845, 'Total loss': 0.14798796334822845}
2022-12-31 06:51:30,499 INFO:     Found new best model at epoch 41
2022-12-31 06:51:30,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:30,500 INFO:     Epoch: 42
2022-12-31 06:51:32,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3967309921979904, 'Total loss': 0.3967309921979904} | train loss {'Reaction outcome loss': 0.14835374429821968, 'Total loss': 0.14835374429821968}
2022-12-31 06:51:32,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:32,094 INFO:     Epoch: 43
2022-12-31 06:51:33,688 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4280614693959554, 'Total loss': 0.4280614693959554} | train loss {'Reaction outcome loss': 0.1435873598870701, 'Total loss': 0.1435873598870701}
2022-12-31 06:51:33,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:33,688 INFO:     Epoch: 44
2022-12-31 06:51:35,283 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4026767387986183, 'Total loss': 0.4026767387986183} | train loss {'Reaction outcome loss': 0.14439899405306444, 'Total loss': 0.14439899405306444}
2022-12-31 06:51:35,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:35,283 INFO:     Epoch: 45
2022-12-31 06:51:36,863 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39153539737065635, 'Total loss': 0.39153539737065635} | train loss {'Reaction outcome loss': 0.1415268419004592, 'Total loss': 0.1415268419004592}
2022-12-31 06:51:36,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:36,864 INFO:     Epoch: 46
2022-12-31 06:51:38,458 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3719897905985514, 'Total loss': 0.3719897905985514} | train loss {'Reaction outcome loss': 0.13786819052274213, 'Total loss': 0.13786819052274213}
2022-12-31 06:51:38,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:38,458 INFO:     Epoch: 47
2022-12-31 06:51:40,055 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3946302076180776, 'Total loss': 0.3946302076180776} | train loss {'Reaction outcome loss': 0.14019637473951682, 'Total loss': 0.14019637473951682}
2022-12-31 06:51:40,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:40,055 INFO:     Epoch: 48
2022-12-31 06:51:41,650 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4416830465197563, 'Total loss': 0.4416830465197563} | train loss {'Reaction outcome loss': 0.13627698189816076, 'Total loss': 0.13627698189816076}
2022-12-31 06:51:41,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:41,651 INFO:     Epoch: 49
2022-12-31 06:51:43,245 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4130843013525009, 'Total loss': 0.4130843013525009} | train loss {'Reaction outcome loss': 0.13478525630731095, 'Total loss': 0.13478525630731095}
2022-12-31 06:51:43,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:43,245 INFO:     Epoch: 50
2022-12-31 06:51:44,831 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3610520541667938, 'Total loss': 0.3610520541667938} | train loss {'Reaction outcome loss': 0.1351209223352895, 'Total loss': 0.1351209223352895}
2022-12-31 06:51:44,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:44,832 INFO:     Epoch: 51
2022-12-31 06:51:46,445 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3945890195667744, 'Total loss': 0.3945890195667744} | train loss {'Reaction outcome loss': 0.13528548716481542, 'Total loss': 0.13528548716481542}
2022-12-31 06:51:46,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:46,445 INFO:     Epoch: 52
2022-12-31 06:51:48,036 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37118806391954423, 'Total loss': 0.37118806391954423} | train loss {'Reaction outcome loss': 0.13430933840744666, 'Total loss': 0.13430933840744666}
2022-12-31 06:51:48,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:48,037 INFO:     Epoch: 53
2022-12-31 06:51:49,723 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40889849315087, 'Total loss': 0.40889849315087} | train loss {'Reaction outcome loss': 0.1323959901344677, 'Total loss': 0.1323959901344677}
2022-12-31 06:51:49,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:49,725 INFO:     Epoch: 54
2022-12-31 06:51:51,312 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4407775789499283, 'Total loss': 0.4407775789499283} | train loss {'Reaction outcome loss': 0.1337437531515626, 'Total loss': 0.1337437531515626}
2022-12-31 06:51:51,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:51,312 INFO:     Epoch: 55
2022-12-31 06:51:52,902 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40955806722243626, 'Total loss': 0.40955806722243626} | train loss {'Reaction outcome loss': 0.1387335497995914, 'Total loss': 0.1387335497995914}
2022-12-31 06:51:52,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:52,903 INFO:     Epoch: 56
2022-12-31 06:51:54,490 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38581496973832446, 'Total loss': 0.38581496973832446} | train loss {'Reaction outcome loss': 0.1309372934708681, 'Total loss': 0.1309372934708681}
2022-12-31 06:51:54,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:54,490 INFO:     Epoch: 57
2022-12-31 06:51:56,165 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3982013920942942, 'Total loss': 0.3982013920942942} | train loss {'Reaction outcome loss': 0.1281486575636064, 'Total loss': 0.1281486575636064}
2022-12-31 06:51:56,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:56,166 INFO:     Epoch: 58
2022-12-31 06:51:57,799 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4169806728760401, 'Total loss': 0.4169806728760401} | train loss {'Reaction outcome loss': 0.12610769150366258, 'Total loss': 0.12610769150366258}
2022-12-31 06:51:57,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:57,800 INFO:     Epoch: 59
2022-12-31 06:51:59,432 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39316925456126534, 'Total loss': 0.39316925456126534} | train loss {'Reaction outcome loss': 0.12994942086236724, 'Total loss': 0.12994942086236724}
2022-12-31 06:51:59,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:51:59,432 INFO:     Epoch: 60
2022-12-31 06:52:01,066 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4059968610604604, 'Total loss': 0.4059968610604604} | train loss {'Reaction outcome loss': 0.12858087593961054, 'Total loss': 0.12858087593961054}
2022-12-31 06:52:01,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:01,066 INFO:     Epoch: 61
2022-12-31 06:52:02,699 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3647438277800878, 'Total loss': 0.3647438277800878} | train loss {'Reaction outcome loss': 0.12349563074810259, 'Total loss': 0.12349563074810259}
2022-12-31 06:52:02,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:02,699 INFO:     Epoch: 62
2022-12-31 06:52:04,293 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38893645207087196, 'Total loss': 0.38893645207087196} | train loss {'Reaction outcome loss': 0.1291810479496238, 'Total loss': 0.1291810479496238}
2022-12-31 06:52:04,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:04,293 INFO:     Epoch: 63
2022-12-31 06:52:05,927 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.414988699555397, 'Total loss': 0.414988699555397} | train loss {'Reaction outcome loss': 0.12306096833164896, 'Total loss': 0.12306096833164896}
2022-12-31 06:52:05,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:05,927 INFO:     Epoch: 64
2022-12-31 06:52:07,514 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38334087332089745, 'Total loss': 0.38334087332089745} | train loss {'Reaction outcome loss': 0.12499329694323379, 'Total loss': 0.12499329694323379}
2022-12-31 06:52:07,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:07,514 INFO:     Epoch: 65
2022-12-31 06:52:09,129 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4232058644294739, 'Total loss': 0.4232058644294739} | train loss {'Reaction outcome loss': 0.1305213739435666, 'Total loss': 0.1305213739435666}
2022-12-31 06:52:09,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:09,130 INFO:     Epoch: 66
2022-12-31 06:52:10,717 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4141942250697563, 'Total loss': 0.4141942250697563} | train loss {'Reaction outcome loss': 0.1265510313790223, 'Total loss': 0.1265510313790223}
2022-12-31 06:52:10,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:10,717 INFO:     Epoch: 67
2022-12-31 06:52:12,314 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4293461710214615, 'Total loss': 0.4293461710214615} | train loss {'Reaction outcome loss': 0.12505219058508252, 'Total loss': 0.12505219058508252}
2022-12-31 06:52:12,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:12,314 INFO:     Epoch: 68
2022-12-31 06:52:13,926 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40652780830860136, 'Total loss': 0.40652780830860136} | train loss {'Reaction outcome loss': 0.118984415261178, 'Total loss': 0.118984415261178}
2022-12-31 06:52:13,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:13,926 INFO:     Epoch: 69
2022-12-31 06:52:15,561 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45481079518795015, 'Total loss': 0.45481079518795015} | train loss {'Reaction outcome loss': 0.12042332499037149, 'Total loss': 0.12042332499037149}
2022-12-31 06:52:15,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:15,561 INFO:     Epoch: 70
2022-12-31 06:52:17,145 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40112306276957194, 'Total loss': 0.40112306276957194} | train loss {'Reaction outcome loss': 0.12308072311394741, 'Total loss': 0.12308072311394741}
2022-12-31 06:52:17,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:17,145 INFO:     Epoch: 71
2022-12-31 06:52:18,772 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3582173099120458, 'Total loss': 0.3582173099120458} | train loss {'Reaction outcome loss': 0.12154167003558461, 'Total loss': 0.12154167003558461}
2022-12-31 06:52:18,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:18,772 INFO:     Epoch: 72
2022-12-31 06:52:20,406 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4207655077179273, 'Total loss': 0.4207655077179273} | train loss {'Reaction outcome loss': 0.12440275816879204, 'Total loss': 0.12440275816879204}
2022-12-31 06:52:20,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:20,406 INFO:     Epoch: 73
2022-12-31 06:52:22,001 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43065666953722637, 'Total loss': 0.43065666953722637} | train loss {'Reaction outcome loss': 0.1240245703078559, 'Total loss': 0.1240245703078559}
2022-12-31 06:52:22,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:22,001 INFO:     Epoch: 74
2022-12-31 06:52:23,585 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43732711573441824, 'Total loss': 0.43732711573441824} | train loss {'Reaction outcome loss': 0.11707405910940628, 'Total loss': 0.11707405910940628}
2022-12-31 06:52:23,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:23,585 INFO:     Epoch: 75
2022-12-31 06:52:25,198 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39223339955012004, 'Total loss': 0.39223339955012004} | train loss {'Reaction outcome loss': 0.12234117001178245, 'Total loss': 0.12234117001178245}
2022-12-31 06:52:25,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:25,199 INFO:     Epoch: 76
2022-12-31 06:52:26,824 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42432272831598916, 'Total loss': 0.42432272831598916} | train loss {'Reaction outcome loss': 0.12467171683412637, 'Total loss': 0.12467171683412637}
2022-12-31 06:52:26,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:26,824 INFO:     Epoch: 77
2022-12-31 06:52:28,415 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45983617355426154, 'Total loss': 0.45983617355426154} | train loss {'Reaction outcome loss': 0.11509818591631096, 'Total loss': 0.11509818591631096}
2022-12-31 06:52:28,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:28,415 INFO:     Epoch: 78
2022-12-31 06:52:30,017 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4082328995068868, 'Total loss': 0.4082328995068868} | train loss {'Reaction outcome loss': 0.11602250956569375, 'Total loss': 0.11602250956569375}
2022-12-31 06:52:30,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:30,017 INFO:     Epoch: 79
2022-12-31 06:52:31,526 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4326585570971171, 'Total loss': 0.4326585570971171} | train loss {'Reaction outcome loss': 0.11562006240298223, 'Total loss': 0.11562006240298223}
2022-12-31 06:52:31,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:31,527 INFO:     Epoch: 80
2022-12-31 06:52:32,625 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4230572839577993, 'Total loss': 0.4230572839577993} | train loss {'Reaction outcome loss': 0.11376939203273986, 'Total loss': 0.11376939203273986}
2022-12-31 06:52:32,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:32,625 INFO:     Epoch: 81
2022-12-31 06:52:33,715 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43912457426389057, 'Total loss': 0.43912457426389057} | train loss {'Reaction outcome loss': 0.11671135358931668, 'Total loss': 0.11671135358931668}
2022-12-31 06:52:33,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:33,715 INFO:     Epoch: 82
2022-12-31 06:52:34,804 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4308505748709043, 'Total loss': 0.4308505748709043} | train loss {'Reaction outcome loss': 0.12003523642987672, 'Total loss': 0.12003523642987672}
2022-12-31 06:52:34,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:34,805 INFO:     Epoch: 83
2022-12-31 06:52:35,892 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4345828860998154, 'Total loss': 0.4345828860998154} | train loss {'Reaction outcome loss': 0.118012168494524, 'Total loss': 0.118012168494524}
2022-12-31 06:52:35,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:35,892 INFO:     Epoch: 84
2022-12-31 06:52:37,506 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4016890044013659, 'Total loss': 0.4016890044013659} | train loss {'Reaction outcome loss': 0.12105175755519379, 'Total loss': 0.12105175755519379}
2022-12-31 06:52:37,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:37,506 INFO:     Epoch: 85
2022-12-31 06:52:39,086 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4435697962840398, 'Total loss': 0.4435697962840398} | train loss {'Reaction outcome loss': 0.11662120375837237, 'Total loss': 0.11662120375837237}
2022-12-31 06:52:39,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:39,086 INFO:     Epoch: 86
2022-12-31 06:52:40,754 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43851635654767357, 'Total loss': 0.43851635654767357} | train loss {'Reaction outcome loss': 0.11479545005930526, 'Total loss': 0.11479545005930526}
2022-12-31 06:52:40,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:40,754 INFO:     Epoch: 87
2022-12-31 06:52:42,341 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40442361732323967, 'Total loss': 0.40442361732323967} | train loss {'Reaction outcome loss': 0.1170450759419271, 'Total loss': 0.1170450759419271}
2022-12-31 06:52:42,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:42,341 INFO:     Epoch: 88
2022-12-31 06:52:43,974 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3865900675455729, 'Total loss': 0.3865900675455729} | train loss {'Reaction outcome loss': 0.11271785937139689, 'Total loss': 0.11271785937139689}
2022-12-31 06:52:43,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:43,975 INFO:     Epoch: 89
2022-12-31 06:52:45,573 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42388631999492643, 'Total loss': 0.42388631999492643} | train loss {'Reaction outcome loss': 0.11259158199302495, 'Total loss': 0.11259158199302495}
2022-12-31 06:52:45,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:45,574 INFO:     Epoch: 90
2022-12-31 06:52:47,162 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4500898912549019, 'Total loss': 0.4500898912549019} | train loss {'Reaction outcome loss': 0.11332363671214213, 'Total loss': 0.11332363671214213}
2022-12-31 06:52:47,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:47,162 INFO:     Epoch: 91
2022-12-31 06:52:48,793 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3706269125143687, 'Total loss': 0.3706269125143687} | train loss {'Reaction outcome loss': 0.114983425738558, 'Total loss': 0.114983425738558}
2022-12-31 06:52:48,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:48,794 INFO:     Epoch: 92
2022-12-31 06:52:50,428 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4500556503732999, 'Total loss': 0.4500556503732999} | train loss {'Reaction outcome loss': 0.11566872088534146, 'Total loss': 0.11566872088534146}
2022-12-31 06:52:50,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:50,428 INFO:     Epoch: 93
2022-12-31 06:52:52,016 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3871285359064738, 'Total loss': 0.3871285359064738} | train loss {'Reaction outcome loss': 0.11440741380236741, 'Total loss': 0.11440741380236741}
2022-12-31 06:52:52,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:52,017 INFO:     Epoch: 94
2022-12-31 06:52:53,604 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38541661500930785, 'Total loss': 0.38541661500930785} | train loss {'Reaction outcome loss': 0.11386236327879021, 'Total loss': 0.11386236327879021}
2022-12-31 06:52:53,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:53,604 INFO:     Epoch: 95
2022-12-31 06:52:55,190 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4356714258591334, 'Total loss': 0.4356714258591334} | train loss {'Reaction outcome loss': 0.11230200242828509, 'Total loss': 0.11230200242828509}
2022-12-31 06:52:55,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:55,190 INFO:     Epoch: 96
2022-12-31 06:52:56,780 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4152710348367691, 'Total loss': 0.4152710348367691} | train loss {'Reaction outcome loss': 0.11337570209963405, 'Total loss': 0.11337570209963405}
2022-12-31 06:52:56,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:56,781 INFO:     Epoch: 97
2022-12-31 06:52:58,376 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38916750575105347, 'Total loss': 0.38916750575105347} | train loss {'Reaction outcome loss': 0.11247068816259834, 'Total loss': 0.11247068816259834}
2022-12-31 06:52:58,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:58,376 INFO:     Epoch: 98
2022-12-31 06:52:59,972 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39795410335063935, 'Total loss': 0.39795410335063935} | train loss {'Reaction outcome loss': 0.11026470108486959, 'Total loss': 0.11026470108486959}
2022-12-31 06:52:59,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:52:59,973 INFO:     Epoch: 99
2022-12-31 06:53:01,566 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39056020279725395, 'Total loss': 0.39056020279725395} | train loss {'Reaction outcome loss': 0.11260231711980767, 'Total loss': 0.11260231711980767}
2022-12-31 06:53:01,567 INFO:     Best model found after epoch 42 of 100.
2022-12-31 06:53:01,567 INFO:   Done with stage: TRAINING
2022-12-31 06:53:01,567 INFO:   Starting stage: EVALUATION
2022-12-31 06:53:01,716 INFO:   Done with stage: EVALUATION
2022-12-31 06:53:01,716 INFO:   Leaving out SEQ value Fold_2
2022-12-31 06:53:01,729 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:53:01,729 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:53:02,374 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:53:02,374 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:53:02,445 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:53:02,445 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:53:02,446 INFO:     No hyperparam tuning for this model
2022-12-31 06:53:02,446 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:53:02,446 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:53:02,446 INFO:     None feature selector for col prot
2022-12-31 06:53:02,447 INFO:     None feature selector for col prot
2022-12-31 06:53:02,447 INFO:     None feature selector for col prot
2022-12-31 06:53:02,447 INFO:     None feature selector for col chem
2022-12-31 06:53:02,447 INFO:     None feature selector for col chem
2022-12-31 06:53:02,447 INFO:     None feature selector for col chem
2022-12-31 06:53:02,447 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:53:02,447 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:53:02,449 INFO:     Number of params in model 224011
2022-12-31 06:53:02,452 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:53:02,453 INFO:   Starting stage: TRAINING
2022-12-31 06:53:02,498 INFO:     Val loss before train {'Reaction outcome loss': 0.9550633947054545, 'Total loss': 0.9550633947054545}
2022-12-31 06:53:02,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:02,498 INFO:     Epoch: 0
2022-12-31 06:53:04,101 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5381061176458994, 'Total loss': 0.5381061176458994} | train loss {'Reaction outcome loss': 0.7960962394293207, 'Total loss': 0.7960962394293207}
2022-12-31 06:53:04,101 INFO:     Found new best model at epoch 0
2022-12-31 06:53:04,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:04,102 INFO:     Epoch: 1
2022-12-31 06:53:05,708 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4903572837511698, 'Total loss': 0.4903572837511698} | train loss {'Reaction outcome loss': 0.5230899310133753, 'Total loss': 0.5230899310133753}
2022-12-31 06:53:05,708 INFO:     Found new best model at epoch 1
2022-12-31 06:53:05,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:05,709 INFO:     Epoch: 2
2022-12-31 06:53:07,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43577452848354975, 'Total loss': 0.43577452848354975} | train loss {'Reaction outcome loss': 0.45702998312937954, 'Total loss': 0.45702998312937954}
2022-12-31 06:53:07,322 INFO:     Found new best model at epoch 2
2022-12-31 06:53:07,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:07,323 INFO:     Epoch: 3
2022-12-31 06:53:08,936 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4235579212506612, 'Total loss': 0.4235579212506612} | train loss {'Reaction outcome loss': 0.41375143505143425, 'Total loss': 0.41375143505143425}
2022-12-31 06:53:08,936 INFO:     Found new best model at epoch 3
2022-12-31 06:53:08,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:08,937 INFO:     Epoch: 4
2022-12-31 06:53:10,550 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40973254640897117, 'Total loss': 0.40973254640897117} | train loss {'Reaction outcome loss': 0.38407744682074463, 'Total loss': 0.38407744682074463}
2022-12-31 06:53:10,550 INFO:     Found new best model at epoch 4
2022-12-31 06:53:10,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:10,551 INFO:     Epoch: 5
2022-12-31 06:53:12,163 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.424078361193339, 'Total loss': 0.424078361193339} | train loss {'Reaction outcome loss': 0.36102963081241524, 'Total loss': 0.36102963081241524}
2022-12-31 06:53:12,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:12,163 INFO:     Epoch: 6
2022-12-31 06:53:13,761 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4020360747973124, 'Total loss': 0.4020360747973124} | train loss {'Reaction outcome loss': 0.34838148135773456, 'Total loss': 0.34838148135773456}
2022-12-31 06:53:13,761 INFO:     Found new best model at epoch 6
2022-12-31 06:53:13,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:13,762 INFO:     Epoch: 7
2022-12-31 06:53:15,365 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39348747779925664, 'Total loss': 0.39348747779925664} | train loss {'Reaction outcome loss': 0.3237905949354172, 'Total loss': 0.3237905949354172}
2022-12-31 06:53:15,366 INFO:     Found new best model at epoch 7
2022-12-31 06:53:15,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:15,367 INFO:     Epoch: 8
2022-12-31 06:53:16,981 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39858265072107313, 'Total loss': 0.39858265072107313} | train loss {'Reaction outcome loss': 0.3101619539415314, 'Total loss': 0.3101619539415314}
2022-12-31 06:53:16,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:16,982 INFO:     Epoch: 9
2022-12-31 06:53:18,598 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3856714735428492, 'Total loss': 0.3856714735428492} | train loss {'Reaction outcome loss': 0.29324433687448936, 'Total loss': 0.29324433687448936}
2022-12-31 06:53:18,598 INFO:     Found new best model at epoch 9
2022-12-31 06:53:18,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:18,599 INFO:     Epoch: 10
2022-12-31 06:53:20,213 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3926776399215062, 'Total loss': 0.3926776399215062} | train loss {'Reaction outcome loss': 0.2817043571522201, 'Total loss': 0.2817043571522201}
2022-12-31 06:53:20,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:20,214 INFO:     Epoch: 11
2022-12-31 06:53:21,827 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40619633396466576, 'Total loss': 0.40619633396466576} | train loss {'Reaction outcome loss': 0.2704667517928964, 'Total loss': 0.2704667517928964}
2022-12-31 06:53:21,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:21,828 INFO:     Epoch: 12
2022-12-31 06:53:23,462 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40545304367939633, 'Total loss': 0.40545304367939633} | train loss {'Reaction outcome loss': 0.2597489887372638, 'Total loss': 0.2597489887372638}
2022-12-31 06:53:23,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:23,462 INFO:     Epoch: 13
2022-12-31 06:53:25,068 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38286710480848946, 'Total loss': 0.38286710480848946} | train loss {'Reaction outcome loss': 0.25358896062158753, 'Total loss': 0.25358896062158753}
2022-12-31 06:53:25,068 INFO:     Found new best model at epoch 13
2022-12-31 06:53:25,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:25,069 INFO:     Epoch: 14
2022-12-31 06:53:26,679 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.36541813363631565, 'Total loss': 0.36541813363631565} | train loss {'Reaction outcome loss': 0.24585525347531711, 'Total loss': 0.24585525347531711}
2022-12-31 06:53:26,679 INFO:     Found new best model at epoch 14
2022-12-31 06:53:26,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:26,680 INFO:     Epoch: 15
2022-12-31 06:53:28,291 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41345043381055196, 'Total loss': 0.41345043381055196} | train loss {'Reaction outcome loss': 0.23380500688659447, 'Total loss': 0.23380500688659447}
2022-12-31 06:53:28,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:28,291 INFO:     Epoch: 16
2022-12-31 06:53:29,942 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39905463221172494, 'Total loss': 0.39905463221172494} | train loss {'Reaction outcome loss': 0.22597665723793917, 'Total loss': 0.22597665723793917}
2022-12-31 06:53:29,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:29,942 INFO:     Epoch: 17
2022-12-31 06:53:31,552 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3934823093314966, 'Total loss': 0.3934823093314966} | train loss {'Reaction outcome loss': 0.22241123001614627, 'Total loss': 0.22241123001614627}
2022-12-31 06:53:31,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:31,553 INFO:     Epoch: 18
2022-12-31 06:53:33,150 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38664745291074115, 'Total loss': 0.38664745291074115} | train loss {'Reaction outcome loss': 0.21663721028144342, 'Total loss': 0.21663721028144342}
2022-12-31 06:53:33,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:33,150 INFO:     Epoch: 19
2022-12-31 06:53:34,800 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39369527300198875, 'Total loss': 0.39369527300198875} | train loss {'Reaction outcome loss': 0.2120819131497049, 'Total loss': 0.2120819131497049}
2022-12-31 06:53:34,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:34,800 INFO:     Epoch: 20
2022-12-31 06:53:36,449 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4139339715242386, 'Total loss': 0.4139339715242386} | train loss {'Reaction outcome loss': 0.20439589665998725, 'Total loss': 0.20439589665998725}
2022-12-31 06:53:36,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:36,450 INFO:     Epoch: 21
2022-12-31 06:53:38,056 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38604685763518015, 'Total loss': 0.38604685763518015} | train loss {'Reaction outcome loss': 0.1974396517017625, 'Total loss': 0.1974396517017625}
2022-12-31 06:53:38,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:38,057 INFO:     Epoch: 22
2022-12-31 06:53:39,671 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3728345140814781, 'Total loss': 0.3728345140814781} | train loss {'Reaction outcome loss': 0.19599583753840114, 'Total loss': 0.19599583753840114}
2022-12-31 06:53:39,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:39,672 INFO:     Epoch: 23
2022-12-31 06:53:41,267 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4037226587533951, 'Total loss': 0.4037226587533951} | train loss {'Reaction outcome loss': 0.19274407550420639, 'Total loss': 0.19274407550420639}
2022-12-31 06:53:41,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:41,268 INFO:     Epoch: 24
2022-12-31 06:53:42,875 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38726507623990375, 'Total loss': 0.38726507623990375} | train loss {'Reaction outcome loss': 0.18601220621842973, 'Total loss': 0.18601220621842973}
2022-12-31 06:53:42,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:42,875 INFO:     Epoch: 25
2022-12-31 06:53:44,498 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37803011685609816, 'Total loss': 0.37803011685609816} | train loss {'Reaction outcome loss': 0.18301439515049875, 'Total loss': 0.18301439515049875}
2022-12-31 06:53:44,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:44,498 INFO:     Epoch: 26
2022-12-31 06:53:46,145 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39996472199757893, 'Total loss': 0.39996472199757893} | train loss {'Reaction outcome loss': 0.1788217020662923, 'Total loss': 0.1788217020662923}
2022-12-31 06:53:46,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:46,146 INFO:     Epoch: 27
2022-12-31 06:53:47,793 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40727118055025735, 'Total loss': 0.40727118055025735} | train loss {'Reaction outcome loss': 0.17641058589338604, 'Total loss': 0.17641058589338604}
2022-12-31 06:53:47,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:47,793 INFO:     Epoch: 28
2022-12-31 06:53:49,425 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3800599813461304, 'Total loss': 0.3800599813461304} | train loss {'Reaction outcome loss': 0.1730029211603921, 'Total loss': 0.1730029211603921}
2022-12-31 06:53:49,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:49,425 INFO:     Epoch: 29
2022-12-31 06:53:51,050 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38491821264227233, 'Total loss': 0.38491821264227233} | train loss {'Reaction outcome loss': 0.17264968315207394, 'Total loss': 0.17264968315207394}
2022-12-31 06:53:51,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:51,051 INFO:     Epoch: 30
2022-12-31 06:53:52,659 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4191417892773946, 'Total loss': 0.4191417892773946} | train loss {'Reaction outcome loss': 0.16748842807575026, 'Total loss': 0.16748842807575026}
2022-12-31 06:53:52,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:52,659 INFO:     Epoch: 31
2022-12-31 06:53:54,307 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3899679630994797, 'Total loss': 0.3899679630994797} | train loss {'Reaction outcome loss': 0.16455237464095554, 'Total loss': 0.16455237464095554}
2022-12-31 06:53:54,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:54,308 INFO:     Epoch: 32
2022-12-31 06:53:55,955 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4104818562666575, 'Total loss': 0.4104818562666575} | train loss {'Reaction outcome loss': 0.16526770307920383, 'Total loss': 0.16526770307920383}
2022-12-31 06:53:55,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:55,956 INFO:     Epoch: 33
2022-12-31 06:53:57,604 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4169190396865209, 'Total loss': 0.4169190396865209} | train loss {'Reaction outcome loss': 0.1632076184414871, 'Total loss': 0.1632076184414871}
2022-12-31 06:53:57,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:57,604 INFO:     Epoch: 34
2022-12-31 06:53:59,220 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4293911019961039, 'Total loss': 0.4293911019961039} | train loss {'Reaction outcome loss': 0.15966459691361354, 'Total loss': 0.15966459691361354}
2022-12-31 06:53:59,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:53:59,220 INFO:     Epoch: 35
2022-12-31 06:54:00,827 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3826282157252232, 'Total loss': 0.3826282157252232} | train loss {'Reaction outcome loss': 0.15584508087621987, 'Total loss': 0.15584508087621987}
2022-12-31 06:54:00,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:00,827 INFO:     Epoch: 36
2022-12-31 06:54:02,477 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40904744416475297, 'Total loss': 0.40904744416475297} | train loss {'Reaction outcome loss': 0.15475392981643116, 'Total loss': 0.15475392981643116}
2022-12-31 06:54:02,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:02,477 INFO:     Epoch: 37
2022-12-31 06:54:04,081 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4011902833978335, 'Total loss': 0.4011902833978335} | train loss {'Reaction outcome loss': 0.15275657486279298, 'Total loss': 0.15275657486279298}
2022-12-31 06:54:04,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:04,081 INFO:     Epoch: 38
2022-12-31 06:54:05,691 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4085248341163, 'Total loss': 0.4085248341163} | train loss {'Reaction outcome loss': 0.15470427814803092, 'Total loss': 0.15470427814803092}
2022-12-31 06:54:05,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:05,692 INFO:     Epoch: 39
2022-12-31 06:54:07,327 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4071722373366356, 'Total loss': 0.4071722373366356} | train loss {'Reaction outcome loss': 0.1503655947846816, 'Total loss': 0.1503655947846816}
2022-12-31 06:54:07,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:07,328 INFO:     Epoch: 40
2022-12-31 06:54:08,937 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3993258665005366, 'Total loss': 0.3993258665005366} | train loss {'Reaction outcome loss': 0.1472154397935518, 'Total loss': 0.1472154397935518}
2022-12-31 06:54:08,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:08,937 INFO:     Epoch: 41
2022-12-31 06:54:10,558 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4132511427005132, 'Total loss': 0.4132511427005132} | train loss {'Reaction outcome loss': 0.14441388980723427, 'Total loss': 0.14441388980723427}
2022-12-31 06:54:10,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:10,559 INFO:     Epoch: 42
2022-12-31 06:54:12,176 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39469805161158245, 'Total loss': 0.39469805161158245} | train loss {'Reaction outcome loss': 0.14624070774179196, 'Total loss': 0.14624070774179196}
2022-12-31 06:54:12,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:12,176 INFO:     Epoch: 43
2022-12-31 06:54:13,792 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38887920329968134, 'Total loss': 0.38887920329968134} | train loss {'Reaction outcome loss': 0.14250499589613427, 'Total loss': 0.14250499589613427}
2022-12-31 06:54:13,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:13,793 INFO:     Epoch: 44
2022-12-31 06:54:15,407 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4132987002531687, 'Total loss': 0.4132987002531687} | train loss {'Reaction outcome loss': 0.14712588089334705, 'Total loss': 0.14712588089334705}
2022-12-31 06:54:15,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:15,407 INFO:     Epoch: 45
2022-12-31 06:54:17,014 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40506925284862516, 'Total loss': 0.40506925284862516} | train loss {'Reaction outcome loss': 0.14466940490596922, 'Total loss': 0.14466940490596922}
2022-12-31 06:54:17,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:17,015 INFO:     Epoch: 46
2022-12-31 06:54:18,623 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39684050232172013, 'Total loss': 0.39684050232172013} | train loss {'Reaction outcome loss': 0.14233361056455188, 'Total loss': 0.14233361056455188}
2022-12-31 06:54:18,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:18,623 INFO:     Epoch: 47
2022-12-31 06:54:20,240 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3574635331829389, 'Total loss': 0.3574635331829389} | train loss {'Reaction outcome loss': 0.13682435482169372, 'Total loss': 0.13682435482169372}
2022-12-31 06:54:20,240 INFO:     Found new best model at epoch 47
2022-12-31 06:54:20,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:20,242 INFO:     Epoch: 48
2022-12-31 06:54:21,861 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3815817711253961, 'Total loss': 0.3815817711253961} | train loss {'Reaction outcome loss': 0.13445871099013917, 'Total loss': 0.13445871099013917}
2022-12-31 06:54:21,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:21,861 INFO:     Epoch: 49
2022-12-31 06:54:23,480 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.382732155919075, 'Total loss': 0.382732155919075} | train loss {'Reaction outcome loss': 0.13533360571906405, 'Total loss': 0.13533360571906405}
2022-12-31 06:54:23,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:23,480 INFO:     Epoch: 50
2022-12-31 06:54:25,098 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40653500656286873, 'Total loss': 0.40653500656286873} | train loss {'Reaction outcome loss': 0.1377741103451427, 'Total loss': 0.1377741103451427}
2022-12-31 06:54:25,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:25,098 INFO:     Epoch: 51
2022-12-31 06:54:26,692 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3917465458313624, 'Total loss': 0.3917465458313624} | train loss {'Reaction outcome loss': 0.1344795832886313, 'Total loss': 0.1344795832886313}
2022-12-31 06:54:26,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:26,693 INFO:     Epoch: 52
2022-12-31 06:54:28,321 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40794696907202405, 'Total loss': 0.40794696907202405} | train loss {'Reaction outcome loss': 0.13257445372814436, 'Total loss': 0.13257445372814436}
2022-12-31 06:54:28,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:28,322 INFO:     Epoch: 53
2022-12-31 06:54:29,971 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42813192506631215, 'Total loss': 0.42813192506631215} | train loss {'Reaction outcome loss': 0.1368662348156455, 'Total loss': 0.1368662348156455}
2022-12-31 06:54:29,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:29,971 INFO:     Epoch: 54
2022-12-31 06:54:31,574 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40722646365563075, 'Total loss': 0.40722646365563075} | train loss {'Reaction outcome loss': 0.1349845203421466, 'Total loss': 0.1349845203421466}
2022-12-31 06:54:31,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:31,575 INFO:     Epoch: 55
2022-12-31 06:54:33,225 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4255985339482625, 'Total loss': 0.4255985339482625} | train loss {'Reaction outcome loss': 0.1331512755408448, 'Total loss': 0.1331512755408448}
2022-12-31 06:54:33,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:33,225 INFO:     Epoch: 56
2022-12-31 06:54:34,831 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.461359108487765, 'Total loss': 0.461359108487765} | train loss {'Reaction outcome loss': 0.13296341138592765, 'Total loss': 0.13296341138592765}
2022-12-31 06:54:34,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:34,831 INFO:     Epoch: 57
2022-12-31 06:54:36,439 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4147220258911451, 'Total loss': 0.4147220258911451} | train loss {'Reaction outcome loss': 0.12765961369485967, 'Total loss': 0.12765961369485967}
2022-12-31 06:54:36,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:36,440 INFO:     Epoch: 58
2022-12-31 06:54:38,089 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41799405018488567, 'Total loss': 0.41799405018488567} | train loss {'Reaction outcome loss': 0.1305672746053115, 'Total loss': 0.1305672746053115}
2022-12-31 06:54:38,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:38,090 INFO:     Epoch: 59
2022-12-31 06:54:39,741 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4331488529841105, 'Total loss': 0.4331488529841105} | train loss {'Reaction outcome loss': 0.12716489660138958, 'Total loss': 0.12716489660138958}
2022-12-31 06:54:39,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:39,741 INFO:     Epoch: 60
2022-12-31 06:54:41,390 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4205651432275772, 'Total loss': 0.4205651432275772} | train loss {'Reaction outcome loss': 0.12787829894388952, 'Total loss': 0.12787829894388952}
2022-12-31 06:54:41,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:41,391 INFO:     Epoch: 61
2022-12-31 06:54:43,040 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39688948541879654, 'Total loss': 0.39688948541879654} | train loss {'Reaction outcome loss': 0.13345291273817964, 'Total loss': 0.13345291273817964}
2022-12-31 06:54:43,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:43,042 INFO:     Epoch: 62
2022-12-31 06:54:44,646 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4087325553099314, 'Total loss': 0.4087325553099314} | train loss {'Reaction outcome loss': 0.1271549823224871, 'Total loss': 0.1271549823224871}
2022-12-31 06:54:44,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:44,646 INFO:     Epoch: 63
2022-12-31 06:54:46,248 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4388380984465281, 'Total loss': 0.4388380984465281} | train loss {'Reaction outcome loss': 0.12664394527095893, 'Total loss': 0.12664394527095893}
2022-12-31 06:54:46,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:46,248 INFO:     Epoch: 64
2022-12-31 06:54:47,897 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39471041709184645, 'Total loss': 0.39471041709184645} | train loss {'Reaction outcome loss': 0.12219924393048795, 'Total loss': 0.12219924393048795}
2022-12-31 06:54:47,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:47,898 INFO:     Epoch: 65
2022-12-31 06:54:49,548 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4235314647356669, 'Total loss': 0.4235314647356669} | train loss {'Reaction outcome loss': 0.12279672637228331, 'Total loss': 0.12279672637228331}
2022-12-31 06:54:49,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:49,549 INFO:     Epoch: 66
2022-12-31 06:54:51,155 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40318277378877004, 'Total loss': 0.40318277378877004} | train loss {'Reaction outcome loss': 0.12360361899269649, 'Total loss': 0.12360361899269649}
2022-12-31 06:54:51,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:51,155 INFO:     Epoch: 67
2022-12-31 06:54:52,763 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4226480866471926, 'Total loss': 0.4226480866471926} | train loss {'Reaction outcome loss': 0.12588126917478432, 'Total loss': 0.12588126917478432}
2022-12-31 06:54:52,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:52,763 INFO:     Epoch: 68
2022-12-31 06:54:54,376 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3868517736593882, 'Total loss': 0.3868517736593882} | train loss {'Reaction outcome loss': 0.12421597080665511, 'Total loss': 0.12421597080665511}
2022-12-31 06:54:54,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:54,376 INFO:     Epoch: 69
2022-12-31 06:54:55,988 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4074073185523351, 'Total loss': 0.4074073185523351} | train loss {'Reaction outcome loss': 0.12263541069581942, 'Total loss': 0.12263541069581942}
2022-12-31 06:54:55,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:55,988 INFO:     Epoch: 70
2022-12-31 06:54:57,595 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4116134031365315, 'Total loss': 0.4116134031365315} | train loss {'Reaction outcome loss': 0.122154191727784, 'Total loss': 0.122154191727784}
2022-12-31 06:54:57,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:57,595 INFO:     Epoch: 71
2022-12-31 06:54:59,205 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43090467552344003, 'Total loss': 0.43090467552344003} | train loss {'Reaction outcome loss': 0.12143404674410385, 'Total loss': 0.12143404674410385}
2022-12-31 06:54:59,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:54:59,206 INFO:     Epoch: 72
2022-12-31 06:55:00,814 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39291514654954274, 'Total loss': 0.39291514654954274} | train loss {'Reaction outcome loss': 0.1186759570192029, 'Total loss': 0.1186759570192029}
2022-12-31 06:55:00,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:00,815 INFO:     Epoch: 73
2022-12-31 06:55:02,454 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4374658077955246, 'Total loss': 0.4374658077955246} | train loss {'Reaction outcome loss': 0.11931784670922334, 'Total loss': 0.11931784670922334}
2022-12-31 06:55:02,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:02,455 INFO:     Epoch: 74
2022-12-31 06:55:04,055 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40660499334335326, 'Total loss': 0.40660499334335326} | train loss {'Reaction outcome loss': 0.12422161984230208, 'Total loss': 0.12422161984230208}
2022-12-31 06:55:04,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:04,055 INFO:     Epoch: 75
2022-12-31 06:55:05,707 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4009122908115387, 'Total loss': 0.4009122908115387} | train loss {'Reaction outcome loss': 0.12355385560467567, 'Total loss': 0.12355385560467567}
2022-12-31 06:55:05,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:05,707 INFO:     Epoch: 76
2022-12-31 06:55:07,358 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44020542403062185, 'Total loss': 0.44020542403062185} | train loss {'Reaction outcome loss': 0.1211874034293132, 'Total loss': 0.1211874034293132}
2022-12-31 06:55:07,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:07,359 INFO:     Epoch: 77
2022-12-31 06:55:09,010 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4185983012119929, 'Total loss': 0.4185983012119929} | train loss {'Reaction outcome loss': 0.1191296733858023, 'Total loss': 0.1191296733858023}
2022-12-31 06:55:09,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:09,010 INFO:     Epoch: 78
2022-12-31 06:55:10,661 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40158255100250245, 'Total loss': 0.40158255100250245} | train loss {'Reaction outcome loss': 0.11542212966843134, 'Total loss': 0.11542212966843134}
2022-12-31 06:55:10,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:10,661 INFO:     Epoch: 79
2022-12-31 06:55:12,277 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4088832805554072, 'Total loss': 0.4088832805554072} | train loss {'Reaction outcome loss': 0.12008173442377716, 'Total loss': 0.12008173442377716}
2022-12-31 06:55:12,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:12,278 INFO:     Epoch: 80
2022-12-31 06:55:13,889 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4452821580072244, 'Total loss': 0.4452821580072244} | train loss {'Reaction outcome loss': 0.11907810479212198, 'Total loss': 0.11907810479212198}
2022-12-31 06:55:13,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:13,890 INFO:     Epoch: 81
2022-12-31 06:55:15,508 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41969289208451904, 'Total loss': 0.41969289208451904} | train loss {'Reaction outcome loss': 0.11721341238683429, 'Total loss': 0.11721341238683429}
2022-12-31 06:55:15,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:15,509 INFO:     Epoch: 82
2022-12-31 06:55:17,128 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40385186672210693, 'Total loss': 0.40385186672210693} | train loss {'Reaction outcome loss': 0.116411160658977, 'Total loss': 0.116411160658977}
2022-12-31 06:55:17,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:17,128 INFO:     Epoch: 83
2022-12-31 06:55:18,746 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41936681667963666, 'Total loss': 0.41936681667963666} | train loss {'Reaction outcome loss': 0.12215910267584489, 'Total loss': 0.12215910267584489}
2022-12-31 06:55:18,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:18,746 INFO:     Epoch: 84
2022-12-31 06:55:20,353 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4087875182429949, 'Total loss': 0.4087875182429949} | train loss {'Reaction outcome loss': 0.11775072605389911, 'Total loss': 0.11775072605389911}
2022-12-31 06:55:20,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:20,354 INFO:     Epoch: 85
2022-12-31 06:55:21,956 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43259083131949105, 'Total loss': 0.43259083131949105} | train loss {'Reaction outcome loss': 0.11519010902219282, 'Total loss': 0.11519010902219282}
2022-12-31 06:55:21,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:21,956 INFO:     Epoch: 86
2022-12-31 06:55:23,562 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4477666993935903, 'Total loss': 0.4477666993935903} | train loss {'Reaction outcome loss': 0.1128459827087303, 'Total loss': 0.1128459827087303}
2022-12-31 06:55:23,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:23,562 INFO:     Epoch: 87
2022-12-31 06:55:25,175 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4180618663628896, 'Total loss': 0.4180618663628896} | train loss {'Reaction outcome loss': 0.1162691249233419, 'Total loss': 0.1162691249233419}
2022-12-31 06:55:25,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:25,175 INFO:     Epoch: 88
2022-12-31 06:55:26,787 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4061743835608164, 'Total loss': 0.4061743835608164} | train loss {'Reaction outcome loss': 0.12096311156060138, 'Total loss': 0.12096311156060138}
2022-12-31 06:55:26,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:26,787 INFO:     Epoch: 89
2022-12-31 06:55:28,399 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4074510395526886, 'Total loss': 0.4074510395526886} | train loss {'Reaction outcome loss': 0.1183103911619443, 'Total loss': 0.1183103911619443}
2022-12-31 06:55:28,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:28,400 INFO:     Epoch: 90
2022-12-31 06:55:30,018 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4315789699554443, 'Total loss': 0.4315789699554443} | train loss {'Reaction outcome loss': 0.1150381085513853, 'Total loss': 0.1150381085513853}
2022-12-31 06:55:30,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:30,019 INFO:     Epoch: 91
2022-12-31 06:55:31,645 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4389420141776403, 'Total loss': 0.4389420141776403} | train loss {'Reaction outcome loss': 0.10974760692189346, 'Total loss': 0.10974760692189346}
2022-12-31 06:55:31,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:31,645 INFO:     Epoch: 92
2022-12-31 06:55:33,295 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4325004975001017, 'Total loss': 0.4325004975001017} | train loss {'Reaction outcome loss': 0.11669505502940257, 'Total loss': 0.11669505502940257}
2022-12-31 06:55:33,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:33,295 INFO:     Epoch: 93
2022-12-31 06:55:34,903 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45382040143013, 'Total loss': 0.45382040143013} | train loss {'Reaction outcome loss': 0.11524130666312374, 'Total loss': 0.11524130666312374}
2022-12-31 06:55:34,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:34,903 INFO:     Epoch: 94
2022-12-31 06:55:36,552 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39903077234824497, 'Total loss': 0.39903077234824497} | train loss {'Reaction outcome loss': 0.11396030655358476, 'Total loss': 0.11396030655358476}
2022-12-31 06:55:36,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:36,553 INFO:     Epoch: 95
2022-12-31 06:55:38,166 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.422945765654246, 'Total loss': 0.422945765654246} | train loss {'Reaction outcome loss': 0.1213091941835889, 'Total loss': 0.1213091941835889}
2022-12-31 06:55:38,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:38,166 INFO:     Epoch: 96
2022-12-31 06:55:39,764 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44958506027857464, 'Total loss': 0.44958506027857464} | train loss {'Reaction outcome loss': 0.11411532342780627, 'Total loss': 0.11411532342780627}
2022-12-31 06:55:39,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:39,765 INFO:     Epoch: 97
2022-12-31 06:55:41,367 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4325040360291799, 'Total loss': 0.4325040360291799} | train loss {'Reaction outcome loss': 0.10800052265871153, 'Total loss': 0.10800052265871153}
2022-12-31 06:55:41,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:41,367 INFO:     Epoch: 98
2022-12-31 06:55:43,016 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4021922037005424, 'Total loss': 0.4021922037005424} | train loss {'Reaction outcome loss': 0.11184193751686354, 'Total loss': 0.11184193751686354}
2022-12-31 06:55:43,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:43,016 INFO:     Epoch: 99
2022-12-31 06:55:44,614 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3776882461582621, 'Total loss': 0.3776882461582621} | train loss {'Reaction outcome loss': 0.11665437220898286, 'Total loss': 0.11665437220898286}
2022-12-31 06:55:44,614 INFO:     Best model found after epoch 48 of 100.
2022-12-31 06:55:44,614 INFO:   Done with stage: TRAINING
2022-12-31 06:55:44,614 INFO:   Starting stage: EVALUATION
2022-12-31 06:55:44,748 INFO:   Done with stage: EVALUATION
2022-12-31 06:55:44,748 INFO:   Leaving out SEQ value Fold_3
2022-12-31 06:55:44,761 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 06:55:44,761 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:55:45,413 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:55:45,413 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:55:45,483 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:55:45,484 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:55:45,484 INFO:     No hyperparam tuning for this model
2022-12-31 06:55:45,484 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:55:45,484 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:55:45,484 INFO:     None feature selector for col prot
2022-12-31 06:55:45,485 INFO:     None feature selector for col prot
2022-12-31 06:55:45,485 INFO:     None feature selector for col prot
2022-12-31 06:55:45,485 INFO:     None feature selector for col chem
2022-12-31 06:55:45,485 INFO:     None feature selector for col chem
2022-12-31 06:55:45,485 INFO:     None feature selector for col chem
2022-12-31 06:55:45,485 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:55:45,485 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:55:45,487 INFO:     Number of params in model 224011
2022-12-31 06:55:45,490 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:55:45,491 INFO:   Starting stage: TRAINING
2022-12-31 06:55:45,536 INFO:     Val loss before train {'Reaction outcome loss': 0.9619551817576091, 'Total loss': 0.9619551817576091}
2022-12-31 06:55:45,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:45,536 INFO:     Epoch: 0
2022-12-31 06:55:47,141 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5185270130634307, 'Total loss': 0.5185270130634307} | train loss {'Reaction outcome loss': 0.7690828784103811, 'Total loss': 0.7690828784103811}
2022-12-31 06:55:47,141 INFO:     Found new best model at epoch 0
2022-12-31 06:55:47,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:47,142 INFO:     Epoch: 1
2022-12-31 06:55:48,736 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44727464616298673, 'Total loss': 0.44727464616298673} | train loss {'Reaction outcome loss': 0.5066910431767903, 'Total loss': 0.5066910431767903}
2022-12-31 06:55:48,737 INFO:     Found new best model at epoch 1
2022-12-31 06:55:48,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:48,738 INFO:     Epoch: 2
2022-12-31 06:55:50,344 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44711167315642036, 'Total loss': 0.44711167315642036} | train loss {'Reaction outcome loss': 0.44398076244949425, 'Total loss': 0.44398076244949425}
2022-12-31 06:55:50,344 INFO:     Found new best model at epoch 2
2022-12-31 06:55:50,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:50,345 INFO:     Epoch: 3
2022-12-31 06:55:51,956 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42215499877929685, 'Total loss': 0.42215499877929685} | train loss {'Reaction outcome loss': 0.4061468034765146, 'Total loss': 0.4061468034765146}
2022-12-31 06:55:51,956 INFO:     Found new best model at epoch 3
2022-12-31 06:55:51,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:51,957 INFO:     Epoch: 4
2022-12-31 06:55:53,566 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43190303444862366, 'Total loss': 0.43190303444862366} | train loss {'Reaction outcome loss': 0.3780628857168838, 'Total loss': 0.3780628857168838}
2022-12-31 06:55:53,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:53,567 INFO:     Epoch: 5
2022-12-31 06:55:55,178 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4007629056771596, 'Total loss': 0.4007629056771596} | train loss {'Reaction outcome loss': 0.35177963420096103, 'Total loss': 0.35177963420096103}
2022-12-31 06:55:55,179 INFO:     Found new best model at epoch 5
2022-12-31 06:55:55,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:55,180 INFO:     Epoch: 6
2022-12-31 06:55:56,783 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3778556843598684, 'Total loss': 0.3778556843598684} | train loss {'Reaction outcome loss': 0.3325558235719256, 'Total loss': 0.3325558235719256}
2022-12-31 06:55:56,783 INFO:     Found new best model at epoch 6
2022-12-31 06:55:56,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:56,784 INFO:     Epoch: 7
2022-12-31 06:55:58,388 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37807208597660064, 'Total loss': 0.37807208597660064} | train loss {'Reaction outcome loss': 0.3141377440714923, 'Total loss': 0.3141377440714923}
2022-12-31 06:55:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:55:58,388 INFO:     Epoch: 8
2022-12-31 06:56:00,002 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38734786411126454, 'Total loss': 0.38734786411126454} | train loss {'Reaction outcome loss': 0.29814250238348533, 'Total loss': 0.29814250238348533}
2022-12-31 06:56:00,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:00,003 INFO:     Epoch: 9
2022-12-31 06:56:01,619 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3696406622727712, 'Total loss': 0.3696406622727712} | train loss {'Reaction outcome loss': 0.28661835666773094, 'Total loss': 0.28661835666773094}
2022-12-31 06:56:01,619 INFO:     Found new best model at epoch 9
2022-12-31 06:56:01,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:01,620 INFO:     Epoch: 10
2022-12-31 06:56:03,234 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.432483047246933, 'Total loss': 0.432483047246933} | train loss {'Reaction outcome loss': 0.2716518029788115, 'Total loss': 0.2716518029788115}
2022-12-31 06:56:03,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:03,234 INFO:     Epoch: 11
2022-12-31 06:56:04,848 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4026159743467967, 'Total loss': 0.4026159743467967} | train loss {'Reaction outcome loss': 0.2618646267937483, 'Total loss': 0.2618646267937483}
2022-12-31 06:56:04,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:04,848 INFO:     Epoch: 12
2022-12-31 06:56:06,456 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4066685736179352, 'Total loss': 0.4066685736179352} | train loss {'Reaction outcome loss': 0.25093799942329414, 'Total loss': 0.25093799942329414}
2022-12-31 06:56:06,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:06,457 INFO:     Epoch: 13
2022-12-31 06:56:08,064 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3975543171167374, 'Total loss': 0.3975543171167374} | train loss {'Reaction outcome loss': 0.24456355451558628, 'Total loss': 0.24456355451558628}
2022-12-31 06:56:08,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:08,065 INFO:     Epoch: 14
2022-12-31 06:56:09,679 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38181540767351785, 'Total loss': 0.38181540767351785} | train loss {'Reaction outcome loss': 0.23605226852462022, 'Total loss': 0.23605226852462022}
2022-12-31 06:56:09,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:09,679 INFO:     Epoch: 15
2022-12-31 06:56:11,281 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4219555050134659, 'Total loss': 0.4219555050134659} | train loss {'Reaction outcome loss': 0.22494764606991824, 'Total loss': 0.22494764606991824}
2022-12-31 06:56:11,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:11,281 INFO:     Epoch: 16
2022-12-31 06:56:12,889 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4101406047741572, 'Total loss': 0.4101406047741572} | train loss {'Reaction outcome loss': 0.22186226165262016, 'Total loss': 0.22186226165262016}
2022-12-31 06:56:12,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:12,889 INFO:     Epoch: 17
2022-12-31 06:56:14,484 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37553857068220775, 'Total loss': 0.37553857068220775} | train loss {'Reaction outcome loss': 0.2105694481300829, 'Total loss': 0.2105694481300829}
2022-12-31 06:56:14,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:14,484 INFO:     Epoch: 18
2022-12-31 06:56:16,126 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4063109576702118, 'Total loss': 0.4063109576702118} | train loss {'Reaction outcome loss': 0.20380052508799917, 'Total loss': 0.20380052508799917}
2022-12-31 06:56:16,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:16,126 INFO:     Epoch: 19
2022-12-31 06:56:17,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4078525568048159, 'Total loss': 0.4078525568048159} | train loss {'Reaction outcome loss': 0.2008060463126341, 'Total loss': 0.2008060463126341}
2022-12-31 06:56:17,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:17,729 INFO:     Epoch: 20
2022-12-31 06:56:19,379 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41080207924048107, 'Total loss': 0.41080207924048107} | train loss {'Reaction outcome loss': 0.1956968474793282, 'Total loss': 0.1956968474793282}
2022-12-31 06:56:19,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:19,379 INFO:     Epoch: 21
2022-12-31 06:56:21,030 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4002330183982849, 'Total loss': 0.4002330183982849} | train loss {'Reaction outcome loss': 0.1931287293410758, 'Total loss': 0.1931287293410758}
2022-12-31 06:56:21,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:21,030 INFO:     Epoch: 22
2022-12-31 06:56:22,681 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41771730581919353, 'Total loss': 0.41771730581919353} | train loss {'Reaction outcome loss': 0.1871558712237943, 'Total loss': 0.1871558712237943}
2022-12-31 06:56:22,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:22,681 INFO:     Epoch: 23
2022-12-31 06:56:24,297 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42638497352600097, 'Total loss': 0.42638497352600097} | train loss {'Reaction outcome loss': 0.1830487365759637, 'Total loss': 0.1830487365759637}
2022-12-31 06:56:24,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:24,298 INFO:     Epoch: 24
2022-12-31 06:56:25,936 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4161817048986753, 'Total loss': 0.4161817048986753} | train loss {'Reaction outcome loss': 0.18035472140912592, 'Total loss': 0.18035472140912592}
2022-12-31 06:56:25,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:25,937 INFO:     Epoch: 25
2022-12-31 06:56:27,548 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40558861891428627, 'Total loss': 0.40558861891428627} | train loss {'Reaction outcome loss': 0.17643004658557201, 'Total loss': 0.17643004658557201}
2022-12-31 06:56:27,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:27,548 INFO:     Epoch: 26
2022-12-31 06:56:29,198 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4213182717561722, 'Total loss': 0.4213182717561722} | train loss {'Reaction outcome loss': 0.17230862236316621, 'Total loss': 0.17230862236316621}
2022-12-31 06:56:29,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:29,198 INFO:     Epoch: 27
2022-12-31 06:56:30,849 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41065785884857176, 'Total loss': 0.41065785884857176} | train loss {'Reaction outcome loss': 0.16957113996528797, 'Total loss': 0.16957113996528797}
2022-12-31 06:56:30,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:30,849 INFO:     Epoch: 28
2022-12-31 06:56:32,461 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4153636783361435, 'Total loss': 0.4153636783361435} | train loss {'Reaction outcome loss': 0.17142715074978496, 'Total loss': 0.17142715074978496}
2022-12-31 06:56:32,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:32,462 INFO:     Epoch: 29
2022-12-31 06:56:34,075 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4331102738777796, 'Total loss': 0.4331102738777796} | train loss {'Reaction outcome loss': 0.16432232840707267, 'Total loss': 0.16432232840707267}
2022-12-31 06:56:34,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:34,075 INFO:     Epoch: 30
2022-12-31 06:56:35,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41473499735196434, 'Total loss': 0.41473499735196434} | train loss {'Reaction outcome loss': 0.16164534667805924, 'Total loss': 0.16164534667805924}
2022-12-31 06:56:35,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:35,685 INFO:     Epoch: 31
2022-12-31 06:56:37,349 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4150044580300649, 'Total loss': 0.4150044580300649} | train loss {'Reaction outcome loss': 0.16100513148563403, 'Total loss': 0.16100513148563403}
2022-12-31 06:56:37,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:37,349 INFO:     Epoch: 32
2022-12-31 06:56:38,958 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39902513722578686, 'Total loss': 0.39902513722578686} | train loss {'Reaction outcome loss': 0.15813479352280171, 'Total loss': 0.15813479352280171}
2022-12-31 06:56:38,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:38,959 INFO:     Epoch: 33
2022-12-31 06:56:40,628 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40198599845170974, 'Total loss': 0.40198599845170974} | train loss {'Reaction outcome loss': 0.15451011920592536, 'Total loss': 0.15451011920592536}
2022-12-31 06:56:40,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:40,628 INFO:     Epoch: 34
2022-12-31 06:56:42,238 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4077305210754275, 'Total loss': 0.4077305210754275} | train loss {'Reaction outcome loss': 0.156318559403103, 'Total loss': 0.156318559403103}
2022-12-31 06:56:42,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:42,238 INFO:     Epoch: 35
2022-12-31 06:56:43,847 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4177360365788142, 'Total loss': 0.4177360365788142} | train loss {'Reaction outcome loss': 0.15396389701016192, 'Total loss': 0.15396389701016192}
2022-12-31 06:56:43,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:43,848 INFO:     Epoch: 36
2022-12-31 06:56:45,507 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40549388031164807, 'Total loss': 0.40549388031164807} | train loss {'Reaction outcome loss': 0.15181828795483568, 'Total loss': 0.15181828795483568}
2022-12-31 06:56:45,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:45,507 INFO:     Epoch: 37
2022-12-31 06:56:47,140 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42998071809609734, 'Total loss': 0.42998071809609734} | train loss {'Reaction outcome loss': 0.14876497296589244, 'Total loss': 0.14876497296589244}
2022-12-31 06:56:47,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:47,140 INFO:     Epoch: 38
2022-12-31 06:56:48,747 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4697283963362376, 'Total loss': 0.4697283963362376} | train loss {'Reaction outcome loss': 0.14636729372474944, 'Total loss': 0.14636729372474944}
2022-12-31 06:56:48,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:48,747 INFO:     Epoch: 39
2022-12-31 06:56:50,353 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.404590701063474, 'Total loss': 0.404590701063474} | train loss {'Reaction outcome loss': 0.14579733497680702, 'Total loss': 0.14579733497680702}
2022-12-31 06:56:50,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:50,353 INFO:     Epoch: 40
2022-12-31 06:56:51,968 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37969373216231667, 'Total loss': 0.37969373216231667} | train loss {'Reaction outcome loss': 0.14497951702996545, 'Total loss': 0.14497951702996545}
2022-12-31 06:56:51,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:51,968 INFO:     Epoch: 41
2022-12-31 06:56:53,571 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45093158781528475, 'Total loss': 0.45093158781528475} | train loss {'Reaction outcome loss': 0.1430436312085031, 'Total loss': 0.1430436312085031}
2022-12-31 06:56:53,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:53,571 INFO:     Epoch: 42
2022-12-31 06:56:55,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4051498552163442, 'Total loss': 0.4051498552163442} | train loss {'Reaction outcome loss': 0.1440805892951202, 'Total loss': 0.1440805892951202}
2022-12-31 06:56:55,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:55,183 INFO:     Epoch: 43
2022-12-31 06:56:56,796 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42160242845614754, 'Total loss': 0.42160242845614754} | train loss {'Reaction outcome loss': 0.14396008193139395, 'Total loss': 0.14396008193139395}
2022-12-31 06:56:56,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:56,796 INFO:     Epoch: 44
2022-12-31 06:56:58,409 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4156916946172714, 'Total loss': 0.4156916946172714} | train loss {'Reaction outcome loss': 0.13711025071140026, 'Total loss': 0.13711025071140026}
2022-12-31 06:56:58,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:56:58,410 INFO:     Epoch: 45
2022-12-31 06:57:00,016 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4332997570435206, 'Total loss': 0.4332997570435206} | train loss {'Reaction outcome loss': 0.13696683357965989, 'Total loss': 0.13696683357965989}
2022-12-31 06:57:00,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:00,016 INFO:     Epoch: 46
2022-12-31 06:57:01,613 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41947129170099895, 'Total loss': 0.41947129170099895} | train loss {'Reaction outcome loss': 0.13380626802856144, 'Total loss': 0.13380626802856144}
2022-12-31 06:57:01,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:01,614 INFO:     Epoch: 47
2022-12-31 06:57:03,219 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.443395866950353, 'Total loss': 0.443395866950353} | train loss {'Reaction outcome loss': 0.13655790497283757, 'Total loss': 0.13655790497283757}
2022-12-31 06:57:03,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:03,219 INFO:     Epoch: 48
2022-12-31 06:57:04,820 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4335161030292511, 'Total loss': 0.4335161030292511} | train loss {'Reaction outcome loss': 0.13369632117028762, 'Total loss': 0.13369632117028762}
2022-12-31 06:57:04,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:04,821 INFO:     Epoch: 49
2022-12-31 06:57:06,420 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4405663887659709, 'Total loss': 0.4405663887659709} | train loss {'Reaction outcome loss': 0.13097106642769582, 'Total loss': 0.13097106642769582}
2022-12-31 06:57:06,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:06,420 INFO:     Epoch: 50
2022-12-31 06:57:08,023 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4451925953229268, 'Total loss': 0.4451925953229268} | train loss {'Reaction outcome loss': 0.1328347811788103, 'Total loss': 0.1328347811788103}
2022-12-31 06:57:08,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:08,023 INFO:     Epoch: 51
2022-12-31 06:57:09,623 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4238132397333781, 'Total loss': 0.4238132397333781} | train loss {'Reaction outcome loss': 0.13158472377405822, 'Total loss': 0.13158472377405822}
2022-12-31 06:57:09,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:09,624 INFO:     Epoch: 52
2022-12-31 06:57:11,256 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4449714293082555, 'Total loss': 0.4449714293082555} | train loss {'Reaction outcome loss': 0.1280405965419554, 'Total loss': 0.1280405965419554}
2022-12-31 06:57:11,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:11,256 INFO:     Epoch: 53
2022-12-31 06:57:12,867 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4590103715658188, 'Total loss': 0.4590103715658188} | train loss {'Reaction outcome loss': 0.12945858178741848, 'Total loss': 0.12945858178741848}
2022-12-31 06:57:12,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:12,868 INFO:     Epoch: 54
2022-12-31 06:57:14,480 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4110140837728977, 'Total loss': 0.4110140837728977} | train loss {'Reaction outcome loss': 0.12833917804443054, 'Total loss': 0.12833917804443054}
2022-12-31 06:57:14,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:14,480 INFO:     Epoch: 55
2022-12-31 06:57:16,093 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4381348709265391, 'Total loss': 0.4381348709265391} | train loss {'Reaction outcome loss': 0.1271991672284942, 'Total loss': 0.1271991672284942}
2022-12-31 06:57:16,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:16,093 INFO:     Epoch: 56
2022-12-31 06:57:17,706 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4406741216778755, 'Total loss': 0.4406741216778755} | train loss {'Reaction outcome loss': 0.12977307720320558, 'Total loss': 0.12977307720320558}
2022-12-31 06:57:17,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:17,706 INFO:     Epoch: 57
2022-12-31 06:57:19,334 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43445033530394234, 'Total loss': 0.43445033530394234} | train loss {'Reaction outcome loss': 0.12769921765030517, 'Total loss': 0.12769921765030517}
2022-12-31 06:57:19,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:19,334 INFO:     Epoch: 58
2022-12-31 06:57:20,950 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4589011788368225, 'Total loss': 0.4589011788368225} | train loss {'Reaction outcome loss': 0.12517637225891035, 'Total loss': 0.12517637225891035}
2022-12-31 06:57:20,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:20,951 INFO:     Epoch: 59
2022-12-31 06:57:22,560 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4291528950134913, 'Total loss': 0.4291528950134913} | train loss {'Reaction outcome loss': 0.12518146871521144, 'Total loss': 0.12518146871521144}
2022-12-31 06:57:22,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:22,560 INFO:     Epoch: 60
2022-12-31 06:57:24,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4315970013538996, 'Total loss': 0.4315970013538996} | train loss {'Reaction outcome loss': 0.12461410581990805, 'Total loss': 0.12461410581990805}
2022-12-31 06:57:24,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:24,210 INFO:     Epoch: 61
2022-12-31 06:57:25,860 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45707805156707765, 'Total loss': 0.45707805156707765} | train loss {'Reaction outcome loss': 0.1259870554055393, 'Total loss': 0.1259870554055393}
2022-12-31 06:57:25,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:25,861 INFO:     Epoch: 62
2022-12-31 06:57:27,470 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44491907271246117, 'Total loss': 0.44491907271246117} | train loss {'Reaction outcome loss': 0.12343793917603682, 'Total loss': 0.12343793917603682}
2022-12-31 06:57:27,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:27,470 INFO:     Epoch: 63
2022-12-31 06:57:29,119 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4470601042111715, 'Total loss': 0.4470601042111715} | train loss {'Reaction outcome loss': 0.12256466405785704, 'Total loss': 0.12256466405785704}
2022-12-31 06:57:29,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:29,119 INFO:     Epoch: 64
2022-12-31 06:57:30,723 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44707677960395814, 'Total loss': 0.44707677960395814} | train loss {'Reaction outcome loss': 0.12105280721566919, 'Total loss': 0.12105280721566919}
2022-12-31 06:57:30,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:30,723 INFO:     Epoch: 65
2022-12-31 06:57:32,338 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4537681058049202, 'Total loss': 0.4537681058049202} | train loss {'Reaction outcome loss': 0.1233181179871606, 'Total loss': 0.1233181179871606}
2022-12-31 06:57:32,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:32,338 INFO:     Epoch: 66
2022-12-31 06:57:33,951 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4211982190608978, 'Total loss': 0.4211982190608978} | train loss {'Reaction outcome loss': 0.11706965549230358, 'Total loss': 0.11706965549230358}
2022-12-31 06:57:33,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:33,952 INFO:     Epoch: 67
2022-12-31 06:57:35,566 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4348027596871058, 'Total loss': 0.4348027596871058} | train loss {'Reaction outcome loss': 0.11990355641451957, 'Total loss': 0.11990355641451957}
2022-12-31 06:57:35,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:35,566 INFO:     Epoch: 68
2022-12-31 06:57:37,171 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4412328451871872, 'Total loss': 0.4412328451871872} | train loss {'Reaction outcome loss': 0.12435277789001808, 'Total loss': 0.12435277789001808}
2022-12-31 06:57:37,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:37,173 INFO:     Epoch: 69
2022-12-31 06:57:38,777 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42332872450351716, 'Total loss': 0.42332872450351716} | train loss {'Reaction outcome loss': 0.1191663191956298, 'Total loss': 0.1191663191956298}
2022-12-31 06:57:38,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:38,778 INFO:     Epoch: 70
2022-12-31 06:57:40,394 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42437632083892823, 'Total loss': 0.42437632083892823} | train loss {'Reaction outcome loss': 0.12761898252460427, 'Total loss': 0.12761898252460427}
2022-12-31 06:57:40,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:40,394 INFO:     Epoch: 71
2022-12-31 06:57:42,009 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.450000503162543, 'Total loss': 0.450000503162543} | train loss {'Reaction outcome loss': 0.11651337500423682, 'Total loss': 0.11651337500423682}
2022-12-31 06:57:42,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:42,009 INFO:     Epoch: 72
2022-12-31 06:57:43,623 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4549825994297862, 'Total loss': 0.4549825994297862} | train loss {'Reaction outcome loss': 0.11457610729381605, 'Total loss': 0.11457610729381605}
2022-12-31 06:57:43,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:43,624 INFO:     Epoch: 73
2022-12-31 06:57:45,236 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4338531340161959, 'Total loss': 0.4338531340161959} | train loss {'Reaction outcome loss': 0.11452569667399473, 'Total loss': 0.11452569667399473}
2022-12-31 06:57:45,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:45,236 INFO:     Epoch: 74
2022-12-31 06:57:46,841 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4704287459452947, 'Total loss': 0.4704287459452947} | train loss {'Reaction outcome loss': 0.11438205281789177, 'Total loss': 0.11438205281789177}
2022-12-31 06:57:46,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:46,841 INFO:     Epoch: 75
2022-12-31 06:57:48,448 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4626631538073222, 'Total loss': 0.4626631538073222} | train loss {'Reaction outcome loss': 0.11989162720987967, 'Total loss': 0.11989162720987967}
2022-12-31 06:57:48,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:48,448 INFO:     Epoch: 76
2022-12-31 06:57:50,063 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45982699294885, 'Total loss': 0.45982699294885} | train loss {'Reaction outcome loss': 0.11710075561609799, 'Total loss': 0.11710075561609799}
2022-12-31 06:57:50,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:50,063 INFO:     Epoch: 77
2022-12-31 06:57:51,675 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44056501165032386, 'Total loss': 0.44056501165032386} | train loss {'Reaction outcome loss': 0.11412889623239528, 'Total loss': 0.11412889623239528}
2022-12-31 06:57:51,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:51,676 INFO:     Epoch: 78
2022-12-31 06:57:53,289 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42488262355327605, 'Total loss': 0.42488262355327605} | train loss {'Reaction outcome loss': 0.11348562903641077, 'Total loss': 0.11348562903641077}
2022-12-31 06:57:53,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:53,290 INFO:     Epoch: 79
2022-12-31 06:57:54,896 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44157306998968127, 'Total loss': 0.44157306998968127} | train loss {'Reaction outcome loss': 0.11518418416210933, 'Total loss': 0.11518418416210933}
2022-12-31 06:57:54,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:54,896 INFO:     Epoch: 80
2022-12-31 06:57:56,498 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41768053819735845, 'Total loss': 0.41768053819735845} | train loss {'Reaction outcome loss': 0.1229019001802688, 'Total loss': 0.1229019001802688}
2022-12-31 06:57:56,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:56,499 INFO:     Epoch: 81
2022-12-31 06:57:58,100 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45371127128601074, 'Total loss': 0.45371127128601074} | train loss {'Reaction outcome loss': 0.11785666820640764, 'Total loss': 0.11785666820640764}
2022-12-31 06:57:58,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:58,100 INFO:     Epoch: 82
2022-12-31 06:57:59,702 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42140445013840994, 'Total loss': 0.42140445013840994} | train loss {'Reaction outcome loss': 0.11301248923137812, 'Total loss': 0.11301248923137812}
2022-12-31 06:57:59,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:57:59,702 INFO:     Epoch: 83
2022-12-31 06:58:01,350 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.451038204630216, 'Total loss': 0.451038204630216} | train loss {'Reaction outcome loss': 0.11208443329193676, 'Total loss': 0.11208443329193676}
2022-12-31 06:58:01,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:01,351 INFO:     Epoch: 84
2022-12-31 06:58:02,952 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4391793777545293, 'Total loss': 0.4391793777545293} | train loss {'Reaction outcome loss': 0.11274614813482647, 'Total loss': 0.11274614813482647}
2022-12-31 06:58:02,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:02,952 INFO:     Epoch: 85
2022-12-31 06:58:04,572 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41413532495498656, 'Total loss': 0.41413532495498656} | train loss {'Reaction outcome loss': 0.11573208753107946, 'Total loss': 0.11573208753107946}
2022-12-31 06:58:04,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:04,572 INFO:     Epoch: 86
2022-12-31 06:58:06,173 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4526242313285669, 'Total loss': 0.4526242313285669} | train loss {'Reaction outcome loss': 0.11249853835532944, 'Total loss': 0.11249853835532944}
2022-12-31 06:58:06,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:06,173 INFO:     Epoch: 87
2022-12-31 06:58:07,788 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47095232804616294, 'Total loss': 0.47095232804616294} | train loss {'Reaction outcome loss': 0.1166176201255625, 'Total loss': 0.1166176201255625}
2022-12-31 06:58:07,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:07,788 INFO:     Epoch: 88
2022-12-31 06:58:09,400 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4157384971777598, 'Total loss': 0.4157384971777598} | train loss {'Reaction outcome loss': 0.11626269572319287, 'Total loss': 0.11626269572319287}
2022-12-31 06:58:09,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:09,401 INFO:     Epoch: 89
2022-12-31 06:58:11,017 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47426492621501287, 'Total loss': 0.47426492621501287} | train loss {'Reaction outcome loss': 0.11176136394208093, 'Total loss': 0.11176136394208093}
2022-12-31 06:58:11,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:11,017 INFO:     Epoch: 90
2022-12-31 06:58:12,625 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4406269431114197, 'Total loss': 0.4406269431114197} | train loss {'Reaction outcome loss': 0.11587516721473994, 'Total loss': 0.11587516721473994}
2022-12-31 06:58:12,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:12,626 INFO:     Epoch: 91
2022-12-31 06:58:14,235 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44514093101024627, 'Total loss': 0.44514093101024627} | train loss {'Reaction outcome loss': 0.11752206930273763, 'Total loss': 0.11752206930273763}
2022-12-31 06:58:14,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:14,236 INFO:     Epoch: 92
2022-12-31 06:58:15,867 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46099184453487396, 'Total loss': 0.46099184453487396} | train loss {'Reaction outcome loss': 0.11422630347163641, 'Total loss': 0.11422630347163641}
2022-12-31 06:58:15,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:15,867 INFO:     Epoch: 93
2022-12-31 06:58:17,517 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41798274566729865, 'Total loss': 0.41798274566729865} | train loss {'Reaction outcome loss': 0.1130778980832275, 'Total loss': 0.1130778980832275}
2022-12-31 06:58:17,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:17,517 INFO:     Epoch: 94
2022-12-31 06:58:19,166 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44203836234907307, 'Total loss': 0.44203836234907307} | train loss {'Reaction outcome loss': 0.11232678651687329, 'Total loss': 0.11232678651687329}
2022-12-31 06:58:19,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:19,167 INFO:     Epoch: 95
2022-12-31 06:58:20,771 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44839340075850487, 'Total loss': 0.44839340075850487} | train loss {'Reaction outcome loss': 0.11184988153612337, 'Total loss': 0.11184988153612337}
2022-12-31 06:58:20,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:20,771 INFO:     Epoch: 96
2022-12-31 06:58:22,409 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4407923609018326, 'Total loss': 0.4407923609018326} | train loss {'Reaction outcome loss': 0.10610539205780212, 'Total loss': 0.10610539205780212}
2022-12-31 06:58:22,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:22,409 INFO:     Epoch: 97
2022-12-31 06:58:24,043 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4329216549793879, 'Total loss': 0.4329216549793879} | train loss {'Reaction outcome loss': 0.11148057276736537, 'Total loss': 0.11148057276736537}
2022-12-31 06:58:24,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:24,044 INFO:     Epoch: 98
2022-12-31 06:58:25,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4328173632423083, 'Total loss': 0.4328173632423083} | train loss {'Reaction outcome loss': 0.11204567238990978, 'Total loss': 0.11204567238990978}
2022-12-31 06:58:25,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:25,656 INFO:     Epoch: 99
2022-12-31 06:58:27,268 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4416569024324417, 'Total loss': 0.4416569024324417} | train loss {'Reaction outcome loss': 0.11339603070455202, 'Total loss': 0.11339603070455202}
2022-12-31 06:58:27,269 INFO:     Best model found after epoch 10 of 100.
2022-12-31 06:58:27,269 INFO:   Done with stage: TRAINING
2022-12-31 06:58:27,269 INFO:   Starting stage: EVALUATION
2022-12-31 06:58:27,406 INFO:   Done with stage: EVALUATION
2022-12-31 06:58:27,406 INFO:   Leaving out SEQ value Fold_4
2022-12-31 06:58:27,419 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 06:58:27,419 INFO:   Starting stage: FEATURE SCALING
2022-12-31 06:58:28,069 INFO:   Done with stage: FEATURE SCALING
2022-12-31 06:58:28,069 INFO:   Starting stage: SCALING TARGETS
2022-12-31 06:58:28,139 INFO:   Done with stage: SCALING TARGETS
2022-12-31 06:58:28,139 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:58:28,139 INFO:     No hyperparam tuning for this model
2022-12-31 06:58:28,139 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 06:58:28,139 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 06:58:28,140 INFO:     None feature selector for col prot
2022-12-31 06:58:28,140 INFO:     None feature selector for col prot
2022-12-31 06:58:28,140 INFO:     None feature selector for col prot
2022-12-31 06:58:28,141 INFO:     None feature selector for col chem
2022-12-31 06:58:28,141 INFO:     None feature selector for col chem
2022-12-31 06:58:28,141 INFO:     None feature selector for col chem
2022-12-31 06:58:28,141 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 06:58:28,141 INFO:   Starting stage: BUILD MODEL
2022-12-31 06:58:28,143 INFO:     Number of params in model 224011
2022-12-31 06:58:28,146 INFO:   Done with stage: BUILD MODEL
2022-12-31 06:58:28,146 INFO:   Starting stage: TRAINING
2022-12-31 06:58:28,191 INFO:     Val loss before train {'Reaction outcome loss': 0.9093695163726807, 'Total loss': 0.9093695163726807}
2022-12-31 06:58:28,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:28,192 INFO:     Epoch: 0
2022-12-31 06:58:29,812 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5315451403458913, 'Total loss': 0.5315451403458913} | train loss {'Reaction outcome loss': 0.7688054719600705, 'Total loss': 0.7688054719600705}
2022-12-31 06:58:29,812 INFO:     Found new best model at epoch 0
2022-12-31 06:58:29,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:29,813 INFO:     Epoch: 1
2022-12-31 06:58:31,433 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4779638071854909, 'Total loss': 0.4779638071854909} | train loss {'Reaction outcome loss': 0.48898141064505646, 'Total loss': 0.48898141064505646}
2022-12-31 06:58:31,434 INFO:     Found new best model at epoch 1
2022-12-31 06:58:31,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:31,435 INFO:     Epoch: 2
2022-12-31 06:58:33,050 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.432030114531517, 'Total loss': 0.432030114531517} | train loss {'Reaction outcome loss': 0.4284631235084658, 'Total loss': 0.4284631235084658}
2022-12-31 06:58:33,050 INFO:     Found new best model at epoch 2
2022-12-31 06:58:33,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:33,051 INFO:     Epoch: 3
2022-12-31 06:58:34,666 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.39015314877033236, 'Total loss': 0.39015314877033236} | train loss {'Reaction outcome loss': 0.39075146020268614, 'Total loss': 0.39075146020268614}
2022-12-31 06:58:34,667 INFO:     Found new best model at epoch 3
2022-12-31 06:58:34,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:34,668 INFO:     Epoch: 4
2022-12-31 06:58:36,284 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39584821164608003, 'Total loss': 0.39584821164608003} | train loss {'Reaction outcome loss': 0.36581034965754533, 'Total loss': 0.36581034965754533}
2022-12-31 06:58:36,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:36,284 INFO:     Epoch: 5
2022-12-31 06:58:37,946 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40418327450752256, 'Total loss': 0.40418327450752256} | train loss {'Reaction outcome loss': 0.3398493693739115, 'Total loss': 0.3398493693739115}
2022-12-31 06:58:37,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:37,946 INFO:     Epoch: 6
2022-12-31 06:58:39,608 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37022912402947744, 'Total loss': 0.37022912402947744} | train loss {'Reaction outcome loss': 0.3194434401779343, 'Total loss': 0.3194434401779343}
2022-12-31 06:58:39,608 INFO:     Found new best model at epoch 6
2022-12-31 06:58:39,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:39,610 INFO:     Epoch: 7
2022-12-31 06:58:41,228 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3761681914329529, 'Total loss': 0.3761681914329529} | train loss {'Reaction outcome loss': 0.3040520190095223, 'Total loss': 0.3040520190095223}
2022-12-31 06:58:41,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:41,228 INFO:     Epoch: 8
2022-12-31 06:58:42,875 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3888981501261393, 'Total loss': 0.3888981501261393} | train loss {'Reaction outcome loss': 0.2854800349931516, 'Total loss': 0.2854800349931516}
2022-12-31 06:58:42,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:42,877 INFO:     Epoch: 9
2022-12-31 06:58:44,493 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3527667671442032, 'Total loss': 0.3527667671442032} | train loss {'Reaction outcome loss': 0.2738161425403224, 'Total loss': 0.2738161425403224}
2022-12-31 06:58:44,494 INFO:     Found new best model at epoch 9
2022-12-31 06:58:44,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:44,495 INFO:     Epoch: 10
2022-12-31 06:58:46,119 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.36277025640010835, 'Total loss': 0.36277025640010835} | train loss {'Reaction outcome loss': 0.26243680400142877, 'Total loss': 0.26243680400142877}
2022-12-31 06:58:46,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:46,119 INFO:     Epoch: 11
2022-12-31 06:58:47,737 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34894847373167676, 'Total loss': 0.34894847373167676} | train loss {'Reaction outcome loss': 0.24962359248404054, 'Total loss': 0.24962359248404054}
2022-12-31 06:58:47,737 INFO:     Found new best model at epoch 11
2022-12-31 06:58:47,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:47,738 INFO:     Epoch: 12
2022-12-31 06:58:49,366 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37287334402402245, 'Total loss': 0.37287334402402245} | train loss {'Reaction outcome loss': 0.24224330112506784, 'Total loss': 0.24224330112506784}
2022-12-31 06:58:49,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:49,366 INFO:     Epoch: 13
2022-12-31 06:58:50,985 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35815718670686086, 'Total loss': 0.35815718670686086} | train loss {'Reaction outcome loss': 0.2307814539855589, 'Total loss': 0.2307814539855589}
2022-12-31 06:58:50,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:50,985 INFO:     Epoch: 14
2022-12-31 06:58:52,594 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3649187942345937, 'Total loss': 0.3649187942345937} | train loss {'Reaction outcome loss': 0.22470260755685362, 'Total loss': 0.22470260755685362}
2022-12-31 06:58:52,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:52,594 INFO:     Epoch: 15
2022-12-31 06:58:54,211 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3403590505321821, 'Total loss': 0.3403590505321821} | train loss {'Reaction outcome loss': 0.2129478259189257, 'Total loss': 0.2129478259189257}
2022-12-31 06:58:54,211 INFO:     Found new best model at epoch 15
2022-12-31 06:58:54,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:54,212 INFO:     Epoch: 16
2022-12-31 06:58:55,830 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3836543281873067, 'Total loss': 0.3836543281873067} | train loss {'Reaction outcome loss': 0.2073478150403758, 'Total loss': 0.2073478150403758}
2022-12-31 06:58:55,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:55,830 INFO:     Epoch: 17
2022-12-31 06:58:57,491 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37810606757799786, 'Total loss': 0.37810606757799786} | train loss {'Reaction outcome loss': 0.20822521560973878, 'Total loss': 0.20822521560973878}
2022-12-31 06:58:57,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:57,491 INFO:     Epoch: 18
2022-12-31 06:58:59,119 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3749039133389791, 'Total loss': 0.3749039133389791} | train loss {'Reaction outcome loss': 0.21486649248644413, 'Total loss': 0.21486649248644413}
2022-12-31 06:58:59,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:58:59,120 INFO:     Epoch: 19
2022-12-31 06:59:00,748 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3767500758171082, 'Total loss': 0.3767500758171082} | train loss {'Reaction outcome loss': 0.19307536395744124, 'Total loss': 0.19307536395744124}
2022-12-31 06:59:00,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:00,748 INFO:     Epoch: 20
2022-12-31 06:59:02,408 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3571052898963292, 'Total loss': 0.3571052898963292} | train loss {'Reaction outcome loss': 0.18666983458546305, 'Total loss': 0.18666983458546305}
2022-12-31 06:59:02,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:02,409 INFO:     Epoch: 21
2022-12-31 06:59:04,024 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3831785579522451, 'Total loss': 0.3831785579522451} | train loss {'Reaction outcome loss': 0.17929111599949174, 'Total loss': 0.17929111599949174}
2022-12-31 06:59:04,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:04,024 INFO:     Epoch: 22
2022-12-31 06:59:05,686 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37830114165941875, 'Total loss': 0.37830114165941875} | train loss {'Reaction outcome loss': 0.17817759420047852, 'Total loss': 0.17817759420047852}
2022-12-31 06:59:05,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:05,686 INFO:     Epoch: 23
2022-12-31 06:59:07,300 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3847895284493764, 'Total loss': 0.3847895284493764} | train loss {'Reaction outcome loss': 0.17520897622413967, 'Total loss': 0.17520897622413967}
2022-12-31 06:59:07,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:07,301 INFO:     Epoch: 24
2022-12-31 06:59:08,926 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3720507095257441, 'Total loss': 0.3720507095257441} | train loss {'Reaction outcome loss': 0.17009572020016503, 'Total loss': 0.17009572020016503}
2022-12-31 06:59:08,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:08,926 INFO:     Epoch: 25
2022-12-31 06:59:10,579 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3667483747005463, 'Total loss': 0.3667483747005463} | train loss {'Reaction outcome loss': 0.18220573221190475, 'Total loss': 0.18220573221190475}
2022-12-31 06:59:10,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:10,579 INFO:     Epoch: 26
2022-12-31 06:59:12,242 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38260118116935093, 'Total loss': 0.38260118116935093} | train loss {'Reaction outcome loss': 0.16477834005448697, 'Total loss': 0.16477834005448697}
2022-12-31 06:59:12,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:12,242 INFO:     Epoch: 27
2022-12-31 06:59:13,904 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3774339308341344, 'Total loss': 0.3774339308341344} | train loss {'Reaction outcome loss': 0.15916598977513047, 'Total loss': 0.15916598977513047}
2022-12-31 06:59:13,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:13,904 INFO:     Epoch: 28
2022-12-31 06:59:15,522 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39362077762683234, 'Total loss': 0.39362077762683234} | train loss {'Reaction outcome loss': 0.15703788058886278, 'Total loss': 0.15703788058886278}
2022-12-31 06:59:15,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:15,522 INFO:     Epoch: 29
2022-12-31 06:59:17,171 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3840430438518524, 'Total loss': 0.3840430438518524} | train loss {'Reaction outcome loss': 0.1603956162580289, 'Total loss': 0.1603956162580289}
2022-12-31 06:59:17,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:17,171 INFO:     Epoch: 30
2022-12-31 06:59:18,819 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34898270964622496, 'Total loss': 0.34898270964622496} | train loss {'Reaction outcome loss': 0.15449822406736674, 'Total loss': 0.15449822406736674}
2022-12-31 06:59:18,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:18,820 INFO:     Epoch: 31
2022-12-31 06:59:20,438 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3761914243300756, 'Total loss': 0.3761914243300756} | train loss {'Reaction outcome loss': 0.14940835325978696, 'Total loss': 0.14940835325978696}
2022-12-31 06:59:20,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:20,438 INFO:     Epoch: 32
2022-12-31 06:59:22,100 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.380944953362147, 'Total loss': 0.380944953362147} | train loss {'Reaction outcome loss': 0.15337894900796423, 'Total loss': 0.15337894900796423}
2022-12-31 06:59:22,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:22,100 INFO:     Epoch: 33
2022-12-31 06:59:23,760 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3862295962870121, 'Total loss': 0.3862295962870121} | train loss {'Reaction outcome loss': 0.18257114365764393, 'Total loss': 0.18257114365764393}
2022-12-31 06:59:23,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:23,761 INFO:     Epoch: 34
2022-12-31 06:59:25,420 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3826443572839101, 'Total loss': 0.3826443572839101} | train loss {'Reaction outcome loss': 0.15202345241002901, 'Total loss': 0.15202345241002901}
2022-12-31 06:59:25,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:25,421 INFO:     Epoch: 35
2022-12-31 06:59:27,033 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38276319205760956, 'Total loss': 0.38276319205760956} | train loss {'Reaction outcome loss': 0.14591906200792806, 'Total loss': 0.14591906200792806}
2022-12-31 06:59:27,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:27,033 INFO:     Epoch: 36
2022-12-31 06:59:28,649 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3851874250608186, 'Total loss': 0.3851874250608186} | train loss {'Reaction outcome loss': 0.1432568361940313, 'Total loss': 0.1432568361940313}
2022-12-31 06:59:28,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:28,650 INFO:     Epoch: 37
2022-12-31 06:59:30,268 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.390189117193222, 'Total loss': 0.390189117193222} | train loss {'Reaction outcome loss': 0.14078201477726301, 'Total loss': 0.14078201477726301}
2022-12-31 06:59:30,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:30,268 INFO:     Epoch: 38
2022-12-31 06:59:31,886 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40123713860909144, 'Total loss': 0.40123713860909144} | train loss {'Reaction outcome loss': 0.1388563120385895, 'Total loss': 0.1388563120385895}
2022-12-31 06:59:31,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:31,886 INFO:     Epoch: 39
2022-12-31 06:59:33,510 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3935215552647909, 'Total loss': 0.3935215552647909} | train loss {'Reaction outcome loss': 0.136135639009729, 'Total loss': 0.136135639009729}
2022-12-31 06:59:33,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:33,510 INFO:     Epoch: 40
2022-12-31 06:59:35,149 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3983370711406072, 'Total loss': 0.3983370711406072} | train loss {'Reaction outcome loss': 0.13671350745194039, 'Total loss': 0.13671350745194039}
2022-12-31 06:59:35,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:35,149 INFO:     Epoch: 41
2022-12-31 06:59:36,805 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3760653247435888, 'Total loss': 0.3760653247435888} | train loss {'Reaction outcome loss': 0.13699915115116248, 'Total loss': 0.13699915115116248}
2022-12-31 06:59:36,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:36,805 INFO:     Epoch: 42
2022-12-31 06:59:38,424 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.376913191874822, 'Total loss': 0.376913191874822} | train loss {'Reaction outcome loss': 0.13244784921340214, 'Total loss': 0.13244784921340214}
2022-12-31 06:59:38,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:38,425 INFO:     Epoch: 43
2022-12-31 06:59:40,050 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3807764324049155, 'Total loss': 0.3807764324049155} | train loss {'Reaction outcome loss': 0.1271994694530883, 'Total loss': 0.1271994694530883}
2022-12-31 06:59:40,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:40,050 INFO:     Epoch: 44
2022-12-31 06:59:41,713 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37163720826307933, 'Total loss': 0.37163720826307933} | train loss {'Reaction outcome loss': 0.12864499724199288, 'Total loss': 0.12864499724199288}
2022-12-31 06:59:41,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:41,713 INFO:     Epoch: 45
2022-12-31 06:59:43,335 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36951375504334766, 'Total loss': 0.36951375504334766} | train loss {'Reaction outcome loss': 0.13034314091761928, 'Total loss': 0.13034314091761928}
2022-12-31 06:59:43,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:43,335 INFO:     Epoch: 46
2022-12-31 06:59:44,951 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3906582976380984, 'Total loss': 0.3906582976380984} | train loss {'Reaction outcome loss': 0.1256155422266549, 'Total loss': 0.1256155422266549}
2022-12-31 06:59:44,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:44,951 INFO:     Epoch: 47
2022-12-31 06:59:46,570 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35036818676938614, 'Total loss': 0.35036818676938614} | train loss {'Reaction outcome loss': 0.12586545692402465, 'Total loss': 0.12586545692402465}
2022-12-31 06:59:46,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:46,570 INFO:     Epoch: 48
2022-12-31 06:59:48,184 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36597047448158265, 'Total loss': 0.36597047448158265} | train loss {'Reaction outcome loss': 0.13404571378866778, 'Total loss': 0.13404571378866778}
2022-12-31 06:59:48,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:48,184 INFO:     Epoch: 49
2022-12-31 06:59:49,802 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36221999724706017, 'Total loss': 0.36221999724706017} | train loss {'Reaction outcome loss': 0.1470812382175991, 'Total loss': 0.1470812382175991}
2022-12-31 06:59:49,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:49,802 INFO:     Epoch: 50
2022-12-31 06:59:51,418 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37091516256332396, 'Total loss': 0.37091516256332396} | train loss {'Reaction outcome loss': 0.1292184834900832, 'Total loss': 0.1292184834900832}
2022-12-31 06:59:51,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:51,419 INFO:     Epoch: 51
2022-12-31 06:59:53,031 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36473785440127054, 'Total loss': 0.36473785440127054} | train loss {'Reaction outcome loss': 0.12106487317393749, 'Total loss': 0.12106487317393749}
2022-12-31 06:59:53,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:53,031 INFO:     Epoch: 52
2022-12-31 06:59:54,655 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36661523456374806, 'Total loss': 0.36661523456374806} | train loss {'Reaction outcome loss': 0.11972047590508895, 'Total loss': 0.11972047590508895}
2022-12-31 06:59:54,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:54,656 INFO:     Epoch: 53
2022-12-31 06:59:56,302 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3604634240269661, 'Total loss': 0.3604634240269661} | train loss {'Reaction outcome loss': 0.11984477005666966, 'Total loss': 0.11984477005666966}
2022-12-31 06:59:56,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:56,302 INFO:     Epoch: 54
2022-12-31 06:59:57,967 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3597754498322805, 'Total loss': 0.3597754498322805} | train loss {'Reaction outcome loss': 0.11774930261252439, 'Total loss': 0.11774930261252439}
2022-12-31 06:59:57,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:57,967 INFO:     Epoch: 55
2022-12-31 06:59:59,587 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3726193755865097, 'Total loss': 0.3726193755865097} | train loss {'Reaction outcome loss': 0.11719239905326412, 'Total loss': 0.11719239905326412}
2022-12-31 06:59:59,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 06:59:59,587 INFO:     Epoch: 56
2022-12-31 07:00:01,207 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36863261411587395, 'Total loss': 0.36863261411587395} | train loss {'Reaction outcome loss': 0.12264433570806801, 'Total loss': 0.12264433570806801}
2022-12-31 07:00:01,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:01,208 INFO:     Epoch: 57
2022-12-31 07:00:02,837 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36316491464773815, 'Total loss': 0.36316491464773815} | train loss {'Reaction outcome loss': 0.11895166761330431, 'Total loss': 0.11895166761330431}
2022-12-31 07:00:02,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:02,837 INFO:     Epoch: 58
2022-12-31 07:00:04,449 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3667578880985578, 'Total loss': 0.3667578880985578} | train loss {'Reaction outcome loss': 0.11876044429178971, 'Total loss': 0.11876044429178971}
2022-12-31 07:00:04,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:04,449 INFO:     Epoch: 59
2022-12-31 07:00:06,112 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3759399259462953, 'Total loss': 0.3759399259462953} | train loss {'Reaction outcome loss': 0.11515577240696576, 'Total loss': 0.11515577240696576}
2022-12-31 07:00:06,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:06,113 INFO:     Epoch: 60
2022-12-31 07:00:07,777 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3600908120473226, 'Total loss': 0.3600908120473226} | train loss {'Reaction outcome loss': 0.11656750825937522, 'Total loss': 0.11656750825937522}
2022-12-31 07:00:07,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:07,777 INFO:     Epoch: 61
2022-12-31 07:00:09,399 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38600353300571444, 'Total loss': 0.38600353300571444} | train loss {'Reaction outcome loss': 0.11856852446288794, 'Total loss': 0.11856852446288794}
2022-12-31 07:00:09,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:09,400 INFO:     Epoch: 62
2022-12-31 07:00:11,063 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3950867036978404, 'Total loss': 0.3950867036978404} | train loss {'Reaction outcome loss': 0.11728431478476906, 'Total loss': 0.11728431478476906}
2022-12-31 07:00:11,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:11,063 INFO:     Epoch: 63
2022-12-31 07:00:12,724 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36272958119710286, 'Total loss': 0.36272958119710286} | train loss {'Reaction outcome loss': 0.1111886113113555, 'Total loss': 0.1111886113113555}
2022-12-31 07:00:12,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:12,724 INFO:     Epoch: 64
2022-12-31 07:00:14,360 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3530250479777654, 'Total loss': 0.3530250479777654} | train loss {'Reaction outcome loss': 0.11403506813677149, 'Total loss': 0.11403506813677149}
2022-12-31 07:00:14,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:14,361 INFO:     Epoch: 65
2022-12-31 07:00:15,984 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3579923321803411, 'Total loss': 0.3579923321803411} | train loss {'Reaction outcome loss': 0.11263456439558903, 'Total loss': 0.11263456439558903}
2022-12-31 07:00:15,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:15,984 INFO:     Epoch: 66
2022-12-31 07:00:17,646 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38909936249256133, 'Total loss': 0.38909936249256133} | train loss {'Reaction outcome loss': 0.11157580668910616, 'Total loss': 0.11157580668910616}
2022-12-31 07:00:17,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:17,646 INFO:     Epoch: 67
2022-12-31 07:00:19,276 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37245475401480993, 'Total loss': 0.37245475401480993} | train loss {'Reaction outcome loss': 0.11424884406844048, 'Total loss': 0.11424884406844048}
2022-12-31 07:00:19,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:19,276 INFO:     Epoch: 68
2022-12-31 07:00:20,885 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3891037702560425, 'Total loss': 0.3891037702560425} | train loss {'Reaction outcome loss': 0.11963569381603098, 'Total loss': 0.11963569381603098}
2022-12-31 07:00:20,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:20,886 INFO:     Epoch: 69
2022-12-31 07:00:22,495 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37550138831138613, 'Total loss': 0.37550138831138613} | train loss {'Reaction outcome loss': 0.1141660554951185, 'Total loss': 0.1141660554951185}
2022-12-31 07:00:22,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:22,496 INFO:     Epoch: 70
2022-12-31 07:00:24,111 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38687290300925575, 'Total loss': 0.38687290300925575} | train loss {'Reaction outcome loss': 0.11214949664081096, 'Total loss': 0.11214949664081096}
2022-12-31 07:00:24,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:24,112 INFO:     Epoch: 71
2022-12-31 07:00:25,732 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3840106954177221, 'Total loss': 0.3840106954177221} | train loss {'Reaction outcome loss': 0.10753387168464858, 'Total loss': 0.10753387168464858}
2022-12-31 07:00:25,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:25,732 INFO:     Epoch: 72
2022-12-31 07:00:27,349 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.334608053167661, 'Total loss': 0.334608053167661} | train loss {'Reaction outcome loss': 0.10961165636916226, 'Total loss': 0.10961165636916226}
2022-12-31 07:00:27,349 INFO:     Found new best model at epoch 72
2022-12-31 07:00:27,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:27,350 INFO:     Epoch: 73
2022-12-31 07:00:28,973 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3605012188355128, 'Total loss': 0.3605012188355128} | train loss {'Reaction outcome loss': 0.11075943513889427, 'Total loss': 0.11075943513889427}
2022-12-31 07:00:28,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:28,973 INFO:     Epoch: 74
2022-12-31 07:00:30,588 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3581241955359777, 'Total loss': 0.3581241955359777} | train loss {'Reaction outcome loss': 0.11169623047686215, 'Total loss': 0.11169623047686215}
2022-12-31 07:00:30,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:30,589 INFO:     Epoch: 75
2022-12-31 07:00:32,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37174455225467684, 'Total loss': 0.37174455225467684} | train loss {'Reaction outcome loss': 0.1143556026407801, 'Total loss': 0.1143556026407801}
2022-12-31 07:00:32,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:32,207 INFO:     Epoch: 76
2022-12-31 07:00:33,828 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37630606939395267, 'Total loss': 0.37630606939395267} | train loss {'Reaction outcome loss': 0.11188968426137327, 'Total loss': 0.11188968426137327}
2022-12-31 07:00:33,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:33,828 INFO:     Epoch: 77
2022-12-31 07:00:35,447 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3473162353038788, 'Total loss': 0.3473162353038788} | train loss {'Reaction outcome loss': 0.10954777885693319, 'Total loss': 0.10954777885693319}
2022-12-31 07:00:35,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:35,448 INFO:     Epoch: 78
2022-12-31 07:00:37,068 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3973913937807083, 'Total loss': 0.3973913937807083} | train loss {'Reaction outcome loss': 0.10749750669735174, 'Total loss': 0.10749750669735174}
2022-12-31 07:00:37,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:37,069 INFO:     Epoch: 79
2022-12-31 07:00:38,682 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.377164855102698, 'Total loss': 0.377164855102698} | train loss {'Reaction outcome loss': 0.10761015764443943, 'Total loss': 0.10761015764443943}
2022-12-31 07:00:38,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:38,683 INFO:     Epoch: 80
2022-12-31 07:00:40,307 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36547644635041554, 'Total loss': 0.36547644635041554} | train loss {'Reaction outcome loss': 0.10541671402229374, 'Total loss': 0.10541671402229374}
2022-12-31 07:00:40,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:40,308 INFO:     Epoch: 81
2022-12-31 07:00:41,923 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34912347594896953, 'Total loss': 0.34912347594896953} | train loss {'Reaction outcome loss': 0.1076465983810983, 'Total loss': 0.1076465983810983}
2022-12-31 07:00:41,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:41,923 INFO:     Epoch: 82
2022-12-31 07:00:43,545 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3561514953772227, 'Total loss': 0.3561514953772227} | train loss {'Reaction outcome loss': 0.10725040626720579, 'Total loss': 0.10725040626720579}
2022-12-31 07:00:43,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:43,545 INFO:     Epoch: 83
2022-12-31 07:00:45,165 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3769603262344996, 'Total loss': 0.3769603262344996} | train loss {'Reaction outcome loss': 0.11446724151661013, 'Total loss': 0.11446724151661013}
2022-12-31 07:00:45,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:45,166 INFO:     Epoch: 84
2022-12-31 07:00:46,790 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3846460849046707, 'Total loss': 0.3846460849046707} | train loss {'Reaction outcome loss': 0.10514379472427511, 'Total loss': 0.10514379472427511}
2022-12-31 07:00:46,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:46,790 INFO:     Epoch: 85
2022-12-31 07:00:48,407 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39304194698731104, 'Total loss': 0.39304194698731104} | train loss {'Reaction outcome loss': 0.10497366055220693, 'Total loss': 0.10497366055220693}
2022-12-31 07:00:48,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:48,408 INFO:     Epoch: 86
2022-12-31 07:00:50,031 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35849120616912844, 'Total loss': 0.35849120616912844} | train loss {'Reaction outcome loss': 0.10934585059083579, 'Total loss': 0.10934585059083579}
2022-12-31 07:00:50,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:50,032 INFO:     Epoch: 87
2022-12-31 07:00:51,646 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.384653606514136, 'Total loss': 0.384653606514136} | train loss {'Reaction outcome loss': 0.10877690522792004, 'Total loss': 0.10877690522792004}
2022-12-31 07:00:51,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:51,646 INFO:     Epoch: 88
2022-12-31 07:00:53,308 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3908958613872528, 'Total loss': 0.3908958613872528} | train loss {'Reaction outcome loss': 0.10515304461823426, 'Total loss': 0.10515304461823426}
2022-12-31 07:00:53,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:53,308 INFO:     Epoch: 89
2022-12-31 07:00:54,970 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40295136670271553, 'Total loss': 0.40295136670271553} | train loss {'Reaction outcome loss': 0.10808546350829377, 'Total loss': 0.10808546350829377}
2022-12-31 07:00:54,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:54,971 INFO:     Epoch: 90
2022-12-31 07:00:56,624 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3878341197967529, 'Total loss': 0.3878341197967529} | train loss {'Reaction outcome loss': 0.10534700420662112, 'Total loss': 0.10534700420662112}
2022-12-31 07:00:56,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:56,624 INFO:     Epoch: 91
2022-12-31 07:00:58,277 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37446485211451846, 'Total loss': 0.37446485211451846} | train loss {'Reaction outcome loss': 0.10057713493564523, 'Total loss': 0.10057713493564523}
2022-12-31 07:00:58,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:58,277 INFO:     Epoch: 92
2022-12-31 07:00:59,897 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3525117814540863, 'Total loss': 0.3525117814540863} | train loss {'Reaction outcome loss': 0.10613468586940882, 'Total loss': 0.10613468586940882}
2022-12-31 07:00:59,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:00:59,897 INFO:     Epoch: 93
2022-12-31 07:01:01,512 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3710001697142919, 'Total loss': 0.3710001697142919} | train loss {'Reaction outcome loss': 0.10425279055303638, 'Total loss': 0.10425279055303638}
2022-12-31 07:01:01,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:01,513 INFO:     Epoch: 94
2022-12-31 07:01:03,126 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3889014646410942, 'Total loss': 0.3889014646410942} | train loss {'Reaction outcome loss': 0.10339980019236227, 'Total loss': 0.10339980019236227}
2022-12-31 07:01:03,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:03,126 INFO:     Epoch: 95
2022-12-31 07:01:04,736 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3662065406640371, 'Total loss': 0.3662065406640371} | train loss {'Reaction outcome loss': 0.10387780051720599, 'Total loss': 0.10387780051720599}
2022-12-31 07:01:04,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:04,736 INFO:     Epoch: 96
2022-12-31 07:01:06,372 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39502307573954265, 'Total loss': 0.39502307573954265} | train loss {'Reaction outcome loss': 0.11166972255686879, 'Total loss': 0.11166972255686879}
2022-12-31 07:01:06,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:06,372 INFO:     Epoch: 97
2022-12-31 07:01:07,986 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3763084411621094, 'Total loss': 0.3763084411621094} | train loss {'Reaction outcome loss': 0.10620581029502647, 'Total loss': 0.10620581029502647}
2022-12-31 07:01:07,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:07,987 INFO:     Epoch: 98
2022-12-31 07:01:09,608 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4174951267739137, 'Total loss': 0.4174951267739137} | train loss {'Reaction outcome loss': 0.10610927135659975, 'Total loss': 0.10610927135659975}
2022-12-31 07:01:09,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:09,609 INFO:     Epoch: 99
2022-12-31 07:01:11,237 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4121423165003459, 'Total loss': 0.4121423165003459} | train loss {'Reaction outcome loss': 0.11318661080862301, 'Total loss': 0.11318661080862301}
2022-12-31 07:01:11,237 INFO:     Best model found after epoch 73 of 100.
2022-12-31 07:01:11,237 INFO:   Done with stage: TRAINING
2022-12-31 07:01:11,237 INFO:   Starting stage: EVALUATION
2022-12-31 07:01:11,368 INFO:   Done with stage: EVALUATION
2022-12-31 07:01:11,368 INFO:   Leaving out SEQ value Fold_5
2022-12-31 07:01:11,381 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:01:11,381 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:01:12,026 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:01:12,026 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:01:12,097 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:01:12,097 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:01:12,097 INFO:     No hyperparam tuning for this model
2022-12-31 07:01:12,097 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:01:12,097 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:01:12,098 INFO:     None feature selector for col prot
2022-12-31 07:01:12,098 INFO:     None feature selector for col prot
2022-12-31 07:01:12,098 INFO:     None feature selector for col prot
2022-12-31 07:01:12,099 INFO:     None feature selector for col chem
2022-12-31 07:01:12,099 INFO:     None feature selector for col chem
2022-12-31 07:01:12,099 INFO:     None feature selector for col chem
2022-12-31 07:01:12,099 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:01:12,099 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:01:12,101 INFO:     Number of params in model 224011
2022-12-31 07:01:12,104 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:01:12,104 INFO:   Starting stage: TRAINING
2022-12-31 07:01:12,150 INFO:     Val loss before train {'Reaction outcome loss': 0.9326274474461873, 'Total loss': 0.9326274474461873}
2022-12-31 07:01:12,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:12,151 INFO:     Epoch: 0
2022-12-31 07:01:13,783 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5769925196965535, 'Total loss': 0.5769925196965535} | train loss {'Reaction outcome loss': 0.7618148508700223, 'Total loss': 0.7618148508700223}
2022-12-31 07:01:13,783 INFO:     Found new best model at epoch 0
2022-12-31 07:01:13,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:13,784 INFO:     Epoch: 1
2022-12-31 07:01:15,405 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5302174131075541, 'Total loss': 0.5302174131075541} | train loss {'Reaction outcome loss': 0.5117497821254421, 'Total loss': 0.5117497821254421}
2022-12-31 07:01:15,406 INFO:     Found new best model at epoch 1
2022-12-31 07:01:15,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:15,407 INFO:     Epoch: 2
2022-12-31 07:01:17,031 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5355506658554077, 'Total loss': 0.5355506658554077} | train loss {'Reaction outcome loss': 0.44330261545491134, 'Total loss': 0.44330261545491134}
2022-12-31 07:01:17,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:17,031 INFO:     Epoch: 3
2022-12-31 07:01:18,651 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5097081144650777, 'Total loss': 0.5097081144650777} | train loss {'Reaction outcome loss': 0.4036982096597176, 'Total loss': 0.4036982096597176}
2022-12-31 07:01:18,652 INFO:     Found new best model at epoch 3
2022-12-31 07:01:18,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:18,653 INFO:     Epoch: 4
2022-12-31 07:01:20,271 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4728735536336899, 'Total loss': 0.4728735536336899} | train loss {'Reaction outcome loss': 0.37774390750144365, 'Total loss': 0.37774390750144365}
2022-12-31 07:01:20,272 INFO:     Found new best model at epoch 4
2022-12-31 07:01:20,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:20,273 INFO:     Epoch: 5
2022-12-31 07:01:21,943 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4683671583731969, 'Total loss': 0.4683671583731969} | train loss {'Reaction outcome loss': 0.3541397434333171, 'Total loss': 0.3541397434333171}
2022-12-31 07:01:21,944 INFO:     Found new best model at epoch 5
2022-12-31 07:01:21,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:21,945 INFO:     Epoch: 6
2022-12-31 07:01:23,568 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4733808696269989, 'Total loss': 0.4733808696269989} | train loss {'Reaction outcome loss': 0.3382686048288853, 'Total loss': 0.3382686048288853}
2022-12-31 07:01:23,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:23,568 INFO:     Epoch: 7
2022-12-31 07:01:25,224 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4643083274364471, 'Total loss': 0.4643083274364471} | train loss {'Reaction outcome loss': 0.3234402944034618, 'Total loss': 0.3234402944034618}
2022-12-31 07:01:25,224 INFO:     Found new best model at epoch 7
2022-12-31 07:01:25,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:25,225 INFO:     Epoch: 8
2022-12-31 07:01:26,863 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4617480049530665, 'Total loss': 0.4617480049530665} | train loss {'Reaction outcome loss': 0.3024329492277617, 'Total loss': 0.3024329492277617}
2022-12-31 07:01:26,863 INFO:     Found new best model at epoch 8
2022-12-31 07:01:26,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:26,864 INFO:     Epoch: 9
2022-12-31 07:01:28,489 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46664325694243114, 'Total loss': 0.46664325694243114} | train loss {'Reaction outcome loss': 0.2931482236334778, 'Total loss': 0.2931482236334778}
2022-12-31 07:01:28,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:28,490 INFO:     Epoch: 10
2022-12-31 07:01:30,160 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4505819588899612, 'Total loss': 0.4505819588899612} | train loss {'Reaction outcome loss': 0.27852478529249286, 'Total loss': 0.27852478529249286}
2022-12-31 07:01:30,160 INFO:     Found new best model at epoch 10
2022-12-31 07:01:30,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:30,161 INFO:     Epoch: 11
2022-12-31 07:01:31,786 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4280088464419047, 'Total loss': 0.4280088464419047} | train loss {'Reaction outcome loss': 0.267695733900804, 'Total loss': 0.267695733900804}
2022-12-31 07:01:31,787 INFO:     Found new best model at epoch 11
2022-12-31 07:01:31,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:31,788 INFO:     Epoch: 12
2022-12-31 07:01:33,411 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4855953842401505, 'Total loss': 0.4855953842401505} | train loss {'Reaction outcome loss': 0.25885133309431024, 'Total loss': 0.25885133309431024}
2022-12-31 07:01:33,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:33,412 INFO:     Epoch: 13
2022-12-31 07:01:35,041 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4678381005922953, 'Total loss': 0.4678381005922953} | train loss {'Reaction outcome loss': 0.25240454845641497, 'Total loss': 0.25240454845641497}
2022-12-31 07:01:35,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:35,041 INFO:     Epoch: 14
2022-12-31 07:01:36,702 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4428165803352992, 'Total loss': 0.4428165803352992} | train loss {'Reaction outcome loss': 0.2443795246794981, 'Total loss': 0.2443795246794981}
2022-12-31 07:01:36,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:36,703 INFO:     Epoch: 15
2022-12-31 07:01:38,372 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46049392918745674, 'Total loss': 0.46049392918745674} | train loss {'Reaction outcome loss': 0.23592093137735065, 'Total loss': 0.23592093137735065}
2022-12-31 07:01:38,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:38,373 INFO:     Epoch: 16
2022-12-31 07:01:39,993 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4335204621156057, 'Total loss': 0.4335204621156057} | train loss {'Reaction outcome loss': 0.22931259344684948, 'Total loss': 0.22931259344684948}
2022-12-31 07:01:39,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:39,994 INFO:     Epoch: 17
2022-12-31 07:01:41,616 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43839793105920155, 'Total loss': 0.43839793105920155} | train loss {'Reaction outcome loss': 0.22000762626582535, 'Total loss': 0.22000762626582535}
2022-12-31 07:01:41,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:41,617 INFO:     Epoch: 18
2022-12-31 07:01:43,272 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4542164365450541, 'Total loss': 0.4542164365450541} | train loss {'Reaction outcome loss': 0.21581584617280358, 'Total loss': 0.21581584617280358}
2022-12-31 07:01:43,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:43,272 INFO:     Epoch: 19
2022-12-31 07:01:44,891 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4396605948607127, 'Total loss': 0.4396605948607127} | train loss {'Reaction outcome loss': 0.21080992370171453, 'Total loss': 0.21080992370171453}
2022-12-31 07:01:44,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:44,891 INFO:     Epoch: 20
2022-12-31 07:01:46,525 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43635590573151906, 'Total loss': 0.43635590573151906} | train loss {'Reaction outcome loss': 0.20519948230942017, 'Total loss': 0.20519948230942017}
2022-12-31 07:01:46,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:46,525 INFO:     Epoch: 21
2022-12-31 07:01:48,159 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46169677985211216, 'Total loss': 0.46169677985211216} | train loss {'Reaction outcome loss': 0.19957517954900808, 'Total loss': 0.19957517954900808}
2022-12-31 07:01:48,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:48,159 INFO:     Epoch: 22
2022-12-31 07:01:49,791 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47297161916891733, 'Total loss': 0.47297161916891733} | train loss {'Reaction outcome loss': 0.19730631217683264, 'Total loss': 0.19730631217683264}
2022-12-31 07:01:49,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:49,791 INFO:     Epoch: 23
2022-12-31 07:01:51,416 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4760766575733821, 'Total loss': 0.4760766575733821} | train loss {'Reaction outcome loss': 0.19331001786898405, 'Total loss': 0.19331001786898405}
2022-12-31 07:01:51,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:51,417 INFO:     Epoch: 24
2022-12-31 07:01:53,052 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4597594896952311, 'Total loss': 0.4597594896952311} | train loss {'Reaction outcome loss': 0.188847282531567, 'Total loss': 0.188847282531567}
2022-12-31 07:01:53,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:53,052 INFO:     Epoch: 25
2022-12-31 07:01:54,678 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45791870752970376, 'Total loss': 0.45791870752970376} | train loss {'Reaction outcome loss': 0.1829609478006832, 'Total loss': 0.1829609478006832}
2022-12-31 07:01:54,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:54,678 INFO:     Epoch: 26
2022-12-31 07:01:56,311 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4404638042052587, 'Total loss': 0.4404638042052587} | train loss {'Reaction outcome loss': 0.18205759948664194, 'Total loss': 0.18205759948664194}
2022-12-31 07:01:56,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:56,311 INFO:     Epoch: 27
2022-12-31 07:01:57,946 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46063331365585325, 'Total loss': 0.46063331365585325} | train loss {'Reaction outcome loss': 0.1774021938429735, 'Total loss': 0.1774021938429735}
2022-12-31 07:01:57,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:57,946 INFO:     Epoch: 28
2022-12-31 07:01:59,581 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44636562168598176, 'Total loss': 0.44636562168598176} | train loss {'Reaction outcome loss': 0.17318039428146845, 'Total loss': 0.17318039428146845}
2022-12-31 07:01:59,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:01:59,581 INFO:     Epoch: 29
2022-12-31 07:02:01,202 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4435429419080416, 'Total loss': 0.4435429419080416} | train loss {'Reaction outcome loss': 0.17088413029398083, 'Total loss': 0.17088413029398083}
2022-12-31 07:02:01,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:01,203 INFO:     Epoch: 30
2022-12-31 07:02:02,825 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47778943640490373, 'Total loss': 0.47778943640490373} | train loss {'Reaction outcome loss': 0.16847967895400115, 'Total loss': 0.16847967895400115}
2022-12-31 07:02:02,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:02,826 INFO:     Epoch: 31
2022-12-31 07:02:04,496 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46825212637583413, 'Total loss': 0.46825212637583413} | train loss {'Reaction outcome loss': 0.17045138177835123, 'Total loss': 0.17045138177835123}
2022-12-31 07:02:04,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:04,496 INFO:     Epoch: 32
2022-12-31 07:02:06,117 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4703253368536631, 'Total loss': 0.4703253368536631} | train loss {'Reaction outcome loss': 0.16746703188509987, 'Total loss': 0.16746703188509987}
2022-12-31 07:02:06,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:06,117 INFO:     Epoch: 33
2022-12-31 07:02:07,738 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4782670795917511, 'Total loss': 0.4782670795917511} | train loss {'Reaction outcome loss': 0.15994568904088508, 'Total loss': 0.15994568904088508}
2022-12-31 07:02:07,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:07,739 INFO:     Epoch: 34
2022-12-31 07:02:09,353 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.479374619325002, 'Total loss': 0.479374619325002} | train loss {'Reaction outcome loss': 0.16186351858294612, 'Total loss': 0.16186351858294612}
2022-12-31 07:02:09,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:09,354 INFO:     Epoch: 35
2022-12-31 07:02:10,975 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5233476837476094, 'Total loss': 0.5233476837476094} | train loss {'Reaction outcome loss': 0.15763289173089964, 'Total loss': 0.15763289173089964}
2022-12-31 07:02:10,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:10,975 INFO:     Epoch: 36
2022-12-31 07:02:12,605 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45009430845578513, 'Total loss': 0.45009430845578513} | train loss {'Reaction outcome loss': 0.1555754883342594, 'Total loss': 0.1555754883342594}
2022-12-31 07:02:12,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:12,605 INFO:     Epoch: 37
2022-12-31 07:02:14,237 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4974577486515045, 'Total loss': 0.4974577486515045} | train loss {'Reaction outcome loss': 0.15410129456959046, 'Total loss': 0.15410129456959046}
2022-12-31 07:02:14,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:14,238 INFO:     Epoch: 38
2022-12-31 07:02:15,870 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46688364644845326, 'Total loss': 0.46688364644845326} | train loss {'Reaction outcome loss': 0.15395016313634732, 'Total loss': 0.15395016313634732}
2022-12-31 07:02:15,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:15,871 INFO:     Epoch: 39
2022-12-31 07:02:17,503 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48345690965652466, 'Total loss': 0.48345690965652466} | train loss {'Reaction outcome loss': 0.15020123594154736, 'Total loss': 0.15020123594154736}
2022-12-31 07:02:17,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:17,503 INFO:     Epoch: 40
2022-12-31 07:02:19,144 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4598055511713028, 'Total loss': 0.4598055511713028} | train loss {'Reaction outcome loss': 0.14988763140857436, 'Total loss': 0.14988763140857436}
2022-12-31 07:02:19,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:19,144 INFO:     Epoch: 41
2022-12-31 07:02:20,801 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.489288322130839, 'Total loss': 0.489288322130839} | train loss {'Reaction outcome loss': 0.15150952310257657, 'Total loss': 0.15150952310257657}
2022-12-31 07:02:20,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:20,802 INFO:     Epoch: 42
2022-12-31 07:02:22,427 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4373129000266393, 'Total loss': 0.4373129000266393} | train loss {'Reaction outcome loss': 0.14901194895621026, 'Total loss': 0.14901194895621026}
2022-12-31 07:02:22,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:22,427 INFO:     Epoch: 43
2022-12-31 07:02:24,096 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.457825946311156, 'Total loss': 0.457825946311156} | train loss {'Reaction outcome loss': 0.14906513551754427, 'Total loss': 0.14906513551754427}
2022-12-31 07:02:24,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:24,097 INFO:     Epoch: 44
2022-12-31 07:02:25,721 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47335417071978253, 'Total loss': 0.47335417071978253} | train loss {'Reaction outcome loss': 0.1417255187776975, 'Total loss': 0.1417255187776975}
2022-12-31 07:02:25,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:25,721 INFO:     Epoch: 45
2022-12-31 07:02:27,391 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4533783515294393, 'Total loss': 0.4533783515294393} | train loss {'Reaction outcome loss': 0.14517445065625792, 'Total loss': 0.14517445065625792}
2022-12-31 07:02:27,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:27,392 INFO:     Epoch: 46
2022-12-31 07:02:29,016 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42578943222761156, 'Total loss': 0.42578943222761156} | train loss {'Reaction outcome loss': 0.14184239277925464, 'Total loss': 0.14184239277925464}
2022-12-31 07:02:29,016 INFO:     Found new best model at epoch 46
2022-12-31 07:02:29,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:29,017 INFO:     Epoch: 47
2022-12-31 07:02:30,657 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.462842924396197, 'Total loss': 0.462842924396197} | train loss {'Reaction outcome loss': 0.14437499447365962, 'Total loss': 0.14437499447365962}
2022-12-31 07:02:30,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:30,657 INFO:     Epoch: 48
2022-12-31 07:02:32,278 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4633506317933401, 'Total loss': 0.4633506317933401} | train loss {'Reaction outcome loss': 0.13981559730911566, 'Total loss': 0.13981559730911566}
2022-12-31 07:02:32,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:32,279 INFO:     Epoch: 49
2022-12-31 07:02:33,897 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47838053007920583, 'Total loss': 0.47838053007920583} | train loss {'Reaction outcome loss': 0.13668649990972306, 'Total loss': 0.13668649990972306}
2022-12-31 07:02:33,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:33,898 INFO:     Epoch: 50
2022-12-31 07:02:35,518 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.457303860783577, 'Total loss': 0.457303860783577} | train loss {'Reaction outcome loss': 0.14029740511913807, 'Total loss': 0.14029740511913807}
2022-12-31 07:02:35,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:35,518 INFO:     Epoch: 51
2022-12-31 07:02:37,138 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44829908112684885, 'Total loss': 0.44829908112684885} | train loss {'Reaction outcome loss': 0.1406816890923851, 'Total loss': 0.1406816890923851}
2022-12-31 07:02:37,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:37,138 INFO:     Epoch: 52
2022-12-31 07:02:38,766 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4544891546169917, 'Total loss': 0.4544891546169917} | train loss {'Reaction outcome loss': 0.1362291348859372, 'Total loss': 0.1362291348859372}
2022-12-31 07:02:38,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:38,766 INFO:     Epoch: 53
2022-12-31 07:02:39,937 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4780221223831177, 'Total loss': 0.4780221223831177} | train loss {'Reaction outcome loss': 0.13767636058152743, 'Total loss': 0.13767636058152743}
2022-12-31 07:02:39,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:39,938 INFO:     Epoch: 54
2022-12-31 07:02:41,058 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4526084949572881, 'Total loss': 0.4526084949572881} | train loss {'Reaction outcome loss': 0.1344231302053113, 'Total loss': 0.1344231302053113}
2022-12-31 07:02:41,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:41,058 INFO:     Epoch: 55
2022-12-31 07:02:42,177 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4637174149354299, 'Total loss': 0.4637174149354299} | train loss {'Reaction outcome loss': 0.1312228996905125, 'Total loss': 0.1312228996905125}
2022-12-31 07:02:42,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:42,177 INFO:     Epoch: 56
2022-12-31 07:02:43,293 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.480485192934672, 'Total loss': 0.480485192934672} | train loss {'Reaction outcome loss': 0.13382750309479258, 'Total loss': 0.13382750309479258}
2022-12-31 07:02:43,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:43,293 INFO:     Epoch: 57
2022-12-31 07:02:44,819 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47283926904201506, 'Total loss': 0.47283926904201506} | train loss {'Reaction outcome loss': 0.1289230005257504, 'Total loss': 0.1289230005257504}
2022-12-31 07:02:44,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:44,821 INFO:     Epoch: 58
2022-12-31 07:02:46,459 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43865727285544076, 'Total loss': 0.43865727285544076} | train loss {'Reaction outcome loss': 0.1310846138600973, 'Total loss': 0.1310846138600973}
2022-12-31 07:02:46,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:46,459 INFO:     Epoch: 59
2022-12-31 07:02:48,087 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4680510232845942, 'Total loss': 0.4680510232845942} | train loss {'Reaction outcome loss': 0.1309178071163783, 'Total loss': 0.1309178071163783}
2022-12-31 07:02:48,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:48,087 INFO:     Epoch: 60
2022-12-31 07:02:49,716 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4749211847782135, 'Total loss': 0.4749211847782135} | train loss {'Reaction outcome loss': 0.13103152149010597, 'Total loss': 0.13103152149010597}
2022-12-31 07:02:49,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:49,716 INFO:     Epoch: 61
2022-12-31 07:02:51,345 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4650351290901502, 'Total loss': 0.4650351290901502} | train loss {'Reaction outcome loss': 0.1305731070036277, 'Total loss': 0.1305731070036277}
2022-12-31 07:02:51,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:51,346 INFO:     Epoch: 62
2022-12-31 07:02:52,917 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4742371519406637, 'Total loss': 0.4742371519406637} | train loss {'Reaction outcome loss': 0.1309747333160941, 'Total loss': 0.1309747333160941}
2022-12-31 07:02:52,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:52,917 INFO:     Epoch: 63
2022-12-31 07:02:54,587 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5096497456232707, 'Total loss': 0.5096497456232707} | train loss {'Reaction outcome loss': 0.1255183411335122, 'Total loss': 0.1255183411335122}
2022-12-31 07:02:54,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:54,587 INFO:     Epoch: 64
2022-12-31 07:02:56,256 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46279922425746917, 'Total loss': 0.46279922425746917} | train loss {'Reaction outcome loss': 0.12419278525986073, 'Total loss': 0.12419278525986073}
2022-12-31 07:02:56,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:56,256 INFO:     Epoch: 65
2022-12-31 07:02:57,880 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48733735978603365, 'Total loss': 0.48733735978603365} | train loss {'Reaction outcome loss': 0.12488731486211777, 'Total loss': 0.12488731486211777}
2022-12-31 07:02:57,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:57,880 INFO:     Epoch: 66
2022-12-31 07:02:59,502 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46637319326400756, 'Total loss': 0.46637319326400756} | train loss {'Reaction outcome loss': 0.12811067325839712, 'Total loss': 0.12811067325839712}
2022-12-31 07:02:59,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:02:59,502 INFO:     Epoch: 67
2022-12-31 07:03:01,171 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4496929089228312, 'Total loss': 0.4496929089228312} | train loss {'Reaction outcome loss': 0.12818907362842658, 'Total loss': 0.12818907362842658}
2022-12-31 07:03:01,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:01,171 INFO:     Epoch: 68
2022-12-31 07:03:02,753 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4813211818536123, 'Total loss': 0.4813211818536123} | train loss {'Reaction outcome loss': 0.12222017201053698, 'Total loss': 0.12222017201053698}
2022-12-31 07:03:02,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:02,753 INFO:     Epoch: 69
2022-12-31 07:03:04,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5073346734046936, 'Total loss': 0.5073346734046936} | train loss {'Reaction outcome loss': 0.12310873595190769, 'Total loss': 0.12310873595190769}
2022-12-31 07:03:04,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:04,383 INFO:     Epoch: 70
2022-12-31 07:03:06,012 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4368519395589828, 'Total loss': 0.4368519395589828} | train loss {'Reaction outcome loss': 0.12307549227661174, 'Total loss': 0.12307549227661174}
2022-12-31 07:03:06,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:06,013 INFO:     Epoch: 71
2022-12-31 07:03:07,643 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5183649629354476, 'Total loss': 0.5183649629354476} | train loss {'Reaction outcome loss': 0.12264643453434781, 'Total loss': 0.12264643453434781}
2022-12-31 07:03:07,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:07,643 INFO:     Epoch: 72
2022-12-31 07:03:09,272 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4740845819314321, 'Total loss': 0.4740845819314321} | train loss {'Reaction outcome loss': 0.12110238421005651, 'Total loss': 0.12110238421005651}
2022-12-31 07:03:09,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:09,272 INFO:     Epoch: 73
2022-12-31 07:03:10,881 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4665025234222412, 'Total loss': 0.4665025234222412} | train loss {'Reaction outcome loss': 0.11837634175430835, 'Total loss': 0.11837634175430835}
2022-12-31 07:03:10,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:10,881 INFO:     Epoch: 74
2022-12-31 07:03:12,500 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4938171888391177, 'Total loss': 0.4938171888391177} | train loss {'Reaction outcome loss': 0.12151111062743873, 'Total loss': 0.12151111062743873}
2022-12-31 07:03:12,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:12,500 INFO:     Epoch: 75
2022-12-31 07:03:14,124 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4793559933702151, 'Total loss': 0.4793559933702151} | train loss {'Reaction outcome loss': 0.12480515973652555, 'Total loss': 0.12480515973652555}
2022-12-31 07:03:14,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:14,124 INFO:     Epoch: 76
2022-12-31 07:03:15,744 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48628100951512654, 'Total loss': 0.48628100951512654} | train loss {'Reaction outcome loss': 0.12418674541862568, 'Total loss': 0.12418674541862568}
2022-12-31 07:03:15,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:15,745 INFO:     Epoch: 77
2022-12-31 07:03:17,363 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.504085577527682, 'Total loss': 0.504085577527682} | train loss {'Reaction outcome loss': 0.11834364950771205, 'Total loss': 0.11834364950771205}
2022-12-31 07:03:17,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:17,364 INFO:     Epoch: 78
2022-12-31 07:03:19,031 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4633319755395254, 'Total loss': 0.4633319755395254} | train loss {'Reaction outcome loss': 0.12137463521582179, 'Total loss': 0.12137463521582179}
2022-12-31 07:03:19,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:19,031 INFO:     Epoch: 79
2022-12-31 07:03:20,608 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46497719287872313, 'Total loss': 0.46497719287872313} | train loss {'Reaction outcome loss': 0.11937423077805324, 'Total loss': 0.11937423077805324}
2022-12-31 07:03:20,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:20,609 INFO:     Epoch: 80
2022-12-31 07:03:22,239 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4532503674427668, 'Total loss': 0.4532503674427668} | train loss {'Reaction outcome loss': 0.11782317550429261, 'Total loss': 0.11782317550429261}
2022-12-31 07:03:22,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:22,240 INFO:     Epoch: 81
2022-12-31 07:03:23,869 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4613313575585683, 'Total loss': 0.4613313575585683} | train loss {'Reaction outcome loss': 0.11851060452504547, 'Total loss': 0.11851060452504547}
2022-12-31 07:03:23,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:23,869 INFO:     Epoch: 82
2022-12-31 07:03:25,540 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.51710324883461, 'Total loss': 0.51710324883461} | train loss {'Reaction outcome loss': 0.11945803153550501, 'Total loss': 0.11945803153550501}
2022-12-31 07:03:25,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:25,540 INFO:     Epoch: 83
2022-12-31 07:03:27,164 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46574923445781075, 'Total loss': 0.46574923445781075} | train loss {'Reaction outcome loss': 0.11809001302612199, 'Total loss': 0.11809001302612199}
2022-12-31 07:03:27,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:27,165 INFO:     Epoch: 84
2022-12-31 07:03:28,790 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5018674403429031, 'Total loss': 0.5018674403429031} | train loss {'Reaction outcome loss': 0.12098333970744445, 'Total loss': 0.12098333970744445}
2022-12-31 07:03:28,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:28,790 INFO:     Epoch: 85
2022-12-31 07:03:30,392 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4954632942875226, 'Total loss': 0.4954632942875226} | train loss {'Reaction outcome loss': 0.11897087306631493, 'Total loss': 0.11897087306631493}
2022-12-31 07:03:30,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:30,393 INFO:     Epoch: 86
2022-12-31 07:03:32,022 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5117321312427521, 'Total loss': 0.5117321312427521} | train loss {'Reaction outcome loss': 0.11573531100146527, 'Total loss': 0.11573531100146527}
2022-12-31 07:03:32,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:32,022 INFO:     Epoch: 87
2022-12-31 07:03:33,650 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49040759801864625, 'Total loss': 0.49040759801864625} | train loss {'Reaction outcome loss': 0.11704539648334526, 'Total loss': 0.11704539648334526}
2022-12-31 07:03:33,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:33,650 INFO:     Epoch: 88
2022-12-31 07:03:35,278 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4680714944998423, 'Total loss': 0.4680714944998423} | train loss {'Reaction outcome loss': 0.1185336615747372, 'Total loss': 0.1185336615747372}
2022-12-31 07:03:35,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:35,279 INFO:     Epoch: 89
2022-12-31 07:03:36,905 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48269682029883065, 'Total loss': 0.48269682029883065} | train loss {'Reaction outcome loss': 0.11598255299031734, 'Total loss': 0.11598255299031734}
2022-12-31 07:03:36,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:36,906 INFO:     Epoch: 90
2022-12-31 07:03:38,464 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4864623626073202, 'Total loss': 0.4864623626073202} | train loss {'Reaction outcome loss': 0.12169801282430814, 'Total loss': 0.12169801282430814}
2022-12-31 07:03:38,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:38,465 INFO:     Epoch: 91
2022-12-31 07:03:40,090 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46634718800584474, 'Total loss': 0.46634718800584474} | train loss {'Reaction outcome loss': 0.12439777150864474, 'Total loss': 0.12439777150864474}
2022-12-31 07:03:40,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:40,090 INFO:     Epoch: 92
2022-12-31 07:03:41,715 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5002361218134562, 'Total loss': 0.5002361218134562} | train loss {'Reaction outcome loss': 0.11580190565672431, 'Total loss': 0.11580190565672431}
2022-12-31 07:03:41,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:41,716 INFO:     Epoch: 93
2022-12-31 07:03:43,340 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47829804917176566, 'Total loss': 0.47829804917176566} | train loss {'Reaction outcome loss': 0.11101402766794127, 'Total loss': 0.11101402766794127}
2022-12-31 07:03:43,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:43,340 INFO:     Epoch: 94
2022-12-31 07:03:44,964 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4860472738742828, 'Total loss': 0.4860472738742828} | train loss {'Reaction outcome loss': 0.1119736897614566, 'Total loss': 0.1119736897614566}
2022-12-31 07:03:44,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:44,964 INFO:     Epoch: 95
2022-12-31 07:03:46,593 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5065801536043485, 'Total loss': 0.5065801536043485} | train loss {'Reaction outcome loss': 0.11988792293923588, 'Total loss': 0.11988792293923588}
2022-12-31 07:03:46,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:46,593 INFO:     Epoch: 96
2022-12-31 07:03:48,160 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48665095269680025, 'Total loss': 0.48665095269680025} | train loss {'Reaction outcome loss': 0.11397865392429088, 'Total loss': 0.11397865392429088}
2022-12-31 07:03:48,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:48,160 INFO:     Epoch: 97
2022-12-31 07:03:49,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5174544389049213, 'Total loss': 0.5174544389049213} | train loss {'Reaction outcome loss': 0.11718006674805488, 'Total loss': 0.11718006674805488}
2022-12-31 07:03:49,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:49,789 INFO:     Epoch: 98
2022-12-31 07:03:51,417 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4917166252930959, 'Total loss': 0.4917166252930959} | train loss {'Reaction outcome loss': 0.1122585047987905, 'Total loss': 0.1122585047987905}
2022-12-31 07:03:51,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:51,419 INFO:     Epoch: 99
2022-12-31 07:03:53,049 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5144121388594309, 'Total loss': 0.5144121388594309} | train loss {'Reaction outcome loss': 0.11531402557140169, 'Total loss': 0.11531402557140169}
2022-12-31 07:03:53,050 INFO:     Best model found after epoch 47 of 100.
2022-12-31 07:03:53,050 INFO:   Done with stage: TRAINING
2022-12-31 07:03:53,050 INFO:   Starting stage: EVALUATION
2022-12-31 07:03:53,173 INFO:   Done with stage: EVALUATION
2022-12-31 07:03:53,174 INFO:   Leaving out SEQ value Fold_6
2022-12-31 07:03:53,186 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:03:53,186 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:03:53,843 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:03:53,843 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:03:53,915 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:03:53,915 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:03:53,915 INFO:     No hyperparam tuning for this model
2022-12-31 07:03:53,915 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:03:53,915 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:03:53,916 INFO:     None feature selector for col prot
2022-12-31 07:03:53,916 INFO:     None feature selector for col prot
2022-12-31 07:03:53,916 INFO:     None feature selector for col prot
2022-12-31 07:03:53,917 INFO:     None feature selector for col chem
2022-12-31 07:03:53,917 INFO:     None feature selector for col chem
2022-12-31 07:03:53,917 INFO:     None feature selector for col chem
2022-12-31 07:03:53,917 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:03:53,917 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:03:53,919 INFO:     Number of params in model 224011
2022-12-31 07:03:53,922 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:03:53,922 INFO:   Starting stage: TRAINING
2022-12-31 07:03:53,968 INFO:     Val loss before train {'Reaction outcome loss': 0.9370604356129965, 'Total loss': 0.9370604356129965}
2022-12-31 07:03:53,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:53,968 INFO:     Epoch: 0
2022-12-31 07:03:55,592 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5641515115896861, 'Total loss': 0.5641515115896861} | train loss {'Reaction outcome loss': 0.7971194036816002, 'Total loss': 0.7971194036816002}
2022-12-31 07:03:55,592 INFO:     Found new best model at epoch 0
2022-12-31 07:03:55,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:55,593 INFO:     Epoch: 1
2022-12-31 07:03:57,168 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4959918975830078, 'Total loss': 0.4959918975830078} | train loss {'Reaction outcome loss': 0.5142028536176854, 'Total loss': 0.5142028536176854}
2022-12-31 07:03:57,168 INFO:     Found new best model at epoch 1
2022-12-31 07:03:57,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:57,169 INFO:     Epoch: 2
2022-12-31 07:03:58,802 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44048736890157064, 'Total loss': 0.44048736890157064} | train loss {'Reaction outcome loss': 0.4398780850834795, 'Total loss': 0.4398780850834795}
2022-12-31 07:03:58,803 INFO:     Found new best model at epoch 2
2022-12-31 07:03:58,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:03:58,804 INFO:     Epoch: 3
2022-12-31 07:04:00,437 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.425805061062177, 'Total loss': 0.425805061062177} | train loss {'Reaction outcome loss': 0.3983443746282736, 'Total loss': 0.3983443746282736}
2022-12-31 07:04:00,438 INFO:     Found new best model at epoch 3
2022-12-31 07:04:00,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:00,439 INFO:     Epoch: 4
2022-12-31 07:04:02,074 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42881687680880226, 'Total loss': 0.42881687680880226} | train loss {'Reaction outcome loss': 0.37110393827895394, 'Total loss': 0.37110393827895394}
2022-12-31 07:04:02,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:02,074 INFO:     Epoch: 5
2022-12-31 07:04:03,709 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41793976227442425, 'Total loss': 0.41793976227442425} | train loss {'Reaction outcome loss': 0.34577291832719037, 'Total loss': 0.34577291832719037}
2022-12-31 07:04:03,709 INFO:     Found new best model at epoch 5
2022-12-31 07:04:03,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:03,710 INFO:     Epoch: 6
2022-12-31 07:04:05,276 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41849606335163114, 'Total loss': 0.41849606335163114} | train loss {'Reaction outcome loss': 0.327545007051974, 'Total loss': 0.327545007051974}
2022-12-31 07:04:05,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:05,276 INFO:     Epoch: 7
2022-12-31 07:04:06,901 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42035847703615825, 'Total loss': 0.42035847703615825} | train loss {'Reaction outcome loss': 0.31142466894556037, 'Total loss': 0.31142466894556037}
2022-12-31 07:04:06,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:06,901 INFO:     Epoch: 8
2022-12-31 07:04:08,590 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4359423259894053, 'Total loss': 0.4359423259894053} | train loss {'Reaction outcome loss': 0.2974073787720787, 'Total loss': 0.2974073787720787}
2022-12-31 07:04:08,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:08,591 INFO:     Epoch: 9
2022-12-31 07:04:10,216 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42274854381879173, 'Total loss': 0.42274854381879173} | train loss {'Reaction outcome loss': 0.2847877757132914, 'Total loss': 0.2847877757132914}
2022-12-31 07:04:10,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:10,216 INFO:     Epoch: 10
2022-12-31 07:04:11,885 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4349627673625946, 'Total loss': 0.4349627673625946} | train loss {'Reaction outcome loss': 0.27162956984357284, 'Total loss': 0.27162956984357284}
2022-12-31 07:04:11,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:11,886 INFO:     Epoch: 11
2022-12-31 07:04:13,509 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4417835752169291, 'Total loss': 0.4417835752169291} | train loss {'Reaction outcome loss': 0.26255553469922566, 'Total loss': 0.26255553469922566}
2022-12-31 07:04:13,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:13,510 INFO:     Epoch: 12
2022-12-31 07:04:15,068 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39665050903956095, 'Total loss': 0.39665050903956095} | train loss {'Reaction outcome loss': 0.25298705265356314, 'Total loss': 0.25298705265356314}
2022-12-31 07:04:15,069 INFO:     Found new best model at epoch 12
2022-12-31 07:04:15,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:15,070 INFO:     Epoch: 13
2022-12-31 07:04:16,686 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40858763456344604, 'Total loss': 0.40858763456344604} | train loss {'Reaction outcome loss': 0.24257111455236532, 'Total loss': 0.24257111455236532}
2022-12-31 07:04:16,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:16,687 INFO:     Epoch: 14
2022-12-31 07:04:18,305 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4059330960114797, 'Total loss': 0.4059330960114797} | train loss {'Reaction outcome loss': 0.232840830292082, 'Total loss': 0.232840830292082}
2022-12-31 07:04:18,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:18,305 INFO:     Epoch: 15
2022-12-31 07:04:19,922 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3965511731803417, 'Total loss': 0.3965511731803417} | train loss {'Reaction outcome loss': 0.2292401639253762, 'Total loss': 0.2292401639253762}
2022-12-31 07:04:19,922 INFO:     Found new best model at epoch 15
2022-12-31 07:04:19,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:19,923 INFO:     Epoch: 16
2022-12-31 07:04:21,538 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39569586515426636, 'Total loss': 0.39569586515426636} | train loss {'Reaction outcome loss': 0.22189044173712766, 'Total loss': 0.22189044173712766}
2022-12-31 07:04:21,539 INFO:     Found new best model at epoch 16
2022-12-31 07:04:21,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:21,540 INFO:     Epoch: 17
2022-12-31 07:04:23,149 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39563490251700084, 'Total loss': 0.39563490251700084} | train loss {'Reaction outcome loss': 0.2123907629656017, 'Total loss': 0.2123907629656017}
2022-12-31 07:04:23,149 INFO:     Found new best model at epoch 17
2022-12-31 07:04:23,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:23,150 INFO:     Epoch: 18
2022-12-31 07:04:24,728 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39521582374970116, 'Total loss': 0.39521582374970116} | train loss {'Reaction outcome loss': 0.2112064071416532, 'Total loss': 0.2112064071416532}
2022-12-31 07:04:24,728 INFO:     Found new best model at epoch 18
2022-12-31 07:04:24,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:24,729 INFO:     Epoch: 19
2022-12-31 07:04:26,350 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41558538873990375, 'Total loss': 0.41558538873990375} | train loss {'Reaction outcome loss': 0.2044527825129484, 'Total loss': 0.2044527825129484}
2022-12-31 07:04:26,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:26,352 INFO:     Epoch: 20
2022-12-31 07:04:27,972 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4149384031693141, 'Total loss': 0.4149384031693141} | train loss {'Reaction outcome loss': 0.20045066181745125, 'Total loss': 0.20045066181745125}
2022-12-31 07:04:27,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:27,973 INFO:     Epoch: 21
2022-12-31 07:04:29,594 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4343587249517441, 'Total loss': 0.4343587249517441} | train loss {'Reaction outcome loss': 0.19436566631851, 'Total loss': 0.19436566631851}
2022-12-31 07:04:29,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:29,594 INFO:     Epoch: 22
2022-12-31 07:04:31,227 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37693190077940625, 'Total loss': 0.37693190077940625} | train loss {'Reaction outcome loss': 0.18996689346239023, 'Total loss': 0.18996689346239023}
2022-12-31 07:04:31,227 INFO:     Found new best model at epoch 22
2022-12-31 07:04:31,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:31,228 INFO:     Epoch: 23
2022-12-31 07:04:32,773 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41107129901647566, 'Total loss': 0.41107129901647566} | train loss {'Reaction outcome loss': 0.18677197780547536, 'Total loss': 0.18677197780547536}
2022-12-31 07:04:32,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:32,774 INFO:     Epoch: 24
2022-12-31 07:04:34,394 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4008425970872243, 'Total loss': 0.4008425970872243} | train loss {'Reaction outcome loss': 0.18331740793203835, 'Total loss': 0.18331740793203835}
2022-12-31 07:04:34,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:34,394 INFO:     Epoch: 25
2022-12-31 07:04:36,062 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4015174974997838, 'Total loss': 0.4015174974997838} | train loss {'Reaction outcome loss': 0.17883812646223535, 'Total loss': 0.17883812646223535}
2022-12-31 07:04:36,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:36,063 INFO:     Epoch: 26
2022-12-31 07:04:37,731 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41507914538184804, 'Total loss': 0.41507914538184804} | train loss {'Reaction outcome loss': 0.17676719741404917, 'Total loss': 0.17676719741404917}
2022-12-31 07:04:37,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:37,731 INFO:     Epoch: 27
2022-12-31 07:04:39,400 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40354214708010355, 'Total loss': 0.40354214708010355} | train loss {'Reaction outcome loss': 0.17658011139528523, 'Total loss': 0.17658011139528523}
2022-12-31 07:04:39,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:39,400 INFO:     Epoch: 28
2022-12-31 07:04:41,024 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4099692682425181, 'Total loss': 0.4099692682425181} | train loss {'Reaction outcome loss': 0.17031728844107918, 'Total loss': 0.17031728844107918}
2022-12-31 07:04:41,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:41,024 INFO:     Epoch: 29
2022-12-31 07:04:42,586 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3942061275243759, 'Total loss': 0.3942061275243759} | train loss {'Reaction outcome loss': 0.16853348236356186, 'Total loss': 0.16853348236356186}
2022-12-31 07:04:42,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:42,586 INFO:     Epoch: 30
2022-12-31 07:04:44,204 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4217286000649134, 'Total loss': 0.4217286000649134} | train loss {'Reaction outcome loss': 0.1662550653105716, 'Total loss': 0.1662550653105716}
2022-12-31 07:04:44,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:44,204 INFO:     Epoch: 31
2022-12-31 07:04:45,872 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40895305474599203, 'Total loss': 0.40895305474599203} | train loss {'Reaction outcome loss': 0.16269039276597302, 'Total loss': 0.16269039276597302}
2022-12-31 07:04:45,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:45,873 INFO:     Epoch: 32
2022-12-31 07:04:47,541 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4155514359474182, 'Total loss': 0.4155514359474182} | train loss {'Reaction outcome loss': 0.16132189809522904, 'Total loss': 0.16132189809522904}
2022-12-31 07:04:47,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:47,541 INFO:     Epoch: 33
2022-12-31 07:04:49,210 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4379787037769953, 'Total loss': 0.4379787037769953} | train loss {'Reaction outcome loss': 0.1585593518871639, 'Total loss': 0.1585593518871639}
2022-12-31 07:04:49,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:49,211 INFO:     Epoch: 34
2022-12-31 07:04:50,770 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41725011765956876, 'Total loss': 0.41725011765956876} | train loss {'Reaction outcome loss': 0.15933831371972168, 'Total loss': 0.15933831371972168}
2022-12-31 07:04:50,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:50,770 INFO:     Epoch: 35
2022-12-31 07:04:52,441 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4110256473223368, 'Total loss': 0.4110256473223368} | train loss {'Reaction outcome loss': 0.15902326177361856, 'Total loss': 0.15902326177361856}
2022-12-31 07:04:52,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:52,441 INFO:     Epoch: 36
2022-12-31 07:04:54,109 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3993852034211159, 'Total loss': 0.3993852034211159} | train loss {'Reaction outcome loss': 0.15465856260462035, 'Total loss': 0.15465856260462035}
2022-12-31 07:04:54,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:54,109 INFO:     Epoch: 37
2022-12-31 07:04:55,732 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4255055954058965, 'Total loss': 0.4255055954058965} | train loss {'Reaction outcome loss': 0.14964962627785786, 'Total loss': 0.14964962627785786}
2022-12-31 07:04:55,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:55,732 INFO:     Epoch: 38
2022-12-31 07:04:57,400 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4408141930898031, 'Total loss': 0.4408141930898031} | train loss {'Reaction outcome loss': 0.14751245023595297, 'Total loss': 0.14751245023595297}
2022-12-31 07:04:57,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:57,401 INFO:     Epoch: 39
2022-12-31 07:04:59,025 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41042612319191296, 'Total loss': 0.41042612319191296} | train loss {'Reaction outcome loss': 0.1500432358967268, 'Total loss': 0.1500432358967268}
2022-12-31 07:04:59,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:04:59,025 INFO:     Epoch: 40
2022-12-31 07:05:00,622 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42936257322629295, 'Total loss': 0.42936257322629295} | train loss {'Reaction outcome loss': 0.14859466454760584, 'Total loss': 0.14859466454760584}
2022-12-31 07:05:00,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:00,623 INFO:     Epoch: 41
2022-12-31 07:05:02,290 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4113930022964875, 'Total loss': 0.4113930022964875} | train loss {'Reaction outcome loss': 0.14675838709388614, 'Total loss': 0.14675838709388614}
2022-12-31 07:05:02,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:02,290 INFO:     Epoch: 42
2022-12-31 07:05:03,958 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41945078571637473, 'Total loss': 0.41945078571637473} | train loss {'Reaction outcome loss': 0.14693875482057084, 'Total loss': 0.14693875482057084}
2022-12-31 07:05:03,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:03,959 INFO:     Epoch: 43
2022-12-31 07:05:05,577 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4126415878534317, 'Total loss': 0.4126415878534317} | train loss {'Reaction outcome loss': 0.14362735070106625, 'Total loss': 0.14362735070106625}
2022-12-31 07:05:05,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:05,577 INFO:     Epoch: 44
2022-12-31 07:05:07,244 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42528456499179207, 'Total loss': 0.42528456499179207} | train loss {'Reaction outcome loss': 0.13914138306645066, 'Total loss': 0.13914138306645066}
2022-12-31 07:05:07,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:07,245 INFO:     Epoch: 45
2022-12-31 07:05:08,862 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41182689666748046, 'Total loss': 0.41182689666748046} | train loss {'Reaction outcome loss': 0.13984531970082745, 'Total loss': 0.13984531970082745}
2022-12-31 07:05:08,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:08,862 INFO:     Epoch: 46
2022-12-31 07:05:10,430 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3915169527133306, 'Total loss': 0.3915169527133306} | train loss {'Reaction outcome loss': 0.13716070148555917, 'Total loss': 0.13716070148555917}
2022-12-31 07:05:10,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:10,430 INFO:     Epoch: 47
2022-12-31 07:05:12,060 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4413201004266739, 'Total loss': 0.4413201004266739} | train loss {'Reaction outcome loss': 0.13614983107921558, 'Total loss': 0.13614983107921558}
2022-12-31 07:05:12,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:12,060 INFO:     Epoch: 48
2022-12-31 07:05:13,690 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.440459014972051, 'Total loss': 0.440459014972051} | train loss {'Reaction outcome loss': 0.1352524081537574, 'Total loss': 0.1352524081537574}
2022-12-31 07:05:13,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:13,690 INFO:     Epoch: 49
2022-12-31 07:05:15,319 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4165557081500689, 'Total loss': 0.4165557081500689} | train loss {'Reaction outcome loss': 0.1395633044292888, 'Total loss': 0.1395633044292888}
2022-12-31 07:05:15,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:15,319 INFO:     Epoch: 50
2022-12-31 07:05:16,947 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4019837270180384, 'Total loss': 0.4019837270180384} | train loss {'Reaction outcome loss': 0.13200473363111165, 'Total loss': 0.13200473363111165}
2022-12-31 07:05:16,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:16,948 INFO:     Epoch: 51
2022-12-31 07:05:18,523 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4361485317349434, 'Total loss': 0.4361485317349434} | train loss {'Reaction outcome loss': 0.13274197273346383, 'Total loss': 0.13274197273346383}
2022-12-31 07:05:18,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:18,524 INFO:     Epoch: 52
2022-12-31 07:05:20,144 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4101828326781591, 'Total loss': 0.4101828326781591} | train loss {'Reaction outcome loss': 0.13375028468994593, 'Total loss': 0.13375028468994593}
2022-12-31 07:05:20,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:20,145 INFO:     Epoch: 53
2022-12-31 07:05:21,764 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4194102376699448, 'Total loss': 0.4194102376699448} | train loss {'Reaction outcome loss': 0.13390742057584737, 'Total loss': 0.13390742057584737}
2022-12-31 07:05:21,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:21,765 INFO:     Epoch: 54
2022-12-31 07:05:23,386 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4331674908598264, 'Total loss': 0.4331674908598264} | train loss {'Reaction outcome loss': 0.1307662466661971, 'Total loss': 0.1307662466661971}
2022-12-31 07:05:23,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:23,386 INFO:     Epoch: 55
2022-12-31 07:05:25,022 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39251704315344493, 'Total loss': 0.39251704315344493} | train loss {'Reaction outcome loss': 0.1326695611592826, 'Total loss': 0.1326695611592826}
2022-12-31 07:05:25,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:25,022 INFO:     Epoch: 56
2022-12-31 07:05:26,650 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4560509085655212, 'Total loss': 0.4560509085655212} | train loss {'Reaction outcome loss': 0.1282884598329717, 'Total loss': 0.1282884598329717}
2022-12-31 07:05:26,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:26,650 INFO:     Epoch: 57
2022-12-31 07:05:28,254 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39463761349519094, 'Total loss': 0.39463761349519094} | train loss {'Reaction outcome loss': 0.12776712070821047, 'Total loss': 0.12776712070821047}
2022-12-31 07:05:28,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:28,255 INFO:     Epoch: 58
2022-12-31 07:05:29,879 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40192221527298294, 'Total loss': 0.40192221527298294} | train loss {'Reaction outcome loss': 0.12684861599343294, 'Total loss': 0.12684861599343294}
2022-12-31 07:05:29,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:29,879 INFO:     Epoch: 59
2022-12-31 07:05:31,548 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4209928959608078, 'Total loss': 0.4209928959608078} | train loss {'Reaction outcome loss': 0.12975950542390213, 'Total loss': 0.12975950542390213}
2022-12-31 07:05:31,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:31,549 INFO:     Epoch: 60
2022-12-31 07:05:33,173 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43612726430098214, 'Total loss': 0.43612726430098214} | train loss {'Reaction outcome loss': 0.12887568134202584, 'Total loss': 0.12887568134202584}
2022-12-31 07:05:33,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:33,173 INFO:     Epoch: 61
2022-12-31 07:05:34,842 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42169902722040814, 'Total loss': 0.42169902722040814} | train loss {'Reaction outcome loss': 0.12929125414112252, 'Total loss': 0.12929125414112252}
2022-12-31 07:05:34,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:34,843 INFO:     Epoch: 62
2022-12-31 07:05:36,424 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4047151158253352, 'Total loss': 0.4047151158253352} | train loss {'Reaction outcome loss': 0.12734507910977874, 'Total loss': 0.12734507910977874}
2022-12-31 07:05:36,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:36,425 INFO:     Epoch: 63
2022-12-31 07:05:38,050 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4298120677471161, 'Total loss': 0.4298120677471161} | train loss {'Reaction outcome loss': 0.12314655143256545, 'Total loss': 0.12314655143256545}
2022-12-31 07:05:38,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:38,050 INFO:     Epoch: 64
2022-12-31 07:05:39,675 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3991360753774643, 'Total loss': 0.3991360753774643} | train loss {'Reaction outcome loss': 0.12124115922690003, 'Total loss': 0.12124115922690003}
2022-12-31 07:05:39,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:39,675 INFO:     Epoch: 65
2022-12-31 07:05:41,343 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4232882042725881, 'Total loss': 0.4232882042725881} | train loss {'Reaction outcome loss': 0.11891861579259891, 'Total loss': 0.11891861579259891}
2022-12-31 07:05:41,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:41,344 INFO:     Epoch: 66
2022-12-31 07:05:43,012 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4045127682387829, 'Total loss': 0.4045127682387829} | train loss {'Reaction outcome loss': 0.12479709378789962, 'Total loss': 0.12479709378789962}
2022-12-31 07:05:43,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:43,012 INFO:     Epoch: 67
2022-12-31 07:05:44,636 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40706346184015274, 'Total loss': 0.40706346184015274} | train loss {'Reaction outcome loss': 0.1220893147502377, 'Total loss': 0.1220893147502377}
2022-12-31 07:05:44,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:44,636 INFO:     Epoch: 68
2022-12-31 07:05:46,220 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39741139113903046, 'Total loss': 0.39741139113903046} | train loss {'Reaction outcome loss': 0.12515581222015706, 'Total loss': 0.12515581222015706}
2022-12-31 07:05:46,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:46,220 INFO:     Epoch: 69
2022-12-31 07:05:47,843 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44853831628958385, 'Total loss': 0.44853831628958385} | train loss {'Reaction outcome loss': 0.12326885147326179, 'Total loss': 0.12326885147326179}
2022-12-31 07:05:47,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:47,844 INFO:     Epoch: 70
2022-12-31 07:05:49,468 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40444396138191224, 'Total loss': 0.40444396138191224} | train loss {'Reaction outcome loss': 0.12359754811461329, 'Total loss': 0.12359754811461329}
2022-12-31 07:05:49,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:49,468 INFO:     Epoch: 71
2022-12-31 07:05:51,090 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4472485825419426, 'Total loss': 0.4472485825419426} | train loss {'Reaction outcome loss': 0.12222802862087903, 'Total loss': 0.12222802862087903}
2022-12-31 07:05:51,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:51,091 INFO:     Epoch: 72
2022-12-31 07:05:52,713 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40662610506018004, 'Total loss': 0.40662610506018004} | train loss {'Reaction outcome loss': 0.11890553185104355, 'Total loss': 0.11890553185104355}
2022-12-31 07:05:52,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:52,713 INFO:     Epoch: 73
2022-12-31 07:05:54,332 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45432471136252084, 'Total loss': 0.45432471136252084} | train loss {'Reaction outcome loss': 0.11663146201010108, 'Total loss': 0.11663146201010108}
2022-12-31 07:05:54,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:54,332 INFO:     Epoch: 74
2022-12-31 07:05:55,952 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40630473059912525, 'Total loss': 0.40630473059912525} | train loss {'Reaction outcome loss': 0.11932467585194197, 'Total loss': 0.11932467585194197}
2022-12-31 07:05:55,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:55,952 INFO:     Epoch: 75
2022-12-31 07:05:57,578 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.385638224085172, 'Total loss': 0.385638224085172} | train loss {'Reaction outcome loss': 0.11781162568721046, 'Total loss': 0.11781162568721046}
2022-12-31 07:05:57,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:57,578 INFO:     Epoch: 76
2022-12-31 07:05:59,221 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45266765281558036, 'Total loss': 0.45266765281558036} | train loss {'Reaction outcome loss': 0.12382732795732977, 'Total loss': 0.12382732795732977}
2022-12-31 07:05:59,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:05:59,221 INFO:     Epoch: 77
2022-12-31 07:06:00,840 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38327325383822125, 'Total loss': 0.38327325383822125} | train loss {'Reaction outcome loss': 0.12427159901271281, 'Total loss': 0.12427159901271281}
2022-12-31 07:06:00,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:00,840 INFO:     Epoch: 78
2022-12-31 07:06:02,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42505434826016425, 'Total loss': 0.42505434826016425} | train loss {'Reaction outcome loss': 0.11875224300233196, 'Total loss': 0.11875224300233196}
2022-12-31 07:06:02,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:02,461 INFO:     Epoch: 79
2022-12-31 07:06:04,039 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42660402655601504, 'Total loss': 0.42660402655601504} | train loss {'Reaction outcome loss': 0.11626330498498377, 'Total loss': 0.11626330498498377}
2022-12-31 07:06:04,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:04,040 INFO:     Epoch: 80
2022-12-31 07:06:05,664 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4066039661566416, 'Total loss': 0.4066039661566416} | train loss {'Reaction outcome loss': 0.11511440584705034, 'Total loss': 0.11511440584705034}
2022-12-31 07:06:05,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:05,664 INFO:     Epoch: 81
2022-12-31 07:06:07,292 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4252398073673248, 'Total loss': 0.4252398073673248} | train loss {'Reaction outcome loss': 0.11498713923957778, 'Total loss': 0.11498713923957778}
2022-12-31 07:06:07,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:07,293 INFO:     Epoch: 82
2022-12-31 07:06:08,920 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4281667133172353, 'Total loss': 0.4281667133172353} | train loss {'Reaction outcome loss': 0.11155487844444785, 'Total loss': 0.11155487844444785}
2022-12-31 07:06:08,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:08,920 INFO:     Epoch: 83
2022-12-31 07:06:10,547 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4255766381820043, 'Total loss': 0.4255766381820043} | train loss {'Reaction outcome loss': 0.11234628299288182, 'Total loss': 0.11234628299288182}
2022-12-31 07:06:10,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:10,548 INFO:     Epoch: 84
2022-12-31 07:06:12,173 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4450550595919291, 'Total loss': 0.4450550595919291} | train loss {'Reaction outcome loss': 0.11246255606863419, 'Total loss': 0.11246255606863419}
2022-12-31 07:06:12,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:12,174 INFO:     Epoch: 85
2022-12-31 07:06:13,757 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3911481430133184, 'Total loss': 0.3911481430133184} | train loss {'Reaction outcome loss': 0.11220853013366407, 'Total loss': 0.11220853013366407}
2022-12-31 07:06:13,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:13,757 INFO:     Epoch: 86
2022-12-31 07:06:15,385 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45150758425394694, 'Total loss': 0.45150758425394694} | train loss {'Reaction outcome loss': 0.11610126330782844, 'Total loss': 0.11610126330782844}
2022-12-31 07:06:15,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:15,385 INFO:     Epoch: 87
2022-12-31 07:06:17,054 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4299898197253545, 'Total loss': 0.4299898197253545} | train loss {'Reaction outcome loss': 0.11405236003937247, 'Total loss': 0.11405236003937247}
2022-12-31 07:06:17,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:17,055 INFO:     Epoch: 88
2022-12-31 07:06:18,716 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4358780264854431, 'Total loss': 0.4358780264854431} | train loss {'Reaction outcome loss': 0.11560329722596958, 'Total loss': 0.11560329722596958}
2022-12-31 07:06:18,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:18,716 INFO:     Epoch: 89
2022-12-31 07:06:20,384 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4207728383441766, 'Total loss': 0.4207728383441766} | train loss {'Reaction outcome loss': 0.1129344876877466, 'Total loss': 0.1129344876877466}
2022-12-31 07:06:20,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:20,384 INFO:     Epoch: 90
2022-12-31 07:06:21,967 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44660740594069165, 'Total loss': 0.44660740594069165} | train loss {'Reaction outcome loss': 0.11175543651832032, 'Total loss': 0.11175543651832032}
2022-12-31 07:06:21,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:21,967 INFO:     Epoch: 91
2022-12-31 07:06:23,595 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43695898056030275, 'Total loss': 0.43695898056030275} | train loss {'Reaction outcome loss': 0.1140724735936345, 'Total loss': 0.1140724735936345}
2022-12-31 07:06:23,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:23,596 INFO:     Epoch: 92
2022-12-31 07:06:25,223 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4131801098585129, 'Total loss': 0.4131801098585129} | train loss {'Reaction outcome loss': 0.11366610160258864, 'Total loss': 0.11366610160258864}
2022-12-31 07:06:25,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:25,224 INFO:     Epoch: 93
2022-12-31 07:06:26,852 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4071502466996511, 'Total loss': 0.4071502466996511} | train loss {'Reaction outcome loss': 0.11186338363918022, 'Total loss': 0.11186338363918022}
2022-12-31 07:06:26,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:26,852 INFO:     Epoch: 94
2022-12-31 07:06:28,481 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3975905070702235, 'Total loss': 0.3975905070702235} | train loss {'Reaction outcome loss': 0.11219140551379118, 'Total loss': 0.11219140551379118}
2022-12-31 07:06:28,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:28,481 INFO:     Epoch: 95
2022-12-31 07:06:30,110 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40842696527640027, 'Total loss': 0.40842696527640027} | train loss {'Reaction outcome loss': 0.10895682369873251, 'Total loss': 0.10895682369873251}
2022-12-31 07:06:30,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:30,111 INFO:     Epoch: 96
2022-12-31 07:06:31,704 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40241868793964386, 'Total loss': 0.40241868793964386} | train loss {'Reaction outcome loss': 0.11550412460697633, 'Total loss': 0.11550412460697633}
2022-12-31 07:06:31,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:31,704 INFO:     Epoch: 97
2022-12-31 07:06:33,333 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4228869915008545, 'Total loss': 0.4228869915008545} | train loss {'Reaction outcome loss': 0.10964733488951887, 'Total loss': 0.10964733488951887}
2022-12-31 07:06:33,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:33,333 INFO:     Epoch: 98
2022-12-31 07:06:34,963 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4327926749984423, 'Total loss': 0.4327926749984423} | train loss {'Reaction outcome loss': 0.11828838265921235, 'Total loss': 0.11828838265921235}
2022-12-31 07:06:34,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:34,963 INFO:     Epoch: 99
2022-12-31 07:06:36,593 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42012404402097064, 'Total loss': 0.42012404402097064} | train loss {'Reaction outcome loss': 0.12086167757311964, 'Total loss': 0.12086167757311964}
2022-12-31 07:06:36,593 INFO:     Best model found after epoch 23 of 100.
2022-12-31 07:06:36,593 INFO:   Done with stage: TRAINING
2022-12-31 07:06:36,593 INFO:   Starting stage: EVALUATION
2022-12-31 07:06:36,717 INFO:   Done with stage: EVALUATION
2022-12-31 07:06:36,717 INFO:   Leaving out SEQ value Fold_7
2022-12-31 07:06:36,729 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:06:36,729 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:06:37,375 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:06:37,375 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:06:37,445 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:06:37,445 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:06:37,445 INFO:     No hyperparam tuning for this model
2022-12-31 07:06:37,445 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:06:37,445 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:06:37,446 INFO:     None feature selector for col prot
2022-12-31 07:06:37,446 INFO:     None feature selector for col prot
2022-12-31 07:06:37,446 INFO:     None feature selector for col prot
2022-12-31 07:06:37,447 INFO:     None feature selector for col chem
2022-12-31 07:06:37,447 INFO:     None feature selector for col chem
2022-12-31 07:06:37,447 INFO:     None feature selector for col chem
2022-12-31 07:06:37,447 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:06:37,447 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:06:37,449 INFO:     Number of params in model 224011
2022-12-31 07:06:37,452 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:06:37,453 INFO:   Starting stage: TRAINING
2022-12-31 07:06:37,498 INFO:     Val loss before train {'Reaction outcome loss': 1.1211174647013347, 'Total loss': 1.1211174647013347}
2022-12-31 07:06:37,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:37,499 INFO:     Epoch: 0
2022-12-31 07:06:39,121 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6301859180132549, 'Total loss': 0.6301859180132549} | train loss {'Reaction outcome loss': 0.7774832222840168, 'Total loss': 0.7774832222840168}
2022-12-31 07:06:39,122 INFO:     Found new best model at epoch 0
2022-12-31 07:06:39,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:39,123 INFO:     Epoch: 1
2022-12-31 07:06:40,728 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5715372403462727, 'Total loss': 0.5715372403462727} | train loss {'Reaction outcome loss': 0.5218002333481243, 'Total loss': 0.5218002333481243}
2022-12-31 07:06:40,728 INFO:     Found new best model at epoch 1
2022-12-31 07:06:40,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:40,729 INFO:     Epoch: 2
2022-12-31 07:06:42,353 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5091967890659969, 'Total loss': 0.5091967890659969} | train loss {'Reaction outcome loss': 0.4535820297356965, 'Total loss': 0.4535820297356965}
2022-12-31 07:06:42,353 INFO:     Found new best model at epoch 2
2022-12-31 07:06:42,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:42,354 INFO:     Epoch: 3
2022-12-31 07:06:43,980 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5138267437616985, 'Total loss': 0.5138267437616985} | train loss {'Reaction outcome loss': 0.410463374229553, 'Total loss': 0.410463374229553}
2022-12-31 07:06:43,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:43,980 INFO:     Epoch: 4
2022-12-31 07:06:45,603 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5140762348969777, 'Total loss': 0.5140762348969777} | train loss {'Reaction outcome loss': 0.3808762681926938, 'Total loss': 0.3808762681926938}
2022-12-31 07:06:45,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:45,604 INFO:     Epoch: 5
2022-12-31 07:06:47,221 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4522247811158498, 'Total loss': 0.4522247811158498} | train loss {'Reaction outcome loss': 0.35594154500227043, 'Total loss': 0.35594154500227043}
2022-12-31 07:06:47,222 INFO:     Found new best model at epoch 5
2022-12-31 07:06:47,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:47,223 INFO:     Epoch: 6
2022-12-31 07:06:48,844 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4456018090248108, 'Total loss': 0.4456018090248108} | train loss {'Reaction outcome loss': 0.35881149697292974, 'Total loss': 0.35881149697292974}
2022-12-31 07:06:48,844 INFO:     Found new best model at epoch 6
2022-12-31 07:06:48,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:48,845 INFO:     Epoch: 7
2022-12-31 07:06:50,452 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48415547211964927, 'Total loss': 0.48415547211964927} | train loss {'Reaction outcome loss': 0.3463320175079929, 'Total loss': 0.3463320175079929}
2022-12-31 07:06:50,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:50,453 INFO:     Epoch: 8
2022-12-31 07:06:52,074 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48815990885098776, 'Total loss': 0.48815990885098776} | train loss {'Reaction outcome loss': 0.3077406451591979, 'Total loss': 0.3077406451591979}
2022-12-31 07:06:52,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:52,074 INFO:     Epoch: 9
2022-12-31 07:06:53,695 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4677344004313151, 'Total loss': 0.4677344004313151} | train loss {'Reaction outcome loss': 0.29317383012971404, 'Total loss': 0.29317383012971404}
2022-12-31 07:06:53,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:53,696 INFO:     Epoch: 10
2022-12-31 07:06:55,317 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46524488627910615, 'Total loss': 0.46524488627910615} | train loss {'Reaction outcome loss': 0.28084535559542745, 'Total loss': 0.28084535559542745}
2022-12-31 07:06:55,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:55,317 INFO:     Epoch: 11
2022-12-31 07:06:56,941 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4434144586324692, 'Total loss': 0.4434144586324692} | train loss {'Reaction outcome loss': 0.268313257286892, 'Total loss': 0.268313257286892}
2022-12-31 07:06:56,941 INFO:     Found new best model at epoch 11
2022-12-31 07:06:56,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:56,942 INFO:     Epoch: 12
2022-12-31 07:06:58,576 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47771722575028736, 'Total loss': 0.47771722575028736} | train loss {'Reaction outcome loss': 0.26168892886050965, 'Total loss': 0.26168892886050965}
2022-12-31 07:06:58,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:06:58,577 INFO:     Epoch: 13
2022-12-31 07:07:00,200 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48057867487271627, 'Total loss': 0.48057867487271627} | train loss {'Reaction outcome loss': 0.25168558929573814, 'Total loss': 0.25168558929573814}
2022-12-31 07:07:00,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:00,200 INFO:     Epoch: 14
2022-12-31 07:07:01,825 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48478834132353466, 'Total loss': 0.48478834132353466} | train loss {'Reaction outcome loss': 0.24032765871210807, 'Total loss': 0.24032765871210807}
2022-12-31 07:07:01,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:01,826 INFO:     Epoch: 15
2022-12-31 07:07:03,450 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47037069698174794, 'Total loss': 0.47037069698174794} | train loss {'Reaction outcome loss': 0.23614976909521973, 'Total loss': 0.23614976909521973}
2022-12-31 07:07:03,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:03,451 INFO:     Epoch: 16
2022-12-31 07:07:05,076 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4713634431362152, 'Total loss': 0.4713634431362152} | train loss {'Reaction outcome loss': 0.22466127336678177, 'Total loss': 0.22466127336678177}
2022-12-31 07:07:05,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:05,076 INFO:     Epoch: 17
2022-12-31 07:07:06,706 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45296273827552797, 'Total loss': 0.45296273827552797} | train loss {'Reaction outcome loss': 0.22298864420314413, 'Total loss': 0.22298864420314413}
2022-12-31 07:07:06,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:06,707 INFO:     Epoch: 18
2022-12-31 07:07:08,298 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46828702290852864, 'Total loss': 0.46828702290852864} | train loss {'Reaction outcome loss': 0.21517342613357038, 'Total loss': 0.21517342613357038}
2022-12-31 07:07:08,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:08,298 INFO:     Epoch: 19
2022-12-31 07:07:09,960 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4509463687737783, 'Total loss': 0.4509463687737783} | train loss {'Reaction outcome loss': 0.20825389885525827, 'Total loss': 0.20825389885525827}
2022-12-31 07:07:09,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:09,961 INFO:     Epoch: 20
2022-12-31 07:07:11,581 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4768428564071655, 'Total loss': 0.4768428564071655} | train loss {'Reaction outcome loss': 0.20949749643172044, 'Total loss': 0.20949749643172044}
2022-12-31 07:07:11,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:11,581 INFO:     Epoch: 21
2022-12-31 07:07:13,244 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5000893493493398, 'Total loss': 0.5000893493493398} | train loss {'Reaction outcome loss': 0.20589919165164852, 'Total loss': 0.20589919165164852}
2022-12-31 07:07:13,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:13,244 INFO:     Epoch: 22
2022-12-31 07:07:14,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48633605341116587, 'Total loss': 0.48633605341116587} | train loss {'Reaction outcome loss': 0.1985183262967426, 'Total loss': 0.1985183262967426}
2022-12-31 07:07:14,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:14,906 INFO:     Epoch: 23
2022-12-31 07:07:16,531 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4506164163351059, 'Total loss': 0.4506164163351059} | train loss {'Reaction outcome loss': 0.1931106594823085, 'Total loss': 0.1931106594823085}
2022-12-31 07:07:16,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:16,532 INFO:     Epoch: 24
2022-12-31 07:07:18,143 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47771071195602416, 'Total loss': 0.47771071195602416} | train loss {'Reaction outcome loss': 0.1882143934355185, 'Total loss': 0.1882143934355185}
2022-12-31 07:07:18,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:18,143 INFO:     Epoch: 25
2022-12-31 07:07:19,805 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.479028324286143, 'Total loss': 0.479028324286143} | train loss {'Reaction outcome loss': 0.18625504195936798, 'Total loss': 0.18625504195936798}
2022-12-31 07:07:19,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:19,805 INFO:     Epoch: 26
2022-12-31 07:07:21,421 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4779564440250397, 'Total loss': 0.4779564440250397} | train loss {'Reaction outcome loss': 0.1807145066458084, 'Total loss': 0.1807145066458084}
2022-12-31 07:07:21,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:21,421 INFO:     Epoch: 27
2022-12-31 07:07:23,082 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5162571171919504, 'Total loss': 0.5162571171919504} | train loss {'Reaction outcome loss': 0.18121992274308982, 'Total loss': 0.18121992274308982}
2022-12-31 07:07:23,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:23,082 INFO:     Epoch: 28
2022-12-31 07:07:24,744 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5106121336420377, 'Total loss': 0.5106121336420377} | train loss {'Reaction outcome loss': 0.17723981622152613, 'Total loss': 0.17723981622152613}
2022-12-31 07:07:24,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:24,744 INFO:     Epoch: 29
2022-12-31 07:07:26,351 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4775570829709371, 'Total loss': 0.4775570829709371} | train loss {'Reaction outcome loss': 0.1759061259082586, 'Total loss': 0.1759061259082586}
2022-12-31 07:07:26,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:26,351 INFO:     Epoch: 30
2022-12-31 07:07:27,976 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4860038056969643, 'Total loss': 0.4860038056969643} | train loss {'Reaction outcome loss': 0.1737989112089449, 'Total loss': 0.1737989112089449}
2022-12-31 07:07:27,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:27,976 INFO:     Epoch: 31
2022-12-31 07:07:29,601 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.488658348719279, 'Total loss': 0.488658348719279} | train loss {'Reaction outcome loss': 0.1870006774349705, 'Total loss': 0.1870006774349705}
2022-12-31 07:07:29,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:29,602 INFO:     Epoch: 32
2022-12-31 07:07:31,227 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4928266902764638, 'Total loss': 0.4928266902764638} | train loss {'Reaction outcome loss': 0.18176722291441957, 'Total loss': 0.18176722291441957}
2022-12-31 07:07:31,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:31,227 INFO:     Epoch: 33
2022-12-31 07:07:32,852 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49461572567621864, 'Total loss': 0.49461572567621864} | train loss {'Reaction outcome loss': 0.16495412941077264, 'Total loss': 0.16495412941077264}
2022-12-31 07:07:32,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:32,852 INFO:     Epoch: 34
2022-12-31 07:07:34,465 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4715818285942078, 'Total loss': 0.4715818285942078} | train loss {'Reaction outcome loss': 0.16406887755800964, 'Total loss': 0.16406887755800964}
2022-12-31 07:07:34,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:34,465 INFO:     Epoch: 35
2022-12-31 07:07:36,083 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49957207043965657, 'Total loss': 0.49957207043965657} | train loss {'Reaction outcome loss': 0.16004035269957123, 'Total loss': 0.16004035269957123}
2022-12-31 07:07:36,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:36,083 INFO:     Epoch: 36
2022-12-31 07:07:37,705 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46981772283713025, 'Total loss': 0.46981772283713025} | train loss {'Reaction outcome loss': 0.15888296757141662, 'Total loss': 0.15888296757141662}
2022-12-31 07:07:37,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:37,705 INFO:     Epoch: 37
2022-12-31 07:07:39,326 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4996683190266291, 'Total loss': 0.4996683190266291} | train loss {'Reaction outcome loss': 0.15850590619569024, 'Total loss': 0.15850590619569024}
2022-12-31 07:07:39,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:39,326 INFO:     Epoch: 38
2022-12-31 07:07:40,949 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4898092438777288, 'Total loss': 0.4898092438777288} | train loss {'Reaction outcome loss': 0.17185023584423345, 'Total loss': 0.17185023584423345}
2022-12-31 07:07:40,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:40,950 INFO:     Epoch: 39
2022-12-31 07:07:42,573 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4882560392220815, 'Total loss': 0.4882560392220815} | train loss {'Reaction outcome loss': 0.16008701832544064, 'Total loss': 0.16008701832544064}
2022-12-31 07:07:42,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:42,573 INFO:     Epoch: 40
2022-12-31 07:07:43,994 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5044870853424073, 'Total loss': 0.5044870853424073} | train loss {'Reaction outcome loss': 0.1592212354771091, 'Total loss': 0.1592212354771091}
2022-12-31 07:07:43,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:43,994 INFO:     Epoch: 41
2022-12-31 07:07:45,130 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4984194238980611, 'Total loss': 0.4984194238980611} | train loss {'Reaction outcome loss': 0.17951685759623576, 'Total loss': 0.17951685759623576}
2022-12-31 07:07:45,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:45,130 INFO:     Epoch: 42
2022-12-31 07:07:46,266 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.466788383324941, 'Total loss': 0.466788383324941} | train loss {'Reaction outcome loss': 0.16010884189829772, 'Total loss': 0.16010884189829772}
2022-12-31 07:07:46,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:46,267 INFO:     Epoch: 43
2022-12-31 07:07:47,402 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5174048205216726, 'Total loss': 0.5174048205216726} | train loss {'Reaction outcome loss': 0.15852637760057722, 'Total loss': 0.15852637760057722}
2022-12-31 07:07:47,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:47,403 INFO:     Epoch: 44
2022-12-31 07:07:48,794 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5044882496198019, 'Total loss': 0.5044882496198019} | train loss {'Reaction outcome loss': 0.16491602467262503, 'Total loss': 0.16491602467262503}
2022-12-31 07:07:48,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:48,794 INFO:     Epoch: 45
2022-12-31 07:07:50,407 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4683159242073695, 'Total loss': 0.4683159242073695} | train loss {'Reaction outcome loss': 0.1569822827915904, 'Total loss': 0.1569822827915904}
2022-12-31 07:07:50,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:50,408 INFO:     Epoch: 46
2022-12-31 07:07:52,029 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4945118794838587, 'Total loss': 0.4945118794838587} | train loss {'Reaction outcome loss': 0.15177106839898552, 'Total loss': 0.15177106839898552}
2022-12-31 07:07:52,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:52,029 INFO:     Epoch: 47
2022-12-31 07:07:53,646 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4990058273077011, 'Total loss': 0.4990058273077011} | train loss {'Reaction outcome loss': 0.14844584168420863, 'Total loss': 0.14844584168420863}
2022-12-31 07:07:53,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:53,647 INFO:     Epoch: 48
2022-12-31 07:07:55,264 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48595961928367615, 'Total loss': 0.48595961928367615} | train loss {'Reaction outcome loss': 0.14848565611453893, 'Total loss': 0.14848565611453893}
2022-12-31 07:07:55,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:55,265 INFO:     Epoch: 49
2022-12-31 07:07:56,887 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5095607817173005, 'Total loss': 0.5095607817173005} | train loss {'Reaction outcome loss': 0.1538277622109846, 'Total loss': 0.1538277622109846}
2022-12-31 07:07:56,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:56,888 INFO:     Epoch: 50
2022-12-31 07:07:58,531 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4892846643924713, 'Total loss': 0.4892846643924713} | train loss {'Reaction outcome loss': 0.15568998003837423, 'Total loss': 0.15568998003837423}
2022-12-31 07:07:58,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:07:58,531 INFO:     Epoch: 51
2022-12-31 07:08:00,175 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5146371444066365, 'Total loss': 0.5146371444066365} | train loss {'Reaction outcome loss': 0.148364479096452, 'Total loss': 0.148364479096452}
2022-12-31 07:08:00,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:00,175 INFO:     Epoch: 52
2022-12-31 07:08:01,796 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5003984173138937, 'Total loss': 0.5003984173138937} | train loss {'Reaction outcome loss': 0.14136593223404328, 'Total loss': 0.14136593223404328}
2022-12-31 07:08:01,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:01,796 INFO:     Epoch: 53
2022-12-31 07:08:03,416 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4691838413476944, 'Total loss': 0.4691838413476944} | train loss {'Reaction outcome loss': 0.1433779553150036, 'Total loss': 0.1433779553150036}
2022-12-31 07:08:03,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:03,417 INFO:     Epoch: 54
2022-12-31 07:08:05,078 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4810902496178945, 'Total loss': 0.4810902496178945} | train loss {'Reaction outcome loss': 0.13541880683518737, 'Total loss': 0.13541880683518737}
2022-12-31 07:08:05,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:05,078 INFO:     Epoch: 55
2022-12-31 07:08:06,700 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4919920563697815, 'Total loss': 0.4919920563697815} | train loss {'Reaction outcome loss': 0.13677835930476262, 'Total loss': 0.13677835930476262}
2022-12-31 07:08:06,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:06,701 INFO:     Epoch: 56
2022-12-31 07:08:08,361 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49979447821776074, 'Total loss': 0.49979447821776074} | train loss {'Reaction outcome loss': 0.13861317136257456, 'Total loss': 0.13861317136257456}
2022-12-31 07:08:08,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:08,362 INFO:     Epoch: 57
2022-12-31 07:08:09,996 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48465433915456135, 'Total loss': 0.48465433915456135} | train loss {'Reaction outcome loss': 0.13541211574942202, 'Total loss': 0.13541211574942202}
2022-12-31 07:08:09,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:09,997 INFO:     Epoch: 58
2022-12-31 07:08:11,607 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4882621089617411, 'Total loss': 0.4882621089617411} | train loss {'Reaction outcome loss': 0.13393323245944214, 'Total loss': 0.13393323245944214}
2022-12-31 07:08:11,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:11,608 INFO:     Epoch: 59
2022-12-31 07:08:13,222 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4936837414900462, 'Total loss': 0.4936837414900462} | train loss {'Reaction outcome loss': 0.1326234044664897, 'Total loss': 0.1326234044664897}
2022-12-31 07:08:13,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:13,222 INFO:     Epoch: 60
2022-12-31 07:08:14,835 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4666844030221303, 'Total loss': 0.4666844030221303} | train loss {'Reaction outcome loss': 0.13518596294444, 'Total loss': 0.13518596294444}
2022-12-31 07:08:14,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:14,835 INFO:     Epoch: 61
2022-12-31 07:08:16,446 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49355029662450156, 'Total loss': 0.49355029662450156} | train loss {'Reaction outcome loss': 0.13513304545663035, 'Total loss': 0.13513304545663035}
2022-12-31 07:08:16,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:16,447 INFO:     Epoch: 62
2022-12-31 07:08:18,062 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5078975150982539, 'Total loss': 0.5078975150982539} | train loss {'Reaction outcome loss': 0.1303427094421552, 'Total loss': 0.1303427094421552}
2022-12-31 07:08:18,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:18,063 INFO:     Epoch: 63
2022-12-31 07:08:19,677 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4759060800075531, 'Total loss': 0.4759060800075531} | train loss {'Reaction outcome loss': 0.12823546916886047, 'Total loss': 0.12823546916886047}
2022-12-31 07:08:19,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:19,677 INFO:     Epoch: 64
2022-12-31 07:08:21,337 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4691782573858897, 'Total loss': 0.4691782573858897} | train loss {'Reaction outcome loss': 0.1268031043262032, 'Total loss': 0.1268031043262032}
2022-12-31 07:08:21,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:21,338 INFO:     Epoch: 65
2022-12-31 07:08:22,998 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48084645768006645, 'Total loss': 0.48084645768006645} | train loss {'Reaction outcome loss': 0.12527633397273705, 'Total loss': 0.12527633397273705}
2022-12-31 07:08:22,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:22,998 INFO:     Epoch: 66
2022-12-31 07:08:24,620 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49673179785410565, 'Total loss': 0.49673179785410565} | train loss {'Reaction outcome loss': 0.12708459027361232, 'Total loss': 0.12708459027361232}
2022-12-31 07:08:24,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:24,621 INFO:     Epoch: 67
2022-12-31 07:08:26,232 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49380143781503044, 'Total loss': 0.49380143781503044} | train loss {'Reaction outcome loss': 0.13217333998784234, 'Total loss': 0.13217333998784234}
2022-12-31 07:08:26,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:26,232 INFO:     Epoch: 68
2022-12-31 07:08:27,846 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4959901630878448, 'Total loss': 0.4959901630878448} | train loss {'Reaction outcome loss': 0.12853241731041318, 'Total loss': 0.12853241731041318}
2022-12-31 07:08:27,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:27,846 INFO:     Epoch: 69
2022-12-31 07:08:29,458 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48468911747137705, 'Total loss': 0.48468911747137705} | train loss {'Reaction outcome loss': 0.12442534674714872, 'Total loss': 0.12442534674714872}
2022-12-31 07:08:29,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:29,458 INFO:     Epoch: 70
2022-12-31 07:08:31,070 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5072605609893799, 'Total loss': 0.5072605609893799} | train loss {'Reaction outcome loss': 0.119245641000579, 'Total loss': 0.119245641000579}
2022-12-31 07:08:31,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:31,071 INFO:     Epoch: 71
2022-12-31 07:08:32,683 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49337033107876777, 'Total loss': 0.49337033107876777} | train loss {'Reaction outcome loss': 0.11706085263015838, 'Total loss': 0.11706085263015838}
2022-12-31 07:08:32,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:32,683 INFO:     Epoch: 72
2022-12-31 07:08:34,295 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5276157985130946, 'Total loss': 0.5276157985130946} | train loss {'Reaction outcome loss': 0.12792807330708086, 'Total loss': 0.12792807330708086}
2022-12-31 07:08:34,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:34,296 INFO:     Epoch: 73
2022-12-31 07:08:35,919 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5249311625957489, 'Total loss': 0.5249311625957489} | train loss {'Reaction outcome loss': 0.1401862544834317, 'Total loss': 0.1401862544834317}
2022-12-31 07:08:35,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:35,919 INFO:     Epoch: 74
2022-12-31 07:08:37,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5105298280715942, 'Total loss': 0.5105298280715942} | train loss {'Reaction outcome loss': 0.12360828552023716, 'Total loss': 0.12360828552023716}
2022-12-31 07:08:37,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:37,534 INFO:     Epoch: 75
2022-12-31 07:08:39,157 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4799044986565908, 'Total loss': 0.4799044986565908} | train loss {'Reaction outcome loss': 0.11916255934393384, 'Total loss': 0.11916255934393384}
2022-12-31 07:08:39,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:39,158 INFO:     Epoch: 76
2022-12-31 07:08:40,784 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.464917266368866, 'Total loss': 0.464917266368866} | train loss {'Reaction outcome loss': 0.1179169829529069, 'Total loss': 0.1179169829529069}
2022-12-31 07:08:40,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:40,784 INFO:     Epoch: 77
2022-12-31 07:08:42,414 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5051199853420257, 'Total loss': 0.5051199853420257} | train loss {'Reaction outcome loss': 0.11804627994939253, 'Total loss': 0.11804627994939253}
2022-12-31 07:08:42,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:42,416 INFO:     Epoch: 78
2022-12-31 07:08:44,029 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5278235634167989, 'Total loss': 0.5278235634167989} | train loss {'Reaction outcome loss': 0.11614138120785356, 'Total loss': 0.11614138120785356}
2022-12-31 07:08:44,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:44,029 INFO:     Epoch: 79
2022-12-31 07:08:45,677 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5068527241547902, 'Total loss': 0.5068527241547902} | train loss {'Reaction outcome loss': 0.11550006272095809, 'Total loss': 0.11550006272095809}
2022-12-31 07:08:45,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:45,678 INFO:     Epoch: 80
2022-12-31 07:08:47,300 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5295007705688477, 'Total loss': 0.5295007705688477} | train loss {'Reaction outcome loss': 0.11372273155075822, 'Total loss': 0.11372273155075822}
2022-12-31 07:08:47,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:47,300 INFO:     Epoch: 81
2022-12-31 07:08:48,917 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5012136509021123, 'Total loss': 0.5012136509021123} | train loss {'Reaction outcome loss': 0.11879233133606538, 'Total loss': 0.11879233133606538}
2022-12-31 07:08:48,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:48,918 INFO:     Epoch: 82
2022-12-31 07:08:50,532 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5071818888187408, 'Total loss': 0.5071818888187408} | train loss {'Reaction outcome loss': 0.11357222434093854, 'Total loss': 0.11357222434093854}
2022-12-31 07:08:50,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:50,533 INFO:     Epoch: 83
2022-12-31 07:08:52,143 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4879403173923492, 'Total loss': 0.4879403173923492} | train loss {'Reaction outcome loss': 0.11781554904671898, 'Total loss': 0.11781554904671898}
2022-12-31 07:08:52,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:52,144 INFO:     Epoch: 84
2022-12-31 07:08:53,808 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5186462660630544, 'Total loss': 0.5186462660630544} | train loss {'Reaction outcome loss': 0.11733803506280495, 'Total loss': 0.11733803506280495}
2022-12-31 07:08:53,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:53,808 INFO:     Epoch: 85
2022-12-31 07:08:55,427 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48507706026236214, 'Total loss': 0.48507706026236214} | train loss {'Reaction outcome loss': 0.11588340720434485, 'Total loss': 0.11588340720434485}
2022-12-31 07:08:55,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:55,427 INFO:     Epoch: 86
2022-12-31 07:08:57,091 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48383052945137023, 'Total loss': 0.48383052945137023} | train loss {'Reaction outcome loss': 0.11824923550686461, 'Total loss': 0.11824923550686461}
2022-12-31 07:08:57,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:57,091 INFO:     Epoch: 87
2022-12-31 07:08:58,755 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5184090594450633, 'Total loss': 0.5184090594450633} | train loss {'Reaction outcome loss': 0.11416322929089538, 'Total loss': 0.11416322929089538}
2022-12-31 07:08:58,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:08:58,755 INFO:     Epoch: 88
2022-12-31 07:09:00,372 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49565462668736776, 'Total loss': 0.49565462668736776} | train loss {'Reaction outcome loss': 0.11364334700456179, 'Total loss': 0.11364334700456179}
2022-12-31 07:09:00,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:00,373 INFO:     Epoch: 89
2022-12-31 07:09:01,991 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47814699361721674, 'Total loss': 0.47814699361721674} | train loss {'Reaction outcome loss': 0.11551164516461448, 'Total loss': 0.11551164516461448}
2022-12-31 07:09:01,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:01,992 INFO:     Epoch: 90
2022-12-31 07:09:03,614 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4597613483667374, 'Total loss': 0.4597613483667374} | train loss {'Reaction outcome loss': 0.11450744269066068, 'Total loss': 0.11450744269066068}
2022-12-31 07:09:03,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:03,614 INFO:     Epoch: 91
2022-12-31 07:09:05,269 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4807094802459081, 'Total loss': 0.4807094802459081} | train loss {'Reaction outcome loss': 0.10882307454079822, 'Total loss': 0.10882307454079822}
2022-12-31 07:09:05,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:05,269 INFO:     Epoch: 92
2022-12-31 07:09:06,889 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.51790531873703, 'Total loss': 0.51790531873703} | train loss {'Reaction outcome loss': 0.11161018959430057, 'Total loss': 0.11161018959430057}
2022-12-31 07:09:06,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:06,889 INFO:     Epoch: 93
2022-12-31 07:09:08,554 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47935948173205056, 'Total loss': 0.47935948173205056} | train loss {'Reaction outcome loss': 0.1100706993521548, 'Total loss': 0.1100706993521548}
2022-12-31 07:09:08,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:08,554 INFO:     Epoch: 94
2022-12-31 07:09:10,172 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5019187072912852, 'Total loss': 0.5019187072912852} | train loss {'Reaction outcome loss': 0.11053148966512062, 'Total loss': 0.11053148966512062}
2022-12-31 07:09:10,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:10,172 INFO:     Epoch: 95
2022-12-31 07:09:11,841 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4579696198304494, 'Total loss': 0.4579696198304494} | train loss {'Reaction outcome loss': 0.1162838088491918, 'Total loss': 0.1162838088491918}
2022-12-31 07:09:11,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:11,841 INFO:     Epoch: 96
2022-12-31 07:09:13,470 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5128454754749934, 'Total loss': 0.5128454754749934} | train loss {'Reaction outcome loss': 0.11011733460907346, 'Total loss': 0.11011733460907346}
2022-12-31 07:09:13,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:13,472 INFO:     Epoch: 97
2022-12-31 07:09:15,093 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48025721311569214, 'Total loss': 0.48025721311569214} | train loss {'Reaction outcome loss': 0.10972714612527878, 'Total loss': 0.10972714612527878}
2022-12-31 07:09:15,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:15,093 INFO:     Epoch: 98
2022-12-31 07:09:16,709 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4799144446849823, 'Total loss': 0.4799144446849823} | train loss {'Reaction outcome loss': 0.11006163622495597, 'Total loss': 0.11006163622495597}
2022-12-31 07:09:16,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:16,709 INFO:     Epoch: 99
2022-12-31 07:09:18,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5056451857089996, 'Total loss': 0.5056451857089996} | train loss {'Reaction outcome loss': 0.10615571222856027, 'Total loss': 0.10615571222856027}
2022-12-31 07:09:18,330 INFO:     Best model found after epoch 12 of 100.
2022-12-31 07:09:18,330 INFO:   Done with stage: TRAINING
2022-12-31 07:09:18,330 INFO:   Starting stage: EVALUATION
2022-12-31 07:09:18,460 INFO:   Done with stage: EVALUATION
2022-12-31 07:09:18,460 INFO:   Leaving out SEQ value Fold_8
2022-12-31 07:09:18,473 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 07:09:18,473 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:09:19,118 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:09:19,118 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:09:19,188 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:09:19,188 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:09:19,188 INFO:     No hyperparam tuning for this model
2022-12-31 07:09:19,188 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:09:19,188 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:09:19,189 INFO:     None feature selector for col prot
2022-12-31 07:09:19,189 INFO:     None feature selector for col prot
2022-12-31 07:09:19,189 INFO:     None feature selector for col prot
2022-12-31 07:09:19,190 INFO:     None feature selector for col chem
2022-12-31 07:09:19,190 INFO:     None feature selector for col chem
2022-12-31 07:09:19,190 INFO:     None feature selector for col chem
2022-12-31 07:09:19,190 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:09:19,190 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:09:19,192 INFO:     Number of params in model 224011
2022-12-31 07:09:19,195 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:09:19,195 INFO:   Starting stage: TRAINING
2022-12-31 07:09:19,241 INFO:     Val loss before train {'Reaction outcome loss': 0.8318350970745086, 'Total loss': 0.8318350970745086}
2022-12-31 07:09:19,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:19,241 INFO:     Epoch: 0
2022-12-31 07:09:20,872 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.560877283414205, 'Total loss': 0.560877283414205} | train loss {'Reaction outcome loss': 0.7868591581817961, 'Total loss': 0.7868591581817961}
2022-12-31 07:09:20,873 INFO:     Found new best model at epoch 0
2022-12-31 07:09:20,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:20,874 INFO:     Epoch: 1
2022-12-31 07:09:22,486 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5013855904340744, 'Total loss': 0.5013855904340744} | train loss {'Reaction outcome loss': 0.517046613469176, 'Total loss': 0.517046613469176}
2022-12-31 07:09:22,486 INFO:     Found new best model at epoch 1
2022-12-31 07:09:22,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:22,487 INFO:     Epoch: 2
2022-12-31 07:09:24,087 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4508116066455841, 'Total loss': 0.4508116066455841} | train loss {'Reaction outcome loss': 0.4456675116271868, 'Total loss': 0.4456675116271868}
2022-12-31 07:09:24,087 INFO:     Found new best model at epoch 2
2022-12-31 07:09:24,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:24,088 INFO:     Epoch: 3
2022-12-31 07:09:25,674 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4307966560125351, 'Total loss': 0.4307966560125351} | train loss {'Reaction outcome loss': 0.41399941272544166, 'Total loss': 0.41399941272544166}
2022-12-31 07:09:25,674 INFO:     Found new best model at epoch 3
2022-12-31 07:09:25,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:25,675 INFO:     Epoch: 4
2022-12-31 07:09:27,276 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4224250187476476, 'Total loss': 0.4224250187476476} | train loss {'Reaction outcome loss': 0.383121987111377, 'Total loss': 0.383121987111377}
2022-12-31 07:09:27,276 INFO:     Found new best model at epoch 4
2022-12-31 07:09:27,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:27,277 INFO:     Epoch: 5
2022-12-31 07:09:28,883 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4239404926697413, 'Total loss': 0.4239404926697413} | train loss {'Reaction outcome loss': 0.3593764263511139, 'Total loss': 0.3593764263511139}
2022-12-31 07:09:28,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:28,883 INFO:     Epoch: 6
2022-12-31 07:09:30,493 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4330565104881922, 'Total loss': 0.4330565104881922} | train loss {'Reaction outcome loss': 0.34060219664425745, 'Total loss': 0.34060219664425745}
2022-12-31 07:09:30,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:30,494 INFO:     Epoch: 7
2022-12-31 07:09:32,091 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44977778792381284, 'Total loss': 0.44977778792381284} | train loss {'Reaction outcome loss': 0.32331483711889625, 'Total loss': 0.32331483711889625}
2022-12-31 07:09:32,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:32,092 INFO:     Epoch: 8
2022-12-31 07:09:33,739 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4305935551722844, 'Total loss': 0.4305935551722844} | train loss {'Reaction outcome loss': 0.3084483511854697, 'Total loss': 0.3084483511854697}
2022-12-31 07:09:33,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:33,740 INFO:     Epoch: 9
2022-12-31 07:09:35,345 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4408749873439471, 'Total loss': 0.4408749873439471} | train loss {'Reaction outcome loss': 0.29184541941695186, 'Total loss': 0.29184541941695186}
2022-12-31 07:09:35,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:35,345 INFO:     Epoch: 10
2022-12-31 07:09:36,986 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48819277385870613, 'Total loss': 0.48819277385870613} | train loss {'Reaction outcome loss': 0.2818193342400728, 'Total loss': 0.2818193342400728}
2022-12-31 07:09:36,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:36,986 INFO:     Epoch: 11
2022-12-31 07:09:38,630 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4270300398270289, 'Total loss': 0.4270300398270289} | train loss {'Reaction outcome loss': 0.267480447711627, 'Total loss': 0.267480447711627}
2022-12-31 07:09:38,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:38,631 INFO:     Epoch: 12
2022-12-31 07:09:40,238 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3992079069217046, 'Total loss': 0.3992079069217046} | train loss {'Reaction outcome loss': 0.2543012948475615, 'Total loss': 0.2543012948475615}
2022-12-31 07:09:40,239 INFO:     Found new best model at epoch 12
2022-12-31 07:09:40,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:40,240 INFO:     Epoch: 13
2022-12-31 07:09:41,841 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41045728834966816, 'Total loss': 0.41045728834966816} | train loss {'Reaction outcome loss': 0.24560146828447163, 'Total loss': 0.24560146828447163}
2022-12-31 07:09:41,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:41,841 INFO:     Epoch: 14
2022-12-31 07:09:43,444 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4616154114405314, 'Total loss': 0.4616154114405314} | train loss {'Reaction outcome loss': 0.23748095422629675, 'Total loss': 0.23748095422629675}
2022-12-31 07:09:43,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:43,445 INFO:     Epoch: 15
2022-12-31 07:09:45,046 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48075448473294574, 'Total loss': 0.48075448473294574} | train loss {'Reaction outcome loss': 0.23166921764720966, 'Total loss': 0.23166921764720966}
2022-12-31 07:09:45,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:45,047 INFO:     Epoch: 16
2022-12-31 07:09:46,644 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43451729317506155, 'Total loss': 0.43451729317506155} | train loss {'Reaction outcome loss': 0.2213767724125272, 'Total loss': 0.2213767724125272}
2022-12-31 07:09:46,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:46,644 INFO:     Epoch: 17
2022-12-31 07:09:48,292 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42786313518881797, 'Total loss': 0.42786313518881797} | train loss {'Reaction outcome loss': 0.21185456027351593, 'Total loss': 0.21185456027351593}
2022-12-31 07:09:48,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:48,292 INFO:     Epoch: 18
2022-12-31 07:09:49,911 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42745610972245535, 'Total loss': 0.42745610972245535} | train loss {'Reaction outcome loss': 0.20780048009524815, 'Total loss': 0.20780048009524815}
2022-12-31 07:09:49,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:49,912 INFO:     Epoch: 19
2022-12-31 07:09:51,512 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4592900147040685, 'Total loss': 0.4592900147040685} | train loss {'Reaction outcome loss': 0.2049923946224425, 'Total loss': 0.2049923946224425}
2022-12-31 07:09:51,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:51,512 INFO:     Epoch: 20
2022-12-31 07:09:53,133 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4119166299700737, 'Total loss': 0.4119166299700737} | train loss {'Reaction outcome loss': 0.19792239093323694, 'Total loss': 0.19792239093323694}
2022-12-31 07:09:53,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:53,133 INFO:     Epoch: 21
2022-12-31 07:09:54,767 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45024675528208413, 'Total loss': 0.45024675528208413} | train loss {'Reaction outcome loss': 0.19438465155769874, 'Total loss': 0.19438465155769874}
2022-12-31 07:09:54,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:54,767 INFO:     Epoch: 22
2022-12-31 07:09:56,366 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42268378337224327, 'Total loss': 0.42268378337224327} | train loss {'Reaction outcome loss': 0.18641375819302713, 'Total loss': 0.18641375819302713}
2022-12-31 07:09:56,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:56,366 INFO:     Epoch: 23
2022-12-31 07:09:57,968 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45437400341033934, 'Total loss': 0.45437400341033934} | train loss {'Reaction outcome loss': 0.18106100231028385, 'Total loss': 0.18106100231028385}
2022-12-31 07:09:57,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:57,968 INFO:     Epoch: 24
2022-12-31 07:09:59,572 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46260077158610025, 'Total loss': 0.46260077158610025} | train loss {'Reaction outcome loss': 0.18031067685326085, 'Total loss': 0.18031067685326085}
2022-12-31 07:09:59,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:09:59,572 INFO:     Epoch: 25
2022-12-31 07:10:01,220 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4513956308364868, 'Total loss': 0.4513956308364868} | train loss {'Reaction outcome loss': 0.1744066149057535, 'Total loss': 0.1744066149057535}
2022-12-31 07:10:01,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:01,220 INFO:     Epoch: 26
2022-12-31 07:10:02,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4564216713110606, 'Total loss': 0.4564216713110606} | train loss {'Reaction outcome loss': 0.16925890301864077, 'Total loss': 0.16925890301864077}
2022-12-31 07:10:02,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:02,869 INFO:     Epoch: 27
2022-12-31 07:10:04,478 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46530696948369343, 'Total loss': 0.46530696948369343} | train loss {'Reaction outcome loss': 0.16641519596650653, 'Total loss': 0.16641519596650653}
2022-12-31 07:10:04,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:04,478 INFO:     Epoch: 28
2022-12-31 07:10:06,097 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47923762947320936, 'Total loss': 0.47923762947320936} | train loss {'Reaction outcome loss': 0.16583359415173857, 'Total loss': 0.16583359415173857}
2022-12-31 07:10:06,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:06,097 INFO:     Epoch: 29
2022-12-31 07:10:07,702 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47284770806630455, 'Total loss': 0.47284770806630455} | train loss {'Reaction outcome loss': 0.16550236596406376, 'Total loss': 0.16550236596406376}
2022-12-31 07:10:07,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:07,702 INFO:     Epoch: 30
2022-12-31 07:10:09,350 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4500374853610992, 'Total loss': 0.4500374853610992} | train loss {'Reaction outcome loss': 0.15879456502093126, 'Total loss': 0.15879456502093126}
2022-12-31 07:10:09,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:09,350 INFO:     Epoch: 31
2022-12-31 07:10:10,953 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47417688071727754, 'Total loss': 0.47417688071727754} | train loss {'Reaction outcome loss': 0.15925346355015127, 'Total loss': 0.15925346355015127}
2022-12-31 07:10:10,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:10,953 INFO:     Epoch: 32
2022-12-31 07:10:12,601 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48229644596576693, 'Total loss': 0.48229644596576693} | train loss {'Reaction outcome loss': 0.1573424956142685, 'Total loss': 0.1573424956142685}
2022-12-31 07:10:12,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:12,602 INFO:     Epoch: 33
2022-12-31 07:10:14,239 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48619440098603567, 'Total loss': 0.48619440098603567} | train loss {'Reaction outcome loss': 0.15032180758995295, 'Total loss': 0.15032180758995295}
2022-12-31 07:10:14,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:14,239 INFO:     Epoch: 34
2022-12-31 07:10:15,847 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48330947856108347, 'Total loss': 0.48330947856108347} | train loss {'Reaction outcome loss': 0.14939391116074618, 'Total loss': 0.14939391116074618}
2022-12-31 07:10:15,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:15,848 INFO:     Epoch: 35
2022-12-31 07:10:17,460 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.474227648973465, 'Total loss': 0.474227648973465} | train loss {'Reaction outcome loss': 0.14829628621941826, 'Total loss': 0.14829628621941826}
2022-12-31 07:10:17,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:17,460 INFO:     Epoch: 36
2022-12-31 07:10:19,111 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4399122913678487, 'Total loss': 0.4399122913678487} | train loss {'Reaction outcome loss': 0.14890117691591873, 'Total loss': 0.14890117691591873}
2022-12-31 07:10:19,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:19,112 INFO:     Epoch: 37
2022-12-31 07:10:20,721 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4620556195576986, 'Total loss': 0.4620556195576986} | train loss {'Reaction outcome loss': 0.1423472961696395, 'Total loss': 0.1423472961696395}
2022-12-31 07:10:20,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:20,721 INFO:     Epoch: 38
2022-12-31 07:10:22,328 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4801867425441742, 'Total loss': 0.4801867425441742} | train loss {'Reaction outcome loss': 0.14491664469378054, 'Total loss': 0.14491664469378054}
2022-12-31 07:10:22,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:22,329 INFO:     Epoch: 39
2022-12-31 07:10:23,934 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4260587086280187, 'Total loss': 0.4260587086280187} | train loss {'Reaction outcome loss': 0.14646752161674037, 'Total loss': 0.14646752161674037}
2022-12-31 07:10:23,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:23,934 INFO:     Epoch: 40
2022-12-31 07:10:25,568 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44955063859621686, 'Total loss': 0.44955063859621686} | train loss {'Reaction outcome loss': 0.1419765549732277, 'Total loss': 0.1419765549732277}
2022-12-31 07:10:25,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:25,569 INFO:     Epoch: 41
2022-12-31 07:10:27,171 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4729844535390536, 'Total loss': 0.4729844535390536} | train loss {'Reaction outcome loss': 0.1409851658790216, 'Total loss': 0.1409851658790216}
2022-12-31 07:10:27,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:27,172 INFO:     Epoch: 42
2022-12-31 07:10:28,848 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4522187014420827, 'Total loss': 0.4522187014420827} | train loss {'Reaction outcome loss': 0.1396882010786964, 'Total loss': 0.1396882010786964}
2022-12-31 07:10:28,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:28,848 INFO:     Epoch: 43
2022-12-31 07:10:30,496 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4587670306364695, 'Total loss': 0.4587670306364695} | train loss {'Reaction outcome loss': 0.13624962251361486, 'Total loss': 0.13624962251361486}
2022-12-31 07:10:30,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:30,496 INFO:     Epoch: 44
2022-12-31 07:10:32,125 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4714385410149892, 'Total loss': 0.4714385410149892} | train loss {'Reaction outcome loss': 0.13681672376845658, 'Total loss': 0.13681672376845658}
2022-12-31 07:10:32,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:32,126 INFO:     Epoch: 45
2022-12-31 07:10:33,739 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4565622647603353, 'Total loss': 0.4565622647603353} | train loss {'Reaction outcome loss': 0.13295293286320392, 'Total loss': 0.13295293286320392}
2022-12-31 07:10:33,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:33,739 INFO:     Epoch: 46
2022-12-31 07:10:35,342 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4620986541112264, 'Total loss': 0.4620986541112264} | train loss {'Reaction outcome loss': 0.13479438410004616, 'Total loss': 0.13479438410004616}
2022-12-31 07:10:35,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:35,342 INFO:     Epoch: 47
2022-12-31 07:10:36,990 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48128025432427723, 'Total loss': 0.48128025432427723} | train loss {'Reaction outcome loss': 0.13099761011187722, 'Total loss': 0.13099761011187722}
2022-12-31 07:10:36,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:36,990 INFO:     Epoch: 48
2022-12-31 07:10:38,638 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4450589040915171, 'Total loss': 0.4450589040915171} | train loss {'Reaction outcome loss': 0.13512911867472704, 'Total loss': 0.13512911867472704}
2022-12-31 07:10:38,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:38,638 INFO:     Epoch: 49
2022-12-31 07:10:40,241 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44210106631120044, 'Total loss': 0.44210106631120044} | train loss {'Reaction outcome loss': 0.1260993150912606, 'Total loss': 0.1260993150912606}
2022-12-31 07:10:40,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:40,242 INFO:     Epoch: 50
2022-12-31 07:10:41,858 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4743063728014628, 'Total loss': 0.4743063728014628} | train loss {'Reaction outcome loss': 0.1297202579656711, 'Total loss': 0.1297202579656711}
2022-12-31 07:10:41,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:41,858 INFO:     Epoch: 51
2022-12-31 07:10:43,470 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4583817720413208, 'Total loss': 0.4583817720413208} | train loss {'Reaction outcome loss': 0.12459119224587768, 'Total loss': 0.12459119224587768}
2022-12-31 07:10:43,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:43,471 INFO:     Epoch: 52
2022-12-31 07:10:45,076 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44194633861382804, 'Total loss': 0.44194633861382804} | train loss {'Reaction outcome loss': 0.12503570534482625, 'Total loss': 0.12503570534482625}
2022-12-31 07:10:45,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:45,076 INFO:     Epoch: 53
2022-12-31 07:10:46,701 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4426334172487259, 'Total loss': 0.4426334172487259} | train loss {'Reaction outcome loss': 0.12784649814091567, 'Total loss': 0.12784649814091567}
2022-12-31 07:10:46,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:46,701 INFO:     Epoch: 54
2022-12-31 07:10:48,347 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4770133058230082, 'Total loss': 0.4770133058230082} | train loss {'Reaction outcome loss': 0.12580303557686182, 'Total loss': 0.12580303557686182}
2022-12-31 07:10:48,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:48,347 INFO:     Epoch: 55
2022-12-31 07:10:49,989 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4586422284444173, 'Total loss': 0.4586422284444173} | train loss {'Reaction outcome loss': 0.11910334543195845, 'Total loss': 0.11910334543195845}
2022-12-31 07:10:49,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:49,990 INFO:     Epoch: 56
2022-12-31 07:10:51,598 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4735050489505132, 'Total loss': 0.4735050489505132} | train loss {'Reaction outcome loss': 0.11972724593815523, 'Total loss': 0.11972724593815523}
2022-12-31 07:10:51,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:51,599 INFO:     Epoch: 57
2022-12-31 07:10:53,205 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4524850110212962, 'Total loss': 0.4524850110212962} | train loss {'Reaction outcome loss': 0.12267470901770802, 'Total loss': 0.12267470901770802}
2022-12-31 07:10:53,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:53,205 INFO:     Epoch: 58
2022-12-31 07:10:54,819 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4743160347143809, 'Total loss': 0.4743160347143809} | train loss {'Reaction outcome loss': 0.12597550553895098, 'Total loss': 0.12597550553895098}
2022-12-31 07:10:54,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:54,819 INFO:     Epoch: 59
2022-12-31 07:10:56,433 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4569552421569824, 'Total loss': 0.4569552421569824} | train loss {'Reaction outcome loss': 0.12166795777972705, 'Total loss': 0.12166795777972705}
2022-12-31 07:10:56,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:56,434 INFO:     Epoch: 60
2022-12-31 07:10:58,038 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4718335022528966, 'Total loss': 0.4718335022528966} | train loss {'Reaction outcome loss': 0.12182050736376294, 'Total loss': 0.12182050736376294}
2022-12-31 07:10:58,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:58,038 INFO:     Epoch: 61
2022-12-31 07:10:59,663 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4667575443784396, 'Total loss': 0.4667575443784396} | train loss {'Reaction outcome loss': 0.1194132216628233, 'Total loss': 0.1194132216628233}
2022-12-31 07:10:59,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:10:59,663 INFO:     Epoch: 62
2022-12-31 07:11:01,312 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5012288928031922, 'Total loss': 0.5012288928031922} | train loss {'Reaction outcome loss': 0.11700389953415134, 'Total loss': 0.11700389953415134}
2022-12-31 07:11:01,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:01,312 INFO:     Epoch: 63
2022-12-31 07:11:02,917 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4346326380968094, 'Total loss': 0.4346326380968094} | train loss {'Reaction outcome loss': 0.1177678311593749, 'Total loss': 0.1177678311593749}
2022-12-31 07:11:02,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:02,918 INFO:     Epoch: 64
2022-12-31 07:11:04,522 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.468865767121315, 'Total loss': 0.468865767121315} | train loss {'Reaction outcome loss': 0.11641990839347352, 'Total loss': 0.11641990839347352}
2022-12-31 07:11:04,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:04,522 INFO:     Epoch: 65
2022-12-31 07:11:06,171 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4864854524532954, 'Total loss': 0.4864854524532954} | train loss {'Reaction outcome loss': 0.11161406349771431, 'Total loss': 0.11161406349771431}
2022-12-31 07:11:06,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:06,171 INFO:     Epoch: 66
2022-12-31 07:11:07,819 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4329937865336736, 'Total loss': 0.4329937865336736} | train loss {'Reaction outcome loss': 0.11384817517199383, 'Total loss': 0.11384817517199383}
2022-12-31 07:11:07,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:07,820 INFO:     Epoch: 67
2022-12-31 07:11:09,427 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4599677781263987, 'Total loss': 0.4599677781263987} | train loss {'Reaction outcome loss': 0.11748097581877272, 'Total loss': 0.11748097581877272}
2022-12-31 07:11:09,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:09,427 INFO:     Epoch: 68
2022-12-31 07:11:11,075 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4748884747425715, 'Total loss': 0.4748884747425715} | train loss {'Reaction outcome loss': 0.11800095968179568, 'Total loss': 0.11800095968179568}
2022-12-31 07:11:11,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:11,076 INFO:     Epoch: 69
2022-12-31 07:11:12,669 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4497299551963806, 'Total loss': 0.4497299551963806} | train loss {'Reaction outcome loss': 0.11309289050468645, 'Total loss': 0.11309289050468645}
2022-12-31 07:11:12,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:12,669 INFO:     Epoch: 70
2022-12-31 07:11:14,317 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4575458308060964, 'Total loss': 0.4575458308060964} | train loss {'Reaction outcome loss': 0.11244790324682954, 'Total loss': 0.11244790324682954}
2022-12-31 07:11:14,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:14,317 INFO:     Epoch: 71
2022-12-31 07:11:15,920 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4679561267296473, 'Total loss': 0.4679561267296473} | train loss {'Reaction outcome loss': 0.11223507017393454, 'Total loss': 0.11223507017393454}
2022-12-31 07:11:15,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:15,921 INFO:     Epoch: 72
2022-12-31 07:11:17,536 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48392049173514046, 'Total loss': 0.48392049173514046} | train loss {'Reaction outcome loss': 0.11089464396503448, 'Total loss': 0.11089464396503448}
2022-12-31 07:11:17,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:17,537 INFO:     Epoch: 73
2022-12-31 07:11:19,137 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4581604957580566, 'Total loss': 0.4581604957580566} | train loss {'Reaction outcome loss': 0.11737059152610328, 'Total loss': 0.11737059152610328}
2022-12-31 07:11:19,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:19,138 INFO:     Epoch: 74
2022-12-31 07:11:20,767 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45770325859387717, 'Total loss': 0.45770325859387717} | train loss {'Reaction outcome loss': 0.11255285023528076, 'Total loss': 0.11255285023528076}
2022-12-31 07:11:20,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:20,768 INFO:     Epoch: 75
2022-12-31 07:11:22,380 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4698444604873657, 'Total loss': 0.4698444604873657} | train loss {'Reaction outcome loss': 0.1188368020531633, 'Total loss': 0.1188368020531633}
2022-12-31 07:11:22,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:22,380 INFO:     Epoch: 76
2022-12-31 07:11:24,003 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4281133751074473, 'Total loss': 0.4281133751074473} | train loss {'Reaction outcome loss': 0.11222951186576137, 'Total loss': 0.11222951186576137}
2022-12-31 07:11:24,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:24,003 INFO:     Epoch: 77
2022-12-31 07:11:25,650 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4640755434830984, 'Total loss': 0.4640755434830984} | train loss {'Reaction outcome loss': 0.11024911179084902, 'Total loss': 0.11024911179084902}
2022-12-31 07:11:25,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:25,650 INFO:     Epoch: 78
2022-12-31 07:11:27,271 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4319736108183861, 'Total loss': 0.4319736108183861} | train loss {'Reaction outcome loss': 0.10641028475607779, 'Total loss': 0.10641028475607779}
2022-12-31 07:11:27,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:27,271 INFO:     Epoch: 79
2022-12-31 07:11:28,916 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4583228747049967, 'Total loss': 0.4583228747049967} | train loss {'Reaction outcome loss': 0.11272017799834483, 'Total loss': 0.11272017799834483}
2022-12-31 07:11:28,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:28,916 INFO:     Epoch: 80
2022-12-31 07:11:30,545 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4562786897023519, 'Total loss': 0.4562786897023519} | train loss {'Reaction outcome loss': 0.11373225767267392, 'Total loss': 0.11373225767267392}
2022-12-31 07:11:30,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:30,545 INFO:     Epoch: 81
2022-12-31 07:11:32,196 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4468687057495117, 'Total loss': 0.4468687057495117} | train loss {'Reaction outcome loss': 0.10765877823739646, 'Total loss': 0.10765877823739646}
2022-12-31 07:11:32,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:32,197 INFO:     Epoch: 82
2022-12-31 07:11:33,800 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46675753593444824, 'Total loss': 0.46675753593444824} | train loss {'Reaction outcome loss': 0.10753383779436024, 'Total loss': 0.10753383779436024}
2022-12-31 07:11:33,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:33,800 INFO:     Epoch: 83
2022-12-31 07:11:35,448 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45964876711368563, 'Total loss': 0.45964876711368563} | train loss {'Reaction outcome loss': 0.11018615091656314, 'Total loss': 0.11018615091656314}
2022-12-31 07:11:35,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:35,448 INFO:     Epoch: 84
2022-12-31 07:11:37,077 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4628415142496427, 'Total loss': 0.4628415142496427} | train loss {'Reaction outcome loss': 0.10785404151818803, 'Total loss': 0.10785404151818803}
2022-12-31 07:11:37,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:37,077 INFO:     Epoch: 85
2022-12-31 07:11:38,681 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47811379581689833, 'Total loss': 0.47811379581689833} | train loss {'Reaction outcome loss': 0.10654935593900346, 'Total loss': 0.10654935593900346}
2022-12-31 07:11:38,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:38,683 INFO:     Epoch: 86
2022-12-31 07:11:40,281 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45463927487532296, 'Total loss': 0.45463927487532296} | train loss {'Reaction outcome loss': 0.1094150092974509, 'Total loss': 0.1094150092974509}
2022-12-31 07:11:40,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:40,281 INFO:     Epoch: 87
2022-12-31 07:11:41,914 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4765201230843862, 'Total loss': 0.4765201230843862} | train loss {'Reaction outcome loss': 0.10814624956900756, 'Total loss': 0.10814624956900756}
2022-12-31 07:11:41,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:41,914 INFO:     Epoch: 88
2022-12-31 07:11:43,561 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4740093211332957, 'Total loss': 0.4740093211332957} | train loss {'Reaction outcome loss': 0.11167820956367645, 'Total loss': 0.11167820956367645}
2022-12-31 07:11:43,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:43,561 INFO:     Epoch: 89
2022-12-31 07:11:45,171 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4682776724298795, 'Total loss': 0.4682776724298795} | train loss {'Reaction outcome loss': 0.11236889177702204, 'Total loss': 0.11236889177702204}
2022-12-31 07:11:45,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:45,172 INFO:     Epoch: 90
2022-12-31 07:11:46,818 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4952467481295268, 'Total loss': 0.4952467481295268} | train loss {'Reaction outcome loss': 0.11200141138907005, 'Total loss': 0.11200141138907005}
2022-12-31 07:11:46,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:46,818 INFO:     Epoch: 91
2022-12-31 07:11:48,423 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4816037893295288, 'Total loss': 0.4816037893295288} | train loss {'Reaction outcome loss': 0.10751480015885276, 'Total loss': 0.10751480015885276}
2022-12-31 07:11:48,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:48,423 INFO:     Epoch: 92
2022-12-31 07:11:50,036 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4832257529099782, 'Total loss': 0.4832257529099782} | train loss {'Reaction outcome loss': 0.10323594668608187, 'Total loss': 0.10323594668608187}
2022-12-31 07:11:50,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:50,036 INFO:     Epoch: 93
2022-12-31 07:11:51,648 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4994345118602117, 'Total loss': 0.4994345118602117} | train loss {'Reaction outcome loss': 0.10844737889048012, 'Total loss': 0.10844737889048012}
2022-12-31 07:11:51,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:51,648 INFO:     Epoch: 94
2022-12-31 07:11:53,259 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47873150010903676, 'Total loss': 0.47873150010903676} | train loss {'Reaction outcome loss': 0.10461010184839205, 'Total loss': 0.10461010184839205}
2022-12-31 07:11:53,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:53,260 INFO:     Epoch: 95
2022-12-31 07:11:54,905 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47148903807004294, 'Total loss': 0.47148903807004294} | train loss {'Reaction outcome loss': 0.1076065213835873, 'Total loss': 0.1076065213835873}
2022-12-31 07:11:54,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:54,906 INFO:     Epoch: 96
2022-12-31 07:11:56,515 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4492763896783193, 'Total loss': 0.4492763896783193} | train loss {'Reaction outcome loss': 0.10080475487277238, 'Total loss': 0.10080475487277238}
2022-12-31 07:11:56,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:56,515 INFO:     Epoch: 97
2022-12-31 07:11:58,113 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4509303947289785, 'Total loss': 0.4509303947289785} | train loss {'Reaction outcome loss': 0.1021179386123974, 'Total loss': 0.1021179386123974}
2022-12-31 07:11:58,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:58,113 INFO:     Epoch: 98
2022-12-31 07:11:59,761 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4417015895247459, 'Total loss': 0.4417015895247459} | train loss {'Reaction outcome loss': 0.10424821006761266, 'Total loss': 0.10424821006761266}
2022-12-31 07:11:59,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:11:59,761 INFO:     Epoch: 99
2022-12-31 07:12:01,364 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5009612053632736, 'Total loss': 0.5009612053632736} | train loss {'Reaction outcome loss': 0.11036335683281595, 'Total loss': 0.11036335683281595}
2022-12-31 07:12:01,364 INFO:     Best model found after epoch 13 of 100.
2022-12-31 07:12:01,364 INFO:   Done with stage: TRAINING
2022-12-31 07:12:01,365 INFO:   Starting stage: EVALUATION
2022-12-31 07:12:01,500 INFO:   Done with stage: EVALUATION
2022-12-31 07:12:01,500 INFO:   Leaving out SEQ value Fold_9
2022-12-31 07:12:01,512 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:12:01,512 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:12:02,165 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:12:02,165 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:12:02,235 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:12:02,235 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:12:02,235 INFO:     No hyperparam tuning for this model
2022-12-31 07:12:02,235 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:12:02,235 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:12:02,236 INFO:     None feature selector for col prot
2022-12-31 07:12:02,236 INFO:     None feature selector for col prot
2022-12-31 07:12:02,236 INFO:     None feature selector for col prot
2022-12-31 07:12:02,237 INFO:     None feature selector for col chem
2022-12-31 07:12:02,237 INFO:     None feature selector for col chem
2022-12-31 07:12:02,237 INFO:     None feature selector for col chem
2022-12-31 07:12:02,237 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:12:02,237 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:12:02,239 INFO:     Number of params in model 224011
2022-12-31 07:12:02,242 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:12:02,242 INFO:   Starting stage: TRAINING
2022-12-31 07:12:02,286 INFO:     Val loss before train {'Reaction outcome loss': 1.0734080036481222, 'Total loss': 1.0734080036481222}
2022-12-31 07:12:02,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:02,286 INFO:     Epoch: 0
2022-12-31 07:12:03,908 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.619326631228129, 'Total loss': 0.619326631228129} | train loss {'Reaction outcome loss': 0.7779846899967078, 'Total loss': 0.7779846899967078}
2022-12-31 07:12:03,908 INFO:     Found new best model at epoch 0
2022-12-31 07:12:03,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:03,909 INFO:     Epoch: 1
2022-12-31 07:12:05,528 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5159528970718383, 'Total loss': 0.5159528970718383} | train loss {'Reaction outcome loss': 0.5048144736096931, 'Total loss': 0.5048144736096931}
2022-12-31 07:12:05,528 INFO:     Found new best model at epoch 1
2022-12-31 07:12:05,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:05,529 INFO:     Epoch: 2
2022-12-31 07:12:07,177 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49328814844290414, 'Total loss': 0.49328814844290414} | train loss {'Reaction outcome loss': 0.4449361062750382, 'Total loss': 0.4449361062750382}
2022-12-31 07:12:07,178 INFO:     Found new best model at epoch 2
2022-12-31 07:12:07,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:07,179 INFO:     Epoch: 3
2022-12-31 07:12:08,823 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47290974458058677, 'Total loss': 0.47290974458058677} | train loss {'Reaction outcome loss': 0.4008094156998213, 'Total loss': 0.4008094156998213}
2022-12-31 07:12:08,823 INFO:     Found new best model at epoch 3
2022-12-31 07:12:08,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:08,824 INFO:     Epoch: 4
2022-12-31 07:12:10,443 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42749882241090137, 'Total loss': 0.42749882241090137} | train loss {'Reaction outcome loss': 0.37499626353383064, 'Total loss': 0.37499626353383064}
2022-12-31 07:12:10,443 INFO:     Found new best model at epoch 4
2022-12-31 07:12:10,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:10,444 INFO:     Epoch: 5
2022-12-31 07:12:12,055 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45281056066354114, 'Total loss': 0.45281056066354114} | train loss {'Reaction outcome loss': 0.3524884643715716, 'Total loss': 0.3524884643715716}
2022-12-31 07:12:12,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:12,055 INFO:     Epoch: 6
2022-12-31 07:12:13,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4636482278505961, 'Total loss': 0.4636482278505961} | train loss {'Reaction outcome loss': 0.33054890695980843, 'Total loss': 0.33054890695980843}
2022-12-31 07:12:13,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:13,676 INFO:     Epoch: 7
2022-12-31 07:12:15,294 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4395192916194598, 'Total loss': 0.4395192916194598} | train loss {'Reaction outcome loss': 0.3136834150186126, 'Total loss': 0.3136834150186126}
2022-12-31 07:12:15,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:15,294 INFO:     Epoch: 8
2022-12-31 07:12:16,930 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43805499573548634, 'Total loss': 0.43805499573548634} | train loss {'Reaction outcome loss': 0.2959895064177808, 'Total loss': 0.2959895064177808}
2022-12-31 07:12:16,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:16,931 INFO:     Epoch: 9
2022-12-31 07:12:18,547 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46545660694440205, 'Total loss': 0.46545660694440205} | train loss {'Reaction outcome loss': 0.2808099191001468, 'Total loss': 0.2808099191001468}
2022-12-31 07:12:18,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:18,547 INFO:     Epoch: 10
2022-12-31 07:12:20,165 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43613080978393554, 'Total loss': 0.43613080978393554} | train loss {'Reaction outcome loss': 0.2724575110427711, 'Total loss': 0.2724575110427711}
2022-12-31 07:12:20,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:20,165 INFO:     Epoch: 11
2022-12-31 07:12:21,777 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.434122504790624, 'Total loss': 0.434122504790624} | train loss {'Reaction outcome loss': 0.2597621033454071, 'Total loss': 0.2597621033454071}
2022-12-31 07:12:21,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:21,778 INFO:     Epoch: 12
2022-12-31 07:12:23,396 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45349751114845277, 'Total loss': 0.45349751114845277} | train loss {'Reaction outcome loss': 0.25006838914587337, 'Total loss': 0.25006838914587337}
2022-12-31 07:12:23,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:23,396 INFO:     Epoch: 13
2022-12-31 07:12:25,015 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43489573846260704, 'Total loss': 0.43489573846260704} | train loss {'Reaction outcome loss': 0.2413359442050906, 'Total loss': 0.2413359442050906}
2022-12-31 07:12:25,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:25,015 INFO:     Epoch: 14
2022-12-31 07:12:26,674 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4355727434158325, 'Total loss': 0.4355727434158325} | train loss {'Reaction outcome loss': 0.24302771933582626, 'Total loss': 0.24302771933582626}
2022-12-31 07:12:26,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:26,675 INFO:     Epoch: 15
2022-12-31 07:12:28,300 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46193113923072815, 'Total loss': 0.46193113923072815} | train loss {'Reaction outcome loss': 0.2280067451622175, 'Total loss': 0.2280067451622175}
2022-12-31 07:12:28,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:28,301 INFO:     Epoch: 16
2022-12-31 07:12:29,950 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41243759791056317, 'Total loss': 0.41243759791056317} | train loss {'Reaction outcome loss': 0.22811551647685954, 'Total loss': 0.22811551647685954}
2022-12-31 07:12:29,950 INFO:     Found new best model at epoch 16
2022-12-31 07:12:29,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:29,951 INFO:     Epoch: 17
2022-12-31 07:12:31,612 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42806073228518166, 'Total loss': 0.42806073228518166} | train loss {'Reaction outcome loss': 0.21362355989876433, 'Total loss': 0.21362355989876433}
2022-12-31 07:12:31,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:31,612 INFO:     Epoch: 18
2022-12-31 07:12:33,233 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4577082763115565, 'Total loss': 0.4577082763115565} | train loss {'Reaction outcome loss': 0.20825904659653569, 'Total loss': 0.20825904659653569}
2022-12-31 07:12:33,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:33,233 INFO:     Epoch: 19
2022-12-31 07:12:34,852 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4322516143321991, 'Total loss': 0.4322516143321991} | train loss {'Reaction outcome loss': 0.2002952619239796, 'Total loss': 0.2002952619239796}
2022-12-31 07:12:34,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:34,853 INFO:     Epoch: 20
2022-12-31 07:12:36,471 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44920386870702106, 'Total loss': 0.44920386870702106} | train loss {'Reaction outcome loss': 0.19290816773781957, 'Total loss': 0.19290816773781957}
2022-12-31 07:12:36,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:36,471 INFO:     Epoch: 21
2022-12-31 07:12:38,133 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4592854082584381, 'Total loss': 0.4592854082584381} | train loss {'Reaction outcome loss': 0.19211817513206514, 'Total loss': 0.19211817513206514}
2022-12-31 07:12:38,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:38,134 INFO:     Epoch: 22
2022-12-31 07:12:39,760 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4525244027376175, 'Total loss': 0.4525244027376175} | train loss {'Reaction outcome loss': 0.1958069872968169, 'Total loss': 0.1958069872968169}
2022-12-31 07:12:39,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:39,761 INFO:     Epoch: 23
2022-12-31 07:12:41,413 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44781882961591085, 'Total loss': 0.44781882961591085} | train loss {'Reaction outcome loss': 0.19916153199079892, 'Total loss': 0.19916153199079892}
2022-12-31 07:12:41,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:41,414 INFO:     Epoch: 24
2022-12-31 07:12:43,032 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43217078745365145, 'Total loss': 0.43217078745365145} | train loss {'Reaction outcome loss': 0.17802801231543222, 'Total loss': 0.17802801231543222}
2022-12-31 07:12:43,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:43,032 INFO:     Epoch: 25
2022-12-31 07:12:44,660 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46751798391342164, 'Total loss': 0.46751798391342164} | train loss {'Reaction outcome loss': 0.17610134815365291, 'Total loss': 0.17610134815365291}
2022-12-31 07:12:44,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:44,661 INFO:     Epoch: 26
2022-12-31 07:12:46,286 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48786487330993017, 'Total loss': 0.48786487330993017} | train loss {'Reaction outcome loss': 0.18738675571006277, 'Total loss': 0.18738675571006277}
2022-12-31 07:12:46,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:46,286 INFO:     Epoch: 27
2022-12-31 07:12:47,909 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46498842239379884, 'Total loss': 0.46498842239379884} | train loss {'Reaction outcome loss': 0.16642562571602562, 'Total loss': 0.16642562571602562}
2022-12-31 07:12:47,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:47,909 INFO:     Epoch: 28
2022-12-31 07:12:49,521 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45889940559864045, 'Total loss': 0.45889940559864045} | train loss {'Reaction outcome loss': 0.1659912266228618, 'Total loss': 0.1659912266228618}
2022-12-31 07:12:49,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:49,521 INFO:     Epoch: 29
2022-12-31 07:12:51,139 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48356133202711743, 'Total loss': 0.48356133202711743} | train loss {'Reaction outcome loss': 0.1733062955365094, 'Total loss': 0.1733062955365094}
2022-12-31 07:12:51,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:51,140 INFO:     Epoch: 30
2022-12-31 07:12:52,747 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4570397609456753, 'Total loss': 0.4570397609456753} | train loss {'Reaction outcome loss': 0.1576857973978685, 'Total loss': 0.1576857973978685}
2022-12-31 07:12:52,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:52,747 INFO:     Epoch: 31
2022-12-31 07:12:54,407 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4740641762812932, 'Total loss': 0.4740641762812932} | train loss {'Reaction outcome loss': 0.15451646475560046, 'Total loss': 0.15451646475560046}
2022-12-31 07:12:54,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:54,407 INFO:     Epoch: 32
2022-12-31 07:12:56,066 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4554085592428843, 'Total loss': 0.4554085592428843} | train loss {'Reaction outcome loss': 0.1531094310601053, 'Total loss': 0.1531094310601053}
2022-12-31 07:12:56,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:56,066 INFO:     Epoch: 33
2022-12-31 07:12:57,706 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4939897785584132, 'Total loss': 0.4939897785584132} | train loss {'Reaction outcome loss': 0.15087821171112845, 'Total loss': 0.15087821171112845}
2022-12-31 07:12:57,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:57,707 INFO:     Epoch: 34
2022-12-31 07:12:59,320 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47845858335494995, 'Total loss': 0.47845858335494995} | train loss {'Reaction outcome loss': 0.14939583887759572, 'Total loss': 0.14939583887759572}
2022-12-31 07:12:59,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:12:59,320 INFO:     Epoch: 35
2022-12-31 07:13:00,957 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48168658713499707, 'Total loss': 0.48168658713499707} | train loss {'Reaction outcome loss': 0.14709709176700478, 'Total loss': 0.14709709176700478}
2022-12-31 07:13:00,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:00,957 INFO:     Epoch: 36
2022-12-31 07:13:02,616 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.450844869017601, 'Total loss': 0.450844869017601} | train loss {'Reaction outcome loss': 0.14532250038810426, 'Total loss': 0.14532250038810426}
2022-12-31 07:13:02,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:02,616 INFO:     Epoch: 37
2022-12-31 07:13:04,231 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4717467904090881, 'Total loss': 0.4717467904090881} | train loss {'Reaction outcome loss': 0.1470273754494501, 'Total loss': 0.1470273754494501}
2022-12-31 07:13:04,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:04,231 INFO:     Epoch: 38
2022-12-31 07:13:05,890 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.496754023929437, 'Total loss': 0.496754023929437} | train loss {'Reaction outcome loss': 0.14302763815931688, 'Total loss': 0.14302763815931688}
2022-12-31 07:13:05,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:05,890 INFO:     Epoch: 39
2022-12-31 07:13:07,530 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4880080719788869, 'Total loss': 0.4880080719788869} | train loss {'Reaction outcome loss': 0.14049751176903752, 'Total loss': 0.14049751176903752}
2022-12-31 07:13:07,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:07,531 INFO:     Epoch: 40
2022-12-31 07:13:09,137 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4885083774725596, 'Total loss': 0.4885083774725596} | train loss {'Reaction outcome loss': 0.1365113688238046, 'Total loss': 0.1365113688238046}
2022-12-31 07:13:09,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:09,138 INFO:     Epoch: 41
2022-12-31 07:13:10,749 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45525330901145933, 'Total loss': 0.45525330901145933} | train loss {'Reaction outcome loss': 0.13680896945099474, 'Total loss': 0.13680896945099474}
2022-12-31 07:13:10,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:10,749 INFO:     Epoch: 42
2022-12-31 07:13:12,409 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47739580969015755, 'Total loss': 0.47739580969015755} | train loss {'Reaction outcome loss': 0.13889654485641242, 'Total loss': 0.13889654485641242}
2022-12-31 07:13:12,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:12,409 INFO:     Epoch: 43
2022-12-31 07:13:14,068 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5171128471692403, 'Total loss': 0.5171128471692403} | train loss {'Reaction outcome loss': 0.14020569219618387, 'Total loss': 0.14020569219618387}
2022-12-31 07:13:14,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:14,069 INFO:     Epoch: 44
2022-12-31 07:13:15,717 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48468474050362903, 'Total loss': 0.48468474050362903} | train loss {'Reaction outcome loss': 0.17091038374844397, 'Total loss': 0.17091038374844397}
2022-12-31 07:13:15,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:15,717 INFO:     Epoch: 45
2022-12-31 07:13:17,343 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4613504946231842, 'Total loss': 0.4613504946231842} | train loss {'Reaction outcome loss': 0.137709743932119, 'Total loss': 0.137709743932119}
2022-12-31 07:13:17,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:17,343 INFO:     Epoch: 46
2022-12-31 07:13:18,955 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44197845285137494, 'Total loss': 0.44197845285137494} | train loss {'Reaction outcome loss': 0.13178356360995036, 'Total loss': 0.13178356360995036}
2022-12-31 07:13:18,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:18,956 INFO:     Epoch: 47
2022-12-31 07:13:20,584 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4839712083339691, 'Total loss': 0.4839712083339691} | train loss {'Reaction outcome loss': 0.13263521085257485, 'Total loss': 0.13263521085257485}
2022-12-31 07:13:20,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:20,584 INFO:     Epoch: 48
2022-12-31 07:13:22,213 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49939130047957103, 'Total loss': 0.49939130047957103} | train loss {'Reaction outcome loss': 0.1254285453652895, 'Total loss': 0.1254285453652895}
2022-12-31 07:13:22,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:22,214 INFO:     Epoch: 49
2022-12-31 07:13:23,835 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47211384574572246, 'Total loss': 0.47211384574572246} | train loss {'Reaction outcome loss': 0.12464152974902443, 'Total loss': 0.12464152974902443}
2022-12-31 07:13:23,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:23,836 INFO:     Epoch: 50
2022-12-31 07:13:25,454 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44483425418535866, 'Total loss': 0.44483425418535866} | train loss {'Reaction outcome loss': 0.12971661303469073, 'Total loss': 0.12971661303469073}
2022-12-31 07:13:25,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:25,454 INFO:     Epoch: 51
2022-12-31 07:13:27,084 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4872798681259155, 'Total loss': 0.4872798681259155} | train loss {'Reaction outcome loss': 0.1261052495953492, 'Total loss': 0.1261052495953492}
2022-12-31 07:13:27,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:27,084 INFO:     Epoch: 52
2022-12-31 07:13:28,707 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49227243264516196, 'Total loss': 0.49227243264516196} | train loss {'Reaction outcome loss': 0.1289213091722163, 'Total loss': 0.1289213091722163}
2022-12-31 07:13:28,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:28,708 INFO:     Epoch: 53
2022-12-31 07:13:30,337 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4518517086903254, 'Total loss': 0.4518517086903254} | train loss {'Reaction outcome loss': 0.12807892585208167, 'Total loss': 0.12807892585208167}
2022-12-31 07:13:30,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:30,337 INFO:     Epoch: 54
2022-12-31 07:13:31,963 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5138776938120524, 'Total loss': 0.5138776938120524} | train loss {'Reaction outcome loss': 0.1257166561671234, 'Total loss': 0.1257166561671234}
2022-12-31 07:13:31,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:31,964 INFO:     Epoch: 55
2022-12-31 07:13:33,589 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44892771144708, 'Total loss': 0.44892771144708} | train loss {'Reaction outcome loss': 0.12350514175826295, 'Total loss': 0.12350514175826295}
2022-12-31 07:13:33,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:33,589 INFO:     Epoch: 56
2022-12-31 07:13:35,210 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4547875165939331, 'Total loss': 0.4547875165939331} | train loss {'Reaction outcome loss': 0.12185470059773872, 'Total loss': 0.12185470059773872}
2022-12-31 07:13:35,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:35,210 INFO:     Epoch: 57
2022-12-31 07:13:36,829 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42776470482349394, 'Total loss': 0.42776470482349394} | train loss {'Reaction outcome loss': 0.12519395432942818, 'Total loss': 0.12519395432942818}
2022-12-31 07:13:36,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:36,829 INFO:     Epoch: 58
2022-12-31 07:13:38,487 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45995598832766216, 'Total loss': 0.45995598832766216} | train loss {'Reaction outcome loss': 0.12483590826778326, 'Total loss': 0.12483590826778326}
2022-12-31 07:13:38,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:38,487 INFO:     Epoch: 59
2022-12-31 07:13:40,104 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4742125660181046, 'Total loss': 0.4742125660181046} | train loss {'Reaction outcome loss': 0.1190341373532673, 'Total loss': 0.1190341373532673}
2022-12-31 07:13:40,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:40,105 INFO:     Epoch: 60
2022-12-31 07:13:41,725 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4573772966861725, 'Total loss': 0.4573772966861725} | train loss {'Reaction outcome loss': 0.12165365421825576, 'Total loss': 0.12165365421825576}
2022-12-31 07:13:41,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:41,725 INFO:     Epoch: 61
2022-12-31 07:13:43,364 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48732014546791713, 'Total loss': 0.48732014546791713} | train loss {'Reaction outcome loss': 0.12098788397017178, 'Total loss': 0.12098788397017178}
2022-12-31 07:13:43,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:43,365 INFO:     Epoch: 62
2022-12-31 07:13:44,992 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4727710584799449, 'Total loss': 0.4727710584799449} | train loss {'Reaction outcome loss': 0.12238059173663371, 'Total loss': 0.12238059173663371}
2022-12-31 07:13:44,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:44,994 INFO:     Epoch: 63
2022-12-31 07:13:46,610 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47664339443047843, 'Total loss': 0.47664339443047843} | train loss {'Reaction outcome loss': 0.11787583205554308, 'Total loss': 0.11787583205554308}
2022-12-31 07:13:46,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:46,610 INFO:     Epoch: 64
2022-12-31 07:13:48,234 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44734950611988705, 'Total loss': 0.44734950611988705} | train loss {'Reaction outcome loss': 0.11582838915047182, 'Total loss': 0.11582838915047182}
2022-12-31 07:13:48,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:48,235 INFO:     Epoch: 65
2022-12-31 07:13:49,861 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46596975326538087, 'Total loss': 0.46596975326538087} | train loss {'Reaction outcome loss': 0.11847000066663368, 'Total loss': 0.11847000066663368}
2022-12-31 07:13:49,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:49,861 INFO:     Epoch: 66
2022-12-31 07:13:51,488 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4447283099095027, 'Total loss': 0.4447283099095027} | train loss {'Reaction outcome loss': 0.11642797090757666, 'Total loss': 0.11642797090757666}
2022-12-31 07:13:51,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:51,489 INFO:     Epoch: 67
2022-12-31 07:13:53,130 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44507037897904717, 'Total loss': 0.44507037897904717} | train loss {'Reaction outcome loss': 0.1157244462764525, 'Total loss': 0.1157244462764525}
2022-12-31 07:13:53,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:53,130 INFO:     Epoch: 68
2022-12-31 07:13:54,789 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49423972169558206, 'Total loss': 0.49423972169558206} | train loss {'Reaction outcome loss': 0.1141418084321692, 'Total loss': 0.1141418084321692}
2022-12-31 07:13:54,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:54,790 INFO:     Epoch: 69
2022-12-31 07:13:56,405 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4632677336533864, 'Total loss': 0.4632677336533864} | train loss {'Reaction outcome loss': 0.11947277123149631, 'Total loss': 0.11947277123149631}
2022-12-31 07:13:56,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:56,406 INFO:     Epoch: 70
2022-12-31 07:13:58,065 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47437869707743324, 'Total loss': 0.47437869707743324} | train loss {'Reaction outcome loss': 0.11531754634981316, 'Total loss': 0.11531754634981316}
2022-12-31 07:13:58,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:58,066 INFO:     Epoch: 71
2022-12-31 07:13:59,725 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4515371839205424, 'Total loss': 0.4515371839205424} | train loss {'Reaction outcome loss': 0.1170959254107573, 'Total loss': 0.1170959254107573}
2022-12-31 07:13:59,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:13:59,726 INFO:     Epoch: 72
2022-12-31 07:14:01,340 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47208619862794876, 'Total loss': 0.47208619862794876} | train loss {'Reaction outcome loss': 0.1161560946139102, 'Total loss': 0.1161560946139102}
2022-12-31 07:14:01,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:01,340 INFO:     Epoch: 73
2022-12-31 07:14:03,000 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4635017623504003, 'Total loss': 0.4635017623504003} | train loss {'Reaction outcome loss': 0.11122119680879658, 'Total loss': 0.11122119680879658}
2022-12-31 07:14:03,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:03,001 INFO:     Epoch: 74
2022-12-31 07:14:04,607 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4746018201112747, 'Total loss': 0.4746018201112747} | train loss {'Reaction outcome loss': 0.11073245992746956, 'Total loss': 0.11073245992746956}
2022-12-31 07:14:04,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:04,608 INFO:     Epoch: 75
2022-12-31 07:14:06,235 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4536096781492233, 'Total loss': 0.4536096781492233} | train loss {'Reaction outcome loss': 0.11713711186240434, 'Total loss': 0.11713711186240434}
2022-12-31 07:14:06,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:06,235 INFO:     Epoch: 76
2022-12-31 07:14:07,863 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.439888999486963, 'Total loss': 0.439888999486963} | train loss {'Reaction outcome loss': 0.11124707769133, 'Total loss': 0.11124707769133}
2022-12-31 07:14:07,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:07,863 INFO:     Epoch: 77
2022-12-31 07:14:09,501 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4499498764673869, 'Total loss': 0.4499498764673869} | train loss {'Reaction outcome loss': 0.11168623805744995, 'Total loss': 0.11168623805744995}
2022-12-31 07:14:09,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:09,501 INFO:     Epoch: 78
2022-12-31 07:14:11,159 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48879818320274354, 'Total loss': 0.48879818320274354} | train loss {'Reaction outcome loss': 0.11332590765316812, 'Total loss': 0.11332590765316812}
2022-12-31 07:14:11,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:11,159 INFO:     Epoch: 79
2022-12-31 07:14:12,871 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4778673619031906, 'Total loss': 0.4778673619031906} | train loss {'Reaction outcome loss': 0.11124118124016737, 'Total loss': 0.11124118124016737}
2022-12-31 07:14:12,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:12,872 INFO:     Epoch: 80
2022-12-31 07:14:14,493 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4385263085365295, 'Total loss': 0.4385263085365295} | train loss {'Reaction outcome loss': 0.11017643461738287, 'Total loss': 0.11017643461738287}
2022-12-31 07:14:14,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:14,493 INFO:     Epoch: 81
2022-12-31 07:14:16,114 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47858150204022726, 'Total loss': 0.47858150204022726} | train loss {'Reaction outcome loss': 0.11625114963008078, 'Total loss': 0.11625114963008078}
2022-12-31 07:14:16,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:16,115 INFO:     Epoch: 82
2022-12-31 07:14:17,827 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43615317543347676, 'Total loss': 0.43615317543347676} | train loss {'Reaction outcome loss': 0.10812044736171694, 'Total loss': 0.10812044736171694}
2022-12-31 07:14:17,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:17,827 INFO:     Epoch: 83
2022-12-31 07:14:19,448 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4669306755065918, 'Total loss': 0.4669306755065918} | train loss {'Reaction outcome loss': 0.10812071183328584, 'Total loss': 0.10812071183328584}
2022-12-31 07:14:19,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:19,448 INFO:     Epoch: 84
2022-12-31 07:14:21,074 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49658241073290504, 'Total loss': 0.49658241073290504} | train loss {'Reaction outcome loss': 0.10862279393233251, 'Total loss': 0.10862279393233251}
2022-12-31 07:14:21,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:21,076 INFO:     Epoch: 85
2022-12-31 07:14:22,696 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4727145075798035, 'Total loss': 0.4727145075798035} | train loss {'Reaction outcome loss': 0.1078808848717439, 'Total loss': 0.1078808848717439}
2022-12-31 07:14:22,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:22,696 INFO:     Epoch: 86
2022-12-31 07:14:24,321 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47367992202440895, 'Total loss': 0.47367992202440895} | train loss {'Reaction outcome loss': 0.10642976552059037, 'Total loss': 0.10642976552059037}
2022-12-31 07:14:24,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:24,321 INFO:     Epoch: 87
2022-12-31 07:14:26,009 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5010242362817129, 'Total loss': 0.5010242362817129} | train loss {'Reaction outcome loss': 0.11034424239244674, 'Total loss': 0.11034424239244674}
2022-12-31 07:14:26,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:26,009 INFO:     Epoch: 88
2022-12-31 07:14:27,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5064230938752492, 'Total loss': 0.5064230938752492} | train loss {'Reaction outcome loss': 0.1123288607927532, 'Total loss': 0.1123288607927532}
2022-12-31 07:14:27,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:27,671 INFO:     Epoch: 89
2022-12-31 07:14:29,295 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.515672683219115, 'Total loss': 0.515672683219115} | train loss {'Reaction outcome loss': 0.11312454799749042, 'Total loss': 0.11312454799749042}
2022-12-31 07:14:29,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:29,295 INFO:     Epoch: 90
2022-12-31 07:14:30,912 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49204646746317543, 'Total loss': 0.49204646746317543} | train loss {'Reaction outcome loss': 0.11196059474562955, 'Total loss': 0.11196059474562955}
2022-12-31 07:14:30,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:30,912 INFO:     Epoch: 91
2022-12-31 07:14:32,531 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4564108004172643, 'Total loss': 0.4564108004172643} | train loss {'Reaction outcome loss': 0.10742056021294759, 'Total loss': 0.10742056021294759}
2022-12-31 07:14:32,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:32,531 INFO:     Epoch: 92
2022-12-31 07:14:34,147 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47397280037403106, 'Total loss': 0.47397280037403106} | train loss {'Reaction outcome loss': 0.10563086416222954, 'Total loss': 0.10563086416222954}
2022-12-31 07:14:34,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:34,148 INFO:     Epoch: 93
2022-12-31 07:14:35,764 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4765089293320974, 'Total loss': 0.4765089293320974} | train loss {'Reaction outcome loss': 0.10862655964455621, 'Total loss': 0.10862655964455621}
2022-12-31 07:14:35,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:35,765 INFO:     Epoch: 94
2022-12-31 07:14:37,425 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45470837155977883, 'Total loss': 0.45470837155977883} | train loss {'Reaction outcome loss': 0.10882243019709001, 'Total loss': 0.10882243019709001}
2022-12-31 07:14:37,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:37,426 INFO:     Epoch: 95
2022-12-31 07:14:39,086 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5073413491249085, 'Total loss': 0.5073413491249085} | train loss {'Reaction outcome loss': 0.10853664787356283, 'Total loss': 0.10853664787356283}
2022-12-31 07:14:39,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:39,086 INFO:     Epoch: 96
2022-12-31 07:14:40,773 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4922397752602895, 'Total loss': 0.4922397752602895} | train loss {'Reaction outcome loss': 0.11229029068762549, 'Total loss': 0.11229029068762549}
2022-12-31 07:14:40,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:40,774 INFO:     Epoch: 97
2022-12-31 07:14:42,438 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4368962953488032, 'Total loss': 0.4368962953488032} | train loss {'Reaction outcome loss': 0.1091198089715613, 'Total loss': 0.1091198089715613}
2022-12-31 07:14:42,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:42,439 INFO:     Epoch: 98
2022-12-31 07:14:44,119 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45849951207637785, 'Total loss': 0.45849951207637785} | train loss {'Reaction outcome loss': 0.10334798683028686, 'Total loss': 0.10334798683028686}
2022-12-31 07:14:44,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:44,120 INFO:     Epoch: 99
2022-12-31 07:14:45,800 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4524609496196111, 'Total loss': 0.4524609496196111} | train loss {'Reaction outcome loss': 0.10594615821458359, 'Total loss': 0.10594615821458359}
2022-12-31 07:14:45,800 INFO:     Best model found after epoch 17 of 100.
2022-12-31 07:14:45,800 INFO:   Done with stage: TRAINING
2022-12-31 07:14:45,800 INFO:   Starting stage: EVALUATION
2022-12-31 07:14:45,929 INFO:   Done with stage: EVALUATION
2022-12-31 07:14:45,930 INFO: Done with stage: RUNNING SPLITS
2022-12-31 07:14:45,930 INFO: Starting stage: COMPUTE METRICS
2022-12-31 07:14:47,095 INFO: Done with stage: COMPUTE METRICS
2022-12-31 07:14:47,095 INFO: Starting stage: EXPORT RESULTS
2022-12-31 07:14:47,113 INFO:   Final results averaged over 50 folds: 
2022-12-31 07:14:47,116 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.163245           NaN  0.312095       NaN
2022-12-31 07:14:48,803 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 07:14:48,809 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 07:14:48,810 DEBUG:   interactive is False
2022-12-31 07:14:48,810 DEBUG:   platform is linux
2022-12-31 07:14:48,810 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 07:14:48,983 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 07:14:48,985 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 07:14:49,420 DEBUG:   Loaded backend agg version unknown.
2022-12-31 07:14:49,422 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,423 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,424 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,425 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,426 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,426 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,426 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,426 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,426 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 07:14:49,462 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 07:14:49,462 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,462 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,462 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,462 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,462 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,463 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 07:14:49,464 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,465 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,465 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 07:14:49,474 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,474 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 07:14:49,476 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 07:14:49,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 07:14:49,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 07:14:49,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 07:14:49,477 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 07:14:49,834 INFO: Done with stage: EXPORT RESULTS
2022-12-31 07:14:49,834 INFO: Starting stage: SAVE MODEL
2022-12-31 07:14:49,901 INFO: Done with stage: SAVE MODEL
2022-12-31 07:14:49,901 INFO: Wall time for program:  8156.32 seconds
