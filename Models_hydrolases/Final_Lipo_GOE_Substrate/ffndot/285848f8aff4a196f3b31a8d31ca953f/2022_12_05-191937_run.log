2022-12-05 19:19:53,880 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/285848f8aff4a196f3b31a8d31ca953f/2022_12_05-191937",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-05 19:19:53,891 INFO: Starting stage: BUILD FEATURIZERS
2022-12-05 19:19:53,897 INFO:   Creating esm representation model
2022-12-05 19:19:53,897 INFO:   Done esm representation model
2022-12-05 19:19:53,897 INFO: Done with stage: BUILD FEATURIZERS
2022-12-05 19:19:53,897 INFO: Starting stage: BUILDING DATASET
2022-12-05 19:19:53,955 INFO: Done with stage: BUILDING DATASET
2022-12-05 19:19:53,955 INFO: Starting stage: FEATURIZING DATA
2022-12-05 19:19:53,955 INFO:   Featurizing proteins
2022-12-05 19:19:53,961 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-05 19:19:53,978 INFO:   Loaded feature cache of size 204
2022-12-05 19:19:53,979 INFO:   Starting to pool ESM Embeddings
2022-12-05 19:19:54,087 INFO:   Featurizing molecules
2022-12-05 19:19:54,091 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-05 19:19:54,104 INFO:   Loaded feature cache of size 495
2022-12-05 19:19:55,455 INFO: Done with stage: FEATURIZING DATA
2022-12-05 19:19:55,455 INFO: Starting stage: RUNNING SPLITS
2022-12-05 19:19:55,464 INFO:   Leaving out SEQ value Fold_0
2022-12-05 19:19:55,478 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 19:19:55,478 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:19:56,137 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:19:56,137 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:19:56,204 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:19:56,204 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:19:56,204 INFO:     No hyperparam tuning for this model
2022-12-05 19:19:56,204 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:19:56,204 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:19:56,205 INFO:     None feature selector for col prot
2022-12-05 19:19:56,205 INFO:     None feature selector for col prot
2022-12-05 19:19:56,205 INFO:     None feature selector for col prot
2022-12-05 19:19:56,206 INFO:     None feature selector for col chem
2022-12-05 19:19:56,206 INFO:     None feature selector for col chem
2022-12-05 19:19:56,206 INFO:     None feature selector for col chem
2022-12-05 19:19:56,206 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:19:56,206 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:19:56,208 INFO:     Number of params in model 215821
2022-12-05 19:19:56,208 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:19:56,208 INFO:   Starting stage: TRAINING
2022-12-05 19:19:58,257 INFO:     Val loss before train {'Reaction outcome loss': 1.0176387165868006, 'Total loss': 1.0176387165868006}
2022-12-05 19:19:58,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:19:58,258 INFO:     Epoch: 0
2022-12-05 19:19:59,040 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6108136281024578, 'Total loss': 0.6108136281024578} | train loss {'Reaction outcome loss': 0.7898299024730432, 'Total loss': 0.7898299024730432}
2022-12-05 19:19:59,040 INFO:     Found new best model at epoch 0
2022-12-05 19:19:59,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:19:59,041 INFO:     Epoch: 1
2022-12-05 19:19:59,814 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5337624369665633, 'Total loss': 0.5337624369665633} | train loss {'Reaction outcome loss': 0.5339455031713501, 'Total loss': 0.5339455031713501}
2022-12-05 19:19:59,814 INFO:     Found new best model at epoch 1
2022-12-05 19:19:59,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:19:59,815 INFO:     Epoch: 2
2022-12-05 19:20:00,592 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4999226303987725, 'Total loss': 0.4999226303987725} | train loss {'Reaction outcome loss': 0.4659778771341824, 'Total loss': 0.4659778771341824}
2022-12-05 19:20:00,592 INFO:     Found new best model at epoch 2
2022-12-05 19:20:00,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:00,593 INFO:     Epoch: 3
2022-12-05 19:20:01,370 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48064491464648135, 'Total loss': 0.48064491464648135} | train loss {'Reaction outcome loss': 0.426343206194092, 'Total loss': 0.426343206194092}
2022-12-05 19:20:01,370 INFO:     Found new best model at epoch 3
2022-12-05 19:20:01,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:01,371 INFO:     Epoch: 4
2022-12-05 19:20:02,148 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4850736679725869, 'Total loss': 0.4850736679725869} | train loss {'Reaction outcome loss': 0.39975539521604286, 'Total loss': 0.39975539521604286}
2022-12-05 19:20:02,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:02,148 INFO:     Epoch: 5
2022-12-05 19:20:02,928 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4647384951280993, 'Total loss': 0.4647384951280993} | train loss {'Reaction outcome loss': 0.37848499951670406, 'Total loss': 0.37848499951670406}
2022-12-05 19:20:02,928 INFO:     Found new best model at epoch 5
2022-12-05 19:20:02,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:02,929 INFO:     Epoch: 6
2022-12-05 19:20:03,705 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46144481834977175, 'Total loss': 0.46144481834977175} | train loss {'Reaction outcome loss': 0.3599763991402798, 'Total loss': 0.3599763991402798}
2022-12-05 19:20:03,705 INFO:     Found new best model at epoch 6
2022-12-05 19:20:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:03,706 INFO:     Epoch: 7
2022-12-05 19:20:04,482 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4516031000503274, 'Total loss': 0.4516031000503274} | train loss {'Reaction outcome loss': 0.3430705624708875, 'Total loss': 0.3430705624708875}
2022-12-05 19:20:04,482 INFO:     Found new best model at epoch 7
2022-12-05 19:20:04,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:04,483 INFO:     Epoch: 8
2022-12-05 19:20:05,264 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46656677196192187, 'Total loss': 0.46656677196192187} | train loss {'Reaction outcome loss': 0.32820443741855077, 'Total loss': 0.32820443741855077}
2022-12-05 19:20:05,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:05,264 INFO:     Epoch: 9
2022-12-05 19:20:06,043 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4460256830897442, 'Total loss': 0.4460256830897442} | train loss {'Reaction outcome loss': 0.3139709315155862, 'Total loss': 0.3139709315155862}
2022-12-05 19:20:06,044 INFO:     Found new best model at epoch 9
2022-12-05 19:20:06,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:06,044 INFO:     Epoch: 10
2022-12-05 19:20:06,821 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4530844383461531, 'Total loss': 0.4530844383461531} | train loss {'Reaction outcome loss': 0.3037044529604619, 'Total loss': 0.3037044529604619}
2022-12-05 19:20:06,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:06,822 INFO:     Epoch: 11
2022-12-05 19:20:07,602 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44325033176776973, 'Total loss': 0.44325033176776973} | train loss {'Reaction outcome loss': 0.2917494850508014, 'Total loss': 0.2917494850508014}
2022-12-05 19:20:07,602 INFO:     Found new best model at epoch 11
2022-12-05 19:20:07,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:07,603 INFO:     Epoch: 12
2022-12-05 19:20:08,382 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4478370699771615, 'Total loss': 0.4478370699771615} | train loss {'Reaction outcome loss': 0.28123202764230676, 'Total loss': 0.28123202764230676}
2022-12-05 19:20:08,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:08,383 INFO:     Epoch: 13
2022-12-05 19:20:09,158 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44438143213127934, 'Total loss': 0.44438143213127934} | train loss {'Reaction outcome loss': 0.2727454688674847, 'Total loss': 0.2727454688674847}
2022-12-05 19:20:09,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:09,158 INFO:     Epoch: 14
2022-12-05 19:20:09,940 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4437926695790402, 'Total loss': 0.4437926695790402} | train loss {'Reaction outcome loss': 0.2619752823146152, 'Total loss': 0.2619752823146152}
2022-12-05 19:20:09,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:09,940 INFO:     Epoch: 15
2022-12-05 19:20:10,722 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4492862221113471, 'Total loss': 0.4492862221113471} | train loss {'Reaction outcome loss': 0.25887626232426675, 'Total loss': 0.25887626232426675}
2022-12-05 19:20:10,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:10,722 INFO:     Epoch: 16
2022-12-05 19:20:11,499 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45246949895869853, 'Total loss': 0.45246949895869853} | train loss {'Reaction outcome loss': 0.24548258249205154, 'Total loss': 0.24548258249205154}
2022-12-05 19:20:11,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:11,499 INFO:     Epoch: 17
2022-12-05 19:20:12,279 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45466429203055625, 'Total loss': 0.45466429203055625} | train loss {'Reaction outcome loss': 0.23960634081273294, 'Total loss': 0.23960634081273294}
2022-12-05 19:20:12,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:12,279 INFO:     Epoch: 18
2022-12-05 19:20:13,060 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4360987467821254, 'Total loss': 0.4360987467821254} | train loss {'Reaction outcome loss': 0.23373142660396998, 'Total loss': 0.23373142660396998}
2022-12-05 19:20:13,060 INFO:     Found new best model at epoch 18
2022-12-05 19:20:13,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:13,061 INFO:     Epoch: 19
2022-12-05 19:20:13,845 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4449420557465664, 'Total loss': 0.4449420557465664} | train loss {'Reaction outcome loss': 0.22590529124756328, 'Total loss': 0.22590529124756328}
2022-12-05 19:20:13,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:13,846 INFO:     Epoch: 20
2022-12-05 19:20:14,624 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44093127531367676, 'Total loss': 0.44093127531367676} | train loss {'Reaction outcome loss': 0.22092665226549887, 'Total loss': 0.22092665226549887}
2022-12-05 19:20:14,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:14,624 INFO:     Epoch: 21
2022-12-05 19:20:15,401 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44128825116989223, 'Total loss': 0.44128825116989223} | train loss {'Reaction outcome loss': 0.2153025754406804, 'Total loss': 0.2153025754406804}
2022-12-05 19:20:15,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:15,401 INFO:     Epoch: 22
2022-12-05 19:20:16,181 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4686620072569958, 'Total loss': 0.4686620072569958} | train loss {'Reaction outcome loss': 0.20945120477651963, 'Total loss': 0.20945120477651963}
2022-12-05 19:20:16,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:16,181 INFO:     Epoch: 23
2022-12-05 19:20:16,959 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.453622997153637, 'Total loss': 0.453622997153637} | train loss {'Reaction outcome loss': 0.20698743507449255, 'Total loss': 0.20698743507449255}
2022-12-05 19:20:16,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:16,960 INFO:     Epoch: 24
2022-12-05 19:20:17,738 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46606979571109597, 'Total loss': 0.46606979571109597} | train loss {'Reaction outcome loss': 0.20212930306547977, 'Total loss': 0.20212930306547977}
2022-12-05 19:20:17,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:17,738 INFO:     Epoch: 25
2022-12-05 19:20:18,524 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47090569796950316, 'Total loss': 0.47090569796950316} | train loss {'Reaction outcome loss': 0.1960917209488813, 'Total loss': 0.1960917209488813}
2022-12-05 19:20:18,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:18,524 INFO:     Epoch: 26
2022-12-05 19:20:19,310 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4703809506324835, 'Total loss': 0.4703809506324835} | train loss {'Reaction outcome loss': 0.19507153680334327, 'Total loss': 0.19507153680334327}
2022-12-05 19:20:19,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:19,311 INFO:     Epoch: 27
2022-12-05 19:20:20,089 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46688914368318957, 'Total loss': 0.46688914368318957} | train loss {'Reaction outcome loss': 0.19040218687265134, 'Total loss': 0.19040218687265134}
2022-12-05 19:20:20,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:20,090 INFO:     Epoch: 28
2022-12-05 19:20:20,871 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47110321355420487, 'Total loss': 0.47110321355420487} | train loss {'Reaction outcome loss': 0.1846480351552123, 'Total loss': 0.1846480351552123}
2022-12-05 19:20:20,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:20,871 INFO:     Epoch: 29
2022-12-05 19:20:21,650 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4728631325239359, 'Total loss': 0.4728631325239359} | train loss {'Reaction outcome loss': 0.18140251565816218, 'Total loss': 0.18140251565816218}
2022-12-05 19:20:21,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:21,650 INFO:     Epoch: 30
2022-12-05 19:20:22,429 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4593715844459312, 'Total loss': 0.4593715844459312} | train loss {'Reaction outcome loss': 0.17644855899156117, 'Total loss': 0.17644855899156117}
2022-12-05 19:20:22,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:22,429 INFO:     Epoch: 31
2022-12-05 19:20:23,216 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46438676638658655, 'Total loss': 0.46438676638658655} | train loss {'Reaction outcome loss': 0.17790132038081524, 'Total loss': 0.17790132038081524}
2022-12-05 19:20:23,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:23,216 INFO:     Epoch: 32
2022-12-05 19:20:23,999 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45835653536541515, 'Total loss': 0.45835653536541515} | train loss {'Reaction outcome loss': 0.17576582651951764, 'Total loss': 0.17576582651951764}
2022-12-05 19:20:23,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:23,999 INFO:     Epoch: 33
2022-12-05 19:20:24,784 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46192972275406813, 'Total loss': 0.46192972275406813} | train loss {'Reaction outcome loss': 0.17242240278264048, 'Total loss': 0.17242240278264048}
2022-12-05 19:20:24,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:24,784 INFO:     Epoch: 34
2022-12-05 19:20:25,569 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47306780932947645, 'Total loss': 0.47306780932947645} | train loss {'Reaction outcome loss': 0.1716592491405909, 'Total loss': 0.1716592491405909}
2022-12-05 19:20:25,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:25,569 INFO:     Epoch: 35
2022-12-05 19:20:26,356 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46865252699962884, 'Total loss': 0.46865252699962884} | train loss {'Reaction outcome loss': 0.16823680130535829, 'Total loss': 0.16823680130535829}
2022-12-05 19:20:26,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:26,357 INFO:     Epoch: 36
2022-12-05 19:20:27,144 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47373722424340803, 'Total loss': 0.47373722424340803} | train loss {'Reaction outcome loss': 0.1662257771068787, 'Total loss': 0.1662257771068787}
2022-12-05 19:20:27,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:27,145 INFO:     Epoch: 37
2022-12-05 19:20:27,927 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46988426460776217, 'Total loss': 0.46988426460776217} | train loss {'Reaction outcome loss': 0.16170215814328584, 'Total loss': 0.16170215814328584}
2022-12-05 19:20:27,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:27,927 INFO:     Epoch: 38
2022-12-05 19:20:28,710 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47433953957502234, 'Total loss': 0.47433953957502234} | train loss {'Reaction outcome loss': 0.16109457357069018, 'Total loss': 0.16109457357069018}
2022-12-05 19:20:28,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:28,710 INFO:     Epoch: 39
2022-12-05 19:20:29,492 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4771204393270404, 'Total loss': 0.4771204393270404} | train loss {'Reaction outcome loss': 0.15903987480541232, 'Total loss': 0.15903987480541232}
2022-12-05 19:20:29,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:29,493 INFO:     Epoch: 40
2022-12-05 19:20:30,279 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47329650576724563, 'Total loss': 0.47329650576724563} | train loss {'Reaction outcome loss': 0.1558672991184304, 'Total loss': 0.1558672991184304}
2022-12-05 19:20:30,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:30,279 INFO:     Epoch: 41
2022-12-05 19:20:31,065 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47832570173019584, 'Total loss': 0.47832570173019584} | train loss {'Reaction outcome loss': 0.15755428139456226, 'Total loss': 0.15755428139456226}
2022-12-05 19:20:31,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:31,065 INFO:     Epoch: 42
2022-12-05 19:20:31,853 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4832942759574846, 'Total loss': 0.4832942759574846} | train loss {'Reaction outcome loss': 0.15399267577153983, 'Total loss': 0.15399267577153983}
2022-12-05 19:20:31,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:31,853 INFO:     Epoch: 43
2022-12-05 19:20:32,640 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4743823391753574, 'Total loss': 0.4743823391753574} | train loss {'Reaction outcome loss': 0.1546653728611523, 'Total loss': 0.1546653728611523}
2022-12-05 19:20:32,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:32,642 INFO:     Epoch: 44
2022-12-05 19:20:33,428 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46406985195570216, 'Total loss': 0.46406985195570216} | train loss {'Reaction outcome loss': 0.1519023532841782, 'Total loss': 0.1519023532841782}
2022-12-05 19:20:33,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:33,428 INFO:     Epoch: 45
2022-12-05 19:20:34,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4786744627148606, 'Total loss': 0.4786744627148606} | train loss {'Reaction outcome loss': 0.15052419052016539, 'Total loss': 0.15052419052016539}
2022-12-05 19:20:34,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:34,211 INFO:     Epoch: 46
2022-12-05 19:20:35,001 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46017055767913195, 'Total loss': 0.46017055767913195} | train loss {'Reaction outcome loss': 0.1495037452989548, 'Total loss': 0.1495037452989548}
2022-12-05 19:20:35,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:35,001 INFO:     Epoch: 47
2022-12-05 19:20:35,785 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48252804785273795, 'Total loss': 0.48252804785273795} | train loss {'Reaction outcome loss': 0.145208119002522, 'Total loss': 0.145208119002522}
2022-12-05 19:20:35,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:35,785 INFO:     Epoch: 48
2022-12-05 19:20:36,576 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46212197597636734, 'Total loss': 0.46212197597636734} | train loss {'Reaction outcome loss': 0.1450017621954445, 'Total loss': 0.1450017621954445}
2022-12-05 19:20:36,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:36,576 INFO:     Epoch: 49
2022-12-05 19:20:37,361 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4580860416903052, 'Total loss': 0.4580860416903052} | train loss {'Reaction outcome loss': 0.14560465245759574, 'Total loss': 0.14560465245759574}
2022-12-05 19:20:37,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:37,361 INFO:     Epoch: 50
2022-12-05 19:20:38,146 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4956819331923196, 'Total loss': 0.4956819331923196} | train loss {'Reaction outcome loss': 0.14582975491972977, 'Total loss': 0.14582975491972977}
2022-12-05 19:20:38,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:38,146 INFO:     Epoch: 51
2022-12-05 19:20:38,933 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48123293768527897, 'Total loss': 0.48123293768527897} | train loss {'Reaction outcome loss': 0.14253923115244166, 'Total loss': 0.14253923115244166}
2022-12-05 19:20:38,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:38,934 INFO:     Epoch: 52
2022-12-05 19:20:39,729 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48510559007178905, 'Total loss': 0.48510559007178905} | train loss {'Reaction outcome loss': 0.1425079132628734, 'Total loss': 0.1425079132628734}
2022-12-05 19:20:39,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:39,729 INFO:     Epoch: 53
2022-12-05 19:20:40,519 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4711665282415789, 'Total loss': 0.4711665282415789} | train loss {'Reaction outcome loss': 0.1406223536698056, 'Total loss': 0.1406223536698056}
2022-12-05 19:20:40,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:40,519 INFO:     Epoch: 54
2022-12-05 19:20:41,311 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48785152927387593, 'Total loss': 0.48785152927387593} | train loss {'Reaction outcome loss': 0.13867601338147995, 'Total loss': 0.13867601338147995}
2022-12-05 19:20:41,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:41,311 INFO:     Epoch: 55
2022-12-05 19:20:42,099 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48787978152896083, 'Total loss': 0.48787978152896083} | train loss {'Reaction outcome loss': 0.1386810820206206, 'Total loss': 0.1386810820206206}
2022-12-05 19:20:42,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:42,099 INFO:     Epoch: 56
2022-12-05 19:20:42,890 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49280123481916827, 'Total loss': 0.49280123481916827} | train loss {'Reaction outcome loss': 0.13758255749345435, 'Total loss': 0.13758255749345435}
2022-12-05 19:20:42,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:42,890 INFO:     Epoch: 57
2022-12-05 19:20:43,679 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49149700825990633, 'Total loss': 0.49149700825990633} | train loss {'Reaction outcome loss': 0.1371373117168541, 'Total loss': 0.1371373117168541}
2022-12-05 19:20:43,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:43,679 INFO:     Epoch: 58
2022-12-05 19:20:44,465 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4760683428409488, 'Total loss': 0.4760683428409488} | train loss {'Reaction outcome loss': 0.13497293151945608, 'Total loss': 0.13497293151945608}
2022-12-05 19:20:44,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:44,465 INFO:     Epoch: 59
2022-12-05 19:20:45,250 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4750944505943808, 'Total loss': 0.4750944505943808} | train loss {'Reaction outcome loss': 0.13540570187519807, 'Total loss': 0.13540570187519807}
2022-12-05 19:20:45,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:45,250 INFO:     Epoch: 60
2022-12-05 19:20:46,031 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47666784947694735, 'Total loss': 0.47666784947694735} | train loss {'Reaction outcome loss': 0.13557784526502012, 'Total loss': 0.13557784526502012}
2022-12-05 19:20:46,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:46,031 INFO:     Epoch: 61
2022-12-05 19:20:46,818 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4774184268574382, 'Total loss': 0.4774184268574382} | train loss {'Reaction outcome loss': 0.13257862414523472, 'Total loss': 0.13257862414523472}
2022-12-05 19:20:46,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:46,818 INFO:     Epoch: 62
2022-12-05 19:20:47,596 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4907861074735952, 'Total loss': 0.4907861074735952} | train loss {'Reaction outcome loss': 0.1324317490827048, 'Total loss': 0.1324317490827048}
2022-12-05 19:20:47,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:47,597 INFO:     Epoch: 63
2022-12-05 19:20:48,373 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48643408473147903, 'Total loss': 0.48643408473147903} | train loss {'Reaction outcome loss': 0.12936996605216725, 'Total loss': 0.12936996605216725}
2022-12-05 19:20:48,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:48,374 INFO:     Epoch: 64
2022-12-05 19:20:49,155 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47601438469665, 'Total loss': 0.47601438469665} | train loss {'Reaction outcome loss': 0.12948169648937394, 'Total loss': 0.12948169648937394}
2022-12-05 19:20:49,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:49,155 INFO:     Epoch: 65
2022-12-05 19:20:49,934 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47327204152595165, 'Total loss': 0.47327204152595165} | train loss {'Reaction outcome loss': 0.1308465375732936, 'Total loss': 0.1308465375732936}
2022-12-05 19:20:49,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:49,934 INFO:     Epoch: 66
2022-12-05 19:20:50,713 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47739384964455006, 'Total loss': 0.47739384964455006} | train loss {'Reaction outcome loss': 0.12869625117965652, 'Total loss': 0.12869625117965652}
2022-12-05 19:20:50,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:50,714 INFO:     Epoch: 67
2022-12-05 19:20:51,495 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48837681253289067, 'Total loss': 0.48837681253289067} | train loss {'Reaction outcome loss': 0.12726013740280367, 'Total loss': 0.12726013740280367}
2022-12-05 19:20:51,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:51,496 INFO:     Epoch: 68
2022-12-05 19:20:52,282 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.487645581018093, 'Total loss': 0.487645581018093} | train loss {'Reaction outcome loss': 0.1279376639076127, 'Total loss': 0.1279376639076127}
2022-12-05 19:20:52,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:52,282 INFO:     Epoch: 69
2022-12-05 19:20:53,065 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49711395314959594, 'Total loss': 0.49711395314959594} | train loss {'Reaction outcome loss': 0.12844349027870863, 'Total loss': 0.12844349027870863}
2022-12-05 19:20:53,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:53,066 INFO:     Epoch: 70
2022-12-05 19:20:53,844 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.495691308448481, 'Total loss': 0.495691308448481} | train loss {'Reaction outcome loss': 0.12675963773880702, 'Total loss': 0.12675963773880702}
2022-12-05 19:20:53,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:53,844 INFO:     Epoch: 71
2022-12-05 19:20:54,625 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47949489362018055, 'Total loss': 0.47949489362018055} | train loss {'Reaction outcome loss': 0.12827285664675178, 'Total loss': 0.12827285664675178}
2022-12-05 19:20:54,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:54,625 INFO:     Epoch: 72
2022-12-05 19:20:55,411 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4743565975926643, 'Total loss': 0.4743565975926643} | train loss {'Reaction outcome loss': 0.12527839663499568, 'Total loss': 0.12527839663499568}
2022-12-05 19:20:55,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:55,411 INFO:     Epoch: 73
2022-12-05 19:20:56,196 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4966855475375819, 'Total loss': 0.4966855475375819} | train loss {'Reaction outcome loss': 0.12578526803399206, 'Total loss': 0.12578526803399206}
2022-12-05 19:20:56,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:56,196 INFO:     Epoch: 74
2022-12-05 19:20:56,977 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4862816032282142, 'Total loss': 0.4862816032282142} | train loss {'Reaction outcome loss': 0.1229262303018973, 'Total loss': 0.1229262303018973}
2022-12-05 19:20:56,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:56,977 INFO:     Epoch: 75
2022-12-05 19:20:57,757 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.483039119908976, 'Total loss': 0.483039119908976} | train loss {'Reaction outcome loss': 0.1229590073716445, 'Total loss': 0.1229590073716445}
2022-12-05 19:20:57,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:57,757 INFO:     Epoch: 76
2022-12-05 19:20:58,542 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47303597317185514, 'Total loss': 0.47303597317185514} | train loss {'Reaction outcome loss': 0.12488145289606735, 'Total loss': 0.12488145289606735}
2022-12-05 19:20:58,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:58,542 INFO:     Epoch: 77
2022-12-05 19:20:59,326 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4990967765103939, 'Total loss': 0.4990967765103939} | train loss {'Reaction outcome loss': 0.12147377608114945, 'Total loss': 0.12147377608114945}
2022-12-05 19:20:59,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:20:59,326 INFO:     Epoch: 78
2022-12-05 19:21:00,103 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4674503089383591, 'Total loss': 0.4674503089383591} | train loss {'Reaction outcome loss': 0.12069534753510332, 'Total loss': 0.12069534753510332}
2022-12-05 19:21:00,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:00,103 INFO:     Epoch: 79
2022-12-05 19:21:00,881 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47002173440400946, 'Total loss': 0.47002173440400946} | train loss {'Reaction outcome loss': 0.12438264349475503, 'Total loss': 0.12438264349475503}
2022-12-05 19:21:00,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:00,881 INFO:     Epoch: 80
2022-12-05 19:21:01,663 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4747350018384845, 'Total loss': 0.4747350018384845} | train loss {'Reaction outcome loss': 0.12160736304845234, 'Total loss': 0.12160736304845234}
2022-12-05 19:21:01,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:01,663 INFO:     Epoch: 81
2022-12-05 19:21:02,442 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4989034100327381, 'Total loss': 0.4989034100327381} | train loss {'Reaction outcome loss': 0.12176852569472595, 'Total loss': 0.12176852569472595}
2022-12-05 19:21:02,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:02,443 INFO:     Epoch: 82
2022-12-05 19:21:03,223 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4870297610759735, 'Total loss': 0.4870297610759735} | train loss {'Reaction outcome loss': 0.12242407833042813, 'Total loss': 0.12242407833042813}
2022-12-05 19:21:03,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:03,224 INFO:     Epoch: 83
2022-12-05 19:21:04,005 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47750341268472896, 'Total loss': 0.47750341268472896} | train loss {'Reaction outcome loss': 0.11856290635072672, 'Total loss': 0.11856290635072672}
2022-12-05 19:21:04,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:04,005 INFO:     Epoch: 84
2022-12-05 19:21:04,783 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47801439273496005, 'Total loss': 0.47801439273496005} | train loss {'Reaction outcome loss': 0.11877357614699935, 'Total loss': 0.11877357614699935}
2022-12-05 19:21:04,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:04,783 INFO:     Epoch: 85
2022-12-05 19:21:05,568 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45797475028869716, 'Total loss': 0.45797475028869716} | train loss {'Reaction outcome loss': 0.11956789326228079, 'Total loss': 0.11956789326228079}
2022-12-05 19:21:05,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:05,568 INFO:     Epoch: 86
2022-12-05 19:21:06,347 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47794517666794534, 'Total loss': 0.47794517666794534} | train loss {'Reaction outcome loss': 0.11939203244687409, 'Total loss': 0.11939203244687409}
2022-12-05 19:21:06,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:06,347 INFO:     Epoch: 87
2022-12-05 19:21:07,128 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5113541043775026, 'Total loss': 0.5113541043775026} | train loss {'Reaction outcome loss': 0.11665786398941132, 'Total loss': 0.11665786398941132}
2022-12-05 19:21:07,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:07,129 INFO:     Epoch: 88
2022-12-05 19:21:07,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47523369969323626, 'Total loss': 0.47523369969323626} | train loss {'Reaction outcome loss': 0.12071024753596084, 'Total loss': 0.12071024753596084}
2022-12-05 19:21:07,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:07,911 INFO:     Epoch: 89
2022-12-05 19:21:08,692 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4703010414228883, 'Total loss': 0.4703010414228883} | train loss {'Reaction outcome loss': 0.11717869112359695, 'Total loss': 0.11717869112359695}
2022-12-05 19:21:08,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:08,692 INFO:     Epoch: 90
2022-12-05 19:21:09,474 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.471526387819024, 'Total loss': 0.471526387819024} | train loss {'Reaction outcome loss': 0.1194243754878579, 'Total loss': 0.1194243754878579}
2022-12-05 19:21:09,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:09,475 INFO:     Epoch: 91
2022-12-05 19:21:10,257 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47052535449349603, 'Total loss': 0.47052535449349603} | train loss {'Reaction outcome loss': 0.11899868128286889, 'Total loss': 0.11899868128286889}
2022-12-05 19:21:10,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:10,257 INFO:     Epoch: 92
2022-12-05 19:21:11,037 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4657481635032698, 'Total loss': 0.4657481635032698} | train loss {'Reaction outcome loss': 0.11587353577822081, 'Total loss': 0.11587353577822081}
2022-12-05 19:21:11,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:11,037 INFO:     Epoch: 93
2022-12-05 19:21:11,818 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47610281477140826, 'Total loss': 0.47610281477140826} | train loss {'Reaction outcome loss': 0.11460438673002799, 'Total loss': 0.11460438673002799}
2022-12-05 19:21:11,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:11,819 INFO:     Epoch: 94
2022-12-05 19:21:12,614 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46875500575054524, 'Total loss': 0.46875500575054524} | train loss {'Reaction outcome loss': 0.11630426178930602, 'Total loss': 0.11630426178930602}
2022-12-05 19:21:12,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:12,614 INFO:     Epoch: 95
2022-12-05 19:21:13,400 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4873261306174966, 'Total loss': 0.4873261306174966} | train loss {'Reaction outcome loss': 0.1156016670026221, 'Total loss': 0.1156016670026221}
2022-12-05 19:21:13,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:13,400 INFO:     Epoch: 96
2022-12-05 19:21:14,184 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48186354581699814, 'Total loss': 0.48186354581699814} | train loss {'Reaction outcome loss': 0.11514374926365668, 'Total loss': 0.11514374926365668}
2022-12-05 19:21:14,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:14,184 INFO:     Epoch: 97
2022-12-05 19:21:14,964 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4819582988356435, 'Total loss': 0.4819582988356435} | train loss {'Reaction outcome loss': 0.11558799546013479, 'Total loss': 0.11558799546013479}
2022-12-05 19:21:14,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:14,964 INFO:     Epoch: 98
2022-12-05 19:21:15,743 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4838663433180299, 'Total loss': 0.4838663433180299} | train loss {'Reaction outcome loss': 0.11624485902778316, 'Total loss': 0.11624485902778316}
2022-12-05 19:21:15,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:15,743 INFO:     Epoch: 99
2022-12-05 19:21:16,523 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4832413681717806, 'Total loss': 0.4832413681717806} | train loss {'Reaction outcome loss': 0.11274764696746821, 'Total loss': 0.11274764696746821}
2022-12-05 19:21:16,524 INFO:     Best model found after epoch 19 of 100.
2022-12-05 19:21:16,524 INFO:   Done with stage: TRAINING
2022-12-05 19:21:16,524 INFO:   Starting stage: EVALUATION
2022-12-05 19:21:16,662 INFO:   Done with stage: EVALUATION
2022-12-05 19:21:16,662 INFO:   Leaving out SEQ value Fold_1
2022-12-05 19:21:16,675 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:21:16,675 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:21:17,334 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:21:17,334 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:21:17,402 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:21:17,402 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:21:17,402 INFO:     No hyperparam tuning for this model
2022-12-05 19:21:17,402 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:21:17,403 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:21:17,403 INFO:     None feature selector for col prot
2022-12-05 19:21:17,403 INFO:     None feature selector for col prot
2022-12-05 19:21:17,403 INFO:     None feature selector for col prot
2022-12-05 19:21:17,404 INFO:     None feature selector for col chem
2022-12-05 19:21:17,404 INFO:     None feature selector for col chem
2022-12-05 19:21:17,404 INFO:     None feature selector for col chem
2022-12-05 19:21:17,404 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:21:17,404 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:21:17,406 INFO:     Number of params in model 215821
2022-12-05 19:21:17,409 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:21:17,409 INFO:   Starting stage: TRAINING
2022-12-05 19:21:17,470 INFO:     Val loss before train {'Reaction outcome loss': 1.0194574418393048, 'Total loss': 1.0194574418393048}
2022-12-05 19:21:17,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:17,470 INFO:     Epoch: 0
2022-12-05 19:21:18,264 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6590381135994737, 'Total loss': 0.6590381135994737} | train loss {'Reaction outcome loss': 0.7867336869843093, 'Total loss': 0.7867336869843093}
2022-12-05 19:21:18,264 INFO:     Found new best model at epoch 0
2022-12-05 19:21:18,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:18,265 INFO:     Epoch: 1
2022-12-05 19:21:19,057 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5678163915872574, 'Total loss': 0.5678163915872574} | train loss {'Reaction outcome loss': 0.5392347397471247, 'Total loss': 0.5392347397471247}
2022-12-05 19:21:19,058 INFO:     Found new best model at epoch 1
2022-12-05 19:21:19,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:19,059 INFO:     Epoch: 2
2022-12-05 19:21:19,855 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5333777239376848, 'Total loss': 0.5333777239376848} | train loss {'Reaction outcome loss': 0.47202793897887474, 'Total loss': 0.47202793897887474}
2022-12-05 19:21:19,855 INFO:     Found new best model at epoch 2
2022-12-05 19:21:19,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:19,856 INFO:     Epoch: 3
2022-12-05 19:21:20,647 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5113960741595789, 'Total loss': 0.5113960741595789} | train loss {'Reaction outcome loss': 0.42909403351938674, 'Total loss': 0.42909403351938674}
2022-12-05 19:21:20,648 INFO:     Found new best model at epoch 3
2022-12-05 19:21:20,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:20,648 INFO:     Epoch: 4
2022-12-05 19:21:21,444 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4858630462126298, 'Total loss': 0.4858630462126298} | train loss {'Reaction outcome loss': 0.40142958722857813, 'Total loss': 0.40142958722857813}
2022-12-05 19:21:21,444 INFO:     Found new best model at epoch 4
2022-12-05 19:21:21,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:21,445 INFO:     Epoch: 5
2022-12-05 19:21:22,240 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4810391820289872, 'Total loss': 0.4810391820289872} | train loss {'Reaction outcome loss': 0.3841642978702962, 'Total loss': 0.3841642978702962}
2022-12-05 19:21:22,241 INFO:     Found new best model at epoch 5
2022-12-05 19:21:22,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:22,242 INFO:     Epoch: 6
2022-12-05 19:21:23,030 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47100070728497073, 'Total loss': 0.47100070728497073} | train loss {'Reaction outcome loss': 0.3587089347302431, 'Total loss': 0.3587089347302431}
2022-12-05 19:21:23,030 INFO:     Found new best model at epoch 6
2022-12-05 19:21:23,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:23,031 INFO:     Epoch: 7
2022-12-05 19:21:23,819 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46257915686477313, 'Total loss': 0.46257915686477313} | train loss {'Reaction outcome loss': 0.34328177179160874, 'Total loss': 0.34328177179160874}
2022-12-05 19:21:23,819 INFO:     Found new best model at epoch 7
2022-12-05 19:21:23,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:23,820 INFO:     Epoch: 8
2022-12-05 19:21:24,614 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46342134357176046, 'Total loss': 0.46342134357176046} | train loss {'Reaction outcome loss': 0.3281895373061842, 'Total loss': 0.3281895373061842}
2022-12-05 19:21:24,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:24,614 INFO:     Epoch: 9
2022-12-05 19:21:25,407 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45605055649172177, 'Total loss': 0.45605055649172177} | train loss {'Reaction outcome loss': 0.31465093031344626, 'Total loss': 0.31465093031344626}
2022-12-05 19:21:25,407 INFO:     Found new best model at epoch 9
2022-12-05 19:21:25,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:25,408 INFO:     Epoch: 10
2022-12-05 19:21:26,202 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46663800085132773, 'Total loss': 0.46663800085132773} | train loss {'Reaction outcome loss': 0.2996047409138216, 'Total loss': 0.2996047409138216}
2022-12-05 19:21:26,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:26,202 INFO:     Epoch: 11
2022-12-05 19:21:26,995 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44088040393861855, 'Total loss': 0.44088040393861855} | train loss {'Reaction outcome loss': 0.29070795590231413, 'Total loss': 0.29070795590231413}
2022-12-05 19:21:26,995 INFO:     Found new best model at epoch 11
2022-12-05 19:21:26,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:26,996 INFO:     Epoch: 12
2022-12-05 19:21:27,788 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46389419957995415, 'Total loss': 0.46389419957995415} | train loss {'Reaction outcome loss': 0.2800634169351566, 'Total loss': 0.2800634169351566}
2022-12-05 19:21:27,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:27,788 INFO:     Epoch: 13
2022-12-05 19:21:28,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45621967992999335, 'Total loss': 0.45621967992999335} | train loss {'Reaction outcome loss': 0.26927143356834465, 'Total loss': 0.26927143356834465}
2022-12-05 19:21:28,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:28,582 INFO:     Epoch: 14
2022-12-05 19:21:29,374 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44361142272298987, 'Total loss': 0.44361142272298987} | train loss {'Reaction outcome loss': 0.2669966022977945, 'Total loss': 0.2669966022977945}
2022-12-05 19:21:29,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:29,374 INFO:     Epoch: 15
2022-12-05 19:21:30,167 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4402351403100924, 'Total loss': 0.4402351403100924} | train loss {'Reaction outcome loss': 0.2583029599264566, 'Total loss': 0.2583029599264566}
2022-12-05 19:21:30,167 INFO:     Found new best model at epoch 15
2022-12-05 19:21:30,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:30,168 INFO:     Epoch: 16
2022-12-05 19:21:30,962 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43466922031207517, 'Total loss': 0.43466922031207517} | train loss {'Reaction outcome loss': 0.2533650809092078, 'Total loss': 0.2533650809092078}
2022-12-05 19:21:30,962 INFO:     Found new best model at epoch 16
2022-12-05 19:21:30,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:30,963 INFO:     Epoch: 17
2022-12-05 19:21:31,760 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45093162764202466, 'Total loss': 0.45093162764202466} | train loss {'Reaction outcome loss': 0.24696341415147036, 'Total loss': 0.24696341415147036}
2022-12-05 19:21:31,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:31,760 INFO:     Epoch: 18
2022-12-05 19:21:32,556 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44036995111541316, 'Total loss': 0.44036995111541316} | train loss {'Reaction outcome loss': 0.2380752886083686, 'Total loss': 0.2380752886083686}
2022-12-05 19:21:32,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:32,557 INFO:     Epoch: 19
2022-12-05 19:21:33,352 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4634645510126244, 'Total loss': 0.4634645510126244} | train loss {'Reaction outcome loss': 0.2326680548434421, 'Total loss': 0.2326680548434421}
2022-12-05 19:21:33,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:33,352 INFO:     Epoch: 20
2022-12-05 19:21:34,145 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46274378590963106, 'Total loss': 0.46274378590963106} | train loss {'Reaction outcome loss': 0.23134969639392033, 'Total loss': 0.23134969639392033}
2022-12-05 19:21:34,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:34,146 INFO:     Epoch: 21
2022-12-05 19:21:34,939 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4420946823771704, 'Total loss': 0.4420946823771704} | train loss {'Reaction outcome loss': 0.22508995488346348, 'Total loss': 0.22508995488346348}
2022-12-05 19:21:34,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:34,940 INFO:     Epoch: 22
2022-12-05 19:21:35,736 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44853343814611435, 'Total loss': 0.44853343814611435} | train loss {'Reaction outcome loss': 0.22435774492771038, 'Total loss': 0.22435774492771038}
2022-12-05 19:21:35,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:35,736 INFO:     Epoch: 23
2022-12-05 19:21:36,531 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4360293224453926, 'Total loss': 0.4360293224453926} | train loss {'Reaction outcome loss': 0.21475333379589112, 'Total loss': 0.21475333379589112}
2022-12-05 19:21:36,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:36,531 INFO:     Epoch: 24
2022-12-05 19:21:37,330 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44135796346447687, 'Total loss': 0.44135796346447687} | train loss {'Reaction outcome loss': 0.22124732432034816, 'Total loss': 0.22124732432034816}
2022-12-05 19:21:37,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:37,330 INFO:     Epoch: 25
2022-12-05 19:21:38,130 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44276811148632655, 'Total loss': 0.44276811148632655} | train loss {'Reaction outcome loss': 0.2108525086631659, 'Total loss': 0.2108525086631659}
2022-12-05 19:21:38,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:38,130 INFO:     Epoch: 26
2022-12-05 19:21:38,927 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4447637755762447, 'Total loss': 0.4447637755762447} | train loss {'Reaction outcome loss': 0.20314565327712278, 'Total loss': 0.20314565327712278}
2022-12-05 19:21:38,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:38,928 INFO:     Epoch: 27
2022-12-05 19:21:39,729 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4604404897175052, 'Total loss': 0.4604404897175052} | train loss {'Reaction outcome loss': 0.19927149692075213, 'Total loss': 0.19927149692075213}
2022-12-05 19:21:39,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:39,729 INFO:     Epoch: 28
2022-12-05 19:21:40,531 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4600707041946324, 'Total loss': 0.4600707041946324} | train loss {'Reaction outcome loss': 0.19752963814839178, 'Total loss': 0.19752963814839178}
2022-12-05 19:21:40,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:40,531 INFO:     Epoch: 29
2022-12-05 19:21:41,324 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4425916058773344, 'Total loss': 0.4425916058773344} | train loss {'Reaction outcome loss': 0.19750051134028415, 'Total loss': 0.19750051134028415}
2022-12-05 19:21:41,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:41,325 INFO:     Epoch: 30
2022-12-05 19:21:42,118 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47219795191829855, 'Total loss': 0.47219795191829855} | train loss {'Reaction outcome loss': 0.19190499061333988, 'Total loss': 0.19190499061333988}
2022-12-05 19:21:42,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:42,118 INFO:     Epoch: 31
2022-12-05 19:21:42,914 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49224263565106824, 'Total loss': 0.49224263565106824} | train loss {'Reaction outcome loss': 0.18906749261972997, 'Total loss': 0.18906749261972997}
2022-12-05 19:21:42,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:42,914 INFO:     Epoch: 32
2022-12-05 19:21:43,710 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4460422061383724, 'Total loss': 0.4460422061383724} | train loss {'Reaction outcome loss': 0.18770229859420887, 'Total loss': 0.18770229859420887}
2022-12-05 19:21:43,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:43,710 INFO:     Epoch: 33
2022-12-05 19:21:44,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4425404098900882, 'Total loss': 0.4425404098900882} | train loss {'Reaction outcome loss': 0.18346986642884097, 'Total loss': 0.18346986642884097}
2022-12-05 19:21:44,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:44,509 INFO:     Epoch: 34
2022-12-05 19:21:45,306 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4375156675550071, 'Total loss': 0.4375156675550071} | train loss {'Reaction outcome loss': 0.18202744156446474, 'Total loss': 0.18202744156446474}
2022-12-05 19:21:45,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:45,306 INFO:     Epoch: 35
2022-12-05 19:21:46,105 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45940164307301695, 'Total loss': 0.45940164307301695} | train loss {'Reaction outcome loss': 0.18412937283485767, 'Total loss': 0.18412937283485767}
2022-12-05 19:21:46,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:46,106 INFO:     Epoch: 36
2022-12-05 19:21:46,902 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45738405564969237, 'Total loss': 0.45738405564969237} | train loss {'Reaction outcome loss': 0.17956294065062334, 'Total loss': 0.17956294065062334}
2022-12-05 19:21:46,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:46,902 INFO:     Epoch: 37
2022-12-05 19:21:47,701 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46174559301950713, 'Total loss': 0.46174559301950713} | train loss {'Reaction outcome loss': 0.1731389737141277, 'Total loss': 0.1731389737141277}
2022-12-05 19:21:47,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:47,701 INFO:     Epoch: 38
2022-12-05 19:21:48,497 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4594771411608566, 'Total loss': 0.4594771411608566} | train loss {'Reaction outcome loss': 0.17096930553736958, 'Total loss': 0.17096930553736958}
2022-12-05 19:21:48,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:48,498 INFO:     Epoch: 39
2022-12-05 19:21:49,293 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4589368553662842, 'Total loss': 0.4589368553662842} | train loss {'Reaction outcome loss': 0.16799761561548662, 'Total loss': 0.16799761561548662}
2022-12-05 19:21:49,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:49,293 INFO:     Epoch: 40
2022-12-05 19:21:50,096 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45310998403213243, 'Total loss': 0.45310998403213243} | train loss {'Reaction outcome loss': 0.1689538086956812, 'Total loss': 0.1689538086956812}
2022-12-05 19:21:50,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:50,096 INFO:     Epoch: 41
2022-12-05 19:21:50,901 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46893649209629407, 'Total loss': 0.46893649209629407} | train loss {'Reaction outcome loss': 0.16823959368684513, 'Total loss': 0.16823959368684513}
2022-12-05 19:21:50,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:50,901 INFO:     Epoch: 42
2022-12-05 19:21:51,698 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4646568095142191, 'Total loss': 0.4646568095142191} | train loss {'Reaction outcome loss': 0.16700952253511803, 'Total loss': 0.16700952253511803}
2022-12-05 19:21:51,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:51,698 INFO:     Epoch: 43
2022-12-05 19:21:52,506 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45039504021406174, 'Total loss': 0.45039504021406174} | train loss {'Reaction outcome loss': 0.1632299708383467, 'Total loss': 0.1632299708383467}
2022-12-05 19:21:52,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:52,507 INFO:     Epoch: 44
2022-12-05 19:21:53,310 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4625677557831461, 'Total loss': 0.4625677557831461} | train loss {'Reaction outcome loss': 0.158603588783235, 'Total loss': 0.158603588783235}
2022-12-05 19:21:53,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:53,310 INFO:     Epoch: 45
2022-12-05 19:21:54,118 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45879819616675377, 'Total loss': 0.45879819616675377} | train loss {'Reaction outcome loss': 0.15530132695910925, 'Total loss': 0.15530132695910925}
2022-12-05 19:21:54,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:54,119 INFO:     Epoch: 46
2022-12-05 19:21:54,921 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4697064838626168, 'Total loss': 0.4697064838626168} | train loss {'Reaction outcome loss': 0.1570417625897447, 'Total loss': 0.1570417625897447}
2022-12-05 19:21:54,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:54,921 INFO:     Epoch: 47
2022-12-05 19:21:55,713 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47479438375342975, 'Total loss': 0.47479438375342975} | train loss {'Reaction outcome loss': 0.15372554362121865, 'Total loss': 0.15372554362121865}
2022-12-05 19:21:55,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:55,713 INFO:     Epoch: 48
2022-12-05 19:21:56,509 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46808644519610837, 'Total loss': 0.46808644519610837} | train loss {'Reaction outcome loss': 0.156378149669542, 'Total loss': 0.156378149669542}
2022-12-05 19:21:56,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:56,509 INFO:     Epoch: 49
2022-12-05 19:21:57,302 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4614335129206831, 'Total loss': 0.4614335129206831} | train loss {'Reaction outcome loss': 0.1540150336302847, 'Total loss': 0.1540150336302847}
2022-12-05 19:21:57,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:57,302 INFO:     Epoch: 50
2022-12-05 19:21:58,101 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46776202270253137, 'Total loss': 0.46776202270253137} | train loss {'Reaction outcome loss': 0.15433444257689874, 'Total loss': 0.15433444257689874}
2022-12-05 19:21:58,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:58,101 INFO:     Epoch: 51
2022-12-05 19:21:58,900 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.473978297107599, 'Total loss': 0.473978297107599} | train loss {'Reaction outcome loss': 0.14917460384379003, 'Total loss': 0.14917460384379003}
2022-12-05 19:21:58,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:58,900 INFO:     Epoch: 52
2022-12-05 19:21:59,694 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47295701977881516, 'Total loss': 0.47295701977881516} | train loss {'Reaction outcome loss': 0.14843375249369908, 'Total loss': 0.14843375249369908}
2022-12-05 19:21:59,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:21:59,694 INFO:     Epoch: 53
2022-12-05 19:22:00,492 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46098247644576157, 'Total loss': 0.46098247644576157} | train loss {'Reaction outcome loss': 0.14904068559709832, 'Total loss': 0.14904068559709832}
2022-12-05 19:22:00,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:00,492 INFO:     Epoch: 54
2022-12-05 19:22:01,289 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.478124461221424, 'Total loss': 0.478124461221424} | train loss {'Reaction outcome loss': 0.14411917124188653, 'Total loss': 0.14411917124188653}
2022-12-05 19:22:01,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:01,289 INFO:     Epoch: 55
2022-12-05 19:22:02,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.467700852250511, 'Total loss': 0.467700852250511} | train loss {'Reaction outcome loss': 0.1465106356949338, 'Total loss': 0.1465106356949338}
2022-12-05 19:22:02,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:02,082 INFO:     Epoch: 56
2022-12-05 19:22:02,879 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4598860483277928, 'Total loss': 0.4598860483277928} | train loss {'Reaction outcome loss': 0.14929806099080967, 'Total loss': 0.14929806099080967}
2022-12-05 19:22:02,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:02,879 INFO:     Epoch: 57
2022-12-05 19:22:03,673 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4615812687711282, 'Total loss': 0.4615812687711282} | train loss {'Reaction outcome loss': 0.14346536712698366, 'Total loss': 0.14346536712698366}
2022-12-05 19:22:03,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:03,673 INFO:     Epoch: 58
2022-12-05 19:22:04,470 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4774413759058172, 'Total loss': 0.4774413759058172} | train loss {'Reaction outcome loss': 0.14095663677086592, 'Total loss': 0.14095663677086592}
2022-12-05 19:22:04,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:04,470 INFO:     Epoch: 59
2022-12-05 19:22:05,262 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4807642972604795, 'Total loss': 0.4807642972604795} | train loss {'Reaction outcome loss': 0.14090239657428463, 'Total loss': 0.14090239657428463}
2022-12-05 19:22:05,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:05,263 INFO:     Epoch: 60
2022-12-05 19:22:06,055 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46859879419207573, 'Total loss': 0.46859879419207573} | train loss {'Reaction outcome loss': 0.1402279368530099, 'Total loss': 0.1402279368530099}
2022-12-05 19:22:06,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:06,056 INFO:     Epoch: 61
2022-12-05 19:22:06,853 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4687783924693411, 'Total loss': 0.4687783924693411} | train loss {'Reaction outcome loss': 0.13977512347640145, 'Total loss': 0.13977512347640145}
2022-12-05 19:22:06,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:06,854 INFO:     Epoch: 62
2022-12-05 19:22:07,659 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47260176119479264, 'Total loss': 0.47260176119479264} | train loss {'Reaction outcome loss': 0.13753153882950905, 'Total loss': 0.13753153882950905}
2022-12-05 19:22:07,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:07,659 INFO:     Epoch: 63
2022-12-05 19:22:08,461 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.471714547411962, 'Total loss': 0.471714547411962} | train loss {'Reaction outcome loss': 0.1396506776663697, 'Total loss': 0.1396506776663697}
2022-12-05 19:22:08,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:08,461 INFO:     Epoch: 64
2022-12-05 19:22:09,262 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4680560976266861, 'Total loss': 0.4680560976266861} | train loss {'Reaction outcome loss': 0.13775326918644704, 'Total loss': 0.13775326918644704}
2022-12-05 19:22:09,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:09,262 INFO:     Epoch: 65
2022-12-05 19:22:10,060 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4725514535199512, 'Total loss': 0.4725514535199512} | train loss {'Reaction outcome loss': 0.13548389793965618, 'Total loss': 0.13548389793965618}
2022-12-05 19:22:10,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:10,060 INFO:     Epoch: 66
2022-12-05 19:22:10,862 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4734398350119591, 'Total loss': 0.4734398350119591} | train loss {'Reaction outcome loss': 0.1344526932774647, 'Total loss': 0.1344526932774647}
2022-12-05 19:22:10,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:10,862 INFO:     Epoch: 67
2022-12-05 19:22:11,661 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46563842418518936, 'Total loss': 0.46563842418518936} | train loss {'Reaction outcome loss': 0.13555306541593934, 'Total loss': 0.13555306541593934}
2022-12-05 19:22:11,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:11,661 INFO:     Epoch: 68
2022-12-05 19:22:12,460 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46825808489864523, 'Total loss': 0.46825808489864523} | train loss {'Reaction outcome loss': 0.1341612332006577, 'Total loss': 0.1341612332006577}
2022-12-05 19:22:12,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:12,460 INFO:     Epoch: 69
2022-12-05 19:22:13,257 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4669696326282891, 'Total loss': 0.4669696326282891} | train loss {'Reaction outcome loss': 0.13501279581119477, 'Total loss': 0.13501279581119477}
2022-12-05 19:22:13,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:13,257 INFO:     Epoch: 70
2022-12-05 19:22:14,053 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4648340561173179, 'Total loss': 0.4648340561173179} | train loss {'Reaction outcome loss': 0.13268306550498193, 'Total loss': 0.13268306550498193}
2022-12-05 19:22:14,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:14,053 INFO:     Epoch: 71
2022-12-05 19:22:14,848 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46691617284986103, 'Total loss': 0.46691617284986103} | train loss {'Reaction outcome loss': 0.1417456636665321, 'Total loss': 0.1417456636665321}
2022-12-05 19:22:14,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:14,848 INFO:     Epoch: 72
2022-12-05 19:22:15,643 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46317112852226605, 'Total loss': 0.46317112852226605} | train loss {'Reaction outcome loss': 0.13668313530473575, 'Total loss': 0.13668313530473575}
2022-12-05 19:22:15,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:15,643 INFO:     Epoch: 73
2022-12-05 19:22:16,437 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49272870272397995, 'Total loss': 0.49272870272397995} | train loss {'Reaction outcome loss': 0.12866980848675555, 'Total loss': 0.12866980848675555}
2022-12-05 19:22:16,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:16,437 INFO:     Epoch: 74
2022-12-05 19:22:17,232 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4756384322589094, 'Total loss': 0.4756384322589094} | train loss {'Reaction outcome loss': 0.12664146198813808, 'Total loss': 0.12664146198813808}
2022-12-05 19:22:17,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:17,232 INFO:     Epoch: 75
2022-12-05 19:22:18,028 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46260950748216023, 'Total loss': 0.46260950748216023} | train loss {'Reaction outcome loss': 0.12419300252639572, 'Total loss': 0.12419300252639572}
2022-12-05 19:22:18,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:18,029 INFO:     Epoch: 76
2022-12-05 19:22:18,825 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48664632507345895, 'Total loss': 0.48664632507345895} | train loss {'Reaction outcome loss': 0.12790201661301406, 'Total loss': 0.12790201661301406}
2022-12-05 19:22:18,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:18,825 INFO:     Epoch: 77
2022-12-05 19:22:19,622 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4744205837222663, 'Total loss': 0.4744205837222663} | train loss {'Reaction outcome loss': 0.12671460687872851, 'Total loss': 0.12671460687872851}
2022-12-05 19:22:19,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:19,623 INFO:     Epoch: 78
2022-12-05 19:22:20,419 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46934683654795994, 'Total loss': 0.46934683654795994} | train loss {'Reaction outcome loss': 0.12490926369994516, 'Total loss': 0.12490926369994516}
2022-12-05 19:22:20,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:20,419 INFO:     Epoch: 79
2022-12-05 19:22:21,211 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47257021052593534, 'Total loss': 0.47257021052593534} | train loss {'Reaction outcome loss': 0.12435051714360473, 'Total loss': 0.12435051714360473}
2022-12-05 19:22:21,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:21,212 INFO:     Epoch: 80
2022-12-05 19:22:22,004 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4646369974044236, 'Total loss': 0.4646369974044236} | train loss {'Reaction outcome loss': 0.12569243599178065, 'Total loss': 0.12569243599178065}
2022-12-05 19:22:22,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:22,004 INFO:     Epoch: 81
2022-12-05 19:22:22,798 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45425816862420604, 'Total loss': 0.45425816862420604} | train loss {'Reaction outcome loss': 0.12255550527319252, 'Total loss': 0.12255550527319252}
2022-12-05 19:22:22,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:22,798 INFO:     Epoch: 82
2022-12-05 19:22:23,591 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4670664652843367, 'Total loss': 0.4670664652843367} | train loss {'Reaction outcome loss': 0.1240910595350782, 'Total loss': 0.1240910595350782}
2022-12-05 19:22:23,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:23,591 INFO:     Epoch: 83
2022-12-05 19:22:24,383 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4738045421174981, 'Total loss': 0.4738045421174981} | train loss {'Reaction outcome loss': 0.12307390255800746, 'Total loss': 0.12307390255800746}
2022-12-05 19:22:24,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:24,383 INFO:     Epoch: 84
2022-12-05 19:22:25,177 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47784640707752923, 'Total loss': 0.47784640707752923} | train loss {'Reaction outcome loss': 0.12267955320958908, 'Total loss': 0.12267955320958908}
2022-12-05 19:22:25,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:25,178 INFO:     Epoch: 85
2022-12-05 19:22:25,977 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4682561538436196, 'Total loss': 0.4682561538436196} | train loss {'Reaction outcome loss': 0.12469765109571851, 'Total loss': 0.12469765109571851}
2022-12-05 19:22:25,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:25,977 INFO:     Epoch: 86
2022-12-05 19:22:26,770 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47396738454699516, 'Total loss': 0.47396738454699516} | train loss {'Reaction outcome loss': 0.13012761338368842, 'Total loss': 0.13012761338368842}
2022-12-05 19:22:26,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:26,770 INFO:     Epoch: 87
2022-12-05 19:22:27,566 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4841895012015646, 'Total loss': 0.4841895012015646} | train loss {'Reaction outcome loss': 0.12117931505416328, 'Total loss': 0.12117931505416328}
2022-12-05 19:22:27,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:27,566 INFO:     Epoch: 88
2022-12-05 19:22:28,363 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4656486636535688, 'Total loss': 0.4656486636535688} | train loss {'Reaction outcome loss': 0.12076119070322167, 'Total loss': 0.12076119070322167}
2022-12-05 19:22:28,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:28,364 INFO:     Epoch: 89
2022-12-05 19:22:29,160 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4690202996134758, 'Total loss': 0.4690202996134758} | train loss {'Reaction outcome loss': 0.12223454619482582, 'Total loss': 0.12223454619482582}
2022-12-05 19:22:29,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:29,161 INFO:     Epoch: 90
2022-12-05 19:22:29,955 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4677065153690902, 'Total loss': 0.4677065153690902} | train loss {'Reaction outcome loss': 0.12152530458427754, 'Total loss': 0.12152530458427754}
2022-12-05 19:22:29,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:29,955 INFO:     Epoch: 91
2022-12-05 19:22:30,747 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4616447426378727, 'Total loss': 0.4616447426378727} | train loss {'Reaction outcome loss': 0.12296819663889375, 'Total loss': 0.12296819663889375}
2022-12-05 19:22:30,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:30,747 INFO:     Epoch: 92
2022-12-05 19:22:31,543 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46410608071495185, 'Total loss': 0.46410608071495185} | train loss {'Reaction outcome loss': 0.12491783686736335, 'Total loss': 0.12491783686736335}
2022-12-05 19:22:31,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:31,543 INFO:     Epoch: 93
2022-12-05 19:22:32,337 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4643640850077976, 'Total loss': 0.4643640850077976} | train loss {'Reaction outcome loss': 0.118735791429093, 'Total loss': 0.118735791429093}
2022-12-05 19:22:32,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:32,337 INFO:     Epoch: 94
2022-12-05 19:22:33,130 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47695544294335623, 'Total loss': 0.47695544294335623} | train loss {'Reaction outcome loss': 0.1163482348743811, 'Total loss': 0.1163482348743811}
2022-12-05 19:22:33,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:33,130 INFO:     Epoch: 95
2022-12-05 19:22:33,922 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47267702560533176, 'Total loss': 0.47267702560533176} | train loss {'Reaction outcome loss': 0.11821471039688418, 'Total loss': 0.11821471039688418}
2022-12-05 19:22:33,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:33,922 INFO:     Epoch: 96
2022-12-05 19:22:34,715 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47787820090624417, 'Total loss': 0.47787820090624417} | train loss {'Reaction outcome loss': 0.12062758802123337, 'Total loss': 0.12062758802123337}
2022-12-05 19:22:34,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:34,715 INFO:     Epoch: 97
2022-12-05 19:22:35,508 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4684360438788479, 'Total loss': 0.4684360438788479} | train loss {'Reaction outcome loss': 0.12713253298615998, 'Total loss': 0.12713253298615998}
2022-12-05 19:22:35,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:35,508 INFO:     Epoch: 98
2022-12-05 19:22:36,299 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4596862264654853, 'Total loss': 0.4596862264654853} | train loss {'Reaction outcome loss': 0.1174146614380573, 'Total loss': 0.1174146614380573}
2022-12-05 19:22:36,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:36,300 INFO:     Epoch: 99
2022-12-05 19:22:37,101 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46688965640284796, 'Total loss': 0.46688965640284796} | train loss {'Reaction outcome loss': 0.11790818763227082, 'Total loss': 0.11790818763227082}
2022-12-05 19:22:37,102 INFO:     Best model found after epoch 17 of 100.
2022-12-05 19:22:37,102 INFO:   Done with stage: TRAINING
2022-12-05 19:22:37,102 INFO:   Starting stage: EVALUATION
2022-12-05 19:22:37,227 INFO:   Done with stage: EVALUATION
2022-12-05 19:22:37,227 INFO:   Leaving out SEQ value Fold_2
2022-12-05 19:22:37,240 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:22:37,240 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:22:37,877 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:22:37,878 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:22:37,946 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:22:37,946 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:22:37,946 INFO:     No hyperparam tuning for this model
2022-12-05 19:22:37,946 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:22:37,946 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:22:37,947 INFO:     None feature selector for col prot
2022-12-05 19:22:37,947 INFO:     None feature selector for col prot
2022-12-05 19:22:37,947 INFO:     None feature selector for col prot
2022-12-05 19:22:37,948 INFO:     None feature selector for col chem
2022-12-05 19:22:37,948 INFO:     None feature selector for col chem
2022-12-05 19:22:37,948 INFO:     None feature selector for col chem
2022-12-05 19:22:37,948 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:22:37,948 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:22:37,950 INFO:     Number of params in model 215821
2022-12-05 19:22:37,953 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:22:37,953 INFO:   Starting stage: TRAINING
2022-12-05 19:22:38,013 INFO:     Val loss before train {'Reaction outcome loss': 0.9209136109460484, 'Total loss': 0.9209136109460484}
2022-12-05 19:22:38,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:38,013 INFO:     Epoch: 0
2022-12-05 19:22:38,800 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5385646738789298, 'Total loss': 0.5385646738789298} | train loss {'Reaction outcome loss': 0.7935357178960528, 'Total loss': 0.7935357178960528}
2022-12-05 19:22:38,800 INFO:     Found new best model at epoch 0
2022-12-05 19:22:38,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:38,800 INFO:     Epoch: 1
2022-12-05 19:22:39,588 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46055652878501196, 'Total loss': 0.46055652878501196} | train loss {'Reaction outcome loss': 0.5368264252433972, 'Total loss': 0.5368264252433972}
2022-12-05 19:22:39,588 INFO:     Found new best model at epoch 1
2022-12-05 19:22:39,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:39,589 INFO:     Epoch: 2
2022-12-05 19:22:40,379 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4442078901285475, 'Total loss': 0.4442078901285475} | train loss {'Reaction outcome loss': 0.46912335449335524, 'Total loss': 0.46912335449335524}
2022-12-05 19:22:40,380 INFO:     Found new best model at epoch 2
2022-12-05 19:22:40,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:40,380 INFO:     Epoch: 3
2022-12-05 19:22:41,167 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4052023559131406, 'Total loss': 0.4052023559131406} | train loss {'Reaction outcome loss': 0.4269876078075292, 'Total loss': 0.4269876078075292}
2022-12-05 19:22:41,167 INFO:     Found new best model at epoch 3
2022-12-05 19:22:41,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:41,168 INFO:     Epoch: 4
2022-12-05 19:22:41,954 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3970063894309781, 'Total loss': 0.3970063894309781} | train loss {'Reaction outcome loss': 0.3979301022327676, 'Total loss': 0.3979301022327676}
2022-12-05 19:22:41,954 INFO:     Found new best model at epoch 4
2022-12-05 19:22:41,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:41,955 INFO:     Epoch: 5
2022-12-05 19:22:42,741 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38648218221285124, 'Total loss': 0.38648218221285124} | train loss {'Reaction outcome loss': 0.3758211828920306, 'Total loss': 0.3758211828920306}
2022-12-05 19:22:42,741 INFO:     Found new best model at epoch 5
2022-12-05 19:22:42,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:42,742 INFO:     Epoch: 6
2022-12-05 19:22:43,527 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39188306948000734, 'Total loss': 0.39188306948000734} | train loss {'Reaction outcome loss': 0.35999695196443676, 'Total loss': 0.35999695196443676}
2022-12-05 19:22:43,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:43,528 INFO:     Epoch: 7
2022-12-05 19:22:44,313 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38482195883989334, 'Total loss': 0.38482195883989334} | train loss {'Reaction outcome loss': 0.34317303874662947, 'Total loss': 0.34317303874662947}
2022-12-05 19:22:44,313 INFO:     Found new best model at epoch 7
2022-12-05 19:22:44,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:44,314 INFO:     Epoch: 8
2022-12-05 19:22:45,100 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3775147670371966, 'Total loss': 0.3775147670371966} | train loss {'Reaction outcome loss': 0.3291202348105762, 'Total loss': 0.3291202348105762}
2022-12-05 19:22:45,100 INFO:     Found new best model at epoch 8
2022-12-05 19:22:45,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:45,101 INFO:     Epoch: 9
2022-12-05 19:22:45,892 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3659655997021632, 'Total loss': 0.3659655997021632} | train loss {'Reaction outcome loss': 0.31625026038714815, 'Total loss': 0.31625026038714815}
2022-12-05 19:22:45,892 INFO:     Found new best model at epoch 9
2022-12-05 19:22:45,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:45,893 INFO:     Epoch: 10
2022-12-05 19:22:46,682 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38501178032972594, 'Total loss': 0.38501178032972594} | train loss {'Reaction outcome loss': 0.3046009722716954, 'Total loss': 0.3046009722716954}
2022-12-05 19:22:46,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:46,683 INFO:     Epoch: 11
2022-12-05 19:22:47,474 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3666741428050128, 'Total loss': 0.3666741428050128} | train loss {'Reaction outcome loss': 0.29449754783085413, 'Total loss': 0.29449754783085413}
2022-12-05 19:22:47,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:47,474 INFO:     Epoch: 12
2022-12-05 19:22:48,260 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35707392933016474, 'Total loss': 0.35707392933016474} | train loss {'Reaction outcome loss': 0.2832156776773686, 'Total loss': 0.2832156776773686}
2022-12-05 19:22:48,260 INFO:     Found new best model at epoch 12
2022-12-05 19:22:48,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:48,261 INFO:     Epoch: 13
2022-12-05 19:22:49,049 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3705119173973799, 'Total loss': 0.3705119173973799} | train loss {'Reaction outcome loss': 0.2721494101900227, 'Total loss': 0.2721494101900227}
2022-12-05 19:22:49,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:49,050 INFO:     Epoch: 14
2022-12-05 19:22:49,835 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3652990193698894, 'Total loss': 0.3652990193698894} | train loss {'Reaction outcome loss': 0.26400211684557856, 'Total loss': 0.26400211684557856}
2022-12-05 19:22:49,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:49,836 INFO:     Epoch: 15
2022-12-05 19:22:50,627 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37637616761706094, 'Total loss': 0.37637616761706094} | train loss {'Reaction outcome loss': 0.25876874342864875, 'Total loss': 0.25876874342864875}
2022-12-05 19:22:50,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:50,627 INFO:     Epoch: 16
2022-12-05 19:22:51,416 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37315897711298684, 'Total loss': 0.37315897711298684} | train loss {'Reaction outcome loss': 0.2522622076224308, 'Total loss': 0.2522622076224308}
2022-12-05 19:22:51,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:51,416 INFO:     Epoch: 17
2022-12-05 19:22:52,203 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36128743534738367, 'Total loss': 0.36128743534738367} | train loss {'Reaction outcome loss': 0.24491471417096197, 'Total loss': 0.24491471417096197}
2022-12-05 19:22:52,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:52,204 INFO:     Epoch: 18
2022-12-05 19:22:52,992 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3766514144160531, 'Total loss': 0.3766514144160531} | train loss {'Reaction outcome loss': 0.24167224164215886, 'Total loss': 0.24167224164215886}
2022-12-05 19:22:52,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:52,992 INFO:     Epoch: 19
2022-12-05 19:22:53,778 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38449225066737697, 'Total loss': 0.38449225066737697} | train loss {'Reaction outcome loss': 0.23212578284497165, 'Total loss': 0.23212578284497165}
2022-12-05 19:22:53,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:53,778 INFO:     Epoch: 20
2022-12-05 19:22:54,564 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3586236216466535, 'Total loss': 0.3586236216466535} | train loss {'Reaction outcome loss': 0.2249579095718812, 'Total loss': 0.2249579095718812}
2022-12-05 19:22:54,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:54,564 INFO:     Epoch: 21
2022-12-05 19:22:55,353 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39184187928384, 'Total loss': 0.39184187928384} | train loss {'Reaction outcome loss': 0.22453859530541362, 'Total loss': 0.22453859530541362}
2022-12-05 19:22:55,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:55,354 INFO:     Epoch: 22
2022-12-05 19:22:56,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3772921927950599, 'Total loss': 0.3772921927950599} | train loss {'Reaction outcome loss': 0.21780415714851448, 'Total loss': 0.21780415714851448}
2022-12-05 19:22:56,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:56,143 INFO:     Epoch: 23
2022-12-05 19:22:56,936 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39270678060975944, 'Total loss': 0.39270678060975944} | train loss {'Reaction outcome loss': 0.21670938444380858, 'Total loss': 0.21670938444380858}
2022-12-05 19:22:56,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:56,937 INFO:     Epoch: 24
2022-12-05 19:22:57,728 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38541502480141143, 'Total loss': 0.38541502480141143} | train loss {'Reaction outcome loss': 0.2098394053018823, 'Total loss': 0.2098394053018823}
2022-12-05 19:22:57,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:57,728 INFO:     Epoch: 25
2022-12-05 19:22:58,517 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38889375227418815, 'Total loss': 0.38889375227418815} | train loss {'Reaction outcome loss': 0.20649022093536903, 'Total loss': 0.20649022093536903}
2022-12-05 19:22:58,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:58,518 INFO:     Epoch: 26
2022-12-05 19:22:59,306 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37964300404895435, 'Total loss': 0.37964300404895435} | train loss {'Reaction outcome loss': 0.20281913391485507, 'Total loss': 0.20281913391485507}
2022-12-05 19:22:59,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:22:59,307 INFO:     Epoch: 27
2022-12-05 19:23:00,099 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3775591632689942, 'Total loss': 0.3775591632689942} | train loss {'Reaction outcome loss': 0.196722626047475, 'Total loss': 0.196722626047475}
2022-12-05 19:23:00,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:00,099 INFO:     Epoch: 28
2022-12-05 19:23:00,888 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38275379480116745, 'Total loss': 0.38275379480116745} | train loss {'Reaction outcome loss': 0.19356738651285366, 'Total loss': 0.19356738651285366}
2022-12-05 19:23:00,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:00,888 INFO:     Epoch: 29
2022-12-05 19:23:01,677 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37953470037742093, 'Total loss': 0.37953470037742093} | train loss {'Reaction outcome loss': 0.19317432790234382, 'Total loss': 0.19317432790234382}
2022-12-05 19:23:01,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:01,677 INFO:     Epoch: 30
2022-12-05 19:23:02,470 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3951220658015121, 'Total loss': 0.3951220658015121} | train loss {'Reaction outcome loss': 0.18673819457085766, 'Total loss': 0.18673819457085766}
2022-12-05 19:23:02,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:02,470 INFO:     Epoch: 31
2022-12-05 19:23:03,260 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3991672091863372, 'Total loss': 0.3991672091863372} | train loss {'Reaction outcome loss': 0.18625736768756593, 'Total loss': 0.18625736768756593}
2022-12-05 19:23:03,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:03,260 INFO:     Epoch: 32
2022-12-05 19:23:04,057 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40251454981890594, 'Total loss': 0.40251454981890594} | train loss {'Reaction outcome loss': 0.18443256022066487, 'Total loss': 0.18443256022066487}
2022-12-05 19:23:04,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:04,057 INFO:     Epoch: 33
2022-12-05 19:23:04,848 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4008623908527873, 'Total loss': 0.4008623908527873} | train loss {'Reaction outcome loss': 0.17982374449469604, 'Total loss': 0.17982374449469604}
2022-12-05 19:23:04,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:04,848 INFO:     Epoch: 34
2022-12-05 19:23:05,637 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4015398384495215, 'Total loss': 0.4015398384495215} | train loss {'Reaction outcome loss': 0.17754307532188843, 'Total loss': 0.17754307532188843}
2022-12-05 19:23:05,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:05,637 INFO:     Epoch: 35
2022-12-05 19:23:06,426 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4054562852463939, 'Total loss': 0.4054562852463939} | train loss {'Reaction outcome loss': 0.17343864919883864, 'Total loss': 0.17343864919883864}
2022-12-05 19:23:06,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:06,426 INFO:     Epoch: 36
2022-12-05 19:23:07,215 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38068264502693305, 'Total loss': 0.38068264502693305} | train loss {'Reaction outcome loss': 0.17044104692735235, 'Total loss': 0.17044104692735235}
2022-12-05 19:23:07,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:07,216 INFO:     Epoch: 37
2022-12-05 19:23:08,005 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3943003297529437, 'Total loss': 0.3943003297529437} | train loss {'Reaction outcome loss': 0.1726367817849529, 'Total loss': 0.1726367817849529}
2022-12-05 19:23:08,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:08,007 INFO:     Epoch: 38
2022-12-05 19:23:08,805 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3924782834947109, 'Total loss': 0.3924782834947109} | train loss {'Reaction outcome loss': 0.1693100977917107, 'Total loss': 0.1693100977917107}
2022-12-05 19:23:08,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:08,805 INFO:     Epoch: 39
2022-12-05 19:23:09,597 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3948763622479005, 'Total loss': 0.3948763622479005} | train loss {'Reaction outcome loss': 0.1659965500539663, 'Total loss': 0.1659965500539663}
2022-12-05 19:23:09,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:09,597 INFO:     Epoch: 40
2022-12-05 19:23:10,388 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39397968419573526, 'Total loss': 0.39397968419573526} | train loss {'Reaction outcome loss': 0.16266036210771725, 'Total loss': 0.16266036210771725}
2022-12-05 19:23:10,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:10,388 INFO:     Epoch: 41
2022-12-05 19:23:11,182 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41524393077601085, 'Total loss': 0.41524393077601085} | train loss {'Reaction outcome loss': 0.16168723016673206, 'Total loss': 0.16168723016673206}
2022-12-05 19:23:11,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:11,182 INFO:     Epoch: 42
2022-12-05 19:23:11,974 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3986357313326814, 'Total loss': 0.3986357313326814} | train loss {'Reaction outcome loss': 0.16017597191491906, 'Total loss': 0.16017597191491906}
2022-12-05 19:23:11,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:11,974 INFO:     Epoch: 43
2022-12-05 19:23:12,764 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38100756162946875, 'Total loss': 0.38100756162946875} | train loss {'Reaction outcome loss': 0.15971848570114497, 'Total loss': 0.15971848570114497}
2022-12-05 19:23:12,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:12,765 INFO:     Epoch: 44
2022-12-05 19:23:13,557 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3952335220846263, 'Total loss': 0.3952335220846263} | train loss {'Reaction outcome loss': 0.15860575905867985, 'Total loss': 0.15860575905867985}
2022-12-05 19:23:13,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:13,557 INFO:     Epoch: 45
2022-12-05 19:23:14,345 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3861611517654224, 'Total loss': 0.3861611517654224} | train loss {'Reaction outcome loss': 0.15781950821377794, 'Total loss': 0.15781950821377794}
2022-12-05 19:23:14,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:14,346 INFO:     Epoch: 46
2022-12-05 19:23:15,137 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4094690656797452, 'Total loss': 0.4094690656797452} | train loss {'Reaction outcome loss': 0.15682108502606956, 'Total loss': 0.15682108502606956}
2022-12-05 19:23:15,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:15,138 INFO:     Epoch: 47
2022-12-05 19:23:15,926 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38961597125638614, 'Total loss': 0.38961597125638614} | train loss {'Reaction outcome loss': 0.1544508060858566, 'Total loss': 0.1544508060858566}
2022-12-05 19:23:15,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:15,926 INFO:     Epoch: 48
2022-12-05 19:23:16,715 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4019785323603587, 'Total loss': 0.4019785323603587} | train loss {'Reaction outcome loss': 0.15353306476406905, 'Total loss': 0.15353306476406905}
2022-12-05 19:23:16,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:16,715 INFO:     Epoch: 49
2022-12-05 19:23:17,502 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39485184678977187, 'Total loss': 0.39485184678977187} | train loss {'Reaction outcome loss': 0.15071808398530193, 'Total loss': 0.15071808398530193}
2022-12-05 19:23:17,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:17,502 INFO:     Epoch: 50
2022-12-05 19:23:18,289 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3981242369521748, 'Total loss': 0.3981242369521748} | train loss {'Reaction outcome loss': 0.14893926246737949, 'Total loss': 0.14893926246737949}
2022-12-05 19:23:18,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:18,289 INFO:     Epoch: 51
2022-12-05 19:23:19,075 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42205372554334725, 'Total loss': 0.42205372554334725} | train loss {'Reaction outcome loss': 0.14826124539712862, 'Total loss': 0.14826124539712862}
2022-12-05 19:23:19,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:19,075 INFO:     Epoch: 52
2022-12-05 19:23:19,863 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4101015535945242, 'Total loss': 0.4101015535945242} | train loss {'Reaction outcome loss': 0.14604451735408938, 'Total loss': 0.14604451735408938}
2022-12-05 19:23:19,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:19,863 INFO:     Epoch: 53
2022-12-05 19:23:20,653 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.404711706394499, 'Total loss': 0.404711706394499} | train loss {'Reaction outcome loss': 0.14938134941823628, 'Total loss': 0.14938134941823628}
2022-12-05 19:23:20,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:20,654 INFO:     Epoch: 54
2022-12-05 19:23:21,446 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40502416562627663, 'Total loss': 0.40502416562627663} | train loss {'Reaction outcome loss': 0.14583253481862496, 'Total loss': 0.14583253481862496}
2022-12-05 19:23:21,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:21,446 INFO:     Epoch: 55
2022-12-05 19:23:22,242 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3937592438676141, 'Total loss': 0.3937592438676141} | train loss {'Reaction outcome loss': 0.146720502453343, 'Total loss': 0.146720502453343}
2022-12-05 19:23:22,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:22,242 INFO:     Epoch: 56
2022-12-05 19:23:23,042 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3993285479876001, 'Total loss': 0.3993285479876001} | train loss {'Reaction outcome loss': 0.14440198957691996, 'Total loss': 0.14440198957691996}
2022-12-05 19:23:23,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:23,042 INFO:     Epoch: 57
2022-12-05 19:23:23,835 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3875590215267783, 'Total loss': 0.3875590215267783} | train loss {'Reaction outcome loss': 0.14601446266229057, 'Total loss': 0.14601446266229057}
2022-12-05 19:23:23,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:23,835 INFO:     Epoch: 58
2022-12-05 19:23:24,627 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41372388567436824, 'Total loss': 0.41372388567436824} | train loss {'Reaction outcome loss': 0.14575647398525354, 'Total loss': 0.14575647398525354}
2022-12-05 19:23:24,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:24,627 INFO:     Epoch: 59
2022-12-05 19:23:25,421 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4013360918245532, 'Total loss': 0.4013360918245532} | train loss {'Reaction outcome loss': 0.13991937473872487, 'Total loss': 0.13991937473872487}
2022-12-05 19:23:25,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:25,421 INFO:     Epoch: 60
2022-12-05 19:23:26,213 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4021630708805539, 'Total loss': 0.4021630708805539} | train loss {'Reaction outcome loss': 0.1423219379569803, 'Total loss': 0.1423219379569803}
2022-12-05 19:23:26,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:26,214 INFO:     Epoch: 61
2022-12-05 19:23:27,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.406441926617514, 'Total loss': 0.406441926617514} | train loss {'Reaction outcome loss': 0.13948999224420713, 'Total loss': 0.13948999224420713}
2022-12-05 19:23:27,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:27,001 INFO:     Epoch: 62
2022-12-05 19:23:27,795 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3987053581936793, 'Total loss': 0.3987053581936793} | train loss {'Reaction outcome loss': 0.13873488360597772, 'Total loss': 0.13873488360597772}
2022-12-05 19:23:27,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:27,795 INFO:     Epoch: 63
2022-12-05 19:23:28,595 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3924522643739527, 'Total loss': 0.3924522643739527} | train loss {'Reaction outcome loss': 0.13972178968239804, 'Total loss': 0.13972178968239804}
2022-12-05 19:23:28,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:28,595 INFO:     Epoch: 64
2022-12-05 19:23:29,386 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40754276514053345, 'Total loss': 0.40754276514053345} | train loss {'Reaction outcome loss': 0.13914360543142776, 'Total loss': 0.13914360543142776}
2022-12-05 19:23:29,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:29,386 INFO:     Epoch: 65
2022-12-05 19:23:30,177 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41357351737943565, 'Total loss': 0.41357351737943565} | train loss {'Reaction outcome loss': 0.13904146488033692, 'Total loss': 0.13904146488033692}
2022-12-05 19:23:30,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:30,177 INFO:     Epoch: 66
2022-12-05 19:23:30,973 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42159808427095413, 'Total loss': 0.42159808427095413} | train loss {'Reaction outcome loss': 0.13745201896800072, 'Total loss': 0.13745201896800072}
2022-12-05 19:23:30,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:30,974 INFO:     Epoch: 67
2022-12-05 19:23:31,764 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41033594716678967, 'Total loss': 0.41033594716678967} | train loss {'Reaction outcome loss': 0.1376421732790008, 'Total loss': 0.1376421732790008}
2022-12-05 19:23:31,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:31,764 INFO:     Epoch: 68
2022-12-05 19:23:32,555 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40460740436207165, 'Total loss': 0.40460740436207165} | train loss {'Reaction outcome loss': 0.1361405116372875, 'Total loss': 0.1361405116372875}
2022-12-05 19:23:32,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:32,555 INFO:     Epoch: 69
2022-12-05 19:23:33,349 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4164485653693026, 'Total loss': 0.4164485653693026} | train loss {'Reaction outcome loss': 0.13530042655766011, 'Total loss': 0.13530042655766011}
2022-12-05 19:23:33,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:33,349 INFO:     Epoch: 70
2022-12-05 19:23:34,136 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4092806465923786, 'Total loss': 0.4092806465923786} | train loss {'Reaction outcome loss': 0.1369551513039944, 'Total loss': 0.1369551513039944}
2022-12-05 19:23:34,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:34,137 INFO:     Epoch: 71
2022-12-05 19:23:34,932 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40935833616690204, 'Total loss': 0.40935833616690204} | train loss {'Reaction outcome loss': 0.1335274465800244, 'Total loss': 0.1335274465800244}
2022-12-05 19:23:34,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:34,932 INFO:     Epoch: 72
2022-12-05 19:23:35,721 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4189860492267392, 'Total loss': 0.4189860492267392} | train loss {'Reaction outcome loss': 0.1354332876980913, 'Total loss': 0.1354332876980913}
2022-12-05 19:23:35,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:35,721 INFO:     Epoch: 73
2022-12-05 19:23:36,511 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40819647470859555, 'Total loss': 0.40819647470859555} | train loss {'Reaction outcome loss': 0.1338742842061483, 'Total loss': 0.1338742842061483}
2022-12-05 19:23:36,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:36,511 INFO:     Epoch: 74
2022-12-05 19:23:37,303 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41701700402931735, 'Total loss': 0.41701700402931735} | train loss {'Reaction outcome loss': 0.13590975986527545, 'Total loss': 0.13590975986527545}
2022-12-05 19:23:37,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:37,303 INFO:     Epoch: 75
2022-12-05 19:23:38,091 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3957311158407141, 'Total loss': 0.3957311158407141} | train loss {'Reaction outcome loss': 0.1304112577240686, 'Total loss': 0.1304112577240686}
2022-12-05 19:23:38,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:38,091 INFO:     Epoch: 76
2022-12-05 19:23:38,879 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3957753979008306, 'Total loss': 0.3957753979008306} | train loss {'Reaction outcome loss': 0.13209223266766995, 'Total loss': 0.13209223266766995}
2022-12-05 19:23:38,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:38,881 INFO:     Epoch: 77
2022-12-05 19:23:39,679 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4070717832920226, 'Total loss': 0.4070717832920226} | train loss {'Reaction outcome loss': 0.13035058819745876, 'Total loss': 0.13035058819745876}
2022-12-05 19:23:39,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:39,679 INFO:     Epoch: 78
2022-12-05 19:23:40,470 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4107224501838738, 'Total loss': 0.4107224501838738} | train loss {'Reaction outcome loss': 0.1356883073111578, 'Total loss': 0.1356883073111578}
2022-12-05 19:23:40,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:40,470 INFO:     Epoch: 79
2022-12-05 19:23:41,260 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4142307879572565, 'Total loss': 0.4142307879572565} | train loss {'Reaction outcome loss': 0.13202668214026764, 'Total loss': 0.13202668214026764}
2022-12-05 19:23:41,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:41,260 INFO:     Epoch: 80
2022-12-05 19:23:42,049 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4010869379747998, 'Total loss': 0.4010869379747998} | train loss {'Reaction outcome loss': 0.12870042030224388, 'Total loss': 0.12870042030224388}
2022-12-05 19:23:42,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:42,049 INFO:     Epoch: 81
2022-12-05 19:23:42,839 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4140641641887752, 'Total loss': 0.4140641641887752} | train loss {'Reaction outcome loss': 0.13261971834818928, 'Total loss': 0.13261971834818928}
2022-12-05 19:23:42,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:42,839 INFO:     Epoch: 82
2022-12-05 19:23:43,630 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4161920059810985, 'Total loss': 0.4161920059810985} | train loss {'Reaction outcome loss': 0.1288294464197694, 'Total loss': 0.1288294464197694}
2022-12-05 19:23:43,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:43,630 INFO:     Epoch: 83
2022-12-05 19:23:44,421 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4221715009347959, 'Total loss': 0.4221715009347959} | train loss {'Reaction outcome loss': 0.12960149703585372, 'Total loss': 0.12960149703585372}
2022-12-05 19:23:44,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:44,421 INFO:     Epoch: 84
2022-12-05 19:23:45,213 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41377031786197965, 'Total loss': 0.41377031786197965} | train loss {'Reaction outcome loss': 0.13016508713516653, 'Total loss': 0.13016508713516653}
2022-12-05 19:23:45,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:45,214 INFO:     Epoch: 85
2022-12-05 19:23:46,001 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4192653259431774, 'Total loss': 0.4192653259431774} | train loss {'Reaction outcome loss': 0.13026044697177652, 'Total loss': 0.13026044697177652}
2022-12-05 19:23:46,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:46,001 INFO:     Epoch: 86
2022-12-05 19:23:46,788 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43291202720931987, 'Total loss': 0.43291202720931987} | train loss {'Reaction outcome loss': 0.1307513440255912, 'Total loss': 0.1307513440255912}
2022-12-05 19:23:46,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:46,788 INFO:     Epoch: 87
2022-12-05 19:23:47,574 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3975184569981965, 'Total loss': 0.3975184569981965} | train loss {'Reaction outcome loss': 0.1300763816705772, 'Total loss': 0.1300763816705772}
2022-12-05 19:23:47,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:47,574 INFO:     Epoch: 88
2022-12-05 19:23:48,361 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40316128595308826, 'Total loss': 0.40316128595308826} | train loss {'Reaction outcome loss': 0.128640070397939, 'Total loss': 0.128640070397939}
2022-12-05 19:23:48,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:48,361 INFO:     Epoch: 89
2022-12-05 19:23:49,151 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4096551151438193, 'Total loss': 0.4096551151438193} | train loss {'Reaction outcome loss': 0.1293673703732083, 'Total loss': 0.1293673703732083}
2022-12-05 19:23:49,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:49,151 INFO:     Epoch: 90
2022-12-05 19:23:49,941 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4043812237002633, 'Total loss': 0.4043812237002633} | train loss {'Reaction outcome loss': 0.12518259357965114, 'Total loss': 0.12518259357965114}
2022-12-05 19:23:49,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:49,941 INFO:     Epoch: 91
2022-12-05 19:23:50,728 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39785119772634725, 'Total loss': 0.39785119772634725} | train loss {'Reaction outcome loss': 0.12690803696192346, 'Total loss': 0.12690803696192346}
2022-12-05 19:23:50,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:50,728 INFO:     Epoch: 92
2022-12-05 19:23:51,514 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4255474771965634, 'Total loss': 0.4255474771965634} | train loss {'Reaction outcome loss': 0.1286915640669818, 'Total loss': 0.1286915640669818}
2022-12-05 19:23:51,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:51,515 INFO:     Epoch: 93
2022-12-05 19:23:52,302 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41076538034460763, 'Total loss': 0.41076538034460763} | train loss {'Reaction outcome loss': 0.12694223264650423, 'Total loss': 0.12694223264650423}
2022-12-05 19:23:52,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:52,302 INFO:     Epoch: 94
2022-12-05 19:23:53,090 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40262438831004227, 'Total loss': 0.40262438831004227} | train loss {'Reaction outcome loss': 0.12709685112824853, 'Total loss': 0.12709685112824853}
2022-12-05 19:23:53,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:53,090 INFO:     Epoch: 95
2022-12-05 19:23:53,881 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41090389036319475, 'Total loss': 0.41090389036319475} | train loss {'Reaction outcome loss': 0.12775247785053692, 'Total loss': 0.12775247785053692}
2022-12-05 19:23:53,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:53,881 INFO:     Epoch: 96
2022-12-05 19:23:54,668 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4131761007010937, 'Total loss': 0.4131761007010937} | train loss {'Reaction outcome loss': 0.12591037344263525, 'Total loss': 0.12591037344263525}
2022-12-05 19:23:54,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:54,669 INFO:     Epoch: 97
2022-12-05 19:23:55,455 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40876718102531, 'Total loss': 0.40876718102531} | train loss {'Reaction outcome loss': 0.12519389818213425, 'Total loss': 0.12519389818213425}
2022-12-05 19:23:55,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:55,456 INFO:     Epoch: 98
2022-12-05 19:23:56,242 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40476328134536743, 'Total loss': 0.40476328134536743} | train loss {'Reaction outcome loss': 0.12603958821570388, 'Total loss': 0.12603958821570388}
2022-12-05 19:23:56,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:56,242 INFO:     Epoch: 99
2022-12-05 19:23:57,029 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38936924866654654, 'Total loss': 0.38936924866654654} | train loss {'Reaction outcome loss': 0.12348540594459188, 'Total loss': 0.12348540594459188}
2022-12-05 19:23:57,029 INFO:     Best model found after epoch 13 of 100.
2022-12-05 19:23:57,029 INFO:   Done with stage: TRAINING
2022-12-05 19:23:57,029 INFO:   Starting stage: EVALUATION
2022-12-05 19:23:57,161 INFO:   Done with stage: EVALUATION
2022-12-05 19:23:57,161 INFO:   Leaving out SEQ value Fold_3
2022-12-05 19:23:57,174 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:23:57,174 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:23:57,819 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:23:57,820 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:23:57,888 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:23:57,888 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:23:57,888 INFO:     No hyperparam tuning for this model
2022-12-05 19:23:57,888 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:23:57,888 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:23:57,889 INFO:     None feature selector for col prot
2022-12-05 19:23:57,889 INFO:     None feature selector for col prot
2022-12-05 19:23:57,889 INFO:     None feature selector for col prot
2022-12-05 19:23:57,890 INFO:     None feature selector for col chem
2022-12-05 19:23:57,890 INFO:     None feature selector for col chem
2022-12-05 19:23:57,890 INFO:     None feature selector for col chem
2022-12-05 19:23:57,890 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:23:57,890 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:23:57,892 INFO:     Number of params in model 215821
2022-12-05 19:23:57,895 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:23:57,895 INFO:   Starting stage: TRAINING
2022-12-05 19:23:57,955 INFO:     Val loss before train {'Reaction outcome loss': 0.9649179022420536, 'Total loss': 0.9649179022420536}
2022-12-05 19:23:57,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:57,955 INFO:     Epoch: 0
2022-12-05 19:23:58,741 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.586408260193738, 'Total loss': 0.586408260193738} | train loss {'Reaction outcome loss': 0.8003248899566884, 'Total loss': 0.8003248899566884}
2022-12-05 19:23:58,742 INFO:     Found new best model at epoch 0
2022-12-05 19:23:58,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:58,743 INFO:     Epoch: 1
2022-12-05 19:23:59,531 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5276282849636945, 'Total loss': 0.5276282849636945} | train loss {'Reaction outcome loss': 0.5465716635086099, 'Total loss': 0.5465716635086099}
2022-12-05 19:23:59,532 INFO:     Found new best model at epoch 1
2022-12-05 19:23:59,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:23:59,532 INFO:     Epoch: 2
2022-12-05 19:24:00,322 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48198883777314966, 'Total loss': 0.48198883777314966} | train loss {'Reaction outcome loss': 0.4782364909137998, 'Total loss': 0.4782364909137998}
2022-12-05 19:24:00,322 INFO:     Found new best model at epoch 2
2022-12-05 19:24:00,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:00,323 INFO:     Epoch: 3
2022-12-05 19:24:01,113 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.456619443371892, 'Total loss': 0.456619443371892} | train loss {'Reaction outcome loss': 0.440311734956138, 'Total loss': 0.440311734956138}
2022-12-05 19:24:01,113 INFO:     Found new best model at epoch 3
2022-12-05 19:24:01,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:01,114 INFO:     Epoch: 4
2022-12-05 19:24:01,903 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.438262361694466, 'Total loss': 0.438262361694466} | train loss {'Reaction outcome loss': 0.40980299212494675, 'Total loss': 0.40980299212494675}
2022-12-05 19:24:01,903 INFO:     Found new best model at epoch 4
2022-12-05 19:24:01,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:01,904 INFO:     Epoch: 5
2022-12-05 19:24:02,697 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4334406334568154, 'Total loss': 0.4334406334568154} | train loss {'Reaction outcome loss': 0.3885707154565928, 'Total loss': 0.3885707154565928}
2022-12-05 19:24:02,698 INFO:     Found new best model at epoch 5
2022-12-05 19:24:02,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:02,699 INFO:     Epoch: 6
2022-12-05 19:24:03,485 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4228766130452806, 'Total loss': 0.4228766130452806} | train loss {'Reaction outcome loss': 0.3687057526744142, 'Total loss': 0.3687057526744142}
2022-12-05 19:24:03,485 INFO:     Found new best model at epoch 6
2022-12-05 19:24:03,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:03,486 INFO:     Epoch: 7
2022-12-05 19:24:04,264 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4309253496202556, 'Total loss': 0.4309253496202556} | train loss {'Reaction outcome loss': 0.3517889668442765, 'Total loss': 0.3517889668442765}
2022-12-05 19:24:04,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:04,264 INFO:     Epoch: 8
2022-12-05 19:24:05,042 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.413155137476596, 'Total loss': 0.413155137476596} | train loss {'Reaction outcome loss': 0.3364973690436811, 'Total loss': 0.3364973690436811}
2022-12-05 19:24:05,042 INFO:     Found new best model at epoch 8
2022-12-05 19:24:05,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:05,043 INFO:     Epoch: 9
2022-12-05 19:24:05,827 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41488238830458035, 'Total loss': 0.41488238830458035} | train loss {'Reaction outcome loss': 0.32462813039215244, 'Total loss': 0.32462813039215244}
2022-12-05 19:24:05,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:05,827 INFO:     Epoch: 10
2022-12-05 19:24:06,607 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41081496713344345, 'Total loss': 0.41081496713344345} | train loss {'Reaction outcome loss': 0.31134207847775247, 'Total loss': 0.31134207847775247}
2022-12-05 19:24:06,607 INFO:     Found new best model at epoch 10
2022-12-05 19:24:06,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:06,608 INFO:     Epoch: 11
2022-12-05 19:24:07,389 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.416232535446232, 'Total loss': 0.416232535446232} | train loss {'Reaction outcome loss': 0.2992251035206172, 'Total loss': 0.2992251035206172}
2022-12-05 19:24:07,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:07,389 INFO:     Epoch: 12
2022-12-05 19:24:08,166 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4226143895225091, 'Total loss': 0.4226143895225091} | train loss {'Reaction outcome loss': 0.2897106015256473, 'Total loss': 0.2897106015256473}
2022-12-05 19:24:08,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:08,167 INFO:     Epoch: 13
2022-12-05 19:24:08,948 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4028878604823893, 'Total loss': 0.4028878604823893} | train loss {'Reaction outcome loss': 0.27888263083842335, 'Total loss': 0.27888263083842335}
2022-12-05 19:24:08,949 INFO:     Found new best model at epoch 13
2022-12-05 19:24:08,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:08,949 INFO:     Epoch: 14
2022-12-05 19:24:09,735 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40522292019291356, 'Total loss': 0.40522292019291356} | train loss {'Reaction outcome loss': 0.27210048301791656, 'Total loss': 0.27210048301791656}
2022-12-05 19:24:09,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:09,736 INFO:     Epoch: 15
2022-12-05 19:24:10,522 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4238645136356354, 'Total loss': 0.4238645136356354} | train loss {'Reaction outcome loss': 0.26101157680457954, 'Total loss': 0.26101157680457954}
2022-12-05 19:24:10,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:10,522 INFO:     Epoch: 16
2022-12-05 19:24:11,303 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4257927100089463, 'Total loss': 0.4257927100089463} | train loss {'Reaction outcome loss': 0.25527400115923005, 'Total loss': 0.25527400115923005}
2022-12-05 19:24:11,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:11,304 INFO:     Epoch: 17
2022-12-05 19:24:12,082 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42358402349054813, 'Total loss': 0.42358402349054813} | train loss {'Reaction outcome loss': 0.2456112207502735, 'Total loss': 0.2456112207502735}
2022-12-05 19:24:12,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:12,083 INFO:     Epoch: 18
2022-12-05 19:24:12,861 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43537885560230777, 'Total loss': 0.43537885560230777} | train loss {'Reaction outcome loss': 0.24080023507074433, 'Total loss': 0.24080023507074433}
2022-12-05 19:24:12,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:12,861 INFO:     Epoch: 19
2022-12-05 19:24:13,642 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4177721637216481, 'Total loss': 0.4177721637216481} | train loss {'Reaction outcome loss': 0.2340916034518456, 'Total loss': 0.2340916034518456}
2022-12-05 19:24:13,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:13,643 INFO:     Epoch: 20
2022-12-05 19:24:14,420 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4182095419700173, 'Total loss': 0.4182095419700173} | train loss {'Reaction outcome loss': 0.22879694420464186, 'Total loss': 0.22879694420464186}
2022-12-05 19:24:14,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:14,421 INFO:     Epoch: 21
2022-12-05 19:24:15,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4161427261477167, 'Total loss': 0.4161427261477167} | train loss {'Reaction outcome loss': 0.22287424577742207, 'Total loss': 0.22287424577742207}
2022-12-05 19:24:15,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:15,202 INFO:     Epoch: 22
2022-12-05 19:24:15,985 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42181599749760196, 'Total loss': 0.42181599749760196} | train loss {'Reaction outcome loss': 0.21747121480958803, 'Total loss': 0.21747121480958803}
2022-12-05 19:24:15,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:15,986 INFO:     Epoch: 23
2022-12-05 19:24:16,764 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4121863344176249, 'Total loss': 0.4121863344176249} | train loss {'Reaction outcome loss': 0.21378182963449127, 'Total loss': 0.21378182963449127}
2022-12-05 19:24:16,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:16,765 INFO:     Epoch: 24
2022-12-05 19:24:17,542 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4135933494703336, 'Total loss': 0.4135933494703336} | train loss {'Reaction outcome loss': 0.20860837063923174, 'Total loss': 0.20860837063923174}
2022-12-05 19:24:17,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:17,543 INFO:     Epoch: 25
2022-12-05 19:24:18,320 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43689316155558283, 'Total loss': 0.43689316155558283} | train loss {'Reaction outcome loss': 0.20278731254594667, 'Total loss': 0.20278731254594667}
2022-12-05 19:24:18,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:18,320 INFO:     Epoch: 26
2022-12-05 19:24:19,098 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42458744313229213, 'Total loss': 0.42458744313229213} | train loss {'Reaction outcome loss': 0.2014958265940754, 'Total loss': 0.2014958265940754}
2022-12-05 19:24:19,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:19,098 INFO:     Epoch: 27
2022-12-05 19:24:19,877 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44932869991118257, 'Total loss': 0.44932869991118257} | train loss {'Reaction outcome loss': 0.19680514127320173, 'Total loss': 0.19680514127320173}
2022-12-05 19:24:19,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:19,877 INFO:     Epoch: 28
2022-12-05 19:24:20,660 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41907439448616723, 'Total loss': 0.41907439448616723} | train loss {'Reaction outcome loss': 0.19316783620386707, 'Total loss': 0.19316783620386707}
2022-12-05 19:24:20,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:20,660 INFO:     Epoch: 29
2022-12-05 19:24:21,439 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4421155754138123, 'Total loss': 0.4421155754138123} | train loss {'Reaction outcome loss': 0.1904030616414182, 'Total loss': 0.1904030616414182}
2022-12-05 19:24:21,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:21,439 INFO:     Epoch: 30
2022-12-05 19:24:22,220 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4183828437870199, 'Total loss': 0.4183828437870199} | train loss {'Reaction outcome loss': 0.1872949131289307, 'Total loss': 0.1872949131289307}
2022-12-05 19:24:22,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:22,220 INFO:     Epoch: 31
2022-12-05 19:24:23,000 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42626832357861777, 'Total loss': 0.42626832357861777} | train loss {'Reaction outcome loss': 0.18441285741876584, 'Total loss': 0.18441285741876584}
2022-12-05 19:24:23,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:23,000 INFO:     Epoch: 32
2022-12-05 19:24:23,782 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42656982825561, 'Total loss': 0.42656982825561} | train loss {'Reaction outcome loss': 0.17956965916923115, 'Total loss': 0.17956965916923115}
2022-12-05 19:24:23,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:23,782 INFO:     Epoch: 33
2022-12-05 19:24:24,559 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44901353594931687, 'Total loss': 0.44901353594931687} | train loss {'Reaction outcome loss': 0.1776689566823901, 'Total loss': 0.1776689566823901}
2022-12-05 19:24:24,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:24,560 INFO:     Epoch: 34
2022-12-05 19:24:25,338 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4418684660711072, 'Total loss': 0.4418684660711072} | train loss {'Reaction outcome loss': 0.17552176480542642, 'Total loss': 0.17552176480542642}
2022-12-05 19:24:25,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:25,339 INFO:     Epoch: 35
2022-12-05 19:24:26,119 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4377459724518386, 'Total loss': 0.4377459724518386} | train loss {'Reaction outcome loss': 0.17233947875852487, 'Total loss': 0.17233947875852487}
2022-12-05 19:24:26,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:26,119 INFO:     Epoch: 36
2022-12-05 19:24:26,897 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4289395465430888, 'Total loss': 0.4289395465430888} | train loss {'Reaction outcome loss': 0.17020662533385414, 'Total loss': 0.17020662533385414}
2022-12-05 19:24:26,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:26,897 INFO:     Epoch: 37
2022-12-05 19:24:27,679 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44814309545538644, 'Total loss': 0.44814309545538644} | train loss {'Reaction outcome loss': 0.16799910350569658, 'Total loss': 0.16799910350569658}
2022-12-05 19:24:27,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:27,679 INFO:     Epoch: 38
2022-12-05 19:24:28,458 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44960354708812456, 'Total loss': 0.44960354708812456} | train loss {'Reaction outcome loss': 0.1703069487472578, 'Total loss': 0.1703069487472578}
2022-12-05 19:24:28,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:28,459 INFO:     Epoch: 39
2022-12-05 19:24:29,237 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4612637771801515, 'Total loss': 0.4612637771801515} | train loss {'Reaction outcome loss': 0.16459489917116507, 'Total loss': 0.16459489917116507}
2022-12-05 19:24:29,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:29,237 INFO:     Epoch: 40
2022-12-05 19:24:30,022 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4476157453927127, 'Total loss': 0.4476157453927127} | train loss {'Reaction outcome loss': 0.16346270252703404, 'Total loss': 0.16346270252703404}
2022-12-05 19:24:30,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:30,022 INFO:     Epoch: 41
2022-12-05 19:24:30,801 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43249472891065205, 'Total loss': 0.43249472891065205} | train loss {'Reaction outcome loss': 0.15925951542294756, 'Total loss': 0.15925951542294756}
2022-12-05 19:24:30,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:30,802 INFO:     Epoch: 42
2022-12-05 19:24:31,582 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4461986483498053, 'Total loss': 0.4461986483498053} | train loss {'Reaction outcome loss': 0.1607201786711812, 'Total loss': 0.1607201786711812}
2022-12-05 19:24:31,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:31,582 INFO:     Epoch: 43
2022-12-05 19:24:32,364 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45532105287367647, 'Total loss': 0.45532105287367647} | train loss {'Reaction outcome loss': 0.15559409333735097, 'Total loss': 0.15559409333735097}
2022-12-05 19:24:32,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:32,364 INFO:     Epoch: 44
2022-12-05 19:24:33,142 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4340057124526621, 'Total loss': 0.4340057124526621} | train loss {'Reaction outcome loss': 0.1545496158453883, 'Total loss': 0.1545496158453883}
2022-12-05 19:24:33,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:33,142 INFO:     Epoch: 45
2022-12-05 19:24:33,921 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44268146716058254, 'Total loss': 0.44268146716058254} | train loss {'Reaction outcome loss': 0.15395257418252983, 'Total loss': 0.15395257418252983}
2022-12-05 19:24:33,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:33,921 INFO:     Epoch: 46
2022-12-05 19:24:34,705 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46278220279650256, 'Total loss': 0.46278220279650256} | train loss {'Reaction outcome loss': 0.1507169807823945, 'Total loss': 0.1507169807823945}
2022-12-05 19:24:34,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:34,706 INFO:     Epoch: 47
2022-12-05 19:24:35,484 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.453375788574869, 'Total loss': 0.453375788574869} | train loss {'Reaction outcome loss': 0.15055199441861133, 'Total loss': 0.15055199441861133}
2022-12-05 19:24:35,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:35,484 INFO:     Epoch: 48
2022-12-05 19:24:36,265 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43775474703447387, 'Total loss': 0.43775474703447387} | train loss {'Reaction outcome loss': 0.14834974313116803, 'Total loss': 0.14834974313116803}
2022-12-05 19:24:36,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:36,266 INFO:     Epoch: 49
2022-12-05 19:24:37,050 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4531381966715509, 'Total loss': 0.4531381966715509} | train loss {'Reaction outcome loss': 0.1481065185968669, 'Total loss': 0.1481065185968669}
2022-12-05 19:24:37,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:37,050 INFO:     Epoch: 50
2022-12-05 19:24:37,833 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45333616537126625, 'Total loss': 0.45333616537126625} | train loss {'Reaction outcome loss': 0.14730453485508962, 'Total loss': 0.14730453485508962}
2022-12-05 19:24:37,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:37,834 INFO:     Epoch: 51
2022-12-05 19:24:38,616 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4396215755153786, 'Total loss': 0.4396215755153786} | train loss {'Reaction outcome loss': 0.1439358513118053, 'Total loss': 0.1439358513118053}
2022-12-05 19:24:38,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:38,617 INFO:     Epoch: 52
2022-12-05 19:24:39,398 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4317161169919101, 'Total loss': 0.4317161169919101} | train loss {'Reaction outcome loss': 0.14493506264929867, 'Total loss': 0.14493506264929867}
2022-12-05 19:24:39,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:39,398 INFO:     Epoch: 53
2022-12-05 19:24:40,183 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4572386196391149, 'Total loss': 0.4572386196391149} | train loss {'Reaction outcome loss': 0.1417124966197476, 'Total loss': 0.1417124966197476}
2022-12-05 19:24:40,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:40,183 INFO:     Epoch: 54
2022-12-05 19:24:40,963 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4540991817008365, 'Total loss': 0.4540991817008365} | train loss {'Reaction outcome loss': 0.14157460205713096, 'Total loss': 0.14157460205713096}
2022-12-05 19:24:40,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:40,965 INFO:     Epoch: 55
2022-12-05 19:24:41,747 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4341151939535683, 'Total loss': 0.4341151939535683} | train loss {'Reaction outcome loss': 0.1443599598900396, 'Total loss': 0.1443599598900396}
2022-12-05 19:24:41,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:41,747 INFO:     Epoch: 56
2022-12-05 19:24:42,526 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.446342145177451, 'Total loss': 0.446342145177451} | train loss {'Reaction outcome loss': 0.13846409111378752, 'Total loss': 0.13846409111378752}
2022-12-05 19:24:42,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:42,527 INFO:     Epoch: 57
2022-12-05 19:24:43,311 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43578584559939126, 'Total loss': 0.43578584559939126} | train loss {'Reaction outcome loss': 0.1372689979302944, 'Total loss': 0.1372689979302944}
2022-12-05 19:24:43,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:43,311 INFO:     Epoch: 58
2022-12-05 19:24:44,091 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45383398167111655, 'Total loss': 0.45383398167111655} | train loss {'Reaction outcome loss': 0.13944845769782455, 'Total loss': 0.13944845769782455}
2022-12-05 19:24:44,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:44,091 INFO:     Epoch: 59
2022-12-05 19:24:44,869 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4436733434823426, 'Total loss': 0.4436733434823426} | train loss {'Reaction outcome loss': 0.13791143982386103, 'Total loss': 0.13791143982386103}
2022-12-05 19:24:44,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:44,870 INFO:     Epoch: 60
2022-12-05 19:24:45,655 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4374990214339711, 'Total loss': 0.4374990214339711} | train loss {'Reaction outcome loss': 0.1377946539173777, 'Total loss': 0.1377946539173777}
2022-12-05 19:24:45,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:45,655 INFO:     Epoch: 61
2022-12-05 19:24:46,437 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44699043746698985, 'Total loss': 0.44699043746698985} | train loss {'Reaction outcome loss': 0.138606525364579, 'Total loss': 0.138606525364579}
2022-12-05 19:24:46,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:46,438 INFO:     Epoch: 62
2022-12-05 19:24:47,221 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4484040681272745, 'Total loss': 0.4484040681272745} | train loss {'Reaction outcome loss': 0.13568371662071774, 'Total loss': 0.13568371662071774}
2022-12-05 19:24:47,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:47,222 INFO:     Epoch: 63
2022-12-05 19:24:48,002 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4346970620926269, 'Total loss': 0.4346970620926269} | train loss {'Reaction outcome loss': 0.13453602989261249, 'Total loss': 0.13453602989261249}
2022-12-05 19:24:48,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:48,003 INFO:     Epoch: 64
2022-12-05 19:24:48,782 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45186105370521545, 'Total loss': 0.45186105370521545} | train loss {'Reaction outcome loss': 0.13198919920440838, 'Total loss': 0.13198919920440838}
2022-12-05 19:24:48,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:48,782 INFO:     Epoch: 65
2022-12-05 19:24:49,565 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4404453587802974, 'Total loss': 0.4404453587802974} | train loss {'Reaction outcome loss': 0.13111312942085218, 'Total loss': 0.13111312942085218}
2022-12-05 19:24:49,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:49,565 INFO:     Epoch: 66
2022-12-05 19:24:50,349 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4462368999692527, 'Total loss': 0.4462368999692527} | train loss {'Reaction outcome loss': 0.13195409905545566, 'Total loss': 0.13195409905545566}
2022-12-05 19:24:50,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:50,350 INFO:     Epoch: 67
2022-12-05 19:24:51,139 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4443378226662224, 'Total loss': 0.4443378226662224} | train loss {'Reaction outcome loss': 0.12941208200491205, 'Total loss': 0.12941208200491205}
2022-12-05 19:24:51,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:51,139 INFO:     Epoch: 68
2022-12-05 19:24:51,923 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42869493399154057, 'Total loss': 0.42869493399154057} | train loss {'Reaction outcome loss': 0.13072222608844844, 'Total loss': 0.13072222608844844}
2022-12-05 19:24:51,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:51,924 INFO:     Epoch: 69
2022-12-05 19:24:52,709 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4722273420881141, 'Total loss': 0.4722273420881141} | train loss {'Reaction outcome loss': 0.13300768467692697, 'Total loss': 0.13300768467692697}
2022-12-05 19:24:52,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:52,709 INFO:     Epoch: 70
2022-12-05 19:24:53,495 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4382745234549723, 'Total loss': 0.4382745234549723} | train loss {'Reaction outcome loss': 0.12989346243593158, 'Total loss': 0.12989346243593158}
2022-12-05 19:24:53,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:53,495 INFO:     Epoch: 71
2022-12-05 19:24:54,279 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4469909911805933, 'Total loss': 0.4469909911805933} | train loss {'Reaction outcome loss': 0.13142925778365866, 'Total loss': 0.13142925778365866}
2022-12-05 19:24:54,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:54,279 INFO:     Epoch: 72
2022-12-05 19:24:55,063 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4454650321806019, 'Total loss': 0.4454650321806019} | train loss {'Reaction outcome loss': 0.12937296720563757, 'Total loss': 0.12937296720563757}
2022-12-05 19:24:55,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:55,064 INFO:     Epoch: 73
2022-12-05 19:24:55,847 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44446950778365135, 'Total loss': 0.44446950778365135} | train loss {'Reaction outcome loss': 0.13287030590356005, 'Total loss': 0.13287030590356005}
2022-12-05 19:24:55,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:55,847 INFO:     Epoch: 74
2022-12-05 19:24:56,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4529286805878986, 'Total loss': 0.4529286805878986} | train loss {'Reaction outcome loss': 0.1282905472518534, 'Total loss': 0.1282905472518534}
2022-12-05 19:24:56,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:56,631 INFO:     Epoch: 75
2022-12-05 19:24:57,413 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4321962049738927, 'Total loss': 0.4321962049738927} | train loss {'Reaction outcome loss': 0.13105315112185723, 'Total loss': 0.13105315112185723}
2022-12-05 19:24:57,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:57,413 INFO:     Epoch: 76
2022-12-05 19:24:58,201 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4437034641477195, 'Total loss': 0.4437034641477195} | train loss {'Reaction outcome loss': 0.12501233525346128, 'Total loss': 0.12501233525346128}
2022-12-05 19:24:58,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:58,201 INFO:     Epoch: 77
2022-12-05 19:24:58,983 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45998869971795514, 'Total loss': 0.45998869971795514} | train loss {'Reaction outcome loss': 0.12640445331985853, 'Total loss': 0.12640445331985853}
2022-12-05 19:24:58,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:58,984 INFO:     Epoch: 78
2022-12-05 19:24:59,769 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46159768832678144, 'Total loss': 0.46159768832678144} | train loss {'Reaction outcome loss': 0.12440246131499202, 'Total loss': 0.12440246131499202}
2022-12-05 19:24:59,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:24:59,770 INFO:     Epoch: 79
2022-12-05 19:25:00,556 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4470950588583946, 'Total loss': 0.4470950588583946} | train loss {'Reaction outcome loss': 0.12786002838794067, 'Total loss': 0.12786002838794067}
2022-12-05 19:25:00,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:00,556 INFO:     Epoch: 80
2022-12-05 19:25:01,345 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4385184066539461, 'Total loss': 0.4385184066539461} | train loss {'Reaction outcome loss': 0.12444491549870189, 'Total loss': 0.12444491549870189}
2022-12-05 19:25:01,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:01,345 INFO:     Epoch: 81
2022-12-05 19:25:02,129 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44382823461836035, 'Total loss': 0.44382823461836035} | train loss {'Reaction outcome loss': 0.12497831830488784, 'Total loss': 0.12497831830488784}
2022-12-05 19:25:02,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:02,129 INFO:     Epoch: 82
2022-12-05 19:25:02,912 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4486834755675359, 'Total loss': 0.4486834755675359} | train loss {'Reaction outcome loss': 0.12559823099979942, 'Total loss': 0.12559823099979942}
2022-12-05 19:25:02,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:02,912 INFO:     Epoch: 83
2022-12-05 19:25:03,696 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44492258165370335, 'Total loss': 0.44492258165370335} | train loss {'Reaction outcome loss': 0.1257460476412457, 'Total loss': 0.1257460476412457}
2022-12-05 19:25:03,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:03,696 INFO:     Epoch: 84
2022-12-05 19:25:04,482 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45473883571949875, 'Total loss': 0.45473883571949875} | train loss {'Reaction outcome loss': 0.1231098574301114, 'Total loss': 0.1231098574301114}
2022-12-05 19:25:04,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:04,482 INFO:     Epoch: 85
2022-12-05 19:25:05,267 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44927503710443323, 'Total loss': 0.44927503710443323} | train loss {'Reaction outcome loss': 0.1242475842068694, 'Total loss': 0.1242475842068694}
2022-12-05 19:25:05,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:05,267 INFO:     Epoch: 86
2022-12-05 19:25:06,048 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4564825465733355, 'Total loss': 0.4564825465733355} | train loss {'Reaction outcome loss': 0.12417146373084005, 'Total loss': 0.12417146373084005}
2022-12-05 19:25:06,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:06,048 INFO:     Epoch: 87
2022-12-05 19:25:06,830 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44076619432731107, 'Total loss': 0.44076619432731107} | train loss {'Reaction outcome loss': 0.12108968173210718, 'Total loss': 0.12108968173210718}
2022-12-05 19:25:06,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:06,830 INFO:     Epoch: 88
2022-12-05 19:25:07,611 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4517122876237739, 'Total loss': 0.4517122876237739} | train loss {'Reaction outcome loss': 0.12267334910527784, 'Total loss': 0.12267334910527784}
2022-12-05 19:25:07,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:07,612 INFO:     Epoch: 89
2022-12-05 19:25:08,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.441238421946764, 'Total loss': 0.441238421946764} | train loss {'Reaction outcome loss': 0.1203112539113024, 'Total loss': 0.1203112539113024}
2022-12-05 19:25:08,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:08,393 INFO:     Epoch: 90
2022-12-05 19:25:09,175 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4633392681452361, 'Total loss': 0.4633392681452361} | train loss {'Reaction outcome loss': 0.12249797149276247, 'Total loss': 0.12249797149276247}
2022-12-05 19:25:09,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:09,175 INFO:     Epoch: 91
2022-12-05 19:25:09,956 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43698100694878533, 'Total loss': 0.43698100694878533} | train loss {'Reaction outcome loss': 0.12146685793805792, 'Total loss': 0.12146685793805792}
2022-12-05 19:25:09,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:09,956 INFO:     Epoch: 92
2022-12-05 19:25:10,742 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43528019586070016, 'Total loss': 0.43528019586070016} | train loss {'Reaction outcome loss': 0.12106145698653192, 'Total loss': 0.12106145698653192}
2022-12-05 19:25:10,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:10,742 INFO:     Epoch: 93
2022-12-05 19:25:11,531 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43701399574902927, 'Total loss': 0.43701399574902927} | train loss {'Reaction outcome loss': 0.12017687027133545, 'Total loss': 0.12017687027133545}
2022-12-05 19:25:11,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:11,532 INFO:     Epoch: 94
2022-12-05 19:25:12,320 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4820618060502139, 'Total loss': 0.4820618060502139} | train loss {'Reaction outcome loss': 0.12400837103665178, 'Total loss': 0.12400837103665178}
2022-12-05 19:25:12,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:12,320 INFO:     Epoch: 95
2022-12-05 19:25:13,106 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44461137598211115, 'Total loss': 0.44461137598211115} | train loss {'Reaction outcome loss': 0.12254013579947, 'Total loss': 0.12254013579947}
2022-12-05 19:25:13,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:13,106 INFO:     Epoch: 96
2022-12-05 19:25:13,893 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4577680609442971, 'Total loss': 0.4577680609442971} | train loss {'Reaction outcome loss': 0.12146794559548096, 'Total loss': 0.12146794559548096}
2022-12-05 19:25:13,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:13,894 INFO:     Epoch: 97
2022-12-05 19:25:14,678 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44558913954956963, 'Total loss': 0.44558913954956963} | train loss {'Reaction outcome loss': 0.12030154207949431, 'Total loss': 0.12030154207949431}
2022-12-05 19:25:14,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:14,678 INFO:     Epoch: 98
2022-12-05 19:25:15,465 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4384753099558028, 'Total loss': 0.4384753099558028} | train loss {'Reaction outcome loss': 0.11886778780620318, 'Total loss': 0.11886778780620318}
2022-12-05 19:25:15,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:15,465 INFO:     Epoch: 99
2022-12-05 19:25:16,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44247593967752025, 'Total loss': 0.44247593967752025} | train loss {'Reaction outcome loss': 0.11953556990745116, 'Total loss': 0.11953556990745116}
2022-12-05 19:25:16,249 INFO:     Best model found after epoch 14 of 100.
2022-12-05 19:25:16,249 INFO:   Done with stage: TRAINING
2022-12-05 19:25:16,249 INFO:   Starting stage: EVALUATION
2022-12-05 19:25:16,380 INFO:   Done with stage: EVALUATION
2022-12-05 19:25:16,380 INFO:   Leaving out SEQ value Fold_4
2022-12-05 19:25:16,392 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:25:16,393 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:25:17,024 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:25:17,024 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:25:17,092 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:25:17,092 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:25:17,092 INFO:     No hyperparam tuning for this model
2022-12-05 19:25:17,092 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:25:17,092 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:25:17,093 INFO:     None feature selector for col prot
2022-12-05 19:25:17,093 INFO:     None feature selector for col prot
2022-12-05 19:25:17,093 INFO:     None feature selector for col prot
2022-12-05 19:25:17,094 INFO:     None feature selector for col chem
2022-12-05 19:25:17,094 INFO:     None feature selector for col chem
2022-12-05 19:25:17,094 INFO:     None feature selector for col chem
2022-12-05 19:25:17,094 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:25:17,094 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:25:17,096 INFO:     Number of params in model 215821
2022-12-05 19:25:17,099 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:25:17,099 INFO:   Starting stage: TRAINING
2022-12-05 19:25:17,159 INFO:     Val loss before train {'Reaction outcome loss': 0.9773291728713296, 'Total loss': 0.9773291728713296}
2022-12-05 19:25:17,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:17,160 INFO:     Epoch: 0
2022-12-05 19:25:17,944 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5984858003529635, 'Total loss': 0.5984858003529635} | train loss {'Reaction outcome loss': 0.7966430380636332, 'Total loss': 0.7966430380636332}
2022-12-05 19:25:17,945 INFO:     Found new best model at epoch 0
2022-12-05 19:25:17,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:17,946 INFO:     Epoch: 1
2022-12-05 19:25:18,735 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5083072070371021, 'Total loss': 0.5083072070371021} | train loss {'Reaction outcome loss': 0.5246845349973562, 'Total loss': 0.5246845349973562}
2022-12-05 19:25:18,735 INFO:     Found new best model at epoch 1
2022-12-05 19:25:18,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:18,736 INFO:     Epoch: 2
2022-12-05 19:25:19,524 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4779138029976325, 'Total loss': 0.4779138029976325} | train loss {'Reaction outcome loss': 0.4531973838197942, 'Total loss': 0.4531973838197942}
2022-12-05 19:25:19,524 INFO:     Found new best model at epoch 2
2022-12-05 19:25:19,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:19,525 INFO:     Epoch: 3
2022-12-05 19:25:20,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45277663523500616, 'Total loss': 0.45277663523500616} | train loss {'Reaction outcome loss': 0.4137482174197022, 'Total loss': 0.4137482174197022}
2022-12-05 19:25:20,312 INFO:     Found new best model at epoch 3
2022-12-05 19:25:20,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:20,313 INFO:     Epoch: 4
2022-12-05 19:25:21,098 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4314901053228162, 'Total loss': 0.4314901053228162} | train loss {'Reaction outcome loss': 0.3879382084218823, 'Total loss': 0.3879382084218823}
2022-12-05 19:25:21,098 INFO:     Found new best model at epoch 4
2022-12-05 19:25:21,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:21,099 INFO:     Epoch: 5
2022-12-05 19:25:21,883 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45266312699426303, 'Total loss': 0.45266312699426303} | train loss {'Reaction outcome loss': 0.365000920332208, 'Total loss': 0.365000920332208}
2022-12-05 19:25:21,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:21,883 INFO:     Epoch: 6
2022-12-05 19:25:22,668 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4132081564854492, 'Total loss': 0.4132081564854492} | train loss {'Reaction outcome loss': 0.3531207540813757, 'Total loss': 0.3531207540813757}
2022-12-05 19:25:22,668 INFO:     Found new best model at epoch 6
2022-12-05 19:25:22,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:22,669 INFO:     Epoch: 7
2022-12-05 19:25:23,453 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4058339829471978, 'Total loss': 0.4058339829471978} | train loss {'Reaction outcome loss': 0.3341493026942623, 'Total loss': 0.3341493026942623}
2022-12-05 19:25:23,453 INFO:     Found new best model at epoch 7
2022-12-05 19:25:23,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:23,454 INFO:     Epoch: 8
2022-12-05 19:25:24,239 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40806380490010435, 'Total loss': 0.40806380490010435} | train loss {'Reaction outcome loss': 0.3205926809079793, 'Total loss': 0.3205926809079793}
2022-12-05 19:25:24,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:24,240 INFO:     Epoch: 9
2022-12-05 19:25:25,025 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4214310104196722, 'Total loss': 0.4214310104196722} | train loss {'Reaction outcome loss': 0.3079531827447366, 'Total loss': 0.3079531827447366}
2022-12-05 19:25:25,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:25,025 INFO:     Epoch: 10
2022-12-05 19:25:25,810 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43056055734103377, 'Total loss': 0.43056055734103377} | train loss {'Reaction outcome loss': 0.297661922902477, 'Total loss': 0.297661922902477}
2022-12-05 19:25:25,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:25,811 INFO:     Epoch: 11
2022-12-05 19:25:26,599 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4073431451212276, 'Total loss': 0.4073431451212276} | train loss {'Reaction outcome loss': 0.28572312274149486, 'Total loss': 0.28572312274149486}
2022-12-05 19:25:26,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:26,599 INFO:     Epoch: 12
2022-12-05 19:25:27,387 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4045467816970565, 'Total loss': 0.4045467816970565} | train loss {'Reaction outcome loss': 0.27824704464601013, 'Total loss': 0.27824704464601013}
2022-12-05 19:25:27,387 INFO:     Found new best model at epoch 12
2022-12-05 19:25:27,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:27,388 INFO:     Epoch: 13
2022-12-05 19:25:28,174 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4049796722829342, 'Total loss': 0.4049796722829342} | train loss {'Reaction outcome loss': 0.2673058006988496, 'Total loss': 0.2673058006988496}
2022-12-05 19:25:28,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:28,175 INFO:     Epoch: 14
2022-12-05 19:25:28,963 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4108781431886283, 'Total loss': 0.4108781431886283} | train loss {'Reaction outcome loss': 0.26159432369227315, 'Total loss': 0.26159432369227315}
2022-12-05 19:25:28,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:28,963 INFO:     Epoch: 15
2022-12-05 19:25:29,749 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4101619984615933, 'Total loss': 0.4101619984615933} | train loss {'Reaction outcome loss': 0.25401869367580027, 'Total loss': 0.25401869367580027}
2022-12-05 19:25:29,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:29,749 INFO:     Epoch: 16
2022-12-05 19:25:30,538 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4076537774367766, 'Total loss': 0.4076537774367766} | train loss {'Reaction outcome loss': 0.24602876372483312, 'Total loss': 0.24602876372483312}
2022-12-05 19:25:30,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:30,539 INFO:     Epoch: 17
2022-12-05 19:25:31,332 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4364029175855897, 'Total loss': 0.4364029175855897} | train loss {'Reaction outcome loss': 0.2411030160833378, 'Total loss': 0.2411030160833378}
2022-12-05 19:25:31,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:31,333 INFO:     Epoch: 18
2022-12-05 19:25:32,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4191603052683852, 'Total loss': 0.4191603052683852} | train loss {'Reaction outcome loss': 0.23138032522128552, 'Total loss': 0.23138032522128552}
2022-12-05 19:25:32,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:32,122 INFO:     Epoch: 19
2022-12-05 19:25:32,906 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40218993987549434, 'Total loss': 0.40218993987549434} | train loss {'Reaction outcome loss': 0.229078250363165, 'Total loss': 0.229078250363165}
2022-12-05 19:25:32,906 INFO:     Found new best model at epoch 19
2022-12-05 19:25:32,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:32,907 INFO:     Epoch: 20
2022-12-05 19:25:33,690 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40694074739109387, 'Total loss': 0.40694074739109387} | train loss {'Reaction outcome loss': 0.22375895981581845, 'Total loss': 0.22375895981581845}
2022-12-05 19:25:33,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:33,691 INFO:     Epoch: 21
2022-12-05 19:25:34,482 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4034214610741897, 'Total loss': 0.4034214610741897} | train loss {'Reaction outcome loss': 0.21676824868333583, 'Total loss': 0.21676824868333583}
2022-12-05 19:25:34,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:34,482 INFO:     Epoch: 22
2022-12-05 19:25:35,266 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40991753136569803, 'Total loss': 0.40991753136569803} | train loss {'Reaction outcome loss': 0.21510984914339318, 'Total loss': 0.21510984914339318}
2022-12-05 19:25:35,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:35,266 INFO:     Epoch: 23
2022-12-05 19:25:36,051 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41281658749688754, 'Total loss': 0.41281658749688754} | train loss {'Reaction outcome loss': 0.21229629188167806, 'Total loss': 0.21229629188167806}
2022-12-05 19:25:36,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:36,051 INFO:     Epoch: 24
2022-12-05 19:25:36,845 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39205810698595916, 'Total loss': 0.39205810698595916} | train loss {'Reaction outcome loss': 0.2054629610205183, 'Total loss': 0.2054629610205183}
2022-12-05 19:25:36,845 INFO:     Found new best model at epoch 24
2022-12-05 19:25:36,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:36,846 INFO:     Epoch: 25
2022-12-05 19:25:37,633 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4056146171959964, 'Total loss': 0.4056146171959964} | train loss {'Reaction outcome loss': 0.20237320726927446, 'Total loss': 0.20237320726927446}
2022-12-05 19:25:37,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:37,633 INFO:     Epoch: 26
2022-12-05 19:25:38,426 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4216517023742199, 'Total loss': 0.4216517023742199} | train loss {'Reaction outcome loss': 0.19550931842959657, 'Total loss': 0.19550931842959657}
2022-12-05 19:25:38,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:38,426 INFO:     Epoch: 27
2022-12-05 19:25:39,210 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41752398217266257, 'Total loss': 0.41752398217266257} | train loss {'Reaction outcome loss': 0.1935433844522554, 'Total loss': 0.1935433844522554}
2022-12-05 19:25:39,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:39,210 INFO:     Epoch: 28
2022-12-05 19:25:39,996 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4332966296510263, 'Total loss': 0.4332966296510263} | train loss {'Reaction outcome loss': 0.1889405131644132, 'Total loss': 0.1889405131644132}
2022-12-05 19:25:39,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:39,996 INFO:     Epoch: 29
2022-12-05 19:25:40,782 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.445237052034248, 'Total loss': 0.445237052034248} | train loss {'Reaction outcome loss': 0.184697466100357, 'Total loss': 0.184697466100357}
2022-12-05 19:25:40,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:40,782 INFO:     Epoch: 30
2022-12-05 19:25:41,572 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3949065290137448, 'Total loss': 0.3949065290137448} | train loss {'Reaction outcome loss': 0.1846557793872697, 'Total loss': 0.1846557793872697}
2022-12-05 19:25:41,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:41,573 INFO:     Epoch: 31
2022-12-05 19:25:42,362 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4145889515903863, 'Total loss': 0.4145889515903863} | train loss {'Reaction outcome loss': 0.17887237613298454, 'Total loss': 0.17887237613298454}
2022-12-05 19:25:42,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:42,362 INFO:     Epoch: 32
2022-12-05 19:25:43,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4012333198704503, 'Total loss': 0.4012333198704503} | train loss {'Reaction outcome loss': 0.1766446064017257, 'Total loss': 0.1766446064017257}
2022-12-05 19:25:43,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:43,148 INFO:     Epoch: 33
2022-12-05 19:25:43,935 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39256952211938123, 'Total loss': 0.39256952211938123} | train loss {'Reaction outcome loss': 0.17669830977612613, 'Total loss': 0.17669830977612613}
2022-12-05 19:25:43,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:43,935 INFO:     Epoch: 34
2022-12-05 19:25:44,722 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40857147019017825, 'Total loss': 0.40857147019017825} | train loss {'Reaction outcome loss': 0.1748655806694712, 'Total loss': 0.1748655806694712}
2022-12-05 19:25:44,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:44,723 INFO:     Epoch: 35
2022-12-05 19:25:45,518 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4218928024850108, 'Total loss': 0.4218928024850108} | train loss {'Reaction outcome loss': 0.1725485914747934, 'Total loss': 0.1725485914747934}
2022-12-05 19:25:45,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:45,519 INFO:     Epoch: 36
2022-12-05 19:25:46,306 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4326467571610754, 'Total loss': 0.4326467571610754} | train loss {'Reaction outcome loss': 0.1751380404875595, 'Total loss': 0.1751380404875595}
2022-12-05 19:25:46,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:46,306 INFO:     Epoch: 37
2022-12-05 19:25:47,095 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41172368718649854, 'Total loss': 0.41172368718649854} | train loss {'Reaction outcome loss': 0.17069261163777236, 'Total loss': 0.17069261163777236}
2022-12-05 19:25:47,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:47,095 INFO:     Epoch: 38
2022-12-05 19:25:47,883 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4348506697199561, 'Total loss': 0.4348506697199561} | train loss {'Reaction outcome loss': 0.1648481834907921, 'Total loss': 0.1648481834907921}
2022-12-05 19:25:47,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:47,884 INFO:     Epoch: 39
2022-12-05 19:25:48,672 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4242190483280204, 'Total loss': 0.4242190483280204} | train loss {'Reaction outcome loss': 0.16192878254366164, 'Total loss': 0.16192878254366164}
2022-12-05 19:25:48,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:48,673 INFO:     Epoch: 40
2022-12-05 19:25:49,460 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4116702279583974, 'Total loss': 0.4116702279583974} | train loss {'Reaction outcome loss': 0.15982136454205123, 'Total loss': 0.15982136454205123}
2022-12-05 19:25:49,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:49,460 INFO:     Epoch: 41
2022-12-05 19:25:50,249 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4189439729618078, 'Total loss': 0.4189439729618078} | train loss {'Reaction outcome loss': 0.16139385356586808, 'Total loss': 0.16139385356586808}
2022-12-05 19:25:50,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:50,250 INFO:     Epoch: 42
2022-12-05 19:25:51,038 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43693992123007774, 'Total loss': 0.43693992123007774} | train loss {'Reaction outcome loss': 0.15980385427876395, 'Total loss': 0.15980385427876395}
2022-12-05 19:25:51,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:51,038 INFO:     Epoch: 43
2022-12-05 19:25:51,825 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4348717944865877, 'Total loss': 0.4348717944865877} | train loss {'Reaction outcome loss': 0.15444508150067865, 'Total loss': 0.15444508150067865}
2022-12-05 19:25:51,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:51,825 INFO:     Epoch: 44
2022-12-05 19:25:52,611 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4161746183579618, 'Total loss': 0.4161746183579618} | train loss {'Reaction outcome loss': 0.1560635908069659, 'Total loss': 0.1560635908069659}
2022-12-05 19:25:52,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:52,611 INFO:     Epoch: 45
2022-12-05 19:25:53,401 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4348912106996233, 'Total loss': 0.4348912106996233} | train loss {'Reaction outcome loss': 0.15243921431199628, 'Total loss': 0.15243921431199628}
2022-12-05 19:25:53,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:53,401 INFO:     Epoch: 46
2022-12-05 19:25:54,185 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42542917518453166, 'Total loss': 0.42542917518453166} | train loss {'Reaction outcome loss': 0.15305664716288447, 'Total loss': 0.15305664716288447}
2022-12-05 19:25:54,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:54,185 INFO:     Epoch: 47
2022-12-05 19:25:54,967 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4349287287755446, 'Total loss': 0.4349287287755446} | train loss {'Reaction outcome loss': 0.14996448014007538, 'Total loss': 0.14996448014007538}
2022-12-05 19:25:54,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:54,968 INFO:     Epoch: 48
2022-12-05 19:25:55,755 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4274093732237816, 'Total loss': 0.4274093732237816} | train loss {'Reaction outcome loss': 0.15066902704384863, 'Total loss': 0.15066902704384863}
2022-12-05 19:25:55,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:55,756 INFO:     Epoch: 49
2022-12-05 19:25:56,538 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44765984266996384, 'Total loss': 0.44765984266996384} | train loss {'Reaction outcome loss': 0.14775205610738118, 'Total loss': 0.14775205610738118}
2022-12-05 19:25:56,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:56,538 INFO:     Epoch: 50
2022-12-05 19:25:57,324 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4373087964274667, 'Total loss': 0.4373087964274667} | train loss {'Reaction outcome loss': 0.14617156954292132, 'Total loss': 0.14617156954292132}
2022-12-05 19:25:57,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:57,325 INFO:     Epoch: 51
2022-12-05 19:25:58,111 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.421179670501839, 'Total loss': 0.421179670501839} | train loss {'Reaction outcome loss': 0.1439063743365054, 'Total loss': 0.1439063743365054}
2022-12-05 19:25:58,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:58,111 INFO:     Epoch: 52
2022-12-05 19:25:58,894 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43766280805522745, 'Total loss': 0.43766280805522745} | train loss {'Reaction outcome loss': 0.14497173948555578, 'Total loss': 0.14497173948555578}
2022-12-05 19:25:58,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:58,894 INFO:     Epoch: 53
2022-12-05 19:25:59,678 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4263047023930333, 'Total loss': 0.4263047023930333} | train loss {'Reaction outcome loss': 0.14222644931655756, 'Total loss': 0.14222644931655756}
2022-12-05 19:25:59,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:25:59,678 INFO:     Epoch: 54
2022-12-05 19:26:00,460 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4199377064677802, 'Total loss': 0.4199377064677802} | train loss {'Reaction outcome loss': 0.14276534726425094, 'Total loss': 0.14276534726425094}
2022-12-05 19:26:00,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:00,460 INFO:     Epoch: 55
2022-12-05 19:26:01,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43264088982885535, 'Total loss': 0.43264088982885535} | train loss {'Reaction outcome loss': 0.14072149368573209, 'Total loss': 0.14072149368573209}
2022-12-05 19:26:01,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:01,244 INFO:     Epoch: 56
2022-12-05 19:26:02,030 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43761090155352245, 'Total loss': 0.43761090155352245} | train loss {'Reaction outcome loss': 0.13953320374902414, 'Total loss': 0.13953320374902414}
2022-12-05 19:26:02,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:02,031 INFO:     Epoch: 57
2022-12-05 19:26:02,816 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44628829610618675, 'Total loss': 0.44628829610618675} | train loss {'Reaction outcome loss': 0.1417553723542666, 'Total loss': 0.1417553723542666}
2022-12-05 19:26:02,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:02,816 INFO:     Epoch: 58
2022-12-05 19:26:03,603 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4539555419575084, 'Total loss': 0.4539555419575084} | train loss {'Reaction outcome loss': 0.14008638767563567, 'Total loss': 0.14008638767563567}
2022-12-05 19:26:03,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:03,603 INFO:     Epoch: 59
2022-12-05 19:26:04,388 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4302130429582162, 'Total loss': 0.4302130429582162} | train loss {'Reaction outcome loss': 0.13717273729568233, 'Total loss': 0.13717273729568233}
2022-12-05 19:26:04,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:04,388 INFO:     Epoch: 60
2022-12-05 19:26:05,170 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43122305754910817, 'Total loss': 0.43122305754910817} | train loss {'Reaction outcome loss': 0.13542191767114767, 'Total loss': 0.13542191767114767}
2022-12-05 19:26:05,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:05,171 INFO:     Epoch: 61
2022-12-05 19:26:05,953 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43049096675928344, 'Total loss': 0.43049096675928344} | train loss {'Reaction outcome loss': 0.13493661302693036, 'Total loss': 0.13493661302693036}
2022-12-05 19:26:05,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:05,953 INFO:     Epoch: 62
2022-12-05 19:26:06,739 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4489667723802003, 'Total loss': 0.4489667723802003} | train loss {'Reaction outcome loss': 0.13323805639330222, 'Total loss': 0.13323805639330222}
2022-12-05 19:26:06,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:06,739 INFO:     Epoch: 63
2022-12-05 19:26:07,527 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4490356756882234, 'Total loss': 0.4490356756882234} | train loss {'Reaction outcome loss': 0.13645980023227783, 'Total loss': 0.13645980023227783}
2022-12-05 19:26:07,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:07,527 INFO:     Epoch: 64
2022-12-05 19:26:08,309 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4658736127682708, 'Total loss': 0.4658736127682708} | train loss {'Reaction outcome loss': 0.13523283942165423, 'Total loss': 0.13523283942165423}
2022-12-05 19:26:08,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:08,309 INFO:     Epoch: 65
2022-12-05 19:26:09,093 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4398300520737063, 'Total loss': 0.4398300520737063} | train loss {'Reaction outcome loss': 0.1326765727936005, 'Total loss': 0.1326765727936005}
2022-12-05 19:26:09,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:09,093 INFO:     Epoch: 66
2022-12-05 19:26:09,879 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4432217021557418, 'Total loss': 0.4432217021557418} | train loss {'Reaction outcome loss': 0.1322665115248184, 'Total loss': 0.1322665115248184}
2022-12-05 19:26:09,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:09,879 INFO:     Epoch: 67
2022-12-05 19:26:10,663 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43785534731366416, 'Total loss': 0.43785534731366416} | train loss {'Reaction outcome loss': 0.134314511898829, 'Total loss': 0.134314511898829}
2022-12-05 19:26:10,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:10,664 INFO:     Epoch: 68
2022-12-05 19:26:11,449 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42739539817822253, 'Total loss': 0.42739539817822253} | train loss {'Reaction outcome loss': 0.13308581906769956, 'Total loss': 0.13308581906769956}
2022-12-05 19:26:11,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:11,449 INFO:     Epoch: 69
2022-12-05 19:26:12,237 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4643822319128297, 'Total loss': 0.4643822319128297} | train loss {'Reaction outcome loss': 0.1298996621590792, 'Total loss': 0.1298996621590792}
2022-12-05 19:26:12,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:12,237 INFO:     Epoch: 70
2022-12-05 19:26:13,023 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42734544072300196, 'Total loss': 0.42734544072300196} | train loss {'Reaction outcome loss': 0.12880885204946507, 'Total loss': 0.12880885204946507}
2022-12-05 19:26:13,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:13,023 INFO:     Epoch: 71
2022-12-05 19:26:13,810 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4336548334156925, 'Total loss': 0.4336548334156925} | train loss {'Reaction outcome loss': 0.1258962285419812, 'Total loss': 0.1258962285419812}
2022-12-05 19:26:13,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:13,810 INFO:     Epoch: 72
2022-12-05 19:26:14,603 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4403401846912774, 'Total loss': 0.4403401846912774} | train loss {'Reaction outcome loss': 0.12870383580044217, 'Total loss': 0.12870383580044217}
2022-12-05 19:26:14,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:14,604 INFO:     Epoch: 73
2022-12-05 19:26:15,391 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42159347676418046, 'Total loss': 0.42159347676418046} | train loss {'Reaction outcome loss': 0.126180856883982, 'Total loss': 0.126180856883982}
2022-12-05 19:26:15,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:15,391 INFO:     Epoch: 74
2022-12-05 19:26:16,177 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.444080613553524, 'Total loss': 0.444080613553524} | train loss {'Reaction outcome loss': 0.12561294721933652, 'Total loss': 0.12561294721933652}
2022-12-05 19:26:16,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:16,177 INFO:     Epoch: 75
2022-12-05 19:26:16,966 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43486886471509933, 'Total loss': 0.43486886471509933} | train loss {'Reaction outcome loss': 0.12405000647567972, 'Total loss': 0.12405000647567972}
2022-12-05 19:26:16,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:16,966 INFO:     Epoch: 76
2022-12-05 19:26:17,761 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44311336732723494, 'Total loss': 0.44311336732723494} | train loss {'Reaction outcome loss': 0.12527853382029094, 'Total loss': 0.12527853382029094}
2022-12-05 19:26:17,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:17,761 INFO:     Epoch: 77
2022-12-05 19:26:18,560 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4336260699413039, 'Total loss': 0.4336260699413039} | train loss {'Reaction outcome loss': 0.12512016759767217, 'Total loss': 0.12512016759767217}
2022-12-05 19:26:18,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:18,560 INFO:     Epoch: 78
2022-12-05 19:26:19,350 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46140396865931427, 'Total loss': 0.46140396865931427} | train loss {'Reaction outcome loss': 0.12368609110767743, 'Total loss': 0.12368609110767743}
2022-12-05 19:26:19,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:19,350 INFO:     Epoch: 79
2022-12-05 19:26:20,142 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44136439805681055, 'Total loss': 0.44136439805681055} | train loss {'Reaction outcome loss': 0.12355332681719138, 'Total loss': 0.12355332681719138}
2022-12-05 19:26:20,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:20,142 INFO:     Epoch: 80
2022-12-05 19:26:20,938 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4340207769789479, 'Total loss': 0.4340207769789479} | train loss {'Reaction outcome loss': 0.1239336373474525, 'Total loss': 0.1239336373474525}
2022-12-05 19:26:20,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:20,939 INFO:     Epoch: 81
2022-12-05 19:26:21,745 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4436566098169847, 'Total loss': 0.4436566098169847} | train loss {'Reaction outcome loss': 0.12390476195331739, 'Total loss': 0.12390476195331739}
2022-12-05 19:26:21,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:21,745 INFO:     Epoch: 82
2022-12-05 19:26:22,546 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4578701941804452, 'Total loss': 0.4578701941804452} | train loss {'Reaction outcome loss': 0.12375870272517205, 'Total loss': 0.12375870272517205}
2022-12-05 19:26:22,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:22,546 INFO:     Epoch: 83
2022-12-05 19:26:23,339 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.438355395401066, 'Total loss': 0.438355395401066} | train loss {'Reaction outcome loss': 0.1218918784844632, 'Total loss': 0.1218918784844632}
2022-12-05 19:26:23,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:23,339 INFO:     Epoch: 84
2022-12-05 19:26:24,127 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4482191331811588, 'Total loss': 0.4482191331811588} | train loss {'Reaction outcome loss': 0.12321569899819335, 'Total loss': 0.12321569899819335}
2022-12-05 19:26:24,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:24,127 INFO:     Epoch: 85
2022-12-05 19:26:24,915 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43654746816239576, 'Total loss': 0.43654746816239576} | train loss {'Reaction outcome loss': 0.12029460943779167, 'Total loss': 0.12029460943779167}
2022-12-05 19:26:24,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:24,915 INFO:     Epoch: 86
2022-12-05 19:26:25,701 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4462905560450798, 'Total loss': 0.4462905560450798} | train loss {'Reaction outcome loss': 0.11760024310146668, 'Total loss': 0.11760024310146668}
2022-12-05 19:26:25,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:25,701 INFO:     Epoch: 87
2022-12-05 19:26:26,487 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44040964103557845, 'Total loss': 0.44040964103557845} | train loss {'Reaction outcome loss': 0.12289108849149577, 'Total loss': 0.12289108849149577}
2022-12-05 19:26:26,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:26,487 INFO:     Epoch: 88
2022-12-05 19:26:27,275 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45315611955117097, 'Total loss': 0.45315611955117097} | train loss {'Reaction outcome loss': 0.11941197806475114, 'Total loss': 0.11941197806475114}
2022-12-05 19:26:27,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:27,275 INFO:     Epoch: 89
2022-12-05 19:26:28,062 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4439788994548673, 'Total loss': 0.4439788994548673} | train loss {'Reaction outcome loss': 0.1198575194050767, 'Total loss': 0.1198575194050767}
2022-12-05 19:26:28,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:28,062 INFO:     Epoch: 90
2022-12-05 19:26:28,850 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45195121445100417, 'Total loss': 0.45195121445100417} | train loss {'Reaction outcome loss': 0.1186104565630762, 'Total loss': 0.1186104565630762}
2022-12-05 19:26:28,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:28,851 INFO:     Epoch: 91
2022-12-05 19:26:29,637 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4407722775570371, 'Total loss': 0.4407722775570371} | train loss {'Reaction outcome loss': 0.11983041018247605, 'Total loss': 0.11983041018247605}
2022-12-05 19:26:29,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:29,637 INFO:     Epoch: 92
2022-12-05 19:26:30,427 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4504135102033615, 'Total loss': 0.4504135102033615} | train loss {'Reaction outcome loss': 0.12103876555148436, 'Total loss': 0.12103876555148436}
2022-12-05 19:26:30,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:30,427 INFO:     Epoch: 93
2022-12-05 19:26:31,212 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43788106637922203, 'Total loss': 0.43788106637922203} | train loss {'Reaction outcome loss': 0.11851162253593912, 'Total loss': 0.11851162253593912}
2022-12-05 19:26:31,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:31,212 INFO:     Epoch: 94
2022-12-05 19:26:31,996 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4552859745242379, 'Total loss': 0.4552859745242379} | train loss {'Reaction outcome loss': 0.11784478411534612, 'Total loss': 0.11784478411534612}
2022-12-05 19:26:31,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:31,997 INFO:     Epoch: 95
2022-12-05 19:26:32,786 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4641592082652179, 'Total loss': 0.4641592082652179} | train loss {'Reaction outcome loss': 0.11881008992085651, 'Total loss': 0.11881008992085651}
2022-12-05 19:26:32,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:32,786 INFO:     Epoch: 96
2022-12-05 19:26:33,580 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4411861774596301, 'Total loss': 0.4411861774596301} | train loss {'Reaction outcome loss': 0.11454144016440426, 'Total loss': 0.11454144016440426}
2022-12-05 19:26:33,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:33,581 INFO:     Epoch: 97
2022-12-05 19:26:34,369 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44242275184528396, 'Total loss': 0.44242275184528396} | train loss {'Reaction outcome loss': 0.11562472321853345, 'Total loss': 0.11562472321853345}
2022-12-05 19:26:34,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:34,369 INFO:     Epoch: 98
2022-12-05 19:26:35,157 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4729671088809317, 'Total loss': 0.4729671088809317} | train loss {'Reaction outcome loss': 0.11944400204383597, 'Total loss': 0.11944400204383597}
2022-12-05 19:26:35,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:35,157 INFO:     Epoch: 99
2022-12-05 19:26:35,943 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46634112196889793, 'Total loss': 0.46634112196889793} | train loss {'Reaction outcome loss': 0.11668109708674708, 'Total loss': 0.11668109708674708}
2022-12-05 19:26:35,943 INFO:     Best model found after epoch 25 of 100.
2022-12-05 19:26:35,943 INFO:   Done with stage: TRAINING
2022-12-05 19:26:35,944 INFO:   Starting stage: EVALUATION
2022-12-05 19:26:36,075 INFO:   Done with stage: EVALUATION
2022-12-05 19:26:36,075 INFO:   Leaving out SEQ value Fold_5
2022-12-05 19:26:36,087 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:26:36,088 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:26:36,734 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:26:36,734 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:26:36,803 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:26:36,804 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:26:36,804 INFO:     No hyperparam tuning for this model
2022-12-05 19:26:36,804 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:26:36,804 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:26:36,804 INFO:     None feature selector for col prot
2022-12-05 19:26:36,805 INFO:     None feature selector for col prot
2022-12-05 19:26:36,805 INFO:     None feature selector for col prot
2022-12-05 19:26:36,805 INFO:     None feature selector for col chem
2022-12-05 19:26:36,805 INFO:     None feature selector for col chem
2022-12-05 19:26:36,805 INFO:     None feature selector for col chem
2022-12-05 19:26:36,805 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:26:36,806 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:26:36,807 INFO:     Number of params in model 215821
2022-12-05 19:26:36,811 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:26:36,811 INFO:   Starting stage: TRAINING
2022-12-05 19:26:36,872 INFO:     Val loss before train {'Reaction outcome loss': 1.0105140602046794, 'Total loss': 1.0105140602046794}
2022-12-05 19:26:36,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:36,872 INFO:     Epoch: 0
2022-12-05 19:26:37,669 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5839932317083533, 'Total loss': 0.5839932317083533} | train loss {'Reaction outcome loss': 0.774395493240009, 'Total loss': 0.774395493240009}
2022-12-05 19:26:37,669 INFO:     Found new best model at epoch 0
2022-12-05 19:26:37,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:37,670 INFO:     Epoch: 1
2022-12-05 19:26:38,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5216863270510327, 'Total loss': 0.5216863270510327} | train loss {'Reaction outcome loss': 0.5325846643100384, 'Total loss': 0.5325846643100384}
2022-12-05 19:26:38,465 INFO:     Found new best model at epoch 1
2022-12-05 19:26:38,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:38,466 INFO:     Epoch: 2
2022-12-05 19:26:39,267 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4706695228815079, 'Total loss': 0.4706695228815079} | train loss {'Reaction outcome loss': 0.4607864598392958, 'Total loss': 0.4607864598392958}
2022-12-05 19:26:39,267 INFO:     Found new best model at epoch 2
2022-12-05 19:26:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:39,268 INFO:     Epoch: 3
2022-12-05 19:26:40,064 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45485062524676323, 'Total loss': 0.45485062524676323} | train loss {'Reaction outcome loss': 0.4218097414203018, 'Total loss': 0.4218097414203018}
2022-12-05 19:26:40,064 INFO:     Found new best model at epoch 3
2022-12-05 19:26:40,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:40,065 INFO:     Epoch: 4
2022-12-05 19:26:40,861 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4363748427819122, 'Total loss': 0.4363748427819122} | train loss {'Reaction outcome loss': 0.39326306093137275, 'Total loss': 0.39326306093137275}
2022-12-05 19:26:40,861 INFO:     Found new best model at epoch 4
2022-12-05 19:26:40,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:40,862 INFO:     Epoch: 5
2022-12-05 19:26:41,656 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4269138445908373, 'Total loss': 0.4269138445908373} | train loss {'Reaction outcome loss': 0.37222106556732376, 'Total loss': 0.37222106556732376}
2022-12-05 19:26:41,656 INFO:     Found new best model at epoch 5
2022-12-05 19:26:41,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:41,657 INFO:     Epoch: 6
2022-12-05 19:26:42,457 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43087125705047086, 'Total loss': 0.43087125705047086} | train loss {'Reaction outcome loss': 0.3524058308557943, 'Total loss': 0.3524058308557943}
2022-12-05 19:26:42,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:42,457 INFO:     Epoch: 7
2022-12-05 19:26:43,252 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4307526492259719, 'Total loss': 0.4307526492259719} | train loss {'Reaction outcome loss': 0.3384215379593826, 'Total loss': 0.3384215379593826}
2022-12-05 19:26:43,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:43,252 INFO:     Epoch: 8
2022-12-05 19:26:44,050 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41258137131279166, 'Total loss': 0.41258137131279166} | train loss {'Reaction outcome loss': 0.3241429443241131, 'Total loss': 0.3241429443241131}
2022-12-05 19:26:44,050 INFO:     Found new best model at epoch 8
2022-12-05 19:26:44,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:44,051 INFO:     Epoch: 9
2022-12-05 19:26:44,844 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.411564748395573, 'Total loss': 0.411564748395573} | train loss {'Reaction outcome loss': 0.3095704240475589, 'Total loss': 0.3095704240475589}
2022-12-05 19:26:44,844 INFO:     Found new best model at epoch 9
2022-12-05 19:26:44,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:44,845 INFO:     Epoch: 10
2022-12-05 19:26:45,638 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41935485804622824, 'Total loss': 0.41935485804622824} | train loss {'Reaction outcome loss': 0.2964535526599479, 'Total loss': 0.2964535526599479}
2022-12-05 19:26:45,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:45,638 INFO:     Epoch: 11
2022-12-05 19:26:46,446 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40961629287763074, 'Total loss': 0.40961629287763074} | train loss {'Reaction outcome loss': 0.28590277808450676, 'Total loss': 0.28590277808450676}
2022-12-05 19:26:46,447 INFO:     Found new best model at epoch 11
2022-12-05 19:26:46,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:46,448 INFO:     Epoch: 12
2022-12-05 19:26:47,255 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4080469963902777, 'Total loss': 0.4080469963902777} | train loss {'Reaction outcome loss': 0.27267700736128125, 'Total loss': 0.27267700736128125}
2022-12-05 19:26:47,256 INFO:     Found new best model at epoch 12
2022-12-05 19:26:47,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:47,256 INFO:     Epoch: 13
2022-12-05 19:26:48,065 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41543012688105757, 'Total loss': 0.41543012688105757} | train loss {'Reaction outcome loss': 0.2637790801976374, 'Total loss': 0.2637790801976374}
2022-12-05 19:26:48,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:48,065 INFO:     Epoch: 14
2022-12-05 19:26:48,863 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4139195264063098, 'Total loss': 0.4139195264063098} | train loss {'Reaction outcome loss': 0.26387173504481914, 'Total loss': 0.26387173504481914}
2022-12-05 19:26:48,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:48,864 INFO:     Epoch: 15
2022-12-05 19:26:49,657 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41855090924284677, 'Total loss': 0.41855090924284677} | train loss {'Reaction outcome loss': 0.25247732738432616, 'Total loss': 0.25247732738432616}
2022-12-05 19:26:49,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:49,657 INFO:     Epoch: 16
2022-12-05 19:26:50,455 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4119669036431746, 'Total loss': 0.4119669036431746} | train loss {'Reaction outcome loss': 0.2449862646610148, 'Total loss': 0.2449862646610148}
2022-12-05 19:26:50,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:50,456 INFO:     Epoch: 17
2022-12-05 19:26:51,248 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40702038766308263, 'Total loss': 0.40702038766308263} | train loss {'Reaction outcome loss': 0.23559523452269404, 'Total loss': 0.23559523452269404}
2022-12-05 19:26:51,248 INFO:     Found new best model at epoch 17
2022-12-05 19:26:51,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:51,249 INFO:     Epoch: 18
2022-12-05 19:26:52,042 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41916952112858946, 'Total loss': 0.41916952112858946} | train loss {'Reaction outcome loss': 0.2274071970852733, 'Total loss': 0.2274071970852733}
2022-12-05 19:26:52,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:52,042 INFO:     Epoch: 19
2022-12-05 19:26:52,843 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4166688204488971, 'Total loss': 0.4166688204488971} | train loss {'Reaction outcome loss': 0.22412209732548488, 'Total loss': 0.22412209732548488}
2022-12-05 19:26:52,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:52,844 INFO:     Epoch: 20
2022-12-05 19:26:53,636 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41452218659899454, 'Total loss': 0.41452218659899454} | train loss {'Reaction outcome loss': 0.21927992554630346, 'Total loss': 0.21927992554630346}
2022-12-05 19:26:53,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:53,636 INFO:     Epoch: 21
2022-12-05 19:26:54,426 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4070976319807497, 'Total loss': 0.4070976319807497} | train loss {'Reaction outcome loss': 0.2158496553296985, 'Total loss': 0.2158496553296985}
2022-12-05 19:26:54,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:54,426 INFO:     Epoch: 22
2022-12-05 19:26:55,217 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43543781069192017, 'Total loss': 0.43543781069192017} | train loss {'Reaction outcome loss': 0.21074484487588288, 'Total loss': 0.21074484487588288}
2022-12-05 19:26:55,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:55,217 INFO:     Epoch: 23
2022-12-05 19:26:56,006 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41814702698452905, 'Total loss': 0.41814702698452905} | train loss {'Reaction outcome loss': 0.2045236891314674, 'Total loss': 0.2045236891314674}
2022-12-05 19:26:56,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:56,006 INFO:     Epoch: 24
2022-12-05 19:26:56,796 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4284644777124578, 'Total loss': 0.4284644777124578} | train loss {'Reaction outcome loss': 0.20022153405299192, 'Total loss': 0.20022153405299192}
2022-12-05 19:26:56,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:56,796 INFO:     Epoch: 25
2022-12-05 19:26:57,589 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4251336553557353, 'Total loss': 0.4251336553557353} | train loss {'Reaction outcome loss': 0.1979971679779682, 'Total loss': 0.1979971679779682}
2022-12-05 19:26:57,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:57,589 INFO:     Epoch: 26
2022-12-05 19:26:58,381 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4242819869382815, 'Total loss': 0.4242819869382815} | train loss {'Reaction outcome loss': 0.19776112510849106, 'Total loss': 0.19776112510849106}
2022-12-05 19:26:58,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:58,381 INFO:     Epoch: 27
2022-12-05 19:26:59,171 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4270739264108918, 'Total loss': 0.4270739264108918} | train loss {'Reaction outcome loss': 0.19612982131631268, 'Total loss': 0.19612982131631268}
2022-12-05 19:26:59,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:59,171 INFO:     Epoch: 28
2022-12-05 19:26:59,963 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4316915480250662, 'Total loss': 0.4316915480250662} | train loss {'Reaction outcome loss': 0.19167954480720434, 'Total loss': 0.19167954480720434}
2022-12-05 19:26:59,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:26:59,963 INFO:     Epoch: 29
2022-12-05 19:27:00,755 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44143129072406073, 'Total loss': 0.44143129072406073} | train loss {'Reaction outcome loss': 0.19016503063143658, 'Total loss': 0.19016503063143658}
2022-12-05 19:27:00,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:00,755 INFO:     Epoch: 30
2022-12-05 19:27:01,547 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4261698221618479, 'Total loss': 0.4261698221618479} | train loss {'Reaction outcome loss': 0.18497449750088246, 'Total loss': 0.18497449750088246}
2022-12-05 19:27:01,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:01,547 INFO:     Epoch: 31
2022-12-05 19:27:02,339 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4200741858644919, 'Total loss': 0.4200741858644919} | train loss {'Reaction outcome loss': 0.18353175169171818, 'Total loss': 0.18353175169171818}
2022-12-05 19:27:02,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:02,340 INFO:     Epoch: 32
2022-12-05 19:27:03,131 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4294506311416626, 'Total loss': 0.4294506311416626} | train loss {'Reaction outcome loss': 0.17691310996431028, 'Total loss': 0.17691310996431028}
2022-12-05 19:27:03,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:03,131 INFO:     Epoch: 33
2022-12-05 19:27:03,922 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4384446326981891, 'Total loss': 0.4384446326981891} | train loss {'Reaction outcome loss': 0.1781772116221759, 'Total loss': 0.1781772116221759}
2022-12-05 19:27:03,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:03,922 INFO:     Epoch: 34
2022-12-05 19:27:04,715 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4315809299322692, 'Total loss': 0.4315809299322692} | train loss {'Reaction outcome loss': 0.17738044363736866, 'Total loss': 0.17738044363736866}
2022-12-05 19:27:04,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:04,715 INFO:     Epoch: 35
2022-12-05 19:27:05,509 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4344054186208682, 'Total loss': 0.4344054186208682} | train loss {'Reaction outcome loss': 0.17400706947030808, 'Total loss': 0.17400706947030808}
2022-12-05 19:27:05,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:05,510 INFO:     Epoch: 36
2022-12-05 19:27:06,305 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4460267946124077, 'Total loss': 0.4460267946124077} | train loss {'Reaction outcome loss': 0.1680033752328984, 'Total loss': 0.1680033752328984}
2022-12-05 19:27:06,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:06,306 INFO:     Epoch: 37
2022-12-05 19:27:07,105 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4489733258431608, 'Total loss': 0.4489733258431608} | train loss {'Reaction outcome loss': 0.1666771883092187, 'Total loss': 0.1666771883092187}
2022-12-05 19:27:07,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:07,105 INFO:     Epoch: 38
2022-12-05 19:27:07,901 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4311581276018511, 'Total loss': 0.4311581276018511} | train loss {'Reaction outcome loss': 0.16981437051977946, 'Total loss': 0.16981437051977946}
2022-12-05 19:27:07,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:07,901 INFO:     Epoch: 39
2022-12-05 19:27:08,698 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44107733074237, 'Total loss': 0.44107733074237} | train loss {'Reaction outcome loss': 0.16368778857217747, 'Total loss': 0.16368778857217747}
2022-12-05 19:27:08,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:08,698 INFO:     Epoch: 40
2022-12-05 19:27:09,488 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43730865960771387, 'Total loss': 0.43730865960771387} | train loss {'Reaction outcome loss': 0.15953522492275546, 'Total loss': 0.15953522492275546}
2022-12-05 19:27:09,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:09,489 INFO:     Epoch: 41
2022-12-05 19:27:10,283 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4335658516396176, 'Total loss': 0.4335658516396176} | train loss {'Reaction outcome loss': 0.16125376222029267, 'Total loss': 0.16125376222029267}
2022-12-05 19:27:10,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:10,283 INFO:     Epoch: 42
2022-12-05 19:27:11,077 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4283599953421138, 'Total loss': 0.4283599953421138} | train loss {'Reaction outcome loss': 0.15967223972745753, 'Total loss': 0.15967223972745753}
2022-12-05 19:27:11,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:11,077 INFO:     Epoch: 43
2022-12-05 19:27:11,869 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43787048723209987, 'Total loss': 0.43787048723209987} | train loss {'Reaction outcome loss': 0.16060750689055875, 'Total loss': 0.16060750689055875}
2022-12-05 19:27:11,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:11,869 INFO:     Epoch: 44
2022-12-05 19:27:12,665 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43960957940329204, 'Total loss': 0.43960957940329204} | train loss {'Reaction outcome loss': 0.16287299547144607, 'Total loss': 0.16287299547144607}
2022-12-05 19:27:12,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:12,665 INFO:     Epoch: 45
2022-12-05 19:27:13,459 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4595978212627498, 'Total loss': 0.4595978212627498} | train loss {'Reaction outcome loss': 0.15793546194942132, 'Total loss': 0.15793546194942132}
2022-12-05 19:27:13,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:13,460 INFO:     Epoch: 46
2022-12-05 19:27:14,254 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4498102461749857, 'Total loss': 0.4498102461749857} | train loss {'Reaction outcome loss': 0.16075532333072282, 'Total loss': 0.16075532333072282}
2022-12-05 19:27:14,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:14,254 INFO:     Epoch: 47
2022-12-05 19:27:15,046 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43378004093061795, 'Total loss': 0.43378004093061795} | train loss {'Reaction outcome loss': 0.15335285335945092, 'Total loss': 0.15335285335945092}
2022-12-05 19:27:15,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:15,047 INFO:     Epoch: 48
2022-12-05 19:27:15,838 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4608402482487939, 'Total loss': 0.4608402482487939} | train loss {'Reaction outcome loss': 0.1536095209480056, 'Total loss': 0.1536095209480056}
2022-12-05 19:27:15,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:15,838 INFO:     Epoch: 49
2022-12-05 19:27:16,626 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44673344221982086, 'Total loss': 0.44673344221982086} | train loss {'Reaction outcome loss': 0.1510402553673336, 'Total loss': 0.1510402553673336}
2022-12-05 19:27:16,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:16,626 INFO:     Epoch: 50
2022-12-05 19:27:17,420 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43558724427765066, 'Total loss': 0.43558724427765066} | train loss {'Reaction outcome loss': 0.15038098685390613, 'Total loss': 0.15038098685390613}
2022-12-05 19:27:17,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:17,421 INFO:     Epoch: 51
2022-12-05 19:27:18,210 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4466807869347659, 'Total loss': 0.4466807869347659} | train loss {'Reaction outcome loss': 0.149737881632288, 'Total loss': 0.149737881632288}
2022-12-05 19:27:18,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:18,211 INFO:     Epoch: 52
2022-12-05 19:27:19,007 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4452562447298657, 'Total loss': 0.4452562447298657} | train loss {'Reaction outcome loss': 0.15041270010505128, 'Total loss': 0.15041270010505128}
2022-12-05 19:27:19,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:19,008 INFO:     Epoch: 53
2022-12-05 19:27:19,807 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44422173737124965, 'Total loss': 0.44422173737124965} | train loss {'Reaction outcome loss': 0.15332013125784003, 'Total loss': 0.15332013125784003}
2022-12-05 19:27:19,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:19,807 INFO:     Epoch: 54
2022-12-05 19:27:20,600 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4438688186081973, 'Total loss': 0.4438688186081973} | train loss {'Reaction outcome loss': 0.14882793063618363, 'Total loss': 0.14882793063618363}
2022-12-05 19:27:20,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:20,600 INFO:     Epoch: 55
2022-12-05 19:27:21,392 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4435228878124194, 'Total loss': 0.4435228878124194} | train loss {'Reaction outcome loss': 0.14720778306757631, 'Total loss': 0.14720778306757631}
2022-12-05 19:27:21,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:21,392 INFO:     Epoch: 56
2022-12-05 19:27:22,185 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4544621174308387, 'Total loss': 0.4544621174308387} | train loss {'Reaction outcome loss': 0.1596974708509409, 'Total loss': 0.1596974708509409}
2022-12-05 19:27:22,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:22,185 INFO:     Epoch: 57
2022-12-05 19:27:22,979 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4398524984717369, 'Total loss': 0.4398524984717369} | train loss {'Reaction outcome loss': 0.1500248328824094, 'Total loss': 0.1500248328824094}
2022-12-05 19:27:22,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:22,979 INFO:     Epoch: 58
2022-12-05 19:27:23,774 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4443634333596988, 'Total loss': 0.4443634333596988} | train loss {'Reaction outcome loss': 0.14204806294553793, 'Total loss': 0.14204806294553793}
2022-12-05 19:27:23,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:23,775 INFO:     Epoch: 59
2022-12-05 19:27:24,568 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45545371384783223, 'Total loss': 0.45545371384783223} | train loss {'Reaction outcome loss': 0.14071186737492983, 'Total loss': 0.14071186737492983}
2022-12-05 19:27:24,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:24,569 INFO:     Epoch: 60
2022-12-05 19:27:25,365 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4506632098081437, 'Total loss': 0.4506632098081437} | train loss {'Reaction outcome loss': 0.14240764900815753, 'Total loss': 0.14240764900815753}
2022-12-05 19:27:25,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:25,365 INFO:     Epoch: 61
2022-12-05 19:27:26,157 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44842422973703255, 'Total loss': 0.44842422973703255} | train loss {'Reaction outcome loss': 0.14001183678784412, 'Total loss': 0.14001183678784412}
2022-12-05 19:27:26,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:26,157 INFO:     Epoch: 62
2022-12-05 19:27:26,956 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45670310814272275, 'Total loss': 0.45670310814272275} | train loss {'Reaction outcome loss': 0.13867995308840322, 'Total loss': 0.13867995308840322}
2022-12-05 19:27:26,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:26,956 INFO:     Epoch: 63
2022-12-05 19:27:27,754 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4595343116670847, 'Total loss': 0.4595343116670847} | train loss {'Reaction outcome loss': 0.14042205648564618, 'Total loss': 0.14042205648564618}
2022-12-05 19:27:27,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:27,754 INFO:     Epoch: 64
2022-12-05 19:27:28,556 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4581414698199792, 'Total loss': 0.4581414698199792} | train loss {'Reaction outcome loss': 0.13911417459971026, 'Total loss': 0.13911417459971026}
2022-12-05 19:27:28,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:28,556 INFO:     Epoch: 65
2022-12-05 19:27:29,358 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4597344476390969, 'Total loss': 0.4597344476390969} | train loss {'Reaction outcome loss': 0.14342809704543366, 'Total loss': 0.14342809704543366}
2022-12-05 19:27:29,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:29,358 INFO:     Epoch: 66
2022-12-05 19:27:30,156 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46866138956763526, 'Total loss': 0.46866138956763526} | train loss {'Reaction outcome loss': 0.1455716361680072, 'Total loss': 0.1455716361680072}
2022-12-05 19:27:30,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:30,156 INFO:     Epoch: 67
2022-12-05 19:27:30,955 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46069237420504744, 'Total loss': 0.46069237420504744} | train loss {'Reaction outcome loss': 0.13986039882608753, 'Total loss': 0.13986039882608753}
2022-12-05 19:27:30,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:30,955 INFO:     Epoch: 68
2022-12-05 19:27:31,753 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46468296579339285, 'Total loss': 0.46468296579339285} | train loss {'Reaction outcome loss': 0.14349327040346047, 'Total loss': 0.14349327040346047}
2022-12-05 19:27:31,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:31,754 INFO:     Epoch: 69
2022-12-05 19:27:32,543 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4699294990436597, 'Total loss': 0.4699294990436597} | train loss {'Reaction outcome loss': 0.1369783956442511, 'Total loss': 0.1369783956442511}
2022-12-05 19:27:32,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:32,544 INFO:     Epoch: 70
2022-12-05 19:27:33,327 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.448146010495045, 'Total loss': 0.448146010495045} | train loss {'Reaction outcome loss': 0.13676638940447255, 'Total loss': 0.13676638940447255}
2022-12-05 19:27:33,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:33,328 INFO:     Epoch: 71
2022-12-05 19:27:34,112 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46244691413911904, 'Total loss': 0.46244691413911904} | train loss {'Reaction outcome loss': 0.1381386119706428, 'Total loss': 0.1381386119706428}
2022-12-05 19:27:34,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:34,112 INFO:     Epoch: 72
2022-12-05 19:27:34,897 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45493045991117304, 'Total loss': 0.45493045991117304} | train loss {'Reaction outcome loss': 0.13456589900530302, 'Total loss': 0.13456589900530302}
2022-12-05 19:27:34,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:34,897 INFO:     Epoch: 73
2022-12-05 19:27:35,691 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45590251074595883, 'Total loss': 0.45590251074595883} | train loss {'Reaction outcome loss': 0.13415164541196728, 'Total loss': 0.13415164541196728}
2022-12-05 19:27:35,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:35,691 INFO:     Epoch: 74
2022-12-05 19:27:36,482 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4483675059269775, 'Total loss': 0.4483675059269775} | train loss {'Reaction outcome loss': 0.1335954615895293, 'Total loss': 0.1335954615895293}
2022-12-05 19:27:36,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:36,483 INFO:     Epoch: 75
2022-12-05 19:27:37,279 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44215069169347937, 'Total loss': 0.44215069169347937} | train loss {'Reaction outcome loss': 0.13247909415550982, 'Total loss': 0.13247909415550982}
2022-12-05 19:27:37,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:37,279 INFO:     Epoch: 76
2022-12-05 19:27:38,079 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46996316652406345, 'Total loss': 0.46996316652406345} | train loss {'Reaction outcome loss': 0.1328061254815715, 'Total loss': 0.1328061254815715}
2022-12-05 19:27:38,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:38,079 INFO:     Epoch: 77
2022-12-05 19:27:38,881 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4614852759987116, 'Total loss': 0.4614852759987116} | train loss {'Reaction outcome loss': 0.12892230670062094, 'Total loss': 0.12892230670062094}
2022-12-05 19:27:38,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:38,881 INFO:     Epoch: 78
2022-12-05 19:27:39,679 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46109291267665947, 'Total loss': 0.46109291267665947} | train loss {'Reaction outcome loss': 0.13165392167489176, 'Total loss': 0.13165392167489176}
2022-12-05 19:27:39,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:39,679 INFO:     Epoch: 79
2022-12-05 19:27:40,481 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46483840861103753, 'Total loss': 0.46483840861103753} | train loss {'Reaction outcome loss': 0.1305365991148992, 'Total loss': 0.1305365991148992}
2022-12-05 19:27:40,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:40,482 INFO:     Epoch: 80
2022-12-05 19:27:41,280 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45857340876351704, 'Total loss': 0.45857340876351704} | train loss {'Reaction outcome loss': 0.13109232881577754, 'Total loss': 0.13109232881577754}
2022-12-05 19:27:41,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:41,280 INFO:     Epoch: 81
2022-12-05 19:27:42,077 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4553531662307002, 'Total loss': 0.4553531662307002} | train loss {'Reaction outcome loss': 0.1309179540154211, 'Total loss': 0.1309179540154211}
2022-12-05 19:27:42,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:42,078 INFO:     Epoch: 82
2022-12-05 19:27:42,879 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45879710668867285, 'Total loss': 0.45879710668867285} | train loss {'Reaction outcome loss': 0.13051984207855485, 'Total loss': 0.13051984207855485}
2022-12-05 19:27:42,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:42,879 INFO:     Epoch: 83
2022-12-05 19:27:43,676 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4513931240547787, 'Total loss': 0.4513931240547787} | train loss {'Reaction outcome loss': 0.12840765249078362, 'Total loss': 0.12840765249078362}
2022-12-05 19:27:43,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:43,677 INFO:     Epoch: 84
2022-12-05 19:27:44,473 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4426868339492516, 'Total loss': 0.4426868339492516} | train loss {'Reaction outcome loss': 0.13036523401918199, 'Total loss': 0.13036523401918199}
2022-12-05 19:27:44,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:44,474 INFO:     Epoch: 85
2022-12-05 19:27:45,275 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.464087094434283, 'Total loss': 0.464087094434283} | train loss {'Reaction outcome loss': 0.12931871617039448, 'Total loss': 0.12931871617039448}
2022-12-05 19:27:45,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:45,275 INFO:     Epoch: 86
2022-12-05 19:27:46,079 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45164562592452223, 'Total loss': 0.45164562592452223} | train loss {'Reaction outcome loss': 0.13000509126096782, 'Total loss': 0.13000509126096782}
2022-12-05 19:27:46,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:46,079 INFO:     Epoch: 87
2022-12-05 19:27:46,883 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.449714855375615, 'Total loss': 0.449714855375615} | train loss {'Reaction outcome loss': 0.13006165778256862, 'Total loss': 0.13006165778256862}
2022-12-05 19:27:46,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:46,883 INFO:     Epoch: 88
2022-12-05 19:27:47,684 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45141547003930266, 'Total loss': 0.45141547003930266} | train loss {'Reaction outcome loss': 0.1296488814619615, 'Total loss': 0.1296488814619615}
2022-12-05 19:27:47,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:47,685 INFO:     Epoch: 89
2022-12-05 19:27:48,485 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45773665742440656, 'Total loss': 0.45773665742440656} | train loss {'Reaction outcome loss': 0.12751902887967193, 'Total loss': 0.12751902887967193}
2022-12-05 19:27:48,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:48,486 INFO:     Epoch: 90
2022-12-05 19:27:49,286 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4654514103789221, 'Total loss': 0.4654514103789221} | train loss {'Reaction outcome loss': 0.1298697065780701, 'Total loss': 0.1298697065780701}
2022-12-05 19:27:49,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:49,286 INFO:     Epoch: 91
2022-12-05 19:27:50,080 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4586082683368163, 'Total loss': 0.4586082683368163} | train loss {'Reaction outcome loss': 0.13373522028357152, 'Total loss': 0.13373522028357152}
2022-12-05 19:27:50,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:50,080 INFO:     Epoch: 92
2022-12-05 19:27:50,875 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4563072540543296, 'Total loss': 0.4563072540543296} | train loss {'Reaction outcome loss': 0.1262662185540777, 'Total loss': 0.1262662185540777}
2022-12-05 19:27:50,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:50,875 INFO:     Epoch: 93
2022-12-05 19:27:51,672 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45971915227445687, 'Total loss': 0.45971915227445687} | train loss {'Reaction outcome loss': 0.12472224188780012, 'Total loss': 0.12472224188780012}
2022-12-05 19:27:51,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:51,672 INFO:     Epoch: 94
2022-12-05 19:27:52,468 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4584916945208203, 'Total loss': 0.4584916945208203} | train loss {'Reaction outcome loss': 0.12556152783667948, 'Total loss': 0.12556152783667948}
2022-12-05 19:27:52,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:52,468 INFO:     Epoch: 95
2022-12-05 19:27:53,262 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.464575432240963, 'Total loss': 0.464575432240963} | train loss {'Reaction outcome loss': 0.1257121028597297, 'Total loss': 0.1257121028597297}
2022-12-05 19:27:53,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:53,262 INFO:     Epoch: 96
2022-12-05 19:27:54,059 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4545725042169744, 'Total loss': 0.4545725042169744} | train loss {'Reaction outcome loss': 0.1262828725718173, 'Total loss': 0.1262828725718173}
2022-12-05 19:27:54,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:54,059 INFO:     Epoch: 97
2022-12-05 19:27:54,853 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47708170725540683, 'Total loss': 0.47708170725540683} | train loss {'Reaction outcome loss': 0.12468384043407826, 'Total loss': 0.12468384043407826}
2022-12-05 19:27:54,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:54,854 INFO:     Epoch: 98
2022-12-05 19:27:55,655 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4525947513228113, 'Total loss': 0.4525947513228113} | train loss {'Reaction outcome loss': 0.12737268144604166, 'Total loss': 0.12737268144604166}
2022-12-05 19:27:55,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:55,655 INFO:     Epoch: 99
2022-12-05 19:27:56,452 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45573606105013326, 'Total loss': 0.45573606105013326} | train loss {'Reaction outcome loss': 0.12524414592637464, 'Total loss': 0.12524414592637464}
2022-12-05 19:27:56,452 INFO:     Best model found after epoch 18 of 100.
2022-12-05 19:27:56,452 INFO:   Done with stage: TRAINING
2022-12-05 19:27:56,452 INFO:   Starting stage: EVALUATION
2022-12-05 19:27:56,577 INFO:   Done with stage: EVALUATION
2022-12-05 19:27:56,578 INFO:   Leaving out SEQ value Fold_6
2022-12-05 19:27:56,590 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:27:56,590 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:27:57,236 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:27:57,237 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:27:57,306 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:27:57,307 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:27:57,307 INFO:     No hyperparam tuning for this model
2022-12-05 19:27:57,307 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:27:57,307 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:27:57,307 INFO:     None feature selector for col prot
2022-12-05 19:27:57,308 INFO:     None feature selector for col prot
2022-12-05 19:27:57,308 INFO:     None feature selector for col prot
2022-12-05 19:27:57,308 INFO:     None feature selector for col chem
2022-12-05 19:27:57,308 INFO:     None feature selector for col chem
2022-12-05 19:27:57,308 INFO:     None feature selector for col chem
2022-12-05 19:27:57,308 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:27:57,309 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:27:57,310 INFO:     Number of params in model 215821
2022-12-05 19:27:57,314 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:27:57,314 INFO:   Starting stage: TRAINING
2022-12-05 19:27:57,375 INFO:     Val loss before train {'Reaction outcome loss': 1.0128876783631064, 'Total loss': 1.0128876783631064}
2022-12-05 19:27:57,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:57,376 INFO:     Epoch: 0
2022-12-05 19:27:58,175 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5946800525892865, 'Total loss': 0.5946800525892865} | train loss {'Reaction outcome loss': 0.7976552422248548, 'Total loss': 0.7976552422248548}
2022-12-05 19:27:58,175 INFO:     Found new best model at epoch 0
2022-12-05 19:27:58,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:58,176 INFO:     Epoch: 1
2022-12-05 19:27:58,973 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5138499933210287, 'Total loss': 0.5138499933210287} | train loss {'Reaction outcome loss': 0.5445968354301106, 'Total loss': 0.5445968354301106}
2022-12-05 19:27:58,973 INFO:     Found new best model at epoch 1
2022-12-05 19:27:58,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:58,974 INFO:     Epoch: 2
2022-12-05 19:27:59,777 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.475298788737167, 'Total loss': 0.475298788737167} | train loss {'Reaction outcome loss': 0.4739035999462489, 'Total loss': 0.4739035999462489}
2022-12-05 19:27:59,777 INFO:     Found new best model at epoch 2
2022-12-05 19:27:59,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:27:59,778 INFO:     Epoch: 3
2022-12-05 19:28:00,577 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46306602927771484, 'Total loss': 0.46306602927771484} | train loss {'Reaction outcome loss': 0.4362434168015757, 'Total loss': 0.4362434168015757}
2022-12-05 19:28:00,577 INFO:     Found new best model at epoch 3
2022-12-05 19:28:00,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:00,578 INFO:     Epoch: 4
2022-12-05 19:28:01,375 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45318496091799304, 'Total loss': 0.45318496091799304} | train loss {'Reaction outcome loss': 0.40807174179222316, 'Total loss': 0.40807174179222316}
2022-12-05 19:28:01,375 INFO:     Found new best model at epoch 4
2022-12-05 19:28:01,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:01,376 INFO:     Epoch: 5
2022-12-05 19:28:02,174 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4446673139252446, 'Total loss': 0.4446673139252446} | train loss {'Reaction outcome loss': 0.3829046923426851, 'Total loss': 0.3829046923426851}
2022-12-05 19:28:02,174 INFO:     Found new best model at epoch 5
2022-12-05 19:28:02,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:02,175 INFO:     Epoch: 6
2022-12-05 19:28:02,975 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44810346039858734, 'Total loss': 0.44810346039858734} | train loss {'Reaction outcome loss': 0.3650310373594684, 'Total loss': 0.3650310373594684}
2022-12-05 19:28:02,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:02,975 INFO:     Epoch: 7
2022-12-05 19:28:03,777 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4306547313251279, 'Total loss': 0.4306547313251279} | train loss {'Reaction outcome loss': 0.348707057745947, 'Total loss': 0.348707057745947}
2022-12-05 19:28:03,777 INFO:     Found new best model at epoch 7
2022-12-05 19:28:03,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:03,778 INFO:     Epoch: 8
2022-12-05 19:28:04,574 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4330898997458545, 'Total loss': 0.4330898997458545} | train loss {'Reaction outcome loss': 0.33095678891385755, 'Total loss': 0.33095678891385755}
2022-12-05 19:28:04,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:04,575 INFO:     Epoch: 9
2022-12-05 19:28:05,371 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4371828999031674, 'Total loss': 0.4371828999031674} | train loss {'Reaction outcome loss': 0.3194369405748383, 'Total loss': 0.3194369405748383}
2022-12-05 19:28:05,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:05,371 INFO:     Epoch: 10
2022-12-05 19:28:06,168 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42950811406428163, 'Total loss': 0.42950811406428163} | train loss {'Reaction outcome loss': 0.30795289960599714, 'Total loss': 0.30795289960599714}
2022-12-05 19:28:06,168 INFO:     Found new best model at epoch 10
2022-12-05 19:28:06,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:06,169 INFO:     Epoch: 11
2022-12-05 19:28:06,964 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42618593912233005, 'Total loss': 0.42618593912233005} | train loss {'Reaction outcome loss': 0.29862684579265697, 'Total loss': 0.29862684579265697}
2022-12-05 19:28:06,965 INFO:     Found new best model at epoch 11
2022-12-05 19:28:06,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:06,966 INFO:     Epoch: 12
2022-12-05 19:28:07,765 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.432029647921974, 'Total loss': 0.432029647921974} | train loss {'Reaction outcome loss': 0.28686404249240316, 'Total loss': 0.28686404249240316}
2022-12-05 19:28:07,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:07,765 INFO:     Epoch: 13
2022-12-05 19:28:08,561 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42358511923389003, 'Total loss': 0.42358511923389003} | train loss {'Reaction outcome loss': 0.275040925780852, 'Total loss': 0.275040925780852}
2022-12-05 19:28:08,561 INFO:     Found new best model at epoch 13
2022-12-05 19:28:08,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:08,562 INFO:     Epoch: 14
2022-12-05 19:28:09,358 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4222766435281797, 'Total loss': 0.4222766435281797} | train loss {'Reaction outcome loss': 0.2652096129773605, 'Total loss': 0.2652096129773605}
2022-12-05 19:28:09,358 INFO:     Found new best model at epoch 14
2022-12-05 19:28:09,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:09,359 INFO:     Epoch: 15
2022-12-05 19:28:10,155 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4234420288015496, 'Total loss': 0.4234420288015496} | train loss {'Reaction outcome loss': 0.25783050534946306, 'Total loss': 0.25783050534946306}
2022-12-05 19:28:10,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:10,155 INFO:     Epoch: 16
2022-12-05 19:28:10,952 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4263955711979758, 'Total loss': 0.4263955711979758} | train loss {'Reaction outcome loss': 0.2528286956460966, 'Total loss': 0.2528286956460966}
2022-12-05 19:28:10,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:10,952 INFO:     Epoch: 17
2022-12-05 19:28:11,747 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4286316712810235, 'Total loss': 0.4286316712810235} | train loss {'Reaction outcome loss': 0.24569652322679758, 'Total loss': 0.24569652322679758}
2022-12-05 19:28:11,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:11,748 INFO:     Epoch: 18
2022-12-05 19:28:12,543 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4328294950114055, 'Total loss': 0.4328294950114055} | train loss {'Reaction outcome loss': 0.23906289455631086, 'Total loss': 0.23906289455631086}
2022-12-05 19:28:12,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:12,544 INFO:     Epoch: 19
2022-12-05 19:28:13,340 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43475430966778233, 'Total loss': 0.43475430966778233} | train loss {'Reaction outcome loss': 0.23407165348649986, 'Total loss': 0.23407165348649986}
2022-12-05 19:28:13,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:13,341 INFO:     Epoch: 20
2022-12-05 19:28:14,141 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42588987658646976, 'Total loss': 0.42588987658646976} | train loss {'Reaction outcome loss': 0.22648211041345231, 'Total loss': 0.22648211041345231}
2022-12-05 19:28:14,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:14,141 INFO:     Epoch: 21
2022-12-05 19:28:14,941 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4201921129768545, 'Total loss': 0.4201921129768545} | train loss {'Reaction outcome loss': 0.22364641030529334, 'Total loss': 0.22364641030529334}
2022-12-05 19:28:14,941 INFO:     Found new best model at epoch 21
2022-12-05 19:28:14,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:14,942 INFO:     Epoch: 22
2022-12-05 19:28:15,742 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4370674795725129, 'Total loss': 0.4370674795725129} | train loss {'Reaction outcome loss': 0.21805503573869506, 'Total loss': 0.21805503573869506}
2022-12-05 19:28:15,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:15,742 INFO:     Epoch: 23
2022-12-05 19:28:16,548 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42637342163784936, 'Total loss': 0.42637342163784936} | train loss {'Reaction outcome loss': 0.21219775217374967, 'Total loss': 0.21219775217374967}
2022-12-05 19:28:16,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:16,548 INFO:     Epoch: 24
2022-12-05 19:28:17,347 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4329113997519016, 'Total loss': 0.4329113997519016} | train loss {'Reaction outcome loss': 0.20769278167356406, 'Total loss': 0.20769278167356406}
2022-12-05 19:28:17,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:17,348 INFO:     Epoch: 25
2022-12-05 19:28:18,145 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4267508424818516, 'Total loss': 0.4267508424818516} | train loss {'Reaction outcome loss': 0.20429715164186013, 'Total loss': 0.20429715164186013}
2022-12-05 19:28:18,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:18,145 INFO:     Epoch: 26
2022-12-05 19:28:18,942 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4265908751298081, 'Total loss': 0.4265908751298081} | train loss {'Reaction outcome loss': 0.20044439568394615, 'Total loss': 0.20044439568394615}
2022-12-05 19:28:18,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:18,943 INFO:     Epoch: 27
2022-12-05 19:28:19,743 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43762498450550164, 'Total loss': 0.43762498450550164} | train loss {'Reaction outcome loss': 0.19861096574834758, 'Total loss': 0.19861096574834758}
2022-12-05 19:28:19,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:19,743 INFO:     Epoch: 28
2022-12-05 19:28:20,540 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4318420257080685, 'Total loss': 0.4318420257080685} | train loss {'Reaction outcome loss': 0.19225726598843693, 'Total loss': 0.19225726598843693}
2022-12-05 19:28:20,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:20,541 INFO:     Epoch: 29
2022-12-05 19:28:21,337 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43735937909646466, 'Total loss': 0.43735937909646466} | train loss {'Reaction outcome loss': 0.1912138559555094, 'Total loss': 0.1912138559555094}
2022-12-05 19:28:21,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:21,338 INFO:     Epoch: 30
2022-12-05 19:28:22,137 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4417923434891484, 'Total loss': 0.4417923434891484} | train loss {'Reaction outcome loss': 0.18531527869673747, 'Total loss': 0.18531527869673747}
2022-12-05 19:28:22,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:22,137 INFO:     Epoch: 31
2022-12-05 19:28:22,935 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43008717454292555, 'Total loss': 0.43008717454292555} | train loss {'Reaction outcome loss': 0.18296317642013873, 'Total loss': 0.18296317642013873}
2022-12-05 19:28:22,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:22,935 INFO:     Epoch: 32
2022-12-05 19:28:23,732 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4357614297081124, 'Total loss': 0.4357614297081124} | train loss {'Reaction outcome loss': 0.18062917770998133, 'Total loss': 0.18062917770998133}
2022-12-05 19:28:23,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:23,732 INFO:     Epoch: 33
2022-12-05 19:28:24,528 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.454607965932651, 'Total loss': 0.454607965932651} | train loss {'Reaction outcome loss': 0.18004338677612045, 'Total loss': 0.18004338677612045}
2022-12-05 19:28:24,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:24,528 INFO:     Epoch: 34
2022-12-05 19:28:25,324 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4497962583872405, 'Total loss': 0.4497962583872405} | train loss {'Reaction outcome loss': 0.17784259469068098, 'Total loss': 0.17784259469068098}
2022-12-05 19:28:25,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:25,325 INFO:     Epoch: 35
2022-12-05 19:28:26,126 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44313045184720645, 'Total loss': 0.44313045184720645} | train loss {'Reaction outcome loss': 0.17187976708725816, 'Total loss': 0.17187976708725816}
2022-12-05 19:28:26,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:26,126 INFO:     Epoch: 36
2022-12-05 19:28:26,922 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.437822348522869, 'Total loss': 0.437822348522869} | train loss {'Reaction outcome loss': 0.1723936396470714, 'Total loss': 0.1723936396470714}
2022-12-05 19:28:26,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:26,923 INFO:     Epoch: 37
2022-12-05 19:28:27,719 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4413244348358024, 'Total loss': 0.4413244348358024} | train loss {'Reaction outcome loss': 0.16993579747635992, 'Total loss': 0.16993579747635992}
2022-12-05 19:28:27,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:27,720 INFO:     Epoch: 38
2022-12-05 19:28:28,516 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4388563707470894, 'Total loss': 0.4388563707470894} | train loss {'Reaction outcome loss': 0.16796973170787696, 'Total loss': 0.16796973170787696}
2022-12-05 19:28:28,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:28,516 INFO:     Epoch: 39
2022-12-05 19:28:29,312 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44573476673527196, 'Total loss': 0.44573476673527196} | train loss {'Reaction outcome loss': 0.16453552285149212, 'Total loss': 0.16453552285149212}
2022-12-05 19:28:29,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:29,312 INFO:     Epoch: 40
2022-12-05 19:28:30,109 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42924070900136774, 'Total loss': 0.42924070900136774} | train loss {'Reaction outcome loss': 0.16032750546301325, 'Total loss': 0.16032750546301325}
2022-12-05 19:28:30,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:30,110 INFO:     Epoch: 41
2022-12-05 19:28:30,907 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4439249732954936, 'Total loss': 0.4439249732954936} | train loss {'Reaction outcome loss': 0.15812458906082377, 'Total loss': 0.15812458906082377}
2022-12-05 19:28:30,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:30,908 INFO:     Epoch: 42
2022-12-05 19:28:31,709 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4436608850955963, 'Total loss': 0.4436608850955963} | train loss {'Reaction outcome loss': 0.1608228671980361, 'Total loss': 0.1608228671980361}
2022-12-05 19:28:31,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:31,709 INFO:     Epoch: 43
2022-12-05 19:28:32,511 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4416909089142626, 'Total loss': 0.4416909089142626} | train loss {'Reaction outcome loss': 0.15619767536108772, 'Total loss': 0.15619767536108772}
2022-12-05 19:28:32,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:32,512 INFO:     Epoch: 44
2022-12-05 19:28:33,312 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4363675645806573, 'Total loss': 0.4363675645806573} | train loss {'Reaction outcome loss': 0.1534506220505723, 'Total loss': 0.1534506220505723}
2022-12-05 19:28:33,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:33,312 INFO:     Epoch: 45
2022-12-05 19:28:34,121 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4450616514818235, 'Total loss': 0.4450616514818235} | train loss {'Reaction outcome loss': 0.15567727435770776, 'Total loss': 0.15567727435770776}
2022-12-05 19:28:34,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:34,121 INFO:     Epoch: 46
2022-12-05 19:28:34,924 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4523416835476052, 'Total loss': 0.4523416835476052} | train loss {'Reaction outcome loss': 0.15435085763719172, 'Total loss': 0.15435085763719172}
2022-12-05 19:28:34,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:34,924 INFO:     Epoch: 47
2022-12-05 19:28:35,732 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45259651880372653, 'Total loss': 0.45259651880372653} | train loss {'Reaction outcome loss': 0.151681681366397, 'Total loss': 0.151681681366397}
2022-12-05 19:28:35,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:35,732 INFO:     Epoch: 48
2022-12-05 19:28:36,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45505862445993855, 'Total loss': 0.45505862445993855} | train loss {'Reaction outcome loss': 0.1509929639737933, 'Total loss': 0.1509929639737933}
2022-12-05 19:28:36,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:36,530 INFO:     Epoch: 49
2022-12-05 19:28:37,331 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4471237496896224, 'Total loss': 0.4471237496896224} | train loss {'Reaction outcome loss': 0.15078513047868206, 'Total loss': 0.15078513047868206}
2022-12-05 19:28:37,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:37,332 INFO:     Epoch: 50
2022-12-05 19:28:38,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4448813535273075, 'Total loss': 0.4448813535273075} | train loss {'Reaction outcome loss': 0.14773634037063008, 'Total loss': 0.14773634037063008}
2022-12-05 19:28:38,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:38,135 INFO:     Epoch: 51
2022-12-05 19:28:38,931 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45970706980336795, 'Total loss': 0.45970706980336795} | train loss {'Reaction outcome loss': 0.14987816190677544, 'Total loss': 0.14987816190677544}
2022-12-05 19:28:38,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:38,931 INFO:     Epoch: 52
2022-12-05 19:28:39,728 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44796618819236755, 'Total loss': 0.44796618819236755} | train loss {'Reaction outcome loss': 0.14493679585716418, 'Total loss': 0.14493679585716418}
2022-12-05 19:28:39,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:39,729 INFO:     Epoch: 53
2022-12-05 19:28:40,531 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43315474231812084, 'Total loss': 0.43315474231812084} | train loss {'Reaction outcome loss': 0.14700403385007033, 'Total loss': 0.14700403385007033}
2022-12-05 19:28:40,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:40,531 INFO:     Epoch: 54
2022-12-05 19:28:41,330 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4456596791066907, 'Total loss': 0.4456596791066907} | train loss {'Reaction outcome loss': 0.14458500332529506, 'Total loss': 0.14458500332529506}
2022-12-05 19:28:41,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:41,331 INFO:     Epoch: 55
2022-12-05 19:28:42,129 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4411396069282835, 'Total loss': 0.4411396069282835} | train loss {'Reaction outcome loss': 0.15037633094470948, 'Total loss': 0.15037633094470948}
2022-12-05 19:28:42,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:42,130 INFO:     Epoch: 56
2022-12-05 19:28:42,932 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44779996353794227, 'Total loss': 0.44779996353794227} | train loss {'Reaction outcome loss': 0.14292242723487078, 'Total loss': 0.14292242723487078}
2022-12-05 19:28:42,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:42,932 INFO:     Epoch: 57
2022-12-05 19:28:43,728 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44752771305766975, 'Total loss': 0.44752771305766975} | train loss {'Reaction outcome loss': 0.14452310170107072, 'Total loss': 0.14452310170107072}
2022-12-05 19:28:43,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:43,728 INFO:     Epoch: 58
2022-12-05 19:28:44,527 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.441858769479123, 'Total loss': 0.441858769479123} | train loss {'Reaction outcome loss': 0.14023693487228406, 'Total loss': 0.14023693487228406}
2022-12-05 19:28:44,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:44,528 INFO:     Epoch: 59
2022-12-05 19:28:45,324 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4438349316743287, 'Total loss': 0.4438349316743287} | train loss {'Reaction outcome loss': 0.13787931150140903, 'Total loss': 0.13787931150140903}
2022-12-05 19:28:45,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:45,324 INFO:     Epoch: 60
2022-12-05 19:28:46,126 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4420883956957947, 'Total loss': 0.4420883956957947} | train loss {'Reaction outcome loss': 0.1400675166345712, 'Total loss': 0.1400675166345712}
2022-12-05 19:28:46,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:46,126 INFO:     Epoch: 61
2022-12-05 19:28:46,923 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4502916315739805, 'Total loss': 0.4502916315739805} | train loss {'Reaction outcome loss': 0.1376612925856945, 'Total loss': 0.1376612925856945}
2022-12-05 19:28:46,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:46,923 INFO:     Epoch: 62
2022-12-05 19:28:47,720 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4393300586803393, 'Total loss': 0.4393300586803393} | train loss {'Reaction outcome loss': 0.13887259046802478, 'Total loss': 0.13887259046802478}
2022-12-05 19:28:47,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:47,721 INFO:     Epoch: 63
2022-12-05 19:28:48,518 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.431103299964558, 'Total loss': 0.431103299964558} | train loss {'Reaction outcome loss': 0.13717018157964753, 'Total loss': 0.13717018157964753}
2022-12-05 19:28:48,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:48,518 INFO:     Epoch: 64
2022-12-05 19:28:49,316 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4406950477172028, 'Total loss': 0.4406950477172028} | train loss {'Reaction outcome loss': 0.13559171048907429, 'Total loss': 0.13559171048907429}
2022-12-05 19:28:49,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:49,316 INFO:     Epoch: 65
2022-12-05 19:28:50,121 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44792310758070514, 'Total loss': 0.44792310758070514} | train loss {'Reaction outcome loss': 0.13643271882920677, 'Total loss': 0.13643271882920677}
2022-12-05 19:28:50,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:50,122 INFO:     Epoch: 66
2022-12-05 19:28:50,919 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45615073157982394, 'Total loss': 0.45615073157982394} | train loss {'Reaction outcome loss': 0.13512009159932215, 'Total loss': 0.13512009159932215}
2022-12-05 19:28:50,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:50,920 INFO:     Epoch: 67
2022-12-05 19:28:51,721 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4375371150672436, 'Total loss': 0.4375371150672436} | train loss {'Reaction outcome loss': 0.13416570375463174, 'Total loss': 0.13416570375463174}
2022-12-05 19:28:51,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:51,721 INFO:     Epoch: 68
2022-12-05 19:28:52,525 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45572550052946265, 'Total loss': 0.45572550052946265} | train loss {'Reaction outcome loss': 0.1323040937178678, 'Total loss': 0.1323040937178678}
2022-12-05 19:28:52,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:52,525 INFO:     Epoch: 69
2022-12-05 19:28:53,330 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4477918767793612, 'Total loss': 0.4477918767793612} | train loss {'Reaction outcome loss': 0.13131496029335163, 'Total loss': 0.13131496029335163}
2022-12-05 19:28:53,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:53,330 INFO:     Epoch: 70
2022-12-05 19:28:54,127 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43961647288365796, 'Total loss': 0.43961647288365796} | train loss {'Reaction outcome loss': 0.13425232422530592, 'Total loss': 0.13425232422530592}
2022-12-05 19:28:54,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:54,127 INFO:     Epoch: 71
2022-12-05 19:28:54,926 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45316432721235533, 'Total loss': 0.45316432721235533} | train loss {'Reaction outcome loss': 0.13144726332487358, 'Total loss': 0.13144726332487358}
2022-12-05 19:28:54,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:54,926 INFO:     Epoch: 72
2022-12-05 19:28:55,722 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45339481871236453, 'Total loss': 0.45339481871236453} | train loss {'Reaction outcome loss': 0.13321641211458032, 'Total loss': 0.13321641211458032}
2022-12-05 19:28:55,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:55,723 INFO:     Epoch: 73
2022-12-05 19:28:56,521 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4573500799861821, 'Total loss': 0.4573500799861821} | train loss {'Reaction outcome loss': 0.12946395486623288, 'Total loss': 0.12946395486623288}
2022-12-05 19:28:56,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:56,522 INFO:     Epoch: 74
2022-12-05 19:28:57,319 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44135143726386805, 'Total loss': 0.44135143726386805} | train loss {'Reaction outcome loss': 0.1295268214457939, 'Total loss': 0.1295268214457939}
2022-12-05 19:28:57,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:57,320 INFO:     Epoch: 75
2022-12-05 19:28:58,116 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44864804670214653, 'Total loss': 0.44864804670214653} | train loss {'Reaction outcome loss': 0.1314556383276208, 'Total loss': 0.1314556383276208}
2022-12-05 19:28:58,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:58,116 INFO:     Epoch: 76
2022-12-05 19:28:58,919 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.434958989308639, 'Total loss': 0.434958989308639} | train loss {'Reaction outcome loss': 0.1267752788637975, 'Total loss': 0.1267752788637975}
2022-12-05 19:28:58,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:58,919 INFO:     Epoch: 77
2022-12-05 19:28:59,716 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45532193915410474, 'Total loss': 0.45532193915410474} | train loss {'Reaction outcome loss': 0.12845290785715466, 'Total loss': 0.12845290785715466}
2022-12-05 19:28:59,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:28:59,717 INFO:     Epoch: 78
2022-12-05 19:29:00,519 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4497405883263458, 'Total loss': 0.4497405883263458} | train loss {'Reaction outcome loss': 0.12771703508276974, 'Total loss': 0.12771703508276974}
2022-12-05 19:29:00,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:00,519 INFO:     Epoch: 79
2022-12-05 19:29:01,319 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4544258476658301, 'Total loss': 0.4544258476658301} | train loss {'Reaction outcome loss': 0.12893442803573224, 'Total loss': 0.12893442803573224}
2022-12-05 19:29:01,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:01,319 INFO:     Epoch: 80
2022-12-05 19:29:02,118 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4376065344973044, 'Total loss': 0.4376065344973044} | train loss {'Reaction outcome loss': 0.12859687591046695, 'Total loss': 0.12859687591046695}
2022-12-05 19:29:02,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:02,119 INFO:     Epoch: 81
2022-12-05 19:29:02,917 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44588670337742026, 'Total loss': 0.44588670337742026} | train loss {'Reaction outcome loss': 0.12541569188808002, 'Total loss': 0.12541569188808002}
2022-12-05 19:29:02,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:02,917 INFO:     Epoch: 82
2022-12-05 19:29:03,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43501447564498946, 'Total loss': 0.43501447564498946} | train loss {'Reaction outcome loss': 0.1269797860389395, 'Total loss': 0.1269797860389395}
2022-12-05 19:29:03,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:03,716 INFO:     Epoch: 83
2022-12-05 19:29:04,510 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4398764065382155, 'Total loss': 0.4398764065382155} | train loss {'Reaction outcome loss': 0.12488086591850245, 'Total loss': 0.12488086591850245}
2022-12-05 19:29:04,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:04,511 INFO:     Epoch: 84
2022-12-05 19:29:05,305 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4533456875519319, 'Total loss': 0.4533456875519319} | train loss {'Reaction outcome loss': 0.12627111999843751, 'Total loss': 0.12627111999843751}
2022-12-05 19:29:05,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:05,306 INFO:     Epoch: 85
2022-12-05 19:29:06,100 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44314841621301393, 'Total loss': 0.44314841621301393} | train loss {'Reaction outcome loss': 0.12623946521536358, 'Total loss': 0.12623946521536358}
2022-12-05 19:29:06,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:06,100 INFO:     Epoch: 86
2022-12-05 19:29:06,895 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43765307421034033, 'Total loss': 0.43765307421034033} | train loss {'Reaction outcome loss': 0.12930720223249087, 'Total loss': 0.12930720223249087}
2022-12-05 19:29:06,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:06,896 INFO:     Epoch: 87
2022-12-05 19:29:07,690 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44952886111356993, 'Total loss': 0.44952886111356993} | train loss {'Reaction outcome loss': 0.12597390557564195, 'Total loss': 0.12597390557564195}
2022-12-05 19:29:07,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:07,691 INFO:     Epoch: 88
2022-12-05 19:29:08,492 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44208479300141335, 'Total loss': 0.44208479300141335} | train loss {'Reaction outcome loss': 0.12372316193256166, 'Total loss': 0.12372316193256166}
2022-12-05 19:29:08,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:08,493 INFO:     Epoch: 89
2022-12-05 19:29:09,294 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4453293372961608, 'Total loss': 0.4453293372961608} | train loss {'Reaction outcome loss': 0.12274658168861342, 'Total loss': 0.12274658168861342}
2022-12-05 19:29:09,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:09,295 INFO:     Epoch: 90
2022-12-05 19:29:10,096 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45303511890498077, 'Total loss': 0.45303511890498077} | train loss {'Reaction outcome loss': 0.12383964943188813, 'Total loss': 0.12383964943188813}
2022-12-05 19:29:10,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:10,097 INFO:     Epoch: 91
2022-12-05 19:29:10,894 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4464817229997028, 'Total loss': 0.4464817229997028} | train loss {'Reaction outcome loss': 0.12391407384477075, 'Total loss': 0.12391407384477075}
2022-12-05 19:29:10,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:10,894 INFO:     Epoch: 92
2022-12-05 19:29:11,696 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45626877214420924, 'Total loss': 0.45626877214420924} | train loss {'Reaction outcome loss': 0.12200980479153054, 'Total loss': 0.12200980479153054}
2022-12-05 19:29:11,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:11,696 INFO:     Epoch: 93
2022-12-05 19:29:12,495 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4360905911096118, 'Total loss': 0.4360905911096118} | train loss {'Reaction outcome loss': 0.11991812879099481, 'Total loss': 0.11991812879099481}
2022-12-05 19:29:12,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:12,495 INFO:     Epoch: 94
2022-12-05 19:29:13,292 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44922621666707774, 'Total loss': 0.44922621666707774} | train loss {'Reaction outcome loss': 0.12128664759333216, 'Total loss': 0.12128664759333216}
2022-12-05 19:29:13,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:13,292 INFO:     Epoch: 95
2022-12-05 19:29:14,092 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44998385858806694, 'Total loss': 0.44998385858806694} | train loss {'Reaction outcome loss': 0.12147190809933349, 'Total loss': 0.12147190809933349}
2022-12-05 19:29:14,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:14,092 INFO:     Epoch: 96
2022-12-05 19:29:14,895 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4421915618533438, 'Total loss': 0.4421915618533438} | train loss {'Reaction outcome loss': 0.11862326689785527, 'Total loss': 0.11862326689785527}
2022-12-05 19:29:14,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:14,895 INFO:     Epoch: 97
2022-12-05 19:29:15,693 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45199313827536325, 'Total loss': 0.45199313827536325} | train loss {'Reaction outcome loss': 0.11788618602534576, 'Total loss': 0.11788618602534576}
2022-12-05 19:29:15,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:15,693 INFO:     Epoch: 98
2022-12-05 19:29:16,491 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4486682347275994, 'Total loss': 0.4486682347275994} | train loss {'Reaction outcome loss': 0.1234017153601012, 'Total loss': 0.1234017153601012}
2022-12-05 19:29:16,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:16,491 INFO:     Epoch: 99
2022-12-05 19:29:17,287 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4494212107224898, 'Total loss': 0.4494212107224898} | train loss {'Reaction outcome loss': 0.11894161428415007, 'Total loss': 0.11894161428415007}
2022-12-05 19:29:17,287 INFO:     Best model found after epoch 22 of 100.
2022-12-05 19:29:17,288 INFO:   Done with stage: TRAINING
2022-12-05 19:29:17,288 INFO:   Starting stage: EVALUATION
2022-12-05 19:29:17,408 INFO:   Done with stage: EVALUATION
2022-12-05 19:29:17,408 INFO:   Leaving out SEQ value Fold_7
2022-12-05 19:29:17,421 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:29:17,421 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:29:18,071 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:29:18,072 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:29:18,141 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:29:18,141 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:29:18,141 INFO:     No hyperparam tuning for this model
2022-12-05 19:29:18,141 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:29:18,141 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:29:18,142 INFO:     None feature selector for col prot
2022-12-05 19:29:18,142 INFO:     None feature selector for col prot
2022-12-05 19:29:18,142 INFO:     None feature selector for col prot
2022-12-05 19:29:18,143 INFO:     None feature selector for col chem
2022-12-05 19:29:18,143 INFO:     None feature selector for col chem
2022-12-05 19:29:18,143 INFO:     None feature selector for col chem
2022-12-05 19:29:18,144 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:29:18,144 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:29:18,145 INFO:     Number of params in model 215821
2022-12-05 19:29:18,149 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:29:18,149 INFO:   Starting stage: TRAINING
2022-12-05 19:29:18,211 INFO:     Val loss before train {'Reaction outcome loss': 1.0177176215431907, 'Total loss': 1.0177176215431907}
2022-12-05 19:29:18,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:18,211 INFO:     Epoch: 0
2022-12-05 19:29:19,012 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6215131448751147, 'Total loss': 0.6215131448751147} | train loss {'Reaction outcome loss': 0.7992555710226901, 'Total loss': 0.7992555710226901}
2022-12-05 19:29:19,012 INFO:     Found new best model at epoch 0
2022-12-05 19:29:19,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:19,013 INFO:     Epoch: 1
2022-12-05 19:29:19,815 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5410888310183178, 'Total loss': 0.5410888310183178} | train loss {'Reaction outcome loss': 0.5372371548703807, 'Total loss': 0.5372371548703807}
2022-12-05 19:29:19,815 INFO:     Found new best model at epoch 1
2022-12-05 19:29:19,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:19,816 INFO:     Epoch: 2
2022-12-05 19:29:20,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5007519220763986, 'Total loss': 0.5007519220763986} | train loss {'Reaction outcome loss': 0.4647044756823042, 'Total loss': 0.4647044756823042}
2022-12-05 19:29:20,611 INFO:     Found new best model at epoch 2
2022-12-05 19:29:20,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:20,612 INFO:     Epoch: 3
2022-12-05 19:29:21,406 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48571284183047037, 'Total loss': 0.48571284183047037} | train loss {'Reaction outcome loss': 0.4277386944703305, 'Total loss': 0.4277386944703305}
2022-12-05 19:29:21,407 INFO:     Found new best model at epoch 3
2022-12-05 19:29:21,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:21,408 INFO:     Epoch: 4
2022-12-05 19:29:22,202 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46969943087209354, 'Total loss': 0.46969943087209354} | train loss {'Reaction outcome loss': 0.3966385809561381, 'Total loss': 0.3966385809561381}
2022-12-05 19:29:22,203 INFO:     Found new best model at epoch 4
2022-12-05 19:29:22,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:22,204 INFO:     Epoch: 5
2022-12-05 19:29:23,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4507070336152207, 'Total loss': 0.4507070336152207} | train loss {'Reaction outcome loss': 0.3781850449590065, 'Total loss': 0.3781850449590065}
2022-12-05 19:29:23,001 INFO:     Found new best model at epoch 5
2022-12-05 19:29:23,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:23,002 INFO:     Epoch: 6
2022-12-05 19:29:23,801 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4399217042055997, 'Total loss': 0.4399217042055997} | train loss {'Reaction outcome loss': 0.3580561257024043, 'Total loss': 0.3580561257024043}
2022-12-05 19:29:23,801 INFO:     Found new best model at epoch 6
2022-12-05 19:29:23,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:23,802 INFO:     Epoch: 7
2022-12-05 19:29:24,596 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43611055544831534, 'Total loss': 0.43611055544831534} | train loss {'Reaction outcome loss': 0.33778784742299844, 'Total loss': 0.33778784742299844}
2022-12-05 19:29:24,596 INFO:     Found new best model at epoch 7
2022-12-05 19:29:24,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:24,597 INFO:     Epoch: 8
2022-12-05 19:29:25,392 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4426391073925929, 'Total loss': 0.4426391073925929} | train loss {'Reaction outcome loss': 0.322959894080635, 'Total loss': 0.322959894080635}
2022-12-05 19:29:25,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:25,392 INFO:     Epoch: 9
2022-12-05 19:29:26,189 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4345742447132414, 'Total loss': 0.4345742447132414} | train loss {'Reaction outcome loss': 0.31167118809363137, 'Total loss': 0.31167118809363137}
2022-12-05 19:29:26,189 INFO:     Found new best model at epoch 9
2022-12-05 19:29:26,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:26,190 INFO:     Epoch: 10
2022-12-05 19:29:26,984 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43551813980395143, 'Total loss': 0.43551813980395143} | train loss {'Reaction outcome loss': 0.2987879018189936, 'Total loss': 0.2987879018189936}
2022-12-05 19:29:26,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:26,985 INFO:     Epoch: 11
2022-12-05 19:29:27,779 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42706960439682007, 'Total loss': 0.42706960439682007} | train loss {'Reaction outcome loss': 0.2876272775941653, 'Total loss': 0.2876272775941653}
2022-12-05 19:29:27,780 INFO:     Found new best model at epoch 11
2022-12-05 19:29:27,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:27,781 INFO:     Epoch: 12
2022-12-05 19:29:28,576 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43202331323515286, 'Total loss': 0.43202331323515286} | train loss {'Reaction outcome loss': 0.2732230847784382, 'Total loss': 0.2732230847784382}
2022-12-05 19:29:28,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:28,576 INFO:     Epoch: 13
2022-12-05 19:29:29,370 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4226413182914257, 'Total loss': 0.4226413182914257} | train loss {'Reaction outcome loss': 0.26361133185354807, 'Total loss': 0.26361133185354807}
2022-12-05 19:29:29,370 INFO:     Found new best model at epoch 13
2022-12-05 19:29:29,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:29,371 INFO:     Epoch: 14
2022-12-05 19:29:30,166 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4114619358019395, 'Total loss': 0.4114619358019395} | train loss {'Reaction outcome loss': 0.25661540034449537, 'Total loss': 0.25661540034449537}
2022-12-05 19:29:30,166 INFO:     Found new best model at epoch 14
2022-12-05 19:29:30,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:30,167 INFO:     Epoch: 15
2022-12-05 19:29:30,967 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42377803373065864, 'Total loss': 0.42377803373065864} | train loss {'Reaction outcome loss': 0.2526571586924164, 'Total loss': 0.2526571586924164}
2022-12-05 19:29:30,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:30,967 INFO:     Epoch: 16
2022-12-05 19:29:31,761 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4151685935529796, 'Total loss': 0.4151685935529796} | train loss {'Reaction outcome loss': 0.24399834527419165, 'Total loss': 0.24399834527419165}
2022-12-05 19:29:31,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:31,761 INFO:     Epoch: 17
2022-12-05 19:29:32,558 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4239276217466051, 'Total loss': 0.4239276217466051} | train loss {'Reaction outcome loss': 0.23735908871358222, 'Total loss': 0.23735908871358222}
2022-12-05 19:29:32,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:32,558 INFO:     Epoch: 18
2022-12-05 19:29:33,352 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41408191892233764, 'Total loss': 0.41408191892233764} | train loss {'Reaction outcome loss': 0.22819377978517097, 'Total loss': 0.22819377978517097}
2022-12-05 19:29:33,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:33,352 INFO:     Epoch: 19
2022-12-05 19:29:34,155 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4233684800565243, 'Total loss': 0.4233684800565243} | train loss {'Reaction outcome loss': 0.2233332760089081, 'Total loss': 0.2233332760089081}
2022-12-05 19:29:34,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:34,156 INFO:     Epoch: 20
2022-12-05 19:29:34,949 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42245275019244716, 'Total loss': 0.42245275019244716} | train loss {'Reaction outcome loss': 0.2181406484894183, 'Total loss': 0.2181406484894183}
2022-12-05 19:29:34,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:34,950 INFO:     Epoch: 21
2022-12-05 19:29:35,744 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4114790287884799, 'Total loss': 0.4114790287884799} | train loss {'Reaction outcome loss': 0.2149751425121236, 'Total loss': 0.2149751425121236}
2022-12-05 19:29:35,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:35,744 INFO:     Epoch: 22
2022-12-05 19:29:36,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4255659631030126, 'Total loss': 0.4255659631030126} | train loss {'Reaction outcome loss': 0.206574470543789, 'Total loss': 0.206574470543789}
2022-12-05 19:29:36,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:36,543 INFO:     Epoch: 23
2022-12-05 19:29:37,341 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4092426293275573, 'Total loss': 0.4092426293275573} | train loss {'Reaction outcome loss': 0.20182518799777938, 'Total loss': 0.20182518799777938}
2022-12-05 19:29:37,341 INFO:     Found new best model at epoch 23
2022-12-05 19:29:37,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:37,342 INFO:     Epoch: 24
2022-12-05 19:29:38,143 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4158387397500602, 'Total loss': 0.4158387397500602} | train loss {'Reaction outcome loss': 0.19969270449237303, 'Total loss': 0.19969270449237303}
2022-12-05 19:29:38,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:38,143 INFO:     Epoch: 25
2022-12-05 19:29:38,945 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.423691539644179, 'Total loss': 0.423691539644179} | train loss {'Reaction outcome loss': 0.1990351465941682, 'Total loss': 0.1990351465941682}
2022-12-05 19:29:38,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:38,946 INFO:     Epoch: 26
2022-12-05 19:29:39,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4015452401204543, 'Total loss': 0.4015452401204543} | train loss {'Reaction outcome loss': 0.19544549960537477, 'Total loss': 0.19544549960537477}
2022-12-05 19:29:39,745 INFO:     Found new best model at epoch 26
2022-12-05 19:29:39,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:39,746 INFO:     Epoch: 27
2022-12-05 19:29:40,555 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4073255124755881, 'Total loss': 0.4073255124755881} | train loss {'Reaction outcome loss': 0.18848325120217282, 'Total loss': 0.18848325120217282}
2022-12-05 19:29:40,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:40,556 INFO:     Epoch: 28
2022-12-05 19:29:41,359 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4204768240451813, 'Total loss': 0.4204768240451813} | train loss {'Reaction outcome loss': 0.1850127168150566, 'Total loss': 0.1850127168150566}
2022-12-05 19:29:41,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:41,360 INFO:     Epoch: 29
2022-12-05 19:29:42,164 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43206032839688385, 'Total loss': 0.43206032839688385} | train loss {'Reaction outcome loss': 0.18180814982101562, 'Total loss': 0.18180814982101562}
2022-12-05 19:29:42,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:42,164 INFO:     Epoch: 30
2022-12-05 19:29:42,968 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42026563733816147, 'Total loss': 0.42026563733816147} | train loss {'Reaction outcome loss': 0.17940328353726087, 'Total loss': 0.17940328353726087}
2022-12-05 19:29:42,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:42,968 INFO:     Epoch: 31
2022-12-05 19:29:43,769 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4263736520978538, 'Total loss': 0.4263736520978538} | train loss {'Reaction outcome loss': 0.176393309623184, 'Total loss': 0.176393309623184}
2022-12-05 19:29:43,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:43,769 INFO:     Epoch: 32
2022-12-05 19:29:44,566 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40844274921850726, 'Total loss': 0.40844274921850726} | train loss {'Reaction outcome loss': 0.1749677066832615, 'Total loss': 0.1749677066832615}
2022-12-05 19:29:44,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:44,566 INFO:     Epoch: 33
2022-12-05 19:29:45,365 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40711706334894354, 'Total loss': 0.40711706334894354} | train loss {'Reaction outcome loss': 0.1745034884736847, 'Total loss': 0.1745034884736847}
2022-12-05 19:29:45,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:45,365 INFO:     Epoch: 34
2022-12-05 19:29:46,165 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42515259117565374, 'Total loss': 0.42515259117565374} | train loss {'Reaction outcome loss': 0.17637226793930116, 'Total loss': 0.17637226793930116}
2022-12-05 19:29:46,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:46,165 INFO:     Epoch: 35
2022-12-05 19:29:46,964 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41128512810577045, 'Total loss': 0.41128512810577045} | train loss {'Reaction outcome loss': 0.17121975653265653, 'Total loss': 0.17121975653265653}
2022-12-05 19:29:46,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:46,964 INFO:     Epoch: 36
2022-12-05 19:29:47,767 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41181442547928204, 'Total loss': 0.41181442547928204} | train loss {'Reaction outcome loss': 0.16808046700681753, 'Total loss': 0.16808046700681753}
2022-12-05 19:29:47,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:47,767 INFO:     Epoch: 37
2022-12-05 19:29:48,565 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41671734574166214, 'Total loss': 0.41671734574166214} | train loss {'Reaction outcome loss': 0.16275647733556597, 'Total loss': 0.16275647733556597}
2022-12-05 19:29:48,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:48,566 INFO:     Epoch: 38
2022-12-05 19:29:49,361 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4285779583521865, 'Total loss': 0.4285779583521865} | train loss {'Reaction outcome loss': 0.16009012518096188, 'Total loss': 0.16009012518096188}
2022-12-05 19:29:49,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:49,362 INFO:     Epoch: 39
2022-12-05 19:29:50,162 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4076602039012042, 'Total loss': 0.4076602039012042} | train loss {'Reaction outcome loss': 0.16303137789371042, 'Total loss': 0.16303137789371042}
2022-12-05 19:29:50,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:50,162 INFO:     Epoch: 40
2022-12-05 19:29:50,961 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42520493878559634, 'Total loss': 0.42520493878559634} | train loss {'Reaction outcome loss': 0.16604359905699245, 'Total loss': 0.16604359905699245}
2022-12-05 19:29:50,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:50,961 INFO:     Epoch: 41
2022-12-05 19:29:51,762 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4140342716127634, 'Total loss': 0.4140342716127634} | train loss {'Reaction outcome loss': 0.1613243385604564, 'Total loss': 0.1613243385604564}
2022-12-05 19:29:51,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:51,762 INFO:     Epoch: 42
2022-12-05 19:29:52,564 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41059250926429575, 'Total loss': 0.41059250926429575} | train loss {'Reaction outcome loss': 0.1531634715617623, 'Total loss': 0.1531634715617623}
2022-12-05 19:29:52,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:52,564 INFO:     Epoch: 43
2022-12-05 19:29:53,362 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4221772053702311, 'Total loss': 0.4221772053702311} | train loss {'Reaction outcome loss': 0.15340775382603228, 'Total loss': 0.15340775382603228}
2022-12-05 19:29:53,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:53,363 INFO:     Epoch: 44
2022-12-05 19:29:54,167 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42806360531936993, 'Total loss': 0.42806360531936993} | train loss {'Reaction outcome loss': 0.15036159768127477, 'Total loss': 0.15036159768127477}
2022-12-05 19:29:54,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:54,167 INFO:     Epoch: 45
2022-12-05 19:29:54,972 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4184633171693845, 'Total loss': 0.4184633171693845} | train loss {'Reaction outcome loss': 0.15612669617902894, 'Total loss': 0.15612669617902894}
2022-12-05 19:29:54,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:54,972 INFO:     Epoch: 46
2022-12-05 19:29:55,772 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4170457808808847, 'Total loss': 0.4170457808808847} | train loss {'Reaction outcome loss': 0.14927501979317923, 'Total loss': 0.14927501979317923}
2022-12-05 19:29:55,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:55,772 INFO:     Epoch: 47
2022-12-05 19:29:56,573 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44169768335467036, 'Total loss': 0.44169768335467036} | train loss {'Reaction outcome loss': 0.15159574712472043, 'Total loss': 0.15159574712472043}
2022-12-05 19:29:56,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:56,573 INFO:     Epoch: 48
2022-12-05 19:29:57,379 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4148787656290965, 'Total loss': 0.4148787656290965} | train loss {'Reaction outcome loss': 0.14863155145379092, 'Total loss': 0.14863155145379092}
2022-12-05 19:29:57,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:57,379 INFO:     Epoch: 49
2022-12-05 19:29:58,186 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4201040613380345, 'Total loss': 0.4201040613380345} | train loss {'Reaction outcome loss': 0.14880126315029527, 'Total loss': 0.14880126315029527}
2022-12-05 19:29:58,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:58,186 INFO:     Epoch: 50
2022-12-05 19:29:58,993 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.419784506613558, 'Total loss': 0.419784506613558} | train loss {'Reaction outcome loss': 0.14501851022635637, 'Total loss': 0.14501851022635637}
2022-12-05 19:29:58,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:58,993 INFO:     Epoch: 51
2022-12-05 19:29:59,797 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4238278113982894, 'Total loss': 0.4238278113982894} | train loss {'Reaction outcome loss': 0.14300772954986962, 'Total loss': 0.14300772954986962}
2022-12-05 19:29:59,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:29:59,798 INFO:     Epoch: 52
2022-12-05 19:30:00,610 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43509038402275607, 'Total loss': 0.43509038402275607} | train loss {'Reaction outcome loss': 0.13886041486417114, 'Total loss': 0.13886041486417114}
2022-12-05 19:30:00,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:00,610 INFO:     Epoch: 53
2022-12-05 19:30:01,434 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4255856309424747, 'Total loss': 0.4255856309424747} | train loss {'Reaction outcome loss': 0.1413650252867626, 'Total loss': 0.1413650252867626}
2022-12-05 19:30:01,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:01,434 INFO:     Epoch: 54
2022-12-05 19:30:02,233 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4167697250165723, 'Total loss': 0.4167697250165723} | train loss {'Reaction outcome loss': 0.1397367566484611, 'Total loss': 0.1397367566484611}
2022-12-05 19:30:02,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:02,234 INFO:     Epoch: 55
2022-12-05 19:30:03,034 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4222530656578866, 'Total loss': 0.4222530656578866} | train loss {'Reaction outcome loss': 0.14748141737767922, 'Total loss': 0.14748141737767922}
2022-12-05 19:30:03,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:03,034 INFO:     Epoch: 56
2022-12-05 19:30:03,834 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4191562944853848, 'Total loss': 0.4191562944853848} | train loss {'Reaction outcome loss': 0.15532222598119966, 'Total loss': 0.15532222598119966}
2022-12-05 19:30:03,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:03,834 INFO:     Epoch: 57
2022-12-05 19:30:04,634 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4347946540537206, 'Total loss': 0.4347946540537206} | train loss {'Reaction outcome loss': 0.14040683483472094, 'Total loss': 0.14040683483472094}
2022-12-05 19:30:04,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:04,634 INFO:     Epoch: 58
2022-12-05 19:30:05,433 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4208597063340924, 'Total loss': 0.4208597063340924} | train loss {'Reaction outcome loss': 0.13658635723989018, 'Total loss': 0.13658635723989018}
2022-12-05 19:30:05,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:05,434 INFO:     Epoch: 59
2022-12-05 19:30:06,234 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4170210088433867, 'Total loss': 0.4170210088433867} | train loss {'Reaction outcome loss': 0.1391878673233665, 'Total loss': 0.1391878673233665}
2022-12-05 19:30:06,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:06,234 INFO:     Epoch: 60
2022-12-05 19:30:07,033 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4448077800599011, 'Total loss': 0.4448077800599011} | train loss {'Reaction outcome loss': 0.1318950731063833, 'Total loss': 0.1318950731063833}
2022-12-05 19:30:07,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:07,033 INFO:     Epoch: 61
2022-12-05 19:30:07,831 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4170529334382577, 'Total loss': 0.4170529334382577} | train loss {'Reaction outcome loss': 0.13264052844738308, 'Total loss': 0.13264052844738308}
2022-12-05 19:30:07,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:07,831 INFO:     Epoch: 62
2022-12-05 19:30:08,627 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40728597647764464, 'Total loss': 0.40728597647764464} | train loss {'Reaction outcome loss': 0.13108881588587876, 'Total loss': 0.13108881588587876}
2022-12-05 19:30:08,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:08,627 INFO:     Epoch: 63
2022-12-05 19:30:09,426 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44580497000027786, 'Total loss': 0.44580497000027786} | train loss {'Reaction outcome loss': 0.13460882235533342, 'Total loss': 0.13460882235533342}
2022-12-05 19:30:09,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:09,427 INFO:     Epoch: 64
2022-12-05 19:30:10,231 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41945122385566885, 'Total loss': 0.41945122385566885} | train loss {'Reaction outcome loss': 0.13166257944184276, 'Total loss': 0.13166257944184276}
2022-12-05 19:30:10,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:10,231 INFO:     Epoch: 65
2022-12-05 19:30:11,035 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41493745732375165, 'Total loss': 0.41493745732375165} | train loss {'Reaction outcome loss': 0.1339276666448523, 'Total loss': 0.1339276666448523}
2022-12-05 19:30:11,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:11,035 INFO:     Epoch: 66
2022-12-05 19:30:11,831 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4172281077639623, 'Total loss': 0.4172281077639623} | train loss {'Reaction outcome loss': 0.1298312109702753, 'Total loss': 0.1298312109702753}
2022-12-05 19:30:11,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:11,832 INFO:     Epoch: 67
2022-12-05 19:30:12,631 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42958301508968527, 'Total loss': 0.42958301508968527} | train loss {'Reaction outcome loss': 0.13038828962403332, 'Total loss': 0.13038828962403332}
2022-12-05 19:30:12,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:12,632 INFO:     Epoch: 68
2022-12-05 19:30:13,428 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43428275031460956, 'Total loss': 0.43428275031460956} | train loss {'Reaction outcome loss': 0.13180535027252036, 'Total loss': 0.13180535027252036}
2022-12-05 19:30:13,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:13,429 INFO:     Epoch: 69
2022-12-05 19:30:14,227 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4269821616736325, 'Total loss': 0.4269821616736325} | train loss {'Reaction outcome loss': 0.12887779087476764, 'Total loss': 0.12887779087476764}
2022-12-05 19:30:14,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:14,228 INFO:     Epoch: 70
2022-12-05 19:30:15,026 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41984776813875546, 'Total loss': 0.41984776813875546} | train loss {'Reaction outcome loss': 0.12572489844763327, 'Total loss': 0.12572489844763327}
2022-12-05 19:30:15,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:15,026 INFO:     Epoch: 71
2022-12-05 19:30:15,827 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4212078198113225, 'Total loss': 0.4212078198113225} | train loss {'Reaction outcome loss': 0.1281251967545252, 'Total loss': 0.1281251967545252}
2022-12-05 19:30:15,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:15,828 INFO:     Epoch: 72
2022-12-05 19:30:16,623 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4228749784048308, 'Total loss': 0.4228749784048308} | train loss {'Reaction outcome loss': 0.12992714390324556, 'Total loss': 0.12992714390324556}
2022-12-05 19:30:16,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:16,623 INFO:     Epoch: 73
2022-12-05 19:30:17,418 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4333444627171213, 'Total loss': 0.4333444627171213} | train loss {'Reaction outcome loss': 0.13188666966460977, 'Total loss': 0.13188666966460977}
2022-12-05 19:30:17,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:17,418 INFO:     Epoch: 74
2022-12-05 19:30:18,214 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4330537969415838, 'Total loss': 0.4330537969415838} | train loss {'Reaction outcome loss': 0.13132557381243307, 'Total loss': 0.13132557381243307}
2022-12-05 19:30:18,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:18,215 INFO:     Epoch: 75
2022-12-05 19:30:19,015 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4348130702803081, 'Total loss': 0.4348130702803081} | train loss {'Reaction outcome loss': 0.12492538439600091, 'Total loss': 0.12492538439600091}
2022-12-05 19:30:19,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:19,015 INFO:     Epoch: 76
2022-12-05 19:30:19,817 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.420713681388985, 'Total loss': 0.420713681388985} | train loss {'Reaction outcome loss': 0.12515606104324645, 'Total loss': 0.12515606104324645}
2022-12-05 19:30:19,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:19,817 INFO:     Epoch: 77
2022-12-05 19:30:20,618 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43749614534052933, 'Total loss': 0.43749614534052933} | train loss {'Reaction outcome loss': 0.12448041008310279, 'Total loss': 0.12448041008310279}
2022-12-05 19:30:20,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:20,619 INFO:     Epoch: 78
2022-12-05 19:30:21,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4273222171786157, 'Total loss': 0.4273222171786157} | train loss {'Reaction outcome loss': 0.12353527722390074, 'Total loss': 0.12353527722390074}
2022-12-05 19:30:21,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:21,423 INFO:     Epoch: 79
2022-12-05 19:30:22,219 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43101208352229814, 'Total loss': 0.43101208352229814} | train loss {'Reaction outcome loss': 0.12545589275416816, 'Total loss': 0.12545589275416816}
2022-12-05 19:30:22,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:22,219 INFO:     Epoch: 80
2022-12-05 19:30:23,019 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43226513622159307, 'Total loss': 0.43226513622159307} | train loss {'Reaction outcome loss': 0.12454245384096314, 'Total loss': 0.12454245384096314}
2022-12-05 19:30:23,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:23,020 INFO:     Epoch: 81
2022-12-05 19:30:23,819 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45271489362825046, 'Total loss': 0.45271489362825046} | train loss {'Reaction outcome loss': 0.11988400408351485, 'Total loss': 0.11988400408351485}
2022-12-05 19:30:23,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:23,820 INFO:     Epoch: 82
2022-12-05 19:30:24,616 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4345279249616645, 'Total loss': 0.4345279249616645} | train loss {'Reaction outcome loss': 0.12241851371384946, 'Total loss': 0.12241851371384946}
2022-12-05 19:30:24,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:24,617 INFO:     Epoch: 83
2022-12-05 19:30:25,415 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42548697509548883, 'Total loss': 0.42548697509548883} | train loss {'Reaction outcome loss': 0.12272610522897137, 'Total loss': 0.12272610522897137}
2022-12-05 19:30:25,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:25,415 INFO:     Epoch: 84
2022-12-05 19:30:26,212 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46010560542345047, 'Total loss': 0.46010560542345047} | train loss {'Reaction outcome loss': 0.12225166815125689, 'Total loss': 0.12225166815125689}
2022-12-05 19:30:26,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:26,212 INFO:     Epoch: 85
2022-12-05 19:30:27,012 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42875860699198465, 'Total loss': 0.42875860699198465} | train loss {'Reaction outcome loss': 0.12180269191320608, 'Total loss': 0.12180269191320608}
2022-12-05 19:30:27,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:27,012 INFO:     Epoch: 86
2022-12-05 19:30:27,815 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4424685043367473, 'Total loss': 0.4424685043367473} | train loss {'Reaction outcome loss': 0.121691841605734, 'Total loss': 0.121691841605734}
2022-12-05 19:30:27,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:27,815 INFO:     Epoch: 87
2022-12-05 19:30:28,617 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4285286705602299, 'Total loss': 0.4285286705602299} | train loss {'Reaction outcome loss': 0.1180120132357327, 'Total loss': 0.1180120132357327}
2022-12-05 19:30:28,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:28,618 INFO:     Epoch: 88
2022-12-05 19:30:29,416 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4356357560239055, 'Total loss': 0.4356357560239055} | train loss {'Reaction outcome loss': 0.12037228837398141, 'Total loss': 0.12037228837398141}
2022-12-05 19:30:29,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:29,416 INFO:     Epoch: 89
2022-12-05 19:30:30,218 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43146843192252243, 'Total loss': 0.43146843192252243} | train loss {'Reaction outcome loss': 0.12083258323191368, 'Total loss': 0.12083258323191368}
2022-12-05 19:30:30,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:30,219 INFO:     Epoch: 90
2022-12-05 19:30:31,018 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4362770041281527, 'Total loss': 0.4362770041281527} | train loss {'Reaction outcome loss': 0.11896410135378842, 'Total loss': 0.11896410135378842}
2022-12-05 19:30:31,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:31,019 INFO:     Epoch: 91
2022-12-05 19:30:31,816 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4298231135207144, 'Total loss': 0.4298231135207144} | train loss {'Reaction outcome loss': 0.11686767593143048, 'Total loss': 0.11686767593143048}
2022-12-05 19:30:31,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:31,816 INFO:     Epoch: 92
2022-12-05 19:30:32,612 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43203757059845055, 'Total loss': 0.43203757059845055} | train loss {'Reaction outcome loss': 0.11818613765312562, 'Total loss': 0.11818613765312562}
2022-12-05 19:30:32,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:32,612 INFO:     Epoch: 93
2022-12-05 19:30:33,411 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43739329650998116, 'Total loss': 0.43739329650998116} | train loss {'Reaction outcome loss': 0.11849931454444342, 'Total loss': 0.11849931454444342}
2022-12-05 19:30:33,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:33,411 INFO:     Epoch: 94
2022-12-05 19:30:34,207 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4243177578530528, 'Total loss': 0.4243177578530528} | train loss {'Reaction outcome loss': 0.1253724690745415, 'Total loss': 0.1253724690745415}
2022-12-05 19:30:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:34,207 INFO:     Epoch: 95
2022-12-05 19:30:35,003 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42097588374533434, 'Total loss': 0.42097588374533434} | train loss {'Reaction outcome loss': 0.11586215917510263, 'Total loss': 0.11586215917510263}
2022-12-05 19:30:35,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:35,003 INFO:     Epoch: 96
2022-12-05 19:30:35,799 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.421826012771238, 'Total loss': 0.421826012771238} | train loss {'Reaction outcome loss': 0.11434342970822746, 'Total loss': 0.11434342970822746}
2022-12-05 19:30:35,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:35,799 INFO:     Epoch: 97
2022-12-05 19:30:36,597 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43051639961248095, 'Total loss': 0.43051639961248095} | train loss {'Reaction outcome loss': 0.11580969026945682, 'Total loss': 0.11580969026945682}
2022-12-05 19:30:36,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:36,597 INFO:     Epoch: 98
2022-12-05 19:30:37,395 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4399835812774571, 'Total loss': 0.4399835812774571} | train loss {'Reaction outcome loss': 0.11416412588314488, 'Total loss': 0.11416412588314488}
2022-12-05 19:30:37,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:37,395 INFO:     Epoch: 99
2022-12-05 19:30:38,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43747601116245444, 'Total loss': 0.43747601116245444} | train loss {'Reaction outcome loss': 0.11538217428162965, 'Total loss': 0.11538217428162965}
2022-12-05 19:30:38,190 INFO:     Best model found after epoch 27 of 100.
2022-12-05 19:30:38,190 INFO:   Done with stage: TRAINING
2022-12-05 19:30:38,190 INFO:   Starting stage: EVALUATION
2022-12-05 19:30:38,316 INFO:   Done with stage: EVALUATION
2022-12-05 19:30:38,316 INFO:   Leaving out SEQ value Fold_8
2022-12-05 19:30:38,329 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:30:38,329 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:30:38,969 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:30:38,969 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:30:39,037 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:30:39,037 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:30:39,037 INFO:     No hyperparam tuning for this model
2022-12-05 19:30:39,037 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:30:39,037 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:30:39,038 INFO:     None feature selector for col prot
2022-12-05 19:30:39,038 INFO:     None feature selector for col prot
2022-12-05 19:30:39,038 INFO:     None feature selector for col prot
2022-12-05 19:30:39,039 INFO:     None feature selector for col chem
2022-12-05 19:30:39,039 INFO:     None feature selector for col chem
2022-12-05 19:30:39,039 INFO:     None feature selector for col chem
2022-12-05 19:30:39,039 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:30:39,039 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:30:39,041 INFO:     Number of params in model 215821
2022-12-05 19:30:39,044 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:30:39,044 INFO:   Starting stage: TRAINING
2022-12-05 19:30:39,105 INFO:     Val loss before train {'Reaction outcome loss': 0.9752164665948261, 'Total loss': 0.9752164665948261}
2022-12-05 19:30:39,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:39,105 INFO:     Epoch: 0
2022-12-05 19:30:39,907 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6060786789113825, 'Total loss': 0.6060786789113825} | train loss {'Reaction outcome loss': 0.8125784890613093, 'Total loss': 0.8125784890613093}
2022-12-05 19:30:39,908 INFO:     Found new best model at epoch 0
2022-12-05 19:30:39,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:39,908 INFO:     Epoch: 1
2022-12-05 19:30:40,708 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.51204913854599, 'Total loss': 0.51204913854599} | train loss {'Reaction outcome loss': 0.5466343785602192, 'Total loss': 0.5466343785602192}
2022-12-05 19:30:40,708 INFO:     Found new best model at epoch 1
2022-12-05 19:30:40,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:40,709 INFO:     Epoch: 2
2022-12-05 19:30:41,507 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4814421239901673, 'Total loss': 0.4814421239901673} | train loss {'Reaction outcome loss': 0.4741012998498403, 'Total loss': 0.4741012998498403}
2022-12-05 19:30:41,508 INFO:     Found new best model at epoch 2
2022-12-05 19:30:41,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:41,508 INFO:     Epoch: 3
2022-12-05 19:30:42,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45790010114962404, 'Total loss': 0.45790010114962404} | train loss {'Reaction outcome loss': 0.43472540634967055, 'Total loss': 0.43472540634967055}
2022-12-05 19:30:42,304 INFO:     Found new best model at epoch 3
2022-12-05 19:30:42,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:42,305 INFO:     Epoch: 4
2022-12-05 19:30:43,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44492372328584845, 'Total loss': 0.44492372328584845} | train loss {'Reaction outcome loss': 0.4030913700338317, 'Total loss': 0.4030913700338317}
2022-12-05 19:30:43,101 INFO:     Found new best model at epoch 4
2022-12-05 19:30:43,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:43,102 INFO:     Epoch: 5
2022-12-05 19:30:43,898 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4499893479726531, 'Total loss': 0.4499893479726531} | train loss {'Reaction outcome loss': 0.3799512249979413, 'Total loss': 0.3799512249979413}
2022-12-05 19:30:43,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:43,898 INFO:     Epoch: 6
2022-12-05 19:30:44,693 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4379694837738167, 'Total loss': 0.4379694837738167} | train loss {'Reaction outcome loss': 0.3610570793632071, 'Total loss': 0.3610570793632071}
2022-12-05 19:30:44,693 INFO:     Found new best model at epoch 6
2022-12-05 19:30:44,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:44,694 INFO:     Epoch: 7
2022-12-05 19:30:45,493 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43465118584307755, 'Total loss': 0.43465118584307755} | train loss {'Reaction outcome loss': 0.34506624285508747, 'Total loss': 0.34506624285508747}
2022-12-05 19:30:45,493 INFO:     Found new best model at epoch 7
2022-12-05 19:30:45,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:45,494 INFO:     Epoch: 8
2022-12-05 19:30:46,291 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43239381977102975, 'Total loss': 0.43239381977102975} | train loss {'Reaction outcome loss': 0.33439798512861796, 'Total loss': 0.33439798512861796}
2022-12-05 19:30:46,292 INFO:     Found new best model at epoch 8
2022-12-05 19:30:46,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:46,292 INFO:     Epoch: 9
2022-12-05 19:30:47,089 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42918718470768497, 'Total loss': 0.42918718470768497} | train loss {'Reaction outcome loss': 0.3195159739931585, 'Total loss': 0.3195159739931585}
2022-12-05 19:30:47,089 INFO:     Found new best model at epoch 9
2022-12-05 19:30:47,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:47,090 INFO:     Epoch: 10
2022-12-05 19:30:47,887 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43342655016617343, 'Total loss': 0.43342655016617343} | train loss {'Reaction outcome loss': 0.31092826611841257, 'Total loss': 0.31092826611841257}
2022-12-05 19:30:47,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:47,887 INFO:     Epoch: 11
2022-12-05 19:30:48,687 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.430832890285687, 'Total loss': 0.430832890285687} | train loss {'Reaction outcome loss': 0.2978867623608122, 'Total loss': 0.2978867623608122}
2022-12-05 19:30:48,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:48,688 INFO:     Epoch: 12
2022-12-05 19:30:49,484 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43160266666249797, 'Total loss': 0.43160266666249797} | train loss {'Reaction outcome loss': 0.2832482610395563, 'Total loss': 0.2832482610395563}
2022-12-05 19:30:49,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:49,484 INFO:     Epoch: 13
2022-12-05 19:30:50,279 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4275914777747609, 'Total loss': 0.4275914777747609} | train loss {'Reaction outcome loss': 0.2808765266166042, 'Total loss': 0.2808765266166042}
2022-12-05 19:30:50,280 INFO:     Found new best model at epoch 13
2022-12-05 19:30:50,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:50,280 INFO:     Epoch: 14
2022-12-05 19:30:51,079 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42659037695689633, 'Total loss': 0.42659037695689633} | train loss {'Reaction outcome loss': 0.26995569190033053, 'Total loss': 0.26995569190033053}
2022-12-05 19:30:51,079 INFO:     Found new best model at epoch 14
2022-12-05 19:30:51,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:51,080 INFO:     Epoch: 15
2022-12-05 19:30:51,880 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4241847450082952, 'Total loss': 0.4241847450082952} | train loss {'Reaction outcome loss': 0.2569201489088506, 'Total loss': 0.2569201489088506}
2022-12-05 19:30:51,880 INFO:     Found new best model at epoch 15
2022-12-05 19:30:51,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:51,881 INFO:     Epoch: 16
2022-12-05 19:30:52,678 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4342370642857118, 'Total loss': 0.4342370642857118} | train loss {'Reaction outcome loss': 0.25173803112707155, 'Total loss': 0.25173803112707155}
2022-12-05 19:30:52,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:52,679 INFO:     Epoch: 17
2022-12-05 19:30:53,476 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43820728276940907, 'Total loss': 0.43820728276940907} | train loss {'Reaction outcome loss': 0.24605382681797874, 'Total loss': 0.24605382681797874}
2022-12-05 19:30:53,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:53,476 INFO:     Epoch: 18
2022-12-05 19:30:54,274 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4392618208446286, 'Total loss': 0.4392618208446286} | train loss {'Reaction outcome loss': 0.23741189686030995, 'Total loss': 0.23741189686030995}
2022-12-05 19:30:54,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:54,274 INFO:     Epoch: 19
2022-12-05 19:30:55,069 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43058122762224893, 'Total loss': 0.43058122762224893} | train loss {'Reaction outcome loss': 0.23393469658276814, 'Total loss': 0.23393469658276814}
2022-12-05 19:30:55,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:55,070 INFO:     Epoch: 20
2022-12-05 19:30:55,865 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4395608825778419, 'Total loss': 0.4395608825778419} | train loss {'Reaction outcome loss': 0.2275510095813979, 'Total loss': 0.2275510095813979}
2022-12-05 19:30:55,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:55,865 INFO:     Epoch: 21
2022-12-05 19:30:56,666 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4388170679184524, 'Total loss': 0.4388170679184524} | train loss {'Reaction outcome loss': 0.22165241451681353, 'Total loss': 0.22165241451681353}
2022-12-05 19:30:56,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:56,666 INFO:     Epoch: 22
2022-12-05 19:30:57,466 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4352660914036361, 'Total loss': 0.4352660914036361} | train loss {'Reaction outcome loss': 0.21755627577423084, 'Total loss': 0.21755627577423084}
2022-12-05 19:30:57,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:57,466 INFO:     Epoch: 23
2022-12-05 19:30:58,267 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43478138389235194, 'Total loss': 0.43478138389235194} | train loss {'Reaction outcome loss': 0.21068204462769544, 'Total loss': 0.21068204462769544}
2022-12-05 19:30:58,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:58,268 INFO:     Epoch: 24
2022-12-05 19:30:59,070 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43334122374653816, 'Total loss': 0.43334122374653816} | train loss {'Reaction outcome loss': 0.20294324551267842, 'Total loss': 0.20294324551267842}
2022-12-05 19:30:59,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:59,070 INFO:     Epoch: 25
2022-12-05 19:30:59,866 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4416597319597548, 'Total loss': 0.4416597319597548} | train loss {'Reaction outcome loss': 0.20203911276300426, 'Total loss': 0.20203911276300426}
2022-12-05 19:30:59,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:30:59,867 INFO:     Epoch: 26
2022-12-05 19:31:00,664 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45844628221609374, 'Total loss': 0.45844628221609374} | train loss {'Reaction outcome loss': 0.19929396786429138, 'Total loss': 0.19929396786429138}
2022-12-05 19:31:00,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:00,664 INFO:     Epoch: 27
2022-12-05 19:31:01,460 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44568469375371933, 'Total loss': 0.44568469375371933} | train loss {'Reaction outcome loss': 0.1961335692194626, 'Total loss': 0.1961335692194626}
2022-12-05 19:31:01,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:01,460 INFO:     Epoch: 28
2022-12-05 19:31:02,254 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4344378743659366, 'Total loss': 0.4344378743659366} | train loss {'Reaction outcome loss': 0.188939096594629, 'Total loss': 0.188939096594629}
2022-12-05 19:31:02,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:02,255 INFO:     Epoch: 29
2022-12-05 19:31:03,050 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4409870896488428, 'Total loss': 0.4409870896488428} | train loss {'Reaction outcome loss': 0.18528559264210373, 'Total loss': 0.18528559264210373}
2022-12-05 19:31:03,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:03,050 INFO:     Epoch: 30
2022-12-05 19:31:03,847 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44715855964882806, 'Total loss': 0.44715855964882806} | train loss {'Reaction outcome loss': 0.1920689226086685, 'Total loss': 0.1920689226086685}
2022-12-05 19:31:03,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:03,848 INFO:     Epoch: 31
2022-12-05 19:31:04,646 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4407070770182393, 'Total loss': 0.4407070770182393} | train loss {'Reaction outcome loss': 0.18635971605898397, 'Total loss': 0.18635971605898397}
2022-12-05 19:31:04,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:04,647 INFO:     Epoch: 32
2022-12-05 19:31:05,444 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43584195092659106, 'Total loss': 0.43584195092659106} | train loss {'Reaction outcome loss': 0.18163018104684378, 'Total loss': 0.18163018104684378}
2022-12-05 19:31:05,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:05,445 INFO:     Epoch: 33
2022-12-05 19:31:06,241 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45123172856189986, 'Total loss': 0.45123172856189986} | train loss {'Reaction outcome loss': 0.17591484614953337, 'Total loss': 0.17591484614953337}
2022-12-05 19:31:06,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:06,241 INFO:     Epoch: 34
2022-12-05 19:31:07,036 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45264993845061824, 'Total loss': 0.45264993845061824} | train loss {'Reaction outcome loss': 0.17491251454963858, 'Total loss': 0.17491251454963858}
2022-12-05 19:31:07,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:07,037 INFO:     Epoch: 35
2022-12-05 19:31:07,831 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43911038406870584, 'Total loss': 0.43911038406870584} | train loss {'Reaction outcome loss': 0.1709981315612778, 'Total loss': 0.1709981315612778}
2022-12-05 19:31:07,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:07,832 INFO:     Epoch: 36
2022-12-05 19:31:08,628 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45095953142101114, 'Total loss': 0.45095953142101114} | train loss {'Reaction outcome loss': 0.1652507540818892, 'Total loss': 0.1652507540818892}
2022-12-05 19:31:08,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:08,628 INFO:     Epoch: 37
2022-12-05 19:31:09,423 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4431520104408264, 'Total loss': 0.4431520104408264} | train loss {'Reaction outcome loss': 0.16695339431343337, 'Total loss': 0.16695339431343337}
2022-12-05 19:31:09,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:09,423 INFO:     Epoch: 38
2022-12-05 19:31:10,220 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4618900902569294, 'Total loss': 0.4618900902569294} | train loss {'Reaction outcome loss': 0.16255265945636552, 'Total loss': 0.16255265945636552}
2022-12-05 19:31:10,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:10,220 INFO:     Epoch: 39
2022-12-05 19:31:11,017 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44237671504643833, 'Total loss': 0.44237671504643833} | train loss {'Reaction outcome loss': 0.16206607849031748, 'Total loss': 0.16206607849031748}
2022-12-05 19:31:11,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:11,017 INFO:     Epoch: 40
2022-12-05 19:31:11,813 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43855389004403894, 'Total loss': 0.43855389004403894} | train loss {'Reaction outcome loss': 0.15696293857657476, 'Total loss': 0.15696293857657476}
2022-12-05 19:31:11,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:11,814 INFO:     Epoch: 41
2022-12-05 19:31:12,610 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46221342039379204, 'Total loss': 0.46221342039379204} | train loss {'Reaction outcome loss': 0.16469370477987447, 'Total loss': 0.16469370477987447}
2022-12-05 19:31:12,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:12,610 INFO:     Epoch: 42
2022-12-05 19:31:13,405 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45442435348575766, 'Total loss': 0.45442435348575766} | train loss {'Reaction outcome loss': 0.16456666778064208, 'Total loss': 0.16456666778064208}
2022-12-05 19:31:13,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:13,405 INFO:     Epoch: 43
2022-12-05 19:31:14,203 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4556876353242181, 'Total loss': 0.4556876353242181} | train loss {'Reaction outcome loss': 0.15210605651019557, 'Total loss': 0.15210605651019557}
2022-12-05 19:31:14,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:14,204 INFO:     Epoch: 44
2022-12-05 19:31:15,002 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44935824755917897, 'Total loss': 0.44935824755917897} | train loss {'Reaction outcome loss': 0.15257706891307946, 'Total loss': 0.15257706891307946}
2022-12-05 19:31:15,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:15,003 INFO:     Epoch: 45
2022-12-05 19:31:15,807 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4547241414812478, 'Total loss': 0.4547241414812478} | train loss {'Reaction outcome loss': 0.14812057775252985, 'Total loss': 0.14812057775252985}
2022-12-05 19:31:15,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:15,807 INFO:     Epoch: 46
2022-12-05 19:31:16,610 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4608930935236541, 'Total loss': 0.4608930935236541} | train loss {'Reaction outcome loss': 0.15329617137458884, 'Total loss': 0.15329617137458884}
2022-12-05 19:31:16,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:16,610 INFO:     Epoch: 47
2022-12-05 19:31:17,406 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4501908120106567, 'Total loss': 0.4501908120106567} | train loss {'Reaction outcome loss': 0.14962187510262798, 'Total loss': 0.14962187510262798}
2022-12-05 19:31:17,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:17,407 INFO:     Epoch: 48
2022-12-05 19:31:18,204 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4499174161729487, 'Total loss': 0.4499174161729487} | train loss {'Reaction outcome loss': 0.1450324513768468, 'Total loss': 0.1450324513768468}
2022-12-05 19:31:18,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:18,204 INFO:     Epoch: 49
2022-12-05 19:31:19,001 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47009713642976503, 'Total loss': 0.47009713642976503} | train loss {'Reaction outcome loss': 0.1446082266160713, 'Total loss': 0.1446082266160713}
2022-12-05 19:31:19,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:19,002 INFO:     Epoch: 50
2022-12-05 19:31:19,799 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44524628533558414, 'Total loss': 0.44524628533558414} | train loss {'Reaction outcome loss': 0.1464393050730349, 'Total loss': 0.1464393050730349}
2022-12-05 19:31:19,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:19,799 INFO:     Epoch: 51
2022-12-05 19:31:20,598 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4470622685145248, 'Total loss': 0.4470622685145248} | train loss {'Reaction outcome loss': 0.1507823277219587, 'Total loss': 0.1507823277219587}
2022-12-05 19:31:20,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:20,598 INFO:     Epoch: 52
2022-12-05 19:31:21,397 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4436849574135108, 'Total loss': 0.4436849574135108} | train loss {'Reaction outcome loss': 0.14172023701432504, 'Total loss': 0.14172023701432504}
2022-12-05 19:31:21,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:21,397 INFO:     Epoch: 53
2022-12-05 19:31:22,199 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4535322558473457, 'Total loss': 0.4535322558473457} | train loss {'Reaction outcome loss': 0.13937678889593916, 'Total loss': 0.13937678889593916}
2022-12-05 19:31:22,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:22,199 INFO:     Epoch: 54
2022-12-05 19:31:22,996 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44902280413291673, 'Total loss': 0.44902280413291673} | train loss {'Reaction outcome loss': 0.1405332684856255, 'Total loss': 0.1405332684856255}
2022-12-05 19:31:22,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:22,996 INFO:     Epoch: 55
2022-12-05 19:31:23,792 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4487471610985019, 'Total loss': 0.4487471610985019} | train loss {'Reaction outcome loss': 0.13930651556247062, 'Total loss': 0.13930651556247062}
2022-12-05 19:31:23,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:23,793 INFO:     Epoch: 56
2022-12-05 19:31:24,591 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46093831448392436, 'Total loss': 0.46093831448392436} | train loss {'Reaction outcome loss': 0.1366587347522574, 'Total loss': 0.1366587347522574}
2022-12-05 19:31:24,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:24,591 INFO:     Epoch: 57
2022-12-05 19:31:25,389 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4515555809167298, 'Total loss': 0.4515555809167298} | train loss {'Reaction outcome loss': 0.1384974103598895, 'Total loss': 0.1384974103598895}
2022-12-05 19:31:25,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:25,389 INFO:     Epoch: 58
2022-12-05 19:31:26,189 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4494456696662713, 'Total loss': 0.4494456696662713} | train loss {'Reaction outcome loss': 0.13540664214314704, 'Total loss': 0.13540664214314704}
2022-12-05 19:31:26,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:26,189 INFO:     Epoch: 59
2022-12-05 19:31:26,989 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4523893286558715, 'Total loss': 0.4523893286558715} | train loss {'Reaction outcome loss': 0.1355815956648062, 'Total loss': 0.1355815956648062}
2022-12-05 19:31:26,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:26,990 INFO:     Epoch: 60
2022-12-05 19:31:27,794 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4638066938654943, 'Total loss': 0.4638066938654943} | train loss {'Reaction outcome loss': 0.13676472395839478, 'Total loss': 0.13676472395839478}
2022-12-05 19:31:27,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:27,794 INFO:     Epoch: 61
2022-12-05 19:31:28,595 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4508843525228175, 'Total loss': 0.4508843525228175} | train loss {'Reaction outcome loss': 0.13395523959450303, 'Total loss': 0.13395523959450303}
2022-12-05 19:31:28,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:28,596 INFO:     Epoch: 62
2022-12-05 19:31:29,394 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4536528428169814, 'Total loss': 0.4536528428169814} | train loss {'Reaction outcome loss': 0.13070557967228022, 'Total loss': 0.13070557967228022}
2022-12-05 19:31:29,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:29,395 INFO:     Epoch: 63
2022-12-05 19:31:30,193 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4426013986495408, 'Total loss': 0.4426013986495408} | train loss {'Reaction outcome loss': 0.1330115381022161, 'Total loss': 0.1330115381022161}
2022-12-05 19:31:30,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:30,193 INFO:     Epoch: 64
2022-12-05 19:31:30,991 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45488317209211265, 'Total loss': 0.45488317209211265} | train loss {'Reaction outcome loss': 0.1337253237067748, 'Total loss': 0.1337253237067748}
2022-12-05 19:31:30,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:30,992 INFO:     Epoch: 65
2022-12-05 19:31:31,789 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4701168841936372, 'Total loss': 0.4701168841936372} | train loss {'Reaction outcome loss': 0.1373374665397321, 'Total loss': 0.1373374665397321}
2022-12-05 19:31:31,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:31,789 INFO:     Epoch: 66
2022-12-05 19:31:32,587 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4426648438569497, 'Total loss': 0.4426648438569497} | train loss {'Reaction outcome loss': 0.13432192090080547, 'Total loss': 0.13432192090080547}
2022-12-05 19:31:32,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:32,587 INFO:     Epoch: 67
2022-12-05 19:31:33,384 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4445568277415904, 'Total loss': 0.4445568277415904} | train loss {'Reaction outcome loss': 0.1304586858409438, 'Total loss': 0.1304586858409438}
2022-12-05 19:31:33,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:33,385 INFO:     Epoch: 68
2022-12-05 19:31:34,179 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44065460190176964, 'Total loss': 0.44065460190176964} | train loss {'Reaction outcome loss': 0.12700972471787755, 'Total loss': 0.12700972471787755}
2022-12-05 19:31:34,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:34,179 INFO:     Epoch: 69
2022-12-05 19:31:34,975 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43932756527580996, 'Total loss': 0.43932756527580996} | train loss {'Reaction outcome loss': 0.12806114778375094, 'Total loss': 0.12806114778375094}
2022-12-05 19:31:34,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:34,975 INFO:     Epoch: 70
2022-12-05 19:31:35,773 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45191601443697105, 'Total loss': 0.45191601443697105} | train loss {'Reaction outcome loss': 0.12452107505507104, 'Total loss': 0.12452107505507104}
2022-12-05 19:31:35,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:35,773 INFO:     Epoch: 71
2022-12-05 19:31:36,572 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4521637296473438, 'Total loss': 0.4521637296473438} | train loss {'Reaction outcome loss': 0.12536566139308186, 'Total loss': 0.12536566139308186}
2022-12-05 19:31:36,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:36,573 INFO:     Epoch: 72
2022-12-05 19:31:37,367 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4447266757488251, 'Total loss': 0.4447266757488251} | train loss {'Reaction outcome loss': 0.1266345720670303, 'Total loss': 0.1266345720670303}
2022-12-05 19:31:37,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:37,367 INFO:     Epoch: 73
2022-12-05 19:31:38,159 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.469244891946966, 'Total loss': 0.469244891946966} | train loss {'Reaction outcome loss': 0.13045036389496223, 'Total loss': 0.13045036389496223}
2022-12-05 19:31:38,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:38,159 INFO:     Epoch: 74
2022-12-05 19:31:38,951 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4567993904717944, 'Total loss': 0.4567993904717944} | train loss {'Reaction outcome loss': 0.12413792295743398, 'Total loss': 0.12413792295743398}
2022-12-05 19:31:38,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:38,951 INFO:     Epoch: 75
2022-12-05 19:31:39,742 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4603958187455481, 'Total loss': 0.4603958187455481} | train loss {'Reaction outcome loss': 0.12228186354644385, 'Total loss': 0.12228186354644385}
2022-12-05 19:31:39,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:39,742 INFO:     Epoch: 76
2022-12-05 19:31:40,535 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4577265608717095, 'Total loss': 0.4577265608717095} | train loss {'Reaction outcome loss': 0.12433701907831286, 'Total loss': 0.12433701907831286}
2022-12-05 19:31:40,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:40,535 INFO:     Epoch: 77
2022-12-05 19:31:41,327 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4766343676231124, 'Total loss': 0.4766343676231124} | train loss {'Reaction outcome loss': 0.12618118495141206, 'Total loss': 0.12618118495141206}
2022-12-05 19:31:41,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:41,327 INFO:     Epoch: 78
2022-12-05 19:31:42,118 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45038053850558674, 'Total loss': 0.45038053850558674} | train loss {'Reaction outcome loss': 0.1255391102608459, 'Total loss': 0.1255391102608459}
2022-12-05 19:31:42,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:42,119 INFO:     Epoch: 79
2022-12-05 19:31:42,913 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4675351638685573, 'Total loss': 0.4675351638685573} | train loss {'Reaction outcome loss': 0.11981842734639793, 'Total loss': 0.11981842734639793}
2022-12-05 19:31:42,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:42,913 INFO:     Epoch: 80
2022-12-05 19:31:43,704 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4570093185386874, 'Total loss': 0.4570093185386874} | train loss {'Reaction outcome loss': 0.11809535117948103, 'Total loss': 0.11809535117948103}
2022-12-05 19:31:43,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:43,705 INFO:     Epoch: 81
2022-12-05 19:31:44,500 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4556588027626276, 'Total loss': 0.4556588027626276} | train loss {'Reaction outcome loss': 0.12244787864926222, 'Total loss': 0.12244787864926222}
2022-12-05 19:31:44,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:44,500 INFO:     Epoch: 82
2022-12-05 19:31:45,294 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4410609438676726, 'Total loss': 0.4410609438676726} | train loss {'Reaction outcome loss': 0.12133907638716432, 'Total loss': 0.12133907638716432}
2022-12-05 19:31:45,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:45,294 INFO:     Epoch: 83
2022-12-05 19:31:46,089 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4589300175959414, 'Total loss': 0.4589300175959414} | train loss {'Reaction outcome loss': 0.12043541599760729, 'Total loss': 0.12043541599760729}
2022-12-05 19:31:46,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:46,090 INFO:     Epoch: 84
2022-12-05 19:31:46,888 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45057161220095376, 'Total loss': 0.45057161220095376} | train loss {'Reaction outcome loss': 0.12087860288709282, 'Total loss': 0.12087860288709282}
2022-12-05 19:31:46,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:46,888 INFO:     Epoch: 85
2022-12-05 19:31:47,684 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46416307071393187, 'Total loss': 0.46416307071393187} | train loss {'Reaction outcome loss': 0.12005633384230649, 'Total loss': 0.12005633384230649}
2022-12-05 19:31:47,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:47,684 INFO:     Epoch: 86
2022-12-05 19:31:48,477 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46012427827174013, 'Total loss': 0.46012427827174013} | train loss {'Reaction outcome loss': 0.12284507386684267, 'Total loss': 0.12284507386684267}
2022-12-05 19:31:48,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:48,477 INFO:     Epoch: 87
2022-12-05 19:31:49,269 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45243504948236724, 'Total loss': 0.45243504948236724} | train loss {'Reaction outcome loss': 0.12003992283754503, 'Total loss': 0.12003992283754503}
2022-12-05 19:31:49,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:49,269 INFO:     Epoch: 88
2022-12-05 19:31:50,060 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44857990606264636, 'Total loss': 0.44857990606264636} | train loss {'Reaction outcome loss': 0.11795062445639538, 'Total loss': 0.11795062445639538}
2022-12-05 19:31:50,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:50,061 INFO:     Epoch: 89
2022-12-05 19:31:50,857 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45589710941368883, 'Total loss': 0.45589710941368883} | train loss {'Reaction outcome loss': 0.11677563832205558, 'Total loss': 0.11677563832205558}
2022-12-05 19:31:50,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:50,857 INFO:     Epoch: 90
2022-12-05 19:31:51,651 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4535799893465909, 'Total loss': 0.4535799893465909} | train loss {'Reaction outcome loss': 0.11920084698721464, 'Total loss': 0.11920084698721464}
2022-12-05 19:31:51,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:51,651 INFO:     Epoch: 91
2022-12-05 19:31:52,442 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4636080773039298, 'Total loss': 0.4636080773039298} | train loss {'Reaction outcome loss': 0.12225556184927959, 'Total loss': 0.12225556184927959}
2022-12-05 19:31:52,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:52,442 INFO:     Epoch: 92
2022-12-05 19:31:53,236 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44653921167958865, 'Total loss': 0.44653921167958865} | train loss {'Reaction outcome loss': 0.11847945755566301, 'Total loss': 0.11847945755566301}
2022-12-05 19:31:53,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:53,236 INFO:     Epoch: 93
2022-12-05 19:31:54,026 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4455479420721531, 'Total loss': 0.4455479420721531} | train loss {'Reaction outcome loss': 0.11390442592631517, 'Total loss': 0.11390442592631517}
2022-12-05 19:31:54,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:54,026 INFO:     Epoch: 94
2022-12-05 19:31:54,820 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4641787467355078, 'Total loss': 0.4641787467355078} | train loss {'Reaction outcome loss': 0.1147739254239841, 'Total loss': 0.1147739254239841}
2022-12-05 19:31:54,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:54,820 INFO:     Epoch: 95
2022-12-05 19:31:55,613 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4437312971461903, 'Total loss': 0.4437312971461903} | train loss {'Reaction outcome loss': 0.11712014824076582, 'Total loss': 0.11712014824076582}
2022-12-05 19:31:55,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:55,614 INFO:     Epoch: 96
2022-12-05 19:31:56,408 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4484343620186502, 'Total loss': 0.4484343620186502} | train loss {'Reaction outcome loss': 0.11713890751601322, 'Total loss': 0.11713890751601322}
2022-12-05 19:31:56,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:56,408 INFO:     Epoch: 97
2022-12-05 19:31:57,203 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45037244429642503, 'Total loss': 0.45037244429642503} | train loss {'Reaction outcome loss': 0.1156485087798177, 'Total loss': 0.1156485087798177}
2022-12-05 19:31:57,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:57,203 INFO:     Epoch: 98
2022-12-05 19:31:57,998 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46124240959232504, 'Total loss': 0.46124240959232504} | train loss {'Reaction outcome loss': 0.11694460934563446, 'Total loss': 0.11694460934563446}
2022-12-05 19:31:57,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:57,999 INFO:     Epoch: 99
2022-12-05 19:31:58,797 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44990366663445125, 'Total loss': 0.44990366663445125} | train loss {'Reaction outcome loss': 0.12232461432183561, 'Total loss': 0.12232461432183561}
2022-12-05 19:31:58,797 INFO:     Best model found after epoch 16 of 100.
2022-12-05 19:31:58,797 INFO:   Done with stage: TRAINING
2022-12-05 19:31:58,797 INFO:   Starting stage: EVALUATION
2022-12-05 19:31:58,923 INFO:   Done with stage: EVALUATION
2022-12-05 19:31:58,923 INFO:   Leaving out SEQ value Fold_9
2022-12-05 19:31:58,936 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:31:58,936 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:31:59,579 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:31:59,579 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:31:59,649 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:31:59,649 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:31:59,649 INFO:     No hyperparam tuning for this model
2022-12-05 19:31:59,649 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:31:59,649 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:31:59,650 INFO:     None feature selector for col prot
2022-12-05 19:31:59,650 INFO:     None feature selector for col prot
2022-12-05 19:31:59,650 INFO:     None feature selector for col prot
2022-12-05 19:31:59,651 INFO:     None feature selector for col chem
2022-12-05 19:31:59,651 INFO:     None feature selector for col chem
2022-12-05 19:31:59,651 INFO:     None feature selector for col chem
2022-12-05 19:31:59,651 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:31:59,651 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:31:59,653 INFO:     Number of params in model 215821
2022-12-05 19:31:59,656 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:31:59,656 INFO:   Starting stage: TRAINING
2022-12-05 19:31:59,717 INFO:     Val loss before train {'Reaction outcome loss': 1.0218822807073593, 'Total loss': 1.0218822807073593}
2022-12-05 19:31:59,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:31:59,717 INFO:     Epoch: 0
2022-12-05 19:32:00,512 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.613342435522513, 'Total loss': 0.613342435522513} | train loss {'Reaction outcome loss': 0.7879713885636948, 'Total loss': 0.7879713885636948}
2022-12-05 19:32:00,512 INFO:     Found new best model at epoch 0
2022-12-05 19:32:00,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:00,513 INFO:     Epoch: 1
2022-12-05 19:32:01,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5224458216266199, 'Total loss': 0.5224458216266199} | train loss {'Reaction outcome loss': 0.5535759924032427, 'Total loss': 0.5535759924032427}
2022-12-05 19:32:01,304 INFO:     Found new best model at epoch 1
2022-12-05 19:32:01,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:01,305 INFO:     Epoch: 2
2022-12-05 19:32:02,095 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4932548789815469, 'Total loss': 0.4932548789815469} | train loss {'Reaction outcome loss': 0.4748545120119566, 'Total loss': 0.4748545120119566}
2022-12-05 19:32:02,095 INFO:     Found new best model at epoch 2
2022-12-05 19:32:02,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:02,096 INFO:     Epoch: 3
2022-12-05 19:32:02,887 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4709139500151981, 'Total loss': 0.4709139500151981} | train loss {'Reaction outcome loss': 0.4301525894552469, 'Total loss': 0.4301525894552469}
2022-12-05 19:32:02,887 INFO:     Found new best model at epoch 3
2022-12-05 19:32:02,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:02,888 INFO:     Epoch: 4
2022-12-05 19:32:03,679 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4551617178049954, 'Total loss': 0.4551617178049954} | train loss {'Reaction outcome loss': 0.401881793815537, 'Total loss': 0.401881793815537}
2022-12-05 19:32:03,679 INFO:     Found new best model at epoch 4
2022-12-05 19:32:03,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:03,680 INFO:     Epoch: 5
2022-12-05 19:32:04,470 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4404309896582907, 'Total loss': 0.4404309896582907} | train loss {'Reaction outcome loss': 0.3810056164438425, 'Total loss': 0.3810056164438425}
2022-12-05 19:32:04,471 INFO:     Found new best model at epoch 5
2022-12-05 19:32:04,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:04,472 INFO:     Epoch: 6
2022-12-05 19:32:05,263 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4338077931580218, 'Total loss': 0.4338077931580218} | train loss {'Reaction outcome loss': 0.3627287184419902, 'Total loss': 0.3627287184419902}
2022-12-05 19:32:05,263 INFO:     Found new best model at epoch 6
2022-12-05 19:32:05,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:05,264 INFO:     Epoch: 7
2022-12-05 19:32:06,053 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44691518253900786, 'Total loss': 0.44691518253900786} | train loss {'Reaction outcome loss': 0.3425091602481328, 'Total loss': 0.3425091602481328}
2022-12-05 19:32:06,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:06,053 INFO:     Epoch: 8
2022-12-05 19:32:06,844 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43474227494814177, 'Total loss': 0.43474227494814177} | train loss {'Reaction outcome loss': 0.3257014556120523, 'Total loss': 0.3257014556120523}
2022-12-05 19:32:06,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:06,844 INFO:     Epoch: 9
2022-12-05 19:32:07,634 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4420232630588792, 'Total loss': 0.4420232630588792} | train loss {'Reaction outcome loss': 0.3102203067618343, 'Total loss': 0.3102203067618343}
2022-12-05 19:32:07,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:07,634 INFO:     Epoch: 10
2022-12-05 19:32:08,424 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4228417527946559, 'Total loss': 0.4228417527946559} | train loss {'Reaction outcome loss': 0.298310463972812, 'Total loss': 0.298310463972812}
2022-12-05 19:32:08,424 INFO:     Found new best model at epoch 10
2022-12-05 19:32:08,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:08,425 INFO:     Epoch: 11
2022-12-05 19:32:09,219 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4342196419496428, 'Total loss': 0.4342196419496428} | train loss {'Reaction outcome loss': 0.28697588904063226, 'Total loss': 0.28697588904063226}
2022-12-05 19:32:09,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:09,219 INFO:     Epoch: 12
2022-12-05 19:32:10,013 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42487853460691194, 'Total loss': 0.42487853460691194} | train loss {'Reaction outcome loss': 0.2740188309628713, 'Total loss': 0.2740188309628713}
2022-12-05 19:32:10,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:10,014 INFO:     Epoch: 13
2022-12-05 19:32:10,806 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42883566055785527, 'Total loss': 0.42883566055785527} | train loss {'Reaction outcome loss': 0.26674731418882547, 'Total loss': 0.26674731418882547}
2022-12-05 19:32:10,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:10,806 INFO:     Epoch: 14
2022-12-05 19:32:11,599 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43704308925027197, 'Total loss': 0.43704308925027197} | train loss {'Reaction outcome loss': 0.25545800228410886, 'Total loss': 0.25545800228410886}
2022-12-05 19:32:11,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:11,599 INFO:     Epoch: 15
2022-12-05 19:32:12,396 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42869035052982246, 'Total loss': 0.42869035052982246} | train loss {'Reaction outcome loss': 0.24798806249974711, 'Total loss': 0.24798806249974711}
2022-12-05 19:32:12,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:12,397 INFO:     Epoch: 16
2022-12-05 19:32:13,186 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4538457210768353, 'Total loss': 0.4538457210768353} | train loss {'Reaction outcome loss': 0.24458749206201266, 'Total loss': 0.24458749206201266}
2022-12-05 19:32:13,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:13,186 INFO:     Epoch: 17
2022-12-05 19:32:13,977 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43796164102175017, 'Total loss': 0.43796164102175017} | train loss {'Reaction outcome loss': 0.23746286166703653, 'Total loss': 0.23746286166703653}
2022-12-05 19:32:13,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:13,977 INFO:     Epoch: 18
2022-12-05 19:32:14,769 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43801009925928985, 'Total loss': 0.43801009925928985} | train loss {'Reaction outcome loss': 0.22688354805172214, 'Total loss': 0.22688354805172214}
2022-12-05 19:32:14,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:14,769 INFO:     Epoch: 19
2022-12-05 19:32:15,562 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4366812387650663, 'Total loss': 0.4366812387650663} | train loss {'Reaction outcome loss': 0.222862759801118, 'Total loss': 0.222862759801118}
2022-12-05 19:32:15,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:15,563 INFO:     Epoch: 20
2022-12-05 19:32:16,353 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4346823665228757, 'Total loss': 0.4346823665228757} | train loss {'Reaction outcome loss': 0.2149004742261852, 'Total loss': 0.2149004742261852}
2022-12-05 19:32:16,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:16,354 INFO:     Epoch: 21
2022-12-05 19:32:17,143 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4373919242485003, 'Total loss': 0.4373919242485003} | train loss {'Reaction outcome loss': 0.21176447440315838, 'Total loss': 0.21176447440315838}
2022-12-05 19:32:17,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:17,144 INFO:     Epoch: 22
2022-12-05 19:32:17,937 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44269909303296695, 'Total loss': 0.44269909303296695} | train loss {'Reaction outcome loss': 0.21055533518253067, 'Total loss': 0.21055533518253067}
2022-12-05 19:32:17,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:17,937 INFO:     Epoch: 23
2022-12-05 19:32:18,729 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45205248858441005, 'Total loss': 0.45205248858441005} | train loss {'Reaction outcome loss': 0.20722014356219787, 'Total loss': 0.20722014356219787}
2022-12-05 19:32:18,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:18,729 INFO:     Epoch: 24
2022-12-05 19:32:19,523 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44172793796116655, 'Total loss': 0.44172793796116655} | train loss {'Reaction outcome loss': 0.19824741774725047, 'Total loss': 0.19824741774725047}
2022-12-05 19:32:19,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:19,523 INFO:     Epoch: 25
2022-12-05 19:32:20,313 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46347953514619306, 'Total loss': 0.46347953514619306} | train loss {'Reaction outcome loss': 0.198987144328322, 'Total loss': 0.198987144328322}
2022-12-05 19:32:20,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:20,314 INFO:     Epoch: 26
2022-12-05 19:32:21,104 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4591171822764657, 'Total loss': 0.4591171822764657} | train loss {'Reaction outcome loss': 0.1898001410323478, 'Total loss': 0.1898001410323478}
2022-12-05 19:32:21,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:21,104 INFO:     Epoch: 27
2022-12-05 19:32:21,900 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.465285428207029, 'Total loss': 0.465285428207029} | train loss {'Reaction outcome loss': 0.18723495026318893, 'Total loss': 0.18723495026318893}
2022-12-05 19:32:21,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:21,900 INFO:     Epoch: 28
2022-12-05 19:32:22,694 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45282643559304153, 'Total loss': 0.45282643559304153} | train loss {'Reaction outcome loss': 0.18502920516106763, 'Total loss': 0.18502920516106763}
2022-12-05 19:32:22,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:22,695 INFO:     Epoch: 29
2022-12-05 19:32:23,487 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46081849052147433, 'Total loss': 0.46081849052147433} | train loss {'Reaction outcome loss': 0.18233948986720944, 'Total loss': 0.18233948986720944}
2022-12-05 19:32:23,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:23,487 INFO:     Epoch: 30
2022-12-05 19:32:24,278 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4450138421221213, 'Total loss': 0.4450138421221213} | train loss {'Reaction outcome loss': 0.17665393130197699, 'Total loss': 0.17665393130197699}
2022-12-05 19:32:24,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:24,278 INFO:     Epoch: 31
2022-12-05 19:32:25,069 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4427373144479299, 'Total loss': 0.4427373144479299} | train loss {'Reaction outcome loss': 0.17764720756575647, 'Total loss': 0.17764720756575647}
2022-12-05 19:32:25,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:25,069 INFO:     Epoch: 32
2022-12-05 19:32:25,866 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4508629891682755, 'Total loss': 0.4508629891682755} | train loss {'Reaction outcome loss': 0.16878705767458418, 'Total loss': 0.16878705767458418}
2022-12-05 19:32:25,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:25,867 INFO:     Epoch: 33
2022-12-05 19:32:26,661 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4682714759626172, 'Total loss': 0.4682714759626172} | train loss {'Reaction outcome loss': 0.1697168105177257, 'Total loss': 0.1697168105177257}
2022-12-05 19:32:26,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:26,662 INFO:     Epoch: 34
2022-12-05 19:32:27,453 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47033777206458827, 'Total loss': 0.47033777206458827} | train loss {'Reaction outcome loss': 0.16602236716367064, 'Total loss': 0.16602236716367064}
2022-12-05 19:32:27,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:27,453 INFO:     Epoch: 35
2022-12-05 19:32:28,251 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44418415308675985, 'Total loss': 0.44418415308675985} | train loss {'Reaction outcome loss': 0.16734418784256888, 'Total loss': 0.16734418784256888}
2022-12-05 19:32:28,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:28,251 INFO:     Epoch: 36
2022-12-05 19:32:29,044 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4759319245137952, 'Total loss': 0.4759319245137952} | train loss {'Reaction outcome loss': 0.1670702836487578, 'Total loss': 0.1670702836487578}
2022-12-05 19:32:29,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:29,046 INFO:     Epoch: 37
2022-12-05 19:32:29,840 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45698186111721123, 'Total loss': 0.45698186111721123} | train loss {'Reaction outcome loss': 0.1690808530776245, 'Total loss': 0.1690808530776245}
2022-12-05 19:32:29,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:29,840 INFO:     Epoch: 38
2022-12-05 19:32:30,632 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4746754382821647, 'Total loss': 0.4746754382821647} | train loss {'Reaction outcome loss': 0.16060812923555765, 'Total loss': 0.16060812923555765}
2022-12-05 19:32:30,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:30,632 INFO:     Epoch: 39
2022-12-05 19:32:31,424 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4650998278097673, 'Total loss': 0.4650998278097673} | train loss {'Reaction outcome loss': 0.1568346710928418, 'Total loss': 0.1568346710928418}
2022-12-05 19:32:31,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:31,424 INFO:     Epoch: 40
2022-12-05 19:32:32,214 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4735795095224272, 'Total loss': 0.4735795095224272} | train loss {'Reaction outcome loss': 0.15763233958739742, 'Total loss': 0.15763233958739742}
2022-12-05 19:32:32,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:32,215 INFO:     Epoch: 41
2022-12-05 19:32:33,010 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4652179330587387, 'Total loss': 0.4652179330587387} | train loss {'Reaction outcome loss': 0.15927932529073013, 'Total loss': 0.15927932529073013}
2022-12-05 19:32:33,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:33,010 INFO:     Epoch: 42
2022-12-05 19:32:33,808 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46892758018591185, 'Total loss': 0.46892758018591185} | train loss {'Reaction outcome loss': 0.1524205547323835, 'Total loss': 0.1524205547323835}
2022-12-05 19:32:33,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:33,808 INFO:     Epoch: 43
2022-12-05 19:32:34,606 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45828992467034946, 'Total loss': 0.45828992467034946} | train loss {'Reaction outcome loss': 0.1535203869036033, 'Total loss': 0.1535203869036033}
2022-12-05 19:32:34,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:34,606 INFO:     Epoch: 44
2022-12-05 19:32:35,401 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46620004082267935, 'Total loss': 0.46620004082267935} | train loss {'Reaction outcome loss': 0.15242927997780262, 'Total loss': 0.15242927997780262}
2022-12-05 19:32:35,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:35,402 INFO:     Epoch: 45
2022-12-05 19:32:36,193 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46480664602396166, 'Total loss': 0.46480664602396166} | train loss {'Reaction outcome loss': 0.14743407897421193, 'Total loss': 0.14743407897421193}
2022-12-05 19:32:36,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:36,193 INFO:     Epoch: 46
2022-12-05 19:32:36,988 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46305220015347004, 'Total loss': 0.46305220015347004} | train loss {'Reaction outcome loss': 0.14436628684582498, 'Total loss': 0.14436628684582498}
2022-12-05 19:32:36,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:36,988 INFO:     Epoch: 47
2022-12-05 19:32:37,783 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4870832230557095, 'Total loss': 0.4870832230557095} | train loss {'Reaction outcome loss': 0.1455510864939224, 'Total loss': 0.1455510864939224}
2022-12-05 19:32:37,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:37,783 INFO:     Epoch: 48
2022-12-05 19:32:38,575 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46025248210538516, 'Total loss': 0.46025248210538516} | train loss {'Reaction outcome loss': 0.14841067233699778, 'Total loss': 0.14841067233699778}
2022-12-05 19:32:38,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:38,575 INFO:     Epoch: 49
2022-12-05 19:32:39,368 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4790865365754474, 'Total loss': 0.4790865365754474} | train loss {'Reaction outcome loss': 0.14598010856326413, 'Total loss': 0.14598010856326413}
2022-12-05 19:32:39,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:39,368 INFO:     Epoch: 50
2022-12-05 19:32:40,161 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47709099101749336, 'Total loss': 0.47709099101749336} | train loss {'Reaction outcome loss': 0.14450308686755747, 'Total loss': 0.14450308686755747}
2022-12-05 19:32:40,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:40,161 INFO:     Epoch: 51
2022-12-05 19:32:40,953 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48930799148299475, 'Total loss': 0.48930799148299475} | train loss {'Reaction outcome loss': 0.13910181627341128, 'Total loss': 0.13910181627341128}
2022-12-05 19:32:40,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:40,953 INFO:     Epoch: 52
2022-12-05 19:32:41,749 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4753191897814924, 'Total loss': 0.4753191897814924} | train loss {'Reaction outcome loss': 0.1409837989596582, 'Total loss': 0.1409837989596582}
2022-12-05 19:32:41,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:41,749 INFO:     Epoch: 53
2022-12-05 19:32:42,541 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47144091654230247, 'Total loss': 0.47144091654230247} | train loss {'Reaction outcome loss': 0.13822637761562218, 'Total loss': 0.13822637761562218}
2022-12-05 19:32:42,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:42,541 INFO:     Epoch: 54
2022-12-05 19:32:43,332 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4766055409881202, 'Total loss': 0.4766055409881202} | train loss {'Reaction outcome loss': 0.1381189054625697, 'Total loss': 0.1381189054625697}
2022-12-05 19:32:43,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:43,333 INFO:     Epoch: 55
2022-12-05 19:32:44,123 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4749050516296517, 'Total loss': 0.4749050516296517} | train loss {'Reaction outcome loss': 0.1378851703062714, 'Total loss': 0.1378851703062714}
2022-12-05 19:32:44,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:44,124 INFO:     Epoch: 56
2022-12-05 19:32:44,915 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47136948156085884, 'Total loss': 0.47136948156085884} | train loss {'Reaction outcome loss': 0.13572454532072972, 'Total loss': 0.13572454532072972}
2022-12-05 19:32:44,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:44,915 INFO:     Epoch: 57
2022-12-05 19:32:45,711 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48148243671113794, 'Total loss': 0.48148243671113794} | train loss {'Reaction outcome loss': 0.13464261902692287, 'Total loss': 0.13464261902692287}
2022-12-05 19:32:45,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:45,711 INFO:     Epoch: 58
2022-12-05 19:32:46,504 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47521427934142674, 'Total loss': 0.47521427934142674} | train loss {'Reaction outcome loss': 0.1369117257611351, 'Total loss': 0.1369117257611351}
2022-12-05 19:32:46,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:46,504 INFO:     Epoch: 59
2022-12-05 19:32:47,301 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4726221546192061, 'Total loss': 0.4726221546192061} | train loss {'Reaction outcome loss': 0.13839615135065275, 'Total loss': 0.13839615135065275}
2022-12-05 19:32:47,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:47,301 INFO:     Epoch: 60
2022-12-05 19:32:48,093 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4667472013018348, 'Total loss': 0.4667472013018348} | train loss {'Reaction outcome loss': 0.13133715154925504, 'Total loss': 0.13133715154925504}
2022-12-05 19:32:48,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:48,094 INFO:     Epoch: 61
2022-12-05 19:32:48,887 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4729019840332595, 'Total loss': 0.4729019840332595} | train loss {'Reaction outcome loss': 0.1315610000848589, 'Total loss': 0.1315610000848589}
2022-12-05 19:32:48,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:48,887 INFO:     Epoch: 62
2022-12-05 19:32:49,678 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47532730481841345, 'Total loss': 0.47532730481841345} | train loss {'Reaction outcome loss': 0.13667920608024456, 'Total loss': 0.13667920608024456}
2022-12-05 19:32:49,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:49,679 INFO:     Epoch: 63
2022-12-05 19:32:50,472 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4608006744899533, 'Total loss': 0.4608006744899533} | train loss {'Reaction outcome loss': 0.12965592152254302, 'Total loss': 0.12965592152254302}
2022-12-05 19:32:50,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:50,472 INFO:     Epoch: 64
2022-12-05 19:32:51,263 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4845262767577713, 'Total loss': 0.4845262767577713} | train loss {'Reaction outcome loss': 0.12963960463037857, 'Total loss': 0.12963960463037857}
2022-12-05 19:32:51,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:51,263 INFO:     Epoch: 65
2022-12-05 19:32:52,054 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4728786058046601, 'Total loss': 0.4728786058046601} | train loss {'Reaction outcome loss': 0.12836429476172395, 'Total loss': 0.12836429476172395}
2022-12-05 19:32:52,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:52,055 INFO:     Epoch: 66
2022-12-05 19:32:52,845 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48339986530217255, 'Total loss': 0.48339986530217255} | train loss {'Reaction outcome loss': 0.1293627640123098, 'Total loss': 0.1293627640123098}
2022-12-05 19:32:52,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:52,846 INFO:     Epoch: 67
2022-12-05 19:32:53,643 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47287816080180084, 'Total loss': 0.47287816080180084} | train loss {'Reaction outcome loss': 0.12712874520110035, 'Total loss': 0.12712874520110035}
2022-12-05 19:32:53,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:53,643 INFO:     Epoch: 68
2022-12-05 19:32:54,434 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.484880461611531, 'Total loss': 0.484880461611531} | train loss {'Reaction outcome loss': 0.12676126051219067, 'Total loss': 0.12676126051219067}
2022-12-05 19:32:54,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:54,435 INFO:     Epoch: 69
2022-12-05 19:32:55,225 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49031389538537373, 'Total loss': 0.49031389538537373} | train loss {'Reaction outcome loss': 0.12631058940939183, 'Total loss': 0.12631058940939183}
2022-12-05 19:32:55,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:55,225 INFO:     Epoch: 70
2022-12-05 19:32:56,019 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4751434190706773, 'Total loss': 0.4751434190706773} | train loss {'Reaction outcome loss': 0.12756729061500385, 'Total loss': 0.12756729061500385}
2022-12-05 19:32:56,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:56,019 INFO:     Epoch: 71
2022-12-05 19:32:56,810 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4928328078240156, 'Total loss': 0.4928328078240156} | train loss {'Reaction outcome loss': 0.12691661492291734, 'Total loss': 0.12691661492291734}
2022-12-05 19:32:56,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:56,811 INFO:     Epoch: 72
2022-12-05 19:32:57,602 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47503224963491614, 'Total loss': 0.47503224963491614} | train loss {'Reaction outcome loss': 0.1245613281948771, 'Total loss': 0.1245613281948771}
2022-12-05 19:32:57,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:57,603 INFO:     Epoch: 73
2022-12-05 19:32:58,397 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4820106311447241, 'Total loss': 0.4820106311447241} | train loss {'Reaction outcome loss': 0.12329141750765836, 'Total loss': 0.12329141750765836}
2022-12-05 19:32:58,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:58,397 INFO:     Epoch: 74
2022-12-05 19:32:59,190 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46018321261825884, 'Total loss': 0.46018321261825884} | train loss {'Reaction outcome loss': 0.12582790294684743, 'Total loss': 0.12582790294684743}
2022-12-05 19:32:59,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:59,190 INFO:     Epoch: 75
2022-12-05 19:32:59,992 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46094512414525857, 'Total loss': 0.46094512414525857} | train loss {'Reaction outcome loss': 0.12591800297259803, 'Total loss': 0.12591800297259803}
2022-12-05 19:32:59,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:32:59,993 INFO:     Epoch: 76
2022-12-05 19:33:00,789 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4833079468120228, 'Total loss': 0.4833079468120228} | train loss {'Reaction outcome loss': 0.12163141952367568, 'Total loss': 0.12163141952367568}
2022-12-05 19:33:00,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:00,789 INFO:     Epoch: 77
2022-12-05 19:33:01,581 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4738833975385536, 'Total loss': 0.4738833975385536} | train loss {'Reaction outcome loss': 0.11965845624429856, 'Total loss': 0.11965845624429856}
2022-12-05 19:33:01,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:01,581 INFO:     Epoch: 78
2022-12-05 19:33:02,374 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48046087846159935, 'Total loss': 0.48046087846159935} | train loss {'Reaction outcome loss': 0.12111329746565513, 'Total loss': 0.12111329746565513}
2022-12-05 19:33:02,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:02,374 INFO:     Epoch: 79
2022-12-05 19:33:03,168 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49321036210114305, 'Total loss': 0.49321036210114305} | train loss {'Reaction outcome loss': 0.12083430625196652, 'Total loss': 0.12083430625196652}
2022-12-05 19:33:03,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:03,168 INFO:     Epoch: 80
2022-12-05 19:33:03,964 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4913997081193057, 'Total loss': 0.4913997081193057} | train loss {'Reaction outcome loss': 0.13039087592379042, 'Total loss': 0.13039087592379042}
2022-12-05 19:33:03,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:03,964 INFO:     Epoch: 81
2022-12-05 19:33:04,758 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4917533539912917, 'Total loss': 0.4917533539912917} | train loss {'Reaction outcome loss': 0.11996218286594187, 'Total loss': 0.11996218286594187}
2022-12-05 19:33:04,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:04,758 INFO:     Epoch: 82
2022-12-05 19:33:05,550 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48368058929389174, 'Total loss': 0.48368058929389174} | train loss {'Reaction outcome loss': 0.11925163668832979, 'Total loss': 0.11925163668832979}
2022-12-05 19:33:05,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:05,550 INFO:     Epoch: 83
2022-12-05 19:33:06,343 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47805372523990547, 'Total loss': 0.47805372523990547} | train loss {'Reaction outcome loss': 0.12079871930031158, 'Total loss': 0.12079871930031158}
2022-12-05 19:33:06,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:06,344 INFO:     Epoch: 84
2022-12-05 19:33:07,135 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49499455805529247, 'Total loss': 0.49499455805529247} | train loss {'Reaction outcome loss': 0.12536648329090977, 'Total loss': 0.12536648329090977}
2022-12-05 19:33:07,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:07,135 INFO:     Epoch: 85
2022-12-05 19:33:07,926 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4909194924614646, 'Total loss': 0.4909194924614646} | train loss {'Reaction outcome loss': 0.1195845022526106, 'Total loss': 0.1195845022526106}
2022-12-05 19:33:07,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:07,927 INFO:     Epoch: 86
2022-12-05 19:33:08,723 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47587091340260074, 'Total loss': 0.47587091340260074} | train loss {'Reaction outcome loss': 0.11769553654551929, 'Total loss': 0.11769553654551929}
2022-12-05 19:33:08,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:08,723 INFO:     Epoch: 87
2022-12-05 19:33:09,519 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48909706266766245, 'Total loss': 0.48909706266766245} | train loss {'Reaction outcome loss': 0.11590883854082842, 'Total loss': 0.11590883854082842}
2022-12-05 19:33:09,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:09,519 INFO:     Epoch: 88
2022-12-05 19:33:10,311 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4756979021159085, 'Total loss': 0.4756979021159085} | train loss {'Reaction outcome loss': 0.12140723320877986, 'Total loss': 0.12140723320877986}
2022-12-05 19:33:10,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:10,311 INFO:     Epoch: 89
2022-12-05 19:33:11,102 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4794048944657499, 'Total loss': 0.4794048944657499} | train loss {'Reaction outcome loss': 0.12467221996034326, 'Total loss': 0.12467221996034326}
2022-12-05 19:33:11,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:11,103 INFO:     Epoch: 90
2022-12-05 19:33:11,893 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48268904198299756, 'Total loss': 0.48268904198299756} | train loss {'Reaction outcome loss': 0.11449340843267528, 'Total loss': 0.11449340843267528}
2022-12-05 19:33:11,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:11,894 INFO:     Epoch: 91
2022-12-05 19:33:12,683 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48166798935695126, 'Total loss': 0.48166798935695126} | train loss {'Reaction outcome loss': 0.11412848561610046, 'Total loss': 0.11412848561610046}
2022-12-05 19:33:12,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:12,684 INFO:     Epoch: 92
2022-12-05 19:33:13,479 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48790558156642044, 'Total loss': 0.48790558156642044} | train loss {'Reaction outcome loss': 0.11431165788415065, 'Total loss': 0.11431165788415065}
2022-12-05 19:33:13,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:13,479 INFO:     Epoch: 93
2022-12-05 19:33:14,274 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.478094689717347, 'Total loss': 0.478094689717347} | train loss {'Reaction outcome loss': 0.11828776490629504, 'Total loss': 0.11828776490629504}
2022-12-05 19:33:14,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:14,274 INFO:     Epoch: 94
2022-12-05 19:33:15,064 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4761837223036723, 'Total loss': 0.4761837223036723} | train loss {'Reaction outcome loss': 0.11689351344865705, 'Total loss': 0.11689351344865705}
2022-12-05 19:33:15,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:15,064 INFO:     Epoch: 95
2022-12-05 19:33:15,854 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48928778957236896, 'Total loss': 0.48928778957236896} | train loss {'Reaction outcome loss': 0.11706370093788092, 'Total loss': 0.11706370093788092}
2022-12-05 19:33:15,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:15,854 INFO:     Epoch: 96
2022-12-05 19:33:16,645 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48374302312731743, 'Total loss': 0.48374302312731743} | train loss {'Reaction outcome loss': 0.12021533924679041, 'Total loss': 0.12021533924679041}
2022-12-05 19:33:16,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:16,645 INFO:     Epoch: 97
2022-12-05 19:33:17,435 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4991356749087572, 'Total loss': 0.4991356749087572} | train loss {'Reaction outcome loss': 0.11520570691162155, 'Total loss': 0.11520570691162155}
2022-12-05 19:33:17,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:17,436 INFO:     Epoch: 98
2022-12-05 19:33:18,230 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48400708355686883, 'Total loss': 0.48400708355686883} | train loss {'Reaction outcome loss': 0.11361729426814718, 'Total loss': 0.11361729426814718}
2022-12-05 19:33:18,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:18,230 INFO:     Epoch: 99
2022-12-05 19:33:19,021 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.483617459169843, 'Total loss': 0.483617459169843} | train loss {'Reaction outcome loss': 0.11482939384510055, 'Total loss': 0.11482939384510055}
2022-12-05 19:33:19,022 INFO:     Best model found after epoch 11 of 100.
2022-12-05 19:33:19,022 INFO:   Done with stage: TRAINING
2022-12-05 19:33:19,022 INFO:   Starting stage: EVALUATION
2022-12-05 19:33:19,148 INFO:   Done with stage: EVALUATION
2022-12-05 19:33:19,157 INFO:   Leaving out SEQ value Fold_0
2022-12-05 19:33:19,169 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 19:33:19,169 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:33:19,800 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:33:19,800 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:33:19,868 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:33:19,868 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:33:19,868 INFO:     No hyperparam tuning for this model
2022-12-05 19:33:19,868 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:33:19,868 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:33:19,869 INFO:     None feature selector for col prot
2022-12-05 19:33:19,869 INFO:     None feature selector for col prot
2022-12-05 19:33:19,869 INFO:     None feature selector for col prot
2022-12-05 19:33:19,870 INFO:     None feature selector for col chem
2022-12-05 19:33:19,870 INFO:     None feature selector for col chem
2022-12-05 19:33:19,870 INFO:     None feature selector for col chem
2022-12-05 19:33:19,870 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:33:19,870 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:33:19,872 INFO:     Number of params in model 215821
2022-12-05 19:33:19,875 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:33:19,875 INFO:   Starting stage: TRAINING
2022-12-05 19:33:19,935 INFO:     Val loss before train {'Reaction outcome loss': 0.9612074827038964, 'Total loss': 0.9612074827038964}
2022-12-05 19:33:19,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:19,936 INFO:     Epoch: 0
2022-12-05 19:33:20,721 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.581136449824932, 'Total loss': 0.581136449824932} | train loss {'Reaction outcome loss': 0.7955583606237246, 'Total loss': 0.7955583606237246}
2022-12-05 19:33:20,721 INFO:     Found new best model at epoch 0
2022-12-05 19:33:20,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:20,722 INFO:     Epoch: 1
2022-12-05 19:33:21,498 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.491451924623445, 'Total loss': 0.491451924623445} | train loss {'Reaction outcome loss': 0.5282286317260177, 'Total loss': 0.5282286317260177}
2022-12-05 19:33:21,498 INFO:     Found new best model at epoch 1
2022-12-05 19:33:21,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:21,499 INFO:     Epoch: 2
2022-12-05 19:33:22,272 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4563149262306302, 'Total loss': 0.4563149262306302} | train loss {'Reaction outcome loss': 0.456168224352868, 'Total loss': 0.456168224352868}
2022-12-05 19:33:22,272 INFO:     Found new best model at epoch 2
2022-12-05 19:33:22,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:22,273 INFO:     Epoch: 3
2022-12-05 19:33:23,044 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4372322403414305, 'Total loss': 0.4372322403414305} | train loss {'Reaction outcome loss': 0.417671854481285, 'Total loss': 0.417671854481285}
2022-12-05 19:33:23,045 INFO:     Found new best model at epoch 3
2022-12-05 19:33:23,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:23,046 INFO:     Epoch: 4
2022-12-05 19:33:23,821 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43363642865835234, 'Total loss': 0.43363642865835234} | train loss {'Reaction outcome loss': 0.38625567053816445, 'Total loss': 0.38625567053816445}
2022-12-05 19:33:23,821 INFO:     Found new best model at epoch 4
2022-12-05 19:33:23,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:23,822 INFO:     Epoch: 5
2022-12-05 19:33:24,593 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4249205374440482, 'Total loss': 0.4249205374440482} | train loss {'Reaction outcome loss': 0.3652779115938846, 'Total loss': 0.3652779115938846}
2022-12-05 19:33:24,593 INFO:     Found new best model at epoch 5
2022-12-05 19:33:24,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:24,594 INFO:     Epoch: 6
2022-12-05 19:33:25,368 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4188272169856138, 'Total loss': 0.4188272169856138} | train loss {'Reaction outcome loss': 0.34415038166100104, 'Total loss': 0.34415038166100104}
2022-12-05 19:33:25,368 INFO:     Found new best model at epoch 6
2022-12-05 19:33:25,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:25,368 INFO:     Epoch: 7
2022-12-05 19:33:26,141 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4107032747462738, 'Total loss': 0.4107032747462738} | train loss {'Reaction outcome loss': 0.3295224694987383, 'Total loss': 0.3295224694987383}
2022-12-05 19:33:26,141 INFO:     Found new best model at epoch 7
2022-12-05 19:33:26,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:26,142 INFO:     Epoch: 8
2022-12-05 19:33:26,920 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4023241078437761, 'Total loss': 0.4023241078437761} | train loss {'Reaction outcome loss': 0.3142541339735926, 'Total loss': 0.3142541339735926}
2022-12-05 19:33:26,920 INFO:     Found new best model at epoch 8
2022-12-05 19:33:26,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:26,921 INFO:     Epoch: 9
2022-12-05 19:33:27,701 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41257759582164677, 'Total loss': 0.41257759582164677} | train loss {'Reaction outcome loss': 0.3027570844616419, 'Total loss': 0.3027570844616419}
2022-12-05 19:33:27,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:27,701 INFO:     Epoch: 10
2022-12-05 19:33:28,476 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4034078997928043, 'Total loss': 0.4034078997928043} | train loss {'Reaction outcome loss': 0.286128256025383, 'Total loss': 0.286128256025383}
2022-12-05 19:33:28,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:28,476 INFO:     Epoch: 11
2022-12-05 19:33:29,251 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41018098766027494, 'Total loss': 0.41018098766027494} | train loss {'Reaction outcome loss': 0.27393093254463174, 'Total loss': 0.27393093254463174}
2022-12-05 19:33:29,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:29,251 INFO:     Epoch: 12
2022-12-05 19:33:30,025 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3997026227934416, 'Total loss': 0.3997026227934416} | train loss {'Reaction outcome loss': 0.26243439516044936, 'Total loss': 0.26243439516044936}
2022-12-05 19:33:30,025 INFO:     Found new best model at epoch 12
2022-12-05 19:33:30,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:30,026 INFO:     Epoch: 13
2022-12-05 19:33:30,801 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41676544865896537, 'Total loss': 0.41676544865896537} | train loss {'Reaction outcome loss': 0.25293590042571473, 'Total loss': 0.25293590042571473}
2022-12-05 19:33:30,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:30,802 INFO:     Epoch: 14
2022-12-05 19:33:31,578 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39956982416468995, 'Total loss': 0.39956982416468995} | train loss {'Reaction outcome loss': 0.24517491774119957, 'Total loss': 0.24517491774119957}
2022-12-05 19:33:31,579 INFO:     Found new best model at epoch 14
2022-12-05 19:33:31,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:31,579 INFO:     Epoch: 15
2022-12-05 19:33:32,357 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4063538898562276, 'Total loss': 0.4063538898562276} | train loss {'Reaction outcome loss': 0.23674360998434785, 'Total loss': 0.23674360998434785}
2022-12-05 19:33:32,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:32,357 INFO:     Epoch: 16
2022-12-05 19:33:33,135 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41198670760143635, 'Total loss': 0.41198670760143635} | train loss {'Reaction outcome loss': 0.22837830537263257, 'Total loss': 0.22837830537263257}
2022-12-05 19:33:33,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:33,135 INFO:     Epoch: 17
2022-12-05 19:33:33,908 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.394026864753213, 'Total loss': 0.394026864753213} | train loss {'Reaction outcome loss': 0.2255060901336464, 'Total loss': 0.2255060901336464}
2022-12-05 19:33:33,908 INFO:     Found new best model at epoch 17
2022-12-05 19:33:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:33,909 INFO:     Epoch: 18
2022-12-05 19:33:34,680 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3990217235892318, 'Total loss': 0.3990217235892318} | train loss {'Reaction outcome loss': 0.21821777916555543, 'Total loss': 0.21821777916555543}
2022-12-05 19:33:34,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:34,680 INFO:     Epoch: 19
2022-12-05 19:33:35,454 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40495567924754566, 'Total loss': 0.40495567924754566} | train loss {'Reaction outcome loss': 0.21080096433544723, 'Total loss': 0.21080096433544723}
2022-12-05 19:33:35,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:35,454 INFO:     Epoch: 20
2022-12-05 19:33:36,230 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.396484624334546, 'Total loss': 0.396484624334546} | train loss {'Reaction outcome loss': 0.2044568879016265, 'Total loss': 0.2044568879016265}
2022-12-05 19:33:36,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:36,230 INFO:     Epoch: 21
2022-12-05 19:33:37,007 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40684932262398477, 'Total loss': 0.40684932262398477} | train loss {'Reaction outcome loss': 0.19917678294910324, 'Total loss': 0.19917678294910324}
2022-12-05 19:33:37,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:37,008 INFO:     Epoch: 22
2022-12-05 19:33:37,787 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4222659106517947, 'Total loss': 0.4222659106517947} | train loss {'Reaction outcome loss': 0.196613659338696, 'Total loss': 0.196613659338696}
2022-12-05 19:33:37,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:37,787 INFO:     Epoch: 23
2022-12-05 19:33:38,559 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4073134875574777, 'Total loss': 0.4073134875574777} | train loss {'Reaction outcome loss': 0.19125455148794032, 'Total loss': 0.19125455148794032}
2022-12-05 19:33:38,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:38,559 INFO:     Epoch: 24
2022-12-05 19:33:39,329 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39698946250732553, 'Total loss': 0.39698946250732553} | train loss {'Reaction outcome loss': 0.1861701508669696, 'Total loss': 0.1861701508669696}
2022-12-05 19:33:39,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:39,329 INFO:     Epoch: 25
2022-12-05 19:33:40,102 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39195628758779794, 'Total loss': 0.39195628758779794} | train loss {'Reaction outcome loss': 0.1808014411647869, 'Total loss': 0.1808014411647869}
2022-12-05 19:33:40,102 INFO:     Found new best model at epoch 25
2022-12-05 19:33:40,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:40,103 INFO:     Epoch: 26
2022-12-05 19:33:40,877 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4007119040849597, 'Total loss': 0.4007119040849597} | train loss {'Reaction outcome loss': 0.179218792942939, 'Total loss': 0.179218792942939}
2022-12-05 19:33:40,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:40,878 INFO:     Epoch: 27
2022-12-05 19:33:41,654 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4007759368003801, 'Total loss': 0.4007759368003801} | train loss {'Reaction outcome loss': 0.17752502863237887, 'Total loss': 0.17752502863237887}
2022-12-05 19:33:41,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:41,654 INFO:     Epoch: 28
2022-12-05 19:33:42,427 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4110514268625614, 'Total loss': 0.4110514268625614} | train loss {'Reaction outcome loss': 0.1716425940854314, 'Total loss': 0.1716425940854314}
2022-12-05 19:33:42,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:42,427 INFO:     Epoch: 29
2022-12-05 19:33:43,201 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4041175679411999, 'Total loss': 0.4041175679411999} | train loss {'Reaction outcome loss': 0.1707868078807867, 'Total loss': 0.1707868078807867}
2022-12-05 19:33:43,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:43,202 INFO:     Epoch: 30
2022-12-05 19:33:43,984 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40554462823756904, 'Total loss': 0.40554462823756904} | train loss {'Reaction outcome loss': 0.16706650217404825, 'Total loss': 0.16706650217404825}
2022-12-05 19:33:43,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:43,984 INFO:     Epoch: 31
2022-12-05 19:33:44,757 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41675282858831936, 'Total loss': 0.41675282858831936} | train loss {'Reaction outcome loss': 0.16369164364082822, 'Total loss': 0.16369164364082822}
2022-12-05 19:33:44,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:44,758 INFO:     Epoch: 32
2022-12-05 19:33:45,531 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4092822896186696, 'Total loss': 0.4092822896186696} | train loss {'Reaction outcome loss': 0.1623171124331377, 'Total loss': 0.1623171124331377}
2022-12-05 19:33:45,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:45,531 INFO:     Epoch: 33
2022-12-05 19:33:46,308 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4192829622432243, 'Total loss': 0.4192829622432243} | train loss {'Reaction outcome loss': 0.16049069071134914, 'Total loss': 0.16049069071134914}
2022-12-05 19:33:46,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:46,308 INFO:     Epoch: 34
2022-12-05 19:33:47,084 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4021134282960448, 'Total loss': 0.4021134282960448} | train loss {'Reaction outcome loss': 0.1580536341133677, 'Total loss': 0.1580536341133677}
2022-12-05 19:33:47,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:47,084 INFO:     Epoch: 35
2022-12-05 19:33:47,858 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4107474750557611, 'Total loss': 0.4107474750557611} | train loss {'Reaction outcome loss': 0.1573771991548531, 'Total loss': 0.1573771991548531}
2022-12-05 19:33:47,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:47,859 INFO:     Epoch: 36
2022-12-05 19:33:48,634 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41369029099858085, 'Total loss': 0.41369029099858085} | train loss {'Reaction outcome loss': 0.1544922485319062, 'Total loss': 0.1544922485319062}
2022-12-05 19:33:48,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:48,634 INFO:     Epoch: 37
2022-12-05 19:33:49,408 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4115359284156977, 'Total loss': 0.4115359284156977} | train loss {'Reaction outcome loss': 0.15144534928747166, 'Total loss': 0.15144534928747166}
2022-12-05 19:33:49,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:49,409 INFO:     Epoch: 38
2022-12-05 19:33:50,188 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4280548716007277, 'Total loss': 0.4280548716007277} | train loss {'Reaction outcome loss': 0.15057846112751666, 'Total loss': 0.15057846112751666}
2022-12-05 19:33:50,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:50,188 INFO:     Epoch: 39
2022-12-05 19:33:50,965 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4260543283334998, 'Total loss': 0.4260543283334998} | train loss {'Reaction outcome loss': 0.15030596837585355, 'Total loss': 0.15030596837585355}
2022-12-05 19:33:50,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:50,965 INFO:     Epoch: 40
2022-12-05 19:33:51,741 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4264466398677161, 'Total loss': 0.4264466398677161} | train loss {'Reaction outcome loss': 0.14644116816329367, 'Total loss': 0.14644116816329367}
2022-12-05 19:33:51,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:51,742 INFO:     Epoch: 41
2022-12-05 19:33:52,515 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41187972523445304, 'Total loss': 0.41187972523445304} | train loss {'Reaction outcome loss': 0.14679585483860333, 'Total loss': 0.14679585483860333}
2022-12-05 19:33:52,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:52,516 INFO:     Epoch: 42
2022-12-05 19:33:53,289 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41473111839488497, 'Total loss': 0.41473111839488497} | train loss {'Reaction outcome loss': 0.1455834833023602, 'Total loss': 0.1455834833023602}
2022-12-05 19:33:53,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:53,289 INFO:     Epoch: 43
2022-12-05 19:33:54,067 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4269993849271952, 'Total loss': 0.4269993849271952} | train loss {'Reaction outcome loss': 0.14279640063551474, 'Total loss': 0.14279640063551474}
2022-12-05 19:33:54,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:54,067 INFO:     Epoch: 44
2022-12-05 19:33:54,840 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4153005829037622, 'Total loss': 0.4153005829037622} | train loss {'Reaction outcome loss': 0.13886915408688072, 'Total loss': 0.13886915408688072}
2022-12-05 19:33:54,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:54,840 INFO:     Epoch: 45
2022-12-05 19:33:55,616 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42557249980610473, 'Total loss': 0.42557249980610473} | train loss {'Reaction outcome loss': 0.13811994855265314, 'Total loss': 0.13811994855265314}
2022-12-05 19:33:55,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:55,617 INFO:     Epoch: 46
2022-12-05 19:33:56,390 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4244462792263475, 'Total loss': 0.4244462792263475} | train loss {'Reaction outcome loss': 0.1367554693126384, 'Total loss': 0.1367554693126384}
2022-12-05 19:33:56,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:56,390 INFO:     Epoch: 47
2022-12-05 19:33:57,167 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4289034660472426, 'Total loss': 0.4289034660472426} | train loss {'Reaction outcome loss': 0.13405775892789717, 'Total loss': 0.13405775892789717}
2022-12-05 19:33:57,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:57,167 INFO:     Epoch: 48
2022-12-05 19:33:57,940 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41657219099444015, 'Total loss': 0.41657219099444015} | train loss {'Reaction outcome loss': 0.13785748973243522, 'Total loss': 0.13785748973243522}
2022-12-05 19:33:57,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:57,940 INFO:     Epoch: 49
2022-12-05 19:33:58,713 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42451554861699425, 'Total loss': 0.42451554861699425} | train loss {'Reaction outcome loss': 0.1354434923824582, 'Total loss': 0.1354434923824582}
2022-12-05 19:33:58,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:58,713 INFO:     Epoch: 50
2022-12-05 19:33:59,486 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4295511874695157, 'Total loss': 0.4295511874695157} | train loss {'Reaction outcome loss': 0.13540556533990328, 'Total loss': 0.13540556533990328}
2022-12-05 19:33:59,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:33:59,486 INFO:     Epoch: 51
2022-12-05 19:34:00,260 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4273060369630193, 'Total loss': 0.4273060369630193} | train loss {'Reaction outcome loss': 0.13567846573490666, 'Total loss': 0.13567846573490666}
2022-12-05 19:34:00,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:00,260 INFO:     Epoch: 52
2022-12-05 19:34:01,034 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4362888821335726, 'Total loss': 0.4362888821335726} | train loss {'Reaction outcome loss': 0.13366136208575202, 'Total loss': 0.13366136208575202}
2022-12-05 19:34:01,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:01,034 INFO:     Epoch: 53
2022-12-05 19:34:01,807 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4179701309564502, 'Total loss': 0.4179701309564502} | train loss {'Reaction outcome loss': 0.13014510218743924, 'Total loss': 0.13014510218743924}
2022-12-05 19:34:01,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:01,808 INFO:     Epoch: 54
2022-12-05 19:34:02,582 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40938229668279025, 'Total loss': 0.40938229668279025} | train loss {'Reaction outcome loss': 0.13132056985778634, 'Total loss': 0.13132056985778634}
2022-12-05 19:34:02,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:02,582 INFO:     Epoch: 55
2022-12-05 19:34:03,355 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4194061638310898, 'Total loss': 0.4194061638310898} | train loss {'Reaction outcome loss': 0.12966382169689783, 'Total loss': 0.12966382169689783}
2022-12-05 19:34:03,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:03,356 INFO:     Epoch: 56
2022-12-05 19:34:04,132 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4289341243200524, 'Total loss': 0.4289341243200524} | train loss {'Reaction outcome loss': 0.12633399570307124, 'Total loss': 0.12633399570307124}
2022-12-05 19:34:04,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:04,133 INFO:     Epoch: 57
2022-12-05 19:34:04,906 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4282661166995071, 'Total loss': 0.4282661166995071} | train loss {'Reaction outcome loss': 0.13067930487249, 'Total loss': 0.13067930487249}
2022-12-05 19:34:04,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:04,907 INFO:     Epoch: 58
2022-12-05 19:34:05,685 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4279669665319975, 'Total loss': 0.4279669665319975} | train loss {'Reaction outcome loss': 0.12965682985973948, 'Total loss': 0.12965682985973948}
2022-12-05 19:34:05,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:05,686 INFO:     Epoch: 59
2022-12-05 19:34:06,481 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42194302362758057, 'Total loss': 0.42194302362758057} | train loss {'Reaction outcome loss': 0.1266042646250607, 'Total loss': 0.1266042646250607}
2022-12-05 19:34:06,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:06,481 INFO:     Epoch: 60
2022-12-05 19:34:07,272 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4341073982244314, 'Total loss': 0.4341073982244314} | train loss {'Reaction outcome loss': 0.12649479776682188, 'Total loss': 0.12649479776682188}
2022-12-05 19:34:07,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:07,273 INFO:     Epoch: 61
2022-12-05 19:34:08,065 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4179810762058857, 'Total loss': 0.4179810762058857} | train loss {'Reaction outcome loss': 0.1250856601261369, 'Total loss': 0.1250856601261369}
2022-12-05 19:34:08,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:08,066 INFO:     Epoch: 62
2022-12-05 19:34:08,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42412272511526594, 'Total loss': 0.42412272511526594} | train loss {'Reaction outcome loss': 0.12449581041134924, 'Total loss': 0.12449581041134924}
2022-12-05 19:34:08,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:08,856 INFO:     Epoch: 63
2022-12-05 19:34:09,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44045179735782536, 'Total loss': 0.44045179735782536} | train loss {'Reaction outcome loss': 0.12404006153897003, 'Total loss': 0.12404006153897003}
2022-12-05 19:34:09,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:09,646 INFO:     Epoch: 64
2022-12-05 19:34:10,436 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41438047761140867, 'Total loss': 0.41438047761140867} | train loss {'Reaction outcome loss': 0.12300423223816563, 'Total loss': 0.12300423223816563}
2022-12-05 19:34:10,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:10,436 INFO:     Epoch: 65
2022-12-05 19:34:11,226 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42495854718740594, 'Total loss': 0.42495854718740594} | train loss {'Reaction outcome loss': 0.12062893208852153, 'Total loss': 0.12062893208852153}
2022-12-05 19:34:11,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:11,227 INFO:     Epoch: 66
2022-12-05 19:34:12,016 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41434443412825117, 'Total loss': 0.41434443412825117} | train loss {'Reaction outcome loss': 0.1226527251747778, 'Total loss': 0.1226527251747778}
2022-12-05 19:34:12,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:12,017 INFO:     Epoch: 67
2022-12-05 19:34:12,807 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43012362649274427, 'Total loss': 0.43012362649274427} | train loss {'Reaction outcome loss': 0.12135687654401049, 'Total loss': 0.12135687654401049}
2022-12-05 19:34:12,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:12,807 INFO:     Epoch: 68
2022-12-05 19:34:13,597 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42102494905161303, 'Total loss': 0.42102494905161303} | train loss {'Reaction outcome loss': 0.12076522688546176, 'Total loss': 0.12076522688546176}
2022-12-05 19:34:13,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:13,598 INFO:     Epoch: 69
2022-12-05 19:34:14,390 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43132812131282894, 'Total loss': 0.43132812131282894} | train loss {'Reaction outcome loss': 0.1187463370400937, 'Total loss': 0.1187463370400937}
2022-12-05 19:34:14,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:14,390 INFO:     Epoch: 70
2022-12-05 19:34:15,181 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42037025405917056, 'Total loss': 0.42037025405917056} | train loss {'Reaction outcome loss': 0.12052647255882314, 'Total loss': 0.12052647255882314}
2022-12-05 19:34:15,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:15,181 INFO:     Epoch: 71
2022-12-05 19:34:15,975 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44290945436372314, 'Total loss': 0.44290945436372314} | train loss {'Reaction outcome loss': 0.11800842902358667, 'Total loss': 0.11800842902358667}
2022-12-05 19:34:15,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:15,975 INFO:     Epoch: 72
2022-12-05 19:34:16,772 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43307461814824927, 'Total loss': 0.43307461814824927} | train loss {'Reaction outcome loss': 0.11917245347022151, 'Total loss': 0.11917245347022151}
2022-12-05 19:34:16,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:16,772 INFO:     Epoch: 73
2022-12-05 19:34:17,563 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42177686233853184, 'Total loss': 0.42177686233853184} | train loss {'Reaction outcome loss': 0.1178604847111513, 'Total loss': 0.1178604847111513}
2022-12-05 19:34:17,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:17,563 INFO:     Epoch: 74
2022-12-05 19:34:18,360 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43546929886174757, 'Total loss': 0.43546929886174757} | train loss {'Reaction outcome loss': 0.11662949574823825, 'Total loss': 0.11662949574823825}
2022-12-05 19:34:18,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:18,361 INFO:     Epoch: 75
2022-12-05 19:34:19,154 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41191179781805637, 'Total loss': 0.41191179781805637} | train loss {'Reaction outcome loss': 0.11507582710097725, 'Total loss': 0.11507582710097725}
2022-12-05 19:34:19,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:19,154 INFO:     Epoch: 76
2022-12-05 19:34:19,947 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43098625402117885, 'Total loss': 0.43098625402117885} | train loss {'Reaction outcome loss': 0.11546192197090804, 'Total loss': 0.11546192197090804}
2022-12-05 19:34:19,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:19,947 INFO:     Epoch: 77
2022-12-05 19:34:20,743 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4163796922495199, 'Total loss': 0.4163796922495199} | train loss {'Reaction outcome loss': 0.11864049470918292, 'Total loss': 0.11864049470918292}
2022-12-05 19:34:20,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:20,744 INFO:     Epoch: 78
2022-12-05 19:34:21,542 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42081836073897605, 'Total loss': 0.42081836073897605} | train loss {'Reaction outcome loss': 0.11512242298603917, 'Total loss': 0.11512242298603917}
2022-12-05 19:34:21,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:21,543 INFO:     Epoch: 79
2022-12-05 19:34:22,328 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.426155453504518, 'Total loss': 0.426155453504518} | train loss {'Reaction outcome loss': 0.11358868485554256, 'Total loss': 0.11358868485554256}
2022-12-05 19:34:22,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:22,328 INFO:     Epoch: 80
2022-12-05 19:34:23,109 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40881706912850224, 'Total loss': 0.40881706912850224} | train loss {'Reaction outcome loss': 0.11451582770809961, 'Total loss': 0.11451582770809961}
2022-12-05 19:34:23,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:23,110 INFO:     Epoch: 81
2022-12-05 19:34:23,890 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.432505443518938, 'Total loss': 0.432505443518938} | train loss {'Reaction outcome loss': 0.1122933967966479, 'Total loss': 0.1122933967966479}
2022-12-05 19:34:23,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:23,890 INFO:     Epoch: 82
2022-12-05 19:34:24,671 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40735446938941644, 'Total loss': 0.40735446938941644} | train loss {'Reaction outcome loss': 0.11185734652350714, 'Total loss': 0.11185734652350714}
2022-12-05 19:34:24,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:24,672 INFO:     Epoch: 83
2022-12-05 19:34:25,453 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44050944509894346, 'Total loss': 0.44050944509894346} | train loss {'Reaction outcome loss': 0.11135782797748046, 'Total loss': 0.11135782797748046}
2022-12-05 19:34:25,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:25,453 INFO:     Epoch: 84
2022-12-05 19:34:26,233 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4085558344458425, 'Total loss': 0.4085558344458425} | train loss {'Reaction outcome loss': 0.11087940843323621, 'Total loss': 0.11087940843323621}
2022-12-05 19:34:26,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:26,234 INFO:     Epoch: 85
2022-12-05 19:34:27,013 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4435843721378681, 'Total loss': 0.4435843721378681} | train loss {'Reaction outcome loss': 0.1105854518121346, 'Total loss': 0.1105854518121346}
2022-12-05 19:34:27,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:27,013 INFO:     Epoch: 86
2022-12-05 19:34:27,796 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41252093073413815, 'Total loss': 0.41252093073413815} | train loss {'Reaction outcome loss': 0.11262669595180716, 'Total loss': 0.11262669595180716}
2022-12-05 19:34:27,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:27,796 INFO:     Epoch: 87
2022-12-05 19:34:28,578 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42295714103898335, 'Total loss': 0.42295714103898335} | train loss {'Reaction outcome loss': 0.11025023194788783, 'Total loss': 0.11025023194788783}
2022-12-05 19:34:28,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:28,578 INFO:     Epoch: 88
2022-12-05 19:34:29,355 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4165379709975664, 'Total loss': 0.4165379709975664} | train loss {'Reaction outcome loss': 0.113443351714822, 'Total loss': 0.113443351714822}
2022-12-05 19:34:29,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:29,356 INFO:     Epoch: 89
2022-12-05 19:34:30,136 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4172882056513498, 'Total loss': 0.4172882056513498} | train loss {'Reaction outcome loss': 0.11090589811404546, 'Total loss': 0.11090589811404546}
2022-12-05 19:34:30,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:30,136 INFO:     Epoch: 90
2022-12-05 19:34:30,921 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4375304363148157, 'Total loss': 0.4375304363148157} | train loss {'Reaction outcome loss': 0.10845658024428068, 'Total loss': 0.10845658024428068}
2022-12-05 19:34:30,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:30,921 INFO:     Epoch: 91
2022-12-05 19:34:31,701 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41442556194094726, 'Total loss': 0.41442556194094726} | train loss {'Reaction outcome loss': 0.11358075144359604, 'Total loss': 0.11358075144359604}
2022-12-05 19:34:31,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:31,701 INFO:     Epoch: 92
2022-12-05 19:34:32,476 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4259044500284417, 'Total loss': 0.4259044500284417} | train loss {'Reaction outcome loss': 0.11192628404761783, 'Total loss': 0.11192628404761783}
2022-12-05 19:34:32,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:32,477 INFO:     Epoch: 93
2022-12-05 19:34:33,255 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42568691906540895, 'Total loss': 0.42568691906540895} | train loss {'Reaction outcome loss': 0.10679496199835414, 'Total loss': 0.10679496199835414}
2022-12-05 19:34:33,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:33,255 INFO:     Epoch: 94
2022-12-05 19:34:34,032 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.412440983881784, 'Total loss': 0.412440983881784} | train loss {'Reaction outcome loss': 0.10800692217938081, 'Total loss': 0.10800692217938081}
2022-12-05 19:34:34,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:34,032 INFO:     Epoch: 95
2022-12-05 19:34:34,809 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4216587221206621, 'Total loss': 0.4216587221206621} | train loss {'Reaction outcome loss': 0.10787162500138513, 'Total loss': 0.10787162500138513}
2022-12-05 19:34:34,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:34,810 INFO:     Epoch: 96
2022-12-05 19:34:35,587 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4305395004014636, 'Total loss': 0.4305395004014636} | train loss {'Reaction outcome loss': 0.10761140194556718, 'Total loss': 0.10761140194556718}
2022-12-05 19:34:35,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:35,588 INFO:     Epoch: 97
2022-12-05 19:34:36,366 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4233327955007553, 'Total loss': 0.4233327955007553} | train loss {'Reaction outcome loss': 0.1070931230100646, 'Total loss': 0.1070931230100646}
2022-12-05 19:34:36,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:36,366 INFO:     Epoch: 98
2022-12-05 19:34:37,145 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42169039791753127, 'Total loss': 0.42169039791753127} | train loss {'Reaction outcome loss': 0.10638807275535639, 'Total loss': 0.10638807275535639}
2022-12-05 19:34:37,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:37,145 INFO:     Epoch: 99
2022-12-05 19:34:37,936 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43450387688570247, 'Total loss': 0.43450387688570247} | train loss {'Reaction outcome loss': 0.10731311373550582, 'Total loss': 0.10731311373550582}
2022-12-05 19:34:37,937 INFO:     Best model found after epoch 26 of 100.
2022-12-05 19:34:37,937 INFO:   Done with stage: TRAINING
2022-12-05 19:34:37,937 INFO:   Starting stage: EVALUATION
2022-12-05 19:34:38,081 INFO:   Done with stage: EVALUATION
2022-12-05 19:34:38,081 INFO:   Leaving out SEQ value Fold_1
2022-12-05 19:34:38,094 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:34:38,094 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:34:38,733 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:34:38,734 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:34:38,802 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:34:38,802 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:34:38,802 INFO:     No hyperparam tuning for this model
2022-12-05 19:34:38,802 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:34:38,802 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:34:38,803 INFO:     None feature selector for col prot
2022-12-05 19:34:38,803 INFO:     None feature selector for col prot
2022-12-05 19:34:38,803 INFO:     None feature selector for col prot
2022-12-05 19:34:38,804 INFO:     None feature selector for col chem
2022-12-05 19:34:38,804 INFO:     None feature selector for col chem
2022-12-05 19:34:38,804 INFO:     None feature selector for col chem
2022-12-05 19:34:38,804 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:34:38,804 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:34:38,806 INFO:     Number of params in model 215821
2022-12-05 19:34:38,809 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:34:38,809 INFO:   Starting stage: TRAINING
2022-12-05 19:34:38,869 INFO:     Val loss before train {'Reaction outcome loss': 1.0279263569550081, 'Total loss': 1.0279263569550081}
2022-12-05 19:34:38,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:38,869 INFO:     Epoch: 0
2022-12-05 19:34:39,665 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6050607992166822, 'Total loss': 0.6050607992166822} | train loss {'Reaction outcome loss': 0.8029786140812554, 'Total loss': 0.8029786140812554}
2022-12-05 19:34:39,665 INFO:     Found new best model at epoch 0
2022-12-05 19:34:39,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:39,666 INFO:     Epoch: 1
2022-12-05 19:34:40,462 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5158231725746935, 'Total loss': 0.5158231725746935} | train loss {'Reaction outcome loss': 0.5503583008702467, 'Total loss': 0.5503583008702467}
2022-12-05 19:34:40,462 INFO:     Found new best model at epoch 1
2022-12-05 19:34:40,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:40,463 INFO:     Epoch: 2
2022-12-05 19:34:41,256 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48565527390349994, 'Total loss': 0.48565527390349994} | train loss {'Reaction outcome loss': 0.4840248256680454, 'Total loss': 0.4840248256680454}
2022-12-05 19:34:41,256 INFO:     Found new best model at epoch 2
2022-12-05 19:34:41,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:41,257 INFO:     Epoch: 3
2022-12-05 19:34:42,049 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46611948243596335, 'Total loss': 0.46611948243596335} | train loss {'Reaction outcome loss': 0.44896260109024977, 'Total loss': 0.44896260109024977}
2022-12-05 19:34:42,049 INFO:     Found new best model at epoch 3
2022-12-05 19:34:42,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:42,050 INFO:     Epoch: 4
2022-12-05 19:34:42,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4285245754502036, 'Total loss': 0.4285245754502036} | train loss {'Reaction outcome loss': 0.4159712716635422, 'Total loss': 0.4159712716635422}
2022-12-05 19:34:42,838 INFO:     Found new best model at epoch 4
2022-12-05 19:34:42,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:42,839 INFO:     Epoch: 5
2022-12-05 19:34:43,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42364860529249365, 'Total loss': 0.42364860529249365} | train loss {'Reaction outcome loss': 0.3899079969808882, 'Total loss': 0.3899079969808882}
2022-12-05 19:34:43,627 INFO:     Found new best model at epoch 5
2022-12-05 19:34:43,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:43,628 INFO:     Epoch: 6
2022-12-05 19:34:44,414 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4211275320161473, 'Total loss': 0.4211275320161473} | train loss {'Reaction outcome loss': 0.36991456959411684, 'Total loss': 0.36991456959411684}
2022-12-05 19:34:44,415 INFO:     Found new best model at epoch 6
2022-12-05 19:34:44,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:44,415 INFO:     Epoch: 7
2022-12-05 19:34:45,206 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4055259603668343, 'Total loss': 0.4055259603668343} | train loss {'Reaction outcome loss': 0.35315568558871746, 'Total loss': 0.35315568558871746}
2022-12-05 19:34:45,206 INFO:     Found new best model at epoch 7
2022-12-05 19:34:45,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:45,207 INFO:     Epoch: 8
2022-12-05 19:34:46,002 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40232098813761363, 'Total loss': 0.40232098813761363} | train loss {'Reaction outcome loss': 0.33833297507965615, 'Total loss': 0.33833297507965615}
2022-12-05 19:34:46,002 INFO:     Found new best model at epoch 8
2022-12-05 19:34:46,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:46,003 INFO:     Epoch: 9
2022-12-05 19:34:46,804 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4002398753708059, 'Total loss': 0.4002398753708059} | train loss {'Reaction outcome loss': 0.3294058131423556, 'Total loss': 0.3294058131423556}
2022-12-05 19:34:46,804 INFO:     Found new best model at epoch 9
2022-12-05 19:34:46,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:46,805 INFO:     Epoch: 10
2022-12-05 19:34:47,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3986772373318672, 'Total loss': 0.3986772373318672} | train loss {'Reaction outcome loss': 0.3177213895234547, 'Total loss': 0.3177213895234547}
2022-12-05 19:34:47,610 INFO:     Found new best model at epoch 10
2022-12-05 19:34:47,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:47,611 INFO:     Epoch: 11
2022-12-05 19:34:48,411 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4146078293296424, 'Total loss': 0.4146078293296424} | train loss {'Reaction outcome loss': 0.3020044261748009, 'Total loss': 0.3020044261748009}
2022-12-05 19:34:48,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:48,411 INFO:     Epoch: 12
2022-12-05 19:34:49,219 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39746061407706956, 'Total loss': 0.39746061407706956} | train loss {'Reaction outcome loss': 0.29356520897275223, 'Total loss': 0.29356520897275223}
2022-12-05 19:34:49,219 INFO:     Found new best model at epoch 12
2022-12-05 19:34:49,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:49,220 INFO:     Epoch: 13
2022-12-05 19:34:50,018 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4096186923032457, 'Total loss': 0.4096186923032457} | train loss {'Reaction outcome loss': 0.2768447897189602, 'Total loss': 0.2768447897189602}
2022-12-05 19:34:50,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:50,018 INFO:     Epoch: 14
2022-12-05 19:34:50,817 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3973359309814193, 'Total loss': 0.3973359309814193} | train loss {'Reaction outcome loss': 0.27238756541901754, 'Total loss': 0.27238756541901754}
2022-12-05 19:34:50,818 INFO:     Found new best model at epoch 14
2022-12-05 19:34:50,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:50,819 INFO:     Epoch: 15
2022-12-05 19:34:51,617 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4059659737077626, 'Total loss': 0.4059659737077626} | train loss {'Reaction outcome loss': 0.2642813893374403, 'Total loss': 0.2642813893374403}
2022-12-05 19:34:51,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:51,617 INFO:     Epoch: 16
2022-12-05 19:34:52,417 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3959080593829805, 'Total loss': 0.3959080593829805} | train loss {'Reaction outcome loss': 0.25693913224541587, 'Total loss': 0.25693913224541587}
2022-12-05 19:34:52,418 INFO:     Found new best model at epoch 16
2022-12-05 19:34:52,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:52,418 INFO:     Epoch: 17
2022-12-05 19:34:53,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40273693119260395, 'Total loss': 0.40273693119260395} | train loss {'Reaction outcome loss': 0.24628376289787382, 'Total loss': 0.24628376289787382}
2022-12-05 19:34:53,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:53,223 INFO:     Epoch: 18
2022-12-05 19:34:54,024 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40200975808230316, 'Total loss': 0.40200975808230316} | train loss {'Reaction outcome loss': 0.2403522468575461, 'Total loss': 0.2403522468575461}
2022-12-05 19:34:54,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:54,024 INFO:     Epoch: 19
2022-12-05 19:34:54,822 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40583889931440353, 'Total loss': 0.40583889931440353} | train loss {'Reaction outcome loss': 0.23385823834857145, 'Total loss': 0.23385823834857145}
2022-12-05 19:34:54,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:54,823 INFO:     Epoch: 20
2022-12-05 19:34:55,629 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.412557144056667, 'Total loss': 0.412557144056667} | train loss {'Reaction outcome loss': 0.2310480267895378, 'Total loss': 0.2310480267895378}
2022-12-05 19:34:55,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:55,630 INFO:     Epoch: 21
2022-12-05 19:34:56,439 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4141614403236996, 'Total loss': 0.4141614403236996} | train loss {'Reaction outcome loss': 0.22865653113435638, 'Total loss': 0.22865653113435638}
2022-12-05 19:34:56,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:56,439 INFO:     Epoch: 22
2022-12-05 19:34:57,253 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4180187762460925, 'Total loss': 0.4180187762460925} | train loss {'Reaction outcome loss': 0.22557040115418706, 'Total loss': 0.22557040115418706}
2022-12-05 19:34:57,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:57,254 INFO:     Epoch: 23
2022-12-05 19:34:58,062 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4318476254967126, 'Total loss': 0.4318476254967126} | train loss {'Reaction outcome loss': 0.22227859528931349, 'Total loss': 0.22227859528931349}
2022-12-05 19:34:58,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:58,063 INFO:     Epoch: 24
2022-12-05 19:34:58,868 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4092949212274768, 'Total loss': 0.4092949212274768} | train loss {'Reaction outcome loss': 0.21072987946097246, 'Total loss': 0.21072987946097246}
2022-12-05 19:34:58,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:58,869 INFO:     Epoch: 25
2022-12-05 19:34:59,671 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4139146643944762, 'Total loss': 0.4139146643944762} | train loss {'Reaction outcome loss': 0.2056733170064234, 'Total loss': 0.2056733170064234}
2022-12-05 19:34:59,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:34:59,671 INFO:     Epoch: 26
2022-12-05 19:35:00,474 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41790181974118407, 'Total loss': 0.41790181974118407} | train loss {'Reaction outcome loss': 0.2063975372400723, 'Total loss': 0.2063975372400723}
2022-12-05 19:35:00,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:00,475 INFO:     Epoch: 27
2022-12-05 19:35:01,280 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4299850614572113, 'Total loss': 0.4299850614572113} | train loss {'Reaction outcome loss': 0.20492115529699, 'Total loss': 0.20492115529699}
2022-12-05 19:35:01,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:01,280 INFO:     Epoch: 28
2022-12-05 19:35:02,083 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4194458472457799, 'Total loss': 0.4194458472457799} | train loss {'Reaction outcome loss': 0.1955079163315325, 'Total loss': 0.1955079163315325}
2022-12-05 19:35:02,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:02,083 INFO:     Epoch: 29
2022-12-05 19:35:02,884 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41337990896268323, 'Total loss': 0.41337990896268323} | train loss {'Reaction outcome loss': 0.1960727220612318, 'Total loss': 0.1960727220612318}
2022-12-05 19:35:02,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:02,884 INFO:     Epoch: 30
2022-12-05 19:35:03,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4330242259258574, 'Total loss': 0.4330242259258574} | train loss {'Reaction outcome loss': 0.1912791372582256, 'Total loss': 0.1912791372582256}
2022-12-05 19:35:03,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:03,686 INFO:     Epoch: 31
2022-12-05 19:35:04,489 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42511147870258853, 'Total loss': 0.42511147870258853} | train loss {'Reaction outcome loss': 0.18864397801881136, 'Total loss': 0.18864397801881136}
2022-12-05 19:35:04,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:04,490 INFO:     Epoch: 32
2022-12-05 19:35:05,289 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41662195087833837, 'Total loss': 0.41662195087833837} | train loss {'Reaction outcome loss': 0.18559129616087264, 'Total loss': 0.18559129616087264}
2022-12-05 19:35:05,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:05,289 INFO:     Epoch: 33
2022-12-05 19:35:06,084 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4205447882413864, 'Total loss': 0.4205447882413864} | train loss {'Reaction outcome loss': 0.18476095040015847, 'Total loss': 0.18476095040015847}
2022-12-05 19:35:06,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:06,085 INFO:     Epoch: 34
2022-12-05 19:35:06,885 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42794911055402324, 'Total loss': 0.42794911055402324} | train loss {'Reaction outcome loss': 0.18170718706556058, 'Total loss': 0.18170718706556058}
2022-12-05 19:35:06,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:06,885 INFO:     Epoch: 35
2022-12-05 19:35:07,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4147373795170676, 'Total loss': 0.4147373795170676} | train loss {'Reaction outcome loss': 0.17570792007173303, 'Total loss': 0.17570792007173303}
2022-12-05 19:35:07,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:07,684 INFO:     Epoch: 36
2022-12-05 19:35:08,480 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42652308636090974, 'Total loss': 0.42652308636090974} | train loss {'Reaction outcome loss': 0.17531168090956292, 'Total loss': 0.17531168090956292}
2022-12-05 19:35:08,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:08,480 INFO:     Epoch: 37
2022-12-05 19:35:09,282 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4322990138422359, 'Total loss': 0.4322990138422359} | train loss {'Reaction outcome loss': 0.17501785683064808, 'Total loss': 0.17501785683064808}
2022-12-05 19:35:09,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:09,283 INFO:     Epoch: 38
2022-12-05 19:35:10,086 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41033230992880737, 'Total loss': 0.41033230992880737} | train loss {'Reaction outcome loss': 0.17606782294085876, 'Total loss': 0.17606782294085876}
2022-12-05 19:35:10,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:10,086 INFO:     Epoch: 39
2022-12-05 19:35:10,884 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4180846107615666, 'Total loss': 0.4180846107615666} | train loss {'Reaction outcome loss': 0.17168496925429053, 'Total loss': 0.17168496925429053}
2022-12-05 19:35:10,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:10,885 INFO:     Epoch: 40
2022-12-05 19:35:11,686 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41597154770385136, 'Total loss': 0.41597154770385136} | train loss {'Reaction outcome loss': 0.16762304560352975, 'Total loss': 0.16762304560352975}
2022-12-05 19:35:11,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:11,686 INFO:     Epoch: 41
2022-12-05 19:35:12,487 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4209254292601889, 'Total loss': 0.4209254292601889} | train loss {'Reaction outcome loss': 0.16826684083714177, 'Total loss': 0.16826684083714177}
2022-12-05 19:35:12,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:12,487 INFO:     Epoch: 42
2022-12-05 19:35:13,294 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4265918377786875, 'Total loss': 0.4265918377786875} | train loss {'Reaction outcome loss': 0.1701953725565059, 'Total loss': 0.1701953725565059}
2022-12-05 19:35:13,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:13,294 INFO:     Epoch: 43
2022-12-05 19:35:14,095 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44218619811263954, 'Total loss': 0.44218619811263954} | train loss {'Reaction outcome loss': 0.16303147203270119, 'Total loss': 0.16303147203270119}
2022-12-05 19:35:14,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:14,095 INFO:     Epoch: 44
2022-12-05 19:35:14,896 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4347727759317918, 'Total loss': 0.4347727759317918} | train loss {'Reaction outcome loss': 0.1625417881468047, 'Total loss': 0.1625417881468047}
2022-12-05 19:35:14,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:14,896 INFO:     Epoch: 45
2022-12-05 19:35:15,700 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.419753430580551, 'Total loss': 0.419753430580551} | train loss {'Reaction outcome loss': 0.16330751616824493, 'Total loss': 0.16330751616824493}
2022-12-05 19:35:15,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:15,701 INFO:     Epoch: 46
2022-12-05 19:35:16,507 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45821049504659395, 'Total loss': 0.45821049504659395} | train loss {'Reaction outcome loss': 0.16288778961820882, 'Total loss': 0.16288778961820882}
2022-12-05 19:35:16,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:16,507 INFO:     Epoch: 47
2022-12-05 19:35:17,310 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42643871649422427, 'Total loss': 0.42643871649422427} | train loss {'Reaction outcome loss': 0.1599293308189282, 'Total loss': 0.1599293308189282}
2022-12-05 19:35:17,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:17,310 INFO:     Epoch: 48
2022-12-05 19:35:18,113 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4203449868681756, 'Total loss': 0.4203449868681756} | train loss {'Reaction outcome loss': 0.15622157237288892, 'Total loss': 0.15622157237288892}
2022-12-05 19:35:18,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:18,113 INFO:     Epoch: 49
2022-12-05 19:35:18,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42188751765272836, 'Total loss': 0.42188751765272836} | train loss {'Reaction outcome loss': 0.15288154919054886, 'Total loss': 0.15288154919054886}
2022-12-05 19:35:18,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:18,921 INFO:     Epoch: 50
2022-12-05 19:35:19,734 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41780882294882427, 'Total loss': 0.41780882294882427} | train loss {'Reaction outcome loss': 0.15195751765569454, 'Total loss': 0.15195751765569454}
2022-12-05 19:35:19,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:19,734 INFO:     Epoch: 51
2022-12-05 19:35:20,542 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43805847791108216, 'Total loss': 0.43805847791108216} | train loss {'Reaction outcome loss': 0.1530048115638948, 'Total loss': 0.1530048115638948}
2022-12-05 19:35:20,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:20,542 INFO:     Epoch: 52
2022-12-05 19:35:21,347 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4339005567810752, 'Total loss': 0.4339005567810752} | train loss {'Reaction outcome loss': 0.15222379693437202, 'Total loss': 0.15222379693437202}
2022-12-05 19:35:21,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:21,347 INFO:     Epoch: 53
2022-12-05 19:35:22,147 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4395077616314996, 'Total loss': 0.4395077616314996} | train loss {'Reaction outcome loss': 0.16189734228256986, 'Total loss': 0.16189734228256986}
2022-12-05 19:35:22,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:22,148 INFO:     Epoch: 54
2022-12-05 19:35:22,946 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4240573617545041, 'Total loss': 0.4240573617545041} | train loss {'Reaction outcome loss': 0.15379706855395786, 'Total loss': 0.15379706855395786}
2022-12-05 19:35:22,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:22,947 INFO:     Epoch: 55
2022-12-05 19:35:23,746 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4366683851588856, 'Total loss': 0.4366683851588856} | train loss {'Reaction outcome loss': 0.1461779884692387, 'Total loss': 0.1461779884692387}
2022-12-05 19:35:23,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:23,746 INFO:     Epoch: 56
2022-12-05 19:35:24,545 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.444807753728872, 'Total loss': 0.444807753728872} | train loss {'Reaction outcome loss': 0.1461605590905194, 'Total loss': 0.1461605590905194}
2022-12-05 19:35:24,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:24,545 INFO:     Epoch: 57
2022-12-05 19:35:25,341 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44197565859014337, 'Total loss': 0.44197565859014337} | train loss {'Reaction outcome loss': 0.14430243086478925, 'Total loss': 0.14430243086478925}
2022-12-05 19:35:25,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:25,341 INFO:     Epoch: 58
2022-12-05 19:35:26,137 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4325019144876437, 'Total loss': 0.4325019144876437} | train loss {'Reaction outcome loss': 0.142947181131736, 'Total loss': 0.142947181131736}
2022-12-05 19:35:26,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:26,137 INFO:     Epoch: 59
2022-12-05 19:35:26,935 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4395682407035069, 'Total loss': 0.4395682407035069} | train loss {'Reaction outcome loss': 0.1477479557864941, 'Total loss': 0.1477479557864941}
2022-12-05 19:35:26,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:26,935 INFO:     Epoch: 60
2022-12-05 19:35:27,735 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4363469613546675, 'Total loss': 0.4363469613546675} | train loss {'Reaction outcome loss': 0.14521398665411736, 'Total loss': 0.14521398665411736}
2022-12-05 19:35:27,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:27,736 INFO:     Epoch: 61
2022-12-05 19:35:28,537 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4334403642199256, 'Total loss': 0.4334403642199256} | train loss {'Reaction outcome loss': 0.14226406543451522, 'Total loss': 0.14226406543451522}
2022-12-05 19:35:28,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:28,538 INFO:     Epoch: 62
2022-12-05 19:35:29,344 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44553294083611533, 'Total loss': 0.44553294083611533} | train loss {'Reaction outcome loss': 0.14249071399285365, 'Total loss': 0.14249071399285365}
2022-12-05 19:35:29,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:29,344 INFO:     Epoch: 63
2022-12-05 19:35:30,143 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43997541950507596, 'Total loss': 0.43997541950507596} | train loss {'Reaction outcome loss': 0.14114863351213666, 'Total loss': 0.14114863351213666}
2022-12-05 19:35:30,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:30,143 INFO:     Epoch: 64
2022-12-05 19:35:30,940 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4421687295491045, 'Total loss': 0.4421687295491045} | train loss {'Reaction outcome loss': 0.14203743206012828, 'Total loss': 0.14203743206012828}
2022-12-05 19:35:30,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:30,940 INFO:     Epoch: 65
2022-12-05 19:35:31,736 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.427379921332679, 'Total loss': 0.427379921332679} | train loss {'Reaction outcome loss': 0.1397464849235799, 'Total loss': 0.1397464849235799}
2022-12-05 19:35:31,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:31,736 INFO:     Epoch: 66
2022-12-05 19:35:32,534 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.441524628888477, 'Total loss': 0.441524628888477} | train loss {'Reaction outcome loss': 0.13942752779661283, 'Total loss': 0.13942752779661283}
2022-12-05 19:35:32,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:32,534 INFO:     Epoch: 67
2022-12-05 19:35:33,328 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43225298754193564, 'Total loss': 0.43225298754193564} | train loss {'Reaction outcome loss': 0.14258887662518363, 'Total loss': 0.14258887662518363}
2022-12-05 19:35:33,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:33,329 INFO:     Epoch: 68
2022-12-05 19:35:34,124 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43557462909004907, 'Total loss': 0.43557462909004907} | train loss {'Reaction outcome loss': 0.13575397007476522, 'Total loss': 0.13575397007476522}
2022-12-05 19:35:34,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:34,124 INFO:     Epoch: 69
2022-12-05 19:35:34,919 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4364899918437004, 'Total loss': 0.4364899918437004} | train loss {'Reaction outcome loss': 0.13850354128691597, 'Total loss': 0.13850354128691597}
2022-12-05 19:35:34,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:34,919 INFO:     Epoch: 70
2022-12-05 19:35:35,715 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42620872672308574, 'Total loss': 0.42620872672308574} | train loss {'Reaction outcome loss': 0.1366573071393829, 'Total loss': 0.1366573071393829}
2022-12-05 19:35:35,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:35,716 INFO:     Epoch: 71
2022-12-05 19:35:36,517 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4382994943721728, 'Total loss': 0.4382994943721728} | train loss {'Reaction outcome loss': 0.13372659719801747, 'Total loss': 0.13372659719801747}
2022-12-05 19:35:36,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:36,518 INFO:     Epoch: 72
2022-12-05 19:35:37,315 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44174662029201334, 'Total loss': 0.44174662029201334} | train loss {'Reaction outcome loss': 0.13414552036356106, 'Total loss': 0.13414552036356106}
2022-12-05 19:35:37,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:37,315 INFO:     Epoch: 73
2022-12-05 19:35:38,107 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43357968161051924, 'Total loss': 0.43357968161051924} | train loss {'Reaction outcome loss': 0.13453106661346037, 'Total loss': 0.13453106661346037}
2022-12-05 19:35:38,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:38,108 INFO:     Epoch: 74
2022-12-05 19:35:38,895 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.433632861145518, 'Total loss': 0.433632861145518} | train loss {'Reaction outcome loss': 0.13418417271633862, 'Total loss': 0.13418417271633862}
2022-12-05 19:35:38,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:38,895 INFO:     Epoch: 75
2022-12-05 19:35:39,685 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43230903724377806, 'Total loss': 0.43230903724377806} | train loss {'Reaction outcome loss': 0.1357977141978253, 'Total loss': 0.1357977141978253}
2022-12-05 19:35:39,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:39,685 INFO:     Epoch: 76
2022-12-05 19:35:40,476 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45103015581315214, 'Total loss': 0.45103015581315214} | train loss {'Reaction outcome loss': 0.13760914976297603, 'Total loss': 0.13760914976297603}
2022-12-05 19:35:40,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:40,476 INFO:     Epoch: 77
2022-12-05 19:35:41,263 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45144637843424623, 'Total loss': 0.45144637843424623} | train loss {'Reaction outcome loss': 0.13188934372549477, 'Total loss': 0.13188934372549477}
2022-12-05 19:35:41,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:41,263 INFO:     Epoch: 78
2022-12-05 19:35:42,055 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44279415939341893, 'Total loss': 0.44279415939341893} | train loss {'Reaction outcome loss': 0.13306353593373346, 'Total loss': 0.13306353593373346}
2022-12-05 19:35:42,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:42,056 INFO:     Epoch: 79
2022-12-05 19:35:42,846 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44214924120090227, 'Total loss': 0.44214924120090227} | train loss {'Reaction outcome loss': 0.13209064260147785, 'Total loss': 0.13209064260147785}
2022-12-05 19:35:42,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:42,846 INFO:     Epoch: 80
2022-12-05 19:35:43,640 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4468552077358419, 'Total loss': 0.4468552077358419} | train loss {'Reaction outcome loss': 0.13102137004044134, 'Total loss': 0.13102137004044134}
2022-12-05 19:35:43,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:43,640 INFO:     Epoch: 81
2022-12-05 19:35:44,432 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45228923112154007, 'Total loss': 0.45228923112154007} | train loss {'Reaction outcome loss': 0.13054582072414367, 'Total loss': 0.13054582072414367}
2022-12-05 19:35:44,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:44,432 INFO:     Epoch: 82
2022-12-05 19:35:45,219 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45190329917452554, 'Total loss': 0.45190329917452554} | train loss {'Reaction outcome loss': 0.1290254178588931, 'Total loss': 0.1290254178588931}
2022-12-05 19:35:45,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:45,219 INFO:     Epoch: 83
2022-12-05 19:35:46,010 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4350259652869268, 'Total loss': 0.4350259652869268} | train loss {'Reaction outcome loss': 0.1316312752354905, 'Total loss': 0.1316312752354905}
2022-12-05 19:35:46,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:46,010 INFO:     Epoch: 84
2022-12-05 19:35:46,798 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44494312900033867, 'Total loss': 0.44494312900033867} | train loss {'Reaction outcome loss': 0.1306605186645198, 'Total loss': 0.1306605186645198}
2022-12-05 19:35:46,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:46,799 INFO:     Epoch: 85
2022-12-05 19:35:47,590 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44659782014787197, 'Total loss': 0.44659782014787197} | train loss {'Reaction outcome loss': 0.12562565977764334, 'Total loss': 0.12562565977764334}
2022-12-05 19:35:47,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:47,591 INFO:     Epoch: 86
2022-12-05 19:35:48,383 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43593120168555866, 'Total loss': 0.43593120168555866} | train loss {'Reaction outcome loss': 0.130385063256812, 'Total loss': 0.130385063256812}
2022-12-05 19:35:48,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:48,383 INFO:     Epoch: 87
2022-12-05 19:35:49,181 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43571689995852386, 'Total loss': 0.43571689995852386} | train loss {'Reaction outcome loss': 0.12355013402095932, 'Total loss': 0.12355013402095932}
2022-12-05 19:35:49,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:49,181 INFO:     Epoch: 88
2022-12-05 19:35:49,980 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42904706121507014, 'Total loss': 0.42904706121507014} | train loss {'Reaction outcome loss': 0.1265530928117242, 'Total loss': 0.1265530928117242}
2022-12-05 19:35:49,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:49,980 INFO:     Epoch: 89
2022-12-05 19:35:50,778 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.438447157767686, 'Total loss': 0.438447157767686} | train loss {'Reaction outcome loss': 0.12497952741830938, 'Total loss': 0.12497952741830938}
2022-12-05 19:35:50,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:50,778 INFO:     Epoch: 90
2022-12-05 19:35:51,575 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43656096675179223, 'Total loss': 0.43656096675179223} | train loss {'Reaction outcome loss': 0.1316055641603856, 'Total loss': 0.1316055641603856}
2022-12-05 19:35:51,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:51,575 INFO:     Epoch: 91
2022-12-05 19:35:52,374 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42636806991967285, 'Total loss': 0.42636806991967285} | train loss {'Reaction outcome loss': 0.12339806364404286, 'Total loss': 0.12339806364404286}
2022-12-05 19:35:52,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:52,374 INFO:     Epoch: 92
2022-12-05 19:35:53,172 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44614050164818764, 'Total loss': 0.44614050164818764} | train loss {'Reaction outcome loss': 0.12473036115659167, 'Total loss': 0.12473036115659167}
2022-12-05 19:35:53,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:53,172 INFO:     Epoch: 93
2022-12-05 19:35:53,972 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4467806944792921, 'Total loss': 0.4467806944792921} | train loss {'Reaction outcome loss': 0.12501589013904574, 'Total loss': 0.12501589013904574}
2022-12-05 19:35:53,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:53,972 INFO:     Epoch: 94
2022-12-05 19:35:54,770 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44095229560678656, 'Total loss': 0.44095229560678656} | train loss {'Reaction outcome loss': 0.12569842677043094, 'Total loss': 0.12569842677043094}
2022-12-05 19:35:54,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:54,770 INFO:     Epoch: 95
2022-12-05 19:35:55,573 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44188080761920323, 'Total loss': 0.44188080761920323} | train loss {'Reaction outcome loss': 0.12133574472676194, 'Total loss': 0.12133574472676194}
2022-12-05 19:35:55,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:55,573 INFO:     Epoch: 96
2022-12-05 19:35:56,374 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45120643417943607, 'Total loss': 0.45120643417943607} | train loss {'Reaction outcome loss': 0.12420038946975882, 'Total loss': 0.12420038946975882}
2022-12-05 19:35:56,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:56,374 INFO:     Epoch: 97
2022-12-05 19:35:57,171 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43018631772561505, 'Total loss': 0.43018631772561505} | train loss {'Reaction outcome loss': 0.12591846323070618, 'Total loss': 0.12591846323070618}
2022-12-05 19:35:57,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:57,171 INFO:     Epoch: 98
2022-12-05 19:35:57,969 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44111510772596707, 'Total loss': 0.44111510772596707} | train loss {'Reaction outcome loss': 0.1227643173489614, 'Total loss': 0.1227643173489614}
2022-12-05 19:35:57,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:57,970 INFO:     Epoch: 99
2022-12-05 19:35:58,773 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43385274640538474, 'Total loss': 0.43385274640538474} | train loss {'Reaction outcome loss': 0.12324782676885455, 'Total loss': 0.12324782676885455}
2022-12-05 19:35:58,773 INFO:     Best model found after epoch 17 of 100.
2022-12-05 19:35:58,773 INFO:   Done with stage: TRAINING
2022-12-05 19:35:58,773 INFO:   Starting stage: EVALUATION
2022-12-05 19:35:58,900 INFO:   Done with stage: EVALUATION
2022-12-05 19:35:58,900 INFO:   Leaving out SEQ value Fold_2
2022-12-05 19:35:58,913 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:35:58,913 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:35:59,558 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:35:59,559 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:35:59,626 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:35:59,626 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:35:59,626 INFO:     No hyperparam tuning for this model
2022-12-05 19:35:59,626 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:35:59,626 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:35:59,627 INFO:     None feature selector for col prot
2022-12-05 19:35:59,627 INFO:     None feature selector for col prot
2022-12-05 19:35:59,627 INFO:     None feature selector for col prot
2022-12-05 19:35:59,628 INFO:     None feature selector for col chem
2022-12-05 19:35:59,628 INFO:     None feature selector for col chem
2022-12-05 19:35:59,628 INFO:     None feature selector for col chem
2022-12-05 19:35:59,628 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:35:59,628 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:35:59,630 INFO:     Number of params in model 215821
2022-12-05 19:35:59,633 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:35:59,633 INFO:   Starting stage: TRAINING
2022-12-05 19:35:59,694 INFO:     Val loss before train {'Reaction outcome loss': 1.0426100235093723, 'Total loss': 1.0426100235093723}
2022-12-05 19:35:59,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:35:59,694 INFO:     Epoch: 0
2022-12-05 19:36:00,485 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.644835118543018, 'Total loss': 0.644835118543018} | train loss {'Reaction outcome loss': 0.7922393633394825, 'Total loss': 0.7922393633394825}
2022-12-05 19:36:00,485 INFO:     Found new best model at epoch 0
2022-12-05 19:36:00,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:00,486 INFO:     Epoch: 1
2022-12-05 19:36:01,277 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5609551986510103, 'Total loss': 0.5609551986510103} | train loss {'Reaction outcome loss': 0.5405238542629748, 'Total loss': 0.5405238542629748}
2022-12-05 19:36:01,277 INFO:     Found new best model at epoch 1
2022-12-05 19:36:01,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:01,278 INFO:     Epoch: 2
2022-12-05 19:36:02,069 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5211850587617267, 'Total loss': 0.5211850587617267} | train loss {'Reaction outcome loss': 0.46739867414746966, 'Total loss': 0.46739867414746966}
2022-12-05 19:36:02,069 INFO:     Found new best model at epoch 2
2022-12-05 19:36:02,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:02,070 INFO:     Epoch: 3
2022-12-05 19:36:02,861 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5007766278629954, 'Total loss': 0.5007766278629954} | train loss {'Reaction outcome loss': 0.42620941868850165, 'Total loss': 0.42620941868850165}
2022-12-05 19:36:02,861 INFO:     Found new best model at epoch 3
2022-12-05 19:36:02,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:02,862 INFO:     Epoch: 4
2022-12-05 19:36:03,652 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4927041923457926, 'Total loss': 0.4927041923457926} | train loss {'Reaction outcome loss': 0.4005250211272921, 'Total loss': 0.4005250211272921}
2022-12-05 19:36:03,652 INFO:     Found new best model at epoch 4
2022-12-05 19:36:03,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:03,653 INFO:     Epoch: 5
2022-12-05 19:36:04,443 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4687245281582529, 'Total loss': 0.4687245281582529} | train loss {'Reaction outcome loss': 0.378190102777919, 'Total loss': 0.378190102777919}
2022-12-05 19:36:04,443 INFO:     Found new best model at epoch 5
2022-12-05 19:36:04,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:04,444 INFO:     Epoch: 6
2022-12-05 19:36:05,235 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4698254113847559, 'Total loss': 0.4698254113847559} | train loss {'Reaction outcome loss': 0.35687307910043364, 'Total loss': 0.35687307910043364}
2022-12-05 19:36:05,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:05,235 INFO:     Epoch: 7
2022-12-05 19:36:06,026 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4582258987833153, 'Total loss': 0.4582258987833153} | train loss {'Reaction outcome loss': 0.34000378470031584, 'Total loss': 0.34000378470031584}
2022-12-05 19:36:06,027 INFO:     Found new best model at epoch 7
2022-12-05 19:36:06,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:06,027 INFO:     Epoch: 8
2022-12-05 19:36:06,827 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45880768075585365, 'Total loss': 0.45880768075585365} | train loss {'Reaction outcome loss': 0.32215754356311294, 'Total loss': 0.32215754356311294}
2022-12-05 19:36:06,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:06,828 INFO:     Epoch: 9
2022-12-05 19:36:07,624 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4649472019889138, 'Total loss': 0.4649472019889138} | train loss {'Reaction outcome loss': 0.30826887851771045, 'Total loss': 0.30826887851771045}
2022-12-05 19:36:07,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:07,624 INFO:     Epoch: 10
2022-12-05 19:36:08,417 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47079767049713567, 'Total loss': 0.47079767049713567} | train loss {'Reaction outcome loss': 0.30070846895782316, 'Total loss': 0.30070846895782316}
2022-12-05 19:36:08,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:08,417 INFO:     Epoch: 11
2022-12-05 19:36:09,212 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4683758629993959, 'Total loss': 0.4683758629993959} | train loss {'Reaction outcome loss': 0.2863930439158362, 'Total loss': 0.2863930439158362}
2022-12-05 19:36:09,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:09,212 INFO:     Epoch: 12
2022-12-05 19:36:10,004 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4863267215815457, 'Total loss': 0.4863267215815457} | train loss {'Reaction outcome loss': 0.27543930785388365, 'Total loss': 0.27543930785388365}
2022-12-05 19:36:10,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:10,004 INFO:     Epoch: 13
2022-12-05 19:36:10,800 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4764820215376941, 'Total loss': 0.4764820215376941} | train loss {'Reaction outcome loss': 0.2646807715676877, 'Total loss': 0.2646807715676877}
2022-12-05 19:36:10,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:10,800 INFO:     Epoch: 14
2022-12-05 19:36:11,595 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4514075502414595, 'Total loss': 0.4514075502414595} | train loss {'Reaction outcome loss': 0.25931396572565546, 'Total loss': 0.25931396572565546}
2022-12-05 19:36:11,595 INFO:     Found new best model at epoch 14
2022-12-05 19:36:11,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:11,596 INFO:     Epoch: 15
2022-12-05 19:36:12,388 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45191835616291925, 'Total loss': 0.45191835616291925} | train loss {'Reaction outcome loss': 0.2502078883654001, 'Total loss': 0.2502078883654001}
2022-12-05 19:36:12,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:12,389 INFO:     Epoch: 16
2022-12-05 19:36:13,179 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.467283285392279, 'Total loss': 0.467283285392279} | train loss {'Reaction outcome loss': 0.24430913654517156, 'Total loss': 0.24430913654517156}
2022-12-05 19:36:13,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:13,180 INFO:     Epoch: 17
2022-12-05 19:36:13,971 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4736615954474969, 'Total loss': 0.4736615954474969} | train loss {'Reaction outcome loss': 0.23456151147886198, 'Total loss': 0.23456151147886198}
2022-12-05 19:36:13,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:13,971 INFO:     Epoch: 18
2022-12-05 19:36:14,761 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4668257656422528, 'Total loss': 0.4668257656422528} | train loss {'Reaction outcome loss': 0.22967499520401566, 'Total loss': 0.22967499520401566}
2022-12-05 19:36:14,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:14,761 INFO:     Epoch: 19
2022-12-05 19:36:15,553 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4516038950532675, 'Total loss': 0.4516038950532675} | train loss {'Reaction outcome loss': 0.222410242806892, 'Total loss': 0.222410242806892}
2022-12-05 19:36:15,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:15,553 INFO:     Epoch: 20
2022-12-05 19:36:16,344 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4710376818071712, 'Total loss': 0.4710376818071712} | train loss {'Reaction outcome loss': 0.2152610726046319, 'Total loss': 0.2152610726046319}
2022-12-05 19:36:16,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:16,344 INFO:     Epoch: 21
2022-12-05 19:36:17,136 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47127973254431377, 'Total loss': 0.47127973254431377} | train loss {'Reaction outcome loss': 0.21348759743327997, 'Total loss': 0.21348759743327997}
2022-12-05 19:36:17,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:17,136 INFO:     Epoch: 22
2022-12-05 19:36:17,927 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5011163814501329, 'Total loss': 0.5011163814501329} | train loss {'Reaction outcome loss': 0.20549606353956826, 'Total loss': 0.20549606353956826}
2022-12-05 19:36:17,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:17,927 INFO:     Epoch: 23
2022-12-05 19:36:18,721 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46652114018797874, 'Total loss': 0.46652114018797874} | train loss {'Reaction outcome loss': 0.20446307660669696, 'Total loss': 0.20446307660669696}
2022-12-05 19:36:18,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:18,721 INFO:     Epoch: 24
2022-12-05 19:36:19,513 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4813039198819421, 'Total loss': 0.4813039198819421} | train loss {'Reaction outcome loss': 0.19567591599663908, 'Total loss': 0.19567591599663908}
2022-12-05 19:36:19,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:19,513 INFO:     Epoch: 25
2022-12-05 19:36:20,302 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4712200445885008, 'Total loss': 0.4712200445885008} | train loss {'Reaction outcome loss': 0.19502572137482313, 'Total loss': 0.19502572137482313}
2022-12-05 19:36:20,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:20,302 INFO:     Epoch: 26
2022-12-05 19:36:21,092 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4964669912376187, 'Total loss': 0.4964669912376187} | train loss {'Reaction outcome loss': 0.1918833781413886, 'Total loss': 0.1918833781413886}
2022-12-05 19:36:21,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:21,092 INFO:     Epoch: 27
2022-12-05 19:36:21,886 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48974342474883253, 'Total loss': 0.48974342474883253} | train loss {'Reaction outcome loss': 0.19031150964449864, 'Total loss': 0.19031150964449864}
2022-12-05 19:36:21,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:21,886 INFO:     Epoch: 28
2022-12-05 19:36:22,680 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4779011776501482, 'Total loss': 0.4779011776501482} | train loss {'Reaction outcome loss': 0.18353201033053348, 'Total loss': 0.18353201033053348}
2022-12-05 19:36:22,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:22,681 INFO:     Epoch: 29
2022-12-05 19:36:23,471 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49790036949244415, 'Total loss': 0.49790036949244415} | train loss {'Reaction outcome loss': 0.18166798819996874, 'Total loss': 0.18166798819996874}
2022-12-05 19:36:23,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:23,471 INFO:     Epoch: 30
2022-12-05 19:36:24,264 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47915830327705905, 'Total loss': 0.47915830327705905} | train loss {'Reaction outcome loss': 0.18285292718863608, 'Total loss': 0.18285292718863608}
2022-12-05 19:36:24,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:24,264 INFO:     Epoch: 31
2022-12-05 19:36:25,057 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47930916060100903, 'Total loss': 0.47930916060100903} | train loss {'Reaction outcome loss': 0.175982909847279, 'Total loss': 0.175982909847279}
2022-12-05 19:36:25,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:25,057 INFO:     Epoch: 32
2022-12-05 19:36:25,849 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4860860410739075, 'Total loss': 0.4860860410739075} | train loss {'Reaction outcome loss': 0.17512815559701045, 'Total loss': 0.17512815559701045}
2022-12-05 19:36:25,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:25,850 INFO:     Epoch: 33
2022-12-05 19:36:26,640 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47498864731328055, 'Total loss': 0.47498864731328055} | train loss {'Reaction outcome loss': 0.17049998964886276, 'Total loss': 0.17049998964886276}
2022-12-05 19:36:26,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:26,640 INFO:     Epoch: 34
2022-12-05 19:36:27,433 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4880206121809103, 'Total loss': 0.4880206121809103} | train loss {'Reaction outcome loss': 0.16795724894927472, 'Total loss': 0.16795724894927472}
2022-12-05 19:36:27,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:27,433 INFO:     Epoch: 35
2022-12-05 19:36:28,226 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48857779428362846, 'Total loss': 0.48857779428362846} | train loss {'Reaction outcome loss': 0.166727451067798, 'Total loss': 0.166727451067798}
2022-12-05 19:36:28,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:28,226 INFO:     Epoch: 36
2022-12-05 19:36:29,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4901815121146766, 'Total loss': 0.4901815121146766} | train loss {'Reaction outcome loss': 0.16594769627388034, 'Total loss': 0.16594769627388034}
2022-12-05 19:36:29,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:29,017 INFO:     Epoch: 37
2022-12-05 19:36:29,806 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49767335199496965, 'Total loss': 0.49767335199496965} | train loss {'Reaction outcome loss': 0.16041943604620743, 'Total loss': 0.16041943604620743}
2022-12-05 19:36:29,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:29,806 INFO:     Epoch: 38
2022-12-05 19:36:30,600 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4901016341014342, 'Total loss': 0.4901016341014342} | train loss {'Reaction outcome loss': 0.16199879464598335, 'Total loss': 0.16199879464598335}
2022-12-05 19:36:30,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:30,600 INFO:     Epoch: 39
2022-12-05 19:36:31,392 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5030511997809465, 'Total loss': 0.5030511997809465} | train loss {'Reaction outcome loss': 0.15969864857592145, 'Total loss': 0.15969864857592145}
2022-12-05 19:36:31,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:31,392 INFO:     Epoch: 40
2022-12-05 19:36:32,184 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4877188676460223, 'Total loss': 0.4877188676460223} | train loss {'Reaction outcome loss': 0.16147268967969078, 'Total loss': 0.16147268967969078}
2022-12-05 19:36:32,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:32,185 INFO:     Epoch: 41
2022-12-05 19:36:32,976 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48435820097273047, 'Total loss': 0.48435820097273047} | train loss {'Reaction outcome loss': 0.15571280784752903, 'Total loss': 0.15571280784752903}
2022-12-05 19:36:32,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:32,976 INFO:     Epoch: 42
2022-12-05 19:36:33,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.510419515723532, 'Total loss': 0.510419515723532} | train loss {'Reaction outcome loss': 0.15537920972066266, 'Total loss': 0.15537920972066266}
2022-12-05 19:36:33,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:33,769 INFO:     Epoch: 43
2022-12-05 19:36:34,560 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5016935403374109, 'Total loss': 0.5016935403374109} | train loss {'Reaction outcome loss': 0.1531379190634708, 'Total loss': 0.1531379190634708}
2022-12-05 19:36:34,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:34,561 INFO:     Epoch: 44
2022-12-05 19:36:35,353 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5085531002418562, 'Total loss': 0.5085531002418562} | train loss {'Reaction outcome loss': 0.1518050075565674, 'Total loss': 0.1518050075565674}
2022-12-05 19:36:35,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:35,353 INFO:     Epoch: 45
2022-12-05 19:36:36,143 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4983058436350389, 'Total loss': 0.4983058436350389} | train loss {'Reaction outcome loss': 0.15153442341454176, 'Total loss': 0.15153442341454176}
2022-12-05 19:36:36,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:36,143 INFO:     Epoch: 46
2022-12-05 19:36:36,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5041699903932485, 'Total loss': 0.5041699903932485} | train loss {'Reaction outcome loss': 0.15074552407830347, 'Total loss': 0.15074552407830347}
2022-12-05 19:36:36,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:36,936 INFO:     Epoch: 47
2022-12-05 19:36:37,731 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49559650874950667, 'Total loss': 0.49559650874950667} | train loss {'Reaction outcome loss': 0.148097694490333, 'Total loss': 0.148097694490333}
2022-12-05 19:36:37,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:37,733 INFO:     Epoch: 48
2022-12-05 19:36:38,528 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.527463283051144, 'Total loss': 0.527463283051144} | train loss {'Reaction outcome loss': 0.14911681498039742, 'Total loss': 0.14911681498039742}
2022-12-05 19:36:38,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:38,528 INFO:     Epoch: 49
2022-12-05 19:36:39,324 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5151395154270259, 'Total loss': 0.5151395154270259} | train loss {'Reaction outcome loss': 0.1445983288543565, 'Total loss': 0.1445983288543565}
2022-12-05 19:36:39,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:39,325 INFO:     Epoch: 50
2022-12-05 19:36:40,118 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5108674944124438, 'Total loss': 0.5108674944124438} | train loss {'Reaction outcome loss': 0.1447567357396593, 'Total loss': 0.1447567357396593}
2022-12-05 19:36:40,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:40,119 INFO:     Epoch: 51
2022-12-05 19:36:40,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5102797330103137, 'Total loss': 0.5102797330103137} | train loss {'Reaction outcome loss': 0.14131251905797695, 'Total loss': 0.14131251905797695}
2022-12-05 19:36:40,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:40,912 INFO:     Epoch: 52
2022-12-05 19:36:41,709 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5214305242354219, 'Total loss': 0.5214305242354219} | train loss {'Reaction outcome loss': 0.14053256421216898, 'Total loss': 0.14053256421216898}
2022-12-05 19:36:41,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:41,710 INFO:     Epoch: 53
2022-12-05 19:36:42,500 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5021227936853062, 'Total loss': 0.5021227936853062} | train loss {'Reaction outcome loss': 0.13876717740631833, 'Total loss': 0.13876717740631833}
2022-12-05 19:36:42,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:42,500 INFO:     Epoch: 54
2022-12-05 19:36:43,290 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5242325843057849, 'Total loss': 0.5242325843057849} | train loss {'Reaction outcome loss': 0.14327248052066685, 'Total loss': 0.14327248052066685}
2022-12-05 19:36:43,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:43,291 INFO:     Epoch: 55
2022-12-05 19:36:44,080 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5002565715800632, 'Total loss': 0.5002565715800632} | train loss {'Reaction outcome loss': 0.13923513314933803, 'Total loss': 0.13923513314933803}
2022-12-05 19:36:44,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:44,081 INFO:     Epoch: 56
2022-12-05 19:36:44,871 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48934829302809457, 'Total loss': 0.48934829302809457} | train loss {'Reaction outcome loss': 0.13869890262353785, 'Total loss': 0.13869890262353785}
2022-12-05 19:36:44,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:44,871 INFO:     Epoch: 57
2022-12-05 19:36:45,664 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4902815463190729, 'Total loss': 0.4902815463190729} | train loss {'Reaction outcome loss': 0.13541345031437826, 'Total loss': 0.13541345031437826}
2022-12-05 19:36:45,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:45,664 INFO:     Epoch: 58
2022-12-05 19:36:46,455 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5066548194312914, 'Total loss': 0.5066548194312914} | train loss {'Reaction outcome loss': 0.1357443138348813, 'Total loss': 0.1357443138348813}
2022-12-05 19:36:46,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:46,455 INFO:     Epoch: 59
2022-12-05 19:36:47,245 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4939244057221169, 'Total loss': 0.4939244057221169} | train loss {'Reaction outcome loss': 0.13636000082657046, 'Total loss': 0.13636000082657046}
2022-12-05 19:36:47,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:47,245 INFO:     Epoch: 60
2022-12-05 19:36:48,035 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5161368984051726, 'Total loss': 0.5161368984051726} | train loss {'Reaction outcome loss': 0.1353024303076827, 'Total loss': 0.1353024303076827}
2022-12-05 19:36:48,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:48,036 INFO:     Epoch: 61
2022-12-05 19:36:48,825 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5021770386533304, 'Total loss': 0.5021770386533304} | train loss {'Reaction outcome loss': 0.13476152916495898, 'Total loss': 0.13476152916495898}
2022-12-05 19:36:48,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:48,826 INFO:     Epoch: 62
2022-12-05 19:36:49,616 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5139125009829347, 'Total loss': 0.5139125009829347} | train loss {'Reaction outcome loss': 0.13385265371477117, 'Total loss': 0.13385265371477117}
2022-12-05 19:36:49,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:49,617 INFO:     Epoch: 63
2022-12-05 19:36:50,408 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49631918661973695, 'Total loss': 0.49631918661973695} | train loss {'Reaction outcome loss': 0.13409238874304052, 'Total loss': 0.13409238874304052}
2022-12-05 19:36:50,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:50,408 INFO:     Epoch: 64
2022-12-05 19:36:51,198 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4951967630874027, 'Total loss': 0.4951967630874027} | train loss {'Reaction outcome loss': 0.1336681739028011, 'Total loss': 0.1336681739028011}
2022-12-05 19:36:51,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:51,198 INFO:     Epoch: 65
2022-12-05 19:36:51,994 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5483519140292298, 'Total loss': 0.5483519140292298} | train loss {'Reaction outcome loss': 0.13231609197599548, 'Total loss': 0.13231609197599548}
2022-12-05 19:36:51,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:51,994 INFO:     Epoch: 66
2022-12-05 19:36:52,786 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4982523942704905, 'Total loss': 0.4982523942704905} | train loss {'Reaction outcome loss': 0.13215311006167713, 'Total loss': 0.13215311006167713}
2022-12-05 19:36:52,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:52,786 INFO:     Epoch: 67
2022-12-05 19:36:53,579 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5005213916301727, 'Total loss': 0.5005213916301727} | train loss {'Reaction outcome loss': 0.1310222327709198, 'Total loss': 0.1310222327709198}
2022-12-05 19:36:53,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:53,580 INFO:     Epoch: 68
2022-12-05 19:36:54,373 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5228495339185677, 'Total loss': 0.5228495339185677} | train loss {'Reaction outcome loss': 0.13020552518796555, 'Total loss': 0.13020552518796555}
2022-12-05 19:36:54,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:54,373 INFO:     Epoch: 69
2022-12-05 19:36:55,166 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4972932982173833, 'Total loss': 0.4972932982173833} | train loss {'Reaction outcome loss': 0.13133369627959873, 'Total loss': 0.13133369627959873}
2022-12-05 19:36:55,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:55,166 INFO:     Epoch: 70
2022-12-05 19:36:55,963 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5152010311457244, 'Total loss': 0.5152010311457244} | train loss {'Reaction outcome loss': 0.1307776088465233, 'Total loss': 0.1307776088465233}
2022-12-05 19:36:55,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:55,964 INFO:     Epoch: 71
2022-12-05 19:36:56,757 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5179461591284383, 'Total loss': 0.5179461591284383} | train loss {'Reaction outcome loss': 0.13056596405804158, 'Total loss': 0.13056596405804158}
2022-12-05 19:36:56,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:56,758 INFO:     Epoch: 72
2022-12-05 19:36:57,554 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5045271214436401, 'Total loss': 0.5045271214436401} | train loss {'Reaction outcome loss': 0.1320383180693096, 'Total loss': 0.1320383180693096}
2022-12-05 19:36:57,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:57,555 INFO:     Epoch: 73
2022-12-05 19:36:58,346 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5222839906134389, 'Total loss': 0.5222839906134389} | train loss {'Reaction outcome loss': 0.12772373714465268, 'Total loss': 0.12772373714465268}
2022-12-05 19:36:58,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:58,346 INFO:     Epoch: 74
2022-12-05 19:36:59,146 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5139380405572328, 'Total loss': 0.5139380405572328} | train loss {'Reaction outcome loss': 0.12713473478750306, 'Total loss': 0.12713473478750306}
2022-12-05 19:36:59,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:59,146 INFO:     Epoch: 75
2022-12-05 19:36:59,946 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5192280719903383, 'Total loss': 0.5192280719903383} | train loss {'Reaction outcome loss': 0.1271897891498342, 'Total loss': 0.1271897891498342}
2022-12-05 19:36:59,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:36:59,946 INFO:     Epoch: 76
2022-12-05 19:37:00,737 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5278805524788119, 'Total loss': 0.5278805524788119} | train loss {'Reaction outcome loss': 0.12529456758757634, 'Total loss': 0.12529456758757634}
2022-12-05 19:37:00,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:00,737 INFO:     Epoch: 77
2022-12-05 19:37:01,527 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5217817347835411, 'Total loss': 0.5217817347835411} | train loss {'Reaction outcome loss': 0.12579242988508574, 'Total loss': 0.12579242988508574}
2022-12-05 19:37:01,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:01,528 INFO:     Epoch: 78
2022-12-05 19:37:02,318 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5001824550669302, 'Total loss': 0.5001824550669302} | train loss {'Reaction outcome loss': 0.1254088087197469, 'Total loss': 0.1254088087197469}
2022-12-05 19:37:02,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:02,318 INFO:     Epoch: 79
2022-12-05 19:37:03,109 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5081060240891847, 'Total loss': 0.5081060240891847} | train loss {'Reaction outcome loss': 0.12669818852362888, 'Total loss': 0.12669818852362888}
2022-12-05 19:37:03,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:03,109 INFO:     Epoch: 80
2022-12-05 19:37:03,902 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5206488831476732, 'Total loss': 0.5206488831476732} | train loss {'Reaction outcome loss': 0.12300963567151707, 'Total loss': 0.12300963567151707}
2022-12-05 19:37:03,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:03,903 INFO:     Epoch: 81
2022-12-05 19:37:04,696 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5387321283871477, 'Total loss': 0.5387321283871477} | train loss {'Reaction outcome loss': 0.12220963190062618, 'Total loss': 0.12220963190062618}
2022-12-05 19:37:04,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:04,696 INFO:     Epoch: 82
2022-12-05 19:37:05,487 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5166300162672997, 'Total loss': 0.5166300162672997} | train loss {'Reaction outcome loss': 0.12476183622695354, 'Total loss': 0.12476183622695354}
2022-12-05 19:37:05,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:05,487 INFO:     Epoch: 83
2022-12-05 19:37:06,284 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5134254280816425, 'Total loss': 0.5134254280816425} | train loss {'Reaction outcome loss': 0.12545058200401918, 'Total loss': 0.12545058200401918}
2022-12-05 19:37:06,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:06,284 INFO:     Epoch: 84
2022-12-05 19:37:07,078 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5087392927909439, 'Total loss': 0.5087392927909439} | train loss {'Reaction outcome loss': 0.12430566447805994, 'Total loss': 0.12430566447805994}
2022-12-05 19:37:07,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:07,079 INFO:     Epoch: 85
2022-12-05 19:37:07,872 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5093874951655214, 'Total loss': 0.5093874951655214} | train loss {'Reaction outcome loss': 0.12435071770177812, 'Total loss': 0.12435071770177812}
2022-12-05 19:37:07,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:07,873 INFO:     Epoch: 86
2022-12-05 19:37:08,669 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5007392432201992, 'Total loss': 0.5007392432201992} | train loss {'Reaction outcome loss': 0.12326712151419143, 'Total loss': 0.12326712151419143}
2022-12-05 19:37:08,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:08,670 INFO:     Epoch: 87
2022-12-05 19:37:09,462 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5178686387159608, 'Total loss': 0.5178686387159608} | train loss {'Reaction outcome loss': 0.12434386886580258, 'Total loss': 0.12434386886580258}
2022-12-05 19:37:09,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:09,462 INFO:     Epoch: 88
2022-12-05 19:37:10,254 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5241267552429979, 'Total loss': 0.5241267552429979} | train loss {'Reaction outcome loss': 0.12362231370441767, 'Total loss': 0.12362231370441767}
2022-12-05 19:37:10,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:10,254 INFO:     Epoch: 89
2022-12-05 19:37:11,048 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5333172858438708, 'Total loss': 0.5333172858438708} | train loss {'Reaction outcome loss': 0.1219968568761738, 'Total loss': 0.1219968568761738}
2022-12-05 19:37:11,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:11,048 INFO:     Epoch: 90
2022-12-05 19:37:11,845 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5009652973914688, 'Total loss': 0.5009652973914688} | train loss {'Reaction outcome loss': 0.1212658430202579, 'Total loss': 0.1212658430202579}
2022-12-05 19:37:11,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:11,846 INFO:     Epoch: 91
2022-12-05 19:37:12,639 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5019987775012851, 'Total loss': 0.5019987775012851} | train loss {'Reaction outcome loss': 0.11989111751317978, 'Total loss': 0.11989111751317978}
2022-12-05 19:37:12,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:12,639 INFO:     Epoch: 92
2022-12-05 19:37:13,432 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5117074623703957, 'Total loss': 0.5117074623703957} | train loss {'Reaction outcome loss': 0.12014538860898845, 'Total loss': 0.12014538860898845}
2022-12-05 19:37:13,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:13,432 INFO:     Epoch: 93
2022-12-05 19:37:14,224 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5241216275502335, 'Total loss': 0.5241216275502335} | train loss {'Reaction outcome loss': 0.12202710441636797, 'Total loss': 0.12202710441636797}
2022-12-05 19:37:14,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:14,224 INFO:     Epoch: 94
2022-12-05 19:37:15,016 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.512586831707846, 'Total loss': 0.512586831707846} | train loss {'Reaction outcome loss': 0.12065785699048821, 'Total loss': 0.12065785699048821}
2022-12-05 19:37:15,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:15,017 INFO:     Epoch: 95
2022-12-05 19:37:15,811 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5089550435712392, 'Total loss': 0.5089550435712392} | train loss {'Reaction outcome loss': 0.12010598948643524, 'Total loss': 0.12010598948643524}
2022-12-05 19:37:15,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:15,811 INFO:     Epoch: 96
2022-12-05 19:37:16,605 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5039712366732684, 'Total loss': 0.5039712366732684} | train loss {'Reaction outcome loss': 0.12152491280314874, 'Total loss': 0.12152491280314874}
2022-12-05 19:37:16,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:16,605 INFO:     Epoch: 97
2022-12-05 19:37:17,402 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5165100726722316, 'Total loss': 0.5165100726722316} | train loss {'Reaction outcome loss': 0.12304395602597874, 'Total loss': 0.12304395602597874}
2022-12-05 19:37:17,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:17,402 INFO:     Epoch: 98
2022-12-05 19:37:18,196 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5211897639727051, 'Total loss': 0.5211897639727051} | train loss {'Reaction outcome loss': 0.12111250222185437, 'Total loss': 0.12111250222185437}
2022-12-05 19:37:18,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:18,196 INFO:     Epoch: 99
2022-12-05 19:37:18,990 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5178592369299043, 'Total loss': 0.5178592369299043} | train loss {'Reaction outcome loss': 0.12004453073426777, 'Total loss': 0.12004453073426777}
2022-12-05 19:37:18,990 INFO:     Best model found after epoch 15 of 100.
2022-12-05 19:37:18,990 INFO:   Done with stage: TRAINING
2022-12-05 19:37:18,990 INFO:   Starting stage: EVALUATION
2022-12-05 19:37:19,122 INFO:   Done with stage: EVALUATION
2022-12-05 19:37:19,123 INFO:   Leaving out SEQ value Fold_3
2022-12-05 19:37:19,136 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 19:37:19,136 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:37:19,777 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:37:19,777 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:37:19,845 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:37:19,845 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:37:19,845 INFO:     No hyperparam tuning for this model
2022-12-05 19:37:19,845 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:37:19,845 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:37:19,846 INFO:     None feature selector for col prot
2022-12-05 19:37:19,846 INFO:     None feature selector for col prot
2022-12-05 19:37:19,846 INFO:     None feature selector for col prot
2022-12-05 19:37:19,847 INFO:     None feature selector for col chem
2022-12-05 19:37:19,847 INFO:     None feature selector for col chem
2022-12-05 19:37:19,847 INFO:     None feature selector for col chem
2022-12-05 19:37:19,847 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:37:19,847 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:37:19,849 INFO:     Number of params in model 215821
2022-12-05 19:37:19,852 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:37:19,852 INFO:   Starting stage: TRAINING
2022-12-05 19:37:19,912 INFO:     Val loss before train {'Reaction outcome loss': 1.0159012924793154, 'Total loss': 1.0159012924793154}
2022-12-05 19:37:19,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:19,912 INFO:     Epoch: 0
2022-12-05 19:37:20,703 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6085868366928988, 'Total loss': 0.6085868366928988} | train loss {'Reaction outcome loss': 0.7910823315137723, 'Total loss': 0.7910823315137723}
2022-12-05 19:37:20,703 INFO:     Found new best model at epoch 0
2022-12-05 19:37:20,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:20,704 INFO:     Epoch: 1
2022-12-05 19:37:21,490 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5220123605672703, 'Total loss': 0.5220123605672703} | train loss {'Reaction outcome loss': 0.5234087017960236, 'Total loss': 0.5234087017960236}
2022-12-05 19:37:21,490 INFO:     Found new best model at epoch 1
2022-12-05 19:37:21,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:21,491 INFO:     Epoch: 2
2022-12-05 19:37:22,278 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48752704747887543, 'Total loss': 0.48752704747887543} | train loss {'Reaction outcome loss': 0.46077890132294325, 'Total loss': 0.46077890132294325}
2022-12-05 19:37:22,278 INFO:     Found new best model at epoch 2
2022-12-05 19:37:22,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:22,279 INFO:     Epoch: 3
2022-12-05 19:37:23,069 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4739597117485002, 'Total loss': 0.4739597117485002} | train loss {'Reaction outcome loss': 0.4246166228148781, 'Total loss': 0.4246166228148781}
2022-12-05 19:37:23,069 INFO:     Found new best model at epoch 3
2022-12-05 19:37:23,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:23,070 INFO:     Epoch: 4
2022-12-05 19:37:23,859 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45381952163785005, 'Total loss': 0.45381952163785005} | train loss {'Reaction outcome loss': 0.3966058234333015, 'Total loss': 0.3966058234333015}
2022-12-05 19:37:23,859 INFO:     Found new best model at epoch 4
2022-12-05 19:37:23,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:23,860 INFO:     Epoch: 5
2022-12-05 19:37:24,647 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44563142782033877, 'Total loss': 0.44563142782033877} | train loss {'Reaction outcome loss': 0.37791345928047526, 'Total loss': 0.37791345928047526}
2022-12-05 19:37:24,647 INFO:     Found new best model at epoch 5
2022-12-05 19:37:24,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:24,648 INFO:     Epoch: 6
2022-12-05 19:37:25,437 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43521789409393485, 'Total loss': 0.43521789409393485} | train loss {'Reaction outcome loss': 0.3565336122009598, 'Total loss': 0.3565336122009598}
2022-12-05 19:37:25,437 INFO:     Found new best model at epoch 6
2022-12-05 19:37:25,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:25,438 INFO:     Epoch: 7
2022-12-05 19:37:26,229 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4405447851086772, 'Total loss': 0.4405447851086772} | train loss {'Reaction outcome loss': 0.3419099780807241, 'Total loss': 0.3419099780807241}
2022-12-05 19:37:26,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:26,229 INFO:     Epoch: 8
2022-12-05 19:37:27,017 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44343493393687317, 'Total loss': 0.44343493393687317} | train loss {'Reaction outcome loss': 0.3275249996146218, 'Total loss': 0.3275249996146218}
2022-12-05 19:37:27,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:27,018 INFO:     Epoch: 9
2022-12-05 19:37:27,804 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42299828383811683, 'Total loss': 0.42299828383811683} | train loss {'Reaction outcome loss': 0.3154099672788479, 'Total loss': 0.3154099672788479}
2022-12-05 19:37:27,804 INFO:     Found new best model at epoch 9
2022-12-05 19:37:27,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:27,805 INFO:     Epoch: 10
2022-12-05 19:37:28,590 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4315666112788888, 'Total loss': 0.4315666112788888} | train loss {'Reaction outcome loss': 0.30466073125478677, 'Total loss': 0.30466073125478677}
2022-12-05 19:37:28,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:28,591 INFO:     Epoch: 11
2022-12-05 19:37:29,381 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42150729617407157, 'Total loss': 0.42150729617407157} | train loss {'Reaction outcome loss': 0.2910162024009118, 'Total loss': 0.2910162024009118}
2022-12-05 19:37:29,381 INFO:     Found new best model at epoch 11
2022-12-05 19:37:29,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:29,382 INFO:     Epoch: 12
2022-12-05 19:37:30,169 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4223955370659052, 'Total loss': 0.4223955370659052} | train loss {'Reaction outcome loss': 0.278827698229522, 'Total loss': 0.278827698229522}
2022-12-05 19:37:30,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:30,169 INFO:     Epoch: 13
2022-12-05 19:37:30,957 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41413190163845237, 'Total loss': 0.41413190163845237} | train loss {'Reaction outcome loss': 0.2702563618172388, 'Total loss': 0.2702563618172388}
2022-12-05 19:37:30,958 INFO:     Found new best model at epoch 13
2022-12-05 19:37:30,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:30,958 INFO:     Epoch: 14
2022-12-05 19:37:31,745 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42461418031260023, 'Total loss': 0.42461418031260023} | train loss {'Reaction outcome loss': 0.2605133390084642, 'Total loss': 0.2605133390084642}
2022-12-05 19:37:31,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:31,745 INFO:     Epoch: 15
2022-12-05 19:37:32,535 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42202162500037704, 'Total loss': 0.42202162500037704} | train loss {'Reaction outcome loss': 0.25524687712828886, 'Total loss': 0.25524687712828886}
2022-12-05 19:37:32,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:32,535 INFO:     Epoch: 16
2022-12-05 19:37:33,322 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4227020092481791, 'Total loss': 0.4227020092481791} | train loss {'Reaction outcome loss': 0.2457939618740414, 'Total loss': 0.2457939618740414}
2022-12-05 19:37:33,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:33,322 INFO:     Epoch: 17
2022-12-05 19:37:34,109 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4164534519578135, 'Total loss': 0.4164534519578135} | train loss {'Reaction outcome loss': 0.2400595935244785, 'Total loss': 0.2400595935244785}
2022-12-05 19:37:34,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:34,109 INFO:     Epoch: 18
2022-12-05 19:37:34,894 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42062609833340314, 'Total loss': 0.42062609833340314} | train loss {'Reaction outcome loss': 0.23238230640160257, 'Total loss': 0.23238230640160257}
2022-12-05 19:37:34,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:34,894 INFO:     Epoch: 19
2022-12-05 19:37:35,683 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4213028848171234, 'Total loss': 0.4213028848171234} | train loss {'Reaction outcome loss': 0.23126251975715648, 'Total loss': 0.23126251975715648}
2022-12-05 19:37:35,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:35,684 INFO:     Epoch: 20
2022-12-05 19:37:36,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4118543000415314, 'Total loss': 0.4118543000415314} | train loss {'Reaction outcome loss': 0.223013397336739, 'Total loss': 0.223013397336739}
2022-12-05 19:37:36,472 INFO:     Found new best model at epoch 20
2022-12-05 19:37:36,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:36,473 INFO:     Epoch: 21
2022-12-05 19:37:37,259 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4153026331995809, 'Total loss': 0.4153026331995809} | train loss {'Reaction outcome loss': 0.21880081441009142, 'Total loss': 0.21880081441009142}
2022-12-05 19:37:37,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:37,259 INFO:     Epoch: 22
2022-12-05 19:37:38,049 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4205999072901038, 'Total loss': 0.4205999072901038} | train loss {'Reaction outcome loss': 0.21395331560099712, 'Total loss': 0.21395331560099712}
2022-12-05 19:37:38,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:38,049 INFO:     Epoch: 23
2022-12-05 19:37:38,838 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41826877379140187, 'Total loss': 0.41826877379140187} | train loss {'Reaction outcome loss': 0.20793030362148754, 'Total loss': 0.20793030362148754}
2022-12-05 19:37:38,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:38,838 INFO:     Epoch: 24
2022-12-05 19:37:39,626 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4214682799092559, 'Total loss': 0.4214682799092559} | train loss {'Reaction outcome loss': 0.2061526233551749, 'Total loss': 0.2061526233551749}
2022-12-05 19:37:39,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:39,627 INFO:     Epoch: 25
2022-12-05 19:37:40,419 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4174655083307, 'Total loss': 0.4174655083307} | train loss {'Reaction outcome loss': 0.20045822876368147, 'Total loss': 0.20045822876368147}
2022-12-05 19:37:40,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:40,420 INFO:     Epoch: 26
2022-12-05 19:37:41,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.418921654307565, 'Total loss': 0.418921654307565} | train loss {'Reaction outcome loss': 0.19803738684133917, 'Total loss': 0.19803738684133917}
2022-12-05 19:37:41,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:41,207 INFO:     Epoch: 27
2022-12-05 19:37:41,998 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4229244243266971, 'Total loss': 0.4229244243266971} | train loss {'Reaction outcome loss': 0.1937761751049366, 'Total loss': 0.1937761751049366}
2022-12-05 19:37:41,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:41,998 INFO:     Epoch: 28
2022-12-05 19:37:42,787 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4208529882652815, 'Total loss': 0.4208529882652815} | train loss {'Reaction outcome loss': 0.18999190535396338, 'Total loss': 0.18999190535396338}
2022-12-05 19:37:42,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:42,788 INFO:     Epoch: 29
2022-12-05 19:37:43,576 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4297880754741125, 'Total loss': 0.4297880754741125} | train loss {'Reaction outcome loss': 0.18486630857815264, 'Total loss': 0.18486630857815264}
2022-12-05 19:37:43,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:43,576 INFO:     Epoch: 30
2022-12-05 19:37:44,364 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42696692950503773, 'Total loss': 0.42696692950503773} | train loss {'Reaction outcome loss': 0.18484145551003883, 'Total loss': 0.18484145551003883}
2022-12-05 19:37:44,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:44,364 INFO:     Epoch: 31
2022-12-05 19:37:45,154 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4277798450270364, 'Total loss': 0.4277798450270364} | train loss {'Reaction outcome loss': 0.18119597960202422, 'Total loss': 0.18119597960202422}
2022-12-05 19:37:45,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:45,154 INFO:     Epoch: 32
2022-12-05 19:37:45,950 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44018058686755424, 'Total loss': 0.44018058686755424} | train loss {'Reaction outcome loss': 0.17666410933416643, 'Total loss': 0.17666410933416643}
2022-12-05 19:37:45,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:45,950 INFO:     Epoch: 33
2022-12-05 19:37:46,748 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4310430537822635, 'Total loss': 0.4310430537822635} | train loss {'Reaction outcome loss': 0.17703084401084018, 'Total loss': 0.17703084401084018}
2022-12-05 19:37:46,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:46,748 INFO:     Epoch: 34
2022-12-05 19:37:47,534 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4326916884544284, 'Total loss': 0.4326916884544284} | train loss {'Reaction outcome loss': 0.1714423202878994, 'Total loss': 0.1714423202878994}
2022-12-05 19:37:47,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:47,534 INFO:     Epoch: 35
2022-12-05 19:37:48,320 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43091363546460176, 'Total loss': 0.43091363546460176} | train loss {'Reaction outcome loss': 0.17372940773846673, 'Total loss': 0.17372940773846673}
2022-12-05 19:37:48,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:48,321 INFO:     Epoch: 36
2022-12-05 19:37:49,107 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44355691466913666, 'Total loss': 0.44355691466913666} | train loss {'Reaction outcome loss': 0.1698860311651694, 'Total loss': 0.1698860311651694}
2022-12-05 19:37:49,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:49,108 INFO:     Epoch: 37
2022-12-05 19:37:49,897 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4457060427859772, 'Total loss': 0.4457060427859772} | train loss {'Reaction outcome loss': 0.1677241450725276, 'Total loss': 0.1677241450725276}
2022-12-05 19:37:49,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:49,897 INFO:     Epoch: 38
2022-12-05 19:37:50,685 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4461243783318719, 'Total loss': 0.4461243783318719} | train loss {'Reaction outcome loss': 0.1638591606017263, 'Total loss': 0.1638591606017263}
2022-12-05 19:37:50,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:50,685 INFO:     Epoch: 39
2022-12-05 19:37:51,479 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4398984884799913, 'Total loss': 0.4398984884799913} | train loss {'Reaction outcome loss': 0.16393988860435174, 'Total loss': 0.16393988860435174}
2022-12-05 19:37:51,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:51,480 INFO:     Epoch: 40
2022-12-05 19:37:52,270 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4369355724301449, 'Total loss': 0.4369355724301449} | train loss {'Reaction outcome loss': 0.16295261536037825, 'Total loss': 0.16295261536037825}
2022-12-05 19:37:52,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:52,270 INFO:     Epoch: 41
2022-12-05 19:37:53,060 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4343013285204422, 'Total loss': 0.4343013285204422} | train loss {'Reaction outcome loss': 0.16142892593243083, 'Total loss': 0.16142892593243083}
2022-12-05 19:37:53,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:53,060 INFO:     Epoch: 42
2022-12-05 19:37:53,850 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4340988356013631, 'Total loss': 0.4340988356013631} | train loss {'Reaction outcome loss': 0.16181803419117313, 'Total loss': 0.16181803419117313}
2022-12-05 19:37:53,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:53,850 INFO:     Epoch: 43
2022-12-05 19:37:54,640 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4583209257486255, 'Total loss': 0.4583209257486255} | train loss {'Reaction outcome loss': 0.15664578931879436, 'Total loss': 0.15664578931879436}
2022-12-05 19:37:54,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:54,640 INFO:     Epoch: 44
2022-12-05 19:37:55,434 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45022550918335136, 'Total loss': 0.45022550918335136} | train loss {'Reaction outcome loss': 0.1582701732557206, 'Total loss': 0.1582701732557206}
2022-12-05 19:37:55,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:55,435 INFO:     Epoch: 45
2022-12-05 19:37:56,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44108372788096584, 'Total loss': 0.44108372788096584} | train loss {'Reaction outcome loss': 0.1513858060581518, 'Total loss': 0.1513858060581518}
2022-12-05 19:37:56,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:56,228 INFO:     Epoch: 46
2022-12-05 19:37:57,018 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4608690731747206, 'Total loss': 0.4608690731747206} | train loss {'Reaction outcome loss': 0.15225732186045804, 'Total loss': 0.15225732186045804}
2022-12-05 19:37:57,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:57,018 INFO:     Epoch: 47
2022-12-05 19:37:57,813 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4499114058738531, 'Total loss': 0.4499114058738531} | train loss {'Reaction outcome loss': 0.1523224777603125, 'Total loss': 0.1523224777603125}
2022-12-05 19:37:57,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:57,813 INFO:     Epoch: 48
2022-12-05 19:37:58,609 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45351939838986066, 'Total loss': 0.45351939838986066} | train loss {'Reaction outcome loss': 0.1515660949020845, 'Total loss': 0.1515660949020845}
2022-12-05 19:37:58,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:58,610 INFO:     Epoch: 49
2022-12-05 19:37:59,411 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4624301319898561, 'Total loss': 0.4624301319898561} | train loss {'Reaction outcome loss': 0.15343775150182917, 'Total loss': 0.15343775150182917}
2022-12-05 19:37:59,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:37:59,412 INFO:     Epoch: 50
2022-12-05 19:38:00,202 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45126285733178606, 'Total loss': 0.45126285733178606} | train loss {'Reaction outcome loss': 0.14732660753194426, 'Total loss': 0.14732660753194426}
2022-12-05 19:38:00,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:00,203 INFO:     Epoch: 51
2022-12-05 19:38:00,994 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45075636790242307, 'Total loss': 0.45075636790242307} | train loss {'Reaction outcome loss': 0.147747760295074, 'Total loss': 0.147747760295074}
2022-12-05 19:38:00,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:00,994 INFO:     Epoch: 52
2022-12-05 19:38:01,788 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4617503975019899, 'Total loss': 0.4617503975019899} | train loss {'Reaction outcome loss': 0.1455926995525961, 'Total loss': 0.1455926995525961}
2022-12-05 19:38:01,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:01,789 INFO:     Epoch: 53
2022-12-05 19:38:02,582 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46648175494615424, 'Total loss': 0.46648175494615424} | train loss {'Reaction outcome loss': 0.1469322228384372, 'Total loss': 0.1469322228384372}
2022-12-05 19:38:02,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:02,582 INFO:     Epoch: 54
2022-12-05 19:38:03,378 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45202342403489487, 'Total loss': 0.45202342403489487} | train loss {'Reaction outcome loss': 0.14811411027445412, 'Total loss': 0.14811411027445412}
2022-12-05 19:38:03,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:03,379 INFO:     Epoch: 55
2022-12-05 19:38:04,169 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4603247607863227, 'Total loss': 0.4603247607863227} | train loss {'Reaction outcome loss': 0.1453897413629733, 'Total loss': 0.1453897413629733}
2022-12-05 19:38:04,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:04,169 INFO:     Epoch: 56
2022-12-05 19:38:04,957 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45149572176295655, 'Total loss': 0.45149572176295655} | train loss {'Reaction outcome loss': 0.14385523531036298, 'Total loss': 0.14385523531036298}
2022-12-05 19:38:04,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:04,957 INFO:     Epoch: 57
2022-12-05 19:38:05,743 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46599570228609927, 'Total loss': 0.46599570228609927} | train loss {'Reaction outcome loss': 0.1406902848345945, 'Total loss': 0.1406902848345945}
2022-12-05 19:38:05,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:05,743 INFO:     Epoch: 58
2022-12-05 19:38:06,530 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46704808397348535, 'Total loss': 0.46704808397348535} | train loss {'Reaction outcome loss': 0.1420751465331824, 'Total loss': 0.1420751465331824}
2022-12-05 19:38:06,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:06,530 INFO:     Epoch: 59
2022-12-05 19:38:07,318 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45366645257833393, 'Total loss': 0.45366645257833393} | train loss {'Reaction outcome loss': 0.14101473851984397, 'Total loss': 0.14101473851984397}
2022-12-05 19:38:07,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:07,319 INFO:     Epoch: 60
2022-12-05 19:38:08,108 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4501997547787289, 'Total loss': 0.4501997547787289} | train loss {'Reaction outcome loss': 0.1385523005022255, 'Total loss': 0.1385523005022255}
2022-12-05 19:38:08,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:08,108 INFO:     Epoch: 61
2022-12-05 19:38:08,894 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.469124577766241, 'Total loss': 0.469124577766241} | train loss {'Reaction outcome loss': 0.13787916789716873, 'Total loss': 0.13787916789716873}
2022-12-05 19:38:08,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:08,894 INFO:     Epoch: 62
2022-12-05 19:38:09,682 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46035708383072255, 'Total loss': 0.46035708383072255} | train loss {'Reaction outcome loss': 0.13612328814800645, 'Total loss': 0.13612328814800645}
2022-12-05 19:38:09,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:09,682 INFO:     Epoch: 63
2022-12-05 19:38:10,481 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4629847150902415, 'Total loss': 0.4629847150902415} | train loss {'Reaction outcome loss': 0.13671245506476062, 'Total loss': 0.13671245506476062}
2022-12-05 19:38:10,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:10,482 INFO:     Epoch: 64
2022-12-05 19:38:11,277 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45996804396773494, 'Total loss': 0.45996804396773494} | train loss {'Reaction outcome loss': 0.1382089069449022, 'Total loss': 0.1382089069449022}
2022-12-05 19:38:11,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:11,278 INFO:     Epoch: 65
2022-12-05 19:38:12,068 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4698047956754995, 'Total loss': 0.4698047956754995} | train loss {'Reaction outcome loss': 0.13819313976440395, 'Total loss': 0.13819313976440395}
2022-12-05 19:38:12,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:12,068 INFO:     Epoch: 66
2022-12-05 19:38:12,860 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45719807820264685, 'Total loss': 0.45719807820264685} | train loss {'Reaction outcome loss': 0.13617312848629032, 'Total loss': 0.13617312848629032}
2022-12-05 19:38:12,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:12,860 INFO:     Epoch: 67
2022-12-05 19:38:13,647 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4602187348659648, 'Total loss': 0.4602187348659648} | train loss {'Reaction outcome loss': 0.13516493600251184, 'Total loss': 0.13516493600251184}
2022-12-05 19:38:13,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:13,648 INFO:     Epoch: 68
2022-12-05 19:38:14,434 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4504612244145815, 'Total loss': 0.4504612244145815} | train loss {'Reaction outcome loss': 0.13542588413158646, 'Total loss': 0.13542588413158646}
2022-12-05 19:38:14,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:14,435 INFO:     Epoch: 69
2022-12-05 19:38:15,225 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4584032986746278, 'Total loss': 0.4584032986746278} | train loss {'Reaction outcome loss': 0.13363461017410164, 'Total loss': 0.13363461017410164}
2022-12-05 19:38:15,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:15,225 INFO:     Epoch: 70
2022-12-05 19:38:16,016 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.456174059662708, 'Total loss': 0.456174059662708} | train loss {'Reaction outcome loss': 0.13699381253453063, 'Total loss': 0.13699381253453063}
2022-12-05 19:38:16,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:16,016 INFO:     Epoch: 71
2022-12-05 19:38:16,801 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4649000715377719, 'Total loss': 0.4649000715377719} | train loss {'Reaction outcome loss': 0.13326831555116128, 'Total loss': 0.13326831555116128}
2022-12-05 19:38:16,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:16,802 INFO:     Epoch: 72
2022-12-05 19:38:17,590 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4581619237744531, 'Total loss': 0.4581619237744531} | train loss {'Reaction outcome loss': 0.13176132582097513, 'Total loss': 0.13176132582097513}
2022-12-05 19:38:17,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:17,591 INFO:     Epoch: 73
2022-12-05 19:38:18,373 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46272578887468163, 'Total loss': 0.46272578887468163} | train loss {'Reaction outcome loss': 0.13072819687563497, 'Total loss': 0.13072819687563497}
2022-12-05 19:38:18,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:18,373 INFO:     Epoch: 74
2022-12-05 19:38:19,159 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45639450674833254, 'Total loss': 0.45639450674833254} | train loss {'Reaction outcome loss': 0.13244734407921674, 'Total loss': 0.13244734407921674}
2022-12-05 19:38:19,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:19,159 INFO:     Epoch: 75
2022-12-05 19:38:19,939 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45795937471611553, 'Total loss': 0.45795937471611553} | train loss {'Reaction outcome loss': 0.13002604338890095, 'Total loss': 0.13002604338890095}
2022-12-05 19:38:19,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:19,939 INFO:     Epoch: 76
2022-12-05 19:38:20,719 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4612204858730006, 'Total loss': 0.4612204858730006} | train loss {'Reaction outcome loss': 0.13042490050715747, 'Total loss': 0.13042490050715747}
2022-12-05 19:38:20,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:20,719 INFO:     Epoch: 77
2022-12-05 19:38:21,498 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46886678559835565, 'Total loss': 0.46886678559835565} | train loss {'Reaction outcome loss': 0.12875066835005752, 'Total loss': 0.12875066835005752}
2022-12-05 19:38:21,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:21,498 INFO:     Epoch: 78
2022-12-05 19:38:22,280 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4548410924021588, 'Total loss': 0.4548410924021588} | train loss {'Reaction outcome loss': 0.13030738668271996, 'Total loss': 0.13030738668271996}
2022-12-05 19:38:22,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:22,280 INFO:     Epoch: 79
2022-12-05 19:38:23,060 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4618100312560104, 'Total loss': 0.4618100312560104} | train loss {'Reaction outcome loss': 0.12715439357199385, 'Total loss': 0.12715439357199385}
2022-12-05 19:38:23,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:23,060 INFO:     Epoch: 80
2022-12-05 19:38:23,842 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46161544842775476, 'Total loss': 0.46161544842775476} | train loss {'Reaction outcome loss': 0.12939554390299027, 'Total loss': 0.12939554390299027}
2022-12-05 19:38:23,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:23,842 INFO:     Epoch: 81
2022-12-05 19:38:24,624 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4590187772761944, 'Total loss': 0.4590187772761944} | train loss {'Reaction outcome loss': 0.12763864692056276, 'Total loss': 0.12763864692056276}
2022-12-05 19:38:24,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:24,624 INFO:     Epoch: 82
2022-12-05 19:38:25,408 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4602177198543105, 'Total loss': 0.4602177198543105} | train loss {'Reaction outcome loss': 0.1266240131331333, 'Total loss': 0.1266240131331333}
2022-12-05 19:38:25,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:25,408 INFO:     Epoch: 83
2022-12-05 19:38:26,191 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44714226071224655, 'Total loss': 0.44714226071224655} | train loss {'Reaction outcome loss': 0.13021167145744272, 'Total loss': 0.13021167145744272}
2022-12-05 19:38:26,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:26,192 INFO:     Epoch: 84
2022-12-05 19:38:26,975 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46710545690946803, 'Total loss': 0.46710545690946803} | train loss {'Reaction outcome loss': 0.12497878657104294, 'Total loss': 0.12497878657104294}
2022-12-05 19:38:26,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:26,976 INFO:     Epoch: 85
2022-12-05 19:38:27,759 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4531289664811866, 'Total loss': 0.4531289664811866} | train loss {'Reaction outcome loss': 0.1250351287584874, 'Total loss': 0.1250351287584874}
2022-12-05 19:38:27,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:27,759 INFO:     Epoch: 86
2022-12-05 19:38:28,543 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4696081727743149, 'Total loss': 0.4696081727743149} | train loss {'Reaction outcome loss': 0.12470994991647294, 'Total loss': 0.12470994991647294}
2022-12-05 19:38:28,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:28,544 INFO:     Epoch: 87
2022-12-05 19:38:29,330 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46169582043969354, 'Total loss': 0.46169582043969354} | train loss {'Reaction outcome loss': 0.12673305763985168, 'Total loss': 0.12673305763985168}
2022-12-05 19:38:29,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:29,331 INFO:     Epoch: 88
2022-12-05 19:38:30,119 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4652605035104031, 'Total loss': 0.4652605035104031} | train loss {'Reaction outcome loss': 0.12545064110766913, 'Total loss': 0.12545064110766913}
2022-12-05 19:38:30,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:30,119 INFO:     Epoch: 89
2022-12-05 19:38:30,901 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45665953273690024, 'Total loss': 0.45665953273690024} | train loss {'Reaction outcome loss': 0.12773010691582057, 'Total loss': 0.12773010691582057}
2022-12-05 19:38:30,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:30,901 INFO:     Epoch: 90
2022-12-05 19:38:31,692 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46338827908039093, 'Total loss': 0.46338827908039093} | train loss {'Reaction outcome loss': 0.1268082595598258, 'Total loss': 0.1268082595598258}
2022-12-05 19:38:31,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:31,692 INFO:     Epoch: 91
2022-12-05 19:38:32,480 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46080854223218076, 'Total loss': 0.46080854223218076} | train loss {'Reaction outcome loss': 0.12373062100673675, 'Total loss': 0.12373062100673675}
2022-12-05 19:38:32,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:32,480 INFO:     Epoch: 92
2022-12-05 19:38:33,268 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4573695562606634, 'Total loss': 0.4573695562606634} | train loss {'Reaction outcome loss': 0.1211272861968848, 'Total loss': 0.1211272861968848}
2022-12-05 19:38:33,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:33,268 INFO:     Epoch: 93
2022-12-05 19:38:34,055 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4571115575557531, 'Total loss': 0.4571115575557531} | train loss {'Reaction outcome loss': 0.12326446238172348, 'Total loss': 0.12326446238172348}
2022-12-05 19:38:34,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:34,055 INFO:     Epoch: 94
2022-12-05 19:38:34,835 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46899316338605657, 'Total loss': 0.46899316338605657} | train loss {'Reaction outcome loss': 0.12427057098353007, 'Total loss': 0.12427057098353007}
2022-12-05 19:38:34,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:34,836 INFO:     Epoch: 95
2022-12-05 19:38:35,615 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46286856192489, 'Total loss': 0.46286856192489} | train loss {'Reaction outcome loss': 0.12472148919401721, 'Total loss': 0.12472148919401721}
2022-12-05 19:38:35,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:35,615 INFO:     Epoch: 96
2022-12-05 19:38:36,399 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4631968514863835, 'Total loss': 0.4631968514863835} | train loss {'Reaction outcome loss': 0.12344758042332823, 'Total loss': 0.12344758042332823}
2022-12-05 19:38:36,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:36,400 INFO:     Epoch: 97
2022-12-05 19:38:37,186 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4702817534291467, 'Total loss': 0.4702817534291467} | train loss {'Reaction outcome loss': 0.12289021323343403, 'Total loss': 0.12289021323343403}
2022-12-05 19:38:37,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:37,187 INFO:     Epoch: 98
2022-12-05 19:38:37,968 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4705117410698602, 'Total loss': 0.4705117410698602} | train loss {'Reaction outcome loss': 0.12215039268761996, 'Total loss': 0.12215039268761996}
2022-12-05 19:38:37,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:37,969 INFO:     Epoch: 99
2022-12-05 19:38:38,749 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45489929703085924, 'Total loss': 0.45489929703085924} | train loss {'Reaction outcome loss': 0.1214736887582074, 'Total loss': 0.1214736887582074}
2022-12-05 19:38:38,750 INFO:     Best model found after epoch 21 of 100.
2022-12-05 19:38:38,750 INFO:   Done with stage: TRAINING
2022-12-05 19:38:38,750 INFO:   Starting stage: EVALUATION
2022-12-05 19:38:38,887 INFO:   Done with stage: EVALUATION
2022-12-05 19:38:38,888 INFO:   Leaving out SEQ value Fold_4
2022-12-05 19:38:38,900 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:38:38,900 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:38:39,543 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:38:39,543 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:38:39,612 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:38:39,612 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:38:39,612 INFO:     No hyperparam tuning for this model
2022-12-05 19:38:39,613 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:38:39,613 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:38:39,613 INFO:     None feature selector for col prot
2022-12-05 19:38:39,613 INFO:     None feature selector for col prot
2022-12-05 19:38:39,614 INFO:     None feature selector for col prot
2022-12-05 19:38:39,614 INFO:     None feature selector for col chem
2022-12-05 19:38:39,614 INFO:     None feature selector for col chem
2022-12-05 19:38:39,614 INFO:     None feature selector for col chem
2022-12-05 19:38:39,614 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:38:39,614 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:38:39,616 INFO:     Number of params in model 215821
2022-12-05 19:38:39,619 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:38:39,619 INFO:   Starting stage: TRAINING
2022-12-05 19:38:39,680 INFO:     Val loss before train {'Reaction outcome loss': 0.9830911189995029, 'Total loss': 0.9830911189995029}
2022-12-05 19:38:39,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:39,680 INFO:     Epoch: 0
2022-12-05 19:38:40,471 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5917858982628043, 'Total loss': 0.5917858982628043} | train loss {'Reaction outcome loss': 0.8079266562753794, 'Total loss': 0.8079266562753794}
2022-12-05 19:38:40,471 INFO:     Found new best model at epoch 0
2022-12-05 19:38:40,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:40,472 INFO:     Epoch: 1
2022-12-05 19:38:41,264 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5196689543398944, 'Total loss': 0.5196689543398944} | train loss {'Reaction outcome loss': 0.5525775410082876, 'Total loss': 0.5525775410082876}
2022-12-05 19:38:41,265 INFO:     Found new best model at epoch 1
2022-12-05 19:38:41,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:41,266 INFO:     Epoch: 2
2022-12-05 19:38:42,053 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46879984404553066, 'Total loss': 0.46879984404553066} | train loss {'Reaction outcome loss': 0.47804583736828393, 'Total loss': 0.47804583736828393}
2022-12-05 19:38:42,053 INFO:     Found new best model at epoch 2
2022-12-05 19:38:42,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:42,054 INFO:     Epoch: 3
2022-12-05 19:38:42,843 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45949206535111775, 'Total loss': 0.45949206535111775} | train loss {'Reaction outcome loss': 0.44049238915346106, 'Total loss': 0.44049238915346106}
2022-12-05 19:38:42,843 INFO:     Found new best model at epoch 3
2022-12-05 19:38:42,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:42,844 INFO:     Epoch: 4
2022-12-05 19:38:43,630 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44514795257286593, 'Total loss': 0.44514795257286593} | train loss {'Reaction outcome loss': 0.40976301632365403, 'Total loss': 0.40976301632365403}
2022-12-05 19:38:43,630 INFO:     Found new best model at epoch 4
2022-12-05 19:38:43,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:43,631 INFO:     Epoch: 5
2022-12-05 19:38:44,421 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4297416088255969, 'Total loss': 0.4297416088255969} | train loss {'Reaction outcome loss': 0.38912773673631706, 'Total loss': 0.38912773673631706}
2022-12-05 19:38:44,421 INFO:     Found new best model at epoch 5
2022-12-05 19:38:44,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:44,422 INFO:     Epoch: 6
2022-12-05 19:38:45,212 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4252008424902504, 'Total loss': 0.4252008424902504} | train loss {'Reaction outcome loss': 0.3665765497757464, 'Total loss': 0.3665765497757464}
2022-12-05 19:38:45,212 INFO:     Found new best model at epoch 6
2022-12-05 19:38:45,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:45,213 INFO:     Epoch: 7
2022-12-05 19:38:46,004 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44803324341773987, 'Total loss': 0.44803324341773987} | train loss {'Reaction outcome loss': 0.3487636353288378, 'Total loss': 0.3487636353288378}
2022-12-05 19:38:46,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:46,004 INFO:     Epoch: 8
2022-12-05 19:38:46,801 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40438754009929573, 'Total loss': 0.40438754009929573} | train loss {'Reaction outcome loss': 0.333391937370203, 'Total loss': 0.333391937370203}
2022-12-05 19:38:46,801 INFO:     Found new best model at epoch 8
2022-12-05 19:38:46,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:46,802 INFO:     Epoch: 9
2022-12-05 19:38:47,594 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40006248280406, 'Total loss': 0.40006248280406} | train loss {'Reaction outcome loss': 0.31780557921346353, 'Total loss': 0.31780557921346353}
2022-12-05 19:38:47,594 INFO:     Found new best model at epoch 9
2022-12-05 19:38:47,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:47,595 INFO:     Epoch: 10
2022-12-05 19:38:48,383 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4394313740459355, 'Total loss': 0.4394313740459355} | train loss {'Reaction outcome loss': 0.3057287856936455, 'Total loss': 0.3057287856936455}
2022-12-05 19:38:48,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:48,383 INFO:     Epoch: 11
2022-12-05 19:38:49,170 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42201821810819884, 'Total loss': 0.42201821810819884} | train loss {'Reaction outcome loss': 0.2948516505105155, 'Total loss': 0.2948516505105155}
2022-12-05 19:38:49,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:49,170 INFO:     Epoch: 12
2022-12-05 19:38:49,957 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43218531290238554, 'Total loss': 0.43218531290238554} | train loss {'Reaction outcome loss': 0.2849639256693879, 'Total loss': 0.2849639256693879}
2022-12-05 19:38:49,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:49,958 INFO:     Epoch: 13
2022-12-05 19:38:50,746 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4004464921626178, 'Total loss': 0.4004464921626178} | train loss {'Reaction outcome loss': 0.2757134878209659, 'Total loss': 0.2757134878209659}
2022-12-05 19:38:50,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:50,746 INFO:     Epoch: 14
2022-12-05 19:38:51,533 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42656779153780505, 'Total loss': 0.42656779153780505} | train loss {'Reaction outcome loss': 0.26430858775061006, 'Total loss': 0.26430858775061006}
2022-12-05 19:38:51,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:51,533 INFO:     Epoch: 15
2022-12-05 19:38:52,326 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4075761715119535, 'Total loss': 0.4075761715119535} | train loss {'Reaction outcome loss': 0.25702597337717914, 'Total loss': 0.25702597337717914}
2022-12-05 19:38:52,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:52,326 INFO:     Epoch: 16
2022-12-05 19:38:53,116 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41448781165209686, 'Total loss': 0.41448781165209686} | train loss {'Reaction outcome loss': 0.24807204625436238, 'Total loss': 0.24807204625436238}
2022-12-05 19:38:53,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:53,116 INFO:     Epoch: 17
2022-12-05 19:38:53,905 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4215350223874504, 'Total loss': 0.4215350223874504} | train loss {'Reaction outcome loss': 0.2424722221889058, 'Total loss': 0.2424722221889058}
2022-12-05 19:38:53,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:53,905 INFO:     Epoch: 18
2022-12-05 19:38:54,691 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4247134832495993, 'Total loss': 0.4247134832495993} | train loss {'Reaction outcome loss': 0.23498080190347165, 'Total loss': 0.23498080190347165}
2022-12-05 19:38:54,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:54,691 INFO:     Epoch: 19
2022-12-05 19:38:55,477 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42433789575641806, 'Total loss': 0.42433789575641806} | train loss {'Reaction outcome loss': 0.22753236070275307, 'Total loss': 0.22753236070275307}
2022-12-05 19:38:55,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:55,478 INFO:     Epoch: 20
2022-12-05 19:38:56,271 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42517131533135066, 'Total loss': 0.42517131533135066} | train loss {'Reaction outcome loss': 0.22138487535471818, 'Total loss': 0.22138487535471818}
2022-12-05 19:38:56,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:56,272 INFO:     Epoch: 21
2022-12-05 19:38:57,062 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45104028352282266, 'Total loss': 0.45104028352282266} | train loss {'Reaction outcome loss': 0.22031982556289556, 'Total loss': 0.22031982556289556}
2022-12-05 19:38:57,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:57,063 INFO:     Epoch: 22
2022-12-05 19:38:57,854 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40495946630835533, 'Total loss': 0.40495946630835533} | train loss {'Reaction outcome loss': 0.21507940988759605, 'Total loss': 0.21507940988759605}
2022-12-05 19:38:57,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:57,854 INFO:     Epoch: 23
2022-12-05 19:38:58,645 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4019002960148183, 'Total loss': 0.4019002960148183} | train loss {'Reaction outcome loss': 0.2051698140495894, 'Total loss': 0.2051698140495894}
2022-12-05 19:38:58,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:58,645 INFO:     Epoch: 24
2022-12-05 19:38:59,432 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41080558943477546, 'Total loss': 0.41080558943477546} | train loss {'Reaction outcome loss': 0.2020177259433026, 'Total loss': 0.2020177259433026}
2022-12-05 19:38:59,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:38:59,432 INFO:     Epoch: 25
2022-12-05 19:39:00,222 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4169609665193341, 'Total loss': 0.4169609665193341} | train loss {'Reaction outcome loss': 0.2002983874280234, 'Total loss': 0.2002983874280234}
2022-12-05 19:39:00,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:00,223 INFO:     Epoch: 26
2022-12-05 19:39:01,015 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4369219670241529, 'Total loss': 0.4369219670241529} | train loss {'Reaction outcome loss': 0.1936357995457187, 'Total loss': 0.1936357995457187}
2022-12-05 19:39:01,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:01,015 INFO:     Epoch: 27
2022-12-05 19:39:01,802 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4374562543393536, 'Total loss': 0.4374562543393536} | train loss {'Reaction outcome loss': 0.19039532013845686, 'Total loss': 0.19039532013845686}
2022-12-05 19:39:01,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:01,802 INFO:     Epoch: 28
2022-12-05 19:39:02,596 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42342333969744766, 'Total loss': 0.42342333969744766} | train loss {'Reaction outcome loss': 0.18605747779413145, 'Total loss': 0.18605747779413145}
2022-12-05 19:39:02,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:02,596 INFO:     Epoch: 29
2022-12-05 19:39:03,386 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43081511523235927, 'Total loss': 0.43081511523235927} | train loss {'Reaction outcome loss': 0.1846188395341136, 'Total loss': 0.1846188395341136}
2022-12-05 19:39:03,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:03,386 INFO:     Epoch: 30
2022-12-05 19:39:04,177 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41716471839357505, 'Total loss': 0.41716471839357505} | train loss {'Reaction outcome loss': 0.1820455165313823, 'Total loss': 0.1820455165313823}
2022-12-05 19:39:04,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:04,178 INFO:     Epoch: 31
2022-12-05 19:39:04,965 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4252637164159255, 'Total loss': 0.4252637164159255} | train loss {'Reaction outcome loss': 0.1764987011269039, 'Total loss': 0.1764987011269039}
2022-12-05 19:39:04,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:04,966 INFO:     Epoch: 32
2022-12-05 19:39:05,753 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4198847316544164, 'Total loss': 0.4198847316544164} | train loss {'Reaction outcome loss': 0.17545645631545662, 'Total loss': 0.17545645631545662}
2022-12-05 19:39:05,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:05,753 INFO:     Epoch: 33
2022-12-05 19:39:06,546 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42327564480629837, 'Total loss': 0.42327564480629837} | train loss {'Reaction outcome loss': 0.1719039676901029, 'Total loss': 0.1719039676901029}
2022-12-05 19:39:06,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:06,546 INFO:     Epoch: 34
2022-12-05 19:39:07,337 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4139202401380647, 'Total loss': 0.4139202401380647} | train loss {'Reaction outcome loss': 0.1693003498245867, 'Total loss': 0.1693003498245867}
2022-12-05 19:39:07,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:07,337 INFO:     Epoch: 35
2022-12-05 19:39:08,126 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45639814030040393, 'Total loss': 0.45639814030040393} | train loss {'Reaction outcome loss': 0.16666792474535047, 'Total loss': 0.16666792474535047}
2022-12-05 19:39:08,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:08,126 INFO:     Epoch: 36
2022-12-05 19:39:08,915 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41368809867311607, 'Total loss': 0.41368809867311607} | train loss {'Reaction outcome loss': 0.16447854739974957, 'Total loss': 0.16447854739974957}
2022-12-05 19:39:08,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:08,916 INFO:     Epoch: 37
2022-12-05 19:39:09,704 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4344389912757007, 'Total loss': 0.4344389912757007} | train loss {'Reaction outcome loss': 0.1606859072890817, 'Total loss': 0.1606859072890817}
2022-12-05 19:39:09,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:09,704 INFO:     Epoch: 38
2022-12-05 19:39:10,492 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43061440167101944, 'Total loss': 0.43061440167101944} | train loss {'Reaction outcome loss': 0.1603882575141532, 'Total loss': 0.1603882575141532}
2022-12-05 19:39:10,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:10,493 INFO:     Epoch: 39
2022-12-05 19:39:11,280 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4568695805289529, 'Total loss': 0.4568695805289529} | train loss {'Reaction outcome loss': 0.15648264082110658, 'Total loss': 0.15648264082110658}
2022-12-05 19:39:11,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:11,280 INFO:     Epoch: 40
2022-12-05 19:39:12,072 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43952211940830405, 'Total loss': 0.43952211940830405} | train loss {'Reaction outcome loss': 0.15430404468610578, 'Total loss': 0.15430404468610578}
2022-12-05 19:39:12,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:12,072 INFO:     Epoch: 41
2022-12-05 19:39:12,866 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42792627994309773, 'Total loss': 0.42792627994309773} | train loss {'Reaction outcome loss': 0.1536305461915172, 'Total loss': 0.1536305461915172}
2022-12-05 19:39:12,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:12,867 INFO:     Epoch: 42
2022-12-05 19:39:13,656 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43861235271800647, 'Total loss': 0.43861235271800647} | train loss {'Reaction outcome loss': 0.1546636150693711, 'Total loss': 0.1546636150693711}
2022-12-05 19:39:13,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:13,656 INFO:     Epoch: 43
2022-12-05 19:39:14,443 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4387921460650184, 'Total loss': 0.4387921460650184} | train loss {'Reaction outcome loss': 0.15242565633082877, 'Total loss': 0.15242565633082877}
2022-12-05 19:39:14,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:14,443 INFO:     Epoch: 44
2022-12-05 19:39:15,230 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4377248121256178, 'Total loss': 0.4377248121256178} | train loss {'Reaction outcome loss': 0.14976320284969952, 'Total loss': 0.14976320284969952}
2022-12-05 19:39:15,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:15,231 INFO:     Epoch: 45
2022-12-05 19:39:16,016 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4229684788733721, 'Total loss': 0.4229684788733721} | train loss {'Reaction outcome loss': 0.14666605659437423, 'Total loss': 0.14666605659437423}
2022-12-05 19:39:16,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:16,016 INFO:     Epoch: 46
2022-12-05 19:39:16,800 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4359769871966405, 'Total loss': 0.4359769871966405} | train loss {'Reaction outcome loss': 0.14902185617508937, 'Total loss': 0.14902185617508937}
2022-12-05 19:39:16,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:16,801 INFO:     Epoch: 47
2022-12-05 19:39:17,589 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4303435052491047, 'Total loss': 0.4303435052491047} | train loss {'Reaction outcome loss': 0.1455068089067936, 'Total loss': 0.1455068089067936}
2022-12-05 19:39:17,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:17,589 INFO:     Epoch: 48
2022-12-05 19:39:18,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43509666791016405, 'Total loss': 0.43509666791016405} | train loss {'Reaction outcome loss': 0.14488494394689191, 'Total loss': 0.14488494394689191}
2022-12-05 19:39:18,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:18,377 INFO:     Epoch: 49
2022-12-05 19:39:19,162 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43295990650288085, 'Total loss': 0.43295990650288085} | train loss {'Reaction outcome loss': 0.14274317486857882, 'Total loss': 0.14274317486857882}
2022-12-05 19:39:19,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:19,163 INFO:     Epoch: 50
2022-12-05 19:39:19,953 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44481480290943926, 'Total loss': 0.44481480290943926} | train loss {'Reaction outcome loss': 0.14199504069223695, 'Total loss': 0.14199504069223695}
2022-12-05 19:39:19,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:19,953 INFO:     Epoch: 51
2022-12-05 19:39:20,741 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4556544158946384, 'Total loss': 0.4556544158946384} | train loss {'Reaction outcome loss': 0.14016166917067402, 'Total loss': 0.14016166917067402}
2022-12-05 19:39:20,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:20,742 INFO:     Epoch: 52
2022-12-05 19:39:21,531 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4543098275634376, 'Total loss': 0.4543098275634376} | train loss {'Reaction outcome loss': 0.13975435218640736, 'Total loss': 0.13975435218640736}
2022-12-05 19:39:21,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:21,531 INFO:     Epoch: 53
2022-12-05 19:39:22,323 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4312854149505835, 'Total loss': 0.4312854149505835} | train loss {'Reaction outcome loss': 0.14016359927018687, 'Total loss': 0.14016359927018687}
2022-12-05 19:39:22,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:22,323 INFO:     Epoch: 54
2022-12-05 19:39:23,114 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44414790482683614, 'Total loss': 0.44414790482683614} | train loss {'Reaction outcome loss': 0.1382126422789024, 'Total loss': 0.1382126422789024}
2022-12-05 19:39:23,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:23,114 INFO:     Epoch: 55
2022-12-05 19:39:23,907 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43974239379167557, 'Total loss': 0.43974239379167557} | train loss {'Reaction outcome loss': 0.13778003550761816, 'Total loss': 0.13778003550761816}
2022-12-05 19:39:23,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:23,907 INFO:     Epoch: 56
2022-12-05 19:39:24,698 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.448686636518687, 'Total loss': 0.448686636518687} | train loss {'Reaction outcome loss': 0.13565996021640545, 'Total loss': 0.13565996021640545}
2022-12-05 19:39:24,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:24,698 INFO:     Epoch: 57
2022-12-05 19:39:25,490 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4473701549524611, 'Total loss': 0.4473701549524611} | train loss {'Reaction outcome loss': 0.13812531183036614, 'Total loss': 0.13812531183036614}
2022-12-05 19:39:25,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:25,490 INFO:     Epoch: 58
2022-12-05 19:39:26,280 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43444863554428925, 'Total loss': 0.43444863554428925} | train loss {'Reaction outcome loss': 0.13505228609606929, 'Total loss': 0.13505228609606929}
2022-12-05 19:39:26,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:26,280 INFO:     Epoch: 59
2022-12-05 19:39:27,071 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44951924512332136, 'Total loss': 0.44951924512332136} | train loss {'Reaction outcome loss': 0.13405588504155072, 'Total loss': 0.13405588504155072}
2022-12-05 19:39:27,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:27,071 INFO:     Epoch: 60
2022-12-05 19:39:27,863 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44974998384714127, 'Total loss': 0.44974998384714127} | train loss {'Reaction outcome loss': 0.13104896764365995, 'Total loss': 0.13104896764365995}
2022-12-05 19:39:27,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:27,863 INFO:     Epoch: 61
2022-12-05 19:39:28,655 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4245471793480895, 'Total loss': 0.4245471793480895} | train loss {'Reaction outcome loss': 0.13145755267112838, 'Total loss': 0.13145755267112838}
2022-12-05 19:39:28,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:28,656 INFO:     Epoch: 62
2022-12-05 19:39:29,453 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42627115886319766, 'Total loss': 0.42627115886319766} | train loss {'Reaction outcome loss': 0.1305701048740623, 'Total loss': 0.1305701048740623}
2022-12-05 19:39:29,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:29,454 INFO:     Epoch: 63
2022-12-05 19:39:30,243 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42902450229633937, 'Total loss': 0.42902450229633937} | train loss {'Reaction outcome loss': 0.12883352288330088, 'Total loss': 0.12883352288330088}
2022-12-05 19:39:30,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:30,244 INFO:     Epoch: 64
2022-12-05 19:39:31,035 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4316892044788057, 'Total loss': 0.4316892044788057} | train loss {'Reaction outcome loss': 0.1300408802356343, 'Total loss': 0.1300408802356343}
2022-12-05 19:39:31,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:31,035 INFO:     Epoch: 65
2022-12-05 19:39:31,827 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43029300529848447, 'Total loss': 0.43029300529848447} | train loss {'Reaction outcome loss': 0.1293792032465643, 'Total loss': 0.1293792032465643}
2022-12-05 19:39:31,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:31,828 INFO:     Epoch: 66
2022-12-05 19:39:32,618 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44557815383781085, 'Total loss': 0.44557815383781085} | train loss {'Reaction outcome loss': 0.12807671073824167, 'Total loss': 0.12807671073824167}
2022-12-05 19:39:32,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:32,618 INFO:     Epoch: 67
2022-12-05 19:39:33,411 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4299104394899173, 'Total loss': 0.4299104394899173} | train loss {'Reaction outcome loss': 0.12822991416466478, 'Total loss': 0.12822991416466478}
2022-12-05 19:39:33,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:33,411 INFO:     Epoch: 68
2022-12-05 19:39:34,207 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4448590688407421, 'Total loss': 0.4448590688407421} | train loss {'Reaction outcome loss': 0.12667063430559877, 'Total loss': 0.12667063430559877}
2022-12-05 19:39:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:34,207 INFO:     Epoch: 69
2022-12-05 19:39:35,002 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45820336585695093, 'Total loss': 0.45820336585695093} | train loss {'Reaction outcome loss': 0.12627871139545221, 'Total loss': 0.12627871139545221}
2022-12-05 19:39:35,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:35,003 INFO:     Epoch: 70
2022-12-05 19:39:35,798 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4369478855620731, 'Total loss': 0.4369478855620731} | train loss {'Reaction outcome loss': 0.12368903738655607, 'Total loss': 0.12368903738655607}
2022-12-05 19:39:35,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:35,799 INFO:     Epoch: 71
2022-12-05 19:39:36,586 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.434053945439783, 'Total loss': 0.434053945439783} | train loss {'Reaction outcome loss': 0.12605003358378095, 'Total loss': 0.12605003358378095}
2022-12-05 19:39:36,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:36,587 INFO:     Epoch: 72
2022-12-05 19:39:37,380 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4520224966108799, 'Total loss': 0.4520224966108799} | train loss {'Reaction outcome loss': 0.12772564183236385, 'Total loss': 0.12772564183236385}
2022-12-05 19:39:37,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:37,381 INFO:     Epoch: 73
2022-12-05 19:39:38,176 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4221953552385623, 'Total loss': 0.4221953552385623} | train loss {'Reaction outcome loss': 0.12569248616239245, 'Total loss': 0.12569248616239245}
2022-12-05 19:39:38,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:38,177 INFO:     Epoch: 74
2022-12-05 19:39:38,977 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4244964499534531, 'Total loss': 0.4244964499534531} | train loss {'Reaction outcome loss': 0.12180750020684636, 'Total loss': 0.12180750020684636}
2022-12-05 19:39:38,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:38,977 INFO:     Epoch: 75
2022-12-05 19:39:39,779 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44560628790747037, 'Total loss': 0.44560628790747037} | train loss {'Reaction outcome loss': 0.12189842644622739, 'Total loss': 0.12189842644622739}
2022-12-05 19:39:39,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:39,779 INFO:     Epoch: 76
2022-12-05 19:39:40,572 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4510534144937992, 'Total loss': 0.4510534144937992} | train loss {'Reaction outcome loss': 0.12470322240676199, 'Total loss': 0.12470322240676199}
2022-12-05 19:39:40,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:40,572 INFO:     Epoch: 77
2022-12-05 19:39:41,363 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42912448942661285, 'Total loss': 0.42912448942661285} | train loss {'Reaction outcome loss': 0.12047107598307182, 'Total loss': 0.12047107598307182}
2022-12-05 19:39:41,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:41,363 INFO:     Epoch: 78
2022-12-05 19:39:42,154 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43365089646117255, 'Total loss': 0.43365089646117255} | train loss {'Reaction outcome loss': 0.12329420108272104, 'Total loss': 0.12329420108272104}
2022-12-05 19:39:42,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:42,154 INFO:     Epoch: 79
2022-12-05 19:39:42,945 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4240759655155919, 'Total loss': 0.4240759655155919} | train loss {'Reaction outcome loss': 0.11962886288077855, 'Total loss': 0.11962886288077855}
2022-12-05 19:39:42,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:42,945 INFO:     Epoch: 80
2022-12-05 19:39:43,736 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4625475389713591, 'Total loss': 0.4625475389713591} | train loss {'Reaction outcome loss': 0.11948673594362881, 'Total loss': 0.11948673594362881}
2022-12-05 19:39:43,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:43,737 INFO:     Epoch: 81
2022-12-05 19:39:44,528 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42202219350094144, 'Total loss': 0.42202219350094144} | train loss {'Reaction outcome loss': 0.11868261472911251, 'Total loss': 0.11868261472911251}
2022-12-05 19:39:44,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:44,528 INFO:     Epoch: 82
2022-12-05 19:39:45,321 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.430046831892634, 'Total loss': 0.430046831892634} | train loss {'Reaction outcome loss': 0.11942822271007664, 'Total loss': 0.11942822271007664}
2022-12-05 19:39:45,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:45,322 INFO:     Epoch: 83
2022-12-05 19:39:46,118 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44468408213420346, 'Total loss': 0.44468408213420346} | train loss {'Reaction outcome loss': 0.1165934433210261, 'Total loss': 0.1165934433210261}
2022-12-05 19:39:46,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:46,119 INFO:     Epoch: 84
2022-12-05 19:39:46,912 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43859982666485436, 'Total loss': 0.43859982666485436} | train loss {'Reaction outcome loss': 0.11844585694524706, 'Total loss': 0.11844585694524706}
2022-12-05 19:39:46,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:46,912 INFO:     Epoch: 85
2022-12-05 19:39:47,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4334114055064591, 'Total loss': 0.4334114055064591} | train loss {'Reaction outcome loss': 0.11858490499838882, 'Total loss': 0.11858490499838882}
2022-12-05 19:39:47,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:47,701 INFO:     Epoch: 86
2022-12-05 19:39:48,496 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4261110360649499, 'Total loss': 0.4261110360649499} | train loss {'Reaction outcome loss': 0.11910098692288204, 'Total loss': 0.11910098692288204}
2022-12-05 19:39:48,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:48,496 INFO:     Epoch: 87
2022-12-05 19:39:49,284 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43177286110056395, 'Total loss': 0.43177286110056395} | train loss {'Reaction outcome loss': 0.1202515448880743, 'Total loss': 0.1202515448880743}
2022-12-05 19:39:49,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:49,284 INFO:     Epoch: 88
2022-12-05 19:39:50,078 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4363973804495551, 'Total loss': 0.4363973804495551} | train loss {'Reaction outcome loss': 0.11773824999679108, 'Total loss': 0.11773824999679108}
2022-12-05 19:39:50,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:50,079 INFO:     Epoch: 89
2022-12-05 19:39:50,870 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4146875259889798, 'Total loss': 0.4146875259889798} | train loss {'Reaction outcome loss': 0.11695708476615195, 'Total loss': 0.11695708476615195}
2022-12-05 19:39:50,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:50,871 INFO:     Epoch: 90
2022-12-05 19:39:51,662 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4341729191893881, 'Total loss': 0.4341729191893881} | train loss {'Reaction outcome loss': 0.11848499291120287, 'Total loss': 0.11848499291120287}
2022-12-05 19:39:51,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:51,662 INFO:     Epoch: 91
2022-12-05 19:39:52,456 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42565781433156435, 'Total loss': 0.42565781433156435} | train loss {'Reaction outcome loss': 0.11572096854144213, 'Total loss': 0.11572096854144213}
2022-12-05 19:39:52,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:52,456 INFO:     Epoch: 92
2022-12-05 19:39:53,246 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4364450678906657, 'Total loss': 0.4364450678906657} | train loss {'Reaction outcome loss': 0.1147236926557154, 'Total loss': 0.1147236926557154}
2022-12-05 19:39:53,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:53,246 INFO:     Epoch: 93
2022-12-05 19:39:54,036 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44712003252723, 'Total loss': 0.44712003252723} | train loss {'Reaction outcome loss': 0.11903200729997182, 'Total loss': 0.11903200729997182}
2022-12-05 19:39:54,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:54,036 INFO:     Epoch: 94
2022-12-05 19:39:54,825 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44329221512783656, 'Total loss': 0.44329221512783656} | train loss {'Reaction outcome loss': 0.11484165268817119, 'Total loss': 0.11484165268817119}
2022-12-05 19:39:54,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:54,825 INFO:     Epoch: 95
2022-12-05 19:39:55,614 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4433884397149086, 'Total loss': 0.4433884397149086} | train loss {'Reaction outcome loss': 0.11377859414003942, 'Total loss': 0.11377859414003942}
2022-12-05 19:39:55,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:55,615 INFO:     Epoch: 96
2022-12-05 19:39:56,406 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.419188858771866, 'Total loss': 0.419188858771866} | train loss {'Reaction outcome loss': 0.11382174588625832, 'Total loss': 0.11382174588625832}
2022-12-05 19:39:56,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:56,407 INFO:     Epoch: 97
2022-12-05 19:39:57,198 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4327191376889294, 'Total loss': 0.4327191376889294} | train loss {'Reaction outcome loss': 0.11289209468024118, 'Total loss': 0.11289209468024118}
2022-12-05 19:39:57,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:57,199 INFO:     Epoch: 98
2022-12-05 19:39:57,985 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4316861672665585, 'Total loss': 0.4316861672665585} | train loss {'Reaction outcome loss': 0.11208965617555136, 'Total loss': 0.11208965617555136}
2022-12-05 19:39:57,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:57,985 INFO:     Epoch: 99
2022-12-05 19:39:58,772 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4134798556227576, 'Total loss': 0.4134798556227576} | train loss {'Reaction outcome loss': 0.11025524152708906, 'Total loss': 0.11025524152708906}
2022-12-05 19:39:58,772 INFO:     Best model found after epoch 10 of 100.
2022-12-05 19:39:58,772 INFO:   Done with stage: TRAINING
2022-12-05 19:39:58,772 INFO:   Starting stage: EVALUATION
2022-12-05 19:39:58,904 INFO:   Done with stage: EVALUATION
2022-12-05 19:39:58,904 INFO:   Leaving out SEQ value Fold_5
2022-12-05 19:39:58,917 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:39:58,917 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:39:59,562 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:39:59,562 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:39:59,631 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:39:59,631 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:39:59,631 INFO:     No hyperparam tuning for this model
2022-12-05 19:39:59,631 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:39:59,631 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:39:59,632 INFO:     None feature selector for col prot
2022-12-05 19:39:59,632 INFO:     None feature selector for col prot
2022-12-05 19:39:59,632 INFO:     None feature selector for col prot
2022-12-05 19:39:59,633 INFO:     None feature selector for col chem
2022-12-05 19:39:59,633 INFO:     None feature selector for col chem
2022-12-05 19:39:59,633 INFO:     None feature selector for col chem
2022-12-05 19:39:59,633 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:39:59,633 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:39:59,635 INFO:     Number of params in model 215821
2022-12-05 19:39:59,638 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:39:59,638 INFO:   Starting stage: TRAINING
2022-12-05 19:39:59,699 INFO:     Val loss before train {'Reaction outcome loss': 1.0515069975094362, 'Total loss': 1.0515069975094362}
2022-12-05 19:39:59,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:39:59,699 INFO:     Epoch: 0
2022-12-05 19:40:00,495 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6260968378999017, 'Total loss': 0.6260968378999017} | train loss {'Reaction outcome loss': 0.7802328968096358, 'Total loss': 0.7802328968096358}
2022-12-05 19:40:00,496 INFO:     Found new best model at epoch 0
2022-12-05 19:40:00,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:00,496 INFO:     Epoch: 1
2022-12-05 19:40:01,297 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5422026525166902, 'Total loss': 0.5422026525166902} | train loss {'Reaction outcome loss': 0.5311411033094171, 'Total loss': 0.5311411033094171}
2022-12-05 19:40:01,297 INFO:     Found new best model at epoch 1
2022-12-05 19:40:01,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:01,298 INFO:     Epoch: 2
2022-12-05 19:40:02,098 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4889139025048776, 'Total loss': 0.4889139025048776} | train loss {'Reaction outcome loss': 0.4728683309275129, 'Total loss': 0.4728683309275129}
2022-12-05 19:40:02,099 INFO:     Found new best model at epoch 2
2022-12-05 19:40:02,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:02,100 INFO:     Epoch: 3
2022-12-05 19:40:02,891 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4687999944117936, 'Total loss': 0.4687999944117936} | train loss {'Reaction outcome loss': 0.439225990581609, 'Total loss': 0.439225990581609}
2022-12-05 19:40:02,891 INFO:     Found new best model at epoch 3
2022-12-05 19:40:02,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:02,892 INFO:     Epoch: 4
2022-12-05 19:40:03,682 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46652388674291695, 'Total loss': 0.46652388674291695} | train loss {'Reaction outcome loss': 0.4153206995744937, 'Total loss': 0.4153206995744937}
2022-12-05 19:40:03,683 INFO:     Found new best model at epoch 4
2022-12-05 19:40:03,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:03,683 INFO:     Epoch: 5
2022-12-05 19:40:04,478 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45868860388343985, 'Total loss': 0.45868860388343985} | train loss {'Reaction outcome loss': 0.39485615244519856, 'Total loss': 0.39485615244519856}
2022-12-05 19:40:04,478 INFO:     Found new best model at epoch 5
2022-12-05 19:40:04,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:04,479 INFO:     Epoch: 6
2022-12-05 19:40:05,271 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4544101879000664, 'Total loss': 0.4544101879000664} | train loss {'Reaction outcome loss': 0.36842270813852185, 'Total loss': 0.36842270813852185}
2022-12-05 19:40:05,271 INFO:     Found new best model at epoch 6
2022-12-05 19:40:05,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:05,272 INFO:     Epoch: 7
2022-12-05 19:40:06,064 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4408278265459971, 'Total loss': 0.4408278265459971} | train loss {'Reaction outcome loss': 0.3509033636646232, 'Total loss': 0.3509033636646232}
2022-12-05 19:40:06,064 INFO:     Found new best model at epoch 7
2022-12-05 19:40:06,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:06,065 INFO:     Epoch: 8
2022-12-05 19:40:06,866 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.440062610601837, 'Total loss': 0.440062610601837} | train loss {'Reaction outcome loss': 0.3351830943725128, 'Total loss': 0.3351830943725128}
2022-12-05 19:40:06,867 INFO:     Found new best model at epoch 8
2022-12-05 19:40:06,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:06,868 INFO:     Epoch: 9
2022-12-05 19:40:07,662 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4327343695543029, 'Total loss': 0.4327343695543029} | train loss {'Reaction outcome loss': 0.32055908070522765, 'Total loss': 0.32055908070522765}
2022-12-05 19:40:07,662 INFO:     Found new best model at epoch 9
2022-12-05 19:40:07,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:07,663 INFO:     Epoch: 10
2022-12-05 19:40:08,455 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.434752436185425, 'Total loss': 0.434752436185425} | train loss {'Reaction outcome loss': 0.31005639168113347, 'Total loss': 0.31005639168113347}
2022-12-05 19:40:08,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:08,455 INFO:     Epoch: 11
2022-12-05 19:40:09,245 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44279584525661037, 'Total loss': 0.44279584525661037} | train loss {'Reaction outcome loss': 0.2939547589011038, 'Total loss': 0.2939547589011038}
2022-12-05 19:40:09,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:09,246 INFO:     Epoch: 12
2022-12-05 19:40:10,042 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43191413378173654, 'Total loss': 0.43191413378173654} | train loss {'Reaction outcome loss': 0.29198041051505547, 'Total loss': 0.29198041051505547}
2022-12-05 19:40:10,042 INFO:     Found new best model at epoch 12
2022-12-05 19:40:10,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:10,043 INFO:     Epoch: 13
2022-12-05 19:40:10,837 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4377516552128575, 'Total loss': 0.4377516552128575} | train loss {'Reaction outcome loss': 0.2839734496978613, 'Total loss': 0.2839734496978613}
2022-12-05 19:40:10,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:10,837 INFO:     Epoch: 14
2022-12-05 19:40:11,631 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4313901164992289, 'Total loss': 0.4313901164992289} | train loss {'Reaction outcome loss': 0.27422804544728835, 'Total loss': 0.27422804544728835}
2022-12-05 19:40:11,631 INFO:     Found new best model at epoch 14
2022-12-05 19:40:11,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:11,632 INFO:     Epoch: 15
2022-12-05 19:40:12,428 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4298798255622387, 'Total loss': 0.4298798255622387} | train loss {'Reaction outcome loss': 0.2623992143010321, 'Total loss': 0.2623992143010321}
2022-12-05 19:40:12,428 INFO:     Found new best model at epoch 15
2022-12-05 19:40:12,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:12,429 INFO:     Epoch: 16
2022-12-05 19:40:13,219 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4274356984956698, 'Total loss': 0.4274356984956698} | train loss {'Reaction outcome loss': 0.25576500026018995, 'Total loss': 0.25576500026018995}
2022-12-05 19:40:13,219 INFO:     Found new best model at epoch 16
2022-12-05 19:40:13,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:13,220 INFO:     Epoch: 17
2022-12-05 19:40:14,015 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42286963015794754, 'Total loss': 0.42286963015794754} | train loss {'Reaction outcome loss': 0.2479848445596754, 'Total loss': 0.2479848445596754}
2022-12-05 19:40:14,015 INFO:     Found new best model at epoch 17
2022-12-05 19:40:14,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:14,016 INFO:     Epoch: 18
2022-12-05 19:40:14,813 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4455312504009767, 'Total loss': 0.4455312504009767} | train loss {'Reaction outcome loss': 0.24050912067957736, 'Total loss': 0.24050912067957736}
2022-12-05 19:40:14,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:14,814 INFO:     Epoch: 19
2022-12-05 19:40:15,607 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4321323457089337, 'Total loss': 0.4321323457089337} | train loss {'Reaction outcome loss': 0.23803030093189192, 'Total loss': 0.23803030093189192}
2022-12-05 19:40:15,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:15,607 INFO:     Epoch: 20
2022-12-05 19:40:16,406 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42207499356432393, 'Total loss': 0.42207499356432393} | train loss {'Reaction outcome loss': 0.2319955040478272, 'Total loss': 0.2319955040478272}
2022-12-05 19:40:16,406 INFO:     Found new best model at epoch 20
2022-12-05 19:40:16,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:16,407 INFO:     Epoch: 21
2022-12-05 19:40:17,203 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4142368496818976, 'Total loss': 0.4142368496818976} | train loss {'Reaction outcome loss': 0.22409005363581153, 'Total loss': 0.22409005363581153}
2022-12-05 19:40:17,203 INFO:     Found new best model at epoch 21
2022-12-05 19:40:17,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:17,204 INFO:     Epoch: 22
2022-12-05 19:40:17,996 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4284479265863245, 'Total loss': 0.4284479265863245} | train loss {'Reaction outcome loss': 0.22033906655634947, 'Total loss': 0.22033906655634947}
2022-12-05 19:40:17,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:17,996 INFO:     Epoch: 23
2022-12-05 19:40:18,789 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41651326113126497, 'Total loss': 0.41651326113126497} | train loss {'Reaction outcome loss': 0.21578162107692073, 'Total loss': 0.21578162107692073}
2022-12-05 19:40:18,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:18,789 INFO:     Epoch: 24
2022-12-05 19:40:19,590 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4168694561178034, 'Total loss': 0.4168694561178034} | train loss {'Reaction outcome loss': 0.20865920734467355, 'Total loss': 0.20865920734467355}
2022-12-05 19:40:19,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:19,590 INFO:     Epoch: 25
2022-12-05 19:40:20,383 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.422013595700264, 'Total loss': 0.422013595700264} | train loss {'Reaction outcome loss': 0.20518875686896715, 'Total loss': 0.20518875686896715}
2022-12-05 19:40:20,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:20,384 INFO:     Epoch: 26
2022-12-05 19:40:21,185 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42383974621241743, 'Total loss': 0.42383974621241743} | train loss {'Reaction outcome loss': 0.20370096326635978, 'Total loss': 0.20370096326635978}
2022-12-05 19:40:21,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:21,185 INFO:     Epoch: 27
2022-12-05 19:40:21,980 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42140561274506827, 'Total loss': 0.42140561274506827} | train loss {'Reaction outcome loss': 0.19947779591870213, 'Total loss': 0.19947779591870213}
2022-12-05 19:40:21,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:21,980 INFO:     Epoch: 28
2022-12-05 19:40:22,774 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4215662933208726, 'Total loss': 0.4215662933208726} | train loss {'Reaction outcome loss': 0.19871663691302544, 'Total loss': 0.19871663691302544}
2022-12-05 19:40:22,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:22,775 INFO:     Epoch: 29
2022-12-05 19:40:23,571 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4160188263790174, 'Total loss': 0.4160188263790174} | train loss {'Reaction outcome loss': 0.19157302271016696, 'Total loss': 0.19157302271016696}
2022-12-05 19:40:23,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:23,571 INFO:     Epoch: 30
2022-12-05 19:40:24,368 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42428319105370477, 'Total loss': 0.42428319105370477} | train loss {'Reaction outcome loss': 0.19069674772470585, 'Total loss': 0.19069674772470585}
2022-12-05 19:40:24,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:24,368 INFO:     Epoch: 31
2022-12-05 19:40:25,164 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4086397540840236, 'Total loss': 0.4086397540840236} | train loss {'Reaction outcome loss': 0.18919966400031618, 'Total loss': 0.18919966400031618}
2022-12-05 19:40:25,164 INFO:     Found new best model at epoch 31
2022-12-05 19:40:25,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:25,165 INFO:     Epoch: 32
2022-12-05 19:40:25,959 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4105740919370543, 'Total loss': 0.4105740919370543} | train loss {'Reaction outcome loss': 0.1868087753412212, 'Total loss': 0.1868087753412212}
2022-12-05 19:40:25,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:25,960 INFO:     Epoch: 33
2022-12-05 19:40:26,752 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41475580632686615, 'Total loss': 0.41475580632686615} | train loss {'Reaction outcome loss': 0.18766449976275082, 'Total loss': 0.18766449976275082}
2022-12-05 19:40:26,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:26,752 INFO:     Epoch: 34
2022-12-05 19:40:27,550 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42476384951309726, 'Total loss': 0.42476384951309726} | train loss {'Reaction outcome loss': 0.18468389058342347, 'Total loss': 0.18468389058342347}
2022-12-05 19:40:27,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:27,551 INFO:     Epoch: 35
2022-12-05 19:40:28,352 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4106922782957554, 'Total loss': 0.4106922782957554} | train loss {'Reaction outcome loss': 0.1765332155020131, 'Total loss': 0.1765332155020131}
2022-12-05 19:40:28,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:28,352 INFO:     Epoch: 36
2022-12-05 19:40:29,152 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41471323574131186, 'Total loss': 0.41471323574131186} | train loss {'Reaction outcome loss': 0.1779180037777735, 'Total loss': 0.1779180037777735}
2022-12-05 19:40:29,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:29,152 INFO:     Epoch: 37
2022-12-05 19:40:29,947 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4166938266293569, 'Total loss': 0.4166938266293569} | train loss {'Reaction outcome loss': 0.17157468447831237, 'Total loss': 0.17157468447831237}
2022-12-05 19:40:29,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:29,947 INFO:     Epoch: 38
2022-12-05 19:40:30,740 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4139870550822128, 'Total loss': 0.4139870550822128} | train loss {'Reaction outcome loss': 0.1704807004661333, 'Total loss': 0.1704807004661333}
2022-12-05 19:40:30,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:30,740 INFO:     Epoch: 39
2022-12-05 19:40:31,537 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4215796535665339, 'Total loss': 0.4215796535665339} | train loss {'Reaction outcome loss': 0.16947885359795803, 'Total loss': 0.16947885359795803}
2022-12-05 19:40:31,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:31,537 INFO:     Epoch: 40
2022-12-05 19:40:32,334 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4261948177590966, 'Total loss': 0.4261948177590966} | train loss {'Reaction outcome loss': 0.16657321886461124, 'Total loss': 0.16657321886461124}
2022-12-05 19:40:32,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:32,334 INFO:     Epoch: 41
2022-12-05 19:40:33,129 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4369292205030268, 'Total loss': 0.4369292205030268} | train loss {'Reaction outcome loss': 0.16383752803627386, 'Total loss': 0.16383752803627386}
2022-12-05 19:40:33,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:33,129 INFO:     Epoch: 42
2022-12-05 19:40:33,922 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4349568066271869, 'Total loss': 0.4349568066271869} | train loss {'Reaction outcome loss': 0.16057837249236068, 'Total loss': 0.16057837249236068}
2022-12-05 19:40:33,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:33,923 INFO:     Epoch: 43
2022-12-05 19:40:34,718 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41440615413541143, 'Total loss': 0.41440615413541143} | train loss {'Reaction outcome loss': 0.16415546731721714, 'Total loss': 0.16415546731721714}
2022-12-05 19:40:34,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:34,718 INFO:     Epoch: 44
2022-12-05 19:40:35,514 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4288200681859797, 'Total loss': 0.4288200681859797} | train loss {'Reaction outcome loss': 0.1606545303212969, 'Total loss': 0.1606545303212969}
2022-12-05 19:40:35,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:35,514 INFO:     Epoch: 45
2022-12-05 19:40:36,309 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42332537404515524, 'Total loss': 0.42332537404515524} | train loss {'Reaction outcome loss': 0.15934142288996986, 'Total loss': 0.15934142288996986}
2022-12-05 19:40:36,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:36,309 INFO:     Epoch: 46
2022-12-05 19:40:37,108 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4322617756710811, 'Total loss': 0.4322617756710811} | train loss {'Reaction outcome loss': 0.15825362931107462, 'Total loss': 0.15825362931107462}
2022-12-05 19:40:37,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:37,108 INFO:     Epoch: 47
2022-12-05 19:40:37,902 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43150670775635674, 'Total loss': 0.43150670775635674} | train loss {'Reaction outcome loss': 0.15751319538485184, 'Total loss': 0.15751319538485184}
2022-12-05 19:40:37,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:37,902 INFO:     Epoch: 48
2022-12-05 19:40:38,694 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.433748047798872, 'Total loss': 0.433748047798872} | train loss {'Reaction outcome loss': 0.15689044447261313, 'Total loss': 0.15689044447261313}
2022-12-05 19:40:38,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:38,695 INFO:     Epoch: 49
2022-12-05 19:40:39,487 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4302588650448756, 'Total loss': 0.4302588650448756} | train loss {'Reaction outcome loss': 0.16331149790028812, 'Total loss': 0.16331149790028812}
2022-12-05 19:40:39,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:39,488 INFO:     Epoch: 50
2022-12-05 19:40:40,281 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42672233656048775, 'Total loss': 0.42672233656048775} | train loss {'Reaction outcome loss': 0.15254719022978172, 'Total loss': 0.15254719022978172}
2022-12-05 19:40:40,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:40,281 INFO:     Epoch: 51
2022-12-05 19:40:41,074 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42547378181056544, 'Total loss': 0.42547378181056544} | train loss {'Reaction outcome loss': 0.15688622067965236, 'Total loss': 0.15688622067965236}
2022-12-05 19:40:41,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:41,074 INFO:     Epoch: 52
2022-12-05 19:40:41,866 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4394176629456607, 'Total loss': 0.4394176629456607} | train loss {'Reaction outcome loss': 0.15173615336508645, 'Total loss': 0.15173615336508645}
2022-12-05 19:40:41,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:41,866 INFO:     Epoch: 53
2022-12-05 19:40:42,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4350098733874885, 'Total loss': 0.4350098733874885} | train loss {'Reaction outcome loss': 0.1495858330716971, 'Total loss': 0.1495858330716971}
2022-12-05 19:40:42,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:42,663 INFO:     Epoch: 54
2022-12-05 19:40:43,458 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42916925420815294, 'Total loss': 0.42916925420815294} | train loss {'Reaction outcome loss': 0.1487769209119955, 'Total loss': 0.1487769209119955}
2022-12-05 19:40:43,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:43,458 INFO:     Epoch: 55
2022-12-05 19:40:44,249 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44208294932137837, 'Total loss': 0.44208294932137837} | train loss {'Reaction outcome loss': 0.14855639803928403, 'Total loss': 0.14855639803928403}
2022-12-05 19:40:44,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:44,249 INFO:     Epoch: 56
2022-12-05 19:40:45,045 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41971261850134894, 'Total loss': 0.41971261850134894} | train loss {'Reaction outcome loss': 0.14951254894225463, 'Total loss': 0.14951254894225463}
2022-12-05 19:40:45,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:45,045 INFO:     Epoch: 57
2022-12-05 19:40:45,837 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42262115769765596, 'Total loss': 0.42262115769765596} | train loss {'Reaction outcome loss': 0.1445783064644105, 'Total loss': 0.1445783064644105}
2022-12-05 19:40:45,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:45,838 INFO:     Epoch: 58
2022-12-05 19:40:46,630 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42469555071809073, 'Total loss': 0.42469555071809073} | train loss {'Reaction outcome loss': 0.14496224439186364, 'Total loss': 0.14496224439186364}
2022-12-05 19:40:46,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:46,630 INFO:     Epoch: 59
2022-12-05 19:40:47,425 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43073733015493915, 'Total loss': 0.43073733015493915} | train loss {'Reaction outcome loss': 0.14568066845840288, 'Total loss': 0.14568066845840288}
2022-12-05 19:40:47,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:47,426 INFO:     Epoch: 60
2022-12-05 19:40:48,220 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41981455886905844, 'Total loss': 0.41981455886905844} | train loss {'Reaction outcome loss': 0.14087927717949275, 'Total loss': 0.14087927717949275}
2022-12-05 19:40:48,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:48,221 INFO:     Epoch: 61
2022-12-05 19:40:49,022 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4305477806112983, 'Total loss': 0.4305477806112983} | train loss {'Reaction outcome loss': 0.14481942806871767, 'Total loss': 0.14481942806871767}
2022-12-05 19:40:49,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:49,022 INFO:     Epoch: 62
2022-12-05 19:40:49,816 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4183994948186658, 'Total loss': 0.4183994948186658} | train loss {'Reaction outcome loss': 0.14140867533752324, 'Total loss': 0.14140867533752324}
2022-12-05 19:40:49,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:49,816 INFO:     Epoch: 63
2022-12-05 19:40:50,612 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4241927196695046, 'Total loss': 0.4241927196695046} | train loss {'Reaction outcome loss': 0.13863351441701113, 'Total loss': 0.13863351441701113}
2022-12-05 19:40:50,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:50,612 INFO:     Epoch: 64
2022-12-05 19:40:51,413 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4296307224272327, 'Total loss': 0.4296307224272327} | train loss {'Reaction outcome loss': 0.13948214056841304, 'Total loss': 0.13948214056841304}
2022-12-05 19:40:51,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:51,413 INFO:     Epoch: 65
2022-12-05 19:40:52,213 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44144241681153124, 'Total loss': 0.44144241681153124} | train loss {'Reaction outcome loss': 0.13968066822149253, 'Total loss': 0.13968066822149253}
2022-12-05 19:40:52,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:52,214 INFO:     Epoch: 66
2022-12-05 19:40:53,011 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.433059748262167, 'Total loss': 0.433059748262167} | train loss {'Reaction outcome loss': 0.13971429643963995, 'Total loss': 0.13971429643963995}
2022-12-05 19:40:53,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:53,011 INFO:     Epoch: 67
2022-12-05 19:40:53,808 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44062783365899866, 'Total loss': 0.44062783365899866} | train loss {'Reaction outcome loss': 0.14425099982771888, 'Total loss': 0.14425099982771888}
2022-12-05 19:40:53,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:53,808 INFO:     Epoch: 68
2022-12-05 19:40:54,602 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4432702152566476, 'Total loss': 0.4432702152566476} | train loss {'Reaction outcome loss': 0.1395188949866454, 'Total loss': 0.1395188949866454}
2022-12-05 19:40:54,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:54,602 INFO:     Epoch: 69
2022-12-05 19:40:55,398 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41879598288373515, 'Total loss': 0.41879598288373515} | train loss {'Reaction outcome loss': 0.13757579884518253, 'Total loss': 0.13757579884518253}
2022-12-05 19:40:55,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:55,398 INFO:     Epoch: 70
2022-12-05 19:40:56,190 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4253458126702092, 'Total loss': 0.4253458126702092} | train loss {'Reaction outcome loss': 0.1373996428112209, 'Total loss': 0.1373996428112209}
2022-12-05 19:40:56,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:56,191 INFO:     Epoch: 71
2022-12-05 19:40:56,982 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4319158809428865, 'Total loss': 0.4319158809428865} | train loss {'Reaction outcome loss': 0.1393226329161812, 'Total loss': 0.1393226329161812}
2022-12-05 19:40:56,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:56,983 INFO:     Epoch: 72
2022-12-05 19:40:57,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4190064739774574, 'Total loss': 0.4190064739774574} | train loss {'Reaction outcome loss': 0.1387954740610675, 'Total loss': 0.1387954740610675}
2022-12-05 19:40:57,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:57,775 INFO:     Epoch: 73
2022-12-05 19:40:58,568 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4270364303480495, 'Total loss': 0.4270364303480495} | train loss {'Reaction outcome loss': 0.13248408308275317, 'Total loss': 0.13248408308275317}
2022-12-05 19:40:58,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:58,569 INFO:     Epoch: 74
2022-12-05 19:40:59,364 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4222053551877087, 'Total loss': 0.4222053551877087} | train loss {'Reaction outcome loss': 0.13414448430678744, 'Total loss': 0.13414448430678744}
2022-12-05 19:40:59,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:40:59,365 INFO:     Epoch: 75
2022-12-05 19:41:00,159 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4254772947593169, 'Total loss': 0.4254772947593169} | train loss {'Reaction outcome loss': 0.1321236113190504, 'Total loss': 0.1321236113190504}
2022-12-05 19:41:00,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:00,159 INFO:     Epoch: 76
2022-12-05 19:41:00,952 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41896820830350573, 'Total loss': 0.41896820830350573} | train loss {'Reaction outcome loss': 0.13260283737409453, 'Total loss': 0.13260283737409453}
2022-12-05 19:41:00,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:00,952 INFO:     Epoch: 77
2022-12-05 19:41:01,750 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4271283302117478, 'Total loss': 0.4271283302117478} | train loss {'Reaction outcome loss': 0.12862186535423706, 'Total loss': 0.12862186535423706}
2022-12-05 19:41:01,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:01,750 INFO:     Epoch: 78
2022-12-05 19:41:02,544 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42578781785612757, 'Total loss': 0.42578781785612757} | train loss {'Reaction outcome loss': 0.13251607135873333, 'Total loss': 0.13251607135873333}
2022-12-05 19:41:02,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:02,545 INFO:     Epoch: 79
2022-12-05 19:41:03,339 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4546732171015306, 'Total loss': 0.4546732171015306} | train loss {'Reaction outcome loss': 0.13125388534656662, 'Total loss': 0.13125388534656662}
2022-12-05 19:41:03,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:03,340 INFO:     Epoch: 80
2022-12-05 19:41:04,137 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43267918056385085, 'Total loss': 0.43267918056385085} | train loss {'Reaction outcome loss': 0.13127588111492955, 'Total loss': 0.13127588111492955}
2022-12-05 19:41:04,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:04,137 INFO:     Epoch: 81
2022-12-05 19:41:04,934 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4497215324504809, 'Total loss': 0.4497215324504809} | train loss {'Reaction outcome loss': 0.1320033254976637, 'Total loss': 0.1320033254976637}
2022-12-05 19:41:04,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:04,935 INFO:     Epoch: 82
2022-12-05 19:41:05,730 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4418885392898863, 'Total loss': 0.4418885392898863} | train loss {'Reaction outcome loss': 0.13140870214473863, 'Total loss': 0.13140870214473863}
2022-12-05 19:41:05,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:05,731 INFO:     Epoch: 83
2022-12-05 19:41:06,521 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4390393414280631, 'Total loss': 0.4390393414280631} | train loss {'Reaction outcome loss': 0.13015851623148691, 'Total loss': 0.13015851623148691}
2022-12-05 19:41:06,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:06,522 INFO:     Epoch: 84
2022-12-05 19:41:07,315 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.440627551891587, 'Total loss': 0.440627551891587} | train loss {'Reaction outcome loss': 0.13163415471521708, 'Total loss': 0.13163415471521708}
2022-12-05 19:41:07,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:07,315 INFO:     Epoch: 85
2022-12-05 19:41:08,109 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43260543437843973, 'Total loss': 0.43260543437843973} | train loss {'Reaction outcome loss': 0.12868765769630053, 'Total loss': 0.12868765769630053}
2022-12-05 19:41:08,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:08,109 INFO:     Epoch: 86
2022-12-05 19:41:08,902 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4276725663380189, 'Total loss': 0.4276725663380189} | train loss {'Reaction outcome loss': 0.12762159393037018, 'Total loss': 0.12762159393037018}
2022-12-05 19:41:08,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:08,903 INFO:     Epoch: 87
2022-12-05 19:41:09,696 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4421189644119956, 'Total loss': 0.4421189644119956} | train loss {'Reaction outcome loss': 0.13045035343360806, 'Total loss': 0.13045035343360806}
2022-12-05 19:41:09,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:09,696 INFO:     Epoch: 88
2022-12-05 19:41:10,490 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4327195974236185, 'Total loss': 0.4327195974236185} | train loss {'Reaction outcome loss': 0.13419575572602058, 'Total loss': 0.13419575572602058}
2022-12-05 19:41:10,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:10,490 INFO:     Epoch: 89
2022-12-05 19:41:11,286 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4361253328282725, 'Total loss': 0.4361253328282725} | train loss {'Reaction outcome loss': 0.14380659638839935, 'Total loss': 0.14380659638839935}
2022-12-05 19:41:11,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:11,286 INFO:     Epoch: 90
2022-12-05 19:41:12,085 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4361002001572739, 'Total loss': 0.4361002001572739} | train loss {'Reaction outcome loss': 0.13038548389883328, 'Total loss': 0.13038548389883328}
2022-12-05 19:41:12,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:12,085 INFO:     Epoch: 91
2022-12-05 19:41:12,879 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45196059210733935, 'Total loss': 0.45196059210733935} | train loss {'Reaction outcome loss': 0.12629991077637934, 'Total loss': 0.12629991077637934}
2022-12-05 19:41:12,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:12,879 INFO:     Epoch: 92
2022-12-05 19:41:13,674 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4300116334449161, 'Total loss': 0.4300116334449161} | train loss {'Reaction outcome loss': 0.1276863087119482, 'Total loss': 0.1276863087119482}
2022-12-05 19:41:13,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:13,675 INFO:     Epoch: 93
2022-12-05 19:41:14,466 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4144703866067258, 'Total loss': 0.4144703866067258} | train loss {'Reaction outcome loss': 0.12472865765401528, 'Total loss': 0.12472865765401528}
2022-12-05 19:41:14,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:14,466 INFO:     Epoch: 94
2022-12-05 19:41:15,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4501507825810801, 'Total loss': 0.4501507825810801} | train loss {'Reaction outcome loss': 0.12340851876929945, 'Total loss': 0.12340851876929945}
2022-12-05 19:41:15,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:15,261 INFO:     Epoch: 95
2022-12-05 19:41:16,054 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4438642778179862, 'Total loss': 0.4438642778179862} | train loss {'Reaction outcome loss': 0.1245113219537957, 'Total loss': 0.1245113219537957}
2022-12-05 19:41:16,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:16,054 INFO:     Epoch: 96
2022-12-05 19:41:16,845 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4443250098689036, 'Total loss': 0.4443250098689036} | train loss {'Reaction outcome loss': 0.12448700451997188, 'Total loss': 0.12448700451997188}
2022-12-05 19:41:16,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:16,847 INFO:     Epoch: 97
2022-12-05 19:41:17,642 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41745415329933167, 'Total loss': 0.41745415329933167} | train loss {'Reaction outcome loss': 0.12105990474975785, 'Total loss': 0.12105990474975785}
2022-12-05 19:41:17,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:17,643 INFO:     Epoch: 98
2022-12-05 19:41:18,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4339007464322177, 'Total loss': 0.4339007464322177} | train loss {'Reaction outcome loss': 0.1225209181340268, 'Total loss': 0.1225209181340268}
2022-12-05 19:41:18,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:18,439 INFO:     Epoch: 99
2022-12-05 19:41:19,232 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42198672314936464, 'Total loss': 0.42198672314936464} | train loss {'Reaction outcome loss': 0.12373272597654025, 'Total loss': 0.12373272597654025}
2022-12-05 19:41:19,232 INFO:     Best model found after epoch 32 of 100.
2022-12-05 19:41:19,232 INFO:   Done with stage: TRAINING
2022-12-05 19:41:19,232 INFO:   Starting stage: EVALUATION
2022-12-05 19:41:19,358 INFO:   Done with stage: EVALUATION
2022-12-05 19:41:19,358 INFO:   Leaving out SEQ value Fold_6
2022-12-05 19:41:19,371 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:41:19,371 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:41:20,021 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:41:20,021 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:41:20,089 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:41:20,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:41:20,089 INFO:     No hyperparam tuning for this model
2022-12-05 19:41:20,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:41:20,089 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:41:20,090 INFO:     None feature selector for col prot
2022-12-05 19:41:20,090 INFO:     None feature selector for col prot
2022-12-05 19:41:20,090 INFO:     None feature selector for col prot
2022-12-05 19:41:20,091 INFO:     None feature selector for col chem
2022-12-05 19:41:20,091 INFO:     None feature selector for col chem
2022-12-05 19:41:20,091 INFO:     None feature selector for col chem
2022-12-05 19:41:20,091 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:41:20,091 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:41:20,093 INFO:     Number of params in model 215821
2022-12-05 19:41:20,096 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:41:20,096 INFO:   Starting stage: TRAINING
2022-12-05 19:41:20,157 INFO:     Val loss before train {'Reaction outcome loss': 0.9796880659731951, 'Total loss': 0.9796880659731951}
2022-12-05 19:41:20,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:20,157 INFO:     Epoch: 0
2022-12-05 19:41:20,954 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5955456068569963, 'Total loss': 0.5955456068569963} | train loss {'Reaction outcome loss': 0.8065654220840623, 'Total loss': 0.8065654220840623}
2022-12-05 19:41:20,954 INFO:     Found new best model at epoch 0
2022-12-05 19:41:20,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:20,955 INFO:     Epoch: 1
2022-12-05 19:41:21,749 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5073646052994512, 'Total loss': 0.5073646052994512} | train loss {'Reaction outcome loss': 0.5408638439952366, 'Total loss': 0.5408638439952366}
2022-12-05 19:41:21,750 INFO:     Found new best model at epoch 1
2022-12-05 19:41:21,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:21,750 INFO:     Epoch: 2
2022-12-05 19:41:22,549 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4888915473764593, 'Total loss': 0.4888915473764593} | train loss {'Reaction outcome loss': 0.4703246311795327, 'Total loss': 0.4703246311795327}
2022-12-05 19:41:22,549 INFO:     Found new best model at epoch 2
2022-12-05 19:41:22,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:22,550 INFO:     Epoch: 3
2022-12-05 19:41:23,346 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45387348024682567, 'Total loss': 0.45387348024682567} | train loss {'Reaction outcome loss': 0.4277749122270653, 'Total loss': 0.4277749122270653}
2022-12-05 19:41:23,347 INFO:     Found new best model at epoch 3
2022-12-05 19:41:23,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:23,348 INFO:     Epoch: 4
2022-12-05 19:41:24,147 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4472239207137715, 'Total loss': 0.4472239207137715} | train loss {'Reaction outcome loss': 0.40070744892281873, 'Total loss': 0.40070744892281873}
2022-12-05 19:41:24,147 INFO:     Found new best model at epoch 4
2022-12-05 19:41:24,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:24,148 INFO:     Epoch: 5
2022-12-05 19:41:24,944 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43345713276754727, 'Total loss': 0.43345713276754727} | train loss {'Reaction outcome loss': 0.37527969593722976, 'Total loss': 0.37527969593722976}
2022-12-05 19:41:24,944 INFO:     Found new best model at epoch 5
2022-12-05 19:41:24,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:24,945 INFO:     Epoch: 6
2022-12-05 19:41:25,740 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.423880609260364, 'Total loss': 0.423880609260364} | train loss {'Reaction outcome loss': 0.3546507631939265, 'Total loss': 0.3546507631939265}
2022-12-05 19:41:25,740 INFO:     Found new best model at epoch 6
2022-12-05 19:41:25,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:25,741 INFO:     Epoch: 7
2022-12-05 19:41:26,535 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42235261100259697, 'Total loss': 0.42235261100259697} | train loss {'Reaction outcome loss': 0.3401597283420063, 'Total loss': 0.3401597283420063}
2022-12-05 19:41:26,536 INFO:     Found new best model at epoch 7
2022-12-05 19:41:26,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:26,536 INFO:     Epoch: 8
2022-12-05 19:41:27,336 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4226483665406704, 'Total loss': 0.4226483665406704} | train loss {'Reaction outcome loss': 0.3257308038732698, 'Total loss': 0.3257308038732698}
2022-12-05 19:41:27,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:27,336 INFO:     Epoch: 9
2022-12-05 19:41:28,134 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40662025355479936, 'Total loss': 0.40662025355479936} | train loss {'Reaction outcome loss': 0.311060308358602, 'Total loss': 0.311060308358602}
2022-12-05 19:41:28,134 INFO:     Found new best model at epoch 9
2022-12-05 19:41:28,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:28,135 INFO:     Epoch: 10
2022-12-05 19:41:28,934 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4120590172030709, 'Total loss': 0.4120590172030709} | train loss {'Reaction outcome loss': 0.2970661345508791, 'Total loss': 0.2970661345508791}
2022-12-05 19:41:28,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:28,934 INFO:     Epoch: 11
2022-12-05 19:41:29,736 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4017710033804178, 'Total loss': 0.4017710033804178} | train loss {'Reaction outcome loss': 0.2884407838085486, 'Total loss': 0.2884407838085486}
2022-12-05 19:41:29,736 INFO:     Found new best model at epoch 11
2022-12-05 19:41:29,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:29,737 INFO:     Epoch: 12
2022-12-05 19:41:30,532 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3985885645855557, 'Total loss': 0.3985885645855557} | train loss {'Reaction outcome loss': 0.27636116361545937, 'Total loss': 0.27636116361545937}
2022-12-05 19:41:30,532 INFO:     Found new best model at epoch 12
2022-12-05 19:41:30,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:30,533 INFO:     Epoch: 13
2022-12-05 19:41:31,333 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3997218547896905, 'Total loss': 0.3997218547896905} | train loss {'Reaction outcome loss': 0.2693919867517487, 'Total loss': 0.2693919867517487}
2022-12-05 19:41:31,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:31,333 INFO:     Epoch: 14
2022-12-05 19:41:32,132 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4124063824049451, 'Total loss': 0.4124063824049451} | train loss {'Reaction outcome loss': 0.26138414965281564, 'Total loss': 0.26138414965281564}
2022-12-05 19:41:32,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:32,132 INFO:     Epoch: 15
2022-12-05 19:41:32,930 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.400567148050124, 'Total loss': 0.400567148050124} | train loss {'Reaction outcome loss': 0.2519223730590555, 'Total loss': 0.2519223730590555}
2022-12-05 19:41:32,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:32,930 INFO:     Epoch: 16
2022-12-05 19:41:33,728 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4058410667560317, 'Total loss': 0.4058410667560317} | train loss {'Reaction outcome loss': 0.24415530021783086, 'Total loss': 0.24415530021783086}
2022-12-05 19:41:33,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:33,728 INFO:     Epoch: 17
2022-12-05 19:41:34,531 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4069701697338711, 'Total loss': 0.4069701697338711} | train loss {'Reaction outcome loss': 0.23721133968642644, 'Total loss': 0.23721133968642644}
2022-12-05 19:41:34,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:34,532 INFO:     Epoch: 18
2022-12-05 19:41:35,328 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41706737063147803, 'Total loss': 0.41706737063147803} | train loss {'Reaction outcome loss': 0.23162502027867782, 'Total loss': 0.23162502027867782}
2022-12-05 19:41:35,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:35,328 INFO:     Epoch: 19
2022-12-05 19:41:36,122 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40730312127958646, 'Total loss': 0.40730312127958646} | train loss {'Reaction outcome loss': 0.22618592218045266, 'Total loss': 0.22618592218045266}
2022-12-05 19:41:36,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:36,123 INFO:     Epoch: 20
2022-12-05 19:41:36,918 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41380568830804393, 'Total loss': 0.41380568830804393} | train loss {'Reaction outcome loss': 0.22088655432866466, 'Total loss': 0.22088655432866466}
2022-12-05 19:41:36,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:36,918 INFO:     Epoch: 21
2022-12-05 19:41:37,715 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39910252595489676, 'Total loss': 0.39910252595489676} | train loss {'Reaction outcome loss': 0.21443395337630664, 'Total loss': 0.21443395337630664}
2022-12-05 19:41:37,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:37,715 INFO:     Epoch: 22
2022-12-05 19:41:38,511 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40459374033591966, 'Total loss': 0.40459374033591966} | train loss {'Reaction outcome loss': 0.20792400474930484, 'Total loss': 0.20792400474930484}
2022-12-05 19:41:38,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:38,511 INFO:     Epoch: 23
2022-12-05 19:41:39,304 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.420037065717307, 'Total loss': 0.420037065717307} | train loss {'Reaction outcome loss': 0.20430892941752268, 'Total loss': 0.20430892941752268}
2022-12-05 19:41:39,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:39,305 INFO:     Epoch: 24
2022-12-05 19:41:40,103 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4228008679029616, 'Total loss': 0.4228008679029616} | train loss {'Reaction outcome loss': 0.19964378976052807, 'Total loss': 0.19964378976052807}
2022-12-05 19:41:40,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:40,104 INFO:     Epoch: 25
2022-12-05 19:41:40,897 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4054454087533734, 'Total loss': 0.4054454087533734} | train loss {'Reaction outcome loss': 0.199110671945457, 'Total loss': 0.199110671945457}
2022-12-05 19:41:40,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:40,898 INFO:     Epoch: 26
2022-12-05 19:41:41,692 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4220834364267913, 'Total loss': 0.4220834364267913} | train loss {'Reaction outcome loss': 0.19328777358356503, 'Total loss': 0.19328777358356503}
2022-12-05 19:41:41,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:41,692 INFO:     Epoch: 27
2022-12-05 19:41:42,490 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40230816179378465, 'Total loss': 0.40230816179378465} | train loss {'Reaction outcome loss': 0.18970066704036248, 'Total loss': 0.18970066704036248}
2022-12-05 19:41:42,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:42,491 INFO:     Epoch: 28
2022-12-05 19:41:43,290 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4161599451168017, 'Total loss': 0.4161599451168017} | train loss {'Reaction outcome loss': 0.18424254878904792, 'Total loss': 0.18424254878904792}
2022-12-05 19:41:43,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:43,290 INFO:     Epoch: 29
2022-12-05 19:41:44,085 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42895212735642085, 'Total loss': 0.42895212735642085} | train loss {'Reaction outcome loss': 0.18247090730695956, 'Total loss': 0.18247090730695956}
2022-12-05 19:41:44,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:44,086 INFO:     Epoch: 30
2022-12-05 19:41:44,881 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4154735448008234, 'Total loss': 0.4154735448008234} | train loss {'Reaction outcome loss': 0.17979288892820477, 'Total loss': 0.17979288892820477}
2022-12-05 19:41:44,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:44,881 INFO:     Epoch: 31
2022-12-05 19:41:45,675 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4256204813718796, 'Total loss': 0.4256204813718796} | train loss {'Reaction outcome loss': 0.17598810712356242, 'Total loss': 0.17598810712356242}
2022-12-05 19:41:45,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:45,676 INFO:     Epoch: 32
2022-12-05 19:41:46,477 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42375633713196625, 'Total loss': 0.42375633713196625} | train loss {'Reaction outcome loss': 0.17326925236791854, 'Total loss': 0.17326925236791854}
2022-12-05 19:41:46,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:46,477 INFO:     Epoch: 33
2022-12-05 19:41:47,273 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42447301880879834, 'Total loss': 0.42447301880879834} | train loss {'Reaction outcome loss': 0.17067154878450017, 'Total loss': 0.17067154878450017}
2022-12-05 19:41:47,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:47,274 INFO:     Epoch: 34
2022-12-05 19:41:48,069 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42619099569591606, 'Total loss': 0.42619099569591606} | train loss {'Reaction outcome loss': 0.1703915150250278, 'Total loss': 0.1703915150250278}
2022-12-05 19:41:48,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:48,071 INFO:     Epoch: 35
2022-12-05 19:41:48,867 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41429550674828614, 'Total loss': 0.41429550674828614} | train loss {'Reaction outcome loss': 0.16880864698079326, 'Total loss': 0.16880864698079326}
2022-12-05 19:41:48,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:48,867 INFO:     Epoch: 36
2022-12-05 19:41:49,662 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4159699316051873, 'Total loss': 0.4159699316051873} | train loss {'Reaction outcome loss': 0.16719620454034978, 'Total loss': 0.16719620454034978}
2022-12-05 19:41:49,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:49,662 INFO:     Epoch: 37
2022-12-05 19:41:50,464 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4227057732641697, 'Total loss': 0.4227057732641697} | train loss {'Reaction outcome loss': 0.16088594685518934, 'Total loss': 0.16088594685518934}
2022-12-05 19:41:50,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:50,464 INFO:     Epoch: 38
2022-12-05 19:41:51,259 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4449361508542841, 'Total loss': 0.4449361508542841} | train loss {'Reaction outcome loss': 0.16331063349160455, 'Total loss': 0.16331063349160455}
2022-12-05 19:41:51,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:51,260 INFO:     Epoch: 39
2022-12-05 19:41:52,060 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4312270517376336, 'Total loss': 0.4312270517376336} | train loss {'Reaction outcome loss': 0.15827594050807098, 'Total loss': 0.15827594050807098}
2022-12-05 19:41:52,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:52,060 INFO:     Epoch: 40
2022-12-05 19:41:52,854 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44138886305418884, 'Total loss': 0.44138886305418884} | train loss {'Reaction outcome loss': 0.15830727865649086, 'Total loss': 0.15830727865649086}
2022-12-05 19:41:52,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:52,854 INFO:     Epoch: 41
2022-12-05 19:41:53,653 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43223619427193294, 'Total loss': 0.43223619427193294} | train loss {'Reaction outcome loss': 0.15661429188724968, 'Total loss': 0.15661429188724968}
2022-12-05 19:41:53,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:53,653 INFO:     Epoch: 42
2022-12-05 19:41:54,448 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4307827754792842, 'Total loss': 0.4307827754792842} | train loss {'Reaction outcome loss': 0.15557848630593188, 'Total loss': 0.15557848630593188}
2022-12-05 19:41:54,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:54,449 INFO:     Epoch: 43
2022-12-05 19:41:55,244 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42751316336745565, 'Total loss': 0.42751316336745565} | train loss {'Reaction outcome loss': 0.15225072313971336, 'Total loss': 0.15225072313971336}
2022-12-05 19:41:55,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:55,244 INFO:     Epoch: 44
2022-12-05 19:41:56,042 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44862878847528587, 'Total loss': 0.44862878847528587} | train loss {'Reaction outcome loss': 0.15331513689260087, 'Total loss': 0.15331513689260087}
2022-12-05 19:41:56,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:56,042 INFO:     Epoch: 45
2022-12-05 19:41:56,836 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43008884144100273, 'Total loss': 0.43008884144100273} | train loss {'Reaction outcome loss': 0.15022852868142147, 'Total loss': 0.15022852868142147}
2022-12-05 19:41:56,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:56,837 INFO:     Epoch: 46
2022-12-05 19:41:57,631 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43397740376266564, 'Total loss': 0.43397740376266564} | train loss {'Reaction outcome loss': 0.14805539523912292, 'Total loss': 0.14805539523912292}
2022-12-05 19:41:57,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:57,631 INFO:     Epoch: 47
2022-12-05 19:41:58,425 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4227297099476511, 'Total loss': 0.4227297099476511} | train loss {'Reaction outcome loss': 0.14966248169601445, 'Total loss': 0.14966248169601445}
2022-12-05 19:41:58,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:58,426 INFO:     Epoch: 48
2022-12-05 19:41:59,222 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4313168783079494, 'Total loss': 0.4313168783079494} | train loss {'Reaction outcome loss': 0.14708933667580207, 'Total loss': 0.14708933667580207}
2022-12-05 19:41:59,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:41:59,222 INFO:     Epoch: 49
2022-12-05 19:42:00,024 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43411393531344156, 'Total loss': 0.43411393531344156} | train loss {'Reaction outcome loss': 0.14398327258024965, 'Total loss': 0.14398327258024965}
2022-12-05 19:42:00,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:00,024 INFO:     Epoch: 50
2022-12-05 19:42:00,818 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43604725667021493, 'Total loss': 0.43604725667021493} | train loss {'Reaction outcome loss': 0.144081242942071, 'Total loss': 0.144081242942071}
2022-12-05 19:42:00,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:00,819 INFO:     Epoch: 51
2022-12-05 19:42:01,608 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.439764471555298, 'Total loss': 0.439764471555298} | train loss {'Reaction outcome loss': 0.1435554516877258, 'Total loss': 0.1435554516877258}
2022-12-05 19:42:01,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:01,608 INFO:     Epoch: 52
2022-12-05 19:42:02,399 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42926679653200234, 'Total loss': 0.42926679653200234} | train loss {'Reaction outcome loss': 0.14213639189819655, 'Total loss': 0.14213639189819655}
2022-12-05 19:42:02,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:02,399 INFO:     Epoch: 53
2022-12-05 19:42:03,192 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44880332120440225, 'Total loss': 0.44880332120440225} | train loss {'Reaction outcome loss': 0.1406905317956942, 'Total loss': 0.1406905317956942}
2022-12-05 19:42:03,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:03,193 INFO:     Epoch: 54
2022-12-05 19:42:03,985 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44512014175680553, 'Total loss': 0.44512014175680553} | train loss {'Reaction outcome loss': 0.14118528163300886, 'Total loss': 0.14118528163300886}
2022-12-05 19:42:03,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:03,985 INFO:     Epoch: 55
2022-12-05 19:42:04,777 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.436712287705053, 'Total loss': 0.436712287705053} | train loss {'Reaction outcome loss': 0.14219665257710842, 'Total loss': 0.14219665257710842}
2022-12-05 19:42:04,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:04,778 INFO:     Epoch: 56
2022-12-05 19:42:05,569 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42894308269023895, 'Total loss': 0.42894308269023895} | train loss {'Reaction outcome loss': 0.1410543156427241, 'Total loss': 0.1410543156427241}
2022-12-05 19:42:05,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:05,569 INFO:     Epoch: 57
2022-12-05 19:42:06,359 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43998533622785047, 'Total loss': 0.43998533622785047} | train loss {'Reaction outcome loss': 0.14014010029214044, 'Total loss': 0.14014010029214044}
2022-12-05 19:42:06,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:06,359 INFO:     Epoch: 58
2022-12-05 19:42:07,148 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42659198628230527, 'Total loss': 0.42659198628230527} | train loss {'Reaction outcome loss': 0.13748960946536354, 'Total loss': 0.13748960946536354}
2022-12-05 19:42:07,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:07,149 INFO:     Epoch: 59
2022-12-05 19:42:07,944 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45946934446692467, 'Total loss': 0.45946934446692467} | train loss {'Reaction outcome loss': 0.13447303725256315, 'Total loss': 0.13447303725256315}
2022-12-05 19:42:07,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:07,944 INFO:     Epoch: 60
2022-12-05 19:42:08,733 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.439240059053356, 'Total loss': 0.439240059053356} | train loss {'Reaction outcome loss': 0.13555512523218508, 'Total loss': 0.13555512523218508}
2022-12-05 19:42:08,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:08,733 INFO:     Epoch: 61
2022-12-05 19:42:09,527 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43287159011445264, 'Total loss': 0.43287159011445264} | train loss {'Reaction outcome loss': 0.13625160605466413, 'Total loss': 0.13625160605466413}
2022-12-05 19:42:09,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:09,527 INFO:     Epoch: 62
2022-12-05 19:42:10,320 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43059848909350956, 'Total loss': 0.43059848909350956} | train loss {'Reaction outcome loss': 0.13423844026927387, 'Total loss': 0.13423844026927387}
2022-12-05 19:42:10,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:10,320 INFO:     Epoch: 63
2022-12-05 19:42:11,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4344126135110855, 'Total loss': 0.4344126135110855} | train loss {'Reaction outcome loss': 0.13392283814027905, 'Total loss': 0.13392283814027905}
2022-12-05 19:42:11,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:11,115 INFO:     Epoch: 64
2022-12-05 19:42:11,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44091026417233725, 'Total loss': 0.44091026417233725} | train loss {'Reaction outcome loss': 0.13469612640478917, 'Total loss': 0.13469612640478917}
2022-12-05 19:42:11,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:11,904 INFO:     Epoch: 65
2022-12-05 19:42:12,695 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44973724301565776, 'Total loss': 0.44973724301565776} | train loss {'Reaction outcome loss': 0.13322046593642764, 'Total loss': 0.13322046593642764}
2022-12-05 19:42:12,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:12,695 INFO:     Epoch: 66
2022-12-05 19:42:13,489 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44296296194873075, 'Total loss': 0.44296296194873075} | train loss {'Reaction outcome loss': 0.13237373838426486, 'Total loss': 0.13237373838426486}
2022-12-05 19:42:13,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:13,489 INFO:     Epoch: 67
2022-12-05 19:42:14,284 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4318840637464415, 'Total loss': 0.4318840637464415} | train loss {'Reaction outcome loss': 0.13453241878925193, 'Total loss': 0.13453241878925193}
2022-12-05 19:42:14,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:14,284 INFO:     Epoch: 68
2022-12-05 19:42:15,079 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44285474853082135, 'Total loss': 0.44285474853082135} | train loss {'Reaction outcome loss': 0.1284546353628919, 'Total loss': 0.1284546353628919}
2022-12-05 19:42:15,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:15,080 INFO:     Epoch: 69
2022-12-05 19:42:15,868 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43391692502932117, 'Total loss': 0.43391692502932117} | train loss {'Reaction outcome loss': 0.1336340804794623, 'Total loss': 0.1336340804794623}
2022-12-05 19:42:15,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:15,868 INFO:     Epoch: 70
2022-12-05 19:42:16,661 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43362846598029137, 'Total loss': 0.43362846598029137} | train loss {'Reaction outcome loss': 0.12839536989227898, 'Total loss': 0.12839536989227898}
2022-12-05 19:42:16,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:16,662 INFO:     Epoch: 71
2022-12-05 19:42:17,456 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44761636040427466, 'Total loss': 0.44761636040427466} | train loss {'Reaction outcome loss': 0.1287019702365562, 'Total loss': 0.1287019702365562}
2022-12-05 19:42:17,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:17,456 INFO:     Epoch: 72
2022-12-05 19:42:18,247 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4414842326871373, 'Total loss': 0.4414842326871373} | train loss {'Reaction outcome loss': 0.12997384497805708, 'Total loss': 0.12997384497805708}
2022-12-05 19:42:18,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:18,248 INFO:     Epoch: 73
2022-12-05 19:42:19,039 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4431136194616556, 'Total loss': 0.4431136194616556} | train loss {'Reaction outcome loss': 0.12880188081368443, 'Total loss': 0.12880188081368443}
2022-12-05 19:42:19,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:19,040 INFO:     Epoch: 74
2022-12-05 19:42:19,835 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43968978321010416, 'Total loss': 0.43968978321010416} | train loss {'Reaction outcome loss': 0.12844955000740987, 'Total loss': 0.12844955000740987}
2022-12-05 19:42:19,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:19,835 INFO:     Epoch: 75
2022-12-05 19:42:20,629 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4339404028247703, 'Total loss': 0.4339404028247703} | train loss {'Reaction outcome loss': 0.12823119011872838, 'Total loss': 0.12823119011872838}
2022-12-05 19:42:20,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:20,629 INFO:     Epoch: 76
2022-12-05 19:42:21,417 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4533513229001652, 'Total loss': 0.4533513229001652} | train loss {'Reaction outcome loss': 0.1263399446353076, 'Total loss': 0.1263399446353076}
2022-12-05 19:42:21,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:21,417 INFO:     Epoch: 77
2022-12-05 19:42:22,209 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43799467621879146, 'Total loss': 0.43799467621879146} | train loss {'Reaction outcome loss': 0.1270927790882847, 'Total loss': 0.1270927790882847}
2022-12-05 19:42:22,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:22,209 INFO:     Epoch: 78
2022-12-05 19:42:23,001 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42616249553181906, 'Total loss': 0.42616249553181906} | train loss {'Reaction outcome loss': 0.1272383472551742, 'Total loss': 0.1272383472551742}
2022-12-05 19:42:23,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:23,001 INFO:     Epoch: 79
2022-12-05 19:42:23,791 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.448477913710204, 'Total loss': 0.448477913710204} | train loss {'Reaction outcome loss': 0.12521183838121472, 'Total loss': 0.12521183838121472}
2022-12-05 19:42:23,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:23,792 INFO:     Epoch: 80
2022-12-05 19:42:24,581 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4369036214934154, 'Total loss': 0.4369036214934154} | train loss {'Reaction outcome loss': 0.12297328430483298, 'Total loss': 0.12297328430483298}
2022-12-05 19:42:24,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:24,581 INFO:     Epoch: 81
2022-12-05 19:42:25,370 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4319912063127214, 'Total loss': 0.4319912063127214} | train loss {'Reaction outcome loss': 0.12767440931225615, 'Total loss': 0.12767440931225615}
2022-12-05 19:42:25,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:25,371 INFO:     Epoch: 82
2022-12-05 19:42:26,159 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4479049241000956, 'Total loss': 0.4479049241000956} | train loss {'Reaction outcome loss': 0.1238190183461073, 'Total loss': 0.1238190183461073}
2022-12-05 19:42:26,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:26,160 INFO:     Epoch: 83
2022-12-05 19:42:26,949 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44616926122795453, 'Total loss': 0.44616926122795453} | train loss {'Reaction outcome loss': 0.12412566084024165, 'Total loss': 0.12412566084024165}
2022-12-05 19:42:26,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:26,949 INFO:     Epoch: 84
2022-12-05 19:42:27,738 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44727712497115135, 'Total loss': 0.44727712497115135} | train loss {'Reaction outcome loss': 0.12170724190711495, 'Total loss': 0.12170724190711495}
2022-12-05 19:42:27,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:27,738 INFO:     Epoch: 85
2022-12-05 19:42:28,527 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4404640251939947, 'Total loss': 0.4404640251939947} | train loss {'Reaction outcome loss': 0.12298739566693022, 'Total loss': 0.12298739566693022}
2022-12-05 19:42:28,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:28,528 INFO:     Epoch: 86
2022-12-05 19:42:29,316 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43319848078218376, 'Total loss': 0.43319848078218376} | train loss {'Reaction outcome loss': 0.12282701026302792, 'Total loss': 0.12282701026302792}
2022-12-05 19:42:29,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:29,316 INFO:     Epoch: 87
2022-12-05 19:42:30,108 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43989607149904425, 'Total loss': 0.43989607149904425} | train loss {'Reaction outcome loss': 0.12410197612799463, 'Total loss': 0.12410197612799463}
2022-12-05 19:42:30,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:30,108 INFO:     Epoch: 88
2022-12-05 19:42:30,901 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4474397108636119, 'Total loss': 0.4474397108636119} | train loss {'Reaction outcome loss': 0.12122357941623177, 'Total loss': 0.12122357941623177}
2022-12-05 19:42:30,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:30,901 INFO:     Epoch: 89
2022-12-05 19:42:31,693 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4297271868722005, 'Total loss': 0.4297271868722005} | train loss {'Reaction outcome loss': 0.1211802837130944, 'Total loss': 0.1211802837130944}
2022-12-05 19:42:31,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:31,693 INFO:     Epoch: 90
2022-12-05 19:42:32,484 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4360471691258929, 'Total loss': 0.4360471691258929} | train loss {'Reaction outcome loss': 0.11927275872233534, 'Total loss': 0.11927275872233534}
2022-12-05 19:42:32,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:32,484 INFO:     Epoch: 91
2022-12-05 19:42:33,276 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4358349224044518, 'Total loss': 0.4358349224044518} | train loss {'Reaction outcome loss': 0.12083450718707736, 'Total loss': 0.12083450718707736}
2022-12-05 19:42:33,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:33,276 INFO:     Epoch: 92
2022-12-05 19:42:34,076 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4356375885280696, 'Total loss': 0.4356375885280696} | train loss {'Reaction outcome loss': 0.12285101651814917, 'Total loss': 0.12285101651814917}
2022-12-05 19:42:34,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:34,076 INFO:     Epoch: 93
2022-12-05 19:42:34,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45576598901640286, 'Total loss': 0.45576598901640286} | train loss {'Reaction outcome loss': 0.12042269506116188, 'Total loss': 0.12042269506116188}
2022-12-05 19:42:34,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:34,868 INFO:     Epoch: 94
2022-12-05 19:42:35,657 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43886893174865027, 'Total loss': 0.43886893174865027} | train loss {'Reaction outcome loss': 0.11936499128839181, 'Total loss': 0.11936499128839181}
2022-12-05 19:42:35,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:35,657 INFO:     Epoch: 95
2022-12-05 19:42:36,457 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4300414899533445, 'Total loss': 0.4300414899533445} | train loss {'Reaction outcome loss': 0.12057007369284908, 'Total loss': 0.12057007369284908}
2022-12-05 19:42:36,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:36,458 INFO:     Epoch: 96
2022-12-05 19:42:37,252 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43637853454459796, 'Total loss': 0.43637853454459796} | train loss {'Reaction outcome loss': 0.11853429034066897, 'Total loss': 0.11853429034066897}
2022-12-05 19:42:37,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:37,253 INFO:     Epoch: 97
2022-12-05 19:42:38,045 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4243827252225442, 'Total loss': 0.4243827252225442} | train loss {'Reaction outcome loss': 0.11912615612644943, 'Total loss': 0.11912615612644943}
2022-12-05 19:42:38,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:38,046 INFO:     Epoch: 98
2022-12-05 19:42:38,838 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4476272108202631, 'Total loss': 0.4476272108202631} | train loss {'Reaction outcome loss': 0.11837414755380803, 'Total loss': 0.11837414755380803}
2022-12-05 19:42:38,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:38,839 INFO:     Epoch: 99
2022-12-05 19:42:39,628 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43578396839174355, 'Total loss': 0.43578396839174355} | train loss {'Reaction outcome loss': 0.11817314175348129, 'Total loss': 0.11817314175348129}
2022-12-05 19:42:39,628 INFO:     Best model found after epoch 13 of 100.
2022-12-05 19:42:39,629 INFO:   Done with stage: TRAINING
2022-12-05 19:42:39,629 INFO:   Starting stage: EVALUATION
2022-12-05 19:42:39,748 INFO:   Done with stage: EVALUATION
2022-12-05 19:42:39,748 INFO:   Leaving out SEQ value Fold_7
2022-12-05 19:42:39,761 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:42:39,761 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:42:40,406 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:42:40,406 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:42:40,474 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:42:40,474 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:42:40,474 INFO:     No hyperparam tuning for this model
2022-12-05 19:42:40,474 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:42:40,474 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:42:40,475 INFO:     None feature selector for col prot
2022-12-05 19:42:40,475 INFO:     None feature selector for col prot
2022-12-05 19:42:40,475 INFO:     None feature selector for col prot
2022-12-05 19:42:40,476 INFO:     None feature selector for col chem
2022-12-05 19:42:40,476 INFO:     None feature selector for col chem
2022-12-05 19:42:40,476 INFO:     None feature selector for col chem
2022-12-05 19:42:40,476 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:42:40,476 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:42:40,478 INFO:     Number of params in model 215821
2022-12-05 19:42:40,481 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:42:40,481 INFO:   Starting stage: TRAINING
2022-12-05 19:42:40,542 INFO:     Val loss before train {'Reaction outcome loss': 0.9953072687441652, 'Total loss': 0.9953072687441652}
2022-12-05 19:42:40,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:40,542 INFO:     Epoch: 0
2022-12-05 19:42:41,338 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6087429611520334, 'Total loss': 0.6087429611520334} | train loss {'Reaction outcome loss': 0.7842458154886, 'Total loss': 0.7842458154886}
2022-12-05 19:42:41,338 INFO:     Found new best model at epoch 0
2022-12-05 19:42:41,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:41,339 INFO:     Epoch: 1
2022-12-05 19:42:42,130 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5319578105753119, 'Total loss': 0.5319578105753119} | train loss {'Reaction outcome loss': 0.5282561112075083, 'Total loss': 0.5282561112075083}
2022-12-05 19:42:42,131 INFO:     Found new best model at epoch 1
2022-12-05 19:42:42,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:42,132 INFO:     Epoch: 2
2022-12-05 19:42:42,924 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5066319453445348, 'Total loss': 0.5066319453445348} | train loss {'Reaction outcome loss': 0.4600123080515092, 'Total loss': 0.4600123080515092}
2022-12-05 19:42:42,925 INFO:     Found new best model at epoch 2
2022-12-05 19:42:42,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:42,925 INFO:     Epoch: 3
2022-12-05 19:42:43,717 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4910867051644759, 'Total loss': 0.4910867051644759} | train loss {'Reaction outcome loss': 0.42197470396997466, 'Total loss': 0.42197470396997466}
2022-12-05 19:42:43,717 INFO:     Found new best model at epoch 3
2022-12-05 19:42:43,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:43,718 INFO:     Epoch: 4
2022-12-05 19:42:44,508 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47725769809701224, 'Total loss': 0.47725769809701224} | train loss {'Reaction outcome loss': 0.39380750609862225, 'Total loss': 0.39380750609862225}
2022-12-05 19:42:44,509 INFO:     Found new best model at epoch 4
2022-12-05 19:42:44,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:44,509 INFO:     Epoch: 5
2022-12-05 19:42:45,304 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.478233855556358, 'Total loss': 0.478233855556358} | train loss {'Reaction outcome loss': 0.3689001762578564, 'Total loss': 0.3689001762578564}
2022-12-05 19:42:45,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:45,304 INFO:     Epoch: 6
2022-12-05 19:42:46,099 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4607853171500293, 'Total loss': 0.4607853171500293} | train loss {'Reaction outcome loss': 0.35425879031179414, 'Total loss': 0.35425879031179414}
2022-12-05 19:42:46,099 INFO:     Found new best model at epoch 6
2022-12-05 19:42:46,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:46,100 INFO:     Epoch: 7
2022-12-05 19:42:46,898 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46941456774419005, 'Total loss': 0.46941456774419005} | train loss {'Reaction outcome loss': 0.3371055905496882, 'Total loss': 0.3371055905496882}
2022-12-05 19:42:46,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:46,898 INFO:     Epoch: 8
2022-12-05 19:42:47,692 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4667019102383744, 'Total loss': 0.4667019102383744} | train loss {'Reaction outcome loss': 0.3239682075537501, 'Total loss': 0.3239682075537501}
2022-12-05 19:42:47,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:47,693 INFO:     Epoch: 9
2022-12-05 19:42:48,484 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4554242068393664, 'Total loss': 0.4554242068393664} | train loss {'Reaction outcome loss': 0.304860713891685, 'Total loss': 0.304860713891685}
2022-12-05 19:42:48,484 INFO:     Found new best model at epoch 9
2022-12-05 19:42:48,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:48,485 INFO:     Epoch: 10
2022-12-05 19:42:49,279 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4580316970294172, 'Total loss': 0.4580316970294172} | train loss {'Reaction outcome loss': 0.29449036720419125, 'Total loss': 0.29449036720419125}
2022-12-05 19:42:49,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:49,279 INFO:     Epoch: 11
2022-12-05 19:42:50,072 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4573230953379111, 'Total loss': 0.4573230953379111} | train loss {'Reaction outcome loss': 0.28494993687397047, 'Total loss': 0.28494993687397047}
2022-12-05 19:42:50,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:50,073 INFO:     Epoch: 12
2022-12-05 19:42:50,867 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4506503174250776, 'Total loss': 0.4506503174250776} | train loss {'Reaction outcome loss': 0.2769623978904659, 'Total loss': 0.2769623978904659}
2022-12-05 19:42:50,867 INFO:     Found new best model at epoch 12
2022-12-05 19:42:50,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:50,868 INFO:     Epoch: 13
2022-12-05 19:42:51,669 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4619772173464298, 'Total loss': 0.4619772173464298} | train loss {'Reaction outcome loss': 0.2671666951068947, 'Total loss': 0.2671666951068947}
2022-12-05 19:42:51,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:51,669 INFO:     Epoch: 14
2022-12-05 19:42:52,458 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45930854976177216, 'Total loss': 0.45930854976177216} | train loss {'Reaction outcome loss': 0.258779052825224, 'Total loss': 0.258779052825224}
2022-12-05 19:42:52,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:52,458 INFO:     Epoch: 15
2022-12-05 19:42:53,248 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4564201764085076, 'Total loss': 0.4564201764085076} | train loss {'Reaction outcome loss': 0.24908785939577124, 'Total loss': 0.24908785939577124}
2022-12-05 19:42:53,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:53,248 INFO:     Epoch: 16
2022-12-05 19:42:54,039 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4495561705394225, 'Total loss': 0.4495561705394225} | train loss {'Reaction outcome loss': 0.23913641745645192, 'Total loss': 0.23913641745645192}
2022-12-05 19:42:54,039 INFO:     Found new best model at epoch 16
2022-12-05 19:42:54,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:54,040 INFO:     Epoch: 17
2022-12-05 19:42:54,830 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4766947322271087, 'Total loss': 0.4766947322271087} | train loss {'Reaction outcome loss': 0.23346760869026184, 'Total loss': 0.23346760869026184}
2022-12-05 19:42:54,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:54,830 INFO:     Epoch: 18
2022-12-05 19:42:55,621 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46713946624235675, 'Total loss': 0.46713946624235675} | train loss {'Reaction outcome loss': 0.2268567881246488, 'Total loss': 0.2268567881246488}
2022-12-05 19:42:55,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:55,621 INFO:     Epoch: 19
2022-12-05 19:42:56,411 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46396431394598703, 'Total loss': 0.46396431394598703} | train loss {'Reaction outcome loss': 0.2220145480316733, 'Total loss': 0.2220145480316733}
2022-12-05 19:42:56,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:56,412 INFO:     Epoch: 20
2022-12-05 19:42:57,202 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4628260377794504, 'Total loss': 0.4628260377794504} | train loss {'Reaction outcome loss': 0.21859889857531076, 'Total loss': 0.21859889857531076}
2022-12-05 19:42:57,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:57,202 INFO:     Epoch: 21
2022-12-05 19:42:57,992 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.475968811661005, 'Total loss': 0.475968811661005} | train loss {'Reaction outcome loss': 0.20941806245114533, 'Total loss': 0.20941806245114533}
2022-12-05 19:42:57,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:57,992 INFO:     Epoch: 22
2022-12-05 19:42:58,782 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4584516686472026, 'Total loss': 0.4584516686472026} | train loss {'Reaction outcome loss': 0.20777206849907676, 'Total loss': 0.20777206849907676}
2022-12-05 19:42:58,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:58,782 INFO:     Epoch: 23
2022-12-05 19:42:59,572 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4843858118084344, 'Total loss': 0.4843858118084344} | train loss {'Reaction outcome loss': 0.203000909506133, 'Total loss': 0.203000909506133}
2022-12-05 19:42:59,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:42:59,573 INFO:     Epoch: 24
2022-12-05 19:43:00,363 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4573538218709556, 'Total loss': 0.4573538218709556} | train loss {'Reaction outcome loss': 0.20016503143274494, 'Total loss': 0.20016503143274494}
2022-12-05 19:43:00,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:00,363 INFO:     Epoch: 25
2022-12-05 19:43:01,161 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46310605718330905, 'Total loss': 0.46310605718330905} | train loss {'Reaction outcome loss': 0.19692212735272704, 'Total loss': 0.19692212735272704}
2022-12-05 19:43:01,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:01,161 INFO:     Epoch: 26
2022-12-05 19:43:01,951 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4576625834134492, 'Total loss': 0.4576625834134492} | train loss {'Reaction outcome loss': 0.19223714129428468, 'Total loss': 0.19223714129428468}
2022-12-05 19:43:01,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:01,951 INFO:     Epoch: 27
2022-12-05 19:43:02,746 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47257766127586365, 'Total loss': 0.47257766127586365} | train loss {'Reaction outcome loss': 0.18709776314696477, 'Total loss': 0.18709776314696477}
2022-12-05 19:43:02,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:02,746 INFO:     Epoch: 28
2022-12-05 19:43:03,542 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4595182656564496, 'Total loss': 0.4595182656564496} | train loss {'Reaction outcome loss': 0.18597234950791444, 'Total loss': 0.18597234950791444}
2022-12-05 19:43:03,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:03,542 INFO:     Epoch: 29
2022-12-05 19:43:04,341 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4690135580233552, 'Total loss': 0.4690135580233552} | train loss {'Reaction outcome loss': 0.1824877905854655, 'Total loss': 0.1824877905854655}
2022-12-05 19:43:04,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:04,341 INFO:     Epoch: 30
2022-12-05 19:43:05,135 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4616624909368428, 'Total loss': 0.4616624909368428} | train loss {'Reaction outcome loss': 0.17986852756791538, 'Total loss': 0.17986852756791538}
2022-12-05 19:43:05,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:05,136 INFO:     Epoch: 31
2022-12-05 19:43:05,929 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48636066405610606, 'Total loss': 0.48636066405610606} | train loss {'Reaction outcome loss': 0.1778360178108297, 'Total loss': 0.1778360178108297}
2022-12-05 19:43:05,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:05,929 INFO:     Epoch: 32
2022-12-05 19:43:06,726 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4839042743498629, 'Total loss': 0.4839042743498629} | train loss {'Reaction outcome loss': 0.17545773408886406, 'Total loss': 0.17545773408886406}
2022-12-05 19:43:06,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:06,726 INFO:     Epoch: 33
2022-12-05 19:43:07,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46648356318473816, 'Total loss': 0.46648356318473816} | train loss {'Reaction outcome loss': 0.17197714309628692, 'Total loss': 0.17197714309628692}
2022-12-05 19:43:07,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:07,526 INFO:     Epoch: 34
2022-12-05 19:43:08,327 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4653157392008738, 'Total loss': 0.4653157392008738} | train loss {'Reaction outcome loss': 0.17214171956443497, 'Total loss': 0.17214171956443497}
2022-12-05 19:43:08,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:08,327 INFO:     Epoch: 35
2022-12-05 19:43:09,122 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47455059736967087, 'Total loss': 0.47455059736967087} | train loss {'Reaction outcome loss': 0.16592824221738883, 'Total loss': 0.16592824221738883}
2022-12-05 19:43:09,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:09,123 INFO:     Epoch: 36
2022-12-05 19:43:09,923 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47486873445185745, 'Total loss': 0.47486873445185745} | train loss {'Reaction outcome loss': 0.16584089416409692, 'Total loss': 0.16584089416409692}
2022-12-05 19:43:09,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:09,924 INFO:     Epoch: 37
2022-12-05 19:43:10,715 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47973827374252404, 'Total loss': 0.47973827374252404} | train loss {'Reaction outcome loss': 0.16288335194751138, 'Total loss': 0.16288335194751138}
2022-12-05 19:43:10,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:10,716 INFO:     Epoch: 38
2022-12-05 19:43:11,506 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48317294771021063, 'Total loss': 0.48317294771021063} | train loss {'Reaction outcome loss': 0.160938055186923, 'Total loss': 0.160938055186923}
2022-12-05 19:43:11,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:11,507 INFO:     Epoch: 39
2022-12-05 19:43:12,297 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47252599691802805, 'Total loss': 0.47252599691802805} | train loss {'Reaction outcome loss': 0.16200360732393398, 'Total loss': 0.16200360732393398}
2022-12-05 19:43:12,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:12,297 INFO:     Epoch: 40
2022-12-05 19:43:13,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4873725942928683, 'Total loss': 0.4873725942928683} | train loss {'Reaction outcome loss': 0.16158752784793895, 'Total loss': 0.16158752784793895}
2022-12-05 19:43:13,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:13,089 INFO:     Epoch: 41
2022-12-05 19:43:13,883 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47613862106068566, 'Total loss': 0.47613862106068566} | train loss {'Reaction outcome loss': 0.1564261017051796, 'Total loss': 0.1564261017051796}
2022-12-05 19:43:13,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:13,883 INFO:     Epoch: 42
2022-12-05 19:43:14,678 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4789901558648456, 'Total loss': 0.4789901558648456} | train loss {'Reaction outcome loss': 0.1587072142339762, 'Total loss': 0.1587072142339762}
2022-12-05 19:43:14,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:14,678 INFO:     Epoch: 43
2022-12-05 19:43:15,471 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4718755961141803, 'Total loss': 0.4718755961141803} | train loss {'Reaction outcome loss': 0.1552386297694137, 'Total loss': 0.1552386297694137}
2022-12-05 19:43:15,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:15,472 INFO:     Epoch: 44
2022-12-05 19:43:16,262 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4832791029052301, 'Total loss': 0.4832791029052301} | train loss {'Reaction outcome loss': 0.15226231152642397, 'Total loss': 0.15226231152642397}
2022-12-05 19:43:16,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:16,262 INFO:     Epoch: 45
2022-12-05 19:43:17,052 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49563163451173087, 'Total loss': 0.49563163451173087} | train loss {'Reaction outcome loss': 0.15226183691617823, 'Total loss': 0.15226183691617823}
2022-12-05 19:43:17,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:17,052 INFO:     Epoch: 46
2022-12-05 19:43:17,843 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48822110586545686, 'Total loss': 0.48822110586545686} | train loss {'Reaction outcome loss': 0.15497150420091085, 'Total loss': 0.15497150420091085}
2022-12-05 19:43:17,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:17,844 INFO:     Epoch: 47
2022-12-05 19:43:18,638 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4797110869125886, 'Total loss': 0.4797110869125886} | train loss {'Reaction outcome loss': 0.14910925423065502, 'Total loss': 0.14910925423065502}
2022-12-05 19:43:18,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:18,638 INFO:     Epoch: 48
2022-12-05 19:43:19,431 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4778573384339159, 'Total loss': 0.4778573384339159} | train loss {'Reaction outcome loss': 0.14910829944476003, 'Total loss': 0.14910829944476003}
2022-12-05 19:43:19,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:19,432 INFO:     Epoch: 49
2022-12-05 19:43:20,223 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4610881314358928, 'Total loss': 0.4610881314358928} | train loss {'Reaction outcome loss': 0.14859972894191742, 'Total loss': 0.14859972894191742}
2022-12-05 19:43:20,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:20,223 INFO:     Epoch: 50
2022-12-05 19:43:21,016 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49263812144371594, 'Total loss': 0.49263812144371594} | train loss {'Reaction outcome loss': 0.1460875609341348, 'Total loss': 0.1460875609341348}
2022-12-05 19:43:21,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:21,017 INFO:     Epoch: 51
2022-12-05 19:43:21,808 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47913656857880677, 'Total loss': 0.47913656857880677} | train loss {'Reaction outcome loss': 0.14587469245757786, 'Total loss': 0.14587469245757786}
2022-12-05 19:43:21,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:21,809 INFO:     Epoch: 52
2022-12-05 19:43:22,599 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4770925058559938, 'Total loss': 0.4770925058559938} | train loss {'Reaction outcome loss': 0.14381345767798204, 'Total loss': 0.14381345767798204}
2022-12-05 19:43:22,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:22,600 INFO:     Epoch: 53
2022-12-05 19:43:23,397 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4724360433491794, 'Total loss': 0.4724360433491794} | train loss {'Reaction outcome loss': 0.14160261537894728, 'Total loss': 0.14160261537894728}
2022-12-05 19:43:23,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:23,397 INFO:     Epoch: 54
2022-12-05 19:43:24,187 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47719348255883565, 'Total loss': 0.47719348255883565} | train loss {'Reaction outcome loss': 0.14315427012080628, 'Total loss': 0.14315427012080628}
2022-12-05 19:43:24,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:24,187 INFO:     Epoch: 55
2022-12-05 19:43:24,977 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4729278578676961, 'Total loss': 0.4729278578676961} | train loss {'Reaction outcome loss': 0.14262674527332908, 'Total loss': 0.14262674527332908}
2022-12-05 19:43:24,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:24,978 INFO:     Epoch: 56
2022-12-05 19:43:25,768 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4829149744050069, 'Total loss': 0.4829149744050069} | train loss {'Reaction outcome loss': 0.1419788030231552, 'Total loss': 0.1419788030231552}
2022-12-05 19:43:25,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:25,769 INFO:     Epoch: 57
2022-12-05 19:43:26,565 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5001735941252925, 'Total loss': 0.5001735941252925} | train loss {'Reaction outcome loss': 0.14199005686227353, 'Total loss': 0.14199005686227353}
2022-12-05 19:43:26,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:26,565 INFO:     Epoch: 58
2022-12-05 19:43:27,356 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4791153711690144, 'Total loss': 0.4791153711690144} | train loss {'Reaction outcome loss': 0.13949475568088313, 'Total loss': 0.13949475568088313}
2022-12-05 19:43:27,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:27,357 INFO:     Epoch: 59
2022-12-05 19:43:28,150 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47296475212682376, 'Total loss': 0.47296475212682376} | train loss {'Reaction outcome loss': 0.14187884098669934, 'Total loss': 0.14187884098669934}
2022-12-05 19:43:28,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:28,150 INFO:     Epoch: 60
2022-12-05 19:43:28,943 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4967367354441773, 'Total loss': 0.4967367354441773} | train loss {'Reaction outcome loss': 0.13769371634078842, 'Total loss': 0.13769371634078842}
2022-12-05 19:43:28,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:28,943 INFO:     Epoch: 61
2022-12-05 19:43:29,735 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4865766777233644, 'Total loss': 0.4865766777233644} | train loss {'Reaction outcome loss': 0.1386589249858873, 'Total loss': 0.1386589249858873}
2022-12-05 19:43:29,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:29,736 INFO:     Epoch: 62
2022-12-05 19:43:30,528 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5009963078932329, 'Total loss': 0.5009963078932329} | train loss {'Reaction outcome loss': 0.13372763238036103, 'Total loss': 0.13372763238036103}
2022-12-05 19:43:30,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:30,528 INFO:     Epoch: 63
2022-12-05 19:43:31,324 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47892309860749677, 'Total loss': 0.47892309860749677} | train loss {'Reaction outcome loss': 0.13642511603182123, 'Total loss': 0.13642511603182123}
2022-12-05 19:43:31,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:31,324 INFO:     Epoch: 64
2022-12-05 19:43:32,114 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.51709370078011, 'Total loss': 0.51709370078011} | train loss {'Reaction outcome loss': 0.13433150699993054, 'Total loss': 0.13433150699993054}
2022-12-05 19:43:32,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:32,115 INFO:     Epoch: 65
2022-12-05 19:43:32,913 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48707052963701164, 'Total loss': 0.48707052963701164} | train loss {'Reaction outcome loss': 0.13400994698637195, 'Total loss': 0.13400994698637195}
2022-12-05 19:43:32,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:32,913 INFO:     Epoch: 66
2022-12-05 19:43:33,703 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5004543946547941, 'Total loss': 0.5004543946547941} | train loss {'Reaction outcome loss': 0.13194392638040647, 'Total loss': 0.13194392638040647}
2022-12-05 19:43:33,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:33,703 INFO:     Epoch: 67
2022-12-05 19:43:34,493 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4774572676555677, 'Total loss': 0.4774572676555677} | train loss {'Reaction outcome loss': 0.13328201404862827, 'Total loss': 0.13328201404862827}
2022-12-05 19:43:34,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:34,493 INFO:     Epoch: 68
2022-12-05 19:43:35,290 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4889769486405633, 'Total loss': 0.4889769486405633} | train loss {'Reaction outcome loss': 0.13305058298752673, 'Total loss': 0.13305058298752673}
2022-12-05 19:43:35,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:35,291 INFO:     Epoch: 69
2022-12-05 19:43:36,085 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5066024220802567, 'Total loss': 0.5066024220802567} | train loss {'Reaction outcome loss': 0.13373349491326558, 'Total loss': 0.13373349491326558}
2022-12-05 19:43:36,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:36,086 INFO:     Epoch: 70
2022-12-05 19:43:36,882 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4971981065517122, 'Total loss': 0.4971981065517122} | train loss {'Reaction outcome loss': 0.13355814324196189, 'Total loss': 0.13355814324196189}
2022-12-05 19:43:36,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:36,883 INFO:     Epoch: 71
2022-12-05 19:43:37,674 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4796015687964179, 'Total loss': 0.4796015687964179} | train loss {'Reaction outcome loss': 0.13290070725094166, 'Total loss': 0.13290070725094166}
2022-12-05 19:43:37,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:37,674 INFO:     Epoch: 72
2022-12-05 19:43:38,468 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48838484016331757, 'Total loss': 0.48838484016331757} | train loss {'Reaction outcome loss': 0.13119468008047871, 'Total loss': 0.13119468008047871}
2022-12-05 19:43:38,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:38,468 INFO:     Epoch: 73
2022-12-05 19:43:39,266 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4937810298394073, 'Total loss': 0.4937810298394073} | train loss {'Reaction outcome loss': 0.13033503030366714, 'Total loss': 0.13033503030366714}
2022-12-05 19:43:39,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:39,267 INFO:     Epoch: 74
2022-12-05 19:43:40,060 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47920941798524425, 'Total loss': 0.47920941798524425} | train loss {'Reaction outcome loss': 0.12941180664910784, 'Total loss': 0.12941180664910784}
2022-12-05 19:43:40,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:40,061 INFO:     Epoch: 75
2022-12-05 19:43:40,852 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4861435480415821, 'Total loss': 0.4861435480415821} | train loss {'Reaction outcome loss': 0.13276620140494477, 'Total loss': 0.13276620140494477}
2022-12-05 19:43:40,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:40,853 INFO:     Epoch: 76
2022-12-05 19:43:41,643 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4893273785710335, 'Total loss': 0.4893273785710335} | train loss {'Reaction outcome loss': 0.13035005338550096, 'Total loss': 0.13035005338550096}
2022-12-05 19:43:41,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:41,644 INFO:     Epoch: 77
2022-12-05 19:43:42,438 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48560693419792433, 'Total loss': 0.48560693419792433} | train loss {'Reaction outcome loss': 0.1280642754000221, 'Total loss': 0.1280642754000221}
2022-12-05 19:43:42,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:42,439 INFO:     Epoch: 78
2022-12-05 19:43:43,229 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.514819433065978, 'Total loss': 0.514819433065978} | train loss {'Reaction outcome loss': 0.12755093512485824, 'Total loss': 0.12755093512485824}
2022-12-05 19:43:43,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:43,229 INFO:     Epoch: 79
2022-12-05 19:43:44,023 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4999775781550191, 'Total loss': 0.4999775781550191} | train loss {'Reaction outcome loss': 0.13245112309607887, 'Total loss': 0.13245112309607887}
2022-12-05 19:43:44,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:44,024 INFO:     Epoch: 80
2022-12-05 19:43:44,816 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4797756038606167, 'Total loss': 0.4797756038606167} | train loss {'Reaction outcome loss': 0.13037454772875795, 'Total loss': 0.13037454772875795}
2022-12-05 19:43:44,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:44,816 INFO:     Epoch: 81
2022-12-05 19:43:45,607 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4957300631160086, 'Total loss': 0.4957300631160086} | train loss {'Reaction outcome loss': 0.1276434156893482, 'Total loss': 0.1276434156893482}
2022-12-05 19:43:45,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:45,607 INFO:     Epoch: 82
2022-12-05 19:43:46,398 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49662748588757083, 'Total loss': 0.49662748588757083} | train loss {'Reaction outcome loss': 0.12925939931676933, 'Total loss': 0.12925939931676933}
2022-12-05 19:43:46,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:46,398 INFO:     Epoch: 83
2022-12-05 19:43:47,189 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.503192030232061, 'Total loss': 0.503192030232061} | train loss {'Reaction outcome loss': 0.1255918222952694, 'Total loss': 0.1255918222952694}
2022-12-05 19:43:47,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:47,189 INFO:     Epoch: 84
2022-12-05 19:43:47,979 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4751235669986768, 'Total loss': 0.4751235669986768} | train loss {'Reaction outcome loss': 0.12681029163368587, 'Total loss': 0.12681029163368587}
2022-12-05 19:43:47,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:47,979 INFO:     Epoch: 85
2022-12-05 19:43:48,768 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4838224048302932, 'Total loss': 0.4838224048302932} | train loss {'Reaction outcome loss': 0.12601583866372465, 'Total loss': 0.12601583866372465}
2022-12-05 19:43:48,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:48,768 INFO:     Epoch: 86
2022-12-05 19:43:49,561 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.482986528087746, 'Total loss': 0.482986528087746} | train loss {'Reaction outcome loss': 0.12677765290267887, 'Total loss': 0.12677765290267887}
2022-12-05 19:43:49,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:49,561 INFO:     Epoch: 87
2022-12-05 19:43:50,356 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4911038867113265, 'Total loss': 0.4911038867113265} | train loss {'Reaction outcome loss': 0.12586717480312912, 'Total loss': 0.12586717480312912}
2022-12-05 19:43:50,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:50,357 INFO:     Epoch: 88
2022-12-05 19:43:51,151 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48824708570133557, 'Total loss': 0.48824708570133557} | train loss {'Reaction outcome loss': 0.1244346457946625, 'Total loss': 0.1244346457946625}
2022-12-05 19:43:51,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:51,151 INFO:     Epoch: 89
2022-12-05 19:43:51,945 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4975261197171428, 'Total loss': 0.4975261197171428} | train loss {'Reaction outcome loss': 0.12632856150758603, 'Total loss': 0.12632856150758603}
2022-12-05 19:43:51,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:51,946 INFO:     Epoch: 90
2022-12-05 19:43:52,743 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49656006829305127, 'Total loss': 0.49656006829305127} | train loss {'Reaction outcome loss': 0.1245121915680131, 'Total loss': 0.1245121915680131}
2022-12-05 19:43:52,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:52,743 INFO:     Epoch: 91
2022-12-05 19:43:53,539 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49899838119745255, 'Total loss': 0.49899838119745255} | train loss {'Reaction outcome loss': 0.12458806146582167, 'Total loss': 0.12458806146582167}
2022-12-05 19:43:53,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:53,539 INFO:     Epoch: 92
2022-12-05 19:43:54,336 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5011765912852504, 'Total loss': 0.5011765912852504} | train loss {'Reaction outcome loss': 0.12299642317192329, 'Total loss': 0.12299642317192329}
2022-12-05 19:43:54,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:54,336 INFO:     Epoch: 93
2022-12-05 19:43:55,126 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5035630610178817, 'Total loss': 0.5035630610178817} | train loss {'Reaction outcome loss': 0.12296926206158053, 'Total loss': 0.12296926206158053}
2022-12-05 19:43:55,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:55,127 INFO:     Epoch: 94
2022-12-05 19:43:55,917 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5162784951654348, 'Total loss': 0.5162784951654348} | train loss {'Reaction outcome loss': 0.1248302812793202, 'Total loss': 0.1248302812793202}
2022-12-05 19:43:55,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:55,918 INFO:     Epoch: 95
2022-12-05 19:43:56,712 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5119555582377043, 'Total loss': 0.5119555582377043} | train loss {'Reaction outcome loss': 0.1277771957984735, 'Total loss': 0.1277771957984735}
2022-12-05 19:43:56,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:56,712 INFO:     Epoch: 96
2022-12-05 19:43:57,503 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49375406246293674, 'Total loss': 0.49375406246293674} | train loss {'Reaction outcome loss': 0.1227521683247159, 'Total loss': 0.1227521683247159}
2022-12-05 19:43:57,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:57,503 INFO:     Epoch: 97
2022-12-05 19:43:58,297 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5030298158526421, 'Total loss': 0.5030298158526421} | train loss {'Reaction outcome loss': 0.12359259854025778, 'Total loss': 0.12359259854025778}
2022-12-05 19:43:58,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:58,298 INFO:     Epoch: 98
2022-12-05 19:43:59,094 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.500506533140486, 'Total loss': 0.500506533140486} | train loss {'Reaction outcome loss': 0.12200681594831328, 'Total loss': 0.12200681594831328}
2022-12-05 19:43:59,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:43:59,094 INFO:     Epoch: 99
2022-12-05 19:43:59,886 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48052642765370285, 'Total loss': 0.48052642765370285} | train loss {'Reaction outcome loss': 0.11941584070483523, 'Total loss': 0.11941584070483523}
2022-12-05 19:43:59,887 INFO:     Best model found after epoch 17 of 100.
2022-12-05 19:43:59,887 INFO:   Done with stage: TRAINING
2022-12-05 19:43:59,887 INFO:   Starting stage: EVALUATION
2022-12-05 19:44:00,006 INFO:   Done with stage: EVALUATION
2022-12-05 19:44:00,007 INFO:   Leaving out SEQ value Fold_8
2022-12-05 19:44:00,019 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:44:00,019 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:44:00,648 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:44:00,648 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:44:00,716 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:44:00,716 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:44:00,717 INFO:     No hyperparam tuning for this model
2022-12-05 19:44:00,717 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:44:00,717 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:44:00,717 INFO:     None feature selector for col prot
2022-12-05 19:44:00,717 INFO:     None feature selector for col prot
2022-12-05 19:44:00,718 INFO:     None feature selector for col prot
2022-12-05 19:44:00,718 INFO:     None feature selector for col chem
2022-12-05 19:44:00,718 INFO:     None feature selector for col chem
2022-12-05 19:44:00,718 INFO:     None feature selector for col chem
2022-12-05 19:44:00,718 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:44:00,718 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:44:00,720 INFO:     Number of params in model 215821
2022-12-05 19:44:00,723 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:44:00,723 INFO:   Starting stage: TRAINING
2022-12-05 19:44:00,783 INFO:     Val loss before train {'Reaction outcome loss': 1.0283449237996882, 'Total loss': 1.0283449237996882}
2022-12-05 19:44:00,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:00,784 INFO:     Epoch: 0
2022-12-05 19:44:01,571 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6138373091816902, 'Total loss': 0.6138373091816902} | train loss {'Reaction outcome loss': 0.7882251110878068, 'Total loss': 0.7882251110878068}
2022-12-05 19:44:01,571 INFO:     Found new best model at epoch 0
2022-12-05 19:44:01,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:01,572 INFO:     Epoch: 1
2022-12-05 19:44:02,362 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5456108278171583, 'Total loss': 0.5456108278171583} | train loss {'Reaction outcome loss': 0.5384410814597056, 'Total loss': 0.5384410814597056}
2022-12-05 19:44:02,362 INFO:     Found new best model at epoch 1
2022-12-05 19:44:02,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:02,363 INFO:     Epoch: 2
2022-12-05 19:44:03,150 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.496168046512387, 'Total loss': 0.496168046512387} | train loss {'Reaction outcome loss': 0.4712849539301173, 'Total loss': 0.4712849539301173}
2022-12-05 19:44:03,150 INFO:     Found new best model at epoch 2
2022-12-05 19:44:03,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:03,151 INFO:     Epoch: 3
2022-12-05 19:44:03,941 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4851221733472564, 'Total loss': 0.4851221733472564} | train loss {'Reaction outcome loss': 0.4320380827675947, 'Total loss': 0.4320380827675947}
2022-12-05 19:44:03,941 INFO:     Found new best model at epoch 3
2022-12-05 19:44:03,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:03,942 INFO:     Epoch: 4
2022-12-05 19:44:04,728 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4727130715142597, 'Total loss': 0.4727130715142597} | train loss {'Reaction outcome loss': 0.40112222658719127, 'Total loss': 0.40112222658719127}
2022-12-05 19:44:04,728 INFO:     Found new best model at epoch 4
2022-12-05 19:44:04,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:04,729 INFO:     Epoch: 5
2022-12-05 19:44:05,514 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4636998979205435, 'Total loss': 0.4636998979205435} | train loss {'Reaction outcome loss': 0.379912784707691, 'Total loss': 0.379912784707691}
2022-12-05 19:44:05,514 INFO:     Found new best model at epoch 5
2022-12-05 19:44:05,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:05,515 INFO:     Epoch: 6
2022-12-05 19:44:06,301 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45011353662068193, 'Total loss': 0.45011353662068193} | train loss {'Reaction outcome loss': 0.3611382113219152, 'Total loss': 0.3611382113219152}
2022-12-05 19:44:06,301 INFO:     Found new best model at epoch 6
2022-12-05 19:44:06,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:06,302 INFO:     Epoch: 7
2022-12-05 19:44:07,090 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4445186264135621, 'Total loss': 0.4445186264135621} | train loss {'Reaction outcome loss': 0.3411718809049622, 'Total loss': 0.3411718809049622}
2022-12-05 19:44:07,090 INFO:     Found new best model at epoch 7
2022-12-05 19:44:07,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:07,091 INFO:     Epoch: 8
2022-12-05 19:44:07,877 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4496371478519656, 'Total loss': 0.4496371478519656} | train loss {'Reaction outcome loss': 0.3282057752282272, 'Total loss': 0.3282057752282272}
2022-12-05 19:44:07,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:07,878 INFO:     Epoch: 9
2022-12-05 19:44:08,668 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42651046795601194, 'Total loss': 0.42651046795601194} | train loss {'Reaction outcome loss': 0.3177838088107495, 'Total loss': 0.3177838088107495}
2022-12-05 19:44:08,668 INFO:     Found new best model at epoch 9
2022-12-05 19:44:08,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:08,669 INFO:     Epoch: 10
2022-12-05 19:44:09,457 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.425966393541206, 'Total loss': 0.425966393541206} | train loss {'Reaction outcome loss': 0.3070790321087306, 'Total loss': 0.3070790321087306}
2022-12-05 19:44:09,457 INFO:     Found new best model at epoch 10
2022-12-05 19:44:09,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:09,458 INFO:     Epoch: 11
2022-12-05 19:44:10,247 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43861870196732605, 'Total loss': 0.43861870196732605} | train loss {'Reaction outcome loss': 0.2900178855971286, 'Total loss': 0.2900178855971286}
2022-12-05 19:44:10,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:10,248 INFO:     Epoch: 12
2022-12-05 19:44:11,038 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4409375014630231, 'Total loss': 0.4409375014630231} | train loss {'Reaction outcome loss': 0.2812276478962377, 'Total loss': 0.2812276478962377}
2022-12-05 19:44:11,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:11,039 INFO:     Epoch: 13
2022-12-05 19:44:11,825 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4470554326068271, 'Total loss': 0.4470554326068271} | train loss {'Reaction outcome loss': 0.27127081753029997, 'Total loss': 0.27127081753029997}
2022-12-05 19:44:11,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:11,825 INFO:     Epoch: 14
2022-12-05 19:44:12,612 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4196489612487229, 'Total loss': 0.4196489612487229} | train loss {'Reaction outcome loss': 0.26092459302893295, 'Total loss': 0.26092459302893295}
2022-12-05 19:44:12,612 INFO:     Found new best model at epoch 14
2022-12-05 19:44:12,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:12,613 INFO:     Epoch: 15
2022-12-05 19:44:13,399 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42912171814929356, 'Total loss': 0.42912171814929356} | train loss {'Reaction outcome loss': 0.2562941304343915, 'Total loss': 0.2562941304343915}
2022-12-05 19:44:13,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:13,400 INFO:     Epoch: 16
2022-12-05 19:44:14,190 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44230975617061963, 'Total loss': 0.44230975617061963} | train loss {'Reaction outcome loss': 0.24993597749273785, 'Total loss': 0.24993597749273785}
2022-12-05 19:44:14,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:14,190 INFO:     Epoch: 17
2022-12-05 19:44:14,977 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43066428567875514, 'Total loss': 0.43066428567875514} | train loss {'Reaction outcome loss': 0.24136906541009182, 'Total loss': 0.24136906541009182}
2022-12-05 19:44:14,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:14,977 INFO:     Epoch: 18
2022-12-05 19:44:15,767 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4497802711345933, 'Total loss': 0.4497802711345933} | train loss {'Reaction outcome loss': 0.23715540670190263, 'Total loss': 0.23715540670190263}
2022-12-05 19:44:15,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:15,767 INFO:     Epoch: 19
2022-12-05 19:44:16,554 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4210663437843323, 'Total loss': 0.4210663437843323} | train loss {'Reaction outcome loss': 0.22876414119714666, 'Total loss': 0.22876414119714666}
2022-12-05 19:44:16,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:16,554 INFO:     Epoch: 20
2022-12-05 19:44:17,340 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43036905201998626, 'Total loss': 0.43036905201998626} | train loss {'Reaction outcome loss': 0.2209316608816506, 'Total loss': 0.2209316608816506}
2022-12-05 19:44:17,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:17,341 INFO:     Epoch: 21
2022-12-05 19:44:18,130 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42792720652439376, 'Total loss': 0.42792720652439376} | train loss {'Reaction outcome loss': 0.2176112175696654, 'Total loss': 0.2176112175696654}
2022-12-05 19:44:18,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:18,130 INFO:     Epoch: 22
2022-12-05 19:44:18,917 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43106385896151717, 'Total loss': 0.43106385896151717} | train loss {'Reaction outcome loss': 0.21376654872225848, 'Total loss': 0.21376654872225848}
2022-12-05 19:44:18,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:18,917 INFO:     Epoch: 23
2022-12-05 19:44:19,703 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42437680201096967, 'Total loss': 0.42437680201096967} | train loss {'Reaction outcome loss': 0.21153219597346265, 'Total loss': 0.21153219597346265}
2022-12-05 19:44:19,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:19,703 INFO:     Epoch: 24
2022-12-05 19:44:20,491 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42692772671580315, 'Total loss': 0.42692772671580315} | train loss {'Reaction outcome loss': 0.2085106209946065, 'Total loss': 0.2085106209946065}
2022-12-05 19:44:20,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:20,491 INFO:     Epoch: 25
2022-12-05 19:44:21,278 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42990808256647806, 'Total loss': 0.42990808256647806} | train loss {'Reaction outcome loss': 0.20528552230251462, 'Total loss': 0.20528552230251462}
2022-12-05 19:44:21,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:21,279 INFO:     Epoch: 26
2022-12-05 19:44:22,070 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46402344514023175, 'Total loss': 0.46402344514023175} | train loss {'Reaction outcome loss': 0.2007767068229706, 'Total loss': 0.2007767068229706}
2022-12-05 19:44:22,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:22,070 INFO:     Epoch: 27
2022-12-05 19:44:22,862 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42907821522517636, 'Total loss': 0.42907821522517636} | train loss {'Reaction outcome loss': 0.2010492072308715, 'Total loss': 0.2010492072308715}
2022-12-05 19:44:22,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:22,863 INFO:     Epoch: 28
2022-12-05 19:44:23,655 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43402666530825873, 'Total loss': 0.43402666530825873} | train loss {'Reaction outcome loss': 0.191339183930564, 'Total loss': 0.191339183930564}
2022-12-05 19:44:23,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:23,655 INFO:     Epoch: 29
2022-12-05 19:44:24,443 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4236838997087695, 'Total loss': 0.4236838997087695} | train loss {'Reaction outcome loss': 0.18783904198813534, 'Total loss': 0.18783904198813534}
2022-12-05 19:44:24,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:24,443 INFO:     Epoch: 30
2022-12-05 19:44:25,231 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43723389303142374, 'Total loss': 0.43723389303142374} | train loss {'Reaction outcome loss': 0.1916711081709215, 'Total loss': 0.1916711081709215}
2022-12-05 19:44:25,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:25,231 INFO:     Epoch: 31
2022-12-05 19:44:26,018 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4371561154045842, 'Total loss': 0.4371561154045842} | train loss {'Reaction outcome loss': 0.18777656924688382, 'Total loss': 0.18777656924688382}
2022-12-05 19:44:26,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:26,019 INFO:     Epoch: 32
2022-12-05 19:44:26,807 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43518289737403393, 'Total loss': 0.43518289737403393} | train loss {'Reaction outcome loss': 0.18460379293573048, 'Total loss': 0.18460379293573048}
2022-12-05 19:44:26,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:26,807 INFO:     Epoch: 33
2022-12-05 19:44:27,595 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4408680559559302, 'Total loss': 0.4408680559559302} | train loss {'Reaction outcome loss': 0.17772610224632598, 'Total loss': 0.17772610224632598}
2022-12-05 19:44:27,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:27,596 INFO:     Epoch: 34
2022-12-05 19:44:28,385 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4474957368590615, 'Total loss': 0.4474957368590615} | train loss {'Reaction outcome loss': 0.17723477826367023, 'Total loss': 0.17723477826367023}
2022-12-05 19:44:28,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:28,386 INFO:     Epoch: 35
2022-12-05 19:44:29,175 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44533858414400707, 'Total loss': 0.44533858414400707} | train loss {'Reaction outcome loss': 0.17345581961576997, 'Total loss': 0.17345581961576997}
2022-12-05 19:44:29,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:29,176 INFO:     Epoch: 36
2022-12-05 19:44:29,965 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44188793088224804, 'Total loss': 0.44188793088224804} | train loss {'Reaction outcome loss': 0.17551133084122228, 'Total loss': 0.17551133084122228}
2022-12-05 19:44:29,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:29,965 INFO:     Epoch: 37
2022-12-05 19:44:30,758 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4403985792940313, 'Total loss': 0.4403985792940313} | train loss {'Reaction outcome loss': 0.1711597109914791, 'Total loss': 0.1711597109914791}
2022-12-05 19:44:30,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:30,758 INFO:     Epoch: 38
2022-12-05 19:44:31,546 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4344541870734908, 'Total loss': 0.4344541870734908} | train loss {'Reaction outcome loss': 0.1686004737904861, 'Total loss': 0.1686004737904861}
2022-12-05 19:44:31,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:31,546 INFO:     Epoch: 39
2022-12-05 19:44:32,334 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44457686015150766, 'Total loss': 0.44457686015150766} | train loss {'Reaction outcome loss': 0.16951781110121653, 'Total loss': 0.16951781110121653}
2022-12-05 19:44:32,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:32,334 INFO:     Epoch: 40
2022-12-05 19:44:33,123 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4446264955807816, 'Total loss': 0.4446264955807816} | train loss {'Reaction outcome loss': 0.16788370064214655, 'Total loss': 0.16788370064214655}
2022-12-05 19:44:33,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:33,123 INFO:     Epoch: 41
2022-12-05 19:44:33,912 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45210364562543953, 'Total loss': 0.45210364562543953} | train loss {'Reaction outcome loss': 0.17183564529426185, 'Total loss': 0.17183564529426185}
2022-12-05 19:44:33,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:33,912 INFO:     Epoch: 42
2022-12-05 19:44:34,702 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45406155863946135, 'Total loss': 0.45406155863946135} | train loss {'Reaction outcome loss': 0.1684238508283368, 'Total loss': 0.1684238508283368}
2022-12-05 19:44:34,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:34,702 INFO:     Epoch: 43
2022-12-05 19:44:35,490 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4449396648190238, 'Total loss': 0.4449396648190238} | train loss {'Reaction outcome loss': 0.16533820269448374, 'Total loss': 0.16533820269448374}
2022-12-05 19:44:35,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:35,490 INFO:     Epoch: 44
2022-12-05 19:44:36,278 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.444500874558633, 'Total loss': 0.444500874558633} | train loss {'Reaction outcome loss': 0.15785884299703878, 'Total loss': 0.15785884299703878}
2022-12-05 19:44:36,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:36,278 INFO:     Epoch: 45
2022-12-05 19:44:37,067 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4443715326488018, 'Total loss': 0.4443715326488018} | train loss {'Reaction outcome loss': 0.1569826157107527, 'Total loss': 0.1569826157107527}
2022-12-05 19:44:37,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:37,067 INFO:     Epoch: 46
2022-12-05 19:44:37,854 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45466786487536, 'Total loss': 0.45466786487536} | train loss {'Reaction outcome loss': 0.15677940345893385, 'Total loss': 0.15677940345893385}
2022-12-05 19:44:37,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:37,854 INFO:     Epoch: 47
2022-12-05 19:44:38,641 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4682105981152166, 'Total loss': 0.4682105981152166} | train loss {'Reaction outcome loss': 0.15463156055523317, 'Total loss': 0.15463156055523317}
2022-12-05 19:44:38,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:38,641 INFO:     Epoch: 48
2022-12-05 19:44:39,427 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43970675935799425, 'Total loss': 0.43970675935799425} | train loss {'Reaction outcome loss': 0.15493706361153106, 'Total loss': 0.15493706361153106}
2022-12-05 19:44:39,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:39,428 INFO:     Epoch: 49
2022-12-05 19:44:40,219 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44509437239982863, 'Total loss': 0.44509437239982863} | train loss {'Reaction outcome loss': 0.15220055071569163, 'Total loss': 0.15220055071569163}
2022-12-05 19:44:40,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:40,219 INFO:     Epoch: 50
2022-12-05 19:44:41,012 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44321062144908036, 'Total loss': 0.44321062144908036} | train loss {'Reaction outcome loss': 0.15668830093041605, 'Total loss': 0.15668830093041605}
2022-12-05 19:44:41,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:41,013 INFO:     Epoch: 51
2022-12-05 19:44:41,802 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44504622945731337, 'Total loss': 0.44504622945731337} | train loss {'Reaction outcome loss': 0.1512535810084101, 'Total loss': 0.1512535810084101}
2022-12-05 19:44:41,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:41,803 INFO:     Epoch: 52
2022-12-05 19:44:42,594 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4505417147143321, 'Total loss': 0.4505417147143321} | train loss {'Reaction outcome loss': 0.14878360936696253, 'Total loss': 0.14878360936696253}
2022-12-05 19:44:42,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:42,594 INFO:     Epoch: 53
2022-12-05 19:44:43,381 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4424573164433241, 'Total loss': 0.4424573164433241} | train loss {'Reaction outcome loss': 0.15040175798669578, 'Total loss': 0.15040175798669578}
2022-12-05 19:44:43,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:43,381 INFO:     Epoch: 54
2022-12-05 19:44:44,167 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4396745176477866, 'Total loss': 0.4396745176477866} | train loss {'Reaction outcome loss': 0.1473973744175574, 'Total loss': 0.1473973744175574}
2022-12-05 19:44:44,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:44,167 INFO:     Epoch: 55
2022-12-05 19:44:44,960 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4588765481656248, 'Total loss': 0.4588765481656248} | train loss {'Reaction outcome loss': 0.14892794941608542, 'Total loss': 0.14892794941608542}
2022-12-05 19:44:44,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:44,961 INFO:     Epoch: 56
2022-12-05 19:44:45,748 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46623720905997534, 'Total loss': 0.46623720905997534} | train loss {'Reaction outcome loss': 0.1456941597631224, 'Total loss': 0.1456941597631224}
2022-12-05 19:44:45,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:45,748 INFO:     Epoch: 57
2022-12-05 19:44:46,535 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.461710395460779, 'Total loss': 0.461710395460779} | train loss {'Reaction outcome loss': 0.14431577230905474, 'Total loss': 0.14431577230905474}
2022-12-05 19:44:46,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:46,536 INFO:     Epoch: 58
2022-12-05 19:44:47,325 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4381592412563888, 'Total loss': 0.4381592412563888} | train loss {'Reaction outcome loss': 0.15064972423409162, 'Total loss': 0.15064972423409162}
2022-12-05 19:44:47,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:47,326 INFO:     Epoch: 59
2022-12-05 19:44:48,113 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4472453885457732, 'Total loss': 0.4472453885457732} | train loss {'Reaction outcome loss': 0.14191606410812993, 'Total loss': 0.14191606410812993}
2022-12-05 19:44:48,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:48,113 INFO:     Epoch: 60
2022-12-05 19:44:48,900 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46515185318209906, 'Total loss': 0.46515185318209906} | train loss {'Reaction outcome loss': 0.14162472016762503, 'Total loss': 0.14162472016762503}
2022-12-05 19:44:48,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:48,900 INFO:     Epoch: 61
2022-12-05 19:44:49,690 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4521218247034333, 'Total loss': 0.4521218247034333} | train loss {'Reaction outcome loss': 0.14364146944210837, 'Total loss': 0.14364146944210837}
2022-12-05 19:44:49,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:49,690 INFO:     Epoch: 62
2022-12-05 19:44:50,479 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4638290005651387, 'Total loss': 0.4638290005651387} | train loss {'Reaction outcome loss': 0.1396727600315895, 'Total loss': 0.1396727600315895}
2022-12-05 19:44:50,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:50,479 INFO:     Epoch: 63
2022-12-05 19:44:51,268 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4587771574204618, 'Total loss': 0.4587771574204618} | train loss {'Reaction outcome loss': 0.13885753966023323, 'Total loss': 0.13885753966023323}
2022-12-05 19:44:51,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:51,268 INFO:     Epoch: 64
2022-12-05 19:44:52,055 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4493208893320777, 'Total loss': 0.4493208893320777} | train loss {'Reaction outcome loss': 0.14402293157292462, 'Total loss': 0.14402293157292462}
2022-12-05 19:44:52,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:52,055 INFO:     Epoch: 65
2022-12-05 19:44:52,842 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4418374638665806, 'Total loss': 0.4418374638665806} | train loss {'Reaction outcome loss': 0.13912926006473994, 'Total loss': 0.13912926006473994}
2022-12-05 19:44:52,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:52,842 INFO:     Epoch: 66
2022-12-05 19:44:53,631 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44742441753094847, 'Total loss': 0.44742441753094847} | train loss {'Reaction outcome loss': 0.14203828970641502, 'Total loss': 0.14203828970641502}
2022-12-05 19:44:53,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:53,633 INFO:     Epoch: 67
2022-12-05 19:44:54,423 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44750752367756585, 'Total loss': 0.44750752367756585} | train loss {'Reaction outcome loss': 0.144779005747756, 'Total loss': 0.144779005747756}
2022-12-05 19:44:54,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:54,423 INFO:     Epoch: 68
2022-12-05 19:44:55,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45376337082548573, 'Total loss': 0.45376337082548573} | train loss {'Reaction outcome loss': 0.1389561292794552, 'Total loss': 0.1389561292794552}
2022-12-05 19:44:55,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:55,212 INFO:     Epoch: 69
2022-12-05 19:44:56,003 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4558973109180277, 'Total loss': 0.4558973109180277} | train loss {'Reaction outcome loss': 0.13637209724189964, 'Total loss': 0.13637209724189964}
2022-12-05 19:44:56,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:56,003 INFO:     Epoch: 70
2022-12-05 19:44:56,800 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45567531595853245, 'Total loss': 0.45567531595853245} | train loss {'Reaction outcome loss': 0.1351713556343848, 'Total loss': 0.1351713556343848}
2022-12-05 19:44:56,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:56,800 INFO:     Epoch: 71
2022-12-05 19:44:57,591 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4428234063088894, 'Total loss': 0.4428234063088894} | train loss {'Reaction outcome loss': 0.13617222284076186, 'Total loss': 0.13617222284076186}
2022-12-05 19:44:57,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:57,591 INFO:     Epoch: 72
2022-12-05 19:44:58,388 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4591284704140641, 'Total loss': 0.4591284704140641} | train loss {'Reaction outcome loss': 0.1366862142270031, 'Total loss': 0.1366862142270031}
2022-12-05 19:44:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:58,388 INFO:     Epoch: 73
2022-12-05 19:44:59,180 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4511749068783088, 'Total loss': 0.4511749068783088} | train loss {'Reaction outcome loss': 0.13323245795164634, 'Total loss': 0.13323245795164634}
2022-12-05 19:44:59,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:59,180 INFO:     Epoch: 74
2022-12-05 19:44:59,975 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4493827752091668, 'Total loss': 0.4493827752091668} | train loss {'Reaction outcome loss': 0.13313963910119858, 'Total loss': 0.13313963910119858}
2022-12-05 19:44:59,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:44:59,976 INFO:     Epoch: 75
2022-12-05 19:45:00,769 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45759461345997726, 'Total loss': 0.45759461345997726} | train loss {'Reaction outcome loss': 0.13162945072177934, 'Total loss': 0.13162945072177934}
2022-12-05 19:45:00,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:00,769 INFO:     Epoch: 76
2022-12-05 19:45:01,562 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4629554850133983, 'Total loss': 0.4629554850133983} | train loss {'Reaction outcome loss': 0.13583942063280988, 'Total loss': 0.13583942063280988}
2022-12-05 19:45:01,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:01,562 INFO:     Epoch: 77
2022-12-05 19:45:02,352 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4344216598705812, 'Total loss': 0.4344216598705812} | train loss {'Reaction outcome loss': 0.13497956519426121, 'Total loss': 0.13497956519426121}
2022-12-05 19:45:02,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:02,353 INFO:     Epoch: 78
2022-12-05 19:45:03,145 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4583835869350217, 'Total loss': 0.4583835869350217} | train loss {'Reaction outcome loss': 0.13550091439835454, 'Total loss': 0.13550091439835454}
2022-12-05 19:45:03,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:03,145 INFO:     Epoch: 79
2022-12-05 19:45:03,938 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4716650101948868, 'Total loss': 0.4716650101948868} | train loss {'Reaction outcome loss': 0.1319353451107738, 'Total loss': 0.1319353451107738}
2022-12-05 19:45:03,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:03,938 INFO:     Epoch: 80
2022-12-05 19:45:04,736 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4628948780962012, 'Total loss': 0.4628948780962012} | train loss {'Reaction outcome loss': 0.1308988736912246, 'Total loss': 0.1308988736912246}
2022-12-05 19:45:04,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:04,736 INFO:     Epoch: 81
2022-12-05 19:45:05,532 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44356875121593475, 'Total loss': 0.44356875121593475} | train loss {'Reaction outcome loss': 0.13041219278332977, 'Total loss': 0.13041219278332977}
2022-12-05 19:45:05,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:05,532 INFO:     Epoch: 82
2022-12-05 19:45:06,329 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43965990672057326, 'Total loss': 0.43965990672057326} | train loss {'Reaction outcome loss': 0.12776588411767956, 'Total loss': 0.12776588411767956}
2022-12-05 19:45:06,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:06,329 INFO:     Epoch: 83
2022-12-05 19:45:07,123 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45008841749619355, 'Total loss': 0.45008841749619355} | train loss {'Reaction outcome loss': 0.13061182623208775, 'Total loss': 0.13061182623208775}
2022-12-05 19:45:07,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:07,123 INFO:     Epoch: 84
2022-12-05 19:45:07,916 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44537544589151035, 'Total loss': 0.44537544589151035} | train loss {'Reaction outcome loss': 0.12755557840410997, 'Total loss': 0.12755557840410997}
2022-12-05 19:45:07,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:07,917 INFO:     Epoch: 85
2022-12-05 19:45:08,714 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.439294924790209, 'Total loss': 0.439294924790209} | train loss {'Reaction outcome loss': 0.13265137540304708, 'Total loss': 0.13265137540304708}
2022-12-05 19:45:08,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:08,714 INFO:     Epoch: 86
2022-12-05 19:45:09,511 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4597276435656981, 'Total loss': 0.4597276435656981} | train loss {'Reaction outcome loss': 0.13397344520790616, 'Total loss': 0.13397344520790616}
2022-12-05 19:45:09,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:09,511 INFO:     Epoch: 87
2022-12-05 19:45:10,306 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4463905824178999, 'Total loss': 0.4463905824178999} | train loss {'Reaction outcome loss': 0.13101817019329018, 'Total loss': 0.13101817019329018}
2022-12-05 19:45:10,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:10,306 INFO:     Epoch: 88
2022-12-05 19:45:11,102 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4392320412126454, 'Total loss': 0.4392320412126454} | train loss {'Reaction outcome loss': 0.12807970890315318, 'Total loss': 0.12807970890315318}
2022-12-05 19:45:11,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:11,103 INFO:     Epoch: 89
2022-12-05 19:45:11,901 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44496928375553, 'Total loss': 0.44496928375553} | train loss {'Reaction outcome loss': 0.13022841320670991, 'Total loss': 0.13022841320670991}
2022-12-05 19:45:11,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:11,901 INFO:     Epoch: 90
2022-12-05 19:45:12,696 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.444984312931245, 'Total loss': 0.444984312931245} | train loss {'Reaction outcome loss': 0.125400035336674, 'Total loss': 0.125400035336674}
2022-12-05 19:45:12,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:12,697 INFO:     Epoch: 91
2022-12-05 19:45:13,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4463304667310281, 'Total loss': 0.4463304667310281} | train loss {'Reaction outcome loss': 0.12744416784766593, 'Total loss': 0.12744416784766593}
2022-12-05 19:45:13,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:13,492 INFO:     Epoch: 92
2022-12-05 19:45:14,286 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4474598528309302, 'Total loss': 0.4474598528309302} | train loss {'Reaction outcome loss': 0.1249099863629019, 'Total loss': 0.1249099863629019}
2022-12-05 19:45:14,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:14,287 INFO:     Epoch: 93
2022-12-05 19:45:15,082 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45749165930531244, 'Total loss': 0.45749165930531244} | train loss {'Reaction outcome loss': 0.12455214582655111, 'Total loss': 0.12455214582655111}
2022-12-05 19:45:15,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:15,083 INFO:     Epoch: 94
2022-12-05 19:45:15,884 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4597853076728908, 'Total loss': 0.4597853076728908} | train loss {'Reaction outcome loss': 0.12207123878089568, 'Total loss': 0.12207123878089568}
2022-12-05 19:45:15,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:15,884 INFO:     Epoch: 95
2022-12-05 19:45:16,683 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4528782984072512, 'Total loss': 0.4528782984072512} | train loss {'Reaction outcome loss': 0.1271355122267476, 'Total loss': 0.1271355122267476}
2022-12-05 19:45:16,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:16,683 INFO:     Epoch: 96
2022-12-05 19:45:17,481 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.450440599667755, 'Total loss': 0.450440599667755} | train loss {'Reaction outcome loss': 0.12354050746361013, 'Total loss': 0.12354050746361013}
2022-12-05 19:45:17,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:17,481 INFO:     Epoch: 97
2022-12-05 19:45:18,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4413259608501738, 'Total loss': 0.4413259608501738} | train loss {'Reaction outcome loss': 0.12320452918079851, 'Total loss': 0.12320452918079851}
2022-12-05 19:45:18,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:18,276 INFO:     Epoch: 98
2022-12-05 19:45:19,072 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4431280532682484, 'Total loss': 0.4431280532682484} | train loss {'Reaction outcome loss': 0.12163804658134336, 'Total loss': 0.12163804658134336}
2022-12-05 19:45:19,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:19,072 INFO:     Epoch: 99
2022-12-05 19:45:19,867 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4497037760236047, 'Total loss': 0.4497037760236047} | train loss {'Reaction outcome loss': 0.12467227602445403, 'Total loss': 0.12467227602445403}
2022-12-05 19:45:19,868 INFO:     Best model found after epoch 15 of 100.
2022-12-05 19:45:19,868 INFO:   Done with stage: TRAINING
2022-12-05 19:45:19,868 INFO:   Starting stage: EVALUATION
2022-12-05 19:45:19,994 INFO:   Done with stage: EVALUATION
2022-12-05 19:45:19,994 INFO:   Leaving out SEQ value Fold_9
2022-12-05 19:45:20,007 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:45:20,007 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:45:20,643 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:45:20,643 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:45:20,711 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:45:20,711 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:45:20,711 INFO:     No hyperparam tuning for this model
2022-12-05 19:45:20,711 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:45:20,711 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:45:20,712 INFO:     None feature selector for col prot
2022-12-05 19:45:20,712 INFO:     None feature selector for col prot
2022-12-05 19:45:20,712 INFO:     None feature selector for col prot
2022-12-05 19:45:20,713 INFO:     None feature selector for col chem
2022-12-05 19:45:20,713 INFO:     None feature selector for col chem
2022-12-05 19:45:20,713 INFO:     None feature selector for col chem
2022-12-05 19:45:20,713 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:45:20,713 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:45:20,715 INFO:     Number of params in model 215821
2022-12-05 19:45:20,718 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:45:20,718 INFO:   Starting stage: TRAINING
2022-12-05 19:45:20,778 INFO:     Val loss before train {'Reaction outcome loss': 1.0188460648059845, 'Total loss': 1.0188460648059845}
2022-12-05 19:45:20,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:20,779 INFO:     Epoch: 0
2022-12-05 19:45:21,576 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5883864150805906, 'Total loss': 0.5883864150805906} | train loss {'Reaction outcome loss': 0.7935961398386187, 'Total loss': 0.7935961398386187}
2022-12-05 19:45:21,576 INFO:     Found new best model at epoch 0
2022-12-05 19:45:21,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:21,577 INFO:     Epoch: 1
2022-12-05 19:45:22,372 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5200347399169748, 'Total loss': 0.5200347399169748} | train loss {'Reaction outcome loss': 0.5480569248358088, 'Total loss': 0.5480569248358088}
2022-12-05 19:45:22,373 INFO:     Found new best model at epoch 1
2022-12-05 19:45:22,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:22,373 INFO:     Epoch: 2
2022-12-05 19:45:23,173 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48936047235673125, 'Total loss': 0.48936047235673125} | train loss {'Reaction outcome loss': 0.4806212124324614, 'Total loss': 0.4806212124324614}
2022-12-05 19:45:23,173 INFO:     Found new best model at epoch 2
2022-12-05 19:45:23,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:23,174 INFO:     Epoch: 3
2022-12-05 19:45:23,974 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46677450801838527, 'Total loss': 0.46677450801838527} | train loss {'Reaction outcome loss': 0.4363633282707944, 'Total loss': 0.4363633282707944}
2022-12-05 19:45:23,974 INFO:     Found new best model at epoch 3
2022-12-05 19:45:23,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:23,975 INFO:     Epoch: 4
2022-12-05 19:45:24,782 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44699803909117525, 'Total loss': 0.44699803909117525} | train loss {'Reaction outcome loss': 0.40326494179786215, 'Total loss': 0.40326494179786215}
2022-12-05 19:45:24,783 INFO:     Found new best model at epoch 4
2022-12-05 19:45:24,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:24,784 INFO:     Epoch: 5
2022-12-05 19:45:25,582 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43173728950999, 'Total loss': 0.43173728950999} | train loss {'Reaction outcome loss': 0.3806066154051692, 'Total loss': 0.3806066154051692}
2022-12-05 19:45:25,582 INFO:     Found new best model at epoch 5
2022-12-05 19:45:25,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:25,583 INFO:     Epoch: 6
2022-12-05 19:45:26,381 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4278220364993269, 'Total loss': 0.4278220364993269} | train loss {'Reaction outcome loss': 0.360921714484932, 'Total loss': 0.360921714484932}
2022-12-05 19:45:26,381 INFO:     Found new best model at epoch 6
2022-12-05 19:45:26,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:26,382 INFO:     Epoch: 7
2022-12-05 19:45:27,184 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4284694008529186, 'Total loss': 0.4284694008529186} | train loss {'Reaction outcome loss': 0.3430295500964407, 'Total loss': 0.3430295500964407}
2022-12-05 19:45:27,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:27,184 INFO:     Epoch: 8
2022-12-05 19:45:27,988 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4197985509579832, 'Total loss': 0.4197985509579832} | train loss {'Reaction outcome loss': 0.327370137336754, 'Total loss': 0.327370137336754}
2022-12-05 19:45:27,988 INFO:     Found new best model at epoch 8
2022-12-05 19:45:27,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:27,989 INFO:     Epoch: 9
2022-12-05 19:45:28,794 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40893125330859964, 'Total loss': 0.40893125330859964} | train loss {'Reaction outcome loss': 0.3144004725881161, 'Total loss': 0.3144004725881161}
2022-12-05 19:45:28,795 INFO:     Found new best model at epoch 9
2022-12-05 19:45:28,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:28,796 INFO:     Epoch: 10
2022-12-05 19:45:29,602 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4215195768258788, 'Total loss': 0.4215195768258788} | train loss {'Reaction outcome loss': 0.29881592689742964, 'Total loss': 0.29881592689742964}
2022-12-05 19:45:29,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:29,603 INFO:     Epoch: 11
2022-12-05 19:45:30,406 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4062898995524103, 'Total loss': 0.4062898995524103} | train loss {'Reaction outcome loss': 0.28746077382276136, 'Total loss': 0.28746077382276136}
2022-12-05 19:45:30,406 INFO:     Found new best model at epoch 11
2022-12-05 19:45:30,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:30,407 INFO:     Epoch: 12
2022-12-05 19:45:31,205 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4101645401255651, 'Total loss': 0.4101645401255651} | train loss {'Reaction outcome loss': 0.280735898883112, 'Total loss': 0.280735898883112}
2022-12-05 19:45:31,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:31,206 INFO:     Epoch: 13
2022-12-05 19:45:32,002 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40971434370360593, 'Total loss': 0.40971434370360593} | train loss {'Reaction outcome loss': 0.2693218341577918, 'Total loss': 0.2693218341577918}
2022-12-05 19:45:32,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:32,002 INFO:     Epoch: 14
2022-12-05 19:45:32,800 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41153022985566745, 'Total loss': 0.41153022985566745} | train loss {'Reaction outcome loss': 0.2549688755384376, 'Total loss': 0.2549688755384376}
2022-12-05 19:45:32,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:32,800 INFO:     Epoch: 15
2022-12-05 19:45:33,600 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.404983041300015, 'Total loss': 0.404983041300015} | train loss {'Reaction outcome loss': 0.25084683515371814, 'Total loss': 0.25084683515371814}
2022-12-05 19:45:33,600 INFO:     Found new best model at epoch 15
2022-12-05 19:45:33,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:33,601 INFO:     Epoch: 16
2022-12-05 19:45:34,401 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41114897280931473, 'Total loss': 0.41114897280931473} | train loss {'Reaction outcome loss': 0.24157631738231547, 'Total loss': 0.24157631738231547}
2022-12-05 19:45:34,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:34,401 INFO:     Epoch: 17
2022-12-05 19:45:35,202 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42216446521607315, 'Total loss': 0.42216446521607315} | train loss {'Reaction outcome loss': 0.23588867815992526, 'Total loss': 0.23588867815992526}
2022-12-05 19:45:35,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:35,202 INFO:     Epoch: 18
2022-12-05 19:45:36,006 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40606433661146596, 'Total loss': 0.40606433661146596} | train loss {'Reaction outcome loss': 0.22890593560652867, 'Total loss': 0.22890593560652867}
2022-12-05 19:45:36,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:36,006 INFO:     Epoch: 19
2022-12-05 19:45:36,817 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4066979250108654, 'Total loss': 0.4066979250108654} | train loss {'Reaction outcome loss': 0.2234336380516329, 'Total loss': 0.2234336380516329}
2022-12-05 19:45:36,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:36,817 INFO:     Epoch: 20
2022-12-05 19:45:37,620 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4162949235601859, 'Total loss': 0.4162949235601859} | train loss {'Reaction outcome loss': 0.21659812942567852, 'Total loss': 0.21659812942567852}
2022-12-05 19:45:37,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:37,620 INFO:     Epoch: 21
2022-12-05 19:45:38,425 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4116537621752782, 'Total loss': 0.4116537621752782} | train loss {'Reaction outcome loss': 0.21082721698668697, 'Total loss': 0.21082721698668697}
2022-12-05 19:45:38,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:38,426 INFO:     Epoch: 22
2022-12-05 19:45:39,230 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4195395474406806, 'Total loss': 0.4195395474406806} | train loss {'Reaction outcome loss': 0.20691686828110006, 'Total loss': 0.20691686828110006}
2022-12-05 19:45:39,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:39,230 INFO:     Epoch: 23
2022-12-05 19:45:40,038 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4169997406954115, 'Total loss': 0.4169997406954115} | train loss {'Reaction outcome loss': 0.20366166523026843, 'Total loss': 0.20366166523026843}
2022-12-05 19:45:40,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:40,038 INFO:     Epoch: 24
2022-12-05 19:45:40,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4244689301333644, 'Total loss': 0.4244689301333644} | train loss {'Reaction outcome loss': 0.20039231134127947, 'Total loss': 0.20039231134127947}
2022-12-05 19:45:40,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:40,839 INFO:     Epoch: 25
2022-12-05 19:45:41,638 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4284782087938352, 'Total loss': 0.4284782087938352} | train loss {'Reaction outcome loss': 0.1931981679893309, 'Total loss': 0.1931981679893309}
2022-12-05 19:45:41,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:41,638 INFO:     Epoch: 26
2022-12-05 19:45:42,442 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4247693666680293, 'Total loss': 0.4247693666680293} | train loss {'Reaction outcome loss': 0.18999345566055947, 'Total loss': 0.18999345566055947}
2022-12-05 19:45:42,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:42,443 INFO:     Epoch: 27
2022-12-05 19:45:43,248 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4302561574361541, 'Total loss': 0.4302561574361541} | train loss {'Reaction outcome loss': 0.18777110268391908, 'Total loss': 0.18777110268391908}
2022-12-05 19:45:43,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:43,249 INFO:     Epoch: 28
2022-12-05 19:45:44,067 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42353248392993753, 'Total loss': 0.42353248392993753} | train loss {'Reaction outcome loss': 0.18234529097624605, 'Total loss': 0.18234529097624605}
2022-12-05 19:45:44,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:44,068 INFO:     Epoch: 29
2022-12-05 19:45:44,886 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42902968773110345, 'Total loss': 0.42902968773110345} | train loss {'Reaction outcome loss': 0.18255359551779204, 'Total loss': 0.18255359551779204}
2022-12-05 19:45:44,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:44,886 INFO:     Epoch: 30
2022-12-05 19:45:45,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43486313115466724, 'Total loss': 0.43486313115466724} | train loss {'Reaction outcome loss': 0.178356553833451, 'Total loss': 0.178356553833451}
2022-12-05 19:45:45,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:45,692 INFO:     Epoch: 31
2022-12-05 19:45:46,498 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42289933968674054, 'Total loss': 0.42289933968674054} | train loss {'Reaction outcome loss': 0.17554523457863158, 'Total loss': 0.17554523457863158}
2022-12-05 19:45:46,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:46,498 INFO:     Epoch: 32
2022-12-05 19:45:47,294 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4496303246441213, 'Total loss': 0.4496303246441213} | train loss {'Reaction outcome loss': 0.17455936708457528, 'Total loss': 0.17455936708457528}
2022-12-05 19:45:47,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:47,294 INFO:     Epoch: 33
2022-12-05 19:45:48,095 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4363267480988394, 'Total loss': 0.4363267480988394} | train loss {'Reaction outcome loss': 0.16921945016140177, 'Total loss': 0.16921945016140177}
2022-12-05 19:45:48,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:48,095 INFO:     Epoch: 34
2022-12-05 19:45:48,895 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.432843483815139, 'Total loss': 0.432843483815139} | train loss {'Reaction outcome loss': 0.16825110300429044, 'Total loss': 0.16825110300429044}
2022-12-05 19:45:48,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:48,895 INFO:     Epoch: 35
2022-12-05 19:45:49,695 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4423364082520658, 'Total loss': 0.4423364082520658} | train loss {'Reaction outcome loss': 0.16481864951821346, 'Total loss': 0.16481864951821346}
2022-12-05 19:45:49,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:49,695 INFO:     Epoch: 36
2022-12-05 19:45:50,493 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4408823018046943, 'Total loss': 0.4408823018046943} | train loss {'Reaction outcome loss': 0.16373384417966008, 'Total loss': 0.16373384417966008}
2022-12-05 19:45:50,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:50,493 INFO:     Epoch: 37
2022-12-05 19:45:51,295 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4412983638996428, 'Total loss': 0.4412983638996428} | train loss {'Reaction outcome loss': 0.16198391546194832, 'Total loss': 0.16198391546194832}
2022-12-05 19:45:51,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:51,295 INFO:     Epoch: 38
2022-12-05 19:45:52,095 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44349295408888295, 'Total loss': 0.44349295408888295} | train loss {'Reaction outcome loss': 0.15863738800098579, 'Total loss': 0.15863738800098579}
2022-12-05 19:45:52,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:52,096 INFO:     Epoch: 39
2022-12-05 19:45:52,893 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4383204552260312, 'Total loss': 0.4383204552260312} | train loss {'Reaction outcome loss': 0.15646069973046262, 'Total loss': 0.15646069973046262}
2022-12-05 19:45:52,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:52,893 INFO:     Epoch: 40
2022-12-05 19:45:53,691 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4331155578521165, 'Total loss': 0.4331155578521165} | train loss {'Reaction outcome loss': 0.15503084372668977, 'Total loss': 0.15503084372668977}
2022-12-05 19:45:53,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:53,691 INFO:     Epoch: 41
2022-12-05 19:45:54,487 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44347190179608087, 'Total loss': 0.44347190179608087} | train loss {'Reaction outcome loss': 0.1553650067428187, 'Total loss': 0.1553650067428187}
2022-12-05 19:45:54,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:54,487 INFO:     Epoch: 42
2022-12-05 19:45:55,285 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4484974779188633, 'Total loss': 0.4484974779188633} | train loss {'Reaction outcome loss': 0.1539421662718298, 'Total loss': 0.1539421662718298}
2022-12-05 19:45:55,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:55,285 INFO:     Epoch: 43
2022-12-05 19:45:56,086 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4508278894830834, 'Total loss': 0.4508278894830834} | train loss {'Reaction outcome loss': 0.15016830982189747, 'Total loss': 0.15016830982189747}
2022-12-05 19:45:56,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:56,087 INFO:     Epoch: 44
2022-12-05 19:45:56,883 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43748766962777486, 'Total loss': 0.43748766962777486} | train loss {'Reaction outcome loss': 0.15151312781287538, 'Total loss': 0.15151312781287538}
2022-12-05 19:45:56,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:56,883 INFO:     Epoch: 45
2022-12-05 19:45:57,682 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45717737993056123, 'Total loss': 0.45717737993056123} | train loss {'Reaction outcome loss': 0.15000507478121547, 'Total loss': 0.15000507478121547}
2022-12-05 19:45:57,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:57,682 INFO:     Epoch: 46
2022-12-05 19:45:58,481 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44597328996116464, 'Total loss': 0.44597328996116464} | train loss {'Reaction outcome loss': 0.14764314861367306, 'Total loss': 0.14764314861367306}
2022-12-05 19:45:58,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:58,481 INFO:     Epoch: 47
2022-12-05 19:45:59,284 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44497092440724373, 'Total loss': 0.44497092440724373} | train loss {'Reaction outcome loss': 0.14772209757187915, 'Total loss': 0.14772209757187915}
2022-12-05 19:45:59,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:45:59,284 INFO:     Epoch: 48
2022-12-05 19:46:00,093 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4497493967752565, 'Total loss': 0.4497493967752565} | train loss {'Reaction outcome loss': 0.1463616912839033, 'Total loss': 0.1463616912839033}
2022-12-05 19:46:00,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:00,093 INFO:     Epoch: 49
2022-12-05 19:46:00,892 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44984440810301085, 'Total loss': 0.44984440810301085} | train loss {'Reaction outcome loss': 0.14481199269873962, 'Total loss': 0.14481199269873962}
2022-12-05 19:46:00,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:00,892 INFO:     Epoch: 50
2022-12-05 19:46:01,692 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44510009173642506, 'Total loss': 0.44510009173642506} | train loss {'Reaction outcome loss': 0.1431525788315001, 'Total loss': 0.1431525788315001}
2022-12-05 19:46:01,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:01,693 INFO:     Epoch: 51
2022-12-05 19:46:02,495 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4521712447431954, 'Total loss': 0.4521712447431954} | train loss {'Reaction outcome loss': 0.14339258346796757, 'Total loss': 0.14339258346796757}
2022-12-05 19:46:02,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:02,496 INFO:     Epoch: 52
2022-12-05 19:46:03,297 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.440570812841708, 'Total loss': 0.440570812841708} | train loss {'Reaction outcome loss': 0.1390845574168188, 'Total loss': 0.1390845574168188}
2022-12-05 19:46:03,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:03,298 INFO:     Epoch: 53
2022-12-05 19:46:04,101 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4597892314195633, 'Total loss': 0.4597892314195633} | train loss {'Reaction outcome loss': 0.14262047437800757, 'Total loss': 0.14262047437800757}
2022-12-05 19:46:04,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:04,102 INFO:     Epoch: 54
2022-12-05 19:46:04,902 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4507066221399741, 'Total loss': 0.4507066221399741} | train loss {'Reaction outcome loss': 0.141647792563984, 'Total loss': 0.141647792563984}
2022-12-05 19:46:04,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:04,902 INFO:     Epoch: 55
2022-12-05 19:46:05,702 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4437531027942896, 'Total loss': 0.4437531027942896} | train loss {'Reaction outcome loss': 0.14097221541751717, 'Total loss': 0.14097221541751717}
2022-12-05 19:46:05,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:05,703 INFO:     Epoch: 56
2022-12-05 19:46:06,502 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44843165584924544, 'Total loss': 0.44843165584924544} | train loss {'Reaction outcome loss': 0.1398633124960226, 'Total loss': 0.1398633124960226}
2022-12-05 19:46:06,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:06,502 INFO:     Epoch: 57
2022-12-05 19:46:07,301 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44140225843611086, 'Total loss': 0.44140225843611086} | train loss {'Reaction outcome loss': 0.13772792233935288, 'Total loss': 0.13772792233935288}
2022-12-05 19:46:07,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:07,302 INFO:     Epoch: 58
2022-12-05 19:46:08,106 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4449248066679998, 'Total loss': 0.4449248066679998} | train loss {'Reaction outcome loss': 0.13654047094525829, 'Total loss': 0.13654047094525829}
2022-12-05 19:46:08,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:08,106 INFO:     Epoch: 59
2022-12-05 19:46:08,912 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45553575964136556, 'Total loss': 0.45553575964136556} | train loss {'Reaction outcome loss': 0.13650867633611685, 'Total loss': 0.13650867633611685}
2022-12-05 19:46:08,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:08,912 INFO:     Epoch: 60
2022-12-05 19:46:09,716 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4509819637645375, 'Total loss': 0.4509819637645375} | train loss {'Reaction outcome loss': 0.13402563370313617, 'Total loss': 0.13402563370313617}
2022-12-05 19:46:09,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:09,717 INFO:     Epoch: 61
2022-12-05 19:46:10,518 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4393721137365157, 'Total loss': 0.4393721137365157} | train loss {'Reaction outcome loss': 0.1365087823867197, 'Total loss': 0.1365087823867197}
2022-12-05 19:46:10,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:10,518 INFO:     Epoch: 62
2022-12-05 19:46:11,317 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44389439475807274, 'Total loss': 0.44389439475807274} | train loss {'Reaction outcome loss': 0.13140792844651808, 'Total loss': 0.13140792844651808}
2022-12-05 19:46:11,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:11,317 INFO:     Epoch: 63
2022-12-05 19:46:12,116 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.460884095931595, 'Total loss': 0.460884095931595} | train loss {'Reaction outcome loss': 0.1301619720160811, 'Total loss': 0.1301619720160811}
2022-12-05 19:46:12,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:12,117 INFO:     Epoch: 64
2022-12-05 19:46:12,917 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44630647789348254, 'Total loss': 0.44630647789348254} | train loss {'Reaction outcome loss': 0.13096578315561336, 'Total loss': 0.13096578315561336}
2022-12-05 19:46:12,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:12,917 INFO:     Epoch: 65
2022-12-05 19:46:13,720 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44431934742764995, 'Total loss': 0.44431934742764995} | train loss {'Reaction outcome loss': 0.1322811546945764, 'Total loss': 0.1322811546945764}
2022-12-05 19:46:13,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:13,721 INFO:     Epoch: 66
2022-12-05 19:46:14,520 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4517859701405872, 'Total loss': 0.4517859701405872} | train loss {'Reaction outcome loss': 0.1294258389802229, 'Total loss': 0.1294258389802229}
2022-12-05 19:46:14,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:14,521 INFO:     Epoch: 67
2022-12-05 19:46:15,319 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46275997534394264, 'Total loss': 0.46275997534394264} | train loss {'Reaction outcome loss': 0.1329045612440114, 'Total loss': 0.1329045612440114}
2022-12-05 19:46:15,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:15,320 INFO:     Epoch: 68
2022-12-05 19:46:16,122 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45435576885938644, 'Total loss': 0.45435576885938644} | train loss {'Reaction outcome loss': 0.13119270050928236, 'Total loss': 0.13119270050928236}
2022-12-05 19:46:16,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:16,122 INFO:     Epoch: 69
2022-12-05 19:46:16,921 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4439778764816848, 'Total loss': 0.4439778764816848} | train loss {'Reaction outcome loss': 0.1288170612702567, 'Total loss': 0.1288170612702567}
2022-12-05 19:46:16,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:16,921 INFO:     Epoch: 70
2022-12-05 19:46:17,723 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4591347984969616, 'Total loss': 0.4591347984969616} | train loss {'Reaction outcome loss': 0.12959386177376034, 'Total loss': 0.12959386177376034}
2022-12-05 19:46:17,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:17,723 INFO:     Epoch: 71
2022-12-05 19:46:18,522 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4324976514008912, 'Total loss': 0.4324976514008912} | train loss {'Reaction outcome loss': 0.13020596178924485, 'Total loss': 0.13020596178924485}
2022-12-05 19:46:18,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:18,522 INFO:     Epoch: 72
2022-12-05 19:46:19,324 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45491360094059596, 'Total loss': 0.45491360094059596} | train loss {'Reaction outcome loss': 0.12817067050960876, 'Total loss': 0.12817067050960876}
2022-12-05 19:46:19,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:19,324 INFO:     Epoch: 73
2022-12-05 19:46:20,127 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4583129068328576, 'Total loss': 0.4583129068328576} | train loss {'Reaction outcome loss': 0.12804881693615067, 'Total loss': 0.12804881693615067}
2022-12-05 19:46:20,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:20,128 INFO:     Epoch: 74
2022-12-05 19:46:20,935 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4716333889148452, 'Total loss': 0.4716333889148452} | train loss {'Reaction outcome loss': 0.12613492225477052, 'Total loss': 0.12613492225477052}
2022-12-05 19:46:20,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:20,936 INFO:     Epoch: 75
2022-12-05 19:46:21,742 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4710417958823117, 'Total loss': 0.4710417958823117} | train loss {'Reaction outcome loss': 0.1270725089144112, 'Total loss': 0.1270725089144112}
2022-12-05 19:46:21,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:21,742 INFO:     Epoch: 76
2022-12-05 19:46:22,553 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44283474439924414, 'Total loss': 0.44283474439924414} | train loss {'Reaction outcome loss': 0.1269801775774648, 'Total loss': 0.1269801775774648}
2022-12-05 19:46:22,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:22,553 INFO:     Epoch: 77
2022-12-05 19:46:23,361 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4571295604109764, 'Total loss': 0.4571295604109764} | train loss {'Reaction outcome loss': 0.12640150718676346, 'Total loss': 0.12640150718676346}
2022-12-05 19:46:23,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:23,361 INFO:     Epoch: 78
2022-12-05 19:46:24,175 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4421157792887904, 'Total loss': 0.4421157792887904} | train loss {'Reaction outcome loss': 0.1253418226861545, 'Total loss': 0.1253418226861545}
2022-12-05 19:46:24,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:24,175 INFO:     Epoch: 79
2022-12-05 19:46:24,981 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4483998543159528, 'Total loss': 0.4483998543159528} | train loss {'Reaction outcome loss': 0.1241812550729411, 'Total loss': 0.1241812550729411}
2022-12-05 19:46:24,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:24,982 INFO:     Epoch: 80
2022-12-05 19:46:25,786 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45233348316766997, 'Total loss': 0.45233348316766997} | train loss {'Reaction outcome loss': 0.12427725817542523, 'Total loss': 0.12427725817542523}
2022-12-05 19:46:25,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:25,786 INFO:     Epoch: 81
2022-12-05 19:46:26,598 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44734074971215293, 'Total loss': 0.44734074971215293} | train loss {'Reaction outcome loss': 0.12473061031872226, 'Total loss': 0.12473061031872226}
2022-12-05 19:46:26,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:26,599 INFO:     Epoch: 82
2022-12-05 19:46:27,404 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4651837023821744, 'Total loss': 0.4651837023821744} | train loss {'Reaction outcome loss': 0.1255809413607142, 'Total loss': 0.1255809413607142}
2022-12-05 19:46:27,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:27,405 INFO:     Epoch: 83
2022-12-05 19:46:28,214 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45738296227698977, 'Total loss': 0.45738296227698977} | train loss {'Reaction outcome loss': 0.12349547195668903, 'Total loss': 0.12349547195668903}
2022-12-05 19:46:28,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:28,214 INFO:     Epoch: 84
2022-12-05 19:46:29,027 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45186528538099746, 'Total loss': 0.45186528538099746} | train loss {'Reaction outcome loss': 0.12284849198805468, 'Total loss': 0.12284849198805468}
2022-12-05 19:46:29,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:29,027 INFO:     Epoch: 85
2022-12-05 19:46:29,829 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4596357206729325, 'Total loss': 0.4596357206729325} | train loss {'Reaction outcome loss': 0.1232181043559385, 'Total loss': 0.1232181043559385}
2022-12-05 19:46:29,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:29,830 INFO:     Epoch: 86
2022-12-05 19:46:30,635 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45600295947356656, 'Total loss': 0.45600295947356656} | train loss {'Reaction outcome loss': 0.12156539766733805, 'Total loss': 0.12156539766733805}
2022-12-05 19:46:30,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:30,635 INFO:     Epoch: 87
2022-12-05 19:46:31,445 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4700501954013651, 'Total loss': 0.4700501954013651} | train loss {'Reaction outcome loss': 0.11929889478074808, 'Total loss': 0.11929889478074808}
2022-12-05 19:46:31,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:31,445 INFO:     Epoch: 88
2022-12-05 19:46:32,249 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4617608833042058, 'Total loss': 0.4617608833042058} | train loss {'Reaction outcome loss': 0.12208883866908089, 'Total loss': 0.12208883866908089}
2022-12-05 19:46:32,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:32,249 INFO:     Epoch: 89
2022-12-05 19:46:33,057 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4451868110759692, 'Total loss': 0.4451868110759692} | train loss {'Reaction outcome loss': 0.12196859262973792, 'Total loss': 0.12196859262973792}
2022-12-05 19:46:33,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:33,058 INFO:     Epoch: 90
2022-12-05 19:46:33,874 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46240913021293556, 'Total loss': 0.46240913021293556} | train loss {'Reaction outcome loss': 0.12243464211614112, 'Total loss': 0.12243464211614112}
2022-12-05 19:46:33,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:33,875 INFO:     Epoch: 91
2022-12-05 19:46:34,688 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4544188217683272, 'Total loss': 0.4544188217683272} | train loss {'Reaction outcome loss': 0.12078996145940055, 'Total loss': 0.12078996145940055}
2022-12-05 19:46:34,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:34,688 INFO:     Epoch: 92
2022-12-05 19:46:35,498 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4506441388617862, 'Total loss': 0.4506441388617862} | train loss {'Reaction outcome loss': 0.12260789322035928, 'Total loss': 0.12260789322035928}
2022-12-05 19:46:35,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:35,499 INFO:     Epoch: 93
2022-12-05 19:46:36,307 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4613121377134865, 'Total loss': 0.4613121377134865} | train loss {'Reaction outcome loss': 0.11811491452352775, 'Total loss': 0.11811491452352775}
2022-12-05 19:46:36,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:36,307 INFO:     Epoch: 94
2022-12-05 19:46:37,124 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45132879811254417, 'Total loss': 0.45132879811254417} | train loss {'Reaction outcome loss': 0.11930615156175449, 'Total loss': 0.11930615156175449}
2022-12-05 19:46:37,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:37,124 INFO:     Epoch: 95
2022-12-05 19:46:37,944 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45707149702039634, 'Total loss': 0.45707149702039634} | train loss {'Reaction outcome loss': 0.11754606993523456, 'Total loss': 0.11754606993523456}
2022-12-05 19:46:37,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:37,945 INFO:     Epoch: 96
2022-12-05 19:46:38,754 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45695160634138365, 'Total loss': 0.45695160634138365} | train loss {'Reaction outcome loss': 0.12002428913969666, 'Total loss': 0.12002428913969666}
2022-12-05 19:46:38,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:38,754 INFO:     Epoch: 97
2022-12-05 19:46:39,564 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4520968334241347, 'Total loss': 0.4520968334241347} | train loss {'Reaction outcome loss': 0.12092841627647079, 'Total loss': 0.12092841627647079}
2022-12-05 19:46:39,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:39,564 INFO:     Epoch: 98
2022-12-05 19:46:40,376 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.458228177306327, 'Total loss': 0.458228177306327} | train loss {'Reaction outcome loss': 0.11853890004192269, 'Total loss': 0.11853890004192269}
2022-12-05 19:46:40,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:40,376 INFO:     Epoch: 99
2022-12-05 19:46:41,181 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45406611500815913, 'Total loss': 0.45406611500815913} | train loss {'Reaction outcome loss': 0.11790569906964177, 'Total loss': 0.11790569906964177}
2022-12-05 19:46:41,181 INFO:     Best model found after epoch 16 of 100.
2022-12-05 19:46:41,181 INFO:   Done with stage: TRAINING
2022-12-05 19:46:41,181 INFO:   Starting stage: EVALUATION
2022-12-05 19:46:41,302 INFO:   Done with stage: EVALUATION
2022-12-05 19:46:41,310 INFO:   Leaving out SEQ value Fold_0
2022-12-05 19:46:41,323 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:46:41,323 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:46:41,965 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:46:41,965 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:46:42,033 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:46:42,034 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:46:42,034 INFO:     No hyperparam tuning for this model
2022-12-05 19:46:42,034 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:46:42,034 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:46:42,035 INFO:     None feature selector for col prot
2022-12-05 19:46:42,035 INFO:     None feature selector for col prot
2022-12-05 19:46:42,035 INFO:     None feature selector for col prot
2022-12-05 19:46:42,035 INFO:     None feature selector for col chem
2022-12-05 19:46:42,035 INFO:     None feature selector for col chem
2022-12-05 19:46:42,035 INFO:     None feature selector for col chem
2022-12-05 19:46:42,036 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:46:42,036 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:46:42,037 INFO:     Number of params in model 215821
2022-12-05 19:46:42,040 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:46:42,041 INFO:   Starting stage: TRAINING
2022-12-05 19:46:42,102 INFO:     Val loss before train {'Reaction outcome loss': 0.9767479422417554, 'Total loss': 0.9767479422417554}
2022-12-05 19:46:42,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:42,102 INFO:     Epoch: 0
2022-12-05 19:46:42,900 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5970383977348154, 'Total loss': 0.5970383977348154} | train loss {'Reaction outcome loss': 0.8001948685062175, 'Total loss': 0.8001948685062175}
2022-12-05 19:46:42,900 INFO:     Found new best model at epoch 0
2022-12-05 19:46:42,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:42,901 INFO:     Epoch: 1
2022-12-05 19:46:43,696 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4919114275412126, 'Total loss': 0.4919114275412126} | train loss {'Reaction outcome loss': 0.5375244431349696, 'Total loss': 0.5375244431349696}
2022-12-05 19:46:43,696 INFO:     Found new best model at epoch 1
2022-12-05 19:46:43,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:43,697 INFO:     Epoch: 2
2022-12-05 19:46:44,490 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45862745425917884, 'Total loss': 0.45862745425917884} | train loss {'Reaction outcome loss': 0.46266230831340865, 'Total loss': 0.46266230831340865}
2022-12-05 19:46:44,490 INFO:     Found new best model at epoch 2
2022-12-05 19:46:44,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:44,491 INFO:     Epoch: 3
2022-12-05 19:46:45,282 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4364925677126104, 'Total loss': 0.4364925677126104} | train loss {'Reaction outcome loss': 0.42237878901009657, 'Total loss': 0.42237878901009657}
2022-12-05 19:46:45,282 INFO:     Found new best model at epoch 3
2022-12-05 19:46:45,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:45,283 INFO:     Epoch: 4
2022-12-05 19:46:46,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4394268644126979, 'Total loss': 0.4394268644126979} | train loss {'Reaction outcome loss': 0.3939532750115103, 'Total loss': 0.3939532750115103}
2022-12-05 19:46:46,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:46,076 INFO:     Epoch: 5
2022-12-05 19:46:46,878 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41806282238526776, 'Total loss': 0.41806282238526776} | train loss {'Reaction outcome loss': 0.368915348819324, 'Total loss': 0.368915348819324}
2022-12-05 19:46:46,878 INFO:     Found new best model at epoch 5
2022-12-05 19:46:46,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:46,879 INFO:     Epoch: 6
2022-12-05 19:46:47,678 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40918210250410164, 'Total loss': 0.40918210250410164} | train loss {'Reaction outcome loss': 0.35064350688944057, 'Total loss': 0.35064350688944057}
2022-12-05 19:46:47,678 INFO:     Found new best model at epoch 6
2022-12-05 19:46:47,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:47,679 INFO:     Epoch: 7
2022-12-05 19:46:48,474 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4082926836880771, 'Total loss': 0.4082926836880771} | train loss {'Reaction outcome loss': 0.3365867008360065, 'Total loss': 0.3365867008360065}
2022-12-05 19:46:48,474 INFO:     Found new best model at epoch 7
2022-12-05 19:46:48,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:48,475 INFO:     Epoch: 8
2022-12-05 19:46:49,267 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3990895064039664, 'Total loss': 0.3990895064039664} | train loss {'Reaction outcome loss': 0.320080365362216, 'Total loss': 0.320080365362216}
2022-12-05 19:46:49,267 INFO:     Found new best model at epoch 8
2022-12-05 19:46:49,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:49,268 INFO:     Epoch: 9
2022-12-05 19:46:50,061 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40343236787752673, 'Total loss': 0.40343236787752673} | train loss {'Reaction outcome loss': 0.30640229458103374, 'Total loss': 0.30640229458103374}
2022-12-05 19:46:50,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:50,061 INFO:     Epoch: 10
2022-12-05 19:46:50,853 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4014297757636417, 'Total loss': 0.4014297757636417} | train loss {'Reaction outcome loss': 0.29095815088675947, 'Total loss': 0.29095815088675947}
2022-12-05 19:46:50,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:50,853 INFO:     Epoch: 11
2022-12-05 19:46:51,646 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39493448727510194, 'Total loss': 0.39493448727510194} | train loss {'Reaction outcome loss': 0.2809238331050289, 'Total loss': 0.2809238331050289}
2022-12-05 19:46:51,646 INFO:     Found new best model at epoch 11
2022-12-05 19:46:51,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:51,647 INFO:     Epoch: 12
2022-12-05 19:46:52,443 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39027240533720364, 'Total loss': 0.39027240533720364} | train loss {'Reaction outcome loss': 0.2729001666210136, 'Total loss': 0.2729001666210136}
2022-12-05 19:46:52,443 INFO:     Found new best model at epoch 12
2022-12-05 19:46:52,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:52,444 INFO:     Epoch: 13
2022-12-05 19:46:53,236 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3882357014173811, 'Total loss': 0.3882357014173811} | train loss {'Reaction outcome loss': 0.26125212758779526, 'Total loss': 0.26125212758779526}
2022-12-05 19:46:53,236 INFO:     Found new best model at epoch 13
2022-12-05 19:46:53,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:53,237 INFO:     Epoch: 14
2022-12-05 19:46:54,034 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3764386305754835, 'Total loss': 0.3764386305754835} | train loss {'Reaction outcome loss': 0.25389810654581807, 'Total loss': 0.25389810654581807}
2022-12-05 19:46:54,035 INFO:     Found new best model at epoch 14
2022-12-05 19:46:54,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:54,035 INFO:     Epoch: 15
2022-12-05 19:46:54,828 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.36589202023407613, 'Total loss': 0.36589202023407613} | train loss {'Reaction outcome loss': 0.2441300818658605, 'Total loss': 0.2441300818658605}
2022-12-05 19:46:54,829 INFO:     Found new best model at epoch 15
2022-12-05 19:46:54,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:54,829 INFO:     Epoch: 16
2022-12-05 19:46:55,626 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38091967813670635, 'Total loss': 0.38091967813670635} | train loss {'Reaction outcome loss': 0.23996068657356864, 'Total loss': 0.23996068657356864}
2022-12-05 19:46:55,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:55,627 INFO:     Epoch: 17
2022-12-05 19:46:56,418 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3833077206191691, 'Total loss': 0.3833077206191691} | train loss {'Reaction outcome loss': 0.23253767657644894, 'Total loss': 0.23253767657644894}
2022-12-05 19:46:56,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:56,418 INFO:     Epoch: 18
2022-12-05 19:46:57,210 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4040246003053405, 'Total loss': 0.4040246003053405} | train loss {'Reaction outcome loss': 0.22343308664098077, 'Total loss': 0.22343308664098077}
2022-12-05 19:46:57,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:57,210 INFO:     Epoch: 19
2022-12-05 19:46:58,003 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.385648347098719, 'Total loss': 0.385648347098719} | train loss {'Reaction outcome loss': 0.2200854878416475, 'Total loss': 0.2200854878416475}
2022-12-05 19:46:58,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:58,004 INFO:     Epoch: 20
2022-12-05 19:46:58,801 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3779920871284875, 'Total loss': 0.3779920871284875} | train loss {'Reaction outcome loss': 0.2148680735759589, 'Total loss': 0.2148680735759589}
2022-12-05 19:46:58,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:58,801 INFO:     Epoch: 21
2022-12-05 19:46:59,594 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3786869954148477, 'Total loss': 0.3786869954148477} | train loss {'Reaction outcome loss': 0.2082577402342339, 'Total loss': 0.2082577402342339}
2022-12-05 19:46:59,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:46:59,594 INFO:     Epoch: 22
2022-12-05 19:47:00,389 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3846306543458592, 'Total loss': 0.3846306543458592} | train loss {'Reaction outcome loss': 0.2035022323685033, 'Total loss': 0.2035022323685033}
2022-12-05 19:47:00,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:00,389 INFO:     Epoch: 23
2022-12-05 19:47:01,183 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41663236458870495, 'Total loss': 0.41663236458870495} | train loss {'Reaction outcome loss': 0.2000033098063907, 'Total loss': 0.2000033098063907}
2022-12-05 19:47:01,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:01,183 INFO:     Epoch: 24
2022-12-05 19:47:01,974 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3890828046609055, 'Total loss': 0.3890828046609055} | train loss {'Reaction outcome loss': 0.19758186998720073, 'Total loss': 0.19758186998720073}
2022-12-05 19:47:01,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:01,975 INFO:     Epoch: 25
2022-12-05 19:47:02,769 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37984910006211564, 'Total loss': 0.37984910006211564} | train loss {'Reaction outcome loss': 0.19301618197742773, 'Total loss': 0.19301618197742773}
2022-12-05 19:47:02,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:02,769 INFO:     Epoch: 26
2022-12-05 19:47:03,560 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38643205165863037, 'Total loss': 0.38643205165863037} | train loss {'Reaction outcome loss': 0.18772867602505247, 'Total loss': 0.18772867602505247}
2022-12-05 19:47:03,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:03,561 INFO:     Epoch: 27
2022-12-05 19:47:04,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3750494435344907, 'Total loss': 0.3750494435344907} | train loss {'Reaction outcome loss': 0.18653593727824638, 'Total loss': 0.18653593727824638}
2022-12-05 19:47:04,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:04,358 INFO:     Epoch: 28
2022-12-05 19:47:05,150 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3743225212462924, 'Total loss': 0.3743225212462924} | train loss {'Reaction outcome loss': 0.1809342740901879, 'Total loss': 0.1809342740901879}
2022-12-05 19:47:05,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:05,151 INFO:     Epoch: 29
2022-12-05 19:47:05,942 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38328325003385544, 'Total loss': 0.38328325003385544} | train loss {'Reaction outcome loss': 0.17802995065493243, 'Total loss': 0.17802995065493243}
2022-12-05 19:47:05,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:05,943 INFO:     Epoch: 30
2022-12-05 19:47:06,738 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3855472528799014, 'Total loss': 0.3855472528799014} | train loss {'Reaction outcome loss': 0.17867034682813956, 'Total loss': 0.17867034682813956}
2022-12-05 19:47:06,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:06,738 INFO:     Epoch: 31
2022-12-05 19:47:07,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39322773468765343, 'Total loss': 0.39322773468765343} | train loss {'Reaction outcome loss': 0.17271119411654617, 'Total loss': 0.17271119411654617}
2022-12-05 19:47:07,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:07,531 INFO:     Epoch: 32
2022-12-05 19:47:08,325 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41039843869988213, 'Total loss': 0.41039843869988213} | train loss {'Reaction outcome loss': 0.1741351379803857, 'Total loss': 0.1741351379803857}
2022-12-05 19:47:08,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:08,325 INFO:     Epoch: 33
2022-12-05 19:47:09,120 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3863410418006507, 'Total loss': 0.3863410418006507} | train loss {'Reaction outcome loss': 0.16928779399212526, 'Total loss': 0.16928779399212526}
2022-12-05 19:47:09,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:09,120 INFO:     Epoch: 34
2022-12-05 19:47:09,912 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38945399038493633, 'Total loss': 0.38945399038493633} | train loss {'Reaction outcome loss': 0.16805575574387094, 'Total loss': 0.16805575574387094}
2022-12-05 19:47:09,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:09,913 INFO:     Epoch: 35
2022-12-05 19:47:10,708 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39287048375064676, 'Total loss': 0.39287048375064676} | train loss {'Reaction outcome loss': 0.16712939792445727, 'Total loss': 0.16712939792445727}
2022-12-05 19:47:10,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:10,708 INFO:     Epoch: 36
2022-12-05 19:47:11,500 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37726338918913493, 'Total loss': 0.37726338918913493} | train loss {'Reaction outcome loss': 0.1617877708063746, 'Total loss': 0.1617877708063746}
2022-12-05 19:47:11,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:11,500 INFO:     Epoch: 37
2022-12-05 19:47:12,294 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39424455910921097, 'Total loss': 0.39424455910921097} | train loss {'Reaction outcome loss': 0.15947211145290308, 'Total loss': 0.15947211145290308}
2022-12-05 19:47:12,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:12,294 INFO:     Epoch: 38
2022-12-05 19:47:13,084 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39560475860807026, 'Total loss': 0.39560475860807026} | train loss {'Reaction outcome loss': 0.1573811436033979, 'Total loss': 0.1573811436033979}
2022-12-05 19:47:13,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:13,084 INFO:     Epoch: 39
2022-12-05 19:47:13,874 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.394189905713905, 'Total loss': 0.394189905713905} | train loss {'Reaction outcome loss': 0.15531034355564993, 'Total loss': 0.15531034355564993}
2022-12-05 19:47:13,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:13,874 INFO:     Epoch: 40
2022-12-05 19:47:14,671 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39658860625191167, 'Total loss': 0.39658860625191167} | train loss {'Reaction outcome loss': 0.15562361932682747, 'Total loss': 0.15562361932682747}
2022-12-05 19:47:14,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:14,671 INFO:     Epoch: 41
2022-12-05 19:47:15,462 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39671197669072583, 'Total loss': 0.39671197669072583} | train loss {'Reaction outcome loss': 0.15238921339718664, 'Total loss': 0.15238921339718664}
2022-12-05 19:47:15,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:15,462 INFO:     Epoch: 42
2022-12-05 19:47:16,252 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3922359763898633, 'Total loss': 0.3922359763898633} | train loss {'Reaction outcome loss': 0.1529633494740238, 'Total loss': 0.1529633494740238}
2022-12-05 19:47:16,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:16,252 INFO:     Epoch: 43
2022-12-05 19:47:17,047 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4110716806555336, 'Total loss': 0.4110716806555336} | train loss {'Reaction outcome loss': 0.14944994665530262, 'Total loss': 0.14944994665530262}
2022-12-05 19:47:17,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:17,048 INFO:     Epoch: 44
2022-12-05 19:47:17,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38514349270950665, 'Total loss': 0.38514349270950665} | train loss {'Reaction outcome loss': 0.14948769836705558, 'Total loss': 0.14948769836705558}
2022-12-05 19:47:17,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:17,845 INFO:     Epoch: 45
2022-12-05 19:47:18,634 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3953288434581323, 'Total loss': 0.3953288434581323} | train loss {'Reaction outcome loss': 0.14818031988201702, 'Total loss': 0.14818031988201702}
2022-12-05 19:47:18,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:18,635 INFO:     Epoch: 46
2022-12-05 19:47:19,424 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40329567139798944, 'Total loss': 0.40329567139798944} | train loss {'Reaction outcome loss': 0.1459416671979184, 'Total loss': 0.1459416671979184}
2022-12-05 19:47:19,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:19,425 INFO:     Epoch: 47
2022-12-05 19:47:20,213 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39098524539308116, 'Total loss': 0.39098524539308116} | train loss {'Reaction outcome loss': 0.14634188012961222, 'Total loss': 0.14634188012961222}
2022-12-05 19:47:20,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:20,213 INFO:     Epoch: 48
2022-12-05 19:47:21,006 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39751262522556563, 'Total loss': 0.39751262522556563} | train loss {'Reaction outcome loss': 0.1465401881279386, 'Total loss': 0.1465401881279386}
2022-12-05 19:47:21,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:21,007 INFO:     Epoch: 49
2022-12-05 19:47:21,801 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4009923445568843, 'Total loss': 0.4009923445568843} | train loss {'Reaction outcome loss': 0.14285141268402946, 'Total loss': 0.14285141268402946}
2022-12-05 19:47:21,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:21,801 INFO:     Epoch: 50
2022-12-05 19:47:22,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37924486500295723, 'Total loss': 0.37924486500295723} | train loss {'Reaction outcome loss': 0.14335026804129689, 'Total loss': 0.14335026804129689}
2022-12-05 19:47:22,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:22,591 INFO:     Epoch: 51
2022-12-05 19:47:23,381 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39580054784362967, 'Total loss': 0.39580054784362967} | train loss {'Reaction outcome loss': 0.13909747816470205, 'Total loss': 0.13909747816470205}
2022-12-05 19:47:23,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:23,381 INFO:     Epoch: 52
2022-12-05 19:47:24,169 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4035770767791705, 'Total loss': 0.4035770767791705} | train loss {'Reaction outcome loss': 0.14083253604416945, 'Total loss': 0.14083253604416945}
2022-12-05 19:47:24,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:24,170 INFO:     Epoch: 53
2022-12-05 19:47:24,959 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3914244610138915, 'Total loss': 0.3914244610138915} | train loss {'Reaction outcome loss': 0.13957460326503734, 'Total loss': 0.13957460326503734}
2022-12-05 19:47:24,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:24,960 INFO:     Epoch: 54
2022-12-05 19:47:25,748 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4075636829842221, 'Total loss': 0.4075636829842221} | train loss {'Reaction outcome loss': 0.1397798363879627, 'Total loss': 0.1397798363879627}
2022-12-05 19:47:25,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:25,748 INFO:     Epoch: 55
2022-12-05 19:47:26,542 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.418860686942935, 'Total loss': 0.418860686942935} | train loss {'Reaction outcome loss': 0.13886242476196922, 'Total loss': 0.13886242476196922}
2022-12-05 19:47:26,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:26,542 INFO:     Epoch: 56
2022-12-05 19:47:27,334 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4144528772343289, 'Total loss': 0.4144528772343289} | train loss {'Reaction outcome loss': 0.13972464167341894, 'Total loss': 0.13972464167341894}
2022-12-05 19:47:27,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:27,334 INFO:     Epoch: 57
2022-12-05 19:47:28,125 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4053444029255347, 'Total loss': 0.4053444029255347} | train loss {'Reaction outcome loss': 0.13559515867002156, 'Total loss': 0.13559515867002156}
2022-12-05 19:47:28,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:28,126 INFO:     Epoch: 58
2022-12-05 19:47:28,916 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4190140813589096, 'Total loss': 0.4190140813589096} | train loss {'Reaction outcome loss': 0.13278331024458215, 'Total loss': 0.13278331024458215}
2022-12-05 19:47:28,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:28,916 INFO:     Epoch: 59
2022-12-05 19:47:29,702 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4004695639014244, 'Total loss': 0.4004695639014244} | train loss {'Reaction outcome loss': 0.1336231092485238, 'Total loss': 0.1336231092485238}
2022-12-05 19:47:29,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:29,703 INFO:     Epoch: 60
2022-12-05 19:47:30,492 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38814920457926666, 'Total loss': 0.38814920457926666} | train loss {'Reaction outcome loss': 0.13277621664182873, 'Total loss': 0.13277621664182873}
2022-12-05 19:47:30,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:30,492 INFO:     Epoch: 61
2022-12-05 19:47:31,283 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4110779357566075, 'Total loss': 0.4110779357566075} | train loss {'Reaction outcome loss': 0.1326052481327586, 'Total loss': 0.1326052481327586}
2022-12-05 19:47:31,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:31,283 INFO:     Epoch: 62
2022-12-05 19:47:32,069 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4060323993590745, 'Total loss': 0.4060323993590745} | train loss {'Reaction outcome loss': 0.13506561183959853, 'Total loss': 0.13506561183959853}
2022-12-05 19:47:32,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:32,069 INFO:     Epoch: 63
2022-12-05 19:47:32,856 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39785490303554316, 'Total loss': 0.39785490303554316} | train loss {'Reaction outcome loss': 0.13217995630539192, 'Total loss': 0.13217995630539192}
2022-12-05 19:47:32,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:32,856 INFO:     Epoch: 64
2022-12-05 19:47:33,642 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38432477054778824, 'Total loss': 0.38432477054778824} | train loss {'Reaction outcome loss': 0.13324880721617718, 'Total loss': 0.13324880721617718}
2022-12-05 19:47:33,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:33,643 INFO:     Epoch: 65
2022-12-05 19:47:34,433 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39564624576914037, 'Total loss': 0.39564624576914037} | train loss {'Reaction outcome loss': 0.12819738814379184, 'Total loss': 0.12819738814379184}
2022-12-05 19:47:34,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:34,433 INFO:     Epoch: 66
2022-12-05 19:47:35,226 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4017454571810297, 'Total loss': 0.4017454571810297} | train loss {'Reaction outcome loss': 0.1292506690156095, 'Total loss': 0.1292506690156095}
2022-12-05 19:47:35,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:35,226 INFO:     Epoch: 67
2022-12-05 19:47:36,013 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3855402950536121, 'Total loss': 0.3855402950536121} | train loss {'Reaction outcome loss': 0.1305727431132477, 'Total loss': 0.1305727431132477}
2022-12-05 19:47:36,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:36,014 INFO:     Epoch: 68
2022-12-05 19:47:36,803 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4050892327319492, 'Total loss': 0.4050892327319492} | train loss {'Reaction outcome loss': 0.13181108203241412, 'Total loss': 0.13181108203241412}
2022-12-05 19:47:36,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:36,804 INFO:     Epoch: 69
2022-12-05 19:47:37,590 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3924787248569456, 'Total loss': 0.3924787248569456} | train loss {'Reaction outcome loss': 0.12635084053463475, 'Total loss': 0.12635084053463475}
2022-12-05 19:47:37,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:37,590 INFO:     Epoch: 70
2022-12-05 19:47:38,377 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4062671468339183, 'Total loss': 0.4062671468339183} | train loss {'Reaction outcome loss': 0.12875342802049555, 'Total loss': 0.12875342802049555}
2022-12-05 19:47:38,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:38,377 INFO:     Epoch: 71
2022-12-05 19:47:39,166 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4031786550344391, 'Total loss': 0.4031786550344391} | train loss {'Reaction outcome loss': 0.12652681772882232, 'Total loss': 0.12652681772882232}
2022-12-05 19:47:39,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:39,167 INFO:     Epoch: 72
2022-12-05 19:47:39,954 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41113725931129674, 'Total loss': 0.41113725931129674} | train loss {'Reaction outcome loss': 0.12363470185700119, 'Total loss': 0.12363470185700119}
2022-12-05 19:47:39,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:39,955 INFO:     Epoch: 73
2022-12-05 19:47:40,745 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4031859902157025, 'Total loss': 0.4031859902157025} | train loss {'Reaction outcome loss': 0.12477122611005087, 'Total loss': 0.12477122611005087}
2022-12-05 19:47:40,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:40,745 INFO:     Epoch: 74
2022-12-05 19:47:41,538 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39245430316606705, 'Total loss': 0.39245430316606705} | train loss {'Reaction outcome loss': 0.12379536109463293, 'Total loss': 0.12379536109463293}
2022-12-05 19:47:41,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:41,538 INFO:     Epoch: 75
2022-12-05 19:47:42,326 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4160547246309844, 'Total loss': 0.4160547246309844} | train loss {'Reaction outcome loss': 0.12448386020046108, 'Total loss': 0.12448386020046108}
2022-12-05 19:47:42,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:42,326 INFO:     Epoch: 76
2022-12-05 19:47:43,112 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39323460971089924, 'Total loss': 0.39323460971089924} | train loss {'Reaction outcome loss': 0.12401164276335312, 'Total loss': 0.12401164276335312}
2022-12-05 19:47:43,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:43,112 INFO:     Epoch: 77
2022-12-05 19:47:43,899 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39589533175934444, 'Total loss': 0.39589533175934444} | train loss {'Reaction outcome loss': 0.12278765710640926, 'Total loss': 0.12278765710640926}
2022-12-05 19:47:43,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:43,899 INFO:     Epoch: 78
2022-12-05 19:47:44,688 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4018829610537399, 'Total loss': 0.4018829610537399} | train loss {'Reaction outcome loss': 0.12612618334895495, 'Total loss': 0.12612618334895495}
2022-12-05 19:47:44,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:44,688 INFO:     Epoch: 79
2022-12-05 19:47:45,477 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4188783900304274, 'Total loss': 0.4188783900304274} | train loss {'Reaction outcome loss': 0.1220850430961166, 'Total loss': 0.1220850430961166}
2022-12-05 19:47:45,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:45,477 INFO:     Epoch: 80
2022-12-05 19:47:46,267 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3937654824165458, 'Total loss': 0.3937654824165458} | train loss {'Reaction outcome loss': 0.12065305387867349, 'Total loss': 0.12065305387867349}
2022-12-05 19:47:46,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:46,267 INFO:     Epoch: 81
2022-12-05 19:47:47,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45123919302766974, 'Total loss': 0.45123919302766974} | train loss {'Reaction outcome loss': 0.12116945513657161, 'Total loss': 0.12116945513657161}
2022-12-05 19:47:47,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:47,054 INFO:     Epoch: 82
2022-12-05 19:47:47,843 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4012942353094166, 'Total loss': 0.4012942353094166} | train loss {'Reaction outcome loss': 0.12435479782027553, 'Total loss': 0.12435479782027553}
2022-12-05 19:47:47,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:47,843 INFO:     Epoch: 83
2022-12-05 19:47:48,628 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4073025103319775, 'Total loss': 0.4073025103319775} | train loss {'Reaction outcome loss': 0.12413496388388531, 'Total loss': 0.12413496388388531}
2022-12-05 19:47:48,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:48,629 INFO:     Epoch: 84
2022-12-05 19:47:49,415 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4038072755475613, 'Total loss': 0.4038072755475613} | train loss {'Reaction outcome loss': 0.12091535445378751, 'Total loss': 0.12091535445378751}
2022-12-05 19:47:49,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:49,415 INFO:     Epoch: 85
2022-12-05 19:47:50,207 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4117660874670202, 'Total loss': 0.4117660874670202} | train loss {'Reaction outcome loss': 0.1213327690806924, 'Total loss': 0.1213327690806924}
2022-12-05 19:47:50,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:50,207 INFO:     Epoch: 86
2022-12-05 19:47:50,997 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4175688343291933, 'Total loss': 0.4175688343291933} | train loss {'Reaction outcome loss': 0.12090688228455125, 'Total loss': 0.12090688228455125}
2022-12-05 19:47:50,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:50,997 INFO:     Epoch: 87
2022-12-05 19:47:51,783 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41008484261957084, 'Total loss': 0.41008484261957084} | train loss {'Reaction outcome loss': 0.12055456769861737, 'Total loss': 0.12055456769861737}
2022-12-05 19:47:51,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:51,783 INFO:     Epoch: 88
2022-12-05 19:47:52,572 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4070279552516612, 'Total loss': 0.4070279552516612} | train loss {'Reaction outcome loss': 0.1190786161707068, 'Total loss': 0.1190786161707068}
2022-12-05 19:47:52,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:52,572 INFO:     Epoch: 89
2022-12-05 19:47:53,363 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41283849135718564, 'Total loss': 0.41283849135718564} | train loss {'Reaction outcome loss': 0.11918424297580306, 'Total loss': 0.11918424297580306}
2022-12-05 19:47:53,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:53,363 INFO:     Epoch: 90
2022-12-05 19:47:54,150 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4166573089632121, 'Total loss': 0.4166573089632121} | train loss {'Reaction outcome loss': 0.11982674181689414, 'Total loss': 0.11982674181689414}
2022-12-05 19:47:54,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:54,151 INFO:     Epoch: 91
2022-12-05 19:47:54,935 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3949403642592105, 'Total loss': 0.3949403642592105} | train loss {'Reaction outcome loss': 0.1238809595055574, 'Total loss': 0.1238809595055574}
2022-12-05 19:47:54,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:54,935 INFO:     Epoch: 92
2022-12-05 19:47:55,723 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3943570987744765, 'Total loss': 0.3943570987744765} | train loss {'Reaction outcome loss': 0.11954055483624035, 'Total loss': 0.11954055483624035}
2022-12-05 19:47:55,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:55,723 INFO:     Epoch: 93
2022-12-05 19:47:56,512 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3962344096296213, 'Total loss': 0.3962344096296213} | train loss {'Reaction outcome loss': 0.11688849620939214, 'Total loss': 0.11688849620939214}
2022-12-05 19:47:56,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:56,513 INFO:     Epoch: 94
2022-12-05 19:47:57,299 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4037401702424342, 'Total loss': 0.4037401702424342} | train loss {'Reaction outcome loss': 0.1164077812387627, 'Total loss': 0.1164077812387627}
2022-12-05 19:47:57,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:57,300 INFO:     Epoch: 95
2022-12-05 19:47:58,084 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39781360065733845, 'Total loss': 0.39781360065733845} | train loss {'Reaction outcome loss': 0.11690647193819893, 'Total loss': 0.11690647193819893}
2022-12-05 19:47:58,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:58,084 INFO:     Epoch: 96
2022-12-05 19:47:58,874 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40015078166669066, 'Total loss': 0.40015078166669066} | train loss {'Reaction outcome loss': 0.11692824084691855, 'Total loss': 0.11692824084691855}
2022-12-05 19:47:58,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:58,874 INFO:     Epoch: 97
2022-12-05 19:47:59,679 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3954973596740853, 'Total loss': 0.3954973596740853} | train loss {'Reaction outcome loss': 0.11728733427518484, 'Total loss': 0.11728733427518484}
2022-12-05 19:47:59,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:47:59,679 INFO:     Epoch: 98
2022-12-05 19:48:00,487 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42327885600653564, 'Total loss': 0.42327885600653564} | train loss {'Reaction outcome loss': 0.11643322252345328, 'Total loss': 0.11643322252345328}
2022-12-05 19:48:00,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:00,488 INFO:     Epoch: 99
2022-12-05 19:48:01,294 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41601898859847675, 'Total loss': 0.41601898859847675} | train loss {'Reaction outcome loss': 0.11549216374298747, 'Total loss': 0.11549216374298747}
2022-12-05 19:48:01,294 INFO:     Best model found after epoch 16 of 100.
2022-12-05 19:48:01,295 INFO:   Done with stage: TRAINING
2022-12-05 19:48:01,295 INFO:   Starting stage: EVALUATION
2022-12-05 19:48:01,426 INFO:   Done with stage: EVALUATION
2022-12-05 19:48:01,427 INFO:   Leaving out SEQ value Fold_1
2022-12-05 19:48:01,440 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 19:48:01,440 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:48:02,076 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:48:02,076 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:48:02,143 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:48:02,143 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:48:02,143 INFO:     No hyperparam tuning for this model
2022-12-05 19:48:02,143 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:48:02,143 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:48:02,144 INFO:     None feature selector for col prot
2022-12-05 19:48:02,144 INFO:     None feature selector for col prot
2022-12-05 19:48:02,144 INFO:     None feature selector for col prot
2022-12-05 19:48:02,145 INFO:     None feature selector for col chem
2022-12-05 19:48:02,145 INFO:     None feature selector for col chem
2022-12-05 19:48:02,145 INFO:     None feature selector for col chem
2022-12-05 19:48:02,145 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:48:02,145 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:48:02,147 INFO:     Number of params in model 215821
2022-12-05 19:48:02,150 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:48:02,150 INFO:   Starting stage: TRAINING
2022-12-05 19:48:02,209 INFO:     Val loss before train {'Reaction outcome loss': 1.0084564325421355, 'Total loss': 1.0084564325421355}
2022-12-05 19:48:02,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:02,209 INFO:     Epoch: 0
2022-12-05 19:48:02,992 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6064089134682057, 'Total loss': 0.6064089134682057} | train loss {'Reaction outcome loss': 0.7909749884909563, 'Total loss': 0.7909749884909563}
2022-12-05 19:48:02,992 INFO:     Found new best model at epoch 0
2022-12-05 19:48:02,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:02,993 INFO:     Epoch: 1
2022-12-05 19:48:03,775 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.524375855922699, 'Total loss': 0.524375855922699} | train loss {'Reaction outcome loss': 0.5363948703302768, 'Total loss': 0.5363948703302768}
2022-12-05 19:48:03,775 INFO:     Found new best model at epoch 1
2022-12-05 19:48:03,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:03,776 INFO:     Epoch: 2
2022-12-05 19:48:04,554 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47860520800878836, 'Total loss': 0.47860520800878836} | train loss {'Reaction outcome loss': 0.46310557467947283, 'Total loss': 0.46310557467947283}
2022-12-05 19:48:04,554 INFO:     Found new best model at epoch 2
2022-12-05 19:48:04,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:04,555 INFO:     Epoch: 3
2022-12-05 19:48:05,335 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47640940616297167, 'Total loss': 0.47640940616297167} | train loss {'Reaction outcome loss': 0.42411746250258553, 'Total loss': 0.42411746250258553}
2022-12-05 19:48:05,336 INFO:     Found new best model at epoch 3
2022-12-05 19:48:05,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:05,336 INFO:     Epoch: 4
2022-12-05 19:48:06,115 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44937783410382826, 'Total loss': 0.44937783410382826} | train loss {'Reaction outcome loss': 0.3985713279878897, 'Total loss': 0.3985713279878897}
2022-12-05 19:48:06,115 INFO:     Found new best model at epoch 4
2022-12-05 19:48:06,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:06,116 INFO:     Epoch: 5
2022-12-05 19:48:06,893 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4363168225038883, 'Total loss': 0.4363168225038883} | train loss {'Reaction outcome loss': 0.37549848823880955, 'Total loss': 0.37549848823880955}
2022-12-05 19:48:06,894 INFO:     Found new best model at epoch 5
2022-12-05 19:48:06,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:06,895 INFO:     Epoch: 6
2022-12-05 19:48:07,673 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43592402650866396, 'Total loss': 0.43592402650866396} | train loss {'Reaction outcome loss': 0.35649316298005024, 'Total loss': 0.35649316298005024}
2022-12-05 19:48:07,673 INFO:     Found new best model at epoch 6
2022-12-05 19:48:07,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:07,674 INFO:     Epoch: 7
2022-12-05 19:48:08,452 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42686599181141965, 'Total loss': 0.42686599181141965} | train loss {'Reaction outcome loss': 0.34260513532308884, 'Total loss': 0.34260513532308884}
2022-12-05 19:48:08,452 INFO:     Found new best model at epoch 7
2022-12-05 19:48:08,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:08,453 INFO:     Epoch: 8
2022-12-05 19:48:09,231 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4389541537262673, 'Total loss': 0.4389541537262673} | train loss {'Reaction outcome loss': 0.3227712339702457, 'Total loss': 0.3227712339702457}
2022-12-05 19:48:09,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:09,231 INFO:     Epoch: 9
2022-12-05 19:48:10,011 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43436519420424174, 'Total loss': 0.43436519420424174} | train loss {'Reaction outcome loss': 0.3061871761034546, 'Total loss': 0.3061871761034546}
2022-12-05 19:48:10,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:10,011 INFO:     Epoch: 10
2022-12-05 19:48:10,793 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4377139834470527, 'Total loss': 0.4377139834470527} | train loss {'Reaction outcome loss': 0.29512340757888533, 'Total loss': 0.29512340757888533}
2022-12-05 19:48:10,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:10,794 INFO:     Epoch: 11
2022-12-05 19:48:11,573 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.447198549675387, 'Total loss': 0.447198549675387} | train loss {'Reaction outcome loss': 0.2875014696224236, 'Total loss': 0.2875014696224236}
2022-12-05 19:48:11,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:11,573 INFO:     Epoch: 12
2022-12-05 19:48:12,352 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4370335039011268, 'Total loss': 0.4370335039011268} | train loss {'Reaction outcome loss': 0.2725540393572531, 'Total loss': 0.2725540393572531}
2022-12-05 19:48:12,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:12,352 INFO:     Epoch: 13
2022-12-05 19:48:13,132 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.443979671528173, 'Total loss': 0.443979671528173} | train loss {'Reaction outcome loss': 0.2651914193490405, 'Total loss': 0.2651914193490405}
2022-12-05 19:48:13,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:13,132 INFO:     Epoch: 14
2022-12-05 19:48:13,911 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4483241639858068, 'Total loss': 0.4483241639858068} | train loss {'Reaction outcome loss': 0.2582380920035358, 'Total loss': 0.2582380920035358}
2022-12-05 19:48:13,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:13,911 INFO:     Epoch: 15
2022-12-05 19:48:14,688 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44645559926365697, 'Total loss': 0.44645559926365697} | train loss {'Reaction outcome loss': 0.24784121857841074, 'Total loss': 0.24784121857841074}
2022-12-05 19:48:14,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:14,689 INFO:     Epoch: 16
2022-12-05 19:48:15,466 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44058946364147716, 'Total loss': 0.44058946364147716} | train loss {'Reaction outcome loss': 0.24044139805889914, 'Total loss': 0.24044139805889914}
2022-12-05 19:48:15,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:15,466 INFO:     Epoch: 17
2022-12-05 19:48:16,243 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4346279799938202, 'Total loss': 0.4346279799938202} | train loss {'Reaction outcome loss': 0.2329860051074391, 'Total loss': 0.2329860051074391}
2022-12-05 19:48:16,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:16,243 INFO:     Epoch: 18
2022-12-05 19:48:17,021 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4432845852056215, 'Total loss': 0.4432845852056215} | train loss {'Reaction outcome loss': 0.22540509965991287, 'Total loss': 0.22540509965991287}
2022-12-05 19:48:17,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:17,022 INFO:     Epoch: 19
2022-12-05 19:48:17,803 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4534784707912179, 'Total loss': 0.4534784707912179} | train loss {'Reaction outcome loss': 0.22455323291290935, 'Total loss': 0.22455323291290935}
2022-12-05 19:48:17,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:17,803 INFO:     Epoch: 20
2022-12-05 19:48:18,580 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44424525838951734, 'Total loss': 0.44424525838951734} | train loss {'Reaction outcome loss': 0.2163820199576425, 'Total loss': 0.2163820199576425}
2022-12-05 19:48:18,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:18,580 INFO:     Epoch: 21
2022-12-05 19:48:19,358 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46455890217492746, 'Total loss': 0.46455890217492746} | train loss {'Reaction outcome loss': 0.209610985066941, 'Total loss': 0.209610985066941}
2022-12-05 19:48:19,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:19,359 INFO:     Epoch: 22
2022-12-05 19:48:20,140 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4491018580142842, 'Total loss': 0.4491018580142842} | train loss {'Reaction outcome loss': 0.20715893721476258, 'Total loss': 0.20715893721476258}
2022-12-05 19:48:20,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:20,140 INFO:     Epoch: 23
2022-12-05 19:48:20,921 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45853014290332794, 'Total loss': 0.45853014290332794} | train loss {'Reaction outcome loss': 0.20039751501792252, 'Total loss': 0.20039751501792252}
2022-12-05 19:48:20,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:20,921 INFO:     Epoch: 24
2022-12-05 19:48:21,701 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4632617183202921, 'Total loss': 0.4632617183202921} | train loss {'Reaction outcome loss': 0.1976810000192972, 'Total loss': 0.1976810000192972}
2022-12-05 19:48:21,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:21,702 INFO:     Epoch: 25
2022-12-05 19:48:22,483 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46673254218212396, 'Total loss': 0.46673254218212396} | train loss {'Reaction outcome loss': 0.19267178792889716, 'Total loss': 0.19267178792889716}
2022-12-05 19:48:22,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:22,484 INFO:     Epoch: 26
2022-12-05 19:48:23,262 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46880531865496966, 'Total loss': 0.46880531865496966} | train loss {'Reaction outcome loss': 0.1893091065341553, 'Total loss': 0.1893091065341553}
2022-12-05 19:48:23,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:23,262 INFO:     Epoch: 27
2022-12-05 19:48:24,039 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46508395048074946, 'Total loss': 0.46508395048074946} | train loss {'Reaction outcome loss': 0.1846567653272868, 'Total loss': 0.1846567653272868}
2022-12-05 19:48:24,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:24,040 INFO:     Epoch: 28
2022-12-05 19:48:24,819 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47541511543961457, 'Total loss': 0.47541511543961457} | train loss {'Reaction outcome loss': 0.18019643341624197, 'Total loss': 0.18019643341624197}
2022-12-05 19:48:24,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:24,819 INFO:     Epoch: 29
2022-12-05 19:48:25,601 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47890155675799345, 'Total loss': 0.47890155675799345} | train loss {'Reaction outcome loss': 0.1793504054715604, 'Total loss': 0.1793504054715604}
2022-12-05 19:48:25,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:25,601 INFO:     Epoch: 30
2022-12-05 19:48:26,384 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.476147071220154, 'Total loss': 0.476147071220154} | train loss {'Reaction outcome loss': 0.18161550904681653, 'Total loss': 0.18161550904681653}
2022-12-05 19:48:26,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:26,384 INFO:     Epoch: 31
2022-12-05 19:48:27,164 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47129648646642996, 'Total loss': 0.47129648646642996} | train loss {'Reaction outcome loss': 0.1743710754216944, 'Total loss': 0.1743710754216944}
2022-12-05 19:48:27,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:27,164 INFO:     Epoch: 32
2022-12-05 19:48:27,943 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47712859615337017, 'Total loss': 0.47712859615337017} | train loss {'Reaction outcome loss': 0.1706166175335891, 'Total loss': 0.1706166175335891}
2022-12-05 19:48:27,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:27,944 INFO:     Epoch: 33
2022-12-05 19:48:28,722 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4822128638625145, 'Total loss': 0.4822128638625145} | train loss {'Reaction outcome loss': 0.16992825348650722, 'Total loss': 0.16992825348650722}
2022-12-05 19:48:28,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:28,722 INFO:     Epoch: 34
2022-12-05 19:48:29,503 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49729042933430784, 'Total loss': 0.49729042933430784} | train loss {'Reaction outcome loss': 0.1669173739513252, 'Total loss': 0.1669173739513252}
2022-12-05 19:48:29,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:29,503 INFO:     Epoch: 35
2022-12-05 19:48:30,284 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4893491135606932, 'Total loss': 0.4893491135606932} | train loss {'Reaction outcome loss': 0.16571090240874653, 'Total loss': 0.16571090240874653}
2022-12-05 19:48:30,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:30,284 INFO:     Epoch: 36
2022-12-05 19:48:31,066 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4746508681496909, 'Total loss': 0.4746508681496909} | train loss {'Reaction outcome loss': 0.1641476140223413, 'Total loss': 0.1641476140223413}
2022-12-05 19:48:31,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:31,066 INFO:     Epoch: 37
2022-12-05 19:48:31,843 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47883103302744934, 'Total loss': 0.47883103302744934} | train loss {'Reaction outcome loss': 0.16241653655260924, 'Total loss': 0.16241653655260924}
2022-12-05 19:48:31,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:31,845 INFO:     Epoch: 38
2022-12-05 19:48:32,622 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48835686265036116, 'Total loss': 0.48835686265036116} | train loss {'Reaction outcome loss': 0.15851566515127083, 'Total loss': 0.15851566515127083}
2022-12-05 19:48:32,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:32,623 INFO:     Epoch: 39
2022-12-05 19:48:33,406 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4889676252076792, 'Total loss': 0.4889676252076792} | train loss {'Reaction outcome loss': 0.16066854129786845, 'Total loss': 0.16066854129786845}
2022-12-05 19:48:33,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:33,406 INFO:     Epoch: 40
2022-12-05 19:48:34,188 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4942055805477985, 'Total loss': 0.4942055805477985} | train loss {'Reaction outcome loss': 0.15914592589922402, 'Total loss': 0.15914592589922402}
2022-12-05 19:48:34,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:34,188 INFO:     Epoch: 41
2022-12-05 19:48:34,965 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47917706640653834, 'Total loss': 0.47917706640653834} | train loss {'Reaction outcome loss': 0.1548773193954195, 'Total loss': 0.1548773193954195}
2022-12-05 19:48:34,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:34,965 INFO:     Epoch: 42
2022-12-05 19:48:35,742 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47999998961770257, 'Total loss': 0.47999998961770257} | train loss {'Reaction outcome loss': 0.15552732947861217, 'Total loss': 0.15552732947861217}
2022-12-05 19:48:35,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:35,742 INFO:     Epoch: 43
2022-12-05 19:48:36,520 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.472628670029862, 'Total loss': 0.472628670029862} | train loss {'Reaction outcome loss': 0.1515496662078203, 'Total loss': 0.1515496662078203}
2022-12-05 19:48:36,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:36,520 INFO:     Epoch: 44
2022-12-05 19:48:37,300 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4831977181656416, 'Total loss': 0.4831977181656416} | train loss {'Reaction outcome loss': 0.15128574052005392, 'Total loss': 0.15128574052005392}
2022-12-05 19:48:37,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:37,300 INFO:     Epoch: 45
2022-12-05 19:48:38,078 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4905299707207569, 'Total loss': 0.4905299707207569} | train loss {'Reaction outcome loss': 0.15167733417141707, 'Total loss': 0.15167733417141707}
2022-12-05 19:48:38,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:38,079 INFO:     Epoch: 46
2022-12-05 19:48:38,864 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.489260378618573, 'Total loss': 0.489260378618573} | train loss {'Reaction outcome loss': 0.14833150341064352, 'Total loss': 0.14833150341064352}
2022-12-05 19:48:38,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:38,864 INFO:     Epoch: 47
2022-12-05 19:48:39,652 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4942493424859158, 'Total loss': 0.4942493424859158} | train loss {'Reaction outcome loss': 0.1458343316574769, 'Total loss': 0.1458343316574769}
2022-12-05 19:48:39,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:39,653 INFO:     Epoch: 48
2022-12-05 19:48:40,439 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4889299301213996, 'Total loss': 0.4889299301213996} | train loss {'Reaction outcome loss': 0.14673104568350095, 'Total loss': 0.14673104568350095}
2022-12-05 19:48:40,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:40,439 INFO:     Epoch: 49
2022-12-05 19:48:41,224 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4846111373152844, 'Total loss': 0.4846111373152844} | train loss {'Reaction outcome loss': 0.14700572362069975, 'Total loss': 0.14700572362069975}
2022-12-05 19:48:41,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:41,224 INFO:     Epoch: 50
2022-12-05 19:48:42,009 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49152811530024504, 'Total loss': 0.49152811530024504} | train loss {'Reaction outcome loss': 0.14374901317136646, 'Total loss': 0.14374901317136646}
2022-12-05 19:48:42,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:42,009 INFO:     Epoch: 51
2022-12-05 19:48:42,794 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5008169410880222, 'Total loss': 0.5008169410880222} | train loss {'Reaction outcome loss': 0.14506336679459844, 'Total loss': 0.14506336679459844}
2022-12-05 19:48:42,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:42,794 INFO:     Epoch: 52
2022-12-05 19:48:43,580 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4962726311628209, 'Total loss': 0.4962726311628209} | train loss {'Reaction outcome loss': 0.14235812160780523, 'Total loss': 0.14235812160780523}
2022-12-05 19:48:43,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:43,580 INFO:     Epoch: 53
2022-12-05 19:48:44,370 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48885404543821204, 'Total loss': 0.48885404543821204} | train loss {'Reaction outcome loss': 0.14295223189341555, 'Total loss': 0.14295223189341555}
2022-12-05 19:48:44,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:44,370 INFO:     Epoch: 54
2022-12-05 19:48:45,155 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49372361773668333, 'Total loss': 0.49372361773668333} | train loss {'Reaction outcome loss': 0.14040952405045307, 'Total loss': 0.14040952405045307}
2022-12-05 19:48:45,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:45,155 INFO:     Epoch: 55
2022-12-05 19:48:45,940 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49392084725374397, 'Total loss': 0.49392084725374397} | train loss {'Reaction outcome loss': 0.13988792428309904, 'Total loss': 0.13988792428309904}
2022-12-05 19:48:45,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:45,940 INFO:     Epoch: 56
2022-12-05 19:48:46,727 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48782325068185495, 'Total loss': 0.48782325068185495} | train loss {'Reaction outcome loss': 0.13973397673433455, 'Total loss': 0.13973397673433455}
2022-12-05 19:48:46,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:46,728 INFO:     Epoch: 57
2022-12-05 19:48:47,517 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.483706085141315, 'Total loss': 0.483706085141315} | train loss {'Reaction outcome loss': 0.13938034377961492, 'Total loss': 0.13938034377961492}
2022-12-05 19:48:47,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:47,517 INFO:     Epoch: 58
2022-12-05 19:48:48,301 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4804268990491712, 'Total loss': 0.4804268990491712} | train loss {'Reaction outcome loss': 0.13746696345722725, 'Total loss': 0.13746696345722725}
2022-12-05 19:48:48,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:48,301 INFO:     Epoch: 59
2022-12-05 19:48:49,089 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48399084945057713, 'Total loss': 0.48399084945057713} | train loss {'Reaction outcome loss': 0.13566251314501948, 'Total loss': 0.13566251314501948}
2022-12-05 19:48:49,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:49,089 INFO:     Epoch: 60
2022-12-05 19:48:49,873 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4889645555684733, 'Total loss': 0.4889645555684733} | train loss {'Reaction outcome loss': 0.13464416513687053, 'Total loss': 0.13464416513687053}
2022-12-05 19:48:49,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:49,874 INFO:     Epoch: 61
2022-12-05 19:48:50,658 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4757991064079972, 'Total loss': 0.4757991064079972} | train loss {'Reaction outcome loss': 0.13487665559866546, 'Total loss': 0.13487665559866546}
2022-12-05 19:48:50,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:50,659 INFO:     Epoch: 62
2022-12-05 19:48:51,444 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.480853351049645, 'Total loss': 0.480853351049645} | train loss {'Reaction outcome loss': 0.13159998290148783, 'Total loss': 0.13159998290148783}
2022-12-05 19:48:51,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:51,444 INFO:     Epoch: 63
2022-12-05 19:48:52,229 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47809898437455645, 'Total loss': 0.47809898437455645} | train loss {'Reaction outcome loss': 0.13277465274841083, 'Total loss': 0.13277465274841083}
2022-12-05 19:48:52,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:52,229 INFO:     Epoch: 64
2022-12-05 19:48:53,017 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48393548193366026, 'Total loss': 0.48393548193366026} | train loss {'Reaction outcome loss': 0.13375652960114517, 'Total loss': 0.13375652960114517}
2022-12-05 19:48:53,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:53,017 INFO:     Epoch: 65
2022-12-05 19:48:53,802 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49117681765279103, 'Total loss': 0.49117681765279103} | train loss {'Reaction outcome loss': 0.1300102682868517, 'Total loss': 0.1300102682868517}
2022-12-05 19:48:53,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:53,802 INFO:     Epoch: 66
2022-12-05 19:48:54,590 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48630497310050697, 'Total loss': 0.48630497310050697} | train loss {'Reaction outcome loss': 0.1297941117666263, 'Total loss': 0.1297941117666263}
2022-12-05 19:48:54,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:54,590 INFO:     Epoch: 67
2022-12-05 19:48:55,376 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4888766293608865, 'Total loss': 0.4888766293608865} | train loss {'Reaction outcome loss': 0.13010413466412343, 'Total loss': 0.13010413466412343}
2022-12-05 19:48:55,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:55,376 INFO:     Epoch: 68
2022-12-05 19:48:56,164 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49377172180386475, 'Total loss': 0.49377172180386475} | train loss {'Reaction outcome loss': 0.13141755915319722, 'Total loss': 0.13141755915319722}
2022-12-05 19:48:56,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:56,164 INFO:     Epoch: 69
2022-12-05 19:48:56,952 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46881369726602423, 'Total loss': 0.46881369726602423} | train loss {'Reaction outcome loss': 0.12939389605734328, 'Total loss': 0.12939389605734328}
2022-12-05 19:48:56,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:56,953 INFO:     Epoch: 70
2022-12-05 19:48:57,741 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49599082300136255, 'Total loss': 0.49599082300136255} | train loss {'Reaction outcome loss': 0.1271533830083692, 'Total loss': 0.1271533830083692}
2022-12-05 19:48:57,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:57,741 INFO:     Epoch: 71
2022-12-05 19:48:58,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48550883195427963, 'Total loss': 0.48550883195427963} | train loss {'Reaction outcome loss': 0.1292897131477977, 'Total loss': 0.1292897131477977}
2022-12-05 19:48:58,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:58,527 INFO:     Epoch: 72
2022-12-05 19:48:59,312 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47016480010609296, 'Total loss': 0.47016480010609296} | train loss {'Reaction outcome loss': 0.12700564781426157, 'Total loss': 0.12700564781426157}
2022-12-05 19:48:59,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:48:59,312 INFO:     Epoch: 73
2022-12-05 19:49:00,097 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4772791734268499, 'Total loss': 0.4772791734268499} | train loss {'Reaction outcome loss': 0.1269067562809942, 'Total loss': 0.1269067562809942}
2022-12-05 19:49:00,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:00,097 INFO:     Epoch: 74
2022-12-05 19:49:00,885 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4775340713040773, 'Total loss': 0.4775340713040773} | train loss {'Reaction outcome loss': 0.12754252810537078, 'Total loss': 0.12754252810537078}
2022-12-05 19:49:00,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:00,885 INFO:     Epoch: 75
2022-12-05 19:49:01,671 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4882666430501051, 'Total loss': 0.4882666430501051} | train loss {'Reaction outcome loss': 0.1264487610049086, 'Total loss': 0.1264487610049086}
2022-12-05 19:49:01,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:01,671 INFO:     Epoch: 76
2022-12-05 19:49:02,457 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.485917414170365, 'Total loss': 0.485917414170365} | train loss {'Reaction outcome loss': 0.12797179787492555, 'Total loss': 0.12797179787492555}
2022-12-05 19:49:02,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:02,457 INFO:     Epoch: 77
2022-12-05 19:49:03,245 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4762205625342768, 'Total loss': 0.4762205625342768} | train loss {'Reaction outcome loss': 0.12411343939449071, 'Total loss': 0.12411343939449071}
2022-12-05 19:49:03,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:03,245 INFO:     Epoch: 78
2022-12-05 19:49:04,029 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4746496050163757, 'Total loss': 0.4746496050163757} | train loss {'Reaction outcome loss': 0.12318263814397494, 'Total loss': 0.12318263814397494}
2022-12-05 19:49:04,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:04,030 INFO:     Epoch: 79
2022-12-05 19:49:04,816 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4753865759040034, 'Total loss': 0.4753865759040034} | train loss {'Reaction outcome loss': 0.12396747637693406, 'Total loss': 0.12396747637693406}
2022-12-05 19:49:04,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:04,816 INFO:     Epoch: 80
2022-12-05 19:49:05,605 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4937554840431657, 'Total loss': 0.4937554840431657} | train loss {'Reaction outcome loss': 0.12450343785508547, 'Total loss': 0.12450343785508547}
2022-12-05 19:49:05,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:05,605 INFO:     Epoch: 81
2022-12-05 19:49:06,388 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4715218505887098, 'Total loss': 0.4715218505887098} | train loss {'Reaction outcome loss': 0.12291246383937666, 'Total loss': 0.12291246383937666}
2022-12-05 19:49:06,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:06,388 INFO:     Epoch: 82
2022-12-05 19:49:07,171 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4934188619602558, 'Total loss': 0.4934188619602558} | train loss {'Reaction outcome loss': 0.12225531180745658, 'Total loss': 0.12225531180745658}
2022-12-05 19:49:07,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:07,171 INFO:     Epoch: 83
2022-12-05 19:49:07,949 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4809150768573894, 'Total loss': 0.4809150768573894} | train loss {'Reaction outcome loss': 0.1237402552079578, 'Total loss': 0.1237402552079578}
2022-12-05 19:49:07,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:07,950 INFO:     Epoch: 84
2022-12-05 19:49:08,731 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4680301117342572, 'Total loss': 0.4680301117342572} | train loss {'Reaction outcome loss': 0.12338172579989021, 'Total loss': 0.12338172579989021}
2022-12-05 19:49:08,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:08,732 INFO:     Epoch: 85
2022-12-05 19:49:09,510 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4756816202817961, 'Total loss': 0.4756816202817961} | train loss {'Reaction outcome loss': 0.12400079979235498, 'Total loss': 0.12400079979235498}
2022-12-05 19:49:09,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:09,510 INFO:     Epoch: 86
2022-12-05 19:49:10,289 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48123696792957393, 'Total loss': 0.48123696792957393} | train loss {'Reaction outcome loss': 0.12031230258414284, 'Total loss': 0.12031230258414284}
2022-12-05 19:49:10,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:10,289 INFO:     Epoch: 87
2022-12-05 19:49:11,072 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4786385003217431, 'Total loss': 0.4786385003217431} | train loss {'Reaction outcome loss': 0.12077003150197213, 'Total loss': 0.12077003150197213}
2022-12-05 19:49:11,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:11,072 INFO:     Epoch: 88
2022-12-05 19:49:11,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4744218267327131, 'Total loss': 0.4744218267327131} | train loss {'Reaction outcome loss': 0.1206253156518188, 'Total loss': 0.1206253156518188}
2022-12-05 19:49:11,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:11,852 INFO:     Epoch: 89
2022-12-05 19:49:12,634 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47657758309397585, 'Total loss': 0.47657758309397585} | train loss {'Reaction outcome loss': 0.11879383779510304, 'Total loss': 0.11879383779510304}
2022-12-05 19:49:12,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:12,635 INFO:     Epoch: 90
2022-12-05 19:49:13,413 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4823930114507675, 'Total loss': 0.4823930114507675} | train loss {'Reaction outcome loss': 0.12040266696241045, 'Total loss': 0.12040266696241045}
2022-12-05 19:49:13,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:13,414 INFO:     Epoch: 91
2022-12-05 19:49:14,195 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4646101119213326, 'Total loss': 0.4646101119213326} | train loss {'Reaction outcome loss': 0.12121362468312061, 'Total loss': 0.12121362468312061}
2022-12-05 19:49:14,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:14,195 INFO:     Epoch: 92
2022-12-05 19:49:14,976 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47105185410311057, 'Total loss': 0.47105185410311057} | train loss {'Reaction outcome loss': 0.11830630352712954, 'Total loss': 0.11830630352712954}
2022-12-05 19:49:14,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:14,976 INFO:     Epoch: 93
2022-12-05 19:49:15,756 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47950775678767715, 'Total loss': 0.47950775678767715} | train loss {'Reaction outcome loss': 0.11660090921285712, 'Total loss': 0.11660090921285712}
2022-12-05 19:49:15,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:15,756 INFO:     Epoch: 94
2022-12-05 19:49:16,533 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4800047663062118, 'Total loss': 0.4800047663062118} | train loss {'Reaction outcome loss': 0.1173646258105957, 'Total loss': 0.1173646258105957}
2022-12-05 19:49:16,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:16,533 INFO:     Epoch: 95
2022-12-05 19:49:17,311 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4749648661114449, 'Total loss': 0.4749648661114449} | train loss {'Reaction outcome loss': 0.11823340300317287, 'Total loss': 0.11823340300317287}
2022-12-05 19:49:17,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:17,311 INFO:     Epoch: 96
2022-12-05 19:49:18,089 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.478170775743418, 'Total loss': 0.478170775743418} | train loss {'Reaction outcome loss': 0.12008479012965911, 'Total loss': 0.12008479012965911}
2022-12-05 19:49:18,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:18,089 INFO:     Epoch: 97
2022-12-05 19:49:18,868 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47046067392410235, 'Total loss': 0.47046067392410235} | train loss {'Reaction outcome loss': 0.11622824851776102, 'Total loss': 0.11622824851776102}
2022-12-05 19:49:18,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:18,869 INFO:     Epoch: 98
2022-12-05 19:49:19,646 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48518501326095226, 'Total loss': 0.48518501326095226} | train loss {'Reaction outcome loss': 0.11741267854478134, 'Total loss': 0.11741267854478134}
2022-12-05 19:49:19,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:19,647 INFO:     Epoch: 99
2022-12-05 19:49:20,425 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4817564709242, 'Total loss': 0.4817564709242} | train loss {'Reaction outcome loss': 0.1161597273331672, 'Total loss': 0.1161597273331672}
2022-12-05 19:49:20,425 INFO:     Best model found after epoch 8 of 100.
2022-12-05 19:49:20,425 INFO:   Done with stage: TRAINING
2022-12-05 19:49:20,426 INFO:   Starting stage: EVALUATION
2022-12-05 19:49:20,568 INFO:   Done with stage: EVALUATION
2022-12-05 19:49:20,569 INFO:   Leaving out SEQ value Fold_2
2022-12-05 19:49:20,581 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:49:20,582 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:49:21,227 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:49:21,227 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:49:21,295 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:49:21,295 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:49:21,295 INFO:     No hyperparam tuning for this model
2022-12-05 19:49:21,295 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:49:21,295 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:49:21,296 INFO:     None feature selector for col prot
2022-12-05 19:49:21,296 INFO:     None feature selector for col prot
2022-12-05 19:49:21,296 INFO:     None feature selector for col prot
2022-12-05 19:49:21,296 INFO:     None feature selector for col chem
2022-12-05 19:49:21,297 INFO:     None feature selector for col chem
2022-12-05 19:49:21,297 INFO:     None feature selector for col chem
2022-12-05 19:49:21,297 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:49:21,297 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:49:21,298 INFO:     Number of params in model 215821
2022-12-05 19:49:21,301 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:49:21,301 INFO:   Starting stage: TRAINING
2022-12-05 19:49:21,362 INFO:     Val loss before train {'Reaction outcome loss': 0.9524861072952097, 'Total loss': 0.9524861072952097}
2022-12-05 19:49:21,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:21,362 INFO:     Epoch: 0
2022-12-05 19:49:22,154 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5968586880375039, 'Total loss': 0.5968586880375039} | train loss {'Reaction outcome loss': 0.7832459808300863, 'Total loss': 0.7832459808300863}
2022-12-05 19:49:22,155 INFO:     Found new best model at epoch 0
2022-12-05 19:49:22,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:22,155 INFO:     Epoch: 1
2022-12-05 19:49:22,948 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5051016326655041, 'Total loss': 0.5051016326655041} | train loss {'Reaction outcome loss': 0.539194761620842, 'Total loss': 0.539194761620842}
2022-12-05 19:49:22,949 INFO:     Found new best model at epoch 1
2022-12-05 19:49:22,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:22,950 INFO:     Epoch: 2
2022-12-05 19:49:23,735 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4736400558189912, 'Total loss': 0.4736400558189912} | train loss {'Reaction outcome loss': 0.460899069694131, 'Total loss': 0.460899069694131}
2022-12-05 19:49:23,735 INFO:     Found new best model at epoch 2
2022-12-05 19:49:23,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:23,736 INFO:     Epoch: 3
2022-12-05 19:49:24,520 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4616068997843699, 'Total loss': 0.4616068997843699} | train loss {'Reaction outcome loss': 0.41899529266876245, 'Total loss': 0.41899529266876245}
2022-12-05 19:49:24,520 INFO:     Found new best model at epoch 3
2022-12-05 19:49:24,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:24,521 INFO:     Epoch: 4
2022-12-05 19:49:25,306 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4558165537362749, 'Total loss': 0.4558165537362749} | train loss {'Reaction outcome loss': 0.3883075641754728, 'Total loss': 0.3883075641754728}
2022-12-05 19:49:25,306 INFO:     Found new best model at epoch 4
2022-12-05 19:49:25,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:25,307 INFO:     Epoch: 5
2022-12-05 19:49:26,096 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43659574403004214, 'Total loss': 0.43659574403004214} | train loss {'Reaction outcome loss': 0.36620229591242215, 'Total loss': 0.36620229591242215}
2022-12-05 19:49:26,096 INFO:     Found new best model at epoch 5
2022-12-05 19:49:26,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:26,097 INFO:     Epoch: 6
2022-12-05 19:49:26,883 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42439147152683954, 'Total loss': 0.42439147152683954} | train loss {'Reaction outcome loss': 0.3463451396296864, 'Total loss': 0.3463451396296864}
2022-12-05 19:49:26,883 INFO:     Found new best model at epoch 6
2022-12-05 19:49:26,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:26,884 INFO:     Epoch: 7
2022-12-05 19:49:27,672 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4020551461726427, 'Total loss': 0.4020551461726427} | train loss {'Reaction outcome loss': 0.33218340783828665, 'Total loss': 0.33218340783828665}
2022-12-05 19:49:27,672 INFO:     Found new best model at epoch 7
2022-12-05 19:49:27,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:27,673 INFO:     Epoch: 8
2022-12-05 19:49:28,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4227151173082265, 'Total loss': 0.4227151173082265} | train loss {'Reaction outcome loss': 0.31421928642400604, 'Total loss': 0.31421928642400604}
2022-12-05 19:49:28,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:28,457 INFO:     Epoch: 9
2022-12-05 19:49:29,246 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4210433882068504, 'Total loss': 0.4210433882068504} | train loss {'Reaction outcome loss': 0.3030772379840826, 'Total loss': 0.3030772379840826}
2022-12-05 19:49:29,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:29,246 INFO:     Epoch: 10
2022-12-05 19:49:30,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4123143848370422, 'Total loss': 0.4123143848370422} | train loss {'Reaction outcome loss': 0.2911808262711112, 'Total loss': 0.2911808262711112}
2022-12-05 19:49:30,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:30,031 INFO:     Epoch: 11
2022-12-05 19:49:30,816 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40424066731198266, 'Total loss': 0.40424066731198266} | train loss {'Reaction outcome loss': 0.2813076145856487, 'Total loss': 0.2813076145856487}
2022-12-05 19:49:30,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:30,816 INFO:     Epoch: 12
2022-12-05 19:49:31,604 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4133447439155795, 'Total loss': 0.4133447439155795} | train loss {'Reaction outcome loss': 0.27321433755550306, 'Total loss': 0.27321433755550306}
2022-12-05 19:49:31,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:31,605 INFO:     Epoch: 13
2022-12-05 19:49:32,389 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40028018097985874, 'Total loss': 0.40028018097985874} | train loss {'Reaction outcome loss': 0.2622222916980987, 'Total loss': 0.2622222916980987}
2022-12-05 19:49:32,389 INFO:     Found new best model at epoch 13
2022-12-05 19:49:32,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:32,390 INFO:     Epoch: 14
2022-12-05 19:49:33,180 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.391762186857787, 'Total loss': 0.391762186857787} | train loss {'Reaction outcome loss': 0.24936175779232128, 'Total loss': 0.24936175779232128}
2022-12-05 19:49:33,180 INFO:     Found new best model at epoch 14
2022-12-05 19:49:33,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:33,181 INFO:     Epoch: 15
2022-12-05 19:49:33,970 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4097109873863784, 'Total loss': 0.4097109873863784} | train loss {'Reaction outcome loss': 0.24629081493085211, 'Total loss': 0.24629081493085211}
2022-12-05 19:49:33,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:33,970 INFO:     Epoch: 16
2022-12-05 19:49:34,762 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4004269032315774, 'Total loss': 0.4004269032315774} | train loss {'Reaction outcome loss': 0.24116524135475217, 'Total loss': 0.24116524135475217}
2022-12-05 19:49:34,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:34,763 INFO:     Epoch: 17
2022-12-05 19:49:35,558 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38959854494102975, 'Total loss': 0.38959854494102975} | train loss {'Reaction outcome loss': 0.23161248157653008, 'Total loss': 0.23161248157653008}
2022-12-05 19:49:35,558 INFO:     Found new best model at epoch 17
2022-12-05 19:49:35,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:35,559 INFO:     Epoch: 18
2022-12-05 19:49:36,346 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4025131470777772, 'Total loss': 0.4025131470777772} | train loss {'Reaction outcome loss': 0.22437372625718716, 'Total loss': 0.22437372625718716}
2022-12-05 19:49:36,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:36,346 INFO:     Epoch: 19
2022-12-05 19:49:37,133 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4014500328762965, 'Total loss': 0.4014500328762965} | train loss {'Reaction outcome loss': 0.22258914756750772, 'Total loss': 0.22258914756750772}
2022-12-05 19:49:37,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:37,133 INFO:     Epoch: 20
2022-12-05 19:49:37,919 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4038361749527129, 'Total loss': 0.4038361749527129} | train loss {'Reaction outcome loss': 0.2211451813095977, 'Total loss': 0.2211451813095977}
2022-12-05 19:49:37,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:37,919 INFO:     Epoch: 21
2022-12-05 19:49:38,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38929224556142633, 'Total loss': 0.38929224556142633} | train loss {'Reaction outcome loss': 0.2104939328622533, 'Total loss': 0.2104939328622533}
2022-12-05 19:49:38,705 INFO:     Found new best model at epoch 21
2022-12-05 19:49:38,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:38,706 INFO:     Epoch: 22
2022-12-05 19:49:39,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3949259140274741, 'Total loss': 0.3949259140274741} | train loss {'Reaction outcome loss': 0.20336789218520346, 'Total loss': 0.20336789218520346}
2022-12-05 19:49:39,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:39,496 INFO:     Epoch: 23
2022-12-05 19:49:40,285 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39206584729254246, 'Total loss': 0.39206584729254246} | train loss {'Reaction outcome loss': 0.20539596919649042, 'Total loss': 0.20539596919649042}
2022-12-05 19:49:40,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:40,285 INFO:     Epoch: 24
2022-12-05 19:49:41,078 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4032687754793601, 'Total loss': 0.4032687754793601} | train loss {'Reaction outcome loss': 0.2033574435546964, 'Total loss': 0.2033574435546964}
2022-12-05 19:49:41,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:41,079 INFO:     Epoch: 25
2022-12-05 19:49:41,871 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39992915161631326, 'Total loss': 0.39992915161631326} | train loss {'Reaction outcome loss': 0.1917042113635675, 'Total loss': 0.1917042113635675}
2022-12-05 19:49:41,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:41,871 INFO:     Epoch: 26
2022-12-05 19:49:42,658 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4015756364573132, 'Total loss': 0.4015756364573132} | train loss {'Reaction outcome loss': 0.18870304373322952, 'Total loss': 0.18870304373322952}
2022-12-05 19:49:42,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:42,658 INFO:     Epoch: 27
2022-12-05 19:49:43,448 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40654205259951676, 'Total loss': 0.40654205259951676} | train loss {'Reaction outcome loss': 0.18674429202252463, 'Total loss': 0.18674429202252463}
2022-12-05 19:49:43,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:43,448 INFO:     Epoch: 28
2022-12-05 19:49:44,234 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4085273729129271, 'Total loss': 0.4085273729129271} | train loss {'Reaction outcome loss': 0.18243336680567698, 'Total loss': 0.18243336680567698}
2022-12-05 19:49:44,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:44,234 INFO:     Epoch: 29
2022-12-05 19:49:45,022 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40293861451474106, 'Total loss': 0.40293861451474106} | train loss {'Reaction outcome loss': 0.1801593417098165, 'Total loss': 0.1801593417098165}
2022-12-05 19:49:45,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:45,022 INFO:     Epoch: 30
2022-12-05 19:49:45,808 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4046751584180377, 'Total loss': 0.4046751584180377} | train loss {'Reaction outcome loss': 0.1778216590494038, 'Total loss': 0.1778216590494038}
2022-12-05 19:49:45,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:45,808 INFO:     Epoch: 31
2022-12-05 19:49:46,596 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3964687358926643, 'Total loss': 0.3964687358926643} | train loss {'Reaction outcome loss': 0.1813368104654647, 'Total loss': 0.1813368104654647}
2022-12-05 19:49:46,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:46,596 INFO:     Epoch: 32
2022-12-05 19:49:47,386 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41293246536092326, 'Total loss': 0.41293246536092326} | train loss {'Reaction outcome loss': 0.18481317406844514, 'Total loss': 0.18481317406844514}
2022-12-05 19:49:47,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:47,386 INFO:     Epoch: 33
2022-12-05 19:49:48,172 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4039245132695545, 'Total loss': 0.4039245132695545} | train loss {'Reaction outcome loss': 0.1712000939829147, 'Total loss': 0.1712000939829147}
2022-12-05 19:49:48,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:48,172 INFO:     Epoch: 34
2022-12-05 19:49:48,958 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4229744795540517, 'Total loss': 0.4229744795540517} | train loss {'Reaction outcome loss': 0.17259962683324873, 'Total loss': 0.17259962683324873}
2022-12-05 19:49:48,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:48,958 INFO:     Epoch: 35
2022-12-05 19:49:49,747 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4300474116409367, 'Total loss': 0.4300474116409367} | train loss {'Reaction outcome loss': 0.17250026886771821, 'Total loss': 0.17250026886771821}
2022-12-05 19:49:49,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:49,747 INFO:     Epoch: 36
2022-12-05 19:49:50,537 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4065585784952749, 'Total loss': 0.4065585784952749} | train loss {'Reaction outcome loss': 0.16457483385074959, 'Total loss': 0.16457483385074959}
2022-12-05 19:49:50,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:50,537 INFO:     Epoch: 37
2022-12-05 19:49:51,326 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4199885312806476, 'Total loss': 0.4199885312806476} | train loss {'Reaction outcome loss': 0.16389124668561494, 'Total loss': 0.16389124668561494}
2022-12-05 19:49:51,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:51,326 INFO:     Epoch: 38
2022-12-05 19:49:52,113 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4316514655947685, 'Total loss': 0.4316514655947685} | train loss {'Reaction outcome loss': 0.16030162115117558, 'Total loss': 0.16030162115117558}
2022-12-05 19:49:52,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:52,113 INFO:     Epoch: 39
2022-12-05 19:49:52,901 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41817203536629677, 'Total loss': 0.41817203536629677} | train loss {'Reaction outcome loss': 0.16094274014736024, 'Total loss': 0.16094274014736024}
2022-12-05 19:49:52,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:52,901 INFO:     Epoch: 40
2022-12-05 19:49:53,691 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42417725785212085, 'Total loss': 0.42417725785212085} | train loss {'Reaction outcome loss': 0.1574996832516874, 'Total loss': 0.1574996832516874}
2022-12-05 19:49:53,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:53,692 INFO:     Epoch: 41
2022-12-05 19:49:54,481 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42196672172708943, 'Total loss': 0.42196672172708943} | train loss {'Reaction outcome loss': 0.15453924941509842, 'Total loss': 0.15453924941509842}
2022-12-05 19:49:54,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:54,482 INFO:     Epoch: 42
2022-12-05 19:49:55,270 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41662536917084997, 'Total loss': 0.41662536917084997} | train loss {'Reaction outcome loss': 0.16017004103976706, 'Total loss': 0.16017004103976706}
2022-12-05 19:49:55,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:55,270 INFO:     Epoch: 43
2022-12-05 19:49:56,057 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40885626135224645, 'Total loss': 0.40885626135224645} | train loss {'Reaction outcome loss': 0.15533144533754842, 'Total loss': 0.15533144533754842}
2022-12-05 19:49:56,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:56,057 INFO:     Epoch: 44
2022-12-05 19:49:56,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41001475433057005, 'Total loss': 0.41001475433057005} | train loss {'Reaction outcome loss': 0.16072369561632455, 'Total loss': 0.16072369561632455}
2022-12-05 19:49:56,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:56,845 INFO:     Epoch: 45
2022-12-05 19:49:57,638 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.410370989956639, 'Total loss': 0.410370989956639} | train loss {'Reaction outcome loss': 0.14829711898075423, 'Total loss': 0.14829711898075423}
2022-12-05 19:49:57,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:57,639 INFO:     Epoch: 46
2022-12-05 19:49:58,428 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4212205216965892, 'Total loss': 0.4212205216965892} | train loss {'Reaction outcome loss': 0.15240233156995975, 'Total loss': 0.15240233156995975}
2022-12-05 19:49:58,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:58,428 INFO:     Epoch: 47
2022-12-05 19:49:59,220 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40854827958074486, 'Total loss': 0.40854827958074486} | train loss {'Reaction outcome loss': 0.15541068156841795, 'Total loss': 0.15541068156841795}
2022-12-05 19:49:59,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:49:59,220 INFO:     Epoch: 48
2022-12-05 19:50:00,007 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4323532913218845, 'Total loss': 0.4323532913218845} | train loss {'Reaction outcome loss': 0.16119971426452703, 'Total loss': 0.16119971426452703}
2022-12-05 19:50:00,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:00,008 INFO:     Epoch: 49
2022-12-05 19:50:00,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4433388881046664, 'Total loss': 0.4433388881046664} | train loss {'Reaction outcome loss': 0.1511936557332152, 'Total loss': 0.1511936557332152}
2022-12-05 19:50:00,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:00,795 INFO:     Epoch: 50
2022-12-05 19:50:01,583 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41572353142228996, 'Total loss': 0.41572353142228996} | train loss {'Reaction outcome loss': 0.15214888858590048, 'Total loss': 0.15214888858590048}
2022-12-05 19:50:01,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:01,583 INFO:     Epoch: 51
2022-12-05 19:50:02,374 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.416300919753584, 'Total loss': 0.416300919753584} | train loss {'Reaction outcome loss': 0.14345292682544544, 'Total loss': 0.14345292682544544}
2022-12-05 19:50:02,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:02,374 INFO:     Epoch: 52
2022-12-05 19:50:03,162 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42365979741920123, 'Total loss': 0.42365979741920123} | train loss {'Reaction outcome loss': 0.14140817440050815, 'Total loss': 0.14140817440050815}
2022-12-05 19:50:03,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:03,162 INFO:     Epoch: 53
2022-12-05 19:50:03,950 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4082167494026097, 'Total loss': 0.4082167494026097} | train loss {'Reaction outcome loss': 0.1434869226968474, 'Total loss': 0.1434869226968474}
2022-12-05 19:50:03,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:03,950 INFO:     Epoch: 54
2022-12-05 19:50:04,741 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43465267054059287, 'Total loss': 0.43465267054059287} | train loss {'Reaction outcome loss': 0.1424932462363108, 'Total loss': 0.1424932462363108}
2022-12-05 19:50:04,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:04,741 INFO:     Epoch: 55
2022-12-05 19:50:05,533 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4322964030910622, 'Total loss': 0.4322964030910622} | train loss {'Reaction outcome loss': 0.14592946601512197, 'Total loss': 0.14592946601512197}
2022-12-05 19:50:05,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:05,534 INFO:     Epoch: 56
2022-12-05 19:50:06,326 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45220111310482025, 'Total loss': 0.45220111310482025} | train loss {'Reaction outcome loss': 0.14024069985970553, 'Total loss': 0.14024069985970553}
2022-12-05 19:50:06,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:06,327 INFO:     Epoch: 57
2022-12-05 19:50:07,124 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4335800041867928, 'Total loss': 0.4335800041867928} | train loss {'Reaction outcome loss': 0.14025816753240838, 'Total loss': 0.14025816753240838}
2022-12-05 19:50:07,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:07,124 INFO:     Epoch: 58
2022-12-05 19:50:07,912 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42844767225059593, 'Total loss': 0.42844767225059593} | train loss {'Reaction outcome loss': 0.13536063274029295, 'Total loss': 0.13536063274029295}
2022-12-05 19:50:07,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:07,912 INFO:     Epoch: 59
2022-12-05 19:50:08,699 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45040675557472487, 'Total loss': 0.45040675557472487} | train loss {'Reaction outcome loss': 0.1377002405858625, 'Total loss': 0.1377002405858625}
2022-12-05 19:50:08,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:08,699 INFO:     Epoch: 60
2022-12-05 19:50:09,488 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4594834660264579, 'Total loss': 0.4594834660264579} | train loss {'Reaction outcome loss': 0.1381951783319958, 'Total loss': 0.1381951783319958}
2022-12-05 19:50:09,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:09,488 INFO:     Epoch: 61
2022-12-05 19:50:10,278 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.434221697632562, 'Total loss': 0.434221697632562} | train loss {'Reaction outcome loss': 0.1376566928603992, 'Total loss': 0.1376566928603992}
2022-12-05 19:50:10,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:10,278 INFO:     Epoch: 62
2022-12-05 19:50:11,067 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42953805151310837, 'Total loss': 0.42953805151310837} | train loss {'Reaction outcome loss': 0.13776039811763685, 'Total loss': 0.13776039811763685}
2022-12-05 19:50:11,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:11,067 INFO:     Epoch: 63
2022-12-05 19:50:11,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4521964906968854, 'Total loss': 0.4521964906968854} | train loss {'Reaction outcome loss': 0.13526720476340548, 'Total loss': 0.13526720476340548}
2022-12-05 19:50:11,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:11,861 INFO:     Epoch: 64
2022-12-05 19:50:12,650 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4393775131214749, 'Total loss': 0.4393775131214749} | train loss {'Reaction outcome loss': 0.1358018867098368, 'Total loss': 0.1358018867098368}
2022-12-05 19:50:12,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:12,650 INFO:     Epoch: 65
2022-12-05 19:50:13,439 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4254639328203418, 'Total loss': 0.4254639328203418} | train loss {'Reaction outcome loss': 0.1313589227344343, 'Total loss': 0.1313589227344343}
2022-12-05 19:50:13,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:13,439 INFO:     Epoch: 66
2022-12-05 19:50:14,227 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4232337908311324, 'Total loss': 0.4232337908311324} | train loss {'Reaction outcome loss': 0.13125983728397533, 'Total loss': 0.13125983728397533}
2022-12-05 19:50:14,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:14,228 INFO:     Epoch: 67
2022-12-05 19:50:15,021 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4489644186740572, 'Total loss': 0.4489644186740572} | train loss {'Reaction outcome loss': 0.13556311148084957, 'Total loss': 0.13556311148084957}
2022-12-05 19:50:15,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:15,021 INFO:     Epoch: 68
2022-12-05 19:50:15,811 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4255428517406637, 'Total loss': 0.4255428517406637} | train loss {'Reaction outcome loss': 0.13095870850464472, 'Total loss': 0.13095870850464472}
2022-12-05 19:50:15,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:15,811 INFO:     Epoch: 69
2022-12-05 19:50:16,601 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4629256122491576, 'Total loss': 0.4629256122491576} | train loss {'Reaction outcome loss': 0.1285295140164101, 'Total loss': 0.1285295140164101}
2022-12-05 19:50:16,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:16,601 INFO:     Epoch: 70
2022-12-05 19:50:17,391 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4309542937712236, 'Total loss': 0.4309542937712236} | train loss {'Reaction outcome loss': 0.1301539579513841, 'Total loss': 0.1301539579513841}
2022-12-05 19:50:17,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:17,391 INFO:     Epoch: 71
2022-12-05 19:50:18,184 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43798926641995256, 'Total loss': 0.43798926641995256} | train loss {'Reaction outcome loss': 0.1309348779168689, 'Total loss': 0.1309348779168689}
2022-12-05 19:50:18,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:18,184 INFO:     Epoch: 72
2022-12-05 19:50:18,976 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.444437807595188, 'Total loss': 0.444437807595188} | train loss {'Reaction outcome loss': 0.13514813721540048, 'Total loss': 0.13514813721540048}
2022-12-05 19:50:18,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:18,976 INFO:     Epoch: 73
2022-12-05 19:50:19,766 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43249625035307626, 'Total loss': 0.43249625035307626} | train loss {'Reaction outcome loss': 0.12959775041961966, 'Total loss': 0.12959775041961966}
2022-12-05 19:50:19,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:19,766 INFO:     Epoch: 74
2022-12-05 19:50:20,557 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41787613758986647, 'Total loss': 0.41787613758986647} | train loss {'Reaction outcome loss': 0.12821220369964295, 'Total loss': 0.12821220369964295}
2022-12-05 19:50:20,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:20,557 INFO:     Epoch: 75
2022-12-05 19:50:21,356 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42955335906960745, 'Total loss': 0.42955335906960745} | train loss {'Reaction outcome loss': 0.12883637473741283, 'Total loss': 0.12883637473741283}
2022-12-05 19:50:21,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:21,356 INFO:     Epoch: 76
2022-12-05 19:50:22,150 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4432840296490626, 'Total loss': 0.4432840296490626} | train loss {'Reaction outcome loss': 0.13260117166596447, 'Total loss': 0.13260117166596447}
2022-12-05 19:50:22,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:22,150 INFO:     Epoch: 77
2022-12-05 19:50:22,949 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4326105121184479, 'Total loss': 0.4326105121184479} | train loss {'Reaction outcome loss': 0.1326810833602118, 'Total loss': 0.1326810833602118}
2022-12-05 19:50:22,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:22,949 INFO:     Epoch: 78
2022-12-05 19:50:23,740 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4227614863352342, 'Total loss': 0.4227614863352342} | train loss {'Reaction outcome loss': 0.12551800387832318, 'Total loss': 0.12551800387832318}
2022-12-05 19:50:23,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:23,741 INFO:     Epoch: 79
2022-12-05 19:50:24,531 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4485449641942978, 'Total loss': 0.4485449641942978} | train loss {'Reaction outcome loss': 0.12524570099753046, 'Total loss': 0.12524570099753046}
2022-12-05 19:50:24,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:24,532 INFO:     Epoch: 80
2022-12-05 19:50:25,327 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4359698217700828, 'Total loss': 0.4359698217700828} | train loss {'Reaction outcome loss': 0.1247838131497451, 'Total loss': 0.1247838131497451}
2022-12-05 19:50:25,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:25,327 INFO:     Epoch: 81
2022-12-05 19:50:26,117 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4347526779906316, 'Total loss': 0.4347526779906316} | train loss {'Reaction outcome loss': 0.12525257311180715, 'Total loss': 0.12525257311180715}
2022-12-05 19:50:26,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:26,117 INFO:     Epoch: 82
2022-12-05 19:50:26,911 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47190154005180707, 'Total loss': 0.47190154005180707} | train loss {'Reaction outcome loss': 0.1252771862122694, 'Total loss': 0.1252771862122694}
2022-12-05 19:50:26,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:26,911 INFO:     Epoch: 83
2022-12-05 19:50:27,707 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.467173211615194, 'Total loss': 0.467173211615194} | train loss {'Reaction outcome loss': 0.12570360640011094, 'Total loss': 0.12570360640011094}
2022-12-05 19:50:27,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:27,707 INFO:     Epoch: 84
2022-12-05 19:50:28,500 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4341268776492639, 'Total loss': 0.4341268776492639} | train loss {'Reaction outcome loss': 0.12871224047080707, 'Total loss': 0.12871224047080707}
2022-12-05 19:50:28,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:28,500 INFO:     Epoch: 85
2022-12-05 19:50:29,293 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4248758706856858, 'Total loss': 0.4248758706856858} | train loss {'Reaction outcome loss': 0.12340499712851818, 'Total loss': 0.12340499712851818}
2022-12-05 19:50:29,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:29,293 INFO:     Epoch: 86
2022-12-05 19:50:30,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44742967188358307, 'Total loss': 0.44742967188358307} | train loss {'Reaction outcome loss': 0.12431673575117279, 'Total loss': 0.12431673575117279}
2022-12-05 19:50:30,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:30,088 INFO:     Epoch: 87
2022-12-05 19:50:30,878 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44231377948414197, 'Total loss': 0.44231377948414197} | train loss {'Reaction outcome loss': 0.12986486890237317, 'Total loss': 0.12986486890237317}
2022-12-05 19:50:30,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:30,878 INFO:     Epoch: 88
2022-12-05 19:50:31,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43199336901307106, 'Total loss': 0.43199336901307106} | train loss {'Reaction outcome loss': 0.12094804797574184, 'Total loss': 0.12094804797574184}
2022-12-05 19:50:31,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:31,671 INFO:     Epoch: 89
2022-12-05 19:50:32,464 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46183959479359066, 'Total loss': 0.46183959479359066} | train loss {'Reaction outcome loss': 0.12294635243774184, 'Total loss': 0.12294635243774184}
2022-12-05 19:50:32,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:32,464 INFO:     Epoch: 90
2022-12-05 19:50:33,256 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4361246248537844, 'Total loss': 0.4361246248537844} | train loss {'Reaction outcome loss': 0.1272789219899578, 'Total loss': 0.1272789219899578}
2022-12-05 19:50:33,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:33,257 INFO:     Epoch: 91
2022-12-05 19:50:34,051 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4480414739386602, 'Total loss': 0.4480414739386602} | train loss {'Reaction outcome loss': 0.1230843954866654, 'Total loss': 0.1230843954866654}
2022-12-05 19:50:34,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:34,051 INFO:     Epoch: 92
2022-12-05 19:50:34,846 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4447592483325438, 'Total loss': 0.4447592483325438} | train loss {'Reaction outcome loss': 0.1240480896839608, 'Total loss': 0.1240480896839608}
2022-12-05 19:50:34,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:34,846 INFO:     Epoch: 93
2022-12-05 19:50:35,639 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4464605281298811, 'Total loss': 0.4464605281298811} | train loss {'Reaction outcome loss': 0.12732640169711731, 'Total loss': 0.12732640169711731}
2022-12-05 19:50:35,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:35,639 INFO:     Epoch: 94
2022-12-05 19:50:36,432 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4168542576107112, 'Total loss': 0.4168542576107112} | train loss {'Reaction outcome loss': 0.13272310533986884, 'Total loss': 0.13272310533986884}
2022-12-05 19:50:36,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:36,434 INFO:     Epoch: 95
2022-12-05 19:50:37,234 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44067808697846805, 'Total loss': 0.44067808697846805} | train loss {'Reaction outcome loss': 0.1212184659633333, 'Total loss': 0.1212184659633333}
2022-12-05 19:50:37,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:37,234 INFO:     Epoch: 96
2022-12-05 19:50:38,039 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4445054607296532, 'Total loss': 0.4445054607296532} | train loss {'Reaction outcome loss': 0.11686748626777668, 'Total loss': 0.11686748626777668}
2022-12-05 19:50:38,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:38,039 INFO:     Epoch: 97
2022-12-05 19:50:38,832 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.450138681652871, 'Total loss': 0.450138681652871} | train loss {'Reaction outcome loss': 0.12116402781263054, 'Total loss': 0.12116402781263054}
2022-12-05 19:50:38,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:38,832 INFO:     Epoch: 98
2022-12-05 19:50:39,626 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4442095279016278, 'Total loss': 0.4442095279016278} | train loss {'Reaction outcome loss': 0.119536064208866, 'Total loss': 0.119536064208866}
2022-12-05 19:50:39,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:39,627 INFO:     Epoch: 99
2022-12-05 19:50:40,419 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4474264688112519, 'Total loss': 0.4474264688112519} | train loss {'Reaction outcome loss': 0.11918518574614274, 'Total loss': 0.11918518574614274}
2022-12-05 19:50:40,419 INFO:     Best model found after epoch 22 of 100.
2022-12-05 19:50:40,419 INFO:   Done with stage: TRAINING
2022-12-05 19:50:40,419 INFO:   Starting stage: EVALUATION
2022-12-05 19:50:40,544 INFO:   Done with stage: EVALUATION
2022-12-05 19:50:40,544 INFO:   Leaving out SEQ value Fold_3
2022-12-05 19:50:40,557 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 19:50:40,557 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:50:41,189 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:50:41,189 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:50:41,256 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:50:41,256 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:50:41,256 INFO:     No hyperparam tuning for this model
2022-12-05 19:50:41,256 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:50:41,256 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:50:41,257 INFO:     None feature selector for col prot
2022-12-05 19:50:41,257 INFO:     None feature selector for col prot
2022-12-05 19:50:41,257 INFO:     None feature selector for col prot
2022-12-05 19:50:41,258 INFO:     None feature selector for col chem
2022-12-05 19:50:41,258 INFO:     None feature selector for col chem
2022-12-05 19:50:41,258 INFO:     None feature selector for col chem
2022-12-05 19:50:41,258 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:50:41,258 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:50:41,260 INFO:     Number of params in model 215821
2022-12-05 19:50:41,263 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:50:41,263 INFO:   Starting stage: TRAINING
2022-12-05 19:50:41,322 INFO:     Val loss before train {'Reaction outcome loss': 1.0200264550918756, 'Total loss': 1.0200264550918756}
2022-12-05 19:50:41,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:41,322 INFO:     Epoch: 0
2022-12-05 19:50:42,106 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5794452747633291, 'Total loss': 0.5794452747633291} | train loss {'Reaction outcome loss': 0.7778257880298818, 'Total loss': 0.7778257880298818}
2022-12-05 19:50:42,107 INFO:     Found new best model at epoch 0
2022-12-05 19:50:42,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:42,107 INFO:     Epoch: 1
2022-12-05 19:50:42,892 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49173268398573233, 'Total loss': 0.49173268398573233} | train loss {'Reaction outcome loss': 0.526437301310848, 'Total loss': 0.526437301310848}
2022-12-05 19:50:42,893 INFO:     Found new best model at epoch 1
2022-12-05 19:50:42,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:42,894 INFO:     Epoch: 2
2022-12-05 19:50:43,679 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4700642470703569, 'Total loss': 0.4700642470703569} | train loss {'Reaction outcome loss': 0.45599259472772724, 'Total loss': 0.45599259472772724}
2022-12-05 19:50:43,679 INFO:     Found new best model at epoch 2
2022-12-05 19:50:43,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:43,680 INFO:     Epoch: 3
2022-12-05 19:50:44,467 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4428988771383153, 'Total loss': 0.4428988771383153} | train loss {'Reaction outcome loss': 0.41884957815780016, 'Total loss': 0.41884957815780016}
2022-12-05 19:50:44,467 INFO:     Found new best model at epoch 3
2022-12-05 19:50:44,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:44,468 INFO:     Epoch: 4
2022-12-05 19:50:45,250 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44240841719993323, 'Total loss': 0.44240841719993323} | train loss {'Reaction outcome loss': 0.3905278559102387, 'Total loss': 0.3905278559102387}
2022-12-05 19:50:45,250 INFO:     Found new best model at epoch 4
2022-12-05 19:50:45,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:45,251 INFO:     Epoch: 5
2022-12-05 19:50:46,038 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42661963957686755, 'Total loss': 0.42661963957686755} | train loss {'Reaction outcome loss': 0.3671819948148532, 'Total loss': 0.3671819948148532}
2022-12-05 19:50:46,039 INFO:     Found new best model at epoch 5
2022-12-05 19:50:46,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:46,040 INFO:     Epoch: 6
2022-12-05 19:50:46,831 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41842949494372966, 'Total loss': 0.41842949494372966} | train loss {'Reaction outcome loss': 0.3496475346142151, 'Total loss': 0.3496475346142151}
2022-12-05 19:50:46,832 INFO:     Found new best model at epoch 6
2022-12-05 19:50:46,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:46,832 INFO:     Epoch: 7
2022-12-05 19:50:47,615 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4278354072986647, 'Total loss': 0.4278354072986647} | train loss {'Reaction outcome loss': 0.33200158621566217, 'Total loss': 0.33200158621566217}
2022-12-05 19:50:47,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:47,615 INFO:     Epoch: 8
2022-12-05 19:50:48,398 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43066271585087446, 'Total loss': 0.43066271585087446} | train loss {'Reaction outcome loss': 0.3170382475602578, 'Total loss': 0.3170382475602578}
2022-12-05 19:50:48,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:48,398 INFO:     Epoch: 9
2022-12-05 19:50:49,182 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41902698749719663, 'Total loss': 0.41902698749719663} | train loss {'Reaction outcome loss': 0.30128693449326227, 'Total loss': 0.30128693449326227}
2022-12-05 19:50:49,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:49,183 INFO:     Epoch: 10
2022-12-05 19:50:49,970 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42006286701490714, 'Total loss': 0.42006286701490714} | train loss {'Reaction outcome loss': 0.2935053735482888, 'Total loss': 0.2935053735482888}
2022-12-05 19:50:49,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:49,970 INFO:     Epoch: 11
2022-12-05 19:50:50,764 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42049639446790826, 'Total loss': 0.42049639446790826} | train loss {'Reaction outcome loss': 0.2823421247914189, 'Total loss': 0.2823421247914189}
2022-12-05 19:50:50,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:50,764 INFO:     Epoch: 12
2022-12-05 19:50:51,548 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4193890822488208, 'Total loss': 0.4193890822488208} | train loss {'Reaction outcome loss': 0.26845561111437494, 'Total loss': 0.26845561111437494}
2022-12-05 19:50:51,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:51,548 INFO:     Epoch: 13
2022-12-05 19:50:52,332 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42325352270935857, 'Total loss': 0.42325352270935857} | train loss {'Reaction outcome loss': 0.26183860593276925, 'Total loss': 0.26183860593276925}
2022-12-05 19:50:52,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:52,332 INFO:     Epoch: 14
2022-12-05 19:50:53,119 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4192247927881951, 'Total loss': 0.4192247927881951} | train loss {'Reaction outcome loss': 0.2529182962645761, 'Total loss': 0.2529182962645761}
2022-12-05 19:50:53,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:53,119 INFO:     Epoch: 15
2022-12-05 19:50:53,905 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42133974266606705, 'Total loss': 0.42133974266606705} | train loss {'Reaction outcome loss': 0.24463558587871614, 'Total loss': 0.24463558587871614}
2022-12-05 19:50:53,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:53,905 INFO:     Epoch: 16
2022-12-05 19:50:54,687 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4202741582033246, 'Total loss': 0.4202741582033246} | train loss {'Reaction outcome loss': 0.24013166282264914, 'Total loss': 0.24013166282264914}
2022-12-05 19:50:54,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:54,687 INFO:     Epoch: 17
2022-12-05 19:50:55,476 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41180584077225174, 'Total loss': 0.41180584077225174} | train loss {'Reaction outcome loss': 0.23267820195035369, 'Total loss': 0.23267820195035369}
2022-12-05 19:50:55,477 INFO:     Found new best model at epoch 17
2022-12-05 19:50:55,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:55,478 INFO:     Epoch: 18
2022-12-05 19:50:56,274 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4378271899944128, 'Total loss': 0.4378271899944128} | train loss {'Reaction outcome loss': 0.2262522917943167, 'Total loss': 0.2262522917943167}
2022-12-05 19:50:56,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:56,274 INFO:     Epoch: 19
2022-12-05 19:50:57,065 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4329918494751287, 'Total loss': 0.4329918494751287} | train loss {'Reaction outcome loss': 0.22333323908206382, 'Total loss': 0.22333323908206382}
2022-12-05 19:50:57,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:57,065 INFO:     Epoch: 20
2022-12-05 19:50:57,856 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.434872743002204, 'Total loss': 0.434872743002204} | train loss {'Reaction outcome loss': 0.21573890533420395, 'Total loss': 0.21573890533420395}
2022-12-05 19:50:57,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:57,856 INFO:     Epoch: 21
2022-12-05 19:50:58,647 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4211779740140882, 'Total loss': 0.4211779740140882} | train loss {'Reaction outcome loss': 0.21151898263907823, 'Total loss': 0.21151898263907823}
2022-12-05 19:50:58,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:58,647 INFO:     Epoch: 22
2022-12-05 19:50:59,433 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43574580654155376, 'Total loss': 0.43574580654155376} | train loss {'Reaction outcome loss': 0.20704141717984295, 'Total loss': 0.20704141717984295}
2022-12-05 19:50:59,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:50:59,433 INFO:     Epoch: 23
2022-12-05 19:51:00,216 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43537128231553146, 'Total loss': 0.43537128231553146} | train loss {'Reaction outcome loss': 0.2035299642240537, 'Total loss': 0.2035299642240537}
2022-12-05 19:51:00,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:00,216 INFO:     Epoch: 24
2022-12-05 19:51:00,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.432188643272533, 'Total loss': 0.432188643272533} | train loss {'Reaction outcome loss': 0.19818258260330948, 'Total loss': 0.19818258260330948}
2022-12-05 19:51:00,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:00,996 INFO:     Epoch: 25
2022-12-05 19:51:01,777 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43142554337202116, 'Total loss': 0.43142554337202116} | train loss {'Reaction outcome loss': 0.1936628121088763, 'Total loss': 0.1936628121088763}
2022-12-05 19:51:01,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:01,777 INFO:     Epoch: 26
2022-12-05 19:51:02,564 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45258141742196195, 'Total loss': 0.45258141742196195} | train loss {'Reaction outcome loss': 0.18966149834183152, 'Total loss': 0.18966149834183152}
2022-12-05 19:51:02,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:02,564 INFO:     Epoch: 27
2022-12-05 19:51:03,348 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4264817847761997, 'Total loss': 0.4264817847761997} | train loss {'Reaction outcome loss': 0.18411319144833527, 'Total loss': 0.18411319144833527}
2022-12-05 19:51:03,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:03,348 INFO:     Epoch: 28
2022-12-05 19:51:04,133 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43757714677688686, 'Total loss': 0.43757714677688686} | train loss {'Reaction outcome loss': 0.17986567290194455, 'Total loss': 0.17986567290194455}
2022-12-05 19:51:04,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:04,133 INFO:     Epoch: 29
2022-12-05 19:51:04,916 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4413390818030335, 'Total loss': 0.4413390818030335} | train loss {'Reaction outcome loss': 0.1798967645488313, 'Total loss': 0.1798967645488313}
2022-12-05 19:51:04,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:04,916 INFO:     Epoch: 30
2022-12-05 19:51:05,696 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44646079907583636, 'Total loss': 0.44646079907583636} | train loss {'Reaction outcome loss': 0.17474672316619363, 'Total loss': 0.17474672316619363}
2022-12-05 19:51:05,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:05,696 INFO:     Epoch: 31
2022-12-05 19:51:06,479 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43394453373066216, 'Total loss': 0.43394453373066216} | train loss {'Reaction outcome loss': 0.17397582570671058, 'Total loss': 0.17397582570671058}
2022-12-05 19:51:06,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:06,480 INFO:     Epoch: 32
2022-12-05 19:51:07,266 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4480188253313996, 'Total loss': 0.4480188253313996} | train loss {'Reaction outcome loss': 0.1688330796104474, 'Total loss': 0.1688330796104474}
2022-12-05 19:51:07,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:07,267 INFO:     Epoch: 33
2022-12-05 19:51:08,054 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44517005988678265, 'Total loss': 0.44517005988678265} | train loss {'Reaction outcome loss': 0.16699343660205115, 'Total loss': 0.16699343660205115}
2022-12-05 19:51:08,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:08,055 INFO:     Epoch: 34
2022-12-05 19:51:08,839 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4449906661066898, 'Total loss': 0.4449906661066898} | train loss {'Reaction outcome loss': 0.167183083176735, 'Total loss': 0.167183083176735}
2022-12-05 19:51:08,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:08,839 INFO:     Epoch: 35
2022-12-05 19:51:09,623 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43824070553446925, 'Total loss': 0.43824070553446925} | train loss {'Reaction outcome loss': 0.16147146043444022, 'Total loss': 0.16147146043444022}
2022-12-05 19:51:09,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:09,623 INFO:     Epoch: 36
2022-12-05 19:51:10,407 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4475938206495241, 'Total loss': 0.4475938206495241} | train loss {'Reaction outcome loss': 0.16016619875416405, 'Total loss': 0.16016619875416405}
2022-12-05 19:51:10,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:10,407 INFO:     Epoch: 37
2022-12-05 19:51:11,195 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4408279570729233, 'Total loss': 0.4408279570729233} | train loss {'Reaction outcome loss': 0.15718162623539444, 'Total loss': 0.15718162623539444}
2022-12-05 19:51:11,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:11,195 INFO:     Epoch: 38
2022-12-05 19:51:11,980 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43404348974311074, 'Total loss': 0.43404348974311074} | train loss {'Reaction outcome loss': 0.15624582172814208, 'Total loss': 0.15624582172814208}
2022-12-05 19:51:11,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:11,981 INFO:     Epoch: 39
2022-12-05 19:51:12,767 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4354978442885155, 'Total loss': 0.4354978442885155} | train loss {'Reaction outcome loss': 0.1534301930595739, 'Total loss': 0.1534301930595739}
2022-12-05 19:51:12,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:12,767 INFO:     Epoch: 40
2022-12-05 19:51:13,548 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4406150326479313, 'Total loss': 0.4406150326479313} | train loss {'Reaction outcome loss': 0.15365629711142573, 'Total loss': 0.15365629711142573}
2022-12-05 19:51:13,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:13,549 INFO:     Epoch: 41
2022-12-05 19:51:14,333 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4361519304125808, 'Total loss': 0.4361519304125808} | train loss {'Reaction outcome loss': 0.14862920738542912, 'Total loss': 0.14862920738542912}
2022-12-05 19:51:14,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:14,334 INFO:     Epoch: 42
2022-12-05 19:51:15,120 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4480499756890674, 'Total loss': 0.4480499756890674} | train loss {'Reaction outcome loss': 0.14963371413912563, 'Total loss': 0.14963371413912563}
2022-12-05 19:51:15,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:15,120 INFO:     Epoch: 43
2022-12-05 19:51:15,904 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4516751121642978, 'Total loss': 0.4516751121642978} | train loss {'Reaction outcome loss': 0.15031842192344855, 'Total loss': 0.15031842192344855}
2022-12-05 19:51:15,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:15,904 INFO:     Epoch: 44
2022-12-05 19:51:16,689 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44968783569543863, 'Total loss': 0.44968783569543863} | train loss {'Reaction outcome loss': 0.14528183427593502, 'Total loss': 0.14528183427593502}
2022-12-05 19:51:16,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:16,689 INFO:     Epoch: 45
2022-12-05 19:51:17,474 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4373534981941068, 'Total loss': 0.4373534981941068} | train loss {'Reaction outcome loss': 0.1428694885642054, 'Total loss': 0.1428694885642054}
2022-12-05 19:51:17,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:17,474 INFO:     Epoch: 46
2022-12-05 19:51:18,256 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4449540418247844, 'Total loss': 0.4449540418247844} | train loss {'Reaction outcome loss': 0.14147436144746472, 'Total loss': 0.14147436144746472}
2022-12-05 19:51:18,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:18,257 INFO:     Epoch: 47
2022-12-05 19:51:19,040 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4570173673158468, 'Total loss': 0.4570173673158468} | train loss {'Reaction outcome loss': 0.14214426142041434, 'Total loss': 0.14214426142041434}
2022-12-05 19:51:19,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:19,040 INFO:     Epoch: 48
2022-12-05 19:51:19,827 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4482732200345328, 'Total loss': 0.4482732200345328} | train loss {'Reaction outcome loss': 0.14188447934728055, 'Total loss': 0.14188447934728055}
2022-12-05 19:51:19,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:19,827 INFO:     Epoch: 49
2022-12-05 19:51:20,612 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4545530260995377, 'Total loss': 0.4545530260995377} | train loss {'Reaction outcome loss': 0.1393877694337461, 'Total loss': 0.1393877694337461}
2022-12-05 19:51:20,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:20,613 INFO:     Epoch: 50
2022-12-05 19:51:21,395 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4426573695138443, 'Total loss': 0.4426573695138443} | train loss {'Reaction outcome loss': 0.1394340376003233, 'Total loss': 0.1394340376003233}
2022-12-05 19:51:21,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:21,395 INFO:     Epoch: 51
2022-12-05 19:51:22,181 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4606941137896028, 'Total loss': 0.4606941137896028} | train loss {'Reaction outcome loss': 0.13804054851491065, 'Total loss': 0.13804054851491065}
2022-12-05 19:51:22,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:22,181 INFO:     Epoch: 52
2022-12-05 19:51:22,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4548432646795761, 'Total loss': 0.4548432646795761} | train loss {'Reaction outcome loss': 0.1360610008934421, 'Total loss': 0.1360610008934421}
2022-12-05 19:51:22,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:22,965 INFO:     Epoch: 53
2022-12-05 19:51:23,747 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45308092964249985, 'Total loss': 0.45308092964249985} | train loss {'Reaction outcome loss': 0.13355006219162682, 'Total loss': 0.13355006219162682}
2022-12-05 19:51:23,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:23,748 INFO:     Epoch: 54
2022-12-05 19:51:24,534 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4400661358999651, 'Total loss': 0.4400661358999651} | train loss {'Reaction outcome loss': 0.1325001674398902, 'Total loss': 0.1325001674398902}
2022-12-05 19:51:24,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:24,534 INFO:     Epoch: 55
2022-12-05 19:51:25,328 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44770040726938914, 'Total loss': 0.44770040726938914} | train loss {'Reaction outcome loss': 0.1350951313468643, 'Total loss': 0.1350951313468643}
2022-12-05 19:51:25,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:25,329 INFO:     Epoch: 56
2022-12-05 19:51:26,114 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4452686922321486, 'Total loss': 0.4452686922321486} | train loss {'Reaction outcome loss': 0.13105427892496962, 'Total loss': 0.13105427892496962}
2022-12-05 19:51:26,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:26,115 INFO:     Epoch: 57
2022-12-05 19:51:26,901 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.440300612602123, 'Total loss': 0.440300612602123} | train loss {'Reaction outcome loss': 0.12896682622796687, 'Total loss': 0.12896682622796687}
2022-12-05 19:51:26,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:26,901 INFO:     Epoch: 58
2022-12-05 19:51:27,685 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44521869649720747, 'Total loss': 0.44521869649720747} | train loss {'Reaction outcome loss': 0.12876594858244061, 'Total loss': 0.12876594858244061}
2022-12-05 19:51:27,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:27,686 INFO:     Epoch: 59
2022-12-05 19:51:28,475 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4430046064216037, 'Total loss': 0.4430046064216037} | train loss {'Reaction outcome loss': 0.1284459802459498, 'Total loss': 0.1284459802459498}
2022-12-05 19:51:28,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:28,476 INFO:     Epoch: 60
2022-12-05 19:51:29,271 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4547379075787788, 'Total loss': 0.4547379075787788} | train loss {'Reaction outcome loss': 0.12736531223368938, 'Total loss': 0.12736531223368938}
2022-12-05 19:51:29,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:29,272 INFO:     Epoch: 61
2022-12-05 19:51:30,060 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4535736339383347, 'Total loss': 0.4535736339383347} | train loss {'Reaction outcome loss': 0.1264401592512722, 'Total loss': 0.1264401592512722}
2022-12-05 19:51:30,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:30,060 INFO:     Epoch: 62
2022-12-05 19:51:30,842 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.438466836200204, 'Total loss': 0.438466836200204} | train loss {'Reaction outcome loss': 0.12889684809249688, 'Total loss': 0.12889684809249688}
2022-12-05 19:51:30,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:30,843 INFO:     Epoch: 63
2022-12-05 19:51:31,626 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4577640485624934, 'Total loss': 0.4577640485624934} | train loss {'Reaction outcome loss': 0.12624890567566893, 'Total loss': 0.12624890567566893}
2022-12-05 19:51:31,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:31,626 INFO:     Epoch: 64
2022-12-05 19:51:32,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43919805385345634, 'Total loss': 0.43919805385345634} | train loss {'Reaction outcome loss': 0.12460225002198923, 'Total loss': 0.12460225002198923}
2022-12-05 19:51:32,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:32,409 INFO:     Epoch: 65
2022-12-05 19:51:33,194 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4504551457804303, 'Total loss': 0.4504551457804303} | train loss {'Reaction outcome loss': 0.12396945904360199, 'Total loss': 0.12396945904360199}
2022-12-05 19:51:33,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:33,194 INFO:     Epoch: 66
2022-12-05 19:51:33,980 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.456597970322121, 'Total loss': 0.456597970322121} | train loss {'Reaction outcome loss': 0.12204339859060577, 'Total loss': 0.12204339859060577}
2022-12-05 19:51:33,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:33,980 INFO:     Epoch: 67
2022-12-05 19:51:34,766 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44640238721703374, 'Total loss': 0.44640238721703374} | train loss {'Reaction outcome loss': 0.1236805939917132, 'Total loss': 0.1236805939917132}
2022-12-05 19:51:34,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:34,766 INFO:     Epoch: 68
2022-12-05 19:51:35,550 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45786078308903894, 'Total loss': 0.45786078308903894} | train loss {'Reaction outcome loss': 0.12369852840182845, 'Total loss': 0.12369852840182845}
2022-12-05 19:51:35,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:35,551 INFO:     Epoch: 69
2022-12-05 19:51:36,339 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44482375404169394, 'Total loss': 0.44482375404169394} | train loss {'Reaction outcome loss': 0.12558826403005324, 'Total loss': 0.12558826403005324}
2022-12-05 19:51:36,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:36,339 INFO:     Epoch: 70
2022-12-05 19:51:37,127 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4642228636630746, 'Total loss': 0.4642228636630746} | train loss {'Reaction outcome loss': 0.1207533981422054, 'Total loss': 0.1207533981422054}
2022-12-05 19:51:37,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:37,127 INFO:     Epoch: 71
2022-12-05 19:51:37,912 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4511530458234077, 'Total loss': 0.4511530458234077} | train loss {'Reaction outcome loss': 0.12216707411771793, 'Total loss': 0.12216707411771793}
2022-12-05 19:51:37,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:37,912 INFO:     Epoch: 72
2022-12-05 19:51:38,697 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4574382090291312, 'Total loss': 0.4574382090291312} | train loss {'Reaction outcome loss': 0.1219950971292851, 'Total loss': 0.1219950971292851}
2022-12-05 19:51:38,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:38,698 INFO:     Epoch: 73
2022-12-05 19:51:39,490 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4397639282221018, 'Total loss': 0.4397639282221018} | train loss {'Reaction outcome loss': 0.11813321138625263, 'Total loss': 0.11813321138625263}
2022-12-05 19:51:39,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:39,490 INFO:     Epoch: 74
2022-12-05 19:51:40,279 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44483283110136207, 'Total loss': 0.44483283110136207} | train loss {'Reaction outcome loss': 0.11907264598278848, 'Total loss': 0.11907264598278848}
2022-12-05 19:51:40,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:40,279 INFO:     Epoch: 75
2022-12-05 19:51:41,069 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45346655263457186, 'Total loss': 0.45346655263457186} | train loss {'Reaction outcome loss': 0.11933700521247553, 'Total loss': 0.11933700521247553}
2022-12-05 19:51:41,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:41,069 INFO:     Epoch: 76
2022-12-05 19:51:41,860 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44671562521956687, 'Total loss': 0.44671562521956687} | train loss {'Reaction outcome loss': 0.12044098457993298, 'Total loss': 0.12044098457993298}
2022-12-05 19:51:41,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:41,860 INFO:     Epoch: 77
2022-12-05 19:51:42,651 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45058079999546674, 'Total loss': 0.45058079999546674} | train loss {'Reaction outcome loss': 0.11724680035420862, 'Total loss': 0.11724680035420862}
2022-12-05 19:51:42,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:42,651 INFO:     Epoch: 78
2022-12-05 19:51:43,439 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4587927050022192, 'Total loss': 0.4587927050022192} | train loss {'Reaction outcome loss': 0.11453842513690718, 'Total loss': 0.11453842513690718}
2022-12-05 19:51:43,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:43,440 INFO:     Epoch: 79
2022-12-05 19:51:44,232 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45318441993968434, 'Total loss': 0.45318441993968434} | train loss {'Reaction outcome loss': 0.11600214155528267, 'Total loss': 0.11600214155528267}
2022-12-05 19:51:44,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:44,232 INFO:     Epoch: 80
2022-12-05 19:51:45,023 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44197855369989264, 'Total loss': 0.44197855369989264} | train loss {'Reaction outcome loss': 0.11737267915006788, 'Total loss': 0.11737267915006788}
2022-12-05 19:51:45,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:45,024 INFO:     Epoch: 81
2022-12-05 19:51:45,812 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4426085720228594, 'Total loss': 0.4426085720228594} | train loss {'Reaction outcome loss': 0.11751602784936606, 'Total loss': 0.11751602784936606}
2022-12-05 19:51:45,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:45,812 INFO:     Epoch: 82
2022-12-05 19:51:46,596 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44049549241398656, 'Total loss': 0.44049549241398656} | train loss {'Reaction outcome loss': 0.11531254592672234, 'Total loss': 0.11531254592672234}
2022-12-05 19:51:46,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:46,596 INFO:     Epoch: 83
2022-12-05 19:51:47,378 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45132807035778844, 'Total loss': 0.45132807035778844} | train loss {'Reaction outcome loss': 0.11413695701382688, 'Total loss': 0.11413695701382688}
2022-12-05 19:51:47,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:47,378 INFO:     Epoch: 84
2022-12-05 19:51:48,161 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4444450412032216, 'Total loss': 0.4444450412032216} | train loss {'Reaction outcome loss': 0.11598260742306832, 'Total loss': 0.11598260742306832}
2022-12-05 19:51:48,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:48,161 INFO:     Epoch: 85
2022-12-05 19:51:48,947 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4391563070374866, 'Total loss': 0.4391563070374866} | train loss {'Reaction outcome loss': 0.11470776063878639, 'Total loss': 0.11470776063878639}
2022-12-05 19:51:48,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:48,947 INFO:     Epoch: 86
2022-12-05 19:51:49,735 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4573108131109282, 'Total loss': 0.4573108131109282} | train loss {'Reaction outcome loss': 0.11274184895007582, 'Total loss': 0.11274184895007582}
2022-12-05 19:51:49,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:49,735 INFO:     Epoch: 87
2022-12-05 19:51:50,526 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4439968938051268, 'Total loss': 0.4439968938051268} | train loss {'Reaction outcome loss': 0.11271085021406656, 'Total loss': 0.11271085021406656}
2022-12-05 19:51:50,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:50,526 INFO:     Epoch: 88
2022-12-05 19:51:51,314 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43827675438897556, 'Total loss': 0.43827675438897556} | train loss {'Reaction outcome loss': 0.11207273085296277, 'Total loss': 0.11207273085296277}
2022-12-05 19:51:51,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:51,315 INFO:     Epoch: 89
2022-12-05 19:51:52,101 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4488162630519202, 'Total loss': 0.4488162630519202} | train loss {'Reaction outcome loss': 0.11521321179375785, 'Total loss': 0.11521321179375785}
2022-12-05 19:51:52,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:52,102 INFO:     Epoch: 90
2022-12-05 19:51:52,891 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4494189893783525, 'Total loss': 0.4494189893783525} | train loss {'Reaction outcome loss': 0.11342144868962589, 'Total loss': 0.11342144868962589}
2022-12-05 19:51:52,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:52,891 INFO:     Epoch: 91
2022-12-05 19:51:53,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44264967670274336, 'Total loss': 0.44264967670274336} | train loss {'Reaction outcome loss': 0.11266226736355389, 'Total loss': 0.11266226736355389}
2022-12-05 19:51:53,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:53,679 INFO:     Epoch: 92
2022-12-05 19:51:54,466 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4419199255143487, 'Total loss': 0.4419199255143487} | train loss {'Reaction outcome loss': 0.11292187400070615, 'Total loss': 0.11292187400070615}
2022-12-05 19:51:54,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:54,467 INFO:     Epoch: 93
2022-12-05 19:51:55,254 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4510432793650516, 'Total loss': 0.4510432793650516} | train loss {'Reaction outcome loss': 0.11359590949246386, 'Total loss': 0.11359590949246386}
2022-12-05 19:51:55,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:55,254 INFO:     Epoch: 94
2022-12-05 19:51:56,038 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46007014984308287, 'Total loss': 0.46007014984308287} | train loss {'Reaction outcome loss': 0.11327349515555457, 'Total loss': 0.11327349515555457}
2022-12-05 19:51:56,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:56,038 INFO:     Epoch: 95
2022-12-05 19:51:56,822 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4372820375963699, 'Total loss': 0.4372820375963699} | train loss {'Reaction outcome loss': 0.11299484913985504, 'Total loss': 0.11299484913985504}
2022-12-05 19:51:56,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:56,822 INFO:     Epoch: 96
2022-12-05 19:51:57,605 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44611475530058836, 'Total loss': 0.44611475530058836} | train loss {'Reaction outcome loss': 0.10833050150683791, 'Total loss': 0.10833050150683791}
2022-12-05 19:51:57,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:57,606 INFO:     Epoch: 97
2022-12-05 19:51:58,388 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4458650270866793, 'Total loss': 0.4458650270866793} | train loss {'Reaction outcome loss': 0.11165773673517415, 'Total loss': 0.11165773673517415}
2022-12-05 19:51:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:58,388 INFO:     Epoch: 98
2022-12-05 19:51:59,179 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4424794976447904, 'Total loss': 0.4424794976447904} | train loss {'Reaction outcome loss': 0.1105990383743507, 'Total loss': 0.1105990383743507}
2022-12-05 19:51:59,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:51:59,179 INFO:     Epoch: 99
2022-12-05 19:51:59,960 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44511189640954485, 'Total loss': 0.44511189640954485} | train loss {'Reaction outcome loss': 0.11017669407177533, 'Total loss': 0.11017669407177533}
2022-12-05 19:51:59,961 INFO:     Best model found after epoch 18 of 100.
2022-12-05 19:51:59,961 INFO:   Done with stage: TRAINING
2022-12-05 19:51:59,961 INFO:   Starting stage: EVALUATION
2022-12-05 19:52:00,098 INFO:   Done with stage: EVALUATION
2022-12-05 19:52:00,098 INFO:   Leaving out SEQ value Fold_4
2022-12-05 19:52:00,111 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:52:00,111 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:52:00,755 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:52:00,755 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:52:00,824 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:52:00,824 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:52:00,824 INFO:     No hyperparam tuning for this model
2022-12-05 19:52:00,824 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:52:00,824 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:52:00,825 INFO:     None feature selector for col prot
2022-12-05 19:52:00,825 INFO:     None feature selector for col prot
2022-12-05 19:52:00,825 INFO:     None feature selector for col prot
2022-12-05 19:52:00,826 INFO:     None feature selector for col chem
2022-12-05 19:52:00,826 INFO:     None feature selector for col chem
2022-12-05 19:52:00,826 INFO:     None feature selector for col chem
2022-12-05 19:52:00,826 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:52:00,826 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:52:00,828 INFO:     Number of params in model 215821
2022-12-05 19:52:00,831 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:52:00,831 INFO:   Starting stage: TRAINING
2022-12-05 19:52:00,892 INFO:     Val loss before train {'Reaction outcome loss': 0.9906587085940621, 'Total loss': 0.9906587085940621}
2022-12-05 19:52:00,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:00,892 INFO:     Epoch: 0
2022-12-05 19:52:01,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6220374303785238, 'Total loss': 0.6220374303785238} | train loss {'Reaction outcome loss': 0.8129882999966221, 'Total loss': 0.8129882999966221}
2022-12-05 19:52:01,698 INFO:     Found new best model at epoch 0
2022-12-05 19:52:01,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:01,699 INFO:     Epoch: 1
2022-12-05 19:52:02,498 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5440908413041722, 'Total loss': 0.5440908413041722} | train loss {'Reaction outcome loss': 0.5598271358758211, 'Total loss': 0.5598271358758211}
2022-12-05 19:52:02,499 INFO:     Found new best model at epoch 1
2022-12-05 19:52:02,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:02,499 INFO:     Epoch: 2
2022-12-05 19:52:03,300 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5060233321379531, 'Total loss': 0.5060233321379531} | train loss {'Reaction outcome loss': 0.48720682845000296, 'Total loss': 0.48720682845000296}
2022-12-05 19:52:03,300 INFO:     Found new best model at epoch 2
2022-12-05 19:52:03,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:03,301 INFO:     Epoch: 3
2022-12-05 19:52:04,100 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47989546778527176, 'Total loss': 0.47989546778527176} | train loss {'Reaction outcome loss': 0.44436071734995614, 'Total loss': 0.44436071734995614}
2022-12-05 19:52:04,100 INFO:     Found new best model at epoch 3
2022-12-05 19:52:04,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:04,101 INFO:     Epoch: 4
2022-12-05 19:52:04,894 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46061836487867613, 'Total loss': 0.46061836487867613} | train loss {'Reaction outcome loss': 0.41582783119332406, 'Total loss': 0.41582783119332406}
2022-12-05 19:52:04,894 INFO:     Found new best model at epoch 4
2022-12-05 19:52:04,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:04,895 INFO:     Epoch: 5
2022-12-05 19:52:05,690 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4359874559397047, 'Total loss': 0.4359874559397047} | train loss {'Reaction outcome loss': 0.3880656517801746, 'Total loss': 0.3880656517801746}
2022-12-05 19:52:05,690 INFO:     Found new best model at epoch 5
2022-12-05 19:52:05,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:05,691 INFO:     Epoch: 6
2022-12-05 19:52:06,486 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44300632483579894, 'Total loss': 0.44300632483579894} | train loss {'Reaction outcome loss': 0.3681656983230383, 'Total loss': 0.3681656983230383}
2022-12-05 19:52:06,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:06,486 INFO:     Epoch: 7
2022-12-05 19:52:07,279 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42406919632445683, 'Total loss': 0.42406919632445683} | train loss {'Reaction outcome loss': 0.3522504328059093, 'Total loss': 0.3522504328059093}
2022-12-05 19:52:07,279 INFO:     Found new best model at epoch 7
2022-12-05 19:52:07,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:07,280 INFO:     Epoch: 8
2022-12-05 19:52:08,073 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42742622406645253, 'Total loss': 0.42742622406645253} | train loss {'Reaction outcome loss': 0.3329591216339219, 'Total loss': 0.3329591216339219}
2022-12-05 19:52:08,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:08,073 INFO:     Epoch: 9
2022-12-05 19:52:08,866 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41347550736232236, 'Total loss': 0.41347550736232236} | train loss {'Reaction outcome loss': 0.32025181877637104, 'Total loss': 0.32025181877637104}
2022-12-05 19:52:08,866 INFO:     Found new best model at epoch 9
2022-12-05 19:52:08,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:08,867 INFO:     Epoch: 10
2022-12-05 19:52:09,664 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42610419541597366, 'Total loss': 0.42610419541597366} | train loss {'Reaction outcome loss': 0.30386280755121864, 'Total loss': 0.30386280755121864}
2022-12-05 19:52:09,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:09,665 INFO:     Epoch: 11
2022-12-05 19:52:10,458 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42373620481653645, 'Total loss': 0.42373620481653645} | train loss {'Reaction outcome loss': 0.29350043508795, 'Total loss': 0.29350043508795}
2022-12-05 19:52:10,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:10,458 INFO:     Epoch: 12
2022-12-05 19:52:11,252 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41029132665558293, 'Total loss': 0.41029132665558293} | train loss {'Reaction outcome loss': 0.28412631556632056, 'Total loss': 0.28412631556632056}
2022-12-05 19:52:11,252 INFO:     Found new best model at epoch 12
2022-12-05 19:52:11,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:11,253 INFO:     Epoch: 13
2022-12-05 19:52:12,046 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4190589761869474, 'Total loss': 0.4190589761869474} | train loss {'Reaction outcome loss': 0.27494547828551263, 'Total loss': 0.27494547828551263}
2022-12-05 19:52:12,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:12,046 INFO:     Epoch: 14
2022-12-05 19:52:12,841 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41237847168337216, 'Total loss': 0.41237847168337216} | train loss {'Reaction outcome loss': 0.2653465130096001, 'Total loss': 0.2653465130096001}
2022-12-05 19:52:12,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:12,842 INFO:     Epoch: 15
2022-12-05 19:52:13,640 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4226660020649433, 'Total loss': 0.4226660020649433} | train loss {'Reaction outcome loss': 0.2543845837334952, 'Total loss': 0.2543845837334952}
2022-12-05 19:52:13,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:13,640 INFO:     Epoch: 16
2022-12-05 19:52:14,440 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40643243423917075, 'Total loss': 0.40643243423917075} | train loss {'Reaction outcome loss': 0.24745569678564225, 'Total loss': 0.24745569678564225}
2022-12-05 19:52:14,440 INFO:     Found new best model at epoch 16
2022-12-05 19:52:14,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:14,441 INFO:     Epoch: 17
2022-12-05 19:52:15,238 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4244167777624997, 'Total loss': 0.4244167777624997} | train loss {'Reaction outcome loss': 0.24119617204151808, 'Total loss': 0.24119617204151808}
2022-12-05 19:52:15,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:15,238 INFO:     Epoch: 18
2022-12-05 19:52:16,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40888141095638275, 'Total loss': 0.40888141095638275} | train loss {'Reaction outcome loss': 0.23207806255067548, 'Total loss': 0.23207806255067548}
2022-12-05 19:52:16,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:16,036 INFO:     Epoch: 19
2022-12-05 19:52:16,829 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41356770592657005, 'Total loss': 0.41356770592657005} | train loss {'Reaction outcome loss': 0.2298836611031044, 'Total loss': 0.2298836611031044}
2022-12-05 19:52:16,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:16,829 INFO:     Epoch: 20
2022-12-05 19:52:17,627 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4200910431417552, 'Total loss': 0.4200910431417552} | train loss {'Reaction outcome loss': 0.22233404683309696, 'Total loss': 0.22233404683309696}
2022-12-05 19:52:17,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:17,627 INFO:     Epoch: 21
2022-12-05 19:52:18,419 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42450655150142586, 'Total loss': 0.42450655150142586} | train loss {'Reaction outcome loss': 0.2140241071371542, 'Total loss': 0.2140241071371542}
2022-12-05 19:52:18,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:18,420 INFO:     Epoch: 22
2022-12-05 19:52:19,211 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4260711937465451, 'Total loss': 0.4260711937465451} | train loss {'Reaction outcome loss': 0.2117895297255487, 'Total loss': 0.2117895297255487}
2022-12-05 19:52:19,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:19,211 INFO:     Epoch: 23
2022-12-05 19:52:20,004 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4216471991755746, 'Total loss': 0.4216471991755746} | train loss {'Reaction outcome loss': 0.20696063212028915, 'Total loss': 0.20696063212028915}
2022-12-05 19:52:20,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:20,004 INFO:     Epoch: 24
2022-12-05 19:52:20,802 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42426588250832126, 'Total loss': 0.42426588250832126} | train loss {'Reaction outcome loss': 0.20017050077477772, 'Total loss': 0.20017050077477772}
2022-12-05 19:52:20,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:20,802 INFO:     Epoch: 25
2022-12-05 19:52:21,598 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4415889426388524, 'Total loss': 0.4415889426388524} | train loss {'Reaction outcome loss': 0.19938399713306176, 'Total loss': 0.19938399713306176}
2022-12-05 19:52:21,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:21,598 INFO:     Epoch: 26
2022-12-05 19:52:22,392 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42134793145074084, 'Total loss': 0.42134793145074084} | train loss {'Reaction outcome loss': 0.1931574617272183, 'Total loss': 0.1931574617272183}
2022-12-05 19:52:22,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:22,393 INFO:     Epoch: 27
2022-12-05 19:52:23,189 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4235609129748561, 'Total loss': 0.4235609129748561} | train loss {'Reaction outcome loss': 0.18924758461634478, 'Total loss': 0.18924758461634478}
2022-12-05 19:52:23,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:23,190 INFO:     Epoch: 28
2022-12-05 19:52:23,982 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4266083799302578, 'Total loss': 0.4266083799302578} | train loss {'Reaction outcome loss': 0.18758051675714313, 'Total loss': 0.18758051675714313}
2022-12-05 19:52:23,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:23,982 INFO:     Epoch: 29
2022-12-05 19:52:24,775 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4250064380466938, 'Total loss': 0.4250064380466938} | train loss {'Reaction outcome loss': 0.18567806973512616, 'Total loss': 0.18567806973512616}
2022-12-05 19:52:24,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:24,775 INFO:     Epoch: 30
2022-12-05 19:52:25,574 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4289540485902266, 'Total loss': 0.4289540485902266} | train loss {'Reaction outcome loss': 0.17881413283307226, 'Total loss': 0.17881413283307226}
2022-12-05 19:52:25,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:25,575 INFO:     Epoch: 31
2022-12-05 19:52:26,368 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4454286501488902, 'Total loss': 0.4454286501488902} | train loss {'Reaction outcome loss': 0.17546477171802713, 'Total loss': 0.17546477171802713}
2022-12-05 19:52:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:26,368 INFO:     Epoch: 32
2022-12-05 19:52:27,164 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44066972590305586, 'Total loss': 0.44066972590305586} | train loss {'Reaction outcome loss': 0.17391944410760077, 'Total loss': 0.17391944410760077}
2022-12-05 19:52:27,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:27,164 INFO:     Epoch: 33
2022-12-05 19:52:27,957 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43363209576769307, 'Total loss': 0.43363209576769307} | train loss {'Reaction outcome loss': 0.17287191500767105, 'Total loss': 0.17287191500767105}
2022-12-05 19:52:27,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:27,957 INFO:     Epoch: 34
2022-12-05 19:52:28,751 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4359101454981349, 'Total loss': 0.4359101454981349} | train loss {'Reaction outcome loss': 0.17016423500383332, 'Total loss': 0.17016423500383332}
2022-12-05 19:52:28,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:28,752 INFO:     Epoch: 35
2022-12-05 19:52:29,546 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42986896295439114, 'Total loss': 0.42986896295439114} | train loss {'Reaction outcome loss': 0.16653728396481565, 'Total loss': 0.16653728396481565}
2022-12-05 19:52:29,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:29,547 INFO:     Epoch: 36
2022-12-05 19:52:30,340 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45196834342046216, 'Total loss': 0.45196834342046216} | train loss {'Reaction outcome loss': 0.16312326364699872, 'Total loss': 0.16312326364699872}
2022-12-05 19:52:30,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:30,340 INFO:     Epoch: 37
2022-12-05 19:52:31,143 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4209643995220011, 'Total loss': 0.4209643995220011} | train loss {'Reaction outcome loss': 0.16282221635863667, 'Total loss': 0.16282221635863667}
2022-12-05 19:52:31,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:31,143 INFO:     Epoch: 38
2022-12-05 19:52:31,938 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4337733022191308, 'Total loss': 0.4337733022191308} | train loss {'Reaction outcome loss': 0.16289402877972012, 'Total loss': 0.16289402877972012}
2022-12-05 19:52:31,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:31,939 INFO:     Epoch: 39
2022-12-05 19:52:32,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.441308163783767, 'Total loss': 0.441308163783767} | train loss {'Reaction outcome loss': 0.15816977280642716, 'Total loss': 0.15816977280642716}
2022-12-05 19:52:32,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:32,734 INFO:     Epoch: 40
2022-12-05 19:52:33,528 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4389750469814647, 'Total loss': 0.4389750469814647} | train loss {'Reaction outcome loss': 0.156657105612178, 'Total loss': 0.156657105612178}
2022-12-05 19:52:33,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:33,528 INFO:     Epoch: 41
2022-12-05 19:52:34,324 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4395005062899806, 'Total loss': 0.4395005062899806} | train loss {'Reaction outcome loss': 0.1550749694297631, 'Total loss': 0.1550749694297631}
2022-12-05 19:52:34,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:34,324 INFO:     Epoch: 42
2022-12-05 19:52:35,122 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44131124527616933, 'Total loss': 0.44131124527616933} | train loss {'Reaction outcome loss': 0.15703188759019418, 'Total loss': 0.15703188759019418}
2022-12-05 19:52:35,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:35,122 INFO:     Epoch: 43
2022-12-05 19:52:35,915 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43927710740403697, 'Total loss': 0.43927710740403697} | train loss {'Reaction outcome loss': 0.15306198444487829, 'Total loss': 0.15306198444487829}
2022-12-05 19:52:35,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:35,915 INFO:     Epoch: 44
2022-12-05 19:52:36,711 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44594329223036766, 'Total loss': 0.44594329223036766} | train loss {'Reaction outcome loss': 0.1477750329894104, 'Total loss': 0.1477750329894104}
2022-12-05 19:52:36,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:36,712 INFO:     Epoch: 45
2022-12-05 19:52:37,505 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4466274194419384, 'Total loss': 0.4466274194419384} | train loss {'Reaction outcome loss': 0.14835923171091464, 'Total loss': 0.14835923171091464}
2022-12-05 19:52:37,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:37,505 INFO:     Epoch: 46
2022-12-05 19:52:38,301 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4444906267930161, 'Total loss': 0.4444906267930161} | train loss {'Reaction outcome loss': 0.1508127115967293, 'Total loss': 0.1508127115967293}
2022-12-05 19:52:38,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:38,301 INFO:     Epoch: 47
2022-12-05 19:52:39,098 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4398930704390461, 'Total loss': 0.4398930704390461} | train loss {'Reaction outcome loss': 0.147251951620884, 'Total loss': 0.147251951620884}
2022-12-05 19:52:39,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:39,098 INFO:     Epoch: 48
2022-12-05 19:52:39,895 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4353285880590027, 'Total loss': 0.4353285880590027} | train loss {'Reaction outcome loss': 0.14499125565822807, 'Total loss': 0.14499125565822807}
2022-12-05 19:52:39,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:39,895 INFO:     Epoch: 49
2022-12-05 19:52:40,693 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4443781138821082, 'Total loss': 0.4443781138821082} | train loss {'Reaction outcome loss': 0.14682348498008063, 'Total loss': 0.14682348498008063}
2022-12-05 19:52:40,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:40,694 INFO:     Epoch: 50
2022-12-05 19:52:41,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4456379511816935, 'Total loss': 0.4456379511816935} | train loss {'Reaction outcome loss': 0.144724847313257, 'Total loss': 0.144724847313257}
2022-12-05 19:52:41,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:41,495 INFO:     Epoch: 51
2022-12-05 19:52:42,290 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4505268287929622, 'Total loss': 0.4505268287929622} | train loss {'Reaction outcome loss': 0.1412050982396449, 'Total loss': 0.1412050982396449}
2022-12-05 19:52:42,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:42,290 INFO:     Epoch: 52
2022-12-05 19:52:43,089 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4583107016303323, 'Total loss': 0.4583107016303323} | train loss {'Reaction outcome loss': 0.14215071244736113, 'Total loss': 0.14215071244736113}
2022-12-05 19:52:43,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:43,089 INFO:     Epoch: 53
2022-12-05 19:52:43,886 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4405019378120249, 'Total loss': 0.4405019378120249} | train loss {'Reaction outcome loss': 0.13839577571789344, 'Total loss': 0.13839577571789344}
2022-12-05 19:52:43,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:43,886 INFO:     Epoch: 54
2022-12-05 19:52:44,679 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4578282982110977, 'Total loss': 0.4578282982110977} | train loss {'Reaction outcome loss': 0.14074125685053127, 'Total loss': 0.14074125685053127}
2022-12-05 19:52:44,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:44,679 INFO:     Epoch: 55
2022-12-05 19:52:45,474 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4484027586877346, 'Total loss': 0.4484027586877346} | train loss {'Reaction outcome loss': 0.1373519013305345, 'Total loss': 0.1373519013305345}
2022-12-05 19:52:45,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:45,474 INFO:     Epoch: 56
2022-12-05 19:52:46,270 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4567109712145545, 'Total loss': 0.4567109712145545} | train loss {'Reaction outcome loss': 0.13559112995262107, 'Total loss': 0.13559112995262107}
2022-12-05 19:52:46,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:46,270 INFO:     Epoch: 57
2022-12-05 19:52:47,065 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4509589553556659, 'Total loss': 0.4509589553556659} | train loss {'Reaction outcome loss': 0.13656602977895207, 'Total loss': 0.13656602977895207}
2022-12-05 19:52:47,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:47,066 INFO:     Epoch: 58
2022-12-05 19:52:47,865 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4553384598005902, 'Total loss': 0.4553384598005902} | train loss {'Reaction outcome loss': 0.13597133659171842, 'Total loss': 0.13597133659171842}
2022-12-05 19:52:47,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:47,865 INFO:     Epoch: 59
2022-12-05 19:52:48,662 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4687706238844178, 'Total loss': 0.4687706238844178} | train loss {'Reaction outcome loss': 0.1336888372147035, 'Total loss': 0.1336888372147035}
2022-12-05 19:52:48,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:48,663 INFO:     Epoch: 60
2022-12-05 19:52:49,467 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45744699849323794, 'Total loss': 0.45744699849323794} | train loss {'Reaction outcome loss': 0.1337860257650215, 'Total loss': 0.1337860257650215}
2022-12-05 19:52:49,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:49,467 INFO:     Epoch: 61
2022-12-05 19:52:50,268 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45668605308641086, 'Total loss': 0.45668605308641086} | train loss {'Reaction outcome loss': 0.13126751380191454, 'Total loss': 0.13126751380191454}
2022-12-05 19:52:50,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:50,268 INFO:     Epoch: 62
2022-12-05 19:52:51,071 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45140927538953046, 'Total loss': 0.45140927538953046} | train loss {'Reaction outcome loss': 0.13351602030677662, 'Total loss': 0.13351602030677662}
2022-12-05 19:52:51,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:51,071 INFO:     Epoch: 63
2022-12-05 19:52:51,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44714894755320117, 'Total loss': 0.44714894755320117} | train loss {'Reaction outcome loss': 0.13052765249214585, 'Total loss': 0.13052765249214585}
2022-12-05 19:52:51,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:51,871 INFO:     Epoch: 64
2022-12-05 19:52:52,672 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46075540442358365, 'Total loss': 0.46075540442358365} | train loss {'Reaction outcome loss': 0.12936515909349244, 'Total loss': 0.12936515909349244}
2022-12-05 19:52:52,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:52,672 INFO:     Epoch: 65
2022-12-05 19:52:53,466 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45845624804496765, 'Total loss': 0.45845624804496765} | train loss {'Reaction outcome loss': 0.12824738596475893, 'Total loss': 0.12824738596475893}
2022-12-05 19:52:53,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:53,466 INFO:     Epoch: 66
2022-12-05 19:52:54,260 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4500943805006417, 'Total loss': 0.4500943805006417} | train loss {'Reaction outcome loss': 0.12877995936545514, 'Total loss': 0.12877995936545514}
2022-12-05 19:52:54,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:54,260 INFO:     Epoch: 67
2022-12-05 19:52:55,059 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4520761194554242, 'Total loss': 0.4520761194554242} | train loss {'Reaction outcome loss': 0.12778471569500624, 'Total loss': 0.12778471569500624}
2022-12-05 19:52:55,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:55,059 INFO:     Epoch: 68
2022-12-05 19:52:55,860 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4477913555773822, 'Total loss': 0.4477913555773822} | train loss {'Reaction outcome loss': 0.12762925671713968, 'Total loss': 0.12762925671713968}
2022-12-05 19:52:55,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:55,860 INFO:     Epoch: 69
2022-12-05 19:52:56,657 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4655644798820669, 'Total loss': 0.4655644798820669} | train loss {'Reaction outcome loss': 0.12735686021211046, 'Total loss': 0.12735686021211046}
2022-12-05 19:52:56,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:56,657 INFO:     Epoch: 70
2022-12-05 19:52:57,455 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44725542583248834, 'Total loss': 0.44725542583248834} | train loss {'Reaction outcome loss': 0.12437795151791145, 'Total loss': 0.12437795151791145}
2022-12-05 19:52:57,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:57,455 INFO:     Epoch: 71
2022-12-05 19:52:58,250 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.440217268907211, 'Total loss': 0.440217268907211} | train loss {'Reaction outcome loss': 0.12401033330318187, 'Total loss': 0.12401033330318187}
2022-12-05 19:52:58,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:58,250 INFO:     Epoch: 72
2022-12-05 19:52:59,045 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4513502720404755, 'Total loss': 0.4513502720404755} | train loss {'Reaction outcome loss': 0.12248735655767602, 'Total loss': 0.12248735655767602}
2022-12-05 19:52:59,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:59,046 INFO:     Epoch: 73
2022-12-05 19:52:59,840 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4637481170621785, 'Total loss': 0.4637481170621785} | train loss {'Reaction outcome loss': 0.1243420146000121, 'Total loss': 0.1243420146000121}
2022-12-05 19:52:59,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:52:59,841 INFO:     Epoch: 74
2022-12-05 19:53:00,635 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46066281301054085, 'Total loss': 0.46066281301054085} | train loss {'Reaction outcome loss': 0.12709844615610857, 'Total loss': 0.12709844615610857}
2022-12-05 19:53:00,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:00,636 INFO:     Epoch: 75
2022-12-05 19:53:01,428 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48408520729704335, 'Total loss': 0.48408520729704335} | train loss {'Reaction outcome loss': 0.12259061584500747, 'Total loss': 0.12259061584500747}
2022-12-05 19:53:01,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:01,428 INFO:     Epoch: 76
2022-12-05 19:53:02,221 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4440766020931981, 'Total loss': 0.4440766020931981} | train loss {'Reaction outcome loss': 0.12305909309596304, 'Total loss': 0.12305909309596304}
2022-12-05 19:53:02,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:02,221 INFO:     Epoch: 77
2022-12-05 19:53:03,024 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4487555639987642, 'Total loss': 0.4487555639987642} | train loss {'Reaction outcome loss': 0.12338376405739016, 'Total loss': 0.12338376405739016}
2022-12-05 19:53:03,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:03,024 INFO:     Epoch: 78
2022-12-05 19:53:03,822 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4403035068376498, 'Total loss': 0.4403035068376498} | train loss {'Reaction outcome loss': 0.1203590911482611, 'Total loss': 0.1203590911482611}
2022-12-05 19:53:03,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:03,823 INFO:     Epoch: 79
2022-12-05 19:53:04,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45221669209951704, 'Total loss': 0.45221669209951704} | train loss {'Reaction outcome loss': 0.12046721573137949, 'Total loss': 0.12046721573137949}
2022-12-05 19:53:04,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:04,617 INFO:     Epoch: 80
2022-12-05 19:53:05,409 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4656974050131711, 'Total loss': 0.4656974050131711} | train loss {'Reaction outcome loss': 0.12059383458578057, 'Total loss': 0.12059383458578057}
2022-12-05 19:53:05,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:05,409 INFO:     Epoch: 81
2022-12-05 19:53:06,202 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44912389970638533, 'Total loss': 0.44912389970638533} | train loss {'Reaction outcome loss': 0.12195805156032645, 'Total loss': 0.12195805156032645}
2022-12-05 19:53:06,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:06,202 INFO:     Epoch: 82
2022-12-05 19:53:07,000 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4586502533744682, 'Total loss': 0.4586502533744682} | train loss {'Reaction outcome loss': 0.12133271248275114, 'Total loss': 0.12133271248275114}
2022-12-05 19:53:07,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:07,000 INFO:     Epoch: 83
2022-12-05 19:53:07,797 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4390900595621629, 'Total loss': 0.4390900595621629} | train loss {'Reaction outcome loss': 0.1176407630705545, 'Total loss': 0.1176407630705545}
2022-12-05 19:53:07,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:07,797 INFO:     Epoch: 84
2022-12-05 19:53:08,596 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45829385044899856, 'Total loss': 0.45829385044899856} | train loss {'Reaction outcome loss': 0.11833424839161095, 'Total loss': 0.11833424839161095}
2022-12-05 19:53:08,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:08,596 INFO:     Epoch: 85
2022-12-05 19:53:09,404 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45133026045831764, 'Total loss': 0.45133026045831764} | train loss {'Reaction outcome loss': 0.11849355779498094, 'Total loss': 0.11849355779498094}
2022-12-05 19:53:09,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:09,405 INFO:     Epoch: 86
2022-12-05 19:53:10,219 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4619373797693036, 'Total loss': 0.4619373797693036} | train loss {'Reaction outcome loss': 0.11849182987240173, 'Total loss': 0.11849182987240173}
2022-12-05 19:53:10,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:10,220 INFO:     Epoch: 87
2022-12-05 19:53:11,036 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4458499886095524, 'Total loss': 0.4458499886095524} | train loss {'Reaction outcome loss': 0.11979269797372963, 'Total loss': 0.11979269797372963}
2022-12-05 19:53:11,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:11,036 INFO:     Epoch: 88
2022-12-05 19:53:11,847 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4482171152803031, 'Total loss': 0.4482171152803031} | train loss {'Reaction outcome loss': 0.11563011047415316, 'Total loss': 0.11563011047415316}
2022-12-05 19:53:11,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:11,848 INFO:     Epoch: 89
2022-12-05 19:53:12,658 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4709633964706551, 'Total loss': 0.4709633964706551} | train loss {'Reaction outcome loss': 0.11694324731210907, 'Total loss': 0.11694324731210907}
2022-12-05 19:53:12,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:12,659 INFO:     Epoch: 90
2022-12-05 19:53:13,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4516375095329501, 'Total loss': 0.4516375095329501} | train loss {'Reaction outcome loss': 0.11692067964242832, 'Total loss': 0.11692067964242832}
2022-12-05 19:53:13,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:13,468 INFO:     Epoch: 91
2022-12-05 19:53:14,278 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44565738788382575, 'Total loss': 0.44565738788382575} | train loss {'Reaction outcome loss': 0.1168392380594366, 'Total loss': 0.1168392380594366}
2022-12-05 19:53:14,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:14,278 INFO:     Epoch: 92
2022-12-05 19:53:15,095 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4580433312803507, 'Total loss': 0.4580433312803507} | train loss {'Reaction outcome loss': 0.11413186799073892, 'Total loss': 0.11413186799073892}
2022-12-05 19:53:15,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:15,095 INFO:     Epoch: 93
2022-12-05 19:53:15,910 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46112437681718305, 'Total loss': 0.46112437681718305} | train loss {'Reaction outcome loss': 0.11316553429294858, 'Total loss': 0.11316553429294858}
2022-12-05 19:53:15,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:15,910 INFO:     Epoch: 94
2022-12-05 19:53:16,714 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4681622362272306, 'Total loss': 0.4681622362272306} | train loss {'Reaction outcome loss': 0.11713648892773856, 'Total loss': 0.11713648892773856}
2022-12-05 19:53:16,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:16,714 INFO:     Epoch: 95
2022-12-05 19:53:17,516 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4607794397002594, 'Total loss': 0.4607794397002594} | train loss {'Reaction outcome loss': 0.11666767504216442, 'Total loss': 0.11666767504216442}
2022-12-05 19:53:17,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:17,516 INFO:     Epoch: 96
2022-12-05 19:53:18,312 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4603347388858145, 'Total loss': 0.4603347388858145} | train loss {'Reaction outcome loss': 0.11295810380890485, 'Total loss': 0.11295810380890485}
2022-12-05 19:53:18,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:18,313 INFO:     Epoch: 97
2022-12-05 19:53:19,105 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4562140022489158, 'Total loss': 0.4562140022489158} | train loss {'Reaction outcome loss': 0.11285630357451737, 'Total loss': 0.11285630357451737}
2022-12-05 19:53:19,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:19,105 INFO:     Epoch: 98
2022-12-05 19:53:19,899 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45102442343803967, 'Total loss': 0.45102442343803967} | train loss {'Reaction outcome loss': 0.11402132673444407, 'Total loss': 0.11402132673444407}
2022-12-05 19:53:19,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:19,900 INFO:     Epoch: 99
2022-12-05 19:53:20,694 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4464148851958188, 'Total loss': 0.4464148851958188} | train loss {'Reaction outcome loss': 0.11274196005017016, 'Total loss': 0.11274196005017016}
2022-12-05 19:53:20,694 INFO:     Best model found after epoch 17 of 100.
2022-12-05 19:53:20,694 INFO:   Done with stage: TRAINING
2022-12-05 19:53:20,694 INFO:   Starting stage: EVALUATION
2022-12-05 19:53:20,814 INFO:   Done with stage: EVALUATION
2022-12-05 19:53:20,814 INFO:   Leaving out SEQ value Fold_5
2022-12-05 19:53:20,826 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:53:20,826 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:53:21,458 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:53:21,458 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:53:21,526 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:53:21,526 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:53:21,526 INFO:     No hyperparam tuning for this model
2022-12-05 19:53:21,526 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:53:21,526 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:53:21,527 INFO:     None feature selector for col prot
2022-12-05 19:53:21,527 INFO:     None feature selector for col prot
2022-12-05 19:53:21,527 INFO:     None feature selector for col prot
2022-12-05 19:53:21,528 INFO:     None feature selector for col chem
2022-12-05 19:53:21,528 INFO:     None feature selector for col chem
2022-12-05 19:53:21,528 INFO:     None feature selector for col chem
2022-12-05 19:53:21,528 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:53:21,528 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:53:21,529 INFO:     Number of params in model 215821
2022-12-05 19:53:21,533 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:53:21,533 INFO:   Starting stage: TRAINING
2022-12-05 19:53:21,593 INFO:     Val loss before train {'Reaction outcome loss': 1.0310090671886096, 'Total loss': 1.0310090671886096}
2022-12-05 19:53:21,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:21,593 INFO:     Epoch: 0
2022-12-05 19:53:22,387 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6342224140058864, 'Total loss': 0.6342224140058864} | train loss {'Reaction outcome loss': 0.7860532450048547, 'Total loss': 0.7860532450048547}
2022-12-05 19:53:22,387 INFO:     Found new best model at epoch 0
2022-12-05 19:53:22,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:22,388 INFO:     Epoch: 1
2022-12-05 19:53:23,174 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5392203940586611, 'Total loss': 0.5392203940586611} | train loss {'Reaction outcome loss': 0.5351112538021103, 'Total loss': 0.5351112538021103}
2022-12-05 19:53:23,174 INFO:     Found new best model at epoch 1
2022-12-05 19:53:23,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:23,175 INFO:     Epoch: 2
2022-12-05 19:53:23,964 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4989495798945427, 'Total loss': 0.4989495798945427} | train loss {'Reaction outcome loss': 0.4663677938312654, 'Total loss': 0.4663677938312654}
2022-12-05 19:53:23,964 INFO:     Found new best model at epoch 2
2022-12-05 19:53:23,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:23,965 INFO:     Epoch: 3
2022-12-05 19:53:24,756 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4976878027347001, 'Total loss': 0.4976878027347001} | train loss {'Reaction outcome loss': 0.4240538889338613, 'Total loss': 0.4240538889338613}
2022-12-05 19:53:24,756 INFO:     Found new best model at epoch 3
2022-12-05 19:53:24,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:24,757 INFO:     Epoch: 4
2022-12-05 19:53:25,547 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.479374305091121, 'Total loss': 0.479374305091121} | train loss {'Reaction outcome loss': 0.39596723207095375, 'Total loss': 0.39596723207095375}
2022-12-05 19:53:25,547 INFO:     Found new best model at epoch 4
2022-12-05 19:53:25,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:25,548 INFO:     Epoch: 5
2022-12-05 19:53:26,335 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46606418964537705, 'Total loss': 0.46606418964537705} | train loss {'Reaction outcome loss': 0.3697521979864008, 'Total loss': 0.3697521979864008}
2022-12-05 19:53:26,335 INFO:     Found new best model at epoch 5
2022-12-05 19:53:26,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:26,336 INFO:     Epoch: 6
2022-12-05 19:53:27,128 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46710931543599477, 'Total loss': 0.46710931543599477} | train loss {'Reaction outcome loss': 0.3538225277474052, 'Total loss': 0.3538225277474052}
2022-12-05 19:53:27,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:27,129 INFO:     Epoch: 7
2022-12-05 19:53:27,924 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.463026915084232, 'Total loss': 0.463026915084232} | train loss {'Reaction outcome loss': 0.34076894420059584, 'Total loss': 0.34076894420059584}
2022-12-05 19:53:27,924 INFO:     Found new best model at epoch 7
2022-12-05 19:53:27,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:27,925 INFO:     Epoch: 8
2022-12-05 19:53:28,714 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46264985271475534, 'Total loss': 0.46264985271475534} | train loss {'Reaction outcome loss': 0.33117288308828946, 'Total loss': 0.33117288308828946}
2022-12-05 19:53:28,714 INFO:     Found new best model at epoch 8
2022-12-05 19:53:28,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:28,715 INFO:     Epoch: 9
2022-12-05 19:53:29,504 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4448812407526103, 'Total loss': 0.4448812407526103} | train loss {'Reaction outcome loss': 0.3156692338918867, 'Total loss': 0.3156692338918867}
2022-12-05 19:53:29,504 INFO:     Found new best model at epoch 9
2022-12-05 19:53:29,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:29,505 INFO:     Epoch: 10
2022-12-05 19:53:30,291 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4640604274516756, 'Total loss': 0.4640604274516756} | train loss {'Reaction outcome loss': 0.3046360538013068, 'Total loss': 0.3046360538013068}
2022-12-05 19:53:30,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:30,292 INFO:     Epoch: 11
2022-12-05 19:53:31,080 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45356611941348424, 'Total loss': 0.45356611941348424} | train loss {'Reaction outcome loss': 0.29157016516817724, 'Total loss': 0.29157016516817724}
2022-12-05 19:53:31,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:31,081 INFO:     Epoch: 12
2022-12-05 19:53:31,871 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4416346475481987, 'Total loss': 0.4416346475481987} | train loss {'Reaction outcome loss': 0.2846720094381556, 'Total loss': 0.2846720094381556}
2022-12-05 19:53:31,871 INFO:     Found new best model at epoch 12
2022-12-05 19:53:31,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:31,872 INFO:     Epoch: 13
2022-12-05 19:53:32,664 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4424187331037088, 'Total loss': 0.4424187331037088} | train loss {'Reaction outcome loss': 0.2671991233461299, 'Total loss': 0.2671991233461299}
2022-12-05 19:53:32,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:32,664 INFO:     Epoch: 14
2022-12-05 19:53:33,456 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4299184111031619, 'Total loss': 0.4299184111031619} | train loss {'Reaction outcome loss': 0.25924390417746146, 'Total loss': 0.25924390417746146}
2022-12-05 19:53:33,456 INFO:     Found new best model at epoch 14
2022-12-05 19:53:33,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:33,457 INFO:     Epoch: 15
2022-12-05 19:53:34,245 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43123427812348714, 'Total loss': 0.43123427812348714} | train loss {'Reaction outcome loss': 0.2572711077839257, 'Total loss': 0.2572711077839257}
2022-12-05 19:53:34,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:34,246 INFO:     Epoch: 16
2022-12-05 19:53:35,033 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4413334483450109, 'Total loss': 0.4413334483450109} | train loss {'Reaction outcome loss': 0.24945369208993218, 'Total loss': 0.24945369208993218}
2022-12-05 19:53:35,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:35,033 INFO:     Epoch: 17
2022-12-05 19:53:35,819 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43615552444349637, 'Total loss': 0.43615552444349637} | train loss {'Reaction outcome loss': 0.24297272964467403, 'Total loss': 0.24297272964467403}
2022-12-05 19:53:35,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:35,819 INFO:     Epoch: 18
2022-12-05 19:53:36,606 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43426223945888603, 'Total loss': 0.43426223945888603} | train loss {'Reaction outcome loss': 0.23490805328193948, 'Total loss': 0.23490805328193948}
2022-12-05 19:53:36,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:36,606 INFO:     Epoch: 19
2022-12-05 19:53:37,395 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4395504661581733, 'Total loss': 0.4395504661581733} | train loss {'Reaction outcome loss': 0.2300684258100475, 'Total loss': 0.2300684258100475}
2022-12-05 19:53:37,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:37,396 INFO:     Epoch: 20
2022-12-05 19:53:38,181 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4625809781930663, 'Total loss': 0.4625809781930663} | train loss {'Reaction outcome loss': 0.23433053013887484, 'Total loss': 0.23433053013887484}
2022-12-05 19:53:38,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:38,182 INFO:     Epoch: 21
2022-12-05 19:53:38,970 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4504848193715919, 'Total loss': 0.4504848193715919} | train loss {'Reaction outcome loss': 0.22337648022716283, 'Total loss': 0.22337648022716283}
2022-12-05 19:53:38,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:38,971 INFO:     Epoch: 22
2022-12-05 19:53:39,768 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4389262475412, 'Total loss': 0.4389262475412} | train loss {'Reaction outcome loss': 0.21531009693679057, 'Total loss': 0.21531009693679057}
2022-12-05 19:53:39,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:39,768 INFO:     Epoch: 23
2022-12-05 19:53:40,567 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4425434378737753, 'Total loss': 0.4425434378737753} | train loss {'Reaction outcome loss': 0.20947711394443685, 'Total loss': 0.20947711394443685}
2022-12-05 19:53:40,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:40,567 INFO:     Epoch: 24
2022-12-05 19:53:41,362 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.461367418481545, 'Total loss': 0.461367418481545} | train loss {'Reaction outcome loss': 0.2058718816682636, 'Total loss': 0.2058718816682636}
2022-12-05 19:53:41,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:41,363 INFO:     Epoch: 25
2022-12-05 19:53:42,155 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4538756398992105, 'Total loss': 0.4538756398992105} | train loss {'Reaction outcome loss': 0.2075938087424286, 'Total loss': 0.2075938087424286}
2022-12-05 19:53:42,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:42,155 INFO:     Epoch: 26
2022-12-05 19:53:42,948 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44795196097005496, 'Total loss': 0.44795196097005496} | train loss {'Reaction outcome loss': 0.20417237494457588, 'Total loss': 0.20417237494457588}
2022-12-05 19:53:42,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:42,950 INFO:     Epoch: 27
2022-12-05 19:53:43,745 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4335118948735974, 'Total loss': 0.4335118948735974} | train loss {'Reaction outcome loss': 0.19919129918039086, 'Total loss': 0.19919129918039086}
2022-12-05 19:53:43,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:43,746 INFO:     Epoch: 28
2022-12-05 19:53:44,542 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4474311592904004, 'Total loss': 0.4474311592904004} | train loss {'Reaction outcome loss': 0.19265791491194353, 'Total loss': 0.19265791491194353}
2022-12-05 19:53:44,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:44,543 INFO:     Epoch: 29
2022-12-05 19:53:45,339 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4494373530826785, 'Total loss': 0.4494373530826785} | train loss {'Reaction outcome loss': 0.1898468683326715, 'Total loss': 0.1898468683326715}
2022-12-05 19:53:45,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:45,340 INFO:     Epoch: 30
2022-12-05 19:53:46,138 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4464539319954135, 'Total loss': 0.4464539319954135} | train loss {'Reaction outcome loss': 0.18809590113126798, 'Total loss': 0.18809590113126798}
2022-12-05 19:53:46,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:46,138 INFO:     Epoch: 31
2022-12-05 19:53:46,934 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.437373954125426, 'Total loss': 0.437373954125426} | train loss {'Reaction outcome loss': 0.1869826779864834, 'Total loss': 0.1869826779864834}
2022-12-05 19:53:46,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:46,935 INFO:     Epoch: 32
2022-12-05 19:53:47,740 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44318129596385086, 'Total loss': 0.44318129596385086} | train loss {'Reaction outcome loss': 0.1811851495997094, 'Total loss': 0.1811851495997094}
2022-12-05 19:53:47,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:47,740 INFO:     Epoch: 33
2022-12-05 19:53:48,537 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44270518743856385, 'Total loss': 0.44270518743856385} | train loss {'Reaction outcome loss': 0.1759636010823824, 'Total loss': 0.1759636010823824}
2022-12-05 19:53:48,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:48,537 INFO:     Epoch: 34
2022-12-05 19:53:49,336 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4332064078612761, 'Total loss': 0.4332064078612761} | train loss {'Reaction outcome loss': 0.17602048811091767, 'Total loss': 0.17602048811091767}
2022-12-05 19:53:49,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:49,337 INFO:     Epoch: 35
2022-12-05 19:53:50,138 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45966341583566234, 'Total loss': 0.45966341583566234} | train loss {'Reaction outcome loss': 0.17678494400039377, 'Total loss': 0.17678494400039377}
2022-12-05 19:53:50,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:50,138 INFO:     Epoch: 36
2022-12-05 19:53:50,936 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45330093293027446, 'Total loss': 0.45330093293027446} | train loss {'Reaction outcome loss': 0.1736315307761203, 'Total loss': 0.1736315307761203}
2022-12-05 19:53:50,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:50,936 INFO:     Epoch: 37
2022-12-05 19:53:51,734 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4505818034098907, 'Total loss': 0.4505818034098907} | train loss {'Reaction outcome loss': 0.171062838037306, 'Total loss': 0.171062838037306}
2022-12-05 19:53:51,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:51,734 INFO:     Epoch: 38
2022-12-05 19:53:52,531 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4448287188160149, 'Total loss': 0.4448287188160149} | train loss {'Reaction outcome loss': 0.17011429081380608, 'Total loss': 0.17011429081380608}
2022-12-05 19:53:52,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:52,531 INFO:     Epoch: 39
2022-12-05 19:53:53,326 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4600699825043028, 'Total loss': 0.4600699825043028} | train loss {'Reaction outcome loss': 0.17439448577823186, 'Total loss': 0.17439448577823186}
2022-12-05 19:53:53,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:53,326 INFO:     Epoch: 40
2022-12-05 19:53:54,120 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4625999331474304, 'Total loss': 0.4625999331474304} | train loss {'Reaction outcome loss': 0.17099248686511265, 'Total loss': 0.17099248686511265}
2022-12-05 19:53:54,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:54,121 INFO:     Epoch: 41
2022-12-05 19:53:54,916 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45748234184628184, 'Total loss': 0.45748234184628184} | train loss {'Reaction outcome loss': 0.16584722987689107, 'Total loss': 0.16584722987689107}
2022-12-05 19:53:54,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:54,917 INFO:     Epoch: 42
2022-12-05 19:53:55,713 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4625844992697239, 'Total loss': 0.4625844992697239} | train loss {'Reaction outcome loss': 0.16268238465599566, 'Total loss': 0.16268238465599566}
2022-12-05 19:53:55,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:55,713 INFO:     Epoch: 43
2022-12-05 19:53:56,507 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4627214798873121, 'Total loss': 0.4627214798873121} | train loss {'Reaction outcome loss': 0.16270037036886822, 'Total loss': 0.16270037036886822}
2022-12-05 19:53:56,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:56,508 INFO:     Epoch: 44
2022-12-05 19:53:57,306 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.466256306591359, 'Total loss': 0.466256306591359} | train loss {'Reaction outcome loss': 0.16044173945686008, 'Total loss': 0.16044173945686008}
2022-12-05 19:53:57,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:57,306 INFO:     Epoch: 45
2022-12-05 19:53:58,101 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45856960117816925, 'Total loss': 0.45856960117816925} | train loss {'Reaction outcome loss': 0.16170149196225864, 'Total loss': 0.16170149196225864}
2022-12-05 19:53:58,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:58,101 INFO:     Epoch: 46
2022-12-05 19:53:58,896 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4798063916916197, 'Total loss': 0.4798063916916197} | train loss {'Reaction outcome loss': 0.1616010950003498, 'Total loss': 0.1616010950003498}
2022-12-05 19:53:58,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:58,896 INFO:     Epoch: 47
2022-12-05 19:53:59,692 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46515518155964936, 'Total loss': 0.46515518155964936} | train loss {'Reaction outcome loss': 0.1615112307688847, 'Total loss': 0.1615112307688847}
2022-12-05 19:53:59,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:53:59,693 INFO:     Epoch: 48
2022-12-05 19:54:00,490 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4482629583640532, 'Total loss': 0.4482629583640532} | train loss {'Reaction outcome loss': 0.15878111909818554, 'Total loss': 0.15878111909818554}
2022-12-05 19:54:00,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:00,490 INFO:     Epoch: 49
2022-12-05 19:54:01,284 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47413123737681995, 'Total loss': 0.47413123737681995} | train loss {'Reaction outcome loss': 0.15356183395935938, 'Total loss': 0.15356183395935938}
2022-12-05 19:54:01,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:01,284 INFO:     Epoch: 50
2022-12-05 19:54:02,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45855489948933775, 'Total loss': 0.45855489948933775} | train loss {'Reaction outcome loss': 0.15444956306624508, 'Total loss': 0.15444956306624508}
2022-12-05 19:54:02,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:02,083 INFO:     Epoch: 51
2022-12-05 19:54:02,882 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4764068519527262, 'Total loss': 0.4764068519527262} | train loss {'Reaction outcome loss': 0.15448891644098378, 'Total loss': 0.15448891644098378}
2022-12-05 19:54:02,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:02,883 INFO:     Epoch: 52
2022-12-05 19:54:03,678 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4566816267642108, 'Total loss': 0.4566816267642108} | train loss {'Reaction outcome loss': 0.15662725003594571, 'Total loss': 0.15662725003594571}
2022-12-05 19:54:03,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:03,678 INFO:     Epoch: 53
2022-12-05 19:54:04,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46089023707265203, 'Total loss': 0.46089023707265203} | train loss {'Reaction outcome loss': 0.14738959965846588, 'Total loss': 0.14738959965846588}
2022-12-05 19:54:04,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:04,475 INFO:     Epoch: 54
2022-12-05 19:54:05,273 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4680754342539744, 'Total loss': 0.4680754342539744} | train loss {'Reaction outcome loss': 0.146603083788504, 'Total loss': 0.146603083788504}
2022-12-05 19:54:05,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:05,273 INFO:     Epoch: 55
2022-12-05 19:54:06,066 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4472351975061677, 'Total loss': 0.4472351975061677} | train loss {'Reaction outcome loss': 0.15025359134261423, 'Total loss': 0.15025359134261423}
2022-12-05 19:54:06,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:06,067 INFO:     Epoch: 56
2022-12-05 19:54:06,859 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4698577377606522, 'Total loss': 0.4698577377606522} | train loss {'Reaction outcome loss': 0.14672230244406803, 'Total loss': 0.14672230244406803}
2022-12-05 19:54:06,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:06,860 INFO:     Epoch: 57
2022-12-05 19:54:07,645 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45965369502929126, 'Total loss': 0.45965369502929126} | train loss {'Reaction outcome loss': 0.14633977180346847, 'Total loss': 0.14633977180346847}
2022-12-05 19:54:07,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:07,646 INFO:     Epoch: 58
2022-12-05 19:54:08,430 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46029217913746834, 'Total loss': 0.46029217913746834} | train loss {'Reaction outcome loss': 0.1437809696715129, 'Total loss': 0.1437809696715129}
2022-12-05 19:54:08,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:08,430 INFO:     Epoch: 59
2022-12-05 19:54:09,215 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4662682403894988, 'Total loss': 0.4662682403894988} | train loss {'Reaction outcome loss': 0.14422766080028132, 'Total loss': 0.14422766080028132}
2022-12-05 19:54:09,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:09,215 INFO:     Epoch: 60
2022-12-05 19:54:10,002 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4698715535077182, 'Total loss': 0.4698715535077182} | train loss {'Reaction outcome loss': 0.14583023353988825, 'Total loss': 0.14583023353988825}
2022-12-05 19:54:10,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:10,002 INFO:     Epoch: 61
2022-12-05 19:54:10,788 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47414234009656037, 'Total loss': 0.47414234009656037} | train loss {'Reaction outcome loss': 0.14646743332612733, 'Total loss': 0.14646743332612733}
2022-12-05 19:54:10,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:10,788 INFO:     Epoch: 62
2022-12-05 19:54:11,580 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4632498879324306, 'Total loss': 0.4632498879324306} | train loss {'Reaction outcome loss': 0.14118159842641595, 'Total loss': 0.14118159842641595}
2022-12-05 19:54:11,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:11,580 INFO:     Epoch: 63
2022-12-05 19:54:12,369 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4617366601120342, 'Total loss': 0.4617366601120342} | train loss {'Reaction outcome loss': 0.14260168172238086, 'Total loss': 0.14260168172238086}
2022-12-05 19:54:12,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:12,369 INFO:     Epoch: 64
2022-12-05 19:54:13,157 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46393282237378036, 'Total loss': 0.46393282237378036} | train loss {'Reaction outcome loss': 0.14266121424055897, 'Total loss': 0.14266121424055897}
2022-12-05 19:54:13,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:13,157 INFO:     Epoch: 65
2022-12-05 19:54:13,941 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4687313959002495, 'Total loss': 0.4687313959002495} | train loss {'Reaction outcome loss': 0.142682987076762, 'Total loss': 0.142682987076762}
2022-12-05 19:54:13,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:13,942 INFO:     Epoch: 66
2022-12-05 19:54:14,730 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4718085029585795, 'Total loss': 0.4718085029585795} | train loss {'Reaction outcome loss': 0.14584412339788216, 'Total loss': 0.14584412339788216}
2022-12-05 19:54:14,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:14,730 INFO:     Epoch: 67
2022-12-05 19:54:15,515 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45796974714506755, 'Total loss': 0.45796974714506755} | train loss {'Reaction outcome loss': 0.1461925900085011, 'Total loss': 0.1461925900085011}
2022-12-05 19:54:15,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:15,515 INFO:     Epoch: 68
2022-12-05 19:54:16,303 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4644699308343909, 'Total loss': 0.4644699308343909} | train loss {'Reaction outcome loss': 0.14762903595727828, 'Total loss': 0.14762903595727828}
2022-12-05 19:54:16,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:16,303 INFO:     Epoch: 69
2022-12-05 19:54:17,091 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46074879000132735, 'Total loss': 0.46074879000132735} | train loss {'Reaction outcome loss': 0.1434577824387639, 'Total loss': 0.1434577824387639}
2022-12-05 19:54:17,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:17,091 INFO:     Epoch: 70
2022-12-05 19:54:17,878 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4585254724052819, 'Total loss': 0.4585254724052819} | train loss {'Reaction outcome loss': 0.13649385834964906, 'Total loss': 0.13649385834964906}
2022-12-05 19:54:17,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:17,879 INFO:     Epoch: 71
2022-12-05 19:54:18,669 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46795725788582454, 'Total loss': 0.46795725788582454} | train loss {'Reaction outcome loss': 0.14175563915147207, 'Total loss': 0.14175563915147207}
2022-12-05 19:54:18,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:18,669 INFO:     Epoch: 72
2022-12-05 19:54:19,460 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4697581052102826, 'Total loss': 0.4697581052102826} | train loss {'Reaction outcome loss': 0.13396893402039325, 'Total loss': 0.13396893402039325}
2022-12-05 19:54:19,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:19,460 INFO:     Epoch: 73
2022-12-05 19:54:20,247 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4613912914964286, 'Total loss': 0.4613912914964286} | train loss {'Reaction outcome loss': 0.13423281931883924, 'Total loss': 0.13423281931883924}
2022-12-05 19:54:20,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:20,248 INFO:     Epoch: 74
2022-12-05 19:54:21,031 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4632881046696143, 'Total loss': 0.4632881046696143} | train loss {'Reaction outcome loss': 0.13384758889946619, 'Total loss': 0.13384758889946619}
2022-12-05 19:54:21,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:21,032 INFO:     Epoch: 75
2022-12-05 19:54:21,819 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4774292314594442, 'Total loss': 0.4774292314594442} | train loss {'Reaction outcome loss': 0.13560210122549643, 'Total loss': 0.13560210122549643}
2022-12-05 19:54:21,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:21,819 INFO:     Epoch: 76
2022-12-05 19:54:22,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4769764163277366, 'Total loss': 0.4769764163277366} | train loss {'Reaction outcome loss': 0.13625726389495074, 'Total loss': 0.13625726389495074}
2022-12-05 19:54:22,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:22,603 INFO:     Epoch: 77
2022-12-05 19:54:23,394 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47205770455978135, 'Total loss': 0.47205770455978135} | train loss {'Reaction outcome loss': 0.1361885571905114, 'Total loss': 0.1361885571905114}
2022-12-05 19:54:23,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:23,394 INFO:     Epoch: 78
2022-12-05 19:54:24,177 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4861570776186206, 'Total loss': 0.4861570776186206} | train loss {'Reaction outcome loss': 0.1375709542182655, 'Total loss': 0.1375709542182655}
2022-12-05 19:54:24,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:24,177 INFO:     Epoch: 79
2022-12-05 19:54:24,961 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4782900099049915, 'Total loss': 0.4782900099049915} | train loss {'Reaction outcome loss': 0.13680616841248053, 'Total loss': 0.13680616841248053}
2022-12-05 19:54:24,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:24,961 INFO:     Epoch: 80
2022-12-05 19:54:25,746 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46584500711072574, 'Total loss': 0.46584500711072574} | train loss {'Reaction outcome loss': 0.13554824885689779, 'Total loss': 0.13554824885689779}
2022-12-05 19:54:25,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:25,747 INFO:     Epoch: 81
2022-12-05 19:54:26,537 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4699085439470681, 'Total loss': 0.4699085439470681} | train loss {'Reaction outcome loss': 0.13749848779004353, 'Total loss': 0.13749848779004353}
2022-12-05 19:54:26,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:26,538 INFO:     Epoch: 82
2022-12-05 19:54:27,324 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4673313874412667, 'Total loss': 0.4673313874412667} | train loss {'Reaction outcome loss': 0.1378824949445512, 'Total loss': 0.1378824949445512}
2022-12-05 19:54:27,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:27,325 INFO:     Epoch: 83
2022-12-05 19:54:28,114 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47591218995777046, 'Total loss': 0.47591218995777046} | train loss {'Reaction outcome loss': 0.12979498688086324, 'Total loss': 0.12979498688086324}
2022-12-05 19:54:28,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:28,114 INFO:     Epoch: 84
2022-12-05 19:54:28,903 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4804192317480391, 'Total loss': 0.4804192317480391} | train loss {'Reaction outcome loss': 0.13066818704640093, 'Total loss': 0.13066818704640093}
2022-12-05 19:54:28,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:28,903 INFO:     Epoch: 85
2022-12-05 19:54:29,691 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4555644044144587, 'Total loss': 0.4555644044144587} | train loss {'Reaction outcome loss': 0.13405403428756243, 'Total loss': 0.13405403428756243}
2022-12-05 19:54:29,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:29,692 INFO:     Epoch: 86
2022-12-05 19:54:30,480 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46316832380199974, 'Total loss': 0.46316832380199974} | train loss {'Reaction outcome loss': 0.12958012344852948, 'Total loss': 0.12958012344852948}
2022-12-05 19:54:30,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:30,480 INFO:     Epoch: 87
2022-12-05 19:54:31,265 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47742384231903334, 'Total loss': 0.47742384231903334} | train loss {'Reaction outcome loss': 0.128224164522762, 'Total loss': 0.128224164522762}
2022-12-05 19:54:31,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:31,266 INFO:     Epoch: 88
2022-12-05 19:54:32,051 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4906045581129464, 'Total loss': 0.4906045581129464} | train loss {'Reaction outcome loss': 0.13120962510183304, 'Total loss': 0.13120962510183304}
2022-12-05 19:54:32,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:32,051 INFO:     Epoch: 89
2022-12-05 19:54:32,838 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46793064644390886, 'Total loss': 0.46793064644390886} | train loss {'Reaction outcome loss': 0.1306750989440821, 'Total loss': 0.1306750989440821}
2022-12-05 19:54:32,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:32,839 INFO:     Epoch: 90
2022-12-05 19:54:33,629 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47387003153562546, 'Total loss': 0.47387003153562546} | train loss {'Reaction outcome loss': 0.12842160360397478, 'Total loss': 0.12842160360397478}
2022-12-05 19:54:33,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:33,629 INFO:     Epoch: 91
2022-12-05 19:54:34,417 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46237688139081, 'Total loss': 0.46237688139081} | train loss {'Reaction outcome loss': 0.1289512875323987, 'Total loss': 0.1289512875323987}
2022-12-05 19:54:34,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:34,417 INFO:     Epoch: 92
2022-12-05 19:54:35,211 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5037013600495729, 'Total loss': 0.5037013600495729} | train loss {'Reaction outcome loss': 0.13077416855027438, 'Total loss': 0.13077416855027438}
2022-12-05 19:54:35,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:35,211 INFO:     Epoch: 93
2022-12-05 19:54:35,998 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48107415945692494, 'Total loss': 0.48107415945692494} | train loss {'Reaction outcome loss': 0.13194258376658585, 'Total loss': 0.13194258376658585}
2022-12-05 19:54:35,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:35,999 INFO:     Epoch: 94
2022-12-05 19:54:36,783 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4772088121284138, 'Total loss': 0.4772088121284138} | train loss {'Reaction outcome loss': 0.12992314892153628, 'Total loss': 0.12992314892153628}
2022-12-05 19:54:36,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:36,783 INFO:     Epoch: 95
2022-12-05 19:54:37,578 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4783318364484744, 'Total loss': 0.4783318364484744} | train loss {'Reaction outcome loss': 0.12713863650562623, 'Total loss': 0.12713863650562623}
2022-12-05 19:54:37,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:37,578 INFO:     Epoch: 96
2022-12-05 19:54:38,368 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47583565691655333, 'Total loss': 0.47583565691655333} | train loss {'Reaction outcome loss': 0.12903180059332114, 'Total loss': 0.12903180059332114}
2022-12-05 19:54:38,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:38,368 INFO:     Epoch: 97
2022-12-05 19:54:39,154 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4944536601277915, 'Total loss': 0.4944536601277915} | train loss {'Reaction outcome loss': 0.13374708891329676, 'Total loss': 0.13374708891329676}
2022-12-05 19:54:39,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:39,154 INFO:     Epoch: 98
2022-12-05 19:54:39,950 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48173216256228363, 'Total loss': 0.48173216256228363} | train loss {'Reaction outcome loss': 0.12964382392508902, 'Total loss': 0.12964382392508902}
2022-12-05 19:54:39,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:39,951 INFO:     Epoch: 99
2022-12-05 19:54:40,747 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46757304532961413, 'Total loss': 0.46757304532961413} | train loss {'Reaction outcome loss': 0.1386362727814418, 'Total loss': 0.1386362727814418}
2022-12-05 19:54:40,747 INFO:     Best model found after epoch 15 of 100.
2022-12-05 19:54:40,747 INFO:   Done with stage: TRAINING
2022-12-05 19:54:40,747 INFO:   Starting stage: EVALUATION
2022-12-05 19:54:40,873 INFO:   Done with stage: EVALUATION
2022-12-05 19:54:40,874 INFO:   Leaving out SEQ value Fold_6
2022-12-05 19:54:40,887 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:54:40,887 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:54:41,540 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:54:41,540 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:54:41,609 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:54:41,609 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:54:41,609 INFO:     No hyperparam tuning for this model
2022-12-05 19:54:41,609 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:54:41,609 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:54:41,610 INFO:     None feature selector for col prot
2022-12-05 19:54:41,610 INFO:     None feature selector for col prot
2022-12-05 19:54:41,610 INFO:     None feature selector for col prot
2022-12-05 19:54:41,611 INFO:     None feature selector for col chem
2022-12-05 19:54:41,611 INFO:     None feature selector for col chem
2022-12-05 19:54:41,611 INFO:     None feature selector for col chem
2022-12-05 19:54:41,611 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:54:41,611 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:54:41,613 INFO:     Number of params in model 215821
2022-12-05 19:54:41,616 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:54:41,616 INFO:   Starting stage: TRAINING
2022-12-05 19:54:41,676 INFO:     Val loss before train {'Reaction outcome loss': 0.9578445215116848, 'Total loss': 0.9578445215116848}
2022-12-05 19:54:41,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:41,676 INFO:     Epoch: 0
2022-12-05 19:54:42,472 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5993538918820295, 'Total loss': 0.5993538918820295} | train loss {'Reaction outcome loss': 0.8018430064041768, 'Total loss': 0.8018430064041768}
2022-12-05 19:54:42,472 INFO:     Found new best model at epoch 0
2022-12-05 19:54:42,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:42,473 INFO:     Epoch: 1
2022-12-05 19:54:43,263 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4938094209540974, 'Total loss': 0.4938094209540974} | train loss {'Reaction outcome loss': 0.545269378250645, 'Total loss': 0.545269378250645}
2022-12-05 19:54:43,264 INFO:     Found new best model at epoch 1
2022-12-05 19:54:43,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:43,264 INFO:     Epoch: 2
2022-12-05 19:54:44,052 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47032923928715964, 'Total loss': 0.47032923928715964} | train loss {'Reaction outcome loss': 0.47551911708808714, 'Total loss': 0.47551911708808714}
2022-12-05 19:54:44,052 INFO:     Found new best model at epoch 2
2022-12-05 19:54:44,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:44,053 INFO:     Epoch: 3
2022-12-05 19:54:44,840 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4416873807256872, 'Total loss': 0.4416873807256872} | train loss {'Reaction outcome loss': 0.4365968968599073, 'Total loss': 0.4365968968599073}
2022-12-05 19:54:44,841 INFO:     Found new best model at epoch 3
2022-12-05 19:54:44,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:44,842 INFO:     Epoch: 4
2022-12-05 19:54:45,632 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44109629873525014, 'Total loss': 0.44109629873525014} | train loss {'Reaction outcome loss': 0.411840011696181, 'Total loss': 0.411840011696181}
2022-12-05 19:54:45,632 INFO:     Found new best model at epoch 4
2022-12-05 19:54:45,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:45,633 INFO:     Epoch: 5
2022-12-05 19:54:46,421 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41970241543921555, 'Total loss': 0.41970241543921555} | train loss {'Reaction outcome loss': 0.3905151509830067, 'Total loss': 0.3905151509830067}
2022-12-05 19:54:46,421 INFO:     Found new best model at epoch 5
2022-12-05 19:54:46,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:46,422 INFO:     Epoch: 6
2022-12-05 19:54:47,210 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41764856163750996, 'Total loss': 0.41764856163750996} | train loss {'Reaction outcome loss': 0.37351439109132173, 'Total loss': 0.37351439109132173}
2022-12-05 19:54:47,210 INFO:     Found new best model at epoch 6
2022-12-05 19:54:47,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:47,211 INFO:     Epoch: 7
2022-12-05 19:54:48,004 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40853612599047745, 'Total loss': 0.40853612599047745} | train loss {'Reaction outcome loss': 0.35966017989501836, 'Total loss': 0.35966017989501836}
2022-12-05 19:54:48,004 INFO:     Found new best model at epoch 7
2022-12-05 19:54:48,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:48,005 INFO:     Epoch: 8
2022-12-05 19:54:48,792 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41202570497989655, 'Total loss': 0.41202570497989655} | train loss {'Reaction outcome loss': 0.34240824741221243, 'Total loss': 0.34240824741221243}
2022-12-05 19:54:48,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:48,792 INFO:     Epoch: 9
2022-12-05 19:54:49,579 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3992862125689333, 'Total loss': 0.3992862125689333} | train loss {'Reaction outcome loss': 0.3292995998335461, 'Total loss': 0.3292995998335461}
2022-12-05 19:54:49,579 INFO:     Found new best model at epoch 9
2022-12-05 19:54:49,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:49,580 INFO:     Epoch: 10
2022-12-05 19:54:50,372 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.395026333630085, 'Total loss': 0.395026333630085} | train loss {'Reaction outcome loss': 0.32032278868099373, 'Total loss': 0.32032278868099373}
2022-12-05 19:54:50,372 INFO:     Found new best model at epoch 10
2022-12-05 19:54:50,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:50,373 INFO:     Epoch: 11
2022-12-05 19:54:51,172 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39763120765035803, 'Total loss': 0.39763120765035803} | train loss {'Reaction outcome loss': 0.3044396723290124, 'Total loss': 0.3044396723290124}
2022-12-05 19:54:51,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:51,172 INFO:     Epoch: 12
2022-12-05 19:54:51,963 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4007990085943179, 'Total loss': 0.4007990085943179} | train loss {'Reaction outcome loss': 0.29581570715433164, 'Total loss': 0.29581570715433164}
2022-12-05 19:54:51,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:51,963 INFO:     Epoch: 13
2022-12-05 19:54:52,758 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39442818848924205, 'Total loss': 0.39442818848924205} | train loss {'Reaction outcome loss': 0.28765066674039247, 'Total loss': 0.28765066674039247}
2022-12-05 19:54:52,758 INFO:     Found new best model at epoch 13
2022-12-05 19:54:52,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:52,759 INFO:     Epoch: 14
2022-12-05 19:54:53,548 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40075903182679956, 'Total loss': 0.40075903182679956} | train loss {'Reaction outcome loss': 0.2812717163995389, 'Total loss': 0.2812717163995389}
2022-12-05 19:54:53,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:53,548 INFO:     Epoch: 15
2022-12-05 19:54:54,337 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40158650668507273, 'Total loss': 0.40158650668507273} | train loss {'Reaction outcome loss': 0.271311764545258, 'Total loss': 0.271311764545258}
2022-12-05 19:54:54,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:54,337 INFO:     Epoch: 16
2022-12-05 19:54:55,129 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4046313881196759, 'Total loss': 0.4046313881196759} | train loss {'Reaction outcome loss': 0.2639302663024395, 'Total loss': 0.2639302663024395}
2022-12-05 19:54:55,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:55,129 INFO:     Epoch: 17
2022-12-05 19:54:55,918 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4097486548125744, 'Total loss': 0.4097486548125744} | train loss {'Reaction outcome loss': 0.25458498887958064, 'Total loss': 0.25458498887958064}
2022-12-05 19:54:55,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:55,919 INFO:     Epoch: 18
2022-12-05 19:54:56,708 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4164911119098013, 'Total loss': 0.4164911119098013} | train loss {'Reaction outcome loss': 0.2507248738209807, 'Total loss': 0.2507248738209807}
2022-12-05 19:54:56,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:56,708 INFO:     Epoch: 19
2022-12-05 19:54:57,499 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4120384549552744, 'Total loss': 0.4120384549552744} | train loss {'Reaction outcome loss': 0.2445378554384074, 'Total loss': 0.2445378554384074}
2022-12-05 19:54:57,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:57,500 INFO:     Epoch: 20
2022-12-05 19:54:58,292 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40644859691912477, 'Total loss': 0.40644859691912477} | train loss {'Reaction outcome loss': 0.23730145164975716, 'Total loss': 0.23730145164975716}
2022-12-05 19:54:58,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:58,292 INFO:     Epoch: 21
2022-12-05 19:54:59,084 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41862554543397645, 'Total loss': 0.41862554543397645} | train loss {'Reaction outcome loss': 0.23442577396429354, 'Total loss': 0.23442577396429354}
2022-12-05 19:54:59,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:59,084 INFO:     Epoch: 22
2022-12-05 19:54:59,874 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4139434183863076, 'Total loss': 0.4139434183863076} | train loss {'Reaction outcome loss': 0.228660995831653, 'Total loss': 0.228660995831653}
2022-12-05 19:54:59,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:54:59,874 INFO:     Epoch: 23
2022-12-05 19:55:00,663 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41587461361830885, 'Total loss': 0.41587461361830885} | train loss {'Reaction outcome loss': 0.2226277774860782, 'Total loss': 0.2226277774860782}
2022-12-05 19:55:00,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:00,663 INFO:     Epoch: 24
2022-12-05 19:55:01,454 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42304175651886244, 'Total loss': 0.42304175651886244} | train loss {'Reaction outcome loss': 0.22081492255411803, 'Total loss': 0.22081492255411803}
2022-12-05 19:55:01,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:01,454 INFO:     Epoch: 25
2022-12-05 19:55:02,248 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4262254559858279, 'Total loss': 0.4262254559858279} | train loss {'Reaction outcome loss': 0.21390113061774643, 'Total loss': 0.21390113061774643}
2022-12-05 19:55:02,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:02,249 INFO:     Epoch: 26
2022-12-05 19:55:03,036 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42364674738862296, 'Total loss': 0.42364674738862296} | train loss {'Reaction outcome loss': 0.21090891918227558, 'Total loss': 0.21090891918227558}
2022-12-05 19:55:03,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:03,036 INFO:     Epoch: 27
2022-12-05 19:55:03,831 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4238669140772386, 'Total loss': 0.4238669140772386} | train loss {'Reaction outcome loss': 0.20537353482758325, 'Total loss': 0.20537353482758325}
2022-12-05 19:55:03,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:03,832 INFO:     Epoch: 28
2022-12-05 19:55:04,626 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41987624764442444, 'Total loss': 0.41987624764442444} | train loss {'Reaction outcome loss': 0.20332056883301947, 'Total loss': 0.20332056883301947}
2022-12-05 19:55:04,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:04,626 INFO:     Epoch: 29
2022-12-05 19:55:05,418 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44235938347198744, 'Total loss': 0.44235938347198744} | train loss {'Reaction outcome loss': 0.20035702093774754, 'Total loss': 0.20035702093774754}
2022-12-05 19:55:05,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:05,418 INFO:     Epoch: 30
2022-12-05 19:55:06,214 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4340005594898354, 'Total loss': 0.4340005594898354} | train loss {'Reaction outcome loss': 0.19794020735688747, 'Total loss': 0.19794020735688747}
2022-12-05 19:55:06,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:06,215 INFO:     Epoch: 31
2022-12-05 19:55:07,006 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42585521428422496, 'Total loss': 0.42585521428422496} | train loss {'Reaction outcome loss': 0.19618416991415283, 'Total loss': 0.19618416991415283}
2022-12-05 19:55:07,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:07,006 INFO:     Epoch: 32
2022-12-05 19:55:07,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41865567295727407, 'Total loss': 0.41865567295727407} | train loss {'Reaction outcome loss': 0.1916436589353027, 'Total loss': 0.1916436589353027}
2022-12-05 19:55:07,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:07,796 INFO:     Epoch: 33
2022-12-05 19:55:08,589 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43220849030397157, 'Total loss': 0.43220849030397157} | train loss {'Reaction outcome loss': 0.19067271345204884, 'Total loss': 0.19067271345204884}
2022-12-05 19:55:08,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:08,590 INFO:     Epoch: 34
2022-12-05 19:55:09,379 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4275811602446166, 'Total loss': 0.4275811602446166} | train loss {'Reaction outcome loss': 0.18280118764678557, 'Total loss': 0.18280118764678557}
2022-12-05 19:55:09,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:09,379 INFO:     Epoch: 35
2022-12-05 19:55:10,171 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4274015304717151, 'Total loss': 0.4274015304717151} | train loss {'Reaction outcome loss': 0.18392225089032324, 'Total loss': 0.18392225089032324}
2022-12-05 19:55:10,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:10,171 INFO:     Epoch: 36
2022-12-05 19:55:10,961 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43311895099891856, 'Total loss': 0.43311895099891856} | train loss {'Reaction outcome loss': 0.18178388503410162, 'Total loss': 0.18178388503410162}
2022-12-05 19:55:10,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:10,961 INFO:     Epoch: 37
2022-12-05 19:55:11,752 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4377382844686508, 'Total loss': 0.4377382844686508} | train loss {'Reaction outcome loss': 0.18030400470560115, 'Total loss': 0.18030400470560115}
2022-12-05 19:55:11,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:11,752 INFO:     Epoch: 38
2022-12-05 19:55:12,543 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4379672677340833, 'Total loss': 0.4379672677340833} | train loss {'Reaction outcome loss': 0.17608575591246686, 'Total loss': 0.17608575591246686}
2022-12-05 19:55:12,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:12,544 INFO:     Epoch: 39
2022-12-05 19:55:13,334 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42997524921189656, 'Total loss': 0.42997524921189656} | train loss {'Reaction outcome loss': 0.17545771427572734, 'Total loss': 0.17545771427572734}
2022-12-05 19:55:13,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:13,334 INFO:     Epoch: 40
2022-12-05 19:55:14,128 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4316876083612442, 'Total loss': 0.4316876083612442} | train loss {'Reaction outcome loss': 0.17119011933344505, 'Total loss': 0.17119011933344505}
2022-12-05 19:55:14,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:14,129 INFO:     Epoch: 41
2022-12-05 19:55:14,920 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4302137731151147, 'Total loss': 0.4302137731151147} | train loss {'Reaction outcome loss': 0.1701961586612367, 'Total loss': 0.1701961586612367}
2022-12-05 19:55:14,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:14,921 INFO:     Epoch: 42
2022-12-05 19:55:15,717 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44017858667807147, 'Total loss': 0.44017858667807147} | train loss {'Reaction outcome loss': 0.16985211179651802, 'Total loss': 0.16985211179651802}
2022-12-05 19:55:15,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:15,718 INFO:     Epoch: 43
2022-12-05 19:55:16,511 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4382506168701432, 'Total loss': 0.4382506168701432} | train loss {'Reaction outcome loss': 0.16724470737690647, 'Total loss': 0.16724470737690647}
2022-12-05 19:55:16,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:16,511 INFO:     Epoch: 44
2022-12-05 19:55:17,302 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45132139629938384, 'Total loss': 0.45132139629938384} | train loss {'Reaction outcome loss': 0.16611127316531155, 'Total loss': 0.16611127316531155}
2022-12-05 19:55:17,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:17,303 INFO:     Epoch: 45
2022-12-05 19:55:18,097 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.436484098773111, 'Total loss': 0.436484098773111} | train loss {'Reaction outcome loss': 0.1652375047861208, 'Total loss': 0.1652375047861208}
2022-12-05 19:55:18,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:18,098 INFO:     Epoch: 46
2022-12-05 19:55:18,893 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4552888286046006, 'Total loss': 0.4552888286046006} | train loss {'Reaction outcome loss': 0.16488927372941567, 'Total loss': 0.16488927372941567}
2022-12-05 19:55:18,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:18,893 INFO:     Epoch: 47
2022-12-05 19:55:19,688 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.443316193128174, 'Total loss': 0.443316193128174} | train loss {'Reaction outcome loss': 0.16239886402693246, 'Total loss': 0.16239886402693246}
2022-12-05 19:55:19,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:19,688 INFO:     Epoch: 48
2022-12-05 19:55:20,489 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4424473158168522, 'Total loss': 0.4424473158168522} | train loss {'Reaction outcome loss': 0.1590584215347565, 'Total loss': 0.1590584215347565}
2022-12-05 19:55:20,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:20,489 INFO:     Epoch: 49
2022-12-05 19:55:21,281 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4601253325288946, 'Total loss': 0.4601253325288946} | train loss {'Reaction outcome loss': 0.15991449512300954, 'Total loss': 0.15991449512300954}
2022-12-05 19:55:21,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:21,281 INFO:     Epoch: 50
2022-12-05 19:55:22,075 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4434040498665788, 'Total loss': 0.4434040498665788} | train loss {'Reaction outcome loss': 0.1586805449558362, 'Total loss': 0.1586805449558362}
2022-12-05 19:55:22,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:22,076 INFO:     Epoch: 51
2022-12-05 19:55:22,871 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4478376191109419, 'Total loss': 0.4478376191109419} | train loss {'Reaction outcome loss': 0.15805247118846782, 'Total loss': 0.15805247118846782}
2022-12-05 19:55:22,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:22,871 INFO:     Epoch: 52
2022-12-05 19:55:23,667 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46295582757077436, 'Total loss': 0.46295582757077436} | train loss {'Reaction outcome loss': 0.155277372961263, 'Total loss': 0.155277372961263}
2022-12-05 19:55:23,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:23,667 INFO:     Epoch: 53
2022-12-05 19:55:24,467 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4527886137366295, 'Total loss': 0.4527886137366295} | train loss {'Reaction outcome loss': 0.15344171611697324, 'Total loss': 0.15344171611697324}
2022-12-05 19:55:24,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:24,468 INFO:     Epoch: 54
2022-12-05 19:55:25,260 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43819595636291936, 'Total loss': 0.43819595636291936} | train loss {'Reaction outcome loss': 0.15284802145775286, 'Total loss': 0.15284802145775286}
2022-12-05 19:55:25,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:25,260 INFO:     Epoch: 55
2022-12-05 19:55:26,061 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4629603832621466, 'Total loss': 0.4629603832621466} | train loss {'Reaction outcome loss': 0.15589504906036442, 'Total loss': 0.15589504906036442}
2022-12-05 19:55:26,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:26,061 INFO:     Epoch: 56
2022-12-05 19:55:26,872 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44274755618111655, 'Total loss': 0.44274755618111655} | train loss {'Reaction outcome loss': 0.15439210984585505, 'Total loss': 0.15439210984585505}
2022-12-05 19:55:26,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:26,873 INFO:     Epoch: 57
2022-12-05 19:55:27,676 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4602375748482617, 'Total loss': 0.4602375748482617} | train loss {'Reaction outcome loss': 0.15052770263320137, 'Total loss': 0.15052770263320137}
2022-12-05 19:55:27,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:27,677 INFO:     Epoch: 58
2022-12-05 19:55:28,477 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.450512614778497, 'Total loss': 0.450512614778497} | train loss {'Reaction outcome loss': 0.15203699628041395, 'Total loss': 0.15203699628041395}
2022-12-05 19:55:28,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:28,477 INFO:     Epoch: 59
2022-12-05 19:55:29,280 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4498023136772893, 'Total loss': 0.4498023136772893} | train loss {'Reaction outcome loss': 0.147459281739899, 'Total loss': 0.147459281739899}
2022-12-05 19:55:29,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:29,280 INFO:     Epoch: 60
2022-12-05 19:55:30,091 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44087487425316463, 'Total loss': 0.44087487425316463} | train loss {'Reaction outcome loss': 0.1498815617674301, 'Total loss': 0.1498815617674301}
2022-12-05 19:55:30,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:30,091 INFO:     Epoch: 61
2022-12-05 19:55:30,901 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4593672410330989, 'Total loss': 0.4593672410330989} | train loss {'Reaction outcome loss': 0.14573172837375634, 'Total loss': 0.14573172837375634}
2022-12-05 19:55:30,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:30,901 INFO:     Epoch: 62
2022-12-05 19:55:31,711 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4498733939094977, 'Total loss': 0.4498733939094977} | train loss {'Reaction outcome loss': 0.14551009795057676, 'Total loss': 0.14551009795057676}
2022-12-05 19:55:31,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:31,711 INFO:     Epoch: 63
2022-12-05 19:55:32,520 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4558401341465386, 'Total loss': 0.4558401341465386} | train loss {'Reaction outcome loss': 0.14517610822804272, 'Total loss': 0.14517610822804272}
2022-12-05 19:55:32,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:32,521 INFO:     Epoch: 64
2022-12-05 19:55:33,327 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4401061272417957, 'Total loss': 0.4401061272417957} | train loss {'Reaction outcome loss': 0.14464150346259796, 'Total loss': 0.14464150346259796}
2022-12-05 19:55:33,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:33,327 INFO:     Epoch: 65
2022-12-05 19:55:34,132 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.440975546836853, 'Total loss': 0.440975546836853} | train loss {'Reaction outcome loss': 0.14400858805334615, 'Total loss': 0.14400858805334615}
2022-12-05 19:55:34,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:34,133 INFO:     Epoch: 66
2022-12-05 19:55:34,944 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4541341851211407, 'Total loss': 0.4541341851211407} | train loss {'Reaction outcome loss': 0.1455159337755533, 'Total loss': 0.1455159337755533}
2022-12-05 19:55:34,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:34,945 INFO:     Epoch: 67
2022-12-05 19:55:35,754 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44443303786895494, 'Total loss': 0.44443303786895494} | train loss {'Reaction outcome loss': 0.1438934881946132, 'Total loss': 0.1438934881946132}
2022-12-05 19:55:35,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:35,755 INFO:     Epoch: 68
2022-12-05 19:55:36,560 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44985492900013924, 'Total loss': 0.44985492900013924} | train loss {'Reaction outcome loss': 0.1447272650717247, 'Total loss': 0.1447272650717247}
2022-12-05 19:55:36,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:36,560 INFO:     Epoch: 69
2022-12-05 19:55:37,362 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4612759964709932, 'Total loss': 0.4612759964709932} | train loss {'Reaction outcome loss': 0.1418973370530312, 'Total loss': 0.1418973370530312}
2022-12-05 19:55:37,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:37,362 INFO:     Epoch: 70
2022-12-05 19:55:38,163 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4583829678595066, 'Total loss': 0.4583829678595066} | train loss {'Reaction outcome loss': 0.14399163174863544, 'Total loss': 0.14399163174863544}
2022-12-05 19:55:38,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:38,163 INFO:     Epoch: 71
2022-12-05 19:55:38,962 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45350456407124345, 'Total loss': 0.45350456407124345} | train loss {'Reaction outcome loss': 0.14130731691200768, 'Total loss': 0.14130731691200768}
2022-12-05 19:55:38,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:38,962 INFO:     Epoch: 72
2022-12-05 19:55:39,765 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4563885761255568, 'Total loss': 0.4563885761255568} | train loss {'Reaction outcome loss': 0.13866716133610857, 'Total loss': 0.13866716133610857}
2022-12-05 19:55:39,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:39,766 INFO:     Epoch: 73
2022-12-05 19:55:40,561 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48369230499321764, 'Total loss': 0.48369230499321764} | train loss {'Reaction outcome loss': 0.13906095628326218, 'Total loss': 0.13906095628326218}
2022-12-05 19:55:40,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:40,561 INFO:     Epoch: 74
2022-12-05 19:55:41,357 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4624550420452248, 'Total loss': 0.4624550420452248} | train loss {'Reaction outcome loss': 0.1380109095254973, 'Total loss': 0.1380109095254973}
2022-12-05 19:55:41,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:41,357 INFO:     Epoch: 75
2022-12-05 19:55:42,151 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45581113479354163, 'Total loss': 0.45581113479354163} | train loss {'Reaction outcome loss': 0.13751861463946802, 'Total loss': 0.13751861463946802}
2022-12-05 19:55:42,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:42,151 INFO:     Epoch: 76
2022-12-05 19:55:42,948 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4550256133079529, 'Total loss': 0.4550256133079529} | train loss {'Reaction outcome loss': 0.1382351194192926, 'Total loss': 0.1382351194192926}
2022-12-05 19:55:42,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:42,948 INFO:     Epoch: 77
2022-12-05 19:55:43,742 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45148131827061827, 'Total loss': 0.45148131827061827} | train loss {'Reaction outcome loss': 0.14006244979288068, 'Total loss': 0.14006244979288068}
2022-12-05 19:55:43,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:43,743 INFO:     Epoch: 78
2022-12-05 19:55:44,539 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4639434851706028, 'Total loss': 0.4639434851706028} | train loss {'Reaction outcome loss': 0.13951644343474218, 'Total loss': 0.13951644343474218}
2022-12-05 19:55:44,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:44,540 INFO:     Epoch: 79
2022-12-05 19:55:45,347 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4496793103489009, 'Total loss': 0.4496793103489009} | train loss {'Reaction outcome loss': 0.13829811922680105, 'Total loss': 0.13829811922680105}
2022-12-05 19:55:45,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:45,347 INFO:     Epoch: 80
2022-12-05 19:55:46,152 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.445265207439661, 'Total loss': 0.445265207439661} | train loss {'Reaction outcome loss': 0.1379248774084713, 'Total loss': 0.1379248774084713}
2022-12-05 19:55:46,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:46,152 INFO:     Epoch: 81
2022-12-05 19:55:46,952 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4645833080126481, 'Total loss': 0.4645833080126481} | train loss {'Reaction outcome loss': 0.13663667436659097, 'Total loss': 0.13663667436659097}
2022-12-05 19:55:46,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:46,954 INFO:     Epoch: 82
2022-12-05 19:55:47,750 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45843335342678154, 'Total loss': 0.45843335342678154} | train loss {'Reaction outcome loss': 0.13279230538154801, 'Total loss': 0.13279230538154801}
2022-12-05 19:55:47,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:47,750 INFO:     Epoch: 83
2022-12-05 19:55:48,555 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.459401663731445, 'Total loss': 0.459401663731445} | train loss {'Reaction outcome loss': 0.13508840871884698, 'Total loss': 0.13508840871884698}
2022-12-05 19:55:48,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:48,555 INFO:     Epoch: 84
2022-12-05 19:55:49,355 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45362885905937717, 'Total loss': 0.45362885905937717} | train loss {'Reaction outcome loss': 0.13355859918444749, 'Total loss': 0.13355859918444749}
2022-12-05 19:55:49,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:49,355 INFO:     Epoch: 85
2022-12-05 19:55:50,152 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45032350210980937, 'Total loss': 0.45032350210980937} | train loss {'Reaction outcome loss': 0.13267127987778476, 'Total loss': 0.13267127987778476}
2022-12-05 19:55:50,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:50,152 INFO:     Epoch: 86
2022-12-05 19:55:50,953 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4623309136791663, 'Total loss': 0.4623309136791663} | train loss {'Reaction outcome loss': 0.13177135279176816, 'Total loss': 0.13177135279176816}
2022-12-05 19:55:50,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:50,954 INFO:     Epoch: 87
2022-12-05 19:55:51,751 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4522829848256978, 'Total loss': 0.4522829848256978} | train loss {'Reaction outcome loss': 0.1301192344737149, 'Total loss': 0.1301192344737149}
2022-12-05 19:55:51,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:51,751 INFO:     Epoch: 88
2022-12-05 19:55:52,561 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45461624183438043, 'Total loss': 0.45461624183438043} | train loss {'Reaction outcome loss': 0.1320264353322977, 'Total loss': 0.1320264353322977}
2022-12-05 19:55:52,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:52,561 INFO:     Epoch: 89
2022-12-05 19:55:53,364 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45745802602984686, 'Total loss': 0.45745802602984686} | train loss {'Reaction outcome loss': 0.1297517481500343, 'Total loss': 0.1297517481500343}
2022-12-05 19:55:53,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:53,365 INFO:     Epoch: 90
2022-12-05 19:55:54,168 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45112533325498755, 'Total loss': 0.45112533325498755} | train loss {'Reaction outcome loss': 0.1309495096192545, 'Total loss': 0.1309495096192545}
2022-12-05 19:55:54,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:54,168 INFO:     Epoch: 91
2022-12-05 19:55:54,975 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4512449289587411, 'Total loss': 0.4512449289587411} | train loss {'Reaction outcome loss': 0.13251740089993203, 'Total loss': 0.13251740089993203}
2022-12-05 19:55:54,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:54,975 INFO:     Epoch: 92
2022-12-05 19:55:55,775 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4453221806748347, 'Total loss': 0.4453221806748347} | train loss {'Reaction outcome loss': 0.1304037282468691, 'Total loss': 0.1304037282468691}
2022-12-05 19:55:55,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:55,776 INFO:     Epoch: 93
2022-12-05 19:55:56,569 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43579137934879825, 'Total loss': 0.43579137934879825} | train loss {'Reaction outcome loss': 0.13006340518721468, 'Total loss': 0.13006340518721468}
2022-12-05 19:55:56,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:56,569 INFO:     Epoch: 94
2022-12-05 19:55:57,363 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46777102520520036, 'Total loss': 0.46777102520520036} | train loss {'Reaction outcome loss': 0.13071005341536815, 'Total loss': 0.13071005341536815}
2022-12-05 19:55:57,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:57,364 INFO:     Epoch: 95
2022-12-05 19:55:58,157 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4516818811270324, 'Total loss': 0.4516818811270324} | train loss {'Reaction outcome loss': 0.13027121055300436, 'Total loss': 0.13027121055300436}
2022-12-05 19:55:58,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:58,157 INFO:     Epoch: 96
2022-12-05 19:55:58,952 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4457787349820137, 'Total loss': 0.4457787349820137} | train loss {'Reaction outcome loss': 0.1312143373558478, 'Total loss': 0.1312143373558478}
2022-12-05 19:55:58,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:58,953 INFO:     Epoch: 97
2022-12-05 19:55:59,747 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4527657719498331, 'Total loss': 0.4527657719498331} | train loss {'Reaction outcome loss': 0.13023665759922756, 'Total loss': 0.13023665759922756}
2022-12-05 19:55:59,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:55:59,747 INFO:     Epoch: 98
2022-12-05 19:56:00,543 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4480056783015078, 'Total loss': 0.4480056783015078} | train loss {'Reaction outcome loss': 0.12830747610273502, 'Total loss': 0.12830747610273502}
2022-12-05 19:56:00,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:00,543 INFO:     Epoch: 99
2022-12-05 19:56:01,336 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4449159223586321, 'Total loss': 0.4449159223586321} | train loss {'Reaction outcome loss': 0.12876751226928806, 'Total loss': 0.12876751226928806}
2022-12-05 19:56:01,336 INFO:     Best model found after epoch 14 of 100.
2022-12-05 19:56:01,336 INFO:   Done with stage: TRAINING
2022-12-05 19:56:01,336 INFO:   Starting stage: EVALUATION
2022-12-05 19:56:01,456 INFO:   Done with stage: EVALUATION
2022-12-05 19:56:01,456 INFO:   Leaving out SEQ value Fold_7
2022-12-05 19:56:01,468 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 19:56:01,469 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:56:02,106 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:56:02,106 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:56:02,175 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:56:02,175 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:56:02,175 INFO:     No hyperparam tuning for this model
2022-12-05 19:56:02,175 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:56:02,175 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:56:02,176 INFO:     None feature selector for col prot
2022-12-05 19:56:02,176 INFO:     None feature selector for col prot
2022-12-05 19:56:02,176 INFO:     None feature selector for col prot
2022-12-05 19:56:02,176 INFO:     None feature selector for col chem
2022-12-05 19:56:02,176 INFO:     None feature selector for col chem
2022-12-05 19:56:02,177 INFO:     None feature selector for col chem
2022-12-05 19:56:02,177 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:56:02,177 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:56:02,178 INFO:     Number of params in model 215821
2022-12-05 19:56:02,181 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:56:02,182 INFO:   Starting stage: TRAINING
2022-12-05 19:56:02,242 INFO:     Val loss before train {'Reaction outcome loss': 1.014470635489984, 'Total loss': 1.014470635489984}
2022-12-05 19:56:02,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:02,242 INFO:     Epoch: 0
2022-12-05 19:56:03,036 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6191230183467269, 'Total loss': 0.6191230183467269} | train loss {'Reaction outcome loss': 0.8165028755762139, 'Total loss': 0.8165028755762139}
2022-12-05 19:56:03,036 INFO:     Found new best model at epoch 0
2022-12-05 19:56:03,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:03,037 INFO:     Epoch: 1
2022-12-05 19:56:03,822 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5101279531690207, 'Total loss': 0.5101279531690207} | train loss {'Reaction outcome loss': 0.5551727599027205, 'Total loss': 0.5551727599027205}
2022-12-05 19:56:03,822 INFO:     Found new best model at epoch 1
2022-12-05 19:56:03,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:03,823 INFO:     Epoch: 2
2022-12-05 19:56:04,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4726492799818516, 'Total loss': 0.4726492799818516} | train loss {'Reaction outcome loss': 0.47746578302918646, 'Total loss': 0.47746578302918646}
2022-12-05 19:56:04,610 INFO:     Found new best model at epoch 2
2022-12-05 19:56:04,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:04,611 INFO:     Epoch: 3
2022-12-05 19:56:05,402 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46416025778109377, 'Total loss': 0.46416025778109377} | train loss {'Reaction outcome loss': 0.4391450935480546, 'Total loss': 0.4391450935480546}
2022-12-05 19:56:05,403 INFO:     Found new best model at epoch 3
2022-12-05 19:56:05,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:05,404 INFO:     Epoch: 4
2022-12-05 19:56:06,192 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44939395209605043, 'Total loss': 0.44939395209605043} | train loss {'Reaction outcome loss': 0.41162126106875285, 'Total loss': 0.41162126106875285}
2022-12-05 19:56:06,192 INFO:     Found new best model at epoch 4
2022-12-05 19:56:06,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:06,193 INFO:     Epoch: 5
2022-12-05 19:56:06,980 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4321036674082279, 'Total loss': 0.4321036674082279} | train loss {'Reaction outcome loss': 0.3906945448444814, 'Total loss': 0.3906945448444814}
2022-12-05 19:56:06,980 INFO:     Found new best model at epoch 5
2022-12-05 19:56:06,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:06,981 INFO:     Epoch: 6
2022-12-05 19:56:07,768 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4252531277862462, 'Total loss': 0.4252531277862462} | train loss {'Reaction outcome loss': 0.37007979902685906, 'Total loss': 0.37007979902685906}
2022-12-05 19:56:07,768 INFO:     Found new best model at epoch 6
2022-12-05 19:56:07,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:07,769 INFO:     Epoch: 7
2022-12-05 19:56:08,563 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.418030877343633, 'Total loss': 0.418030877343633} | train loss {'Reaction outcome loss': 0.3552196558032717, 'Total loss': 0.3552196558032717}
2022-12-05 19:56:08,563 INFO:     Found new best model at epoch 7
2022-12-05 19:56:08,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:08,564 INFO:     Epoch: 8
2022-12-05 19:56:09,360 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4228012460199269, 'Total loss': 0.4228012460199269} | train loss {'Reaction outcome loss': 0.34058263776253683, 'Total loss': 0.34058263776253683}
2022-12-05 19:56:09,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:09,360 INFO:     Epoch: 9
2022-12-05 19:56:10,150 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43263267048380594, 'Total loss': 0.43263267048380594} | train loss {'Reaction outcome loss': 0.32757939586834034, 'Total loss': 0.32757939586834034}
2022-12-05 19:56:10,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:10,150 INFO:     Epoch: 10
2022-12-05 19:56:10,938 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42926761135458946, 'Total loss': 0.42926761135458946} | train loss {'Reaction outcome loss': 0.3133888131197618, 'Total loss': 0.3133888131197618}
2022-12-05 19:56:10,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:10,938 INFO:     Epoch: 11
2022-12-05 19:56:11,725 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41097205166112294, 'Total loss': 0.41097205166112294} | train loss {'Reaction outcome loss': 0.30258048988726677, 'Total loss': 0.30258048988726677}
2022-12-05 19:56:11,725 INFO:     Found new best model at epoch 11
2022-12-05 19:56:11,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:11,726 INFO:     Epoch: 12
2022-12-05 19:56:12,517 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42561087147756055, 'Total loss': 0.42561087147756055} | train loss {'Reaction outcome loss': 0.28974133559635706, 'Total loss': 0.28974133559635706}
2022-12-05 19:56:12,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:12,517 INFO:     Epoch: 13
2022-12-05 19:56:13,311 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41258546100421384, 'Total loss': 0.41258546100421384} | train loss {'Reaction outcome loss': 0.27978961805299835, 'Total loss': 0.27978961805299835}
2022-12-05 19:56:13,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:13,311 INFO:     Epoch: 14
2022-12-05 19:56:14,100 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40463967045599764, 'Total loss': 0.40463967045599764} | train loss {'Reaction outcome loss': 0.27167966058667825, 'Total loss': 0.27167966058667825}
2022-12-05 19:56:14,100 INFO:     Found new best model at epoch 14
2022-12-05 19:56:14,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:14,101 INFO:     Epoch: 15
2022-12-05 19:56:14,890 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4031062667808411, 'Total loss': 0.4031062667808411} | train loss {'Reaction outcome loss': 0.2633954580341067, 'Total loss': 0.2633954580341067}
2022-12-05 19:56:14,890 INFO:     Found new best model at epoch 15
2022-12-05 19:56:14,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:14,891 INFO:     Epoch: 16
2022-12-05 19:56:15,684 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41410748863762076, 'Total loss': 0.41410748863762076} | train loss {'Reaction outcome loss': 0.2554630984761277, 'Total loss': 0.2554630984761277}
2022-12-05 19:56:15,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:15,684 INFO:     Epoch: 17
2022-12-05 19:56:16,487 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4109292323277755, 'Total loss': 0.4109292323277755} | train loss {'Reaction outcome loss': 0.24668665887141714, 'Total loss': 0.24668665887141714}
2022-12-05 19:56:16,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:16,487 INFO:     Epoch: 18
2022-12-05 19:56:17,281 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4087269546633417, 'Total loss': 0.4087269546633417} | train loss {'Reaction outcome loss': 0.2383396585528948, 'Total loss': 0.2383396585528948}
2022-12-05 19:56:17,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:17,281 INFO:     Epoch: 19
2022-12-05 19:56:18,069 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4154720777137713, 'Total loss': 0.4154720777137713} | train loss {'Reaction outcome loss': 0.23528306251581835, 'Total loss': 0.23528306251581835}
2022-12-05 19:56:18,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:18,070 INFO:     Epoch: 20
2022-12-05 19:56:18,861 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4469278793443333, 'Total loss': 0.4469278793443333} | train loss {'Reaction outcome loss': 0.22876462702240263, 'Total loss': 0.22876462702240263}
2022-12-05 19:56:18,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:18,861 INFO:     Epoch: 21
2022-12-05 19:56:19,647 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40920993126928806, 'Total loss': 0.40920993126928806} | train loss {'Reaction outcome loss': 0.22096490422073675, 'Total loss': 0.22096490422073675}
2022-12-05 19:56:19,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:19,647 INFO:     Epoch: 22
2022-12-05 19:56:20,432 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4124694815413518, 'Total loss': 0.4124694815413518} | train loss {'Reaction outcome loss': 0.21706723002146702, 'Total loss': 0.21706723002146702}
2022-12-05 19:56:20,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:20,432 INFO:     Epoch: 23
2022-12-05 19:56:21,221 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4161384199661287, 'Total loss': 0.4161384199661287} | train loss {'Reaction outcome loss': 0.21192915910968976, 'Total loss': 0.21192915910968976}
2022-12-05 19:56:21,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:21,221 INFO:     Epoch: 24
2022-12-05 19:56:22,006 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4124602248722857, 'Total loss': 0.4124602248722857} | train loss {'Reaction outcome loss': 0.20470656478891566, 'Total loss': 0.20470656478891566}
2022-12-05 19:56:22,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:22,007 INFO:     Epoch: 25
2022-12-05 19:56:22,796 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4367413586852225, 'Total loss': 0.4367413586852225} | train loss {'Reaction outcome loss': 0.20384351722135835, 'Total loss': 0.20384351722135835}
2022-12-05 19:56:22,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:22,796 INFO:     Epoch: 26
2022-12-05 19:56:23,584 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4300432677634738, 'Total loss': 0.4300432677634738} | train loss {'Reaction outcome loss': 0.20160230769186605, 'Total loss': 0.20160230769186605}
2022-12-05 19:56:23,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:23,584 INFO:     Epoch: 27
2022-12-05 19:56:24,371 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4150969423353672, 'Total loss': 0.4150969423353672} | train loss {'Reaction outcome loss': 0.19611065471354797, 'Total loss': 0.19611065471354797}
2022-12-05 19:56:24,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:24,372 INFO:     Epoch: 28
2022-12-05 19:56:25,155 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41936884566464205, 'Total loss': 0.41936884566464205} | train loss {'Reaction outcome loss': 0.19135459742071678, 'Total loss': 0.19135459742071678}
2022-12-05 19:56:25,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:25,156 INFO:     Epoch: 29
2022-12-05 19:56:25,941 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4225148650055582, 'Total loss': 0.4225148650055582} | train loss {'Reaction outcome loss': 0.18557704700043007, 'Total loss': 0.18557704700043007}
2022-12-05 19:56:25,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:25,942 INFO:     Epoch: 30
2022-12-05 19:56:26,726 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4171758974817666, 'Total loss': 0.4171758974817666} | train loss {'Reaction outcome loss': 0.18321938529154475, 'Total loss': 0.18321938529154475}
2022-12-05 19:56:26,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:26,726 INFO:     Epoch: 31
2022-12-05 19:56:27,513 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41306377247780224, 'Total loss': 0.41306377247780224} | train loss {'Reaction outcome loss': 0.179833081440658, 'Total loss': 0.179833081440658}
2022-12-05 19:56:27,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:27,514 INFO:     Epoch: 32
2022-12-05 19:56:28,306 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42584090620617976, 'Total loss': 0.42584090620617976} | train loss {'Reaction outcome loss': 0.17625030530806707, 'Total loss': 0.17625030530806707}
2022-12-05 19:56:28,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:28,307 INFO:     Epoch: 33
2022-12-05 19:56:29,094 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44645829498767853, 'Total loss': 0.44645829498767853} | train loss {'Reaction outcome loss': 0.1746835816043372, 'Total loss': 0.1746835816043372}
2022-12-05 19:56:29,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:29,095 INFO:     Epoch: 34
2022-12-05 19:56:29,885 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.421358196572824, 'Total loss': 0.421358196572824} | train loss {'Reaction outcome loss': 0.17296579649709926, 'Total loss': 0.17296579649709926}
2022-12-05 19:56:29,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:29,885 INFO:     Epoch: 35
2022-12-05 19:56:30,669 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.441381132399494, 'Total loss': 0.441381132399494} | train loss {'Reaction outcome loss': 0.17157009247766467, 'Total loss': 0.17157009247766467}
2022-12-05 19:56:30,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:30,669 INFO:     Epoch: 36
2022-12-05 19:56:31,455 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41919367493722925, 'Total loss': 0.41919367493722925} | train loss {'Reaction outcome loss': 0.16609729976222223, 'Total loss': 0.16609729976222223}
2022-12-05 19:56:31,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:31,455 INFO:     Epoch: 37
2022-12-05 19:56:32,239 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42612324214794417, 'Total loss': 0.42612324214794417} | train loss {'Reaction outcome loss': 0.1688322692577328, 'Total loss': 0.1688322692577328}
2022-12-05 19:56:32,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:32,240 INFO:     Epoch: 38
2022-12-05 19:56:33,025 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42439113527705724, 'Total loss': 0.42439113527705724} | train loss {'Reaction outcome loss': 0.16442368751277728, 'Total loss': 0.16442368751277728}
2022-12-05 19:56:33,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:33,026 INFO:     Epoch: 39
2022-12-05 19:56:33,810 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43426595492796466, 'Total loss': 0.43426595492796466} | train loss {'Reaction outcome loss': 0.1598396219161092, 'Total loss': 0.1598396219161092}
2022-12-05 19:56:33,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:33,811 INFO:     Epoch: 40
2022-12-05 19:56:34,600 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42253284130922775, 'Total loss': 0.42253284130922775} | train loss {'Reaction outcome loss': 0.1566592736663867, 'Total loss': 0.1566592736663867}
2022-12-05 19:56:34,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:34,600 INFO:     Epoch: 41
2022-12-05 19:56:35,385 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43701456690376456, 'Total loss': 0.43701456690376456} | train loss {'Reaction outcome loss': 0.16062841324173674, 'Total loss': 0.16062841324173674}
2022-12-05 19:56:35,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:35,385 INFO:     Epoch: 42
2022-12-05 19:56:36,176 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4295960786667737, 'Total loss': 0.4295960786667737} | train loss {'Reaction outcome loss': 0.1547629939354196, 'Total loss': 0.1547629939354196}
2022-12-05 19:56:36,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:36,176 INFO:     Epoch: 43
2022-12-05 19:56:36,964 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4283996522426605, 'Total loss': 0.4283996522426605} | train loss {'Reaction outcome loss': 0.1536471133709562, 'Total loss': 0.1536471133709562}
2022-12-05 19:56:36,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:36,965 INFO:     Epoch: 44
2022-12-05 19:56:37,756 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4427169168537313, 'Total loss': 0.4427169168537313} | train loss {'Reaction outcome loss': 0.15197474088291732, 'Total loss': 0.15197474088291732}
2022-12-05 19:56:37,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:37,756 INFO:     Epoch: 45
2022-12-05 19:56:38,541 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41777956106869335, 'Total loss': 0.41777956106869335} | train loss {'Reaction outcome loss': 0.14842144460702428, 'Total loss': 0.14842144460702428}
2022-12-05 19:56:38,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:38,541 INFO:     Epoch: 46
2022-12-05 19:56:39,330 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41627829775891523, 'Total loss': 0.41627829775891523} | train loss {'Reaction outcome loss': 0.14825570438893473, 'Total loss': 0.14825570438893473}
2022-12-05 19:56:39,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:39,330 INFO:     Epoch: 47
2022-12-05 19:56:40,117 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43811803819103673, 'Total loss': 0.43811803819103673} | train loss {'Reaction outcome loss': 0.14615990132929718, 'Total loss': 0.14615990132929718}
2022-12-05 19:56:40,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:40,117 INFO:     Epoch: 48
2022-12-05 19:56:40,905 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42109544507481833, 'Total loss': 0.42109544507481833} | train loss {'Reaction outcome loss': 0.14711275718802092, 'Total loss': 0.14711275718802092}
2022-12-05 19:56:40,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:40,905 INFO:     Epoch: 49
2022-12-05 19:56:41,698 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43681182915514166, 'Total loss': 0.43681182915514166} | train loss {'Reaction outcome loss': 0.14325160527107667, 'Total loss': 0.14325160527107667}
2022-12-05 19:56:41,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:41,698 INFO:     Epoch: 50
2022-12-05 19:56:42,488 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4139176644384861, 'Total loss': 0.4139176644384861} | train loss {'Reaction outcome loss': 0.1437890836322794, 'Total loss': 0.1437890836322794}
2022-12-05 19:56:42,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:42,488 INFO:     Epoch: 51
2022-12-05 19:56:43,273 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4497100558470596, 'Total loss': 0.4497100558470596} | train loss {'Reaction outcome loss': 0.13985286589939983, 'Total loss': 0.13985286589939983}
2022-12-05 19:56:43,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:43,273 INFO:     Epoch: 52
2022-12-05 19:56:44,057 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43983216109600937, 'Total loss': 0.43983216109600937} | train loss {'Reaction outcome loss': 0.14284442543831408, 'Total loss': 0.14284442543831408}
2022-12-05 19:56:44,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:44,058 INFO:     Epoch: 53
2022-12-05 19:56:44,842 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42622499354183674, 'Total loss': 0.42622499354183674} | train loss {'Reaction outcome loss': 0.14125353830809495, 'Total loss': 0.14125353830809495}
2022-12-05 19:56:44,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:44,843 INFO:     Epoch: 54
2022-12-05 19:56:45,628 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43592932380058547, 'Total loss': 0.43592932380058547} | train loss {'Reaction outcome loss': 0.13864039754380986, 'Total loss': 0.13864039754380986}
2022-12-05 19:56:45,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:45,628 INFO:     Epoch: 55
2022-12-05 19:56:46,413 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43330380286682735, 'Total loss': 0.43330380286682735} | train loss {'Reaction outcome loss': 0.1369464426738571, 'Total loss': 0.1369464426738571}
2022-12-05 19:56:46,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:46,413 INFO:     Epoch: 56
2022-12-05 19:56:47,200 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4402231684123928, 'Total loss': 0.4402231684123928} | train loss {'Reaction outcome loss': 0.13449484201490272, 'Total loss': 0.13449484201490272}
2022-12-05 19:56:47,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:47,200 INFO:     Epoch: 57
2022-12-05 19:56:47,986 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41723854636604135, 'Total loss': 0.41723854636604135} | train loss {'Reaction outcome loss': 0.13771965578958698, 'Total loss': 0.13771965578958698}
2022-12-05 19:56:47,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:47,986 INFO:     Epoch: 58
2022-12-05 19:56:48,770 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4522752739827741, 'Total loss': 0.4522752739827741} | train loss {'Reaction outcome loss': 0.13607113540400656, 'Total loss': 0.13607113540400656}
2022-12-05 19:56:48,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:48,771 INFO:     Epoch: 59
2022-12-05 19:56:49,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42324367842891, 'Total loss': 0.42324367842891} | train loss {'Reaction outcome loss': 0.13605803887606885, 'Total loss': 0.13605803887606885}
2022-12-05 19:56:49,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:49,556 INFO:     Epoch: 60
2022-12-05 19:56:50,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4507615297016772, 'Total loss': 0.4507615297016772} | train loss {'Reaction outcome loss': 0.13380260476652456, 'Total loss': 0.13380260476652456}
2022-12-05 19:56:50,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:50,345 INFO:     Epoch: 61
2022-12-05 19:56:51,135 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4407089118930427, 'Total loss': 0.4407089118930427} | train loss {'Reaction outcome loss': 0.130546596623501, 'Total loss': 0.130546596623501}
2022-12-05 19:56:51,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:51,135 INFO:     Epoch: 62
2022-12-05 19:56:51,926 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4214632263915105, 'Total loss': 0.4214632263915105} | train loss {'Reaction outcome loss': 0.1311597849109343, 'Total loss': 0.1311597849109343}
2022-12-05 19:56:51,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:51,926 INFO:     Epoch: 63
2022-12-05 19:56:52,716 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4306133149022406, 'Total loss': 0.4306133149022406} | train loss {'Reaction outcome loss': 0.1327805368495839, 'Total loss': 0.1327805368495839}
2022-12-05 19:56:52,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:52,717 INFO:     Epoch: 64
2022-12-05 19:56:53,505 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42935318093408237, 'Total loss': 0.42935318093408237} | train loss {'Reaction outcome loss': 0.1292201707329677, 'Total loss': 0.1292201707329677}
2022-12-05 19:56:53,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:53,506 INFO:     Epoch: 65
2022-12-05 19:56:54,300 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4247744381692345, 'Total loss': 0.4247744381692345} | train loss {'Reaction outcome loss': 0.1294077294593563, 'Total loss': 0.1294077294593563}
2022-12-05 19:56:54,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:54,301 INFO:     Epoch: 66
2022-12-05 19:56:55,090 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43563823943788355, 'Total loss': 0.43563823943788355} | train loss {'Reaction outcome loss': 0.1275173246366333, 'Total loss': 0.1275173246366333}
2022-12-05 19:56:55,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:55,091 INFO:     Epoch: 67
2022-12-05 19:56:55,882 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42654775600584055, 'Total loss': 0.42654775600584055} | train loss {'Reaction outcome loss': 0.12872236147903057, 'Total loss': 0.12872236147903057}
2022-12-05 19:56:55,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:55,883 INFO:     Epoch: 68
2022-12-05 19:56:56,673 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4292576963251287, 'Total loss': 0.4292576963251287} | train loss {'Reaction outcome loss': 0.12756402536618466, 'Total loss': 0.12756402536618466}
2022-12-05 19:56:56,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:56,673 INFO:     Epoch: 69
2022-12-05 19:56:57,464 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43740256706422026, 'Total loss': 0.43740256706422026} | train loss {'Reaction outcome loss': 0.12453793481144369, 'Total loss': 0.12453793481144369}
2022-12-05 19:56:57,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:57,464 INFO:     Epoch: 70
2022-12-05 19:56:58,254 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4310209595344283, 'Total loss': 0.4310209595344283} | train loss {'Reaction outcome loss': 0.1255665322993787, 'Total loss': 0.1255665322993787}
2022-12-05 19:56:58,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:58,255 INFO:     Epoch: 71
2022-12-05 19:56:59,047 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4177051532844251, 'Total loss': 0.4177051532844251} | train loss {'Reaction outcome loss': 0.1240204467495181, 'Total loss': 0.1240204467495181}
2022-12-05 19:56:59,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:59,048 INFO:     Epoch: 72
2022-12-05 19:56:59,840 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43156407434831967, 'Total loss': 0.43156407434831967} | train loss {'Reaction outcome loss': 0.12258386822531418, 'Total loss': 0.12258386822531418}
2022-12-05 19:56:59,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:56:59,840 INFO:     Epoch: 73
2022-12-05 19:57:00,632 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.443548311394724, 'Total loss': 0.443548311394724} | train loss {'Reaction outcome loss': 0.12537815129878568, 'Total loss': 0.12537815129878568}
2022-12-05 19:57:00,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:00,632 INFO:     Epoch: 74
2022-12-05 19:57:01,422 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4238906079395251, 'Total loss': 0.4238906079395251} | train loss {'Reaction outcome loss': 0.12343142558725513, 'Total loss': 0.12343142558725513}
2022-12-05 19:57:01,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:01,422 INFO:     Epoch: 75
2022-12-05 19:57:02,216 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4250586313957518, 'Total loss': 0.4250586313957518} | train loss {'Reaction outcome loss': 0.12063982797292422, 'Total loss': 0.12063982797292422}
2022-12-05 19:57:02,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:02,216 INFO:     Epoch: 76
2022-12-05 19:57:03,009 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43428318591957743, 'Total loss': 0.43428318591957743} | train loss {'Reaction outcome loss': 0.11995782327971288, 'Total loss': 0.11995782327971288}
2022-12-05 19:57:03,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:03,009 INFO:     Epoch: 77
2022-12-05 19:57:03,804 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41726892560043116, 'Total loss': 0.41726892560043116} | train loss {'Reaction outcome loss': 0.12026839692297639, 'Total loss': 0.12026839692297639}
2022-12-05 19:57:03,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:03,804 INFO:     Epoch: 78
2022-12-05 19:57:04,601 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45404642955823377, 'Total loss': 0.45404642955823377} | train loss {'Reaction outcome loss': 0.11905085151748998, 'Total loss': 0.11905085151748998}
2022-12-05 19:57:04,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:04,601 INFO:     Epoch: 79
2022-12-05 19:57:05,397 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4266879748214375, 'Total loss': 0.4266879748214375} | train loss {'Reaction outcome loss': 0.12238212610994066, 'Total loss': 0.12238212610994066}
2022-12-05 19:57:05,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:05,397 INFO:     Epoch: 80
2022-12-05 19:57:06,194 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4249109466644851, 'Total loss': 0.4249109466644851} | train loss {'Reaction outcome loss': 0.116088659396129, 'Total loss': 0.116088659396129}
2022-12-05 19:57:06,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:06,194 INFO:     Epoch: 81
2022-12-05 19:57:06,989 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42532431571321055, 'Total loss': 0.42532431571321055} | train loss {'Reaction outcome loss': 0.12130229562825086, 'Total loss': 0.12130229562825086}
2022-12-05 19:57:06,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:06,989 INFO:     Epoch: 82
2022-12-05 19:57:07,784 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4247451519265517, 'Total loss': 0.4247451519265517} | train loss {'Reaction outcome loss': 0.11804962294670392, 'Total loss': 0.11804962294670392}
2022-12-05 19:57:07,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:07,785 INFO:     Epoch: 83
2022-12-05 19:57:08,580 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4307215918194164, 'Total loss': 0.4307215918194164} | train loss {'Reaction outcome loss': 0.11796403878501484, 'Total loss': 0.11796403878501484}
2022-12-05 19:57:08,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:08,580 INFO:     Epoch: 84
2022-12-05 19:57:09,376 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.429821860214526, 'Total loss': 0.429821860214526} | train loss {'Reaction outcome loss': 0.11560613911750973, 'Total loss': 0.11560613911750973}
2022-12-05 19:57:09,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:09,376 INFO:     Epoch: 85
2022-12-05 19:57:10,178 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4443592969328165, 'Total loss': 0.4443592969328165} | train loss {'Reaction outcome loss': 0.11360424998577456, 'Total loss': 0.11360424998577456}
2022-12-05 19:57:10,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:10,178 INFO:     Epoch: 86
2022-12-05 19:57:10,984 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43060278706252575, 'Total loss': 0.43060278706252575} | train loss {'Reaction outcome loss': 0.11585161038389316, 'Total loss': 0.11585161038389316}
2022-12-05 19:57:10,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:10,984 INFO:     Epoch: 87
2022-12-05 19:57:11,794 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.443069111217152, 'Total loss': 0.443069111217152} | train loss {'Reaction outcome loss': 0.11514186264604938, 'Total loss': 0.11514186264604938}
2022-12-05 19:57:11,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:11,795 INFO:     Epoch: 88
2022-12-05 19:57:12,589 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4265952001918446, 'Total loss': 0.4265952001918446} | train loss {'Reaction outcome loss': 0.11516442753906761, 'Total loss': 0.11516442753906761}
2022-12-05 19:57:12,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:12,589 INFO:     Epoch: 89
2022-12-05 19:57:13,382 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4317974702201106, 'Total loss': 0.4317974702201106} | train loss {'Reaction outcome loss': 0.11365103038522054, 'Total loss': 0.11365103038522054}
2022-12-05 19:57:13,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:13,382 INFO:     Epoch: 90
2022-12-05 19:57:14,176 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41960447281599045, 'Total loss': 0.41960447281599045} | train loss {'Reaction outcome loss': 0.11557528172448582, 'Total loss': 0.11557528172448582}
2022-12-05 19:57:14,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:14,176 INFO:     Epoch: 91
2022-12-05 19:57:14,969 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4357802112671462, 'Total loss': 0.4357802112671462} | train loss {'Reaction outcome loss': 0.11648524494803682, 'Total loss': 0.11648524494803682}
2022-12-05 19:57:14,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:14,969 INFO:     Epoch: 92
2022-12-05 19:57:15,770 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40783340619368985, 'Total loss': 0.40783340619368985} | train loss {'Reaction outcome loss': 0.11375427185842882, 'Total loss': 0.11375427185842882}
2022-12-05 19:57:15,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:15,770 INFO:     Epoch: 93
2022-12-05 19:57:16,570 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4363966279409148, 'Total loss': 0.4363966279409148} | train loss {'Reaction outcome loss': 0.11209266339713822, 'Total loss': 0.11209266339713822}
2022-12-05 19:57:16,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:16,570 INFO:     Epoch: 94
2022-12-05 19:57:17,367 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4117746329019693, 'Total loss': 0.4117746329019693} | train loss {'Reaction outcome loss': 0.11355015690609509, 'Total loss': 0.11355015690609509}
2022-12-05 19:57:17,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:17,367 INFO:     Epoch: 95
2022-12-05 19:57:18,163 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4351393355225975, 'Total loss': 0.4351393355225975} | train loss {'Reaction outcome loss': 0.11529383774922819, 'Total loss': 0.11529383774922819}
2022-12-05 19:57:18,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:18,164 INFO:     Epoch: 96
2022-12-05 19:57:18,963 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42093178968537937, 'Total loss': 0.42093178968537937} | train loss {'Reaction outcome loss': 0.10996189869142005, 'Total loss': 0.10996189869142005}
2022-12-05 19:57:18,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:18,963 INFO:     Epoch: 97
2022-12-05 19:57:19,761 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4220558598806912, 'Total loss': 0.4220558598806912} | train loss {'Reaction outcome loss': 0.11297250096591152, 'Total loss': 0.11297250096591152}
2022-12-05 19:57:19,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:19,761 INFO:     Epoch: 98
2022-12-05 19:57:20,561 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43872941386970604, 'Total loss': 0.43872941386970604} | train loss {'Reaction outcome loss': 0.11379961308319958, 'Total loss': 0.11379961308319958}
2022-12-05 19:57:20,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:20,563 INFO:     Epoch: 99
2022-12-05 19:57:21,358 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4154040589928627, 'Total loss': 0.4154040589928627} | train loss {'Reaction outcome loss': 0.11062053785260234, 'Total loss': 0.11062053785260234}
2022-12-05 19:57:21,359 INFO:     Best model found after epoch 16 of 100.
2022-12-05 19:57:21,359 INFO:   Done with stage: TRAINING
2022-12-05 19:57:21,359 INFO:   Starting stage: EVALUATION
2022-12-05 19:57:21,492 INFO:   Done with stage: EVALUATION
2022-12-05 19:57:21,493 INFO:   Leaving out SEQ value Fold_8
2022-12-05 19:57:21,505 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 19:57:21,506 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:57:22,147 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:57:22,147 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:57:22,216 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:57:22,216 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:57:22,216 INFO:     No hyperparam tuning for this model
2022-12-05 19:57:22,216 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:57:22,216 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:57:22,217 INFO:     None feature selector for col prot
2022-12-05 19:57:22,217 INFO:     None feature selector for col prot
2022-12-05 19:57:22,217 INFO:     None feature selector for col prot
2022-12-05 19:57:22,218 INFO:     None feature selector for col chem
2022-12-05 19:57:22,218 INFO:     None feature selector for col chem
2022-12-05 19:57:22,218 INFO:     None feature selector for col chem
2022-12-05 19:57:22,218 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:57:22,218 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:57:22,220 INFO:     Number of params in model 215821
2022-12-05 19:57:22,223 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:57:22,223 INFO:   Starting stage: TRAINING
2022-12-05 19:57:22,285 INFO:     Val loss before train {'Reaction outcome loss': 0.9792445613579317, 'Total loss': 0.9792445613579317}
2022-12-05 19:57:22,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:22,285 INFO:     Epoch: 0
2022-12-05 19:57:23,091 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.608884684741497, 'Total loss': 0.608884684741497} | train loss {'Reaction outcome loss': 0.8136229302373624, 'Total loss': 0.8136229302373624}
2022-12-05 19:57:23,092 INFO:     Found new best model at epoch 0
2022-12-05 19:57:23,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:23,092 INFO:     Epoch: 1
2022-12-05 19:57:23,899 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5264586650512435, 'Total loss': 0.5264586650512435} | train loss {'Reaction outcome loss': 0.5603139523657099, 'Total loss': 0.5603139523657099}
2022-12-05 19:57:23,899 INFO:     Found new best model at epoch 1
2022-12-05 19:57:23,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:23,900 INFO:     Epoch: 2
2022-12-05 19:57:24,711 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49084662104194815, 'Total loss': 0.49084662104194815} | train loss {'Reaction outcome loss': 0.4904887689457786, 'Total loss': 0.4904887689457786}
2022-12-05 19:57:24,712 INFO:     Found new best model at epoch 2
2022-12-05 19:57:24,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:24,713 INFO:     Epoch: 3
2022-12-05 19:57:25,517 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4627337218685584, 'Total loss': 0.4627337218685584} | train loss {'Reaction outcome loss': 0.44735739512308953, 'Total loss': 0.44735739512308953}
2022-12-05 19:57:25,517 INFO:     Found new best model at epoch 3
2022-12-05 19:57:25,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:25,518 INFO:     Epoch: 4
2022-12-05 19:57:26,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45487775247205386, 'Total loss': 0.45487775247205386} | train loss {'Reaction outcome loss': 0.41332727298140526, 'Total loss': 0.41332727298140526}
2022-12-05 19:57:26,324 INFO:     Found new best model at epoch 4
2022-12-05 19:57:26,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:26,325 INFO:     Epoch: 5
2022-12-05 19:57:27,136 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4437721432609992, 'Total loss': 0.4437721432609992} | train loss {'Reaction outcome loss': 0.3900983490410351, 'Total loss': 0.3900983490410351}
2022-12-05 19:57:27,137 INFO:     Found new best model at epoch 5
2022-12-05 19:57:27,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:27,138 INFO:     Epoch: 6
2022-12-05 19:57:27,948 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4260449463670904, 'Total loss': 0.4260449463670904} | train loss {'Reaction outcome loss': 0.3683138033975997, 'Total loss': 0.3683138033975997}
2022-12-05 19:57:27,948 INFO:     Found new best model at epoch 6
2022-12-05 19:57:27,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:27,949 INFO:     Epoch: 7
2022-12-05 19:57:28,764 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42592406713149766, 'Total loss': 0.42592406713149766} | train loss {'Reaction outcome loss': 0.3546441692197996, 'Total loss': 0.3546441692197996}
2022-12-05 19:57:28,764 INFO:     Found new best model at epoch 7
2022-12-05 19:57:28,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:28,765 INFO:     Epoch: 8
2022-12-05 19:57:29,575 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4127816886387088, 'Total loss': 0.4127816886387088} | train loss {'Reaction outcome loss': 0.33399967966420996, 'Total loss': 0.33399967966420996}
2022-12-05 19:57:29,576 INFO:     Found new best model at epoch 8
2022-12-05 19:57:29,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:29,576 INFO:     Epoch: 9
2022-12-05 19:57:30,382 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4127467091787945, 'Total loss': 0.4127467091787945} | train loss {'Reaction outcome loss': 0.3205810081093542, 'Total loss': 0.3205810081093542}
2022-12-05 19:57:30,382 INFO:     Found new best model at epoch 9
2022-12-05 19:57:30,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:30,383 INFO:     Epoch: 10
2022-12-05 19:57:31,183 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41451659866354684, 'Total loss': 0.41451659866354684} | train loss {'Reaction outcome loss': 0.30610688992084994, 'Total loss': 0.30610688992084994}
2022-12-05 19:57:31,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:31,184 INFO:     Epoch: 11
2022-12-05 19:57:31,988 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42126032743941655, 'Total loss': 0.42126032743941655} | train loss {'Reaction outcome loss': 0.2980652441601119, 'Total loss': 0.2980652441601119}
2022-12-05 19:57:31,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:31,988 INFO:     Epoch: 12
2022-12-05 19:57:32,795 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4056897288696332, 'Total loss': 0.4056897288696332} | train loss {'Reaction outcome loss': 0.2853863658083062, 'Total loss': 0.2853863658083062}
2022-12-05 19:57:32,795 INFO:     Found new best model at epoch 12
2022-12-05 19:57:32,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:32,796 INFO:     Epoch: 13
2022-12-05 19:57:33,600 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4030337364158847, 'Total loss': 0.4030337364158847} | train loss {'Reaction outcome loss': 0.2756788096871347, 'Total loss': 0.2756788096871347}
2022-12-05 19:57:33,600 INFO:     Found new best model at epoch 13
2022-12-05 19:57:33,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:33,601 INFO:     Epoch: 14
2022-12-05 19:57:34,404 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40795979581095954, 'Total loss': 0.40795979581095954} | train loss {'Reaction outcome loss': 0.2634858364059079, 'Total loss': 0.2634858364059079}
2022-12-05 19:57:34,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:34,404 INFO:     Epoch: 15
2022-12-05 19:57:35,206 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4040953310375864, 'Total loss': 0.4040953310375864} | train loss {'Reaction outcome loss': 0.2566000953947584, 'Total loss': 0.2566000953947584}
2022-12-05 19:57:35,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:35,206 INFO:     Epoch: 16
2022-12-05 19:57:36,010 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40512309866872703, 'Total loss': 0.40512309866872703} | train loss {'Reaction outcome loss': 0.25085361824641306, 'Total loss': 0.25085361824641306}
2022-12-05 19:57:36,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:36,010 INFO:     Epoch: 17
2022-12-05 19:57:36,813 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4167671273039146, 'Total loss': 0.4167671273039146} | train loss {'Reaction outcome loss': 0.24296774222485482, 'Total loss': 0.24296774222485482}
2022-12-05 19:57:36,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:36,813 INFO:     Epoch: 18
2022-12-05 19:57:37,617 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39410311593250796, 'Total loss': 0.39410311593250796} | train loss {'Reaction outcome loss': 0.2352200601430189, 'Total loss': 0.2352200601430189}
2022-12-05 19:57:37,617 INFO:     Found new best model at epoch 18
2022-12-05 19:57:37,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:37,618 INFO:     Epoch: 19
2022-12-05 19:57:38,421 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40636422925374727, 'Total loss': 0.40636422925374727} | train loss {'Reaction outcome loss': 0.23473443395848717, 'Total loss': 0.23473443395848717}
2022-12-05 19:57:38,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:38,422 INFO:     Epoch: 20
2022-12-05 19:57:39,230 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4201749492097985, 'Total loss': 0.4201749492097985} | train loss {'Reaction outcome loss': 0.22517094119722325, 'Total loss': 0.22517094119722325}
2022-12-05 19:57:39,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:39,231 INFO:     Epoch: 21
2022-12-05 19:57:40,035 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40557971359653905, 'Total loss': 0.40557971359653905} | train loss {'Reaction outcome loss': 0.22154363172669564, 'Total loss': 0.22154363172669564}
2022-12-05 19:57:40,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:40,035 INFO:     Epoch: 22
2022-12-05 19:57:40,836 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4001431871544231, 'Total loss': 0.4001431871544231} | train loss {'Reaction outcome loss': 0.21646661768036504, 'Total loss': 0.21646661768036504}
2022-12-05 19:57:40,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:40,836 INFO:     Epoch: 23
2022-12-05 19:57:41,635 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4082353623075919, 'Total loss': 0.4082353623075919} | train loss {'Reaction outcome loss': 0.21338652205022593, 'Total loss': 0.21338652205022593}
2022-12-05 19:57:41,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:41,635 INFO:     Epoch: 24
2022-12-05 19:57:42,428 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40597401474687184, 'Total loss': 0.40597401474687184} | train loss {'Reaction outcome loss': 0.20821997090693442, 'Total loss': 0.20821997090693442}
2022-12-05 19:57:42,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:42,428 INFO:     Epoch: 25
2022-12-05 19:57:43,219 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43088983405720105, 'Total loss': 0.43088983405720105} | train loss {'Reaction outcome loss': 0.20514426960219298, 'Total loss': 0.20514426960219298}
2022-12-05 19:57:43,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:43,220 INFO:     Epoch: 26
2022-12-05 19:57:44,009 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41236315735361795, 'Total loss': 0.41236315735361795} | train loss {'Reaction outcome loss': 0.19792034238156292, 'Total loss': 0.19792034238156292}
2022-12-05 19:57:44,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:44,009 INFO:     Epoch: 27
2022-12-05 19:57:44,800 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4361693642356179, 'Total loss': 0.4361693642356179} | train loss {'Reaction outcome loss': 0.19849017665030494, 'Total loss': 0.19849017665030494}
2022-12-05 19:57:44,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:44,801 INFO:     Epoch: 28
2022-12-05 19:57:45,592 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4145212403752587, 'Total loss': 0.4145212403752587} | train loss {'Reaction outcome loss': 0.19464915151137016, 'Total loss': 0.19464915151137016}
2022-12-05 19:57:45,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:45,592 INFO:     Epoch: 29
2022-12-05 19:57:46,384 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44261811809106305, 'Total loss': 0.44261811809106305} | train loss {'Reaction outcome loss': 0.18948482737065322, 'Total loss': 0.18948482737065322}
2022-12-05 19:57:46,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:46,385 INFO:     Epoch: 30
2022-12-05 19:57:47,179 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4171604113653302, 'Total loss': 0.4171604113653302} | train loss {'Reaction outcome loss': 0.18715591306587862, 'Total loss': 0.18715591306587862}
2022-12-05 19:57:47,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:47,179 INFO:     Epoch: 31
2022-12-05 19:57:47,973 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4213769913397052, 'Total loss': 0.4213769913397052} | train loss {'Reaction outcome loss': 0.18593132476352395, 'Total loss': 0.18593132476352395}
2022-12-05 19:57:47,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:47,973 INFO:     Epoch: 32
2022-12-05 19:57:48,771 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4257497144016353, 'Total loss': 0.4257497144016353} | train loss {'Reaction outcome loss': 0.18556293850434163, 'Total loss': 0.18556293850434163}
2022-12-05 19:57:48,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:48,771 INFO:     Epoch: 33
2022-12-05 19:57:49,560 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41150492226535623, 'Total loss': 0.41150492226535623} | train loss {'Reaction outcome loss': 0.18102131403922553, 'Total loss': 0.18102131403922553}
2022-12-05 19:57:49,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:49,560 INFO:     Epoch: 34
2022-12-05 19:57:50,362 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42825697362422943, 'Total loss': 0.42825697362422943} | train loss {'Reaction outcome loss': 0.1766709685175409, 'Total loss': 0.1766709685175409}
2022-12-05 19:57:50,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:50,362 INFO:     Epoch: 35
2022-12-05 19:57:51,157 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43250601332296024, 'Total loss': 0.43250601332296024} | train loss {'Reaction outcome loss': 0.176173068395245, 'Total loss': 0.176173068395245}
2022-12-05 19:57:51,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:51,157 INFO:     Epoch: 36
2022-12-05 19:57:51,956 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4273057390343059, 'Total loss': 0.4273057390343059} | train loss {'Reaction outcome loss': 0.17598988385420414, 'Total loss': 0.17598988385420414}
2022-12-05 19:57:51,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:51,957 INFO:     Epoch: 37
2022-12-05 19:57:52,751 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4393625980751081, 'Total loss': 0.4393625980751081} | train loss {'Reaction outcome loss': 0.1707349735191993, 'Total loss': 0.1707349735191993}
2022-12-05 19:57:52,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:52,751 INFO:     Epoch: 38
2022-12-05 19:57:53,543 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43912217376584356, 'Total loss': 0.43912217376584356} | train loss {'Reaction outcome loss': 0.1669524310742535, 'Total loss': 0.1669524310742535}
2022-12-05 19:57:53,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:53,543 INFO:     Epoch: 39
2022-12-05 19:57:54,338 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.415906294841658, 'Total loss': 0.415906294841658} | train loss {'Reaction outcome loss': 0.16688411016648094, 'Total loss': 0.16688411016648094}
2022-12-05 19:57:54,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:54,339 INFO:     Epoch: 40
2022-12-05 19:57:55,136 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42650260640816257, 'Total loss': 0.42650260640816257} | train loss {'Reaction outcome loss': 0.16428548904255993, 'Total loss': 0.16428548904255993}
2022-12-05 19:57:55,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:55,137 INFO:     Epoch: 41
2022-12-05 19:57:55,929 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4381974772973494, 'Total loss': 0.4381974772973494} | train loss {'Reaction outcome loss': 0.1627587005120492, 'Total loss': 0.1627587005120492}
2022-12-05 19:57:55,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:55,929 INFO:     Epoch: 42
2022-12-05 19:57:56,722 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4309738959101113, 'Total loss': 0.4309738959101113} | train loss {'Reaction outcome loss': 0.1591017881873995, 'Total loss': 0.1591017881873995}
2022-12-05 19:57:56,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:56,722 INFO:     Epoch: 43
2022-12-05 19:57:57,522 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4478662305257537, 'Total loss': 0.4478662305257537} | train loss {'Reaction outcome loss': 0.15802046331396746, 'Total loss': 0.15802046331396746}
2022-12-05 19:57:57,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:57,522 INFO:     Epoch: 44
2022-12-05 19:57:58,319 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.440963361073624, 'Total loss': 0.440963361073624} | train loss {'Reaction outcome loss': 0.154834256154455, 'Total loss': 0.154834256154455}
2022-12-05 19:57:58,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:58,320 INFO:     Epoch: 45
2022-12-05 19:57:59,122 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44439949772574683, 'Total loss': 0.44439949772574683} | train loss {'Reaction outcome loss': 0.1601306604627039, 'Total loss': 0.1601306604627039}
2022-12-05 19:57:59,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:59,123 INFO:     Epoch: 46
2022-12-05 19:57:59,917 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4396115585484288, 'Total loss': 0.4396115585484288} | train loss {'Reaction outcome loss': 0.1554897862426456, 'Total loss': 0.1554897862426456}
2022-12-05 19:57:59,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:57:59,918 INFO:     Epoch: 47
2022-12-05 19:58:00,707 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4288841482590545, 'Total loss': 0.4288841482590545} | train loss {'Reaction outcome loss': 0.15113394307122835, 'Total loss': 0.15113394307122835}
2022-12-05 19:58:00,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:00,707 INFO:     Epoch: 48
2022-12-05 19:58:01,496 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.440454173494469, 'Total loss': 0.440454173494469} | train loss {'Reaction outcome loss': 0.15282814725933055, 'Total loss': 0.15282814725933055}
2022-12-05 19:58:01,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:01,496 INFO:     Epoch: 49
2022-12-05 19:58:02,286 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43815668020397425, 'Total loss': 0.43815668020397425} | train loss {'Reaction outcome loss': 0.15021947440090438, 'Total loss': 0.15021947440090438}
2022-12-05 19:58:02,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:02,287 INFO:     Epoch: 50
2022-12-05 19:58:03,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.433707251467488, 'Total loss': 0.433707251467488} | train loss {'Reaction outcome loss': 0.14809281806716876, 'Total loss': 0.14809281806716876}
2022-12-05 19:58:03,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:03,082 INFO:     Epoch: 51
2022-12-05 19:58:03,873 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43424890393560583, 'Total loss': 0.43424890393560583} | train loss {'Reaction outcome loss': 0.14958013353809232, 'Total loss': 0.14958013353809232}
2022-12-05 19:58:03,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:03,873 INFO:     Epoch: 52
2022-12-05 19:58:04,666 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.441810493780808, 'Total loss': 0.441810493780808} | train loss {'Reaction outcome loss': 0.14645311025707353, 'Total loss': 0.14645311025707353}
2022-12-05 19:58:04,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:04,666 INFO:     Epoch: 53
2022-12-05 19:58:05,459 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43395384367216716, 'Total loss': 0.43395384367216716} | train loss {'Reaction outcome loss': 0.1463409148667368, 'Total loss': 0.1463409148667368}
2022-12-05 19:58:05,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:05,459 INFO:     Epoch: 54
2022-12-05 19:58:06,252 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44036338884722104, 'Total loss': 0.44036338884722104} | train loss {'Reaction outcome loss': 0.14552793705896025, 'Total loss': 0.14552793705896025}
2022-12-05 19:58:06,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:06,252 INFO:     Epoch: 55
2022-12-05 19:58:07,042 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4302669597620314, 'Total loss': 0.4302669597620314} | train loss {'Reaction outcome loss': 0.1440538562338559, 'Total loss': 0.1440538562338559}
2022-12-05 19:58:07,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:07,043 INFO:     Epoch: 56
2022-12-05 19:58:07,832 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4392909861423753, 'Total loss': 0.4392909861423753} | train loss {'Reaction outcome loss': 0.14131683680499274, 'Total loss': 0.14131683680499274}
2022-12-05 19:58:07,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:07,833 INFO:     Epoch: 57
2022-12-05 19:58:08,621 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43290574493055994, 'Total loss': 0.43290574493055994} | train loss {'Reaction outcome loss': 0.1425888222236667, 'Total loss': 0.1425888222236667}
2022-12-05 19:58:08,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:08,621 INFO:     Epoch: 58
2022-12-05 19:58:09,413 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4558269520374862, 'Total loss': 0.4558269520374862} | train loss {'Reaction outcome loss': 0.13922996541875746, 'Total loss': 0.13922996541875746}
2022-12-05 19:58:09,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:09,413 INFO:     Epoch: 59
2022-12-05 19:58:10,203 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4374502230096947, 'Total loss': 0.4374502230096947} | train loss {'Reaction outcome loss': 0.14187789407198229, 'Total loss': 0.14187789407198229}
2022-12-05 19:58:10,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:10,203 INFO:     Epoch: 60
2022-12-05 19:58:10,997 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.431862339716066, 'Total loss': 0.431862339716066} | train loss {'Reaction outcome loss': 0.1369739080583977, 'Total loss': 0.1369739080583977}
2022-12-05 19:58:10,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:10,998 INFO:     Epoch: 61
2022-12-05 19:58:11,792 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43480836667797784, 'Total loss': 0.43480836667797784} | train loss {'Reaction outcome loss': 0.13730835932637414, 'Total loss': 0.13730835932637414}
2022-12-05 19:58:11,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:11,792 INFO:     Epoch: 62
2022-12-05 19:58:12,586 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.436090822416273, 'Total loss': 0.436090822416273} | train loss {'Reaction outcome loss': 0.13858481781226734, 'Total loss': 0.13858481781226734}
2022-12-05 19:58:12,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:12,587 INFO:     Epoch: 63
2022-12-05 19:58:13,379 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4419746155088598, 'Total loss': 0.4419746155088598} | train loss {'Reaction outcome loss': 0.136232475261955, 'Total loss': 0.136232475261955}
2022-12-05 19:58:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:13,380 INFO:     Epoch: 64
2022-12-05 19:58:14,177 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4523722031577067, 'Total loss': 0.4523722031577067} | train loss {'Reaction outcome loss': 0.13594112376261863, 'Total loss': 0.13594112376261863}
2022-12-05 19:58:14,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:14,177 INFO:     Epoch: 65
2022-12-05 19:58:14,974 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.426821038804271, 'Total loss': 0.426821038804271} | train loss {'Reaction outcome loss': 0.1329613668663848, 'Total loss': 0.1329613668663848}
2022-12-05 19:58:14,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:14,974 INFO:     Epoch: 66
2022-12-05 19:58:15,764 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.438945222645998, 'Total loss': 0.438945222645998} | train loss {'Reaction outcome loss': 0.13498698264330386, 'Total loss': 0.13498698264330386}
2022-12-05 19:58:15,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:15,764 INFO:     Epoch: 67
2022-12-05 19:58:16,553 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4381855976852504, 'Total loss': 0.4381855976852504} | train loss {'Reaction outcome loss': 0.13276129137844808, 'Total loss': 0.13276129137844808}
2022-12-05 19:58:16,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:16,554 INFO:     Epoch: 68
2022-12-05 19:58:17,348 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44339692423289473, 'Total loss': 0.44339692423289473} | train loss {'Reaction outcome loss': 0.13492611749097705, 'Total loss': 0.13492611749097705}
2022-12-05 19:58:17,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:17,349 INFO:     Epoch: 69
2022-12-05 19:58:18,139 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42999656684696674, 'Total loss': 0.42999656684696674} | train loss {'Reaction outcome loss': 0.13069010618698573, 'Total loss': 0.13069010618698573}
2022-12-05 19:58:18,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:18,139 INFO:     Epoch: 70
2022-12-05 19:58:18,931 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44654509696093475, 'Total loss': 0.44654509696093475} | train loss {'Reaction outcome loss': 0.13303174728888176, 'Total loss': 0.13303174728888176}
2022-12-05 19:58:18,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:18,931 INFO:     Epoch: 71
2022-12-05 19:58:19,725 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.435902843082493, 'Total loss': 0.435902843082493} | train loss {'Reaction outcome loss': 0.1296690112437993, 'Total loss': 0.1296690112437993}
2022-12-05 19:58:19,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:19,725 INFO:     Epoch: 72
2022-12-05 19:58:20,515 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4441535808146, 'Total loss': 0.4441535808146} | train loss {'Reaction outcome loss': 0.1284858741752443, 'Total loss': 0.1284858741752443}
2022-12-05 19:58:20,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:20,515 INFO:     Epoch: 73
2022-12-05 19:58:21,308 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4403962333771316, 'Total loss': 0.4403962333771316} | train loss {'Reaction outcome loss': 0.12956867705760222, 'Total loss': 0.12956867705760222}
2022-12-05 19:58:21,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:21,308 INFO:     Epoch: 74
2022-12-05 19:58:22,097 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44874905405396764, 'Total loss': 0.44874905405396764} | train loss {'Reaction outcome loss': 0.12892979665869667, 'Total loss': 0.12892979665869667}
2022-12-05 19:58:22,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:22,097 INFO:     Epoch: 75
2022-12-05 19:58:22,887 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45668119192123413, 'Total loss': 0.45668119192123413} | train loss {'Reaction outcome loss': 0.12732351566815087, 'Total loss': 0.12732351566815087}
2022-12-05 19:58:22,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:22,888 INFO:     Epoch: 76
2022-12-05 19:58:23,686 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43793112479827623, 'Total loss': 0.43793112479827623} | train loss {'Reaction outcome loss': 0.12757574835596908, 'Total loss': 0.12757574835596908}
2022-12-05 19:58:23,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:23,686 INFO:     Epoch: 77
2022-12-05 19:58:24,482 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4453797038983215, 'Total loss': 0.4453797038983215} | train loss {'Reaction outcome loss': 0.12737250320177765, 'Total loss': 0.12737250320177765}
2022-12-05 19:58:24,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:24,482 INFO:     Epoch: 78
2022-12-05 19:58:25,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4489539221606471, 'Total loss': 0.4489539221606471} | train loss {'Reaction outcome loss': 0.12581659349492721, 'Total loss': 0.12581659349492721}
2022-12-05 19:58:25,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:25,272 INFO:     Epoch: 79
2022-12-05 19:58:26,064 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.429408441551707, 'Total loss': 0.429408441551707} | train loss {'Reaction outcome loss': 0.126344280895747, 'Total loss': 0.126344280895747}
2022-12-05 19:58:26,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:26,064 INFO:     Epoch: 80
2022-12-05 19:58:26,854 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44981871714646166, 'Total loss': 0.44981871714646166} | train loss {'Reaction outcome loss': 0.12482985266814789, 'Total loss': 0.12482985266814789}
2022-12-05 19:58:26,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:26,854 INFO:     Epoch: 81
2022-12-05 19:58:27,645 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44158116507936607, 'Total loss': 0.44158116507936607} | train loss {'Reaction outcome loss': 0.12555127239395533, 'Total loss': 0.12555127239395533}
2022-12-05 19:58:27,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:27,645 INFO:     Epoch: 82
2022-12-05 19:58:28,438 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4321842406961051, 'Total loss': 0.4321842406961051} | train loss {'Reaction outcome loss': 0.1233568534878413, 'Total loss': 0.1233568534878413}
2022-12-05 19:58:28,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:28,438 INFO:     Epoch: 83
2022-12-05 19:58:29,230 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4290849121118134, 'Total loss': 0.4290849121118134} | train loss {'Reaction outcome loss': 0.12405535098045103, 'Total loss': 0.12405535098045103}
2022-12-05 19:58:29,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:29,231 INFO:     Epoch: 84
2022-12-05 19:58:30,025 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.440155580131845, 'Total loss': 0.440155580131845} | train loss {'Reaction outcome loss': 0.12753287877421826, 'Total loss': 0.12753287877421826}
2022-12-05 19:58:30,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:30,025 INFO:     Epoch: 85
2022-12-05 19:58:30,820 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43273416974327783, 'Total loss': 0.43273416974327783} | train loss {'Reaction outcome loss': 0.12229575124764515, 'Total loss': 0.12229575124764515}
2022-12-05 19:58:30,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:30,821 INFO:     Epoch: 86
2022-12-05 19:58:31,611 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44386898692358623, 'Total loss': 0.44386898692358623} | train loss {'Reaction outcome loss': 0.12359984035062935, 'Total loss': 0.12359984035062935}
2022-12-05 19:58:31,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:31,611 INFO:     Epoch: 87
2022-12-05 19:58:32,401 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4441618567163294, 'Total loss': 0.4441618567163294} | train loss {'Reaction outcome loss': 0.12119565451247317, 'Total loss': 0.12119565451247317}
2022-12-05 19:58:32,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:32,402 INFO:     Epoch: 88
2022-12-05 19:58:33,195 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42236190153793857, 'Total loss': 0.42236190153793857} | train loss {'Reaction outcome loss': 0.12155198714425487, 'Total loss': 0.12155198714425487}
2022-12-05 19:58:33,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:33,195 INFO:     Epoch: 89
2022-12-05 19:58:33,985 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43150544369762595, 'Total loss': 0.43150544369762595} | train loss {'Reaction outcome loss': 0.11964247124119391, 'Total loss': 0.11964247124119391}
2022-12-05 19:58:33,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:33,985 INFO:     Epoch: 90
2022-12-05 19:58:34,775 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4227267171848904, 'Total loss': 0.4227267171848904} | train loss {'Reaction outcome loss': 0.11879281632061447, 'Total loss': 0.11879281632061447}
2022-12-05 19:58:34,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:34,776 INFO:     Epoch: 91
2022-12-05 19:58:35,569 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4484521834687753, 'Total loss': 0.4484521834687753} | train loss {'Reaction outcome loss': 0.12212876794153764, 'Total loss': 0.12212876794153764}
2022-12-05 19:58:35,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:35,569 INFO:     Epoch: 92
2022-12-05 19:58:36,365 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44461567869240587, 'Total loss': 0.44461567869240587} | train loss {'Reaction outcome loss': 0.12181575892628321, 'Total loss': 0.12181575892628321}
2022-12-05 19:58:36,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:36,365 INFO:     Epoch: 93
2022-12-05 19:58:37,163 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4429492086849429, 'Total loss': 0.4429492086849429} | train loss {'Reaction outcome loss': 0.12086506626163158, 'Total loss': 0.12086506626163158}
2022-12-05 19:58:37,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:37,163 INFO:     Epoch: 94
2022-12-05 19:58:37,954 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4529387839138508, 'Total loss': 0.4529387839138508} | train loss {'Reaction outcome loss': 0.11956301631571184, 'Total loss': 0.11956301631571184}
2022-12-05 19:58:37,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:37,954 INFO:     Epoch: 95
2022-12-05 19:58:38,744 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4503355784849687, 'Total loss': 0.4503355784849687} | train loss {'Reaction outcome loss': 0.11869225071202363, 'Total loss': 0.11869225071202363}
2022-12-05 19:58:38,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:38,744 INFO:     Epoch: 96
2022-12-05 19:58:39,540 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4278457909822464, 'Total loss': 0.4278457909822464} | train loss {'Reaction outcome loss': 0.11921554719353275, 'Total loss': 0.11921554719353275}
2022-12-05 19:58:39,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:39,541 INFO:     Epoch: 97
2022-12-05 19:58:40,338 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4380458127707243, 'Total loss': 0.4380458127707243} | train loss {'Reaction outcome loss': 0.11851945295253949, 'Total loss': 0.11851945295253949}
2022-12-05 19:58:40,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:40,338 INFO:     Epoch: 98
2022-12-05 19:58:41,128 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44018418714404106, 'Total loss': 0.44018418714404106} | train loss {'Reaction outcome loss': 0.11864249664358795, 'Total loss': 0.11864249664358795}
2022-12-05 19:58:41,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:41,128 INFO:     Epoch: 99
2022-12-05 19:58:41,920 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44388197870417073, 'Total loss': 0.44388197870417073} | train loss {'Reaction outcome loss': 0.11885551502928138, 'Total loss': 0.11885551502928138}
2022-12-05 19:58:41,920 INFO:     Best model found after epoch 19 of 100.
2022-12-05 19:58:41,921 INFO:   Done with stage: TRAINING
2022-12-05 19:58:41,921 INFO:   Starting stage: EVALUATION
2022-12-05 19:58:42,041 INFO:   Done with stage: EVALUATION
2022-12-05 19:58:42,041 INFO:   Leaving out SEQ value Fold_9
2022-12-05 19:58:42,054 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 19:58:42,054 INFO:   Starting stage: FEATURE SCALING
2022-12-05 19:58:42,694 INFO:   Done with stage: FEATURE SCALING
2022-12-05 19:58:42,694 INFO:   Starting stage: SCALING TARGETS
2022-12-05 19:58:42,763 INFO:   Done with stage: SCALING TARGETS
2022-12-05 19:58:42,763 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:58:42,763 INFO:     No hyperparam tuning for this model
2022-12-05 19:58:42,763 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 19:58:42,763 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 19:58:42,764 INFO:     None feature selector for col prot
2022-12-05 19:58:42,764 INFO:     None feature selector for col prot
2022-12-05 19:58:42,764 INFO:     None feature selector for col prot
2022-12-05 19:58:42,764 INFO:     None feature selector for col chem
2022-12-05 19:58:42,764 INFO:     None feature selector for col chem
2022-12-05 19:58:42,764 INFO:     None feature selector for col chem
2022-12-05 19:58:42,765 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 19:58:42,765 INFO:   Starting stage: BUILD MODEL
2022-12-05 19:58:42,766 INFO:     Number of params in model 215821
2022-12-05 19:58:42,769 INFO:   Done with stage: BUILD MODEL
2022-12-05 19:58:42,769 INFO:   Starting stage: TRAINING
2022-12-05 19:58:42,830 INFO:     Val loss before train {'Reaction outcome loss': 1.0357562229037285, 'Total loss': 1.0357562229037285}
2022-12-05 19:58:42,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:42,830 INFO:     Epoch: 0
2022-12-05 19:58:43,623 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6090939302336086, 'Total loss': 0.6090939302336086} | train loss {'Reaction outcome loss': 0.7928946067688436, 'Total loss': 0.7928946067688436}
2022-12-05 19:58:43,624 INFO:     Found new best model at epoch 0
2022-12-05 19:58:43,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:43,624 INFO:     Epoch: 1
2022-12-05 19:58:44,412 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5283520004966042, 'Total loss': 0.5283520004966042} | train loss {'Reaction outcome loss': 0.5387654331350616, 'Total loss': 0.5387654331350616}
2022-12-05 19:58:44,412 INFO:     Found new best model at epoch 1
2022-12-05 19:58:44,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:44,413 INFO:     Epoch: 2
2022-12-05 19:58:45,202 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48887517337094655, 'Total loss': 0.48887517337094655} | train loss {'Reaction outcome loss': 0.4667437501281862, 'Total loss': 0.4667437501281862}
2022-12-05 19:58:45,202 INFO:     Found new best model at epoch 2
2022-12-05 19:58:45,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:45,203 INFO:     Epoch: 3
2022-12-05 19:58:45,993 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4661860242486, 'Total loss': 0.4661860242486} | train loss {'Reaction outcome loss': 0.4237780563518224, 'Total loss': 0.4237780563518224}
2022-12-05 19:58:45,993 INFO:     Found new best model at epoch 3
2022-12-05 19:58:45,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:45,994 INFO:     Epoch: 4
2022-12-05 19:58:46,785 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4428645338524472, 'Total loss': 0.4428645338524472} | train loss {'Reaction outcome loss': 0.39643258707002105, 'Total loss': 0.39643258707002105}
2022-12-05 19:58:46,785 INFO:     Found new best model at epoch 4
2022-12-05 19:58:46,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:46,786 INFO:     Epoch: 5
2022-12-05 19:58:47,572 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4367509270933541, 'Total loss': 0.4367509270933541} | train loss {'Reaction outcome loss': 0.3730076545404519, 'Total loss': 0.3730076545404519}
2022-12-05 19:58:47,572 INFO:     Found new best model at epoch 5
2022-12-05 19:58:47,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:47,573 INFO:     Epoch: 6
2022-12-05 19:58:48,360 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4387228922410445, 'Total loss': 0.4387228922410445} | train loss {'Reaction outcome loss': 0.35379801319557647, 'Total loss': 0.35379801319557647}
2022-12-05 19:58:48,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:48,360 INFO:     Epoch: 7
2022-12-05 19:58:49,149 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42412401803515176, 'Total loss': 0.42412401803515176} | train loss {'Reaction outcome loss': 0.335544200538684, 'Total loss': 0.335544200538684}
2022-12-05 19:58:49,150 INFO:     Found new best model at epoch 7
2022-12-05 19:58:49,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:49,150 INFO:     Epoch: 8
2022-12-05 19:58:49,940 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4202204675159671, 'Total loss': 0.4202204675159671} | train loss {'Reaction outcome loss': 0.3201706429061137, 'Total loss': 0.3201706429061137}
2022-12-05 19:58:49,941 INFO:     Found new best model at epoch 8
2022-12-05 19:58:49,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:49,941 INFO:     Epoch: 9
2022-12-05 19:58:50,732 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44460215351798316, 'Total loss': 0.44460215351798316} | train loss {'Reaction outcome loss': 0.3079524085166966, 'Total loss': 0.3079524085166966}
2022-12-05 19:58:50,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:50,732 INFO:     Epoch: 10
2022-12-05 19:58:51,520 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4299497827887535, 'Total loss': 0.4299497827887535} | train loss {'Reaction outcome loss': 0.29569949635006637, 'Total loss': 0.29569949635006637}
2022-12-05 19:58:51,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:51,520 INFO:     Epoch: 11
2022-12-05 19:58:52,312 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43302528086033737, 'Total loss': 0.43302528086033737} | train loss {'Reaction outcome loss': 0.28384162550829806, 'Total loss': 0.28384162550829806}
2022-12-05 19:58:52,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:52,312 INFO:     Epoch: 12
2022-12-05 19:58:53,107 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42786096984689886, 'Total loss': 0.42786096984689886} | train loss {'Reaction outcome loss': 0.27455043278423397, 'Total loss': 0.27455043278423397}
2022-12-05 19:58:53,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:53,107 INFO:     Epoch: 13
2022-12-05 19:58:53,897 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4479701817035675, 'Total loss': 0.4479701817035675} | train loss {'Reaction outcome loss': 0.26919819094874115, 'Total loss': 0.26919819094874115}
2022-12-05 19:58:53,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:53,898 INFO:     Epoch: 14
2022-12-05 19:58:54,689 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42975789884274657, 'Total loss': 0.42975789884274657} | train loss {'Reaction outcome loss': 0.26390088340531476, 'Total loss': 0.26390088340531476}
2022-12-05 19:58:54,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:54,689 INFO:     Epoch: 15
2022-12-05 19:58:55,477 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.424945534968918, 'Total loss': 0.424945534968918} | train loss {'Reaction outcome loss': 0.24826703532806293, 'Total loss': 0.24826703532806293}
2022-12-05 19:58:55,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:55,478 INFO:     Epoch: 16
2022-12-05 19:58:56,268 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4423414028503678, 'Total loss': 0.4423414028503678} | train loss {'Reaction outcome loss': 0.24134762090468695, 'Total loss': 0.24134762090468695}
2022-12-05 19:58:56,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:56,268 INFO:     Epoch: 17
2022-12-05 19:58:57,066 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43748372488401155, 'Total loss': 0.43748372488401155} | train loss {'Reaction outcome loss': 0.236463376829921, 'Total loss': 0.236463376829921}
2022-12-05 19:58:57,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:57,066 INFO:     Epoch: 18
2022-12-05 19:58:57,855 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4260604117404331, 'Total loss': 0.4260604117404331} | train loss {'Reaction outcome loss': 0.2299036667474851, 'Total loss': 0.2299036667474851}
2022-12-05 19:58:57,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:57,855 INFO:     Epoch: 19
2022-12-05 19:58:58,646 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44772564552047034, 'Total loss': 0.44772564552047034} | train loss {'Reaction outcome loss': 0.22103415704087206, 'Total loss': 0.22103415704087206}
2022-12-05 19:58:58,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:58,647 INFO:     Epoch: 20
2022-12-05 19:58:59,442 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.441637512635101, 'Total loss': 0.441637512635101} | train loss {'Reaction outcome loss': 0.21871424174154938, 'Total loss': 0.21871424174154938}
2022-12-05 19:58:59,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:58:59,443 INFO:     Epoch: 21
2022-12-05 19:59:00,236 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4391323886811733, 'Total loss': 0.4391323886811733} | train loss {'Reaction outcome loss': 0.21302824209892918, 'Total loss': 0.21302824209892918}
2022-12-05 19:59:00,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:00,237 INFO:     Epoch: 22
2022-12-05 19:59:01,031 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4439558285203847, 'Total loss': 0.4439558285203847} | train loss {'Reaction outcome loss': 0.20789967938175477, 'Total loss': 0.20789967938175477}
2022-12-05 19:59:01,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:01,031 INFO:     Epoch: 23
2022-12-05 19:59:01,822 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4464177983728322, 'Total loss': 0.4464177983728322} | train loss {'Reaction outcome loss': 0.20493625855518255, 'Total loss': 0.20493625855518255}
2022-12-05 19:59:01,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:01,822 INFO:     Epoch: 24
2022-12-05 19:59:02,609 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43951589546420355, 'Total loss': 0.43951589546420355} | train loss {'Reaction outcome loss': 0.19845107920196375, 'Total loss': 0.19845107920196375}
2022-12-05 19:59:02,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:02,609 INFO:     Epoch: 25
2022-12-05 19:59:03,395 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4557923342693936, 'Total loss': 0.4557923342693936} | train loss {'Reaction outcome loss': 0.19265746525846994, 'Total loss': 0.19265746525846994}
2022-12-05 19:59:03,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:03,396 INFO:     Epoch: 26
2022-12-05 19:59:04,183 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45967197316614067, 'Total loss': 0.45967197316614067} | train loss {'Reaction outcome loss': 0.19012334856095342, 'Total loss': 0.19012334856095342}
2022-12-05 19:59:04,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:04,183 INFO:     Epoch: 27
2022-12-05 19:59:04,972 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44915938953107054, 'Total loss': 0.44915938953107054} | train loss {'Reaction outcome loss': 0.18955552004850829, 'Total loss': 0.18955552004850829}
2022-12-05 19:59:04,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:04,973 INFO:     Epoch: 28
2022-12-05 19:59:05,769 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47388799928806047, 'Total loss': 0.47388799928806047} | train loss {'Reaction outcome loss': 0.18317798560349505, 'Total loss': 0.18317798560349505}
2022-12-05 19:59:05,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:05,769 INFO:     Epoch: 29
2022-12-05 19:59:06,563 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46213991702957585, 'Total loss': 0.46213991702957585} | train loss {'Reaction outcome loss': 0.17678478993956181, 'Total loss': 0.17678478993956181}
2022-12-05 19:59:06,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:06,563 INFO:     Epoch: 30
2022-12-05 19:59:07,354 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4749146015806632, 'Total loss': 0.4749146015806632} | train loss {'Reaction outcome loss': 0.17318190745858528, 'Total loss': 0.17318190745858528}
2022-12-05 19:59:07,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:07,354 INFO:     Epoch: 31
2022-12-05 19:59:08,143 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.453351017087698, 'Total loss': 0.453351017087698} | train loss {'Reaction outcome loss': 0.17358919349216256, 'Total loss': 0.17358919349216256}
2022-12-05 19:59:08,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:08,143 INFO:     Epoch: 32
2022-12-05 19:59:08,932 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4662533402442932, 'Total loss': 0.4662533402442932} | train loss {'Reaction outcome loss': 0.17147040448570058, 'Total loss': 0.17147040448570058}
2022-12-05 19:59:08,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:08,932 INFO:     Epoch: 33
2022-12-05 19:59:09,723 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46518574180928146, 'Total loss': 0.46518574180928146} | train loss {'Reaction outcome loss': 0.17026126794215396, 'Total loss': 0.17026126794215396}
2022-12-05 19:59:09,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:09,724 INFO:     Epoch: 34
2022-12-05 19:59:10,513 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46907814050262625, 'Total loss': 0.46907814050262625} | train loss {'Reaction outcome loss': 0.1690670928733069, 'Total loss': 0.1690670928733069}
2022-12-05 19:59:10,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:10,514 INFO:     Epoch: 35
2022-12-05 19:59:11,301 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47219344025308435, 'Total loss': 0.47219344025308435} | train loss {'Reaction outcome loss': 0.16523568666264837, 'Total loss': 0.16523568666264837}
2022-12-05 19:59:11,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:11,301 INFO:     Epoch: 36
2022-12-05 19:59:12,091 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4711790061132474, 'Total loss': 0.4711790061132474} | train loss {'Reaction outcome loss': 0.1593478187798006, 'Total loss': 0.1593478187798006}
2022-12-05 19:59:12,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:12,091 INFO:     Epoch: 37
2022-12-05 19:59:12,881 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46957016025077214, 'Total loss': 0.46957016025077214} | train loss {'Reaction outcome loss': 0.1640896611971411, 'Total loss': 0.1640896611971411}
2022-12-05 19:59:12,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:12,882 INFO:     Epoch: 38
2022-12-05 19:59:13,672 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4565236856314269, 'Total loss': 0.4565236856314269} | train loss {'Reaction outcome loss': 0.15742059323469154, 'Total loss': 0.15742059323469154}
2022-12-05 19:59:13,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:13,672 INFO:     Epoch: 39
2022-12-05 19:59:14,468 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47316636043516075, 'Total loss': 0.47316636043516075} | train loss {'Reaction outcome loss': 0.15471462430884902, 'Total loss': 0.15471462430884902}
2022-12-05 19:59:14,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:14,469 INFO:     Epoch: 40
2022-12-05 19:59:15,263 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46400389447808266, 'Total loss': 0.46400389447808266} | train loss {'Reaction outcome loss': 0.15206786246347803, 'Total loss': 0.15206786246347803}
2022-12-05 19:59:15,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:15,263 INFO:     Epoch: 41
2022-12-05 19:59:16,055 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.476882291957736, 'Total loss': 0.476882291957736} | train loss {'Reaction outcome loss': 0.1478746153776221, 'Total loss': 0.1478746153776221}
2022-12-05 19:59:16,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:16,055 INFO:     Epoch: 42
2022-12-05 19:59:16,845 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47163174115121365, 'Total loss': 0.47163174115121365} | train loss {'Reaction outcome loss': 0.15091065105488186, 'Total loss': 0.15091065105488186}
2022-12-05 19:59:16,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:16,845 INFO:     Epoch: 43
2022-12-05 19:59:17,641 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47605269571596925, 'Total loss': 0.47605269571596925} | train loss {'Reaction outcome loss': 0.15140597839737951, 'Total loss': 0.15140597839737951}
2022-12-05 19:59:17,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:17,642 INFO:     Epoch: 44
2022-12-05 19:59:18,435 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47576493803750386, 'Total loss': 0.47576493803750386} | train loss {'Reaction outcome loss': 0.1462208846327566, 'Total loss': 0.1462208846327566}
2022-12-05 19:59:18,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:18,436 INFO:     Epoch: 45
2022-12-05 19:59:19,227 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.477792051197453, 'Total loss': 0.477792051197453} | train loss {'Reaction outcome loss': 0.14340508358952728, 'Total loss': 0.14340508358952728}
2022-12-05 19:59:19,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:19,227 INFO:     Epoch: 46
2022-12-05 19:59:20,018 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46778645468029106, 'Total loss': 0.46778645468029106} | train loss {'Reaction outcome loss': 0.14205254524614405, 'Total loss': 0.14205254524614405}
2022-12-05 19:59:20,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:20,018 INFO:     Epoch: 47
2022-12-05 19:59:20,815 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4723927639424801, 'Total loss': 0.4723927639424801} | train loss {'Reaction outcome loss': 0.14094736418396475, 'Total loss': 0.14094736418396475}
2022-12-05 19:59:20,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:20,815 INFO:     Epoch: 48
2022-12-05 19:59:21,612 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4823718115010045, 'Total loss': 0.4823718115010045} | train loss {'Reaction outcome loss': 0.14007212415428055, 'Total loss': 0.14007212415428055}
2022-12-05 19:59:21,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:21,612 INFO:     Epoch: 49
2022-12-05 19:59:22,404 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47259524396874686, 'Total loss': 0.47259524396874686} | train loss {'Reaction outcome loss': 0.13739496394275472, 'Total loss': 0.13739496394275472}
2022-12-05 19:59:22,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:22,404 INFO:     Epoch: 50
2022-12-05 19:59:23,196 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46899166550825944, 'Total loss': 0.46899166550825944} | train loss {'Reaction outcome loss': 0.1359841526025974, 'Total loss': 0.1359841526025974}
2022-12-05 19:59:23,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:23,197 INFO:     Epoch: 51
2022-12-05 19:59:23,987 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4714487611570142, 'Total loss': 0.4714487611570142} | train loss {'Reaction outcome loss': 0.13484295944000788, 'Total loss': 0.13484295944000788}
2022-12-05 19:59:23,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:23,987 INFO:     Epoch: 52
2022-12-05 19:59:24,780 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4752867618491026, 'Total loss': 0.4752867618491026} | train loss {'Reaction outcome loss': 0.135117816757637, 'Total loss': 0.135117816757637}
2022-12-05 19:59:24,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:24,781 INFO:     Epoch: 53
2022-12-05 19:59:25,573 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4783185249702497, 'Total loss': 0.4783185249702497} | train loss {'Reaction outcome loss': 0.1364338210357828, 'Total loss': 0.1364338210357828}
2022-12-05 19:59:25,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:25,574 INFO:     Epoch: 54
2022-12-05 19:59:26,365 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46612284230914985, 'Total loss': 0.46612284230914985} | train loss {'Reaction outcome loss': 0.1381118503273823, 'Total loss': 0.1381118503273823}
2022-12-05 19:59:26,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:26,365 INFO:     Epoch: 55
2022-12-05 19:59:27,156 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4949938644739715, 'Total loss': 0.4949938644739715} | train loss {'Reaction outcome loss': 0.13312506069040853, 'Total loss': 0.13312506069040853}
2022-12-05 19:59:27,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:27,156 INFO:     Epoch: 56
2022-12-05 19:59:27,949 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47157417771152477, 'Total loss': 0.47157417771152477} | train loss {'Reaction outcome loss': 0.13546690393073357, 'Total loss': 0.13546690393073357}
2022-12-05 19:59:27,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:27,950 INFO:     Epoch: 57
2022-12-05 19:59:28,741 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47916988317262044, 'Total loss': 0.47916988317262044} | train loss {'Reaction outcome loss': 0.13400253560016995, 'Total loss': 0.13400253560016995}
2022-12-05 19:59:28,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:28,741 INFO:     Epoch: 58
2022-12-05 19:59:29,535 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48060194741595874, 'Total loss': 0.48060194741595874} | train loss {'Reaction outcome loss': 0.12960298783956511, 'Total loss': 0.12960298783956511}
2022-12-05 19:59:29,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:29,536 INFO:     Epoch: 59
2022-12-05 19:59:30,329 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.481767208061435, 'Total loss': 0.481767208061435} | train loss {'Reaction outcome loss': 0.12786867331170482, 'Total loss': 0.12786867331170482}
2022-12-05 19:59:30,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:30,329 INFO:     Epoch: 60
2022-12-05 19:59:31,123 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48485690592364833, 'Total loss': 0.48485690592364833} | train loss {'Reaction outcome loss': 0.12476472429900999, 'Total loss': 0.12476472429900999}
2022-12-05 19:59:31,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:31,124 INFO:     Epoch: 61
2022-12-05 19:59:31,915 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4750315719707446, 'Total loss': 0.4750315719707446} | train loss {'Reaction outcome loss': 0.12839773698117932, 'Total loss': 0.12839773698117932}
2022-12-05 19:59:31,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:31,915 INFO:     Epoch: 62
2022-12-05 19:59:32,709 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4935518838465214, 'Total loss': 0.4935518838465214} | train loss {'Reaction outcome loss': 0.12465859561883336, 'Total loss': 0.12465859561883336}
2022-12-05 19:59:32,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:32,710 INFO:     Epoch: 63
2022-12-05 19:59:33,500 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4799584534696557, 'Total loss': 0.4799584534696557} | train loss {'Reaction outcome loss': 0.1256921281472512, 'Total loss': 0.1256921281472512}
2022-12-05 19:59:33,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:33,500 INFO:     Epoch: 64
2022-12-05 19:59:34,294 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48332288048484107, 'Total loss': 0.48332288048484107} | train loss {'Reaction outcome loss': 0.12479383956361939, 'Total loss': 0.12479383956361939}
2022-12-05 19:59:34,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:34,294 INFO:     Epoch: 65
2022-12-05 19:59:35,086 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4854079315608198, 'Total loss': 0.4854079315608198} | train loss {'Reaction outcome loss': 0.12252161637757365, 'Total loss': 0.12252161637757365}
2022-12-05 19:59:35,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:35,086 INFO:     Epoch: 66
2022-12-05 19:59:35,882 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48887072203003545, 'Total loss': 0.48887072203003545} | train loss {'Reaction outcome loss': 0.12240524961036227, 'Total loss': 0.12240524961036227}
2022-12-05 19:59:35,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:35,882 INFO:     Epoch: 67
2022-12-05 19:59:36,672 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48622421209107747, 'Total loss': 0.48622421209107747} | train loss {'Reaction outcome loss': 0.12732893128988715, 'Total loss': 0.12732893128988715}
2022-12-05 19:59:36,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:36,672 INFO:     Epoch: 68
2022-12-05 19:59:37,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4804410677064549, 'Total loss': 0.4804410677064549} | train loss {'Reaction outcome loss': 0.13036529589557516, 'Total loss': 0.13036529589557516}
2022-12-05 19:59:37,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:37,462 INFO:     Epoch: 69
2022-12-05 19:59:38,253 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4786637320437215, 'Total loss': 0.4786637320437215} | train loss {'Reaction outcome loss': 0.12615189852517264, 'Total loss': 0.12615189852517264}
2022-12-05 19:59:38,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:38,253 INFO:     Epoch: 70
2022-12-05 19:59:39,051 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4637833759188652, 'Total loss': 0.4637833759188652} | train loss {'Reaction outcome loss': 0.1335204706908117, 'Total loss': 0.1335204706908117}
2022-12-05 19:59:39,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:39,051 INFO:     Epoch: 71
2022-12-05 19:59:39,841 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48110839826139534, 'Total loss': 0.48110839826139534} | train loss {'Reaction outcome loss': 0.12899569727797136, 'Total loss': 0.12899569727797136}
2022-12-05 19:59:39,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:39,841 INFO:     Epoch: 72
2022-12-05 19:59:40,633 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48340547135607764, 'Total loss': 0.48340547135607764} | train loss {'Reaction outcome loss': 0.12330460327447426, 'Total loss': 0.12330460327447426}
2022-12-05 19:59:40,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:40,633 INFO:     Epoch: 73
2022-12-05 19:59:41,425 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48123696192421694, 'Total loss': 0.48123696192421694} | train loss {'Reaction outcome loss': 0.12515886750464378, 'Total loss': 0.12515886750464378}
2022-12-05 19:59:41,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:41,425 INFO:     Epoch: 74
2022-12-05 19:59:42,217 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4806290709159591, 'Total loss': 0.4806290709159591} | train loss {'Reaction outcome loss': 0.1345213833387549, 'Total loss': 0.1345213833387549}
2022-12-05 19:59:42,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:42,217 INFO:     Epoch: 75
2022-12-05 19:59:43,007 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49624760110269894, 'Total loss': 0.49624760110269894} | train loss {'Reaction outcome loss': 0.1199266267940402, 'Total loss': 0.1199266267940402}
2022-12-05 19:59:43,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:43,008 INFO:     Epoch: 76
2022-12-05 19:59:43,799 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48113770833746955, 'Total loss': 0.48113770833746955} | train loss {'Reaction outcome loss': 0.12192449998110533, 'Total loss': 0.12192449998110533}
2022-12-05 19:59:43,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:43,800 INFO:     Epoch: 77
2022-12-05 19:59:44,597 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4807138798589056, 'Total loss': 0.4807138798589056} | train loss {'Reaction outcome loss': 0.11876632052997828, 'Total loss': 0.11876632052997828}
2022-12-05 19:59:44,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:44,597 INFO:     Epoch: 78
2022-12-05 19:59:45,387 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48052895814180374, 'Total loss': 0.48052895814180374} | train loss {'Reaction outcome loss': 0.11830415934897386, 'Total loss': 0.11830415934897386}
2022-12-05 19:59:45,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:45,388 INFO:     Epoch: 79
2022-12-05 19:59:46,178 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46759044378995895, 'Total loss': 0.46759044378995895} | train loss {'Reaction outcome loss': 0.11772208204606043, 'Total loss': 0.11772208204606043}
2022-12-05 19:59:46,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:46,178 INFO:     Epoch: 80
2022-12-05 19:59:46,970 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4799112169580026, 'Total loss': 0.4799112169580026} | train loss {'Reaction outcome loss': 0.11568476137543014, 'Total loss': 0.11568476137543014}
2022-12-05 19:59:46,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:46,970 INFO:     Epoch: 81
2022-12-05 19:59:47,760 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48549017242409964, 'Total loss': 0.48549017242409964} | train loss {'Reaction outcome loss': 0.11543818491205633, 'Total loss': 0.11543818491205633}
2022-12-05 19:59:47,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:47,761 INFO:     Epoch: 82
2022-12-05 19:59:48,553 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46785589459944854, 'Total loss': 0.46785589459944854} | train loss {'Reaction outcome loss': 0.11748689145739624, 'Total loss': 0.11748689145739624}
2022-12-05 19:59:48,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:48,553 INFO:     Epoch: 83
2022-12-05 19:59:49,343 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4562198580666022, 'Total loss': 0.4562198580666022} | train loss {'Reaction outcome loss': 0.11611590233371265, 'Total loss': 0.11611590233371265}
2022-12-05 19:59:49,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:49,344 INFO:     Epoch: 84
2022-12-05 19:59:50,135 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47216293385083025, 'Total loss': 0.47216293385083025} | train loss {'Reaction outcome loss': 0.11322103243562495, 'Total loss': 0.11322103243562495}
2022-12-05 19:59:50,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:50,135 INFO:     Epoch: 85
2022-12-05 19:59:50,926 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47751364382830536, 'Total loss': 0.47751364382830536} | train loss {'Reaction outcome loss': 0.11376173294909102, 'Total loss': 0.11376173294909102}
2022-12-05 19:59:50,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:50,926 INFO:     Epoch: 86
2022-12-05 19:59:51,720 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4698804561048746, 'Total loss': 0.4698804561048746} | train loss {'Reaction outcome loss': 0.11510881099110915, 'Total loss': 0.11510881099110915}
2022-12-05 19:59:51,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:51,720 INFO:     Epoch: 87
2022-12-05 19:59:52,513 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4724826138805259, 'Total loss': 0.4724826138805259} | train loss {'Reaction outcome loss': 0.1148855202196935, 'Total loss': 0.1148855202196935}
2022-12-05 19:59:52,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:52,514 INFO:     Epoch: 88
2022-12-05 19:59:53,306 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48096281357786874, 'Total loss': 0.48096281357786874} | train loss {'Reaction outcome loss': 0.11624809331920466, 'Total loss': 0.11624809331920466}
2022-12-05 19:59:53,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:53,306 INFO:     Epoch: 89
2022-12-05 19:59:54,097 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4674310013651848, 'Total loss': 0.4674310013651848} | train loss {'Reaction outcome loss': 0.1131531674554383, 'Total loss': 0.1131531674554383}
2022-12-05 19:59:54,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:54,097 INFO:     Epoch: 90
2022-12-05 19:59:54,888 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48879321732304315, 'Total loss': 0.48879321732304315} | train loss {'Reaction outcome loss': 0.11286892718653174, 'Total loss': 0.11286892718653174}
2022-12-05 19:59:54,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:54,889 INFO:     Epoch: 91
2022-12-05 19:59:55,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48467805168845435, 'Total loss': 0.48467805168845435} | train loss {'Reaction outcome loss': 0.11461403237482314, 'Total loss': 0.11461403237482314}
2022-12-05 19:59:55,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:55,682 INFO:     Epoch: 92
2022-12-05 19:59:56,473 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.467169733887369, 'Total loss': 0.467169733887369} | train loss {'Reaction outcome loss': 0.11053514571272229, 'Total loss': 0.11053514571272229}
2022-12-05 19:59:56,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:56,473 INFO:     Epoch: 93
2022-12-05 19:59:57,263 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48345018550753593, 'Total loss': 0.48345018550753593} | train loss {'Reaction outcome loss': 0.11206169295603567, 'Total loss': 0.11206169295603567}
2022-12-05 19:59:57,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:57,264 INFO:     Epoch: 94
2022-12-05 19:59:58,054 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48025752299211244, 'Total loss': 0.48025752299211244} | train loss {'Reaction outcome loss': 0.1120030851318286, 'Total loss': 0.1120030851318286}
2022-12-05 19:59:58,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:58,055 INFO:     Epoch: 95
2022-12-05 19:59:58,846 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48203917931426654, 'Total loss': 0.48203917931426654} | train loss {'Reaction outcome loss': 0.1160458525671503, 'Total loss': 0.1160458525671503}
2022-12-05 19:59:58,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:58,846 INFO:     Epoch: 96
2022-12-05 19:59:59,643 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47218834998255427, 'Total loss': 0.47218834998255427} | train loss {'Reaction outcome loss': 0.11095143399325762, 'Total loss': 0.11095143399325762}
2022-12-05 19:59:59,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 19:59:59,643 INFO:     Epoch: 97
2022-12-05 20:00:00,436 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4722114530476657, 'Total loss': 0.4722114530476657} | train loss {'Reaction outcome loss': 0.11216980002929837, 'Total loss': 0.11216980002929837}
2022-12-05 20:00:00,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:00,437 INFO:     Epoch: 98
2022-12-05 20:00:01,235 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48005926922302355, 'Total loss': 0.48005926922302355} | train loss {'Reaction outcome loss': 0.1084985128275839, 'Total loss': 0.1084985128275839}
2022-12-05 20:00:01,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:01,235 INFO:     Epoch: 99
2022-12-05 20:00:02,027 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4810559634457935, 'Total loss': 0.4810559634457935} | train loss {'Reaction outcome loss': 0.12251133864994353, 'Total loss': 0.12251133864994353}
2022-12-05 20:00:02,028 INFO:     Best model found after epoch 9 of 100.
2022-12-05 20:00:02,029 INFO:   Done with stage: TRAINING
2022-12-05 20:00:02,029 INFO:   Starting stage: EVALUATION
2022-12-05 20:00:02,154 INFO:   Done with stage: EVALUATION
2022-12-05 20:00:02,163 INFO:   Leaving out SEQ value Fold_0
2022-12-05 20:00:02,176 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:00:02,176 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:00:02,814 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:00:02,814 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:00:02,881 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:00:02,882 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:00:02,882 INFO:     No hyperparam tuning for this model
2022-12-05 20:00:02,882 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:00:02,882 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:00:02,882 INFO:     None feature selector for col prot
2022-12-05 20:00:02,883 INFO:     None feature selector for col prot
2022-12-05 20:00:02,883 INFO:     None feature selector for col prot
2022-12-05 20:00:02,883 INFO:     None feature selector for col chem
2022-12-05 20:00:02,883 INFO:     None feature selector for col chem
2022-12-05 20:00:02,883 INFO:     None feature selector for col chem
2022-12-05 20:00:02,884 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:00:02,884 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:00:02,885 INFO:     Number of params in model 215821
2022-12-05 20:00:02,888 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:00:02,888 INFO:   Starting stage: TRAINING
2022-12-05 20:00:02,949 INFO:     Val loss before train {'Reaction outcome loss': 1.08601244606755, 'Total loss': 1.08601244606755}
2022-12-05 20:00:02,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:02,949 INFO:     Epoch: 0
2022-12-05 20:00:03,733 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6253599748015404, 'Total loss': 0.6253599748015404} | train loss {'Reaction outcome loss': 0.78076739809951, 'Total loss': 0.78076739809951}
2022-12-05 20:00:03,733 INFO:     Found new best model at epoch 0
2022-12-05 20:00:03,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:03,734 INFO:     Epoch: 1
2022-12-05 20:00:04,517 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5258436799049377, 'Total loss': 0.5258436799049377} | train loss {'Reaction outcome loss': 0.5283114957566164, 'Total loss': 0.5283114957566164}
2022-12-05 20:00:04,517 INFO:     Found new best model at epoch 1
2022-12-05 20:00:04,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:04,518 INFO:     Epoch: 2
2022-12-05 20:00:05,302 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5114491541277278, 'Total loss': 0.5114491541277278} | train loss {'Reaction outcome loss': 0.4649868643405486, 'Total loss': 0.4649868643405486}
2022-12-05 20:00:05,303 INFO:     Found new best model at epoch 2
2022-12-05 20:00:05,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:05,304 INFO:     Epoch: 3
2022-12-05 20:00:06,086 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48902320523153653, 'Total loss': 0.48902320523153653} | train loss {'Reaction outcome loss': 0.42757807221947886, 'Total loss': 0.42757807221947886}
2022-12-05 20:00:06,086 INFO:     Found new best model at epoch 3
2022-12-05 20:00:06,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:06,087 INFO:     Epoch: 4
2022-12-05 20:00:06,871 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45758814635601913, 'Total loss': 0.45758814635601913} | train loss {'Reaction outcome loss': 0.39515591020486796, 'Total loss': 0.39515591020486796}
2022-12-05 20:00:06,872 INFO:     Found new best model at epoch 4
2022-12-05 20:00:06,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:06,872 INFO:     Epoch: 5
2022-12-05 20:00:07,654 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4585785723545335, 'Total loss': 0.4585785723545335} | train loss {'Reaction outcome loss': 0.3717775077235942, 'Total loss': 0.3717775077235942}
2022-12-05 20:00:07,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:07,654 INFO:     Epoch: 6
2022-12-05 20:00:08,436 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45724123411557893, 'Total loss': 0.45724123411557893} | train loss {'Reaction outcome loss': 0.3531799832929154, 'Total loss': 0.3531799832929154}
2022-12-05 20:00:08,436 INFO:     Found new best model at epoch 6
2022-12-05 20:00:08,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:08,437 INFO:     Epoch: 7
2022-12-05 20:00:09,222 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4501128860495307, 'Total loss': 0.4501128860495307} | train loss {'Reaction outcome loss': 0.3326829609518148, 'Total loss': 0.3326829609518148}
2022-12-05 20:00:09,222 INFO:     Found new best model at epoch 7
2022-12-05 20:00:09,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:09,223 INFO:     Epoch: 8
2022-12-05 20:00:10,005 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45473942228338937, 'Total loss': 0.45473942228338937} | train loss {'Reaction outcome loss': 0.31782777099585047, 'Total loss': 0.31782777099585047}
2022-12-05 20:00:10,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:10,005 INFO:     Epoch: 9
2022-12-05 20:00:10,789 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4347981803796508, 'Total loss': 0.4347981803796508} | train loss {'Reaction outcome loss': 0.30469797770587764, 'Total loss': 0.30469797770587764}
2022-12-05 20:00:10,789 INFO:     Found new best model at epoch 9
2022-12-05 20:00:10,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:10,790 INFO:     Epoch: 10
2022-12-05 20:00:11,572 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43251737274906854, 'Total loss': 0.43251737274906854} | train loss {'Reaction outcome loss': 0.2939056562525885, 'Total loss': 0.2939056562525885}
2022-12-05 20:00:11,573 INFO:     Found new best model at epoch 10
2022-12-05 20:00:11,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:11,573 INFO:     Epoch: 11
2022-12-05 20:00:12,363 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43547514182600106, 'Total loss': 0.43547514182600106} | train loss {'Reaction outcome loss': 0.2819290555253321, 'Total loss': 0.2819290555253321}
2022-12-05 20:00:12,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:12,363 INFO:     Epoch: 12
2022-12-05 20:00:13,153 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4295128421349959, 'Total loss': 0.4295128421349959} | train loss {'Reaction outcome loss': 0.267852316188569, 'Total loss': 0.267852316188569}
2022-12-05 20:00:13,154 INFO:     Found new best model at epoch 12
2022-12-05 20:00:13,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:13,154 INFO:     Epoch: 13
2022-12-05 20:00:13,939 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45447273044423625, 'Total loss': 0.45447273044423625} | train loss {'Reaction outcome loss': 0.2605885920627993, 'Total loss': 0.2605885920627993}
2022-12-05 20:00:13,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:13,940 INFO:     Epoch: 14
2022-12-05 20:00:14,722 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44429883326996455, 'Total loss': 0.44429883326996455} | train loss {'Reaction outcome loss': 0.25579993426799774, 'Total loss': 0.25579993426799774}
2022-12-05 20:00:14,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:14,723 INFO:     Epoch: 15
2022-12-05 20:00:15,509 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45737657899206335, 'Total loss': 0.45737657899206335} | train loss {'Reaction outcome loss': 0.243938261209702, 'Total loss': 0.243938261209702}
2022-12-05 20:00:15,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:15,509 INFO:     Epoch: 16
2022-12-05 20:00:16,295 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45446945100345393, 'Total loss': 0.45446945100345393} | train loss {'Reaction outcome loss': 0.2371035505618368, 'Total loss': 0.2371035505618368}
2022-12-05 20:00:16,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:16,295 INFO:     Epoch: 17
2022-12-05 20:00:17,079 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43762848526239395, 'Total loss': 0.43762848526239395} | train loss {'Reaction outcome loss': 0.23052761913562309, 'Total loss': 0.23052761913562309}
2022-12-05 20:00:17,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:17,079 INFO:     Epoch: 18
2022-12-05 20:00:17,863 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4293472465466369, 'Total loss': 0.4293472465466369} | train loss {'Reaction outcome loss': 0.2260930746793747, 'Total loss': 0.2260930746793747}
2022-12-05 20:00:17,863 INFO:     Found new best model at epoch 18
2022-12-05 20:00:17,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:17,864 INFO:     Epoch: 19
2022-12-05 20:00:18,646 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4266444387083704, 'Total loss': 0.4266444387083704} | train loss {'Reaction outcome loss': 0.21742293477362515, 'Total loss': 0.21742293477362515}
2022-12-05 20:00:18,646 INFO:     Found new best model at epoch 19
2022-12-05 20:00:18,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:18,647 INFO:     Epoch: 20
2022-12-05 20:00:19,432 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44840513288297434, 'Total loss': 0.44840513288297434} | train loss {'Reaction outcome loss': 0.2155973705938276, 'Total loss': 0.2155973705938276}
2022-12-05 20:00:19,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:19,433 INFO:     Epoch: 21
2022-12-05 20:00:20,213 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4431949748911641, 'Total loss': 0.4431949748911641} | train loss {'Reaction outcome loss': 0.20909017131340746, 'Total loss': 0.20909017131340746}
2022-12-05 20:00:20,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:20,213 INFO:     Epoch: 22
2022-12-05 20:00:20,995 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45125852965495805, 'Total loss': 0.45125852965495805} | train loss {'Reaction outcome loss': 0.204377063561459, 'Total loss': 0.204377063561459}
2022-12-05 20:00:20,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:20,995 INFO:     Epoch: 23
2022-12-05 20:00:21,781 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4326530495150523, 'Total loss': 0.4326530495150523} | train loss {'Reaction outcome loss': 0.19956949677090255, 'Total loss': 0.19956949677090255}
2022-12-05 20:00:21,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:21,781 INFO:     Epoch: 24
2022-12-05 20:00:22,569 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4508709321645173, 'Total loss': 0.4508709321645173} | train loss {'Reaction outcome loss': 0.19721247447388512, 'Total loss': 0.19721247447388512}
2022-12-05 20:00:22,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:22,569 INFO:     Epoch: 25
2022-12-05 20:00:23,353 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.463216383010149, 'Total loss': 0.463216383010149} | train loss {'Reaction outcome loss': 0.19317417515783894, 'Total loss': 0.19317417515783894}
2022-12-05 20:00:23,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:23,354 INFO:     Epoch: 26
2022-12-05 20:00:24,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4456090513955463, 'Total loss': 0.4456090513955463} | train loss {'Reaction outcome loss': 0.19042976106307943, 'Total loss': 0.19042976106307943}
2022-12-05 20:00:24,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:24,138 INFO:     Epoch: 27
2022-12-05 20:00:24,924 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.441132492301139, 'Total loss': 0.441132492301139} | train loss {'Reaction outcome loss': 0.184550903053308, 'Total loss': 0.184550903053308}
2022-12-05 20:00:24,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:24,924 INFO:     Epoch: 28
2022-12-05 20:00:25,710 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4409008498451757, 'Total loss': 0.4409008498451757} | train loss {'Reaction outcome loss': 0.18256856438760855, 'Total loss': 0.18256856438760855}
2022-12-05 20:00:25,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:25,710 INFO:     Epoch: 29
2022-12-05 20:00:26,497 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4566846713423729, 'Total loss': 0.4566846713423729} | train loss {'Reaction outcome loss': 0.17773120283928454, 'Total loss': 0.17773120283928454}
2022-12-05 20:00:26,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:26,498 INFO:     Epoch: 30
2022-12-05 20:00:27,284 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44379045187749644, 'Total loss': 0.44379045187749644} | train loss {'Reaction outcome loss': 0.17831654710581107, 'Total loss': 0.17831654710581107}
2022-12-05 20:00:27,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:27,284 INFO:     Epoch: 31
2022-12-05 20:00:28,070 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.457423633472486, 'Total loss': 0.457423633472486} | train loss {'Reaction outcome loss': 0.17777195409396473, 'Total loss': 0.17777195409396473}
2022-12-05 20:00:28,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:28,070 INFO:     Epoch: 32
2022-12-05 20:00:28,853 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44173630682582204, 'Total loss': 0.44173630682582204} | train loss {'Reaction outcome loss': 0.17139859117415487, 'Total loss': 0.17139859117415487}
2022-12-05 20:00:28,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:28,853 INFO:     Epoch: 33
2022-12-05 20:00:29,641 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44108025543391705, 'Total loss': 0.44108025543391705} | train loss {'Reaction outcome loss': 0.16947063418219285, 'Total loss': 0.16947063418219285}
2022-12-05 20:00:29,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:29,641 INFO:     Epoch: 34
2022-12-05 20:00:30,434 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4634130515835502, 'Total loss': 0.4634130515835502} | train loss {'Reaction outcome loss': 0.16626794716837454, 'Total loss': 0.16626794716837454}
2022-12-05 20:00:30,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:30,434 INFO:     Epoch: 35
2022-12-05 20:00:31,227 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4519417458213866, 'Total loss': 0.4519417458213866} | train loss {'Reaction outcome loss': 0.16210744005380845, 'Total loss': 0.16210744005380845}
2022-12-05 20:00:31,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:31,227 INFO:     Epoch: 36
2022-12-05 20:00:32,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4387196624143557, 'Total loss': 0.4387196624143557} | train loss {'Reaction outcome loss': 0.16120001157479627, 'Total loss': 0.16120001157479627}
2022-12-05 20:00:32,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:32,017 INFO:     Epoch: 37
2022-12-05 20:00:32,800 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4550923617048697, 'Total loss': 0.4550923617048697} | train loss {'Reaction outcome loss': 0.16095633502973586, 'Total loss': 0.16095633502973586}
2022-12-05 20:00:32,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:32,801 INFO:     Epoch: 38
2022-12-05 20:00:33,591 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4606307667087425, 'Total loss': 0.4606307667087425} | train loss {'Reaction outcome loss': 0.16001922496575482, 'Total loss': 0.16001922496575482}
2022-12-05 20:00:33,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:33,591 INFO:     Epoch: 39
2022-12-05 20:00:34,373 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47130668874491344, 'Total loss': 0.47130668874491344} | train loss {'Reaction outcome loss': 0.15863123573362828, 'Total loss': 0.15863123573362828}
2022-12-05 20:00:34,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:34,374 INFO:     Epoch: 40
2022-12-05 20:00:35,157 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48078873651948845, 'Total loss': 0.48078873651948845} | train loss {'Reaction outcome loss': 0.15546964242750286, 'Total loss': 0.15546964242750286}
2022-12-05 20:00:35,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:35,157 INFO:     Epoch: 41
2022-12-05 20:00:35,940 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44213495522060176, 'Total loss': 0.44213495522060176} | train loss {'Reaction outcome loss': 0.15333967023358053, 'Total loss': 0.15333967023358053}
2022-12-05 20:00:35,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:35,940 INFO:     Epoch: 42
2022-12-05 20:00:36,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4565821676091714, 'Total loss': 0.4565821676091714} | train loss {'Reaction outcome loss': 0.1527456034659123, 'Total loss': 0.1527456034659123}
2022-12-05 20:00:36,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:36,723 INFO:     Epoch: 43
2022-12-05 20:00:37,507 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45017805898731406, 'Total loss': 0.45017805898731406} | train loss {'Reaction outcome loss': 0.15162449320968316, 'Total loss': 0.15162449320968316}
2022-12-05 20:00:37,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:37,507 INFO:     Epoch: 44
2022-12-05 20:00:38,299 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4526652318256145, 'Total loss': 0.4526652318256145} | train loss {'Reaction outcome loss': 0.1499934590744729, 'Total loss': 0.1499934590744729}
2022-12-05 20:00:38,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:38,299 INFO:     Epoch: 45
2022-12-05 20:00:39,087 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4472989138554443, 'Total loss': 0.4472989138554443} | train loss {'Reaction outcome loss': 0.15075939569850358, 'Total loss': 0.15075939569850358}
2022-12-05 20:00:39,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:39,087 INFO:     Epoch: 46
2022-12-05 20:00:39,872 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4624053680083968, 'Total loss': 0.4624053680083968} | train loss {'Reaction outcome loss': 0.14555292705796202, 'Total loss': 0.14555292705796202}
2022-12-05 20:00:39,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:39,872 INFO:     Epoch: 47
2022-12-05 20:00:40,663 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4552002718502825, 'Total loss': 0.4552002718502825} | train loss {'Reaction outcome loss': 0.14546559916391055, 'Total loss': 0.14546559916391055}
2022-12-05 20:00:40,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:40,663 INFO:     Epoch: 48
2022-12-05 20:00:41,450 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4879005128009753, 'Total loss': 0.4879005128009753} | train loss {'Reaction outcome loss': 0.1456812398280112, 'Total loss': 0.1456812398280112}
2022-12-05 20:00:41,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:41,450 INFO:     Epoch: 49
2022-12-05 20:00:42,235 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43714465556496923, 'Total loss': 0.43714465556496923} | train loss {'Reaction outcome loss': 0.14457032550506446, 'Total loss': 0.14457032550506446}
2022-12-05 20:00:42,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:42,235 INFO:     Epoch: 50
2022-12-05 20:00:43,026 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.471675352786075, 'Total loss': 0.471675352786075} | train loss {'Reaction outcome loss': 0.1448232549945919, 'Total loss': 0.1448232549945919}
2022-12-05 20:00:43,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:43,027 INFO:     Epoch: 51
2022-12-05 20:00:43,813 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45617638663812116, 'Total loss': 0.45617638663812116} | train loss {'Reaction outcome loss': 0.13883815901544022, 'Total loss': 0.13883815901544022}
2022-12-05 20:00:43,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:43,813 INFO:     Epoch: 52
2022-12-05 20:00:44,603 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44853505763140594, 'Total loss': 0.44853505763140594} | train loss {'Reaction outcome loss': 0.14143751388301654, 'Total loss': 0.14143751388301654}
2022-12-05 20:00:44,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:44,603 INFO:     Epoch: 53
2022-12-05 20:00:45,391 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4548239850185134, 'Total loss': 0.4548239850185134} | train loss {'Reaction outcome loss': 0.14328669514887188, 'Total loss': 0.14328669514887188}
2022-12-05 20:00:45,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:45,392 INFO:     Epoch: 54
2022-12-05 20:00:46,180 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4493014680391008, 'Total loss': 0.4493014680391008} | train loss {'Reaction outcome loss': 0.13975478211531833, 'Total loss': 0.13975478211531833}
2022-12-05 20:00:46,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:46,180 INFO:     Epoch: 55
2022-12-05 20:00:46,964 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45124546624720097, 'Total loss': 0.45124546624720097} | train loss {'Reaction outcome loss': 0.13838289133558163, 'Total loss': 0.13838289133558163}
2022-12-05 20:00:46,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:46,964 INFO:     Epoch: 56
2022-12-05 20:00:47,749 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46728549762205646, 'Total loss': 0.46728549762205646} | train loss {'Reaction outcome loss': 0.1381070364494713, 'Total loss': 0.1381070364494713}
2022-12-05 20:00:47,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:47,750 INFO:     Epoch: 57
2022-12-05 20:00:48,534 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4688040018081665, 'Total loss': 0.4688040018081665} | train loss {'Reaction outcome loss': 0.13759499487220025, 'Total loss': 0.13759499487220025}
2022-12-05 20:00:48,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:48,535 INFO:     Epoch: 58
2022-12-05 20:00:49,325 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4826361665671522, 'Total loss': 0.4826361665671522} | train loss {'Reaction outcome loss': 0.13523624949157237, 'Total loss': 0.13523624949157237}
2022-12-05 20:00:49,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:49,325 INFO:     Epoch: 59
2022-12-05 20:00:50,113 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44753068939528684, 'Total loss': 0.44753068939528684} | train loss {'Reaction outcome loss': 0.13630911843204985, 'Total loss': 0.13630911843204985}
2022-12-05 20:00:50,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:50,113 INFO:     Epoch: 60
2022-12-05 20:00:50,902 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.452981831421229, 'Total loss': 0.452981831421229} | train loss {'Reaction outcome loss': 0.13388448294860367, 'Total loss': 0.13388448294860367}
2022-12-05 20:00:50,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:50,903 INFO:     Epoch: 61
2022-12-05 20:00:51,689 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4514592841944911, 'Total loss': 0.4514592841944911} | train loss {'Reaction outcome loss': 0.13475136759177764, 'Total loss': 0.13475136759177764}
2022-12-05 20:00:51,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:51,689 INFO:     Epoch: 62
2022-12-05 20:00:52,477 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45071333325044677, 'Total loss': 0.45071333325044677} | train loss {'Reaction outcome loss': 0.13470088997665716, 'Total loss': 0.13470088997665716}
2022-12-05 20:00:52,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:52,477 INFO:     Epoch: 63
2022-12-05 20:00:53,264 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4574798047542572, 'Total loss': 0.4574798047542572} | train loss {'Reaction outcome loss': 0.13121296234656962, 'Total loss': 0.13121296234656962}
2022-12-05 20:00:53,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:53,264 INFO:     Epoch: 64
2022-12-05 20:00:54,048 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4650797542523254, 'Total loss': 0.4650797542523254} | train loss {'Reaction outcome loss': 0.134106437424768, 'Total loss': 0.134106437424768}
2022-12-05 20:00:54,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:54,056 INFO:     Epoch: 65
2022-12-05 20:00:54,840 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4542528675361113, 'Total loss': 0.4542528675361113} | train loss {'Reaction outcome loss': 0.13276932685807044, 'Total loss': 0.13276932685807044}
2022-12-05 20:00:54,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:54,841 INFO:     Epoch: 66
2022-12-05 20:00:55,627 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4390398559414528, 'Total loss': 0.4390398559414528} | train loss {'Reaction outcome loss': 0.13229716198176752, 'Total loss': 0.13229716198176752}
2022-12-05 20:00:55,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:55,627 INFO:     Epoch: 67
2022-12-05 20:00:56,421 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44796147468415176, 'Total loss': 0.44796147468415176} | train loss {'Reaction outcome loss': 0.12913674579515141, 'Total loss': 0.12913674579515141}
2022-12-05 20:00:56,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:56,421 INFO:     Epoch: 68
2022-12-05 20:00:57,214 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4638699618252841, 'Total loss': 0.4638699618252841} | train loss {'Reaction outcome loss': 0.12933079915083184, 'Total loss': 0.12933079915083184}
2022-12-05 20:00:57,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:57,215 INFO:     Epoch: 69
2022-12-05 20:00:58,004 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45196721567349, 'Total loss': 0.45196721567349} | train loss {'Reaction outcome loss': 0.1310710751356519, 'Total loss': 0.1310710751356519}
2022-12-05 20:00:58,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:58,005 INFO:     Epoch: 70
2022-12-05 20:00:58,792 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44575423328205943, 'Total loss': 0.44575423328205943} | train loss {'Reaction outcome loss': 0.13136857737768062, 'Total loss': 0.13136857737768062}
2022-12-05 20:00:58,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:58,792 INFO:     Epoch: 71
2022-12-05 20:00:59,576 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45409462228417397, 'Total loss': 0.45409462228417397} | train loss {'Reaction outcome loss': 0.1283131829672018, 'Total loss': 0.1283131829672018}
2022-12-05 20:00:59,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:00:59,577 INFO:     Epoch: 72
2022-12-05 20:01:00,370 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44761918823827396, 'Total loss': 0.44761918823827396} | train loss {'Reaction outcome loss': 0.12993386074596522, 'Total loss': 0.12993386074596522}
2022-12-05 20:01:00,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:00,370 INFO:     Epoch: 73
2022-12-05 20:01:01,160 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46029561487111176, 'Total loss': 0.46029561487111176} | train loss {'Reaction outcome loss': 0.12520034429522192, 'Total loss': 0.12520034429522192}
2022-12-05 20:01:01,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:01,160 INFO:     Epoch: 74
2022-12-05 20:01:01,952 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.478278116831048, 'Total loss': 0.478278116831048} | train loss {'Reaction outcome loss': 0.12688399691666877, 'Total loss': 0.12688399691666877}
2022-12-05 20:01:01,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:01,952 INFO:     Epoch: 75
2022-12-05 20:01:02,745 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46895437708801846, 'Total loss': 0.46895437708801846} | train loss {'Reaction outcome loss': 0.12638019360982033, 'Total loss': 0.12638019360982033}
2022-12-05 20:01:02,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:02,745 INFO:     Epoch: 76
2022-12-05 20:01:03,538 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45291024073958397, 'Total loss': 0.45291024073958397} | train loss {'Reaction outcome loss': 0.12563304443824655, 'Total loss': 0.12563304443824655}
2022-12-05 20:01:03,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:03,539 INFO:     Epoch: 77
2022-12-05 20:01:04,332 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4680945763195103, 'Total loss': 0.4680945763195103} | train loss {'Reaction outcome loss': 0.12755919350501227, 'Total loss': 0.12755919350501227}
2022-12-05 20:01:04,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:04,332 INFO:     Epoch: 78
2022-12-05 20:01:05,127 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4710033180361444, 'Total loss': 0.4710033180361444} | train loss {'Reaction outcome loss': 0.12587127098623588, 'Total loss': 0.12587127098623588}
2022-12-05 20:01:05,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:05,127 INFO:     Epoch: 79
2022-12-05 20:01:05,919 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4873881106349555, 'Total loss': 0.4873881106349555} | train loss {'Reaction outcome loss': 0.12390022905809539, 'Total loss': 0.12390022905809539}
2022-12-05 20:01:05,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:05,920 INFO:     Epoch: 80
2022-12-05 20:01:06,714 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45245804502205417, 'Total loss': 0.45245804502205417} | train loss {'Reaction outcome loss': 0.1243602173288866, 'Total loss': 0.1243602173288866}
2022-12-05 20:01:06,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:06,714 INFO:     Epoch: 81
2022-12-05 20:01:07,507 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48929024927995424, 'Total loss': 0.48929024927995424} | train loss {'Reaction outcome loss': 0.12167260283034066, 'Total loss': 0.12167260283034066}
2022-12-05 20:01:07,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:07,507 INFO:     Epoch: 82
2022-12-05 20:01:08,296 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45238063230433245, 'Total loss': 0.45238063230433245} | train loss {'Reaction outcome loss': 0.12606876893919342, 'Total loss': 0.12606876893919342}
2022-12-05 20:01:08,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:08,297 INFO:     Epoch: 83
2022-12-05 20:01:09,082 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.468408875675364, 'Total loss': 0.468408875675364} | train loss {'Reaction outcome loss': 0.12366630505694419, 'Total loss': 0.12366630505694419}
2022-12-05 20:01:09,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:09,083 INFO:     Epoch: 84
2022-12-05 20:01:09,867 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4647129403257912, 'Total loss': 0.4647129403257912} | train loss {'Reaction outcome loss': 0.12488678787663883, 'Total loss': 0.12488678787663883}
2022-12-05 20:01:09,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:09,867 INFO:     Epoch: 85
2022-12-05 20:01:10,657 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45677218018946325, 'Total loss': 0.45677218018946325} | train loss {'Reaction outcome loss': 0.12235966226352113, 'Total loss': 0.12235966226352113}
2022-12-05 20:01:10,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:10,657 INFO:     Epoch: 86
2022-12-05 20:01:11,443 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4687671945853667, 'Total loss': 0.4687671945853667} | train loss {'Reaction outcome loss': 0.12118586894808983, 'Total loss': 0.12118586894808983}
2022-12-05 20:01:11,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:11,443 INFO:     Epoch: 87
2022-12-05 20:01:12,230 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46658922122283414, 'Total loss': 0.46658922122283414} | train loss {'Reaction outcome loss': 0.12090765873388368, 'Total loss': 0.12090765873388368}
2022-12-05 20:01:12,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:12,231 INFO:     Epoch: 88
2022-12-05 20:01:13,020 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4653829911893064, 'Total loss': 0.4653829911893064} | train loss {'Reaction outcome loss': 0.12448728126378691, 'Total loss': 0.12448728126378691}
2022-12-05 20:01:13,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:13,021 INFO:     Epoch: 89
2022-12-05 20:01:13,809 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4599473809992725, 'Total loss': 0.4599473809992725} | train loss {'Reaction outcome loss': 0.12343787752776121, 'Total loss': 0.12343787752776121}
2022-12-05 20:01:13,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:13,810 INFO:     Epoch: 90
2022-12-05 20:01:14,601 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48604217408732936, 'Total loss': 0.48604217408732936} | train loss {'Reaction outcome loss': 0.12314196611773603, 'Total loss': 0.12314196611773603}
2022-12-05 20:01:14,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:14,601 INFO:     Epoch: 91
2022-12-05 20:01:15,390 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45907988162203267, 'Total loss': 0.45907988162203267} | train loss {'Reaction outcome loss': 0.1208698258488154, 'Total loss': 0.1208698258488154}
2022-12-05 20:01:15,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:15,390 INFO:     Epoch: 92
2022-12-05 20:01:16,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4331472170623866, 'Total loss': 0.4331472170623866} | train loss {'Reaction outcome loss': 0.12023790103136277, 'Total loss': 0.12023790103136277}
2022-12-05 20:01:16,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:16,179 INFO:     Epoch: 93
2022-12-05 20:01:16,963 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48340050131082535, 'Total loss': 0.48340050131082535} | train loss {'Reaction outcome loss': 0.11804555353841611, 'Total loss': 0.11804555353841611}
2022-12-05 20:01:16,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:16,963 INFO:     Epoch: 94
2022-12-05 20:01:17,747 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4767009856348688, 'Total loss': 0.4767009856348688} | train loss {'Reaction outcome loss': 0.1209130528934148, 'Total loss': 0.1209130528934148}
2022-12-05 20:01:17,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:17,747 INFO:     Epoch: 95
2022-12-05 20:01:18,536 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47529075972058554, 'Total loss': 0.47529075972058554} | train loss {'Reaction outcome loss': 0.12037727843437876, 'Total loss': 0.12037727843437876}
2022-12-05 20:01:18,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:18,536 INFO:     Epoch: 96
2022-12-05 20:01:19,322 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44846009520221164, 'Total loss': 0.44846009520221164} | train loss {'Reaction outcome loss': 0.12058420667462812, 'Total loss': 0.12058420667462812}
2022-12-05 20:01:19,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:19,322 INFO:     Epoch: 97
2022-12-05 20:01:20,109 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4564851310781457, 'Total loss': 0.4564851310781457} | train loss {'Reaction outcome loss': 0.11893548461969713, 'Total loss': 0.11893548461969713}
2022-12-05 20:01:20,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:20,109 INFO:     Epoch: 98
2022-12-05 20:01:20,893 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46330431205305184, 'Total loss': 0.46330431205305184} | train loss {'Reaction outcome loss': 0.11847645536977418, 'Total loss': 0.11847645536977418}
2022-12-05 20:01:20,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:20,893 INFO:     Epoch: 99
2022-12-05 20:01:21,679 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4411760490726341, 'Total loss': 0.4411760490726341} | train loss {'Reaction outcome loss': 0.11759782617113419, 'Total loss': 0.11759782617113419}
2022-12-05 20:01:21,679 INFO:     Best model found after epoch 20 of 100.
2022-12-05 20:01:21,679 INFO:   Done with stage: TRAINING
2022-12-05 20:01:21,679 INFO:   Starting stage: EVALUATION
2022-12-05 20:01:21,810 INFO:   Done with stage: EVALUATION
2022-12-05 20:01:21,810 INFO:   Leaving out SEQ value Fold_1
2022-12-05 20:01:21,823 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:01:21,823 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:01:22,470 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:01:22,470 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:01:22,539 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:01:22,539 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:01:22,539 INFO:     No hyperparam tuning for this model
2022-12-05 20:01:22,539 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:01:22,539 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:01:22,540 INFO:     None feature selector for col prot
2022-12-05 20:01:22,540 INFO:     None feature selector for col prot
2022-12-05 20:01:22,540 INFO:     None feature selector for col prot
2022-12-05 20:01:22,541 INFO:     None feature selector for col chem
2022-12-05 20:01:22,541 INFO:     None feature selector for col chem
2022-12-05 20:01:22,541 INFO:     None feature selector for col chem
2022-12-05 20:01:22,541 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:01:22,541 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:01:22,543 INFO:     Number of params in model 215821
2022-12-05 20:01:22,546 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:01:22,546 INFO:   Starting stage: TRAINING
2022-12-05 20:01:22,607 INFO:     Val loss before train {'Reaction outcome loss': 0.9751686040650714, 'Total loss': 0.9751686040650714}
2022-12-05 20:01:22,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:22,607 INFO:     Epoch: 0
2022-12-05 20:01:23,394 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5889449715614319, 'Total loss': 0.5889449715614319} | train loss {'Reaction outcome loss': 0.782399362933879, 'Total loss': 0.782399362933879}
2022-12-05 20:01:23,394 INFO:     Found new best model at epoch 0
2022-12-05 20:01:23,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:23,395 INFO:     Epoch: 1
2022-12-05 20:01:24,182 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5062173483046618, 'Total loss': 0.5062173483046618} | train loss {'Reaction outcome loss': 0.5234673731181086, 'Total loss': 0.5234673731181086}
2022-12-05 20:01:24,182 INFO:     Found new best model at epoch 1
2022-12-05 20:01:24,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:24,183 INFO:     Epoch: 2
2022-12-05 20:01:24,966 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4882212142375382, 'Total loss': 0.4882212142375382} | train loss {'Reaction outcome loss': 0.457009036991061, 'Total loss': 0.457009036991061}
2022-12-05 20:01:24,966 INFO:     Found new best model at epoch 2
2022-12-05 20:01:24,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:24,967 INFO:     Epoch: 3
2022-12-05 20:01:25,754 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46322348273613234, 'Total loss': 0.46322348273613234} | train loss {'Reaction outcome loss': 0.4188354647889429, 'Total loss': 0.4188354647889429}
2022-12-05 20:01:25,754 INFO:     Found new best model at epoch 3
2022-12-05 20:01:25,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:25,755 INFO:     Epoch: 4
2022-12-05 20:01:26,541 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45528262514959683, 'Total loss': 0.45528262514959683} | train loss {'Reaction outcome loss': 0.3919468175999972, 'Total loss': 0.3919468175999972}
2022-12-05 20:01:26,542 INFO:     Found new best model at epoch 4
2022-12-05 20:01:26,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:26,543 INFO:     Epoch: 5
2022-12-05 20:01:27,332 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44679528136144986, 'Total loss': 0.44679528136144986} | train loss {'Reaction outcome loss': 0.3663772716814158, 'Total loss': 0.3663772716814158}
2022-12-05 20:01:27,332 INFO:     Found new best model at epoch 5
2022-12-05 20:01:27,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:27,333 INFO:     Epoch: 6
2022-12-05 20:01:28,123 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4292734001170505, 'Total loss': 0.4292734001170505} | train loss {'Reaction outcome loss': 0.3460484136124046, 'Total loss': 0.3460484136124046}
2022-12-05 20:01:28,124 INFO:     Found new best model at epoch 6
2022-12-05 20:01:28,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:28,125 INFO:     Epoch: 7
2022-12-05 20:01:28,911 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4236265869641846, 'Total loss': 0.4236265869641846} | train loss {'Reaction outcome loss': 0.32888494213016667, 'Total loss': 0.32888494213016667}
2022-12-05 20:01:28,911 INFO:     Found new best model at epoch 7
2022-12-05 20:01:28,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:28,912 INFO:     Epoch: 8
2022-12-05 20:01:29,698 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42565165798772464, 'Total loss': 0.42565165798772464} | train loss {'Reaction outcome loss': 0.3154746413230896, 'Total loss': 0.3154746413230896}
2022-12-05 20:01:29,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:29,698 INFO:     Epoch: 9
2022-12-05 20:01:30,486 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4201406152305109, 'Total loss': 0.4201406152305109} | train loss {'Reaction outcome loss': 0.30021127526249203, 'Total loss': 0.30021127526249203}
2022-12-05 20:01:30,486 INFO:     Found new best model at epoch 9
2022-12-05 20:01:30,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:30,487 INFO:     Epoch: 10
2022-12-05 20:01:31,278 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43126383322206413, 'Total loss': 0.43126383322206413} | train loss {'Reaction outcome loss': 0.290213866653491, 'Total loss': 0.290213866653491}
2022-12-05 20:01:31,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:31,278 INFO:     Epoch: 11
2022-12-05 20:01:32,072 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4425908984108405, 'Total loss': 0.4425908984108405} | train loss {'Reaction outcome loss': 0.27674548641151314, 'Total loss': 0.27674548641151314}
2022-12-05 20:01:32,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:32,072 INFO:     Epoch: 12
2022-12-05 20:01:32,861 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41264674677090213, 'Total loss': 0.41264674677090213} | train loss {'Reaction outcome loss': 0.26971697637013026, 'Total loss': 0.26971697637013026}
2022-12-05 20:01:32,861 INFO:     Found new best model at epoch 12
2022-12-05 20:01:32,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:32,862 INFO:     Epoch: 13
2022-12-05 20:01:33,645 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43157126889987424, 'Total loss': 0.43157126889987424} | train loss {'Reaction outcome loss': 0.2611440849395431, 'Total loss': 0.2611440849395431}
2022-12-05 20:01:33,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:33,645 INFO:     Epoch: 14
2022-12-05 20:01:34,433 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4268857054412365, 'Total loss': 0.4268857054412365} | train loss {'Reaction outcome loss': 0.2554853258996594, 'Total loss': 0.2554853258996594}
2022-12-05 20:01:34,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:34,434 INFO:     Epoch: 15
2022-12-05 20:01:35,222 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4210204223001545, 'Total loss': 0.4210204223001545} | train loss {'Reaction outcome loss': 0.24709621640492457, 'Total loss': 0.24709621640492457}
2022-12-05 20:01:35,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:35,223 INFO:     Epoch: 16
2022-12-05 20:01:36,015 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42687410759654915, 'Total loss': 0.42687410759654915} | train loss {'Reaction outcome loss': 0.24152958032732108, 'Total loss': 0.24152958032732108}
2022-12-05 20:01:36,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:36,015 INFO:     Epoch: 17
2022-12-05 20:01:36,803 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4312390649521893, 'Total loss': 0.4312390649521893} | train loss {'Reaction outcome loss': 0.23233555503645723, 'Total loss': 0.23233555503645723}
2022-12-05 20:01:36,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:36,804 INFO:     Epoch: 18
2022-12-05 20:01:37,593 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4313352599062703, 'Total loss': 0.4313352599062703} | train loss {'Reaction outcome loss': 0.2259932918207986, 'Total loss': 0.2259932918207986}
2022-12-05 20:01:37,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:37,593 INFO:     Epoch: 19
2022-12-05 20:01:38,387 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43088565292683517, 'Total loss': 0.43088565292683517} | train loss {'Reaction outcome loss': 0.22174407169222832, 'Total loss': 0.22174407169222832}
2022-12-05 20:01:38,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:38,387 INFO:     Epoch: 20
2022-12-05 20:01:39,177 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45299816300923174, 'Total loss': 0.45299816300923174} | train loss {'Reaction outcome loss': 0.21851741908764352, 'Total loss': 0.21851741908764352}
2022-12-05 20:01:39,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:39,177 INFO:     Epoch: 21
2022-12-05 20:01:39,968 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42018983648581937, 'Total loss': 0.42018983648581937} | train loss {'Reaction outcome loss': 0.21237392303134714, 'Total loss': 0.21237392303134714}
2022-12-05 20:01:39,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:39,968 INFO:     Epoch: 22
2022-12-05 20:01:40,759 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4316742064600641, 'Total loss': 0.4316742064600641} | train loss {'Reaction outcome loss': 0.207395387106404, 'Total loss': 0.207395387106404}
2022-12-05 20:01:40,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:40,759 INFO:     Epoch: 23
2022-12-05 20:01:41,546 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4157235629179261, 'Total loss': 0.4157235629179261} | train loss {'Reaction outcome loss': 0.20255182196899335, 'Total loss': 0.20255182196899335}
2022-12-05 20:01:41,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:41,546 INFO:     Epoch: 24
2022-12-05 20:01:42,335 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4237489454786886, 'Total loss': 0.4237489454786886} | train loss {'Reaction outcome loss': 0.2025318330647994, 'Total loss': 0.2025318330647994}
2022-12-05 20:01:42,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:42,335 INFO:     Epoch: 25
2022-12-05 20:01:43,123 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43439425832845946, 'Total loss': 0.43439425832845946} | train loss {'Reaction outcome loss': 0.1954237367653725, 'Total loss': 0.1954237367653725}
2022-12-05 20:01:43,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:43,124 INFO:     Epoch: 26
2022-12-05 20:01:43,906 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.428541900082068, 'Total loss': 0.428541900082068} | train loss {'Reaction outcome loss': 0.19239371716976167, 'Total loss': 0.19239371716976167}
2022-12-05 20:01:43,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:43,907 INFO:     Epoch: 27
2022-12-05 20:01:44,693 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4386342328719117, 'Total loss': 0.4386342328719117} | train loss {'Reaction outcome loss': 0.19076449852816912, 'Total loss': 0.19076449852816912}
2022-12-05 20:01:44,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:44,693 INFO:     Epoch: 28
2022-12-05 20:01:45,478 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43384806981140916, 'Total loss': 0.43384806981140916} | train loss {'Reaction outcome loss': 0.18580668569371409, 'Total loss': 0.18580668569371409}
2022-12-05 20:01:45,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:45,478 INFO:     Epoch: 29
2022-12-05 20:01:46,264 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43908518281849945, 'Total loss': 0.43908518281849945} | train loss {'Reaction outcome loss': 0.1838733829405843, 'Total loss': 0.1838733829405843}
2022-12-05 20:01:46,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:46,264 INFO:     Epoch: 30
2022-12-05 20:01:47,057 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43151758949864993, 'Total loss': 0.43151758949864993} | train loss {'Reaction outcome loss': 0.18279035723939233, 'Total loss': 0.18279035723939233}
2022-12-05 20:01:47,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:47,058 INFO:     Epoch: 31
2022-12-05 20:01:47,850 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4360421956940131, 'Total loss': 0.4360421956940131} | train loss {'Reaction outcome loss': 0.17805555560911188, 'Total loss': 0.17805555560911188}
2022-12-05 20:01:47,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:47,850 INFO:     Epoch: 32
2022-12-05 20:01:48,642 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4369213357567787, 'Total loss': 0.4369213357567787} | train loss {'Reaction outcome loss': 0.1761556363683574, 'Total loss': 0.1761556363683574}
2022-12-05 20:01:48,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:48,642 INFO:     Epoch: 33
2022-12-05 20:01:49,432 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4603355422785336, 'Total loss': 0.4603355422785336} | train loss {'Reaction outcome loss': 0.1735321884708745, 'Total loss': 0.1735321884708745}
2022-12-05 20:01:49,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:49,432 INFO:     Epoch: 34
2022-12-05 20:01:50,224 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44405053894628177, 'Total loss': 0.44405053894628177} | train loss {'Reaction outcome loss': 0.17184386104345323, 'Total loss': 0.17184386104345323}
2022-12-05 20:01:50,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:50,225 INFO:     Epoch: 35
2022-12-05 20:01:51,016 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45463572205467656, 'Total loss': 0.45463572205467656} | train loss {'Reaction outcome loss': 0.16989057763498658, 'Total loss': 0.16989057763498658}
2022-12-05 20:01:51,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:51,016 INFO:     Epoch: 36
2022-12-05 20:01:51,805 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4521486752412536, 'Total loss': 0.4521486752412536} | train loss {'Reaction outcome loss': 0.16574838121934812, 'Total loss': 0.16574838121934812}
2022-12-05 20:01:51,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:51,805 INFO:     Epoch: 37
2022-12-05 20:01:52,592 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4364766986532645, 'Total loss': 0.4364766986532645} | train loss {'Reaction outcome loss': 0.16629724945036733, 'Total loss': 0.16629724945036733}
2022-12-05 20:01:52,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:52,592 INFO:     Epoch: 38
2022-12-05 20:01:53,376 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44038264182480896, 'Total loss': 0.44038264182480896} | train loss {'Reaction outcome loss': 0.16325361429124463, 'Total loss': 0.16325361429124463}
2022-12-05 20:01:53,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:53,376 INFO:     Epoch: 39
2022-12-05 20:01:54,164 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4448929605158893, 'Total loss': 0.4448929605158893} | train loss {'Reaction outcome loss': 0.15963207412587135, 'Total loss': 0.15963207412587135}
2022-12-05 20:01:54,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:54,164 INFO:     Epoch: 40
2022-12-05 20:01:54,952 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43876491334627976, 'Total loss': 0.43876491334627976} | train loss {'Reaction outcome loss': 0.16017909391346027, 'Total loss': 0.16017909391346027}
2022-12-05 20:01:54,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:54,952 INFO:     Epoch: 41
2022-12-05 20:01:55,741 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4527838314798745, 'Total loss': 0.4527838314798745} | train loss {'Reaction outcome loss': 0.15725305183049368, 'Total loss': 0.15725305183049368}
2022-12-05 20:01:55,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:55,741 INFO:     Epoch: 42
2022-12-05 20:01:56,534 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4524270898916505, 'Total loss': 0.4524270898916505} | train loss {'Reaction outcome loss': 0.15664867420433734, 'Total loss': 0.15664867420433734}
2022-12-05 20:01:56,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:56,534 INFO:     Epoch: 43
2022-12-05 20:01:57,325 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45440068417652085, 'Total loss': 0.45440068417652085} | train loss {'Reaction outcome loss': 0.15716580817361875, 'Total loss': 0.15716580817361875}
2022-12-05 20:01:57,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:57,325 INFO:     Epoch: 44
2022-12-05 20:01:58,117 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43922309086404066, 'Total loss': 0.43922309086404066} | train loss {'Reaction outcome loss': 0.15549983644896015, 'Total loss': 0.15549983644896015}
2022-12-05 20:01:58,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:58,117 INFO:     Epoch: 45
2022-12-05 20:01:58,908 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4606142128733071, 'Total loss': 0.4606142128733071} | train loss {'Reaction outcome loss': 0.1528415438167903, 'Total loss': 0.1528415438167903}
2022-12-05 20:01:58,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:58,909 INFO:     Epoch: 46
2022-12-05 20:01:59,704 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46606138856573537, 'Total loss': 0.46606138856573537} | train loss {'Reaction outcome loss': 0.15349744694421485, 'Total loss': 0.15349744694421485}
2022-12-05 20:01:59,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:01:59,704 INFO:     Epoch: 47
2022-12-05 20:02:00,495 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45328225737268274, 'Total loss': 0.45328225737268274} | train loss {'Reaction outcome loss': 0.15392594220382827, 'Total loss': 0.15392594220382827}
2022-12-05 20:02:00,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:00,495 INFO:     Epoch: 48
2022-12-05 20:02:01,285 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45755810117010365, 'Total loss': 0.45755810117010365} | train loss {'Reaction outcome loss': 0.14981323640261376, 'Total loss': 0.14981323640261376}
2022-12-05 20:02:01,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:01,285 INFO:     Epoch: 49
2022-12-05 20:02:02,076 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4584150097586892, 'Total loss': 0.4584150097586892} | train loss {'Reaction outcome loss': 0.14974991966571127, 'Total loss': 0.14974991966571127}
2022-12-05 20:02:02,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:02,076 INFO:     Epoch: 50
2022-12-05 20:02:02,865 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4592671597545797, 'Total loss': 0.4592671597545797} | train loss {'Reaction outcome loss': 0.1504137259204777, 'Total loss': 0.1504137259204777}
2022-12-05 20:02:02,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:02,865 INFO:     Epoch: 51
2022-12-05 20:02:03,659 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4648294501345266, 'Total loss': 0.4648294501345266} | train loss {'Reaction outcome loss': 0.14940605192084094, 'Total loss': 0.14940605192084094}
2022-12-05 20:02:03,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:03,660 INFO:     Epoch: 52
2022-12-05 20:02:04,456 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45319438681260427, 'Total loss': 0.45319438681260427} | train loss {'Reaction outcome loss': 0.1509412916187121, 'Total loss': 0.1509412916187121}
2022-12-05 20:02:04,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:04,456 INFO:     Epoch: 53
2022-12-05 20:02:05,246 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46934710612351244, 'Total loss': 0.46934710612351244} | train loss {'Reaction outcome loss': 0.1457880936106857, 'Total loss': 0.1457880936106857}
2022-12-05 20:02:05,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:05,247 INFO:     Epoch: 54
2022-12-05 20:02:06,037 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4655448374423114, 'Total loss': 0.4655448374423114} | train loss {'Reaction outcome loss': 0.14423971528149382, 'Total loss': 0.14423971528149382}
2022-12-05 20:02:06,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:06,037 INFO:     Epoch: 55
2022-12-05 20:02:06,829 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.441542743451216, 'Total loss': 0.441542743451216} | train loss {'Reaction outcome loss': 0.14303247752238293, 'Total loss': 0.14303247752238293}
2022-12-05 20:02:06,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:06,829 INFO:     Epoch: 56
2022-12-05 20:02:07,619 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46202472055500204, 'Total loss': 0.46202472055500204} | train loss {'Reaction outcome loss': 0.14269978369072991, 'Total loss': 0.14269978369072991}
2022-12-05 20:02:07,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:07,620 INFO:     Epoch: 57
2022-12-05 20:02:08,410 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4622860283336856, 'Total loss': 0.4622860283336856} | train loss {'Reaction outcome loss': 0.14429632456098893, 'Total loss': 0.14429632456098893}
2022-12-05 20:02:08,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:08,410 INFO:     Epoch: 58
2022-12-05 20:02:09,200 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4912025291811336, 'Total loss': 0.4912025291811336} | train loss {'Reaction outcome loss': 0.14484994779816088, 'Total loss': 0.14484994779816088}
2022-12-05 20:02:09,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:09,200 INFO:     Epoch: 59
2022-12-05 20:02:09,989 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46081720021638, 'Total loss': 0.46081720021638} | train loss {'Reaction outcome loss': 0.14306437994676585, 'Total loss': 0.14306437994676585}
2022-12-05 20:02:09,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:09,989 INFO:     Epoch: 60
2022-12-05 20:02:10,782 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4591223116625439, 'Total loss': 0.4591223116625439} | train loss {'Reaction outcome loss': 0.14288273006677626, 'Total loss': 0.14288273006677626}
2022-12-05 20:02:10,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:10,782 INFO:     Epoch: 61
2022-12-05 20:02:11,572 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44423935443840246, 'Total loss': 0.44423935443840246} | train loss {'Reaction outcome loss': 0.14134289628769062, 'Total loss': 0.14134289628769062}
2022-12-05 20:02:11,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:11,572 INFO:     Epoch: 62
2022-12-05 20:02:12,364 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47140385108915245, 'Total loss': 0.47140385108915245} | train loss {'Reaction outcome loss': 0.14131137310926403, 'Total loss': 0.14131137310926403}
2022-12-05 20:02:12,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:12,364 INFO:     Epoch: 63
2022-12-05 20:02:13,161 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47225872156294907, 'Total loss': 0.47225872156294907} | train loss {'Reaction outcome loss': 0.13929909662324555, 'Total loss': 0.13929909662324555}
2022-12-05 20:02:13,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:13,161 INFO:     Epoch: 64
2022-12-05 20:02:13,952 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45269346389580856, 'Total loss': 0.45269346389580856} | train loss {'Reaction outcome loss': 0.13835465055795348, 'Total loss': 0.13835465055795348}
2022-12-05 20:02:13,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:13,952 INFO:     Epoch: 65
2022-12-05 20:02:14,742 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45202264562249184, 'Total loss': 0.45202264562249184} | train loss {'Reaction outcome loss': 0.14031583687518628, 'Total loss': 0.14031583687518628}
2022-12-05 20:02:14,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:14,742 INFO:     Epoch: 66
2022-12-05 20:02:15,532 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4502226955850016, 'Total loss': 0.4502226955850016} | train loss {'Reaction outcome loss': 0.14113164968332464, 'Total loss': 0.14113164968332464}
2022-12-05 20:02:15,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:15,533 INFO:     Epoch: 67
2022-12-05 20:02:16,324 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4685015979815613, 'Total loss': 0.4685015979815613} | train loss {'Reaction outcome loss': 0.1374227122916859, 'Total loss': 0.1374227122916859}
2022-12-05 20:02:16,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:16,324 INFO:     Epoch: 68
2022-12-05 20:02:17,116 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.459843343293125, 'Total loss': 0.459843343293125} | train loss {'Reaction outcome loss': 0.13624048323503563, 'Total loss': 0.13624048323503563}
2022-12-05 20:02:17,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:17,117 INFO:     Epoch: 69
2022-12-05 20:02:17,909 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46229910952123726, 'Total loss': 0.46229910952123726} | train loss {'Reaction outcome loss': 0.13729809045943678, 'Total loss': 0.13729809045943678}
2022-12-05 20:02:17,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:17,910 INFO:     Epoch: 70
2022-12-05 20:02:18,703 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.472870812158693, 'Total loss': 0.472870812158693} | train loss {'Reaction outcome loss': 0.13562561317670102, 'Total loss': 0.13562561317670102}
2022-12-05 20:02:18,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:18,703 INFO:     Epoch: 71
2022-12-05 20:02:19,498 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45634114098819817, 'Total loss': 0.45634114098819817} | train loss {'Reaction outcome loss': 0.13531327582895755, 'Total loss': 0.13531327582895755}
2022-12-05 20:02:19,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:19,498 INFO:     Epoch: 72
2022-12-05 20:02:20,288 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46197325533086603, 'Total loss': 0.46197325533086603} | train loss {'Reaction outcome loss': 0.1347885307817891, 'Total loss': 0.1347885307817891}
2022-12-05 20:02:20,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:20,289 INFO:     Epoch: 73
2022-12-05 20:02:21,078 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4624776853756471, 'Total loss': 0.4624776853756471} | train loss {'Reaction outcome loss': 0.13441598808811028, 'Total loss': 0.13441598808811028}
2022-12-05 20:02:21,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:21,078 INFO:     Epoch: 74
2022-12-05 20:02:21,869 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47576392882249574, 'Total loss': 0.47576392882249574} | train loss {'Reaction outcome loss': 0.13607203675319954, 'Total loss': 0.13607203675319954}
2022-12-05 20:02:21,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:21,869 INFO:     Epoch: 75
2022-12-05 20:02:22,666 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45868430388244713, 'Total loss': 0.45868430388244713} | train loss {'Reaction outcome loss': 0.13642268625221082, 'Total loss': 0.13642268625221082}
2022-12-05 20:02:22,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:22,666 INFO:     Epoch: 76
2022-12-05 20:02:23,463 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46884401040998375, 'Total loss': 0.46884401040998375} | train loss {'Reaction outcome loss': 0.13724083076706345, 'Total loss': 0.13724083076706345}
2022-12-05 20:02:23,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:23,463 INFO:     Epoch: 77
2022-12-05 20:02:24,254 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4556287139315497, 'Total loss': 0.4556287139315497} | train loss {'Reaction outcome loss': 0.1342909674635347, 'Total loss': 0.1342909674635347}
2022-12-05 20:02:24,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:24,255 INFO:     Epoch: 78
2022-12-05 20:02:25,045 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4862882684577595, 'Total loss': 0.4862882684577595} | train loss {'Reaction outcome loss': 0.13159816414497943, 'Total loss': 0.13159816414497943}
2022-12-05 20:02:25,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:25,045 INFO:     Epoch: 79
2022-12-05 20:02:25,834 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4439497785642743, 'Total loss': 0.4439497785642743} | train loss {'Reaction outcome loss': 0.13037426501360475, 'Total loss': 0.13037426501360475}
2022-12-05 20:02:25,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:25,835 INFO:     Epoch: 80
2022-12-05 20:02:26,627 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4553390040316365, 'Total loss': 0.4553390040316365} | train loss {'Reaction outcome loss': 0.13171872292094083, 'Total loss': 0.13171872292094083}
2022-12-05 20:02:26,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:26,627 INFO:     Epoch: 81
2022-12-05 20:02:27,421 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4442785262045535, 'Total loss': 0.4442785262045535} | train loss {'Reaction outcome loss': 0.13155295393828834, 'Total loss': 0.13155295393828834}
2022-12-05 20:02:27,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:27,421 INFO:     Epoch: 82
2022-12-05 20:02:28,210 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45359066568992357, 'Total loss': 0.45359066568992357} | train loss {'Reaction outcome loss': 0.13159048209841154, 'Total loss': 0.13159048209841154}
2022-12-05 20:02:28,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:28,211 INFO:     Epoch: 83
2022-12-05 20:02:29,000 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4576626138930971, 'Total loss': 0.4576626138930971} | train loss {'Reaction outcome loss': 0.1298421153494594, 'Total loss': 0.1298421153494594}
2022-12-05 20:02:29,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:29,000 INFO:     Epoch: 84
2022-12-05 20:02:29,793 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4452663717622107, 'Total loss': 0.4452663717622107} | train loss {'Reaction outcome loss': 0.13180741543064312, 'Total loss': 0.13180741543064312}
2022-12-05 20:02:29,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:29,793 INFO:     Epoch: 85
2022-12-05 20:02:30,583 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4591542160646482, 'Total loss': 0.4591542160646482} | train loss {'Reaction outcome loss': 0.12991619798145732, 'Total loss': 0.12991619798145732}
2022-12-05 20:02:30,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:30,584 INFO:     Epoch: 86
2022-12-05 20:02:31,376 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47040640630505304, 'Total loss': 0.47040640630505304} | train loss {'Reaction outcome loss': 0.12969174973514616, 'Total loss': 0.12969174973514616}
2022-12-05 20:02:31,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:31,376 INFO:     Epoch: 87
2022-12-05 20:02:32,167 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.467284386808222, 'Total loss': 0.467284386808222} | train loss {'Reaction outcome loss': 0.1279388256294995, 'Total loss': 0.1279388256294995}
2022-12-05 20:02:32,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:32,168 INFO:     Epoch: 88
2022-12-05 20:02:32,961 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4690742174332792, 'Total loss': 0.4690742174332792} | train loss {'Reaction outcome loss': 0.12889841948540842, 'Total loss': 0.12889841948540842}
2022-12-05 20:02:32,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:32,961 INFO:     Epoch: 89
2022-12-05 20:02:33,753 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4390111333605918, 'Total loss': 0.4390111333605918} | train loss {'Reaction outcome loss': 0.1291623248661659, 'Total loss': 0.1291623248661659}
2022-12-05 20:02:33,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:33,754 INFO:     Epoch: 90
2022-12-05 20:02:34,542 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45372806320136244, 'Total loss': 0.45372806320136244} | train loss {'Reaction outcome loss': 0.12660020938789357, 'Total loss': 0.12660020938789357}
2022-12-05 20:02:34,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:34,543 INFO:     Epoch: 91
2022-12-05 20:02:35,332 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4602978459813378, 'Total loss': 0.4602978459813378} | train loss {'Reaction outcome loss': 0.12857457952839987, 'Total loss': 0.12857457952839987}
2022-12-05 20:02:35,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:35,332 INFO:     Epoch: 92
2022-12-05 20:02:36,120 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47425122728401964, 'Total loss': 0.47425122728401964} | train loss {'Reaction outcome loss': 0.1278918360987184, 'Total loss': 0.1278918360987184}
2022-12-05 20:02:36,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:36,120 INFO:     Epoch: 93
2022-12-05 20:02:36,910 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44556805135851557, 'Total loss': 0.44556805135851557} | train loss {'Reaction outcome loss': 0.12840101992597386, 'Total loss': 0.12840101992597386}
2022-12-05 20:02:36,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:36,911 INFO:     Epoch: 94
2022-12-05 20:02:37,695 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4581263766370036, 'Total loss': 0.4581263766370036} | train loss {'Reaction outcome loss': 0.12586615496904266, 'Total loss': 0.12586615496904266}
2022-12-05 20:02:37,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:37,695 INFO:     Epoch: 95
2022-12-05 20:02:38,481 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44994963163679297, 'Total loss': 0.44994963163679297} | train loss {'Reaction outcome loss': 0.12772251409573518, 'Total loss': 0.12772251409573518}
2022-12-05 20:02:38,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:38,481 INFO:     Epoch: 96
2022-12-05 20:02:39,265 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46210432188077405, 'Total loss': 0.46210432188077405} | train loss {'Reaction outcome loss': 0.12513341251000457, 'Total loss': 0.12513341251000457}
2022-12-05 20:02:39,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:39,265 INFO:     Epoch: 97
2022-12-05 20:02:40,048 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.470246294174682, 'Total loss': 0.470246294174682} | train loss {'Reaction outcome loss': 0.1248814232191261, 'Total loss': 0.1248814232191261}
2022-12-05 20:02:40,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:40,048 INFO:     Epoch: 98
2022-12-05 20:02:40,835 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4525334167886864, 'Total loss': 0.4525334167886864} | train loss {'Reaction outcome loss': 0.12412677397761418, 'Total loss': 0.12412677397761418}
2022-12-05 20:02:40,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:40,835 INFO:     Epoch: 99
2022-12-05 20:02:41,619 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45330103241245856, 'Total loss': 0.45330103241245856} | train loss {'Reaction outcome loss': 0.126257927795606, 'Total loss': 0.126257927795606}
2022-12-05 20:02:41,619 INFO:     Best model found after epoch 13 of 100.
2022-12-05 20:02:41,619 INFO:   Done with stage: TRAINING
2022-12-05 20:02:41,619 INFO:   Starting stage: EVALUATION
2022-12-05 20:02:41,751 INFO:   Done with stage: EVALUATION
2022-12-05 20:02:41,751 INFO:   Leaving out SEQ value Fold_2
2022-12-05 20:02:41,764 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:02:41,764 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:02:42,404 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:02:42,404 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:02:42,473 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:02:42,473 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:02:42,473 INFO:     No hyperparam tuning for this model
2022-12-05 20:02:42,473 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:02:42,473 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:02:42,474 INFO:     None feature selector for col prot
2022-12-05 20:02:42,474 INFO:     None feature selector for col prot
2022-12-05 20:02:42,474 INFO:     None feature selector for col prot
2022-12-05 20:02:42,474 INFO:     None feature selector for col chem
2022-12-05 20:02:42,475 INFO:     None feature selector for col chem
2022-12-05 20:02:42,475 INFO:     None feature selector for col chem
2022-12-05 20:02:42,475 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:02:42,475 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:02:42,476 INFO:     Number of params in model 215821
2022-12-05 20:02:42,479 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:02:42,479 INFO:   Starting stage: TRAINING
2022-12-05 20:02:42,540 INFO:     Val loss before train {'Reaction outcome loss': 0.9924232472072948, 'Total loss': 0.9924232472072948}
2022-12-05 20:02:42,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:42,540 INFO:     Epoch: 0
2022-12-05 20:02:43,332 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5963791358199987, 'Total loss': 0.5963791358199987} | train loss {'Reaction outcome loss': 0.8069986900095998, 'Total loss': 0.8069986900095998}
2022-12-05 20:02:43,332 INFO:     Found new best model at epoch 0
2022-12-05 20:02:43,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:43,333 INFO:     Epoch: 1
2022-12-05 20:02:44,121 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5141227733005177, 'Total loss': 0.5141227733005177} | train loss {'Reaction outcome loss': 0.5559634818480566, 'Total loss': 0.5559634818480566}
2022-12-05 20:02:44,121 INFO:     Found new best model at epoch 1
2022-12-05 20:02:44,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:44,122 INFO:     Epoch: 2
2022-12-05 20:02:44,910 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4867032075470144, 'Total loss': 0.4867032075470144} | train loss {'Reaction outcome loss': 0.4765040544182183, 'Total loss': 0.4765040544182183}
2022-12-05 20:02:44,910 INFO:     Found new best model at epoch 2
2022-12-05 20:02:44,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:44,911 INFO:     Epoch: 3
2022-12-05 20:02:45,700 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47200057858770544, 'Total loss': 0.47200057858770544} | train loss {'Reaction outcome loss': 0.4363405017054033, 'Total loss': 0.4363405017054033}
2022-12-05 20:02:45,700 INFO:     Found new best model at epoch 3
2022-12-05 20:02:45,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:45,701 INFO:     Epoch: 4
2022-12-05 20:02:46,490 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45139494707638567, 'Total loss': 0.45139494707638567} | train loss {'Reaction outcome loss': 0.41071517162236126, 'Total loss': 0.41071517162236126}
2022-12-05 20:02:46,490 INFO:     Found new best model at epoch 4
2022-12-05 20:02:46,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:46,491 INFO:     Epoch: 5
2022-12-05 20:02:47,282 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4562366157770157, 'Total loss': 0.4562366157770157} | train loss {'Reaction outcome loss': 0.39339941957218927, 'Total loss': 0.39339941957218927}
2022-12-05 20:02:47,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:47,282 INFO:     Epoch: 6
2022-12-05 20:02:48,074 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4439043483950875, 'Total loss': 0.4439043483950875} | train loss {'Reaction outcome loss': 0.36730835010648255, 'Total loss': 0.36730835010648255}
2022-12-05 20:02:48,074 INFO:     Found new best model at epoch 6
2022-12-05 20:02:48,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:48,075 INFO:     Epoch: 7
2022-12-05 20:02:48,871 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.447028060528365, 'Total loss': 0.447028060528365} | train loss {'Reaction outcome loss': 0.34837245410270534, 'Total loss': 0.34837245410270534}
2022-12-05 20:02:48,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:48,871 INFO:     Epoch: 8
2022-12-05 20:02:49,661 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45388144186951895, 'Total loss': 0.45388144186951895} | train loss {'Reaction outcome loss': 0.33715968962140414, 'Total loss': 0.33715968962140414}
2022-12-05 20:02:49,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:49,662 INFO:     Epoch: 9
2022-12-05 20:02:50,452 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45212534679607913, 'Total loss': 0.45212534679607913} | train loss {'Reaction outcome loss': 0.3242670301845682, 'Total loss': 0.3242670301845682}
2022-12-05 20:02:50,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:50,453 INFO:     Epoch: 10
2022-12-05 20:02:51,241 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43791107630187814, 'Total loss': 0.43791107630187814} | train loss {'Reaction outcome loss': 0.3094057815831894, 'Total loss': 0.3094057815831894}
2022-12-05 20:02:51,241 INFO:     Found new best model at epoch 10
2022-12-05 20:02:51,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:51,242 INFO:     Epoch: 11
2022-12-05 20:02:52,034 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4307090419937264, 'Total loss': 0.4307090419937264} | train loss {'Reaction outcome loss': 0.29498157155537896, 'Total loss': 0.29498157155537896}
2022-12-05 20:02:52,034 INFO:     Found new best model at epoch 11
2022-12-05 20:02:52,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:52,035 INFO:     Epoch: 12
2022-12-05 20:02:52,824 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43245462218130176, 'Total loss': 0.43245462218130176} | train loss {'Reaction outcome loss': 0.2837216462035049, 'Total loss': 0.2837216462035049}
2022-12-05 20:02:52,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:52,824 INFO:     Epoch: 13
2022-12-05 20:02:53,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4334029206498103, 'Total loss': 0.4334029206498103} | train loss {'Reaction outcome loss': 0.27404098301703633, 'Total loss': 0.27404098301703633}
2022-12-05 20:02:53,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:53,613 INFO:     Epoch: 14
2022-12-05 20:02:54,399 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43098287284374237, 'Total loss': 0.43098287284374237} | train loss {'Reaction outcome loss': 0.2608984533154409, 'Total loss': 0.2608984533154409}
2022-12-05 20:02:54,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:54,400 INFO:     Epoch: 15
2022-12-05 20:02:55,187 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4410311589864167, 'Total loss': 0.4410311589864167} | train loss {'Reaction outcome loss': 0.2568703603436831, 'Total loss': 0.2568703603436831}
2022-12-05 20:02:55,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:55,188 INFO:     Epoch: 16
2022-12-05 20:02:55,978 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44382327320900833, 'Total loss': 0.44382327320900833} | train loss {'Reaction outcome loss': 0.25043898102966883, 'Total loss': 0.25043898102966883}
2022-12-05 20:02:55,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:55,979 INFO:     Epoch: 17
2022-12-05 20:02:56,773 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4377543856813149, 'Total loss': 0.4377543856813149} | train loss {'Reaction outcome loss': 0.24642797710698264, 'Total loss': 0.24642797710698264}
2022-12-05 20:02:56,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:56,773 INFO:     Epoch: 18
2022-12-05 20:02:57,563 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44041662256826053, 'Total loss': 0.44041662256826053} | train loss {'Reaction outcome loss': 0.2324632431874391, 'Total loss': 0.2324632431874391}
2022-12-05 20:02:57,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:57,563 INFO:     Epoch: 19
2022-12-05 20:02:58,356 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4412823155183684, 'Total loss': 0.4412823155183684} | train loss {'Reaction outcome loss': 0.23221539497858118, 'Total loss': 0.23221539497858118}
2022-12-05 20:02:58,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:58,356 INFO:     Epoch: 20
2022-12-05 20:02:59,160 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4408422644165429, 'Total loss': 0.4408422644165429} | train loss {'Reaction outcome loss': 0.22344194331511794, 'Total loss': 0.22344194331511794}
2022-12-05 20:02:59,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:59,160 INFO:     Epoch: 21
2022-12-05 20:02:59,967 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44433053413575346, 'Total loss': 0.44433053413575346} | train loss {'Reaction outcome loss': 0.2234555426532561, 'Total loss': 0.2234555426532561}
2022-12-05 20:02:59,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:02:59,967 INFO:     Epoch: 22
2022-12-05 20:03:00,768 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42701731842349877, 'Total loss': 0.42701731842349877} | train loss {'Reaction outcome loss': 0.21687786139336676, 'Total loss': 0.21687786139336676}
2022-12-05 20:03:00,768 INFO:     Found new best model at epoch 22
2022-12-05 20:03:00,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:00,769 INFO:     Epoch: 23
2022-12-05 20:03:01,560 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4602991078387607, 'Total loss': 0.4602991078387607} | train loss {'Reaction outcome loss': 0.21033174265553112, 'Total loss': 0.21033174265553112}
2022-12-05 20:03:01,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:01,561 INFO:     Epoch: 24
2022-12-05 20:03:02,351 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4608271960169077, 'Total loss': 0.4608271960169077} | train loss {'Reaction outcome loss': 0.20476126505122313, 'Total loss': 0.20476126505122313}
2022-12-05 20:03:02,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:02,352 INFO:     Epoch: 25
2022-12-05 20:03:03,142 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4565487504005432, 'Total loss': 0.4565487504005432} | train loss {'Reaction outcome loss': 0.20233121766192227, 'Total loss': 0.20233121766192227}
2022-12-05 20:03:03,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:03,142 INFO:     Epoch: 26
2022-12-05 20:03:03,932 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4428665136749094, 'Total loss': 0.4428665136749094} | train loss {'Reaction outcome loss': 0.20081971817261535, 'Total loss': 0.20081971817261535}
2022-12-05 20:03:03,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:03,932 INFO:     Epoch: 27
2022-12-05 20:03:04,725 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45129058154469187, 'Total loss': 0.45129058154469187} | train loss {'Reaction outcome loss': 0.19588552912139157, 'Total loss': 0.19588552912139157}
2022-12-05 20:03:04,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:04,726 INFO:     Epoch: 28
2022-12-05 20:03:05,519 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.446273649958047, 'Total loss': 0.446273649958047} | train loss {'Reaction outcome loss': 0.1903770635666152, 'Total loss': 0.1903770635666152}
2022-12-05 20:03:05,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:05,519 INFO:     Epoch: 29
2022-12-05 20:03:06,313 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4602705199610103, 'Total loss': 0.4602705199610103} | train loss {'Reaction outcome loss': 0.1922939142159484, 'Total loss': 0.1922939142159484}
2022-12-05 20:03:06,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:06,313 INFO:     Epoch: 30
2022-12-05 20:03:07,108 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46760005673224275, 'Total loss': 0.46760005673224275} | train loss {'Reaction outcome loss': 0.1872037622459263, 'Total loss': 0.1872037622459263}
2022-12-05 20:03:07,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:07,109 INFO:     Epoch: 31
2022-12-05 20:03:07,906 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46832359446720645, 'Total loss': 0.46832359446720645} | train loss {'Reaction outcome loss': 0.18334807716460846, 'Total loss': 0.18334807716460846}
2022-12-05 20:03:07,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:07,907 INFO:     Epoch: 32
2022-12-05 20:03:08,698 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45882477509704506, 'Total loss': 0.45882477509704506} | train loss {'Reaction outcome loss': 0.1814123603481392, 'Total loss': 0.1814123603481392}
2022-12-05 20:03:08,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:08,699 INFO:     Epoch: 33
2022-12-05 20:03:09,491 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45395086434754456, 'Total loss': 0.45395086434754456} | train loss {'Reaction outcome loss': 0.18320405425179584, 'Total loss': 0.18320405425179584}
2022-12-05 20:03:09,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:09,491 INFO:     Epoch: 34
2022-12-05 20:03:10,282 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44614219428463414, 'Total loss': 0.44614219428463414} | train loss {'Reaction outcome loss': 0.17781022371562114, 'Total loss': 0.17781022371562114}
2022-12-05 20:03:10,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:10,282 INFO:     Epoch: 35
2022-12-05 20:03:11,076 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4624621234834194, 'Total loss': 0.4624621234834194} | train loss {'Reaction outcome loss': 0.1775940211437009, 'Total loss': 0.1775940211437009}
2022-12-05 20:03:11,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:11,077 INFO:     Epoch: 36
2022-12-05 20:03:11,876 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4624144373969598, 'Total loss': 0.4624144373969598} | train loss {'Reaction outcome loss': 0.17274757019180034, 'Total loss': 0.17274757019180034}
2022-12-05 20:03:11,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:11,876 INFO:     Epoch: 37
2022-12-05 20:03:12,677 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4585577280006625, 'Total loss': 0.4585577280006625} | train loss {'Reaction outcome loss': 0.1707786928847251, 'Total loss': 0.1707786928847251}
2022-12-05 20:03:12,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:12,677 INFO:     Epoch: 38
2022-12-05 20:03:13,471 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46854212473739276, 'Total loss': 0.46854212473739276} | train loss {'Reaction outcome loss': 0.16596482915997973, 'Total loss': 0.16596482915997973}
2022-12-05 20:03:13,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:13,471 INFO:     Epoch: 39
2022-12-05 20:03:14,265 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47693593105809257, 'Total loss': 0.47693593105809257} | train loss {'Reaction outcome loss': 0.1644777529769264, 'Total loss': 0.1644777529769264}
2022-12-05 20:03:14,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:14,265 INFO:     Epoch: 40
2022-12-05 20:03:15,064 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46630001068115234, 'Total loss': 0.46630001068115234} | train loss {'Reaction outcome loss': 0.1643972857021029, 'Total loss': 0.1643972857021029}
2022-12-05 20:03:15,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:15,064 INFO:     Epoch: 41
2022-12-05 20:03:15,857 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4622310935096307, 'Total loss': 0.4622310935096307} | train loss {'Reaction outcome loss': 0.1644789168105917, 'Total loss': 0.1644789168105917}
2022-12-05 20:03:15,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:15,857 INFO:     Epoch: 42
2022-12-05 20:03:16,649 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4607320725917816, 'Total loss': 0.4607320725917816} | train loss {'Reaction outcome loss': 0.16138209943916, 'Total loss': 0.16138209943916}
2022-12-05 20:03:16,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:16,649 INFO:     Epoch: 43
2022-12-05 20:03:17,449 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4670828956771981, 'Total loss': 0.4670828956771981} | train loss {'Reaction outcome loss': 0.15763358639455155, 'Total loss': 0.15763358639455155}
2022-12-05 20:03:17,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:17,450 INFO:     Epoch: 44
2022-12-05 20:03:18,244 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4647045294669541, 'Total loss': 0.4647045294669541} | train loss {'Reaction outcome loss': 0.1635753752188644, 'Total loss': 0.1635753752188644}
2022-12-05 20:03:18,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:18,244 INFO:     Epoch: 45
2022-12-05 20:03:19,040 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47626367008144205, 'Total loss': 0.47626367008144205} | train loss {'Reaction outcome loss': 0.16137142057119594, 'Total loss': 0.16137142057119594}
2022-12-05 20:03:19,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:19,040 INFO:     Epoch: 46
2022-12-05 20:03:19,829 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46682047234340146, 'Total loss': 0.46682047234340146} | train loss {'Reaction outcome loss': 0.15900700242609267, 'Total loss': 0.15900700242609267}
2022-12-05 20:03:19,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:19,829 INFO:     Epoch: 47
2022-12-05 20:03:20,617 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46448193524371495, 'Total loss': 0.46448193524371495} | train loss {'Reaction outcome loss': 0.15533573780329482, 'Total loss': 0.15533573780329482}
2022-12-05 20:03:20,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:20,618 INFO:     Epoch: 48
2022-12-05 20:03:21,407 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45595911670137534, 'Total loss': 0.45595911670137534} | train loss {'Reaction outcome loss': 0.15420422023577005, 'Total loss': 0.15420422023577005}
2022-12-05 20:03:21,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:21,407 INFO:     Epoch: 49
2022-12-05 20:03:22,195 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45241237567229703, 'Total loss': 0.45241237567229703} | train loss {'Reaction outcome loss': 0.15295603671507071, 'Total loss': 0.15295603671507071}
2022-12-05 20:03:22,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:22,195 INFO:     Epoch: 50
2022-12-05 20:03:22,982 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4641494632444598, 'Total loss': 0.4641494632444598} | train loss {'Reaction outcome loss': 0.15315809316541018, 'Total loss': 0.15315809316541018}
2022-12-05 20:03:22,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:22,983 INFO:     Epoch: 51
2022-12-05 20:03:23,777 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47241411747580225, 'Total loss': 0.47241411747580225} | train loss {'Reaction outcome loss': 0.1533376539619979, 'Total loss': 0.1533376539619979}
2022-12-05 20:03:23,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:23,777 INFO:     Epoch: 52
2022-12-05 20:03:24,568 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4603976837613366, 'Total loss': 0.4603976837613366} | train loss {'Reaction outcome loss': 0.14750142351946668, 'Total loss': 0.14750142351946668}
2022-12-05 20:03:24,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:24,568 INFO:     Epoch: 53
2022-12-05 20:03:25,358 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48355069993571803, 'Total loss': 0.48355069993571803} | train loss {'Reaction outcome loss': 0.14488667766620153, 'Total loss': 0.14488667766620153}
2022-12-05 20:03:25,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:25,358 INFO:     Epoch: 54
2022-12-05 20:03:26,146 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4718926819888028, 'Total loss': 0.4718926819888028} | train loss {'Reaction outcome loss': 0.14592666022841505, 'Total loss': 0.14592666022841505}
2022-12-05 20:03:26,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:26,146 INFO:     Epoch: 55
2022-12-05 20:03:26,935 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4618440107865767, 'Total loss': 0.4618440107865767} | train loss {'Reaction outcome loss': 0.1454792397270198, 'Total loss': 0.1454792397270198}
2022-12-05 20:03:26,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:26,935 INFO:     Epoch: 56
2022-12-05 20:03:27,726 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4702261970801787, 'Total loss': 0.4702261970801787} | train loss {'Reaction outcome loss': 0.14640639050437612, 'Total loss': 0.14640639050437612}
2022-12-05 20:03:27,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:27,726 INFO:     Epoch: 57
2022-12-05 20:03:28,516 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4798993630842729, 'Total loss': 0.4798993630842729} | train loss {'Reaction outcome loss': 0.14694590827352122, 'Total loss': 0.14694590827352122}
2022-12-05 20:03:28,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:28,516 INFO:     Epoch: 58
2022-12-05 20:03:29,305 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47000110657377675, 'Total loss': 0.47000110657377675} | train loss {'Reaction outcome loss': 0.14965640572144798, 'Total loss': 0.14965640572144798}
2022-12-05 20:03:29,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:29,305 INFO:     Epoch: 59
2022-12-05 20:03:30,094 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47277623787522316, 'Total loss': 0.47277623787522316} | train loss {'Reaction outcome loss': 0.14449079586607724, 'Total loss': 0.14449079586607724}
2022-12-05 20:03:30,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:30,094 INFO:     Epoch: 60
2022-12-05 20:03:30,885 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4678960550915111, 'Total loss': 0.4678960550915111} | train loss {'Reaction outcome loss': 0.14366866335242626, 'Total loss': 0.14366866335242626}
2022-12-05 20:03:30,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:30,885 INFO:     Epoch: 61
2022-12-05 20:03:31,675 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47224343703551724, 'Total loss': 0.47224343703551724} | train loss {'Reaction outcome loss': 0.14208961064033662, 'Total loss': 0.14208961064033662}
2022-12-05 20:03:31,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:31,675 INFO:     Epoch: 62
2022-12-05 20:03:32,464 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4712378623133356, 'Total loss': 0.4712378623133356} | train loss {'Reaction outcome loss': 0.13870782151003838, 'Total loss': 0.13870782151003838}
2022-12-05 20:03:32,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:32,465 INFO:     Epoch: 63
2022-12-05 20:03:33,256 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4786659087985754, 'Total loss': 0.4786659087985754} | train loss {'Reaction outcome loss': 0.1379839790540065, 'Total loss': 0.1379839790540065}
2022-12-05 20:03:33,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:33,256 INFO:     Epoch: 64
2022-12-05 20:03:34,046 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45360119369896973, 'Total loss': 0.45360119369896973} | train loss {'Reaction outcome loss': 0.14066647264638893, 'Total loss': 0.14066647264638893}
2022-12-05 20:03:34,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:34,046 INFO:     Epoch: 65
2022-12-05 20:03:34,838 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4825689995830709, 'Total loss': 0.4825689995830709} | train loss {'Reaction outcome loss': 0.138401774800786, 'Total loss': 0.138401774800786}
2022-12-05 20:03:34,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:34,838 INFO:     Epoch: 66
2022-12-05 20:03:35,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46055244925347244, 'Total loss': 0.46055244925347244} | train loss {'Reaction outcome loss': 0.13992626368169964, 'Total loss': 0.13992626368169964}
2022-12-05 20:03:35,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:35,629 INFO:     Epoch: 67
2022-12-05 20:03:36,417 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4634958283806389, 'Total loss': 0.4634958283806389} | train loss {'Reaction outcome loss': 0.1370529146329594, 'Total loss': 0.1370529146329594}
2022-12-05 20:03:36,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:36,417 INFO:     Epoch: 68
2022-12-05 20:03:37,210 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47538156468759885, 'Total loss': 0.47538156468759885} | train loss {'Reaction outcome loss': 0.1371456764653506, 'Total loss': 0.1371456764653506}
2022-12-05 20:03:37,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:37,210 INFO:     Epoch: 69
2022-12-05 20:03:37,999 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4602925499731844, 'Total loss': 0.4602925499731844} | train loss {'Reaction outcome loss': 0.1349041674188093, 'Total loss': 0.1349041674188093}
2022-12-05 20:03:37,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:37,999 INFO:     Epoch: 70
2022-12-05 20:03:38,789 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46144683930006897, 'Total loss': 0.46144683930006897} | train loss {'Reaction outcome loss': 0.13581213188406668, 'Total loss': 0.13581213188406668}
2022-12-05 20:03:38,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:38,790 INFO:     Epoch: 71
2022-12-05 20:03:39,581 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4603696863420985, 'Total loss': 0.4603696863420985} | train loss {'Reaction outcome loss': 0.13397883330490667, 'Total loss': 0.13397883330490667}
2022-12-05 20:03:39,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:39,581 INFO:     Epoch: 72
2022-12-05 20:03:40,376 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47940231554887514, 'Total loss': 0.47940231554887514} | train loss {'Reaction outcome loss': 0.13524411097621386, 'Total loss': 0.13524411097621386}
2022-12-05 20:03:40,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:40,376 INFO:     Epoch: 73
2022-12-05 20:03:41,176 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4699457795782523, 'Total loss': 0.4699457795782523} | train loss {'Reaction outcome loss': 0.13262416039280564, 'Total loss': 0.13262416039280564}
2022-12-05 20:03:41,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:41,176 INFO:     Epoch: 74
2022-12-05 20:03:41,982 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47763406519185414, 'Total loss': 0.47763406519185414} | train loss {'Reaction outcome loss': 0.1330642794157088, 'Total loss': 0.1330642794157088}
2022-12-05 20:03:41,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:41,982 INFO:     Epoch: 75
2022-12-05 20:03:42,788 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45994937826286664, 'Total loss': 0.45994937826286664} | train loss {'Reaction outcome loss': 0.13487369783584646, 'Total loss': 0.13487369783584646}
2022-12-05 20:03:42,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:42,789 INFO:     Epoch: 76
2022-12-05 20:03:43,593 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4572500335899266, 'Total loss': 0.4572500335899266} | train loss {'Reaction outcome loss': 0.13601999196152276, 'Total loss': 0.13601999196152276}
2022-12-05 20:03:43,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:43,594 INFO:     Epoch: 77
2022-12-05 20:03:44,397 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4739239696751941, 'Total loss': 0.4739239696751941} | train loss {'Reaction outcome loss': 0.1337346350830727, 'Total loss': 0.1337346350830727}
2022-12-05 20:03:44,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:44,397 INFO:     Epoch: 78
2022-12-05 20:03:45,198 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46492662822658365, 'Total loss': 0.46492662822658365} | train loss {'Reaction outcome loss': 0.13969903168558834, 'Total loss': 0.13969903168558834}
2022-12-05 20:03:45,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:45,198 INFO:     Epoch: 79
2022-12-05 20:03:45,997 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46269191056489944, 'Total loss': 0.46269191056489944} | train loss {'Reaction outcome loss': 0.12891458582721257, 'Total loss': 0.12891458582721257}
2022-12-05 20:03:45,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:45,997 INFO:     Epoch: 80
2022-12-05 20:03:46,795 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47164085473526607, 'Total loss': 0.47164085473526607} | train loss {'Reaction outcome loss': 0.14433226344149244, 'Total loss': 0.14433226344149244}
2022-12-05 20:03:46,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:46,795 INFO:     Epoch: 81
2022-12-05 20:03:47,593 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46664056757634337, 'Total loss': 0.46664056757634337} | train loss {'Reaction outcome loss': 0.13447413421405652, 'Total loss': 0.13447413421405652}
2022-12-05 20:03:47,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:47,593 INFO:     Epoch: 82
2022-12-05 20:03:48,390 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4736670701002533, 'Total loss': 0.4736670701002533} | train loss {'Reaction outcome loss': 0.1298357714669824, 'Total loss': 0.1298357714669824}
2022-12-05 20:03:48,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:48,390 INFO:     Epoch: 83
2022-12-05 20:03:49,187 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47533134337175975, 'Total loss': 0.47533134337175975} | train loss {'Reaction outcome loss': 0.12794457128656056, 'Total loss': 0.12794457128656056}
2022-12-05 20:03:49,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:49,187 INFO:     Epoch: 84
2022-12-05 20:03:49,990 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46203203092921863, 'Total loss': 0.46203203092921863} | train loss {'Reaction outcome loss': 0.13771129329406057, 'Total loss': 0.13771129329406057}
2022-12-05 20:03:49,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:49,990 INFO:     Epoch: 85
2022-12-05 20:03:50,797 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47168704054572363, 'Total loss': 0.47168704054572363} | train loss {'Reaction outcome loss': 0.13209908099954398, 'Total loss': 0.13209908099954398}
2022-12-05 20:03:50,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:50,798 INFO:     Epoch: 86
2022-12-05 20:03:51,597 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4617497467181899, 'Total loss': 0.4617497467181899} | train loss {'Reaction outcome loss': 0.1275158622016968, 'Total loss': 0.1275158622016968}
2022-12-05 20:03:51,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:51,597 INFO:     Epoch: 87
2022-12-05 20:03:52,401 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45646198237822816, 'Total loss': 0.45646198237822816} | train loss {'Reaction outcome loss': 0.12793214895540042, 'Total loss': 0.12793214895540042}
2022-12-05 20:03:52,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:52,401 INFO:     Epoch: 88
2022-12-05 20:03:53,204 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4658616513691165, 'Total loss': 0.4658616513691165} | train loss {'Reaction outcome loss': 0.12487314208995114, 'Total loss': 0.12487314208995114}
2022-12-05 20:03:53,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:53,204 INFO:     Epoch: 89
2022-12-05 20:03:54,009 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45929589291865175, 'Total loss': 0.45929589291865175} | train loss {'Reaction outcome loss': 0.1252927344184235, 'Total loss': 0.1252927344184235}
2022-12-05 20:03:54,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:54,009 INFO:     Epoch: 90
2022-12-05 20:03:54,809 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4760580282997001, 'Total loss': 0.4760580282997001} | train loss {'Reaction outcome loss': 0.12343225738237261, 'Total loss': 0.12343225738237261}
2022-12-05 20:03:54,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:54,809 INFO:     Epoch: 91
2022-12-05 20:03:55,614 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4687951501797546, 'Total loss': 0.4687951501797546} | train loss {'Reaction outcome loss': 0.12514495347845198, 'Total loss': 0.12514495347845198}
2022-12-05 20:03:55,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:55,614 INFO:     Epoch: 92
2022-12-05 20:03:56,420 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47399648278951645, 'Total loss': 0.47399648278951645} | train loss {'Reaction outcome loss': 0.12575933964628921, 'Total loss': 0.12575933964628921}
2022-12-05 20:03:56,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:56,421 INFO:     Epoch: 93
2022-12-05 20:03:57,228 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4673998337239027, 'Total loss': 0.4673998337239027} | train loss {'Reaction outcome loss': 0.12644996990728746, 'Total loss': 0.12644996990728746}
2022-12-05 20:03:57,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:57,229 INFO:     Epoch: 94
2022-12-05 20:03:58,035 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4766167676584287, 'Total loss': 0.4766167676584287} | train loss {'Reaction outcome loss': 0.1257644049448116, 'Total loss': 0.1257644049448116}
2022-12-05 20:03:58,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:58,036 INFO:     Epoch: 95
2022-12-05 20:03:58,842 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4612614766440608, 'Total loss': 0.4612614766440608} | train loss {'Reaction outcome loss': 0.12369743271764776, 'Total loss': 0.12369743271764776}
2022-12-05 20:03:58,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:58,843 INFO:     Epoch: 96
2022-12-05 20:03:59,651 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4704902663149617, 'Total loss': 0.4704902663149617} | train loss {'Reaction outcome loss': 0.1265318726381732, 'Total loss': 0.1265318726381732}
2022-12-05 20:03:59,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:03:59,651 INFO:     Epoch: 97
2022-12-05 20:04:00,465 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46586438607085834, 'Total loss': 0.46586438607085834} | train loss {'Reaction outcome loss': 0.12447554381330486, 'Total loss': 0.12447554381330486}
2022-12-05 20:04:00,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:00,465 INFO:     Epoch: 98
2022-12-05 20:04:01,275 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46460933136669075, 'Total loss': 0.46460933136669075} | train loss {'Reaction outcome loss': 0.12686780516552146, 'Total loss': 0.12686780516552146}
2022-12-05 20:04:01,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:01,275 INFO:     Epoch: 99
2022-12-05 20:04:02,079 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.470165264877406, 'Total loss': 0.470165264877406} | train loss {'Reaction outcome loss': 0.12323377287083188, 'Total loss': 0.12323377287083188}
2022-12-05 20:04:02,079 INFO:     Best model found after epoch 23 of 100.
2022-12-05 20:04:02,079 INFO:   Done with stage: TRAINING
2022-12-05 20:04:02,079 INFO:   Starting stage: EVALUATION
2022-12-05 20:04:02,206 INFO:   Done with stage: EVALUATION
2022-12-05 20:04:02,206 INFO:   Leaving out SEQ value Fold_3
2022-12-05 20:04:02,219 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:04:02,219 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:04:02,864 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:04:02,865 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:04:02,933 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:04:02,933 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:04:02,933 INFO:     No hyperparam tuning for this model
2022-12-05 20:04:02,933 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:04:02,933 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:04:02,934 INFO:     None feature selector for col prot
2022-12-05 20:04:02,934 INFO:     None feature selector for col prot
2022-12-05 20:04:02,934 INFO:     None feature selector for col prot
2022-12-05 20:04:02,935 INFO:     None feature selector for col chem
2022-12-05 20:04:02,935 INFO:     None feature selector for col chem
2022-12-05 20:04:02,935 INFO:     None feature selector for col chem
2022-12-05 20:04:02,935 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:04:02,935 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:04:02,937 INFO:     Number of params in model 215821
2022-12-05 20:04:02,940 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:04:02,940 INFO:   Starting stage: TRAINING
2022-12-05 20:04:03,001 INFO:     Val loss before train {'Reaction outcome loss': 0.9790758910504255, 'Total loss': 0.9790758910504255}
2022-12-05 20:04:03,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:03,001 INFO:     Epoch: 0
2022-12-05 20:04:03,794 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6249926036054437, 'Total loss': 0.6249926036054437} | train loss {'Reaction outcome loss': 0.7978366739895879, 'Total loss': 0.7978366739895879}
2022-12-05 20:04:03,795 INFO:     Found new best model at epoch 0
2022-12-05 20:04:03,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:03,796 INFO:     Epoch: 1
2022-12-05 20:04:04,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5325968997044996, 'Total loss': 0.5325968997044996} | train loss {'Reaction outcome loss': 0.5486797763985031, 'Total loss': 0.5486797763985031}
2022-12-05 20:04:04,590 INFO:     Found new best model at epoch 1
2022-12-05 20:04:04,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:04,591 INFO:     Epoch: 2
2022-12-05 20:04:05,390 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5115524340759624, 'Total loss': 0.5115524340759624} | train loss {'Reaction outcome loss': 0.475209457412058, 'Total loss': 0.475209457412058}
2022-12-05 20:04:05,390 INFO:     Found new best model at epoch 2
2022-12-05 20:04:05,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:05,391 INFO:     Epoch: 3
2022-12-05 20:04:06,185 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4659088843248107, 'Total loss': 0.4659088843248107} | train loss {'Reaction outcome loss': 0.43309321123726513, 'Total loss': 0.43309321123726513}
2022-12-05 20:04:06,186 INFO:     Found new best model at epoch 3
2022-12-05 20:04:06,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:06,186 INFO:     Epoch: 4
2022-12-05 20:04:06,981 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4572805149311369, 'Total loss': 0.4572805149311369} | train loss {'Reaction outcome loss': 0.40355822072953595, 'Total loss': 0.40355822072953595}
2022-12-05 20:04:06,981 INFO:     Found new best model at epoch 4
2022-12-05 20:04:06,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:06,982 INFO:     Epoch: 5
2022-12-05 20:04:07,773 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44912674582817336, 'Total loss': 0.44912674582817336} | train loss {'Reaction outcome loss': 0.378713057539901, 'Total loss': 0.378713057539901}
2022-12-05 20:04:07,773 INFO:     Found new best model at epoch 5
2022-12-05 20:04:07,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:07,774 INFO:     Epoch: 6
2022-12-05 20:04:08,566 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43333319371396845, 'Total loss': 0.43333319371396845} | train loss {'Reaction outcome loss': 0.36177420865516274, 'Total loss': 0.36177420865516274}
2022-12-05 20:04:08,566 INFO:     Found new best model at epoch 6
2022-12-05 20:04:08,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:08,567 INFO:     Epoch: 7
2022-12-05 20:04:09,357 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43665112588893285, 'Total loss': 0.43665112588893285} | train loss {'Reaction outcome loss': 0.34573693682952805, 'Total loss': 0.34573693682952805}
2022-12-05 20:04:09,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:09,357 INFO:     Epoch: 8
2022-12-05 20:04:10,147 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4312307526442138, 'Total loss': 0.4312307526442138} | train loss {'Reaction outcome loss': 0.3293719837860185, 'Total loss': 0.3293719837860185}
2022-12-05 20:04:10,148 INFO:     Found new best model at epoch 8
2022-12-05 20:04:10,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:10,149 INFO:     Epoch: 9
2022-12-05 20:04:10,943 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41490206799723883, 'Total loss': 0.41490206799723883} | train loss {'Reaction outcome loss': 0.31538186876141294, 'Total loss': 0.31538186876141294}
2022-12-05 20:04:10,943 INFO:     Found new best model at epoch 9
2022-12-05 20:04:10,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:10,944 INFO:     Epoch: 10
2022-12-05 20:04:11,734 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42252056063576177, 'Total loss': 0.42252056063576177} | train loss {'Reaction outcome loss': 0.3031008857853559, 'Total loss': 0.3031008857853559}
2022-12-05 20:04:11,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:11,734 INFO:     Epoch: 11
2022-12-05 20:04:12,525 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4215896712108092, 'Total loss': 0.4215896712108092} | train loss {'Reaction outcome loss': 0.2948068729164649, 'Total loss': 0.2948068729164649}
2022-12-05 20:04:12,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:12,525 INFO:     Epoch: 12
2022-12-05 20:04:13,316 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4116036177358844, 'Total loss': 0.4116036177358844} | train loss {'Reaction outcome loss': 0.28078453927015773, 'Total loss': 0.28078453927015773}
2022-12-05 20:04:13,316 INFO:     Found new best model at epoch 12
2022-12-05 20:04:13,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:13,317 INFO:     Epoch: 13
2022-12-05 20:04:14,115 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41208729859102855, 'Total loss': 0.41208729859102855} | train loss {'Reaction outcome loss': 0.27154182070980265, 'Total loss': 0.27154182070980265}
2022-12-05 20:04:14,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:14,115 INFO:     Epoch: 14
2022-12-05 20:04:14,909 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41530492495406757, 'Total loss': 0.41530492495406757} | train loss {'Reaction outcome loss': 0.26487748624414814, 'Total loss': 0.26487748624414814}
2022-12-05 20:04:14,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:14,909 INFO:     Epoch: 15
2022-12-05 20:04:15,701 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4185051709752191, 'Total loss': 0.4185051709752191} | train loss {'Reaction outcome loss': 0.2549456075137975, 'Total loss': 0.2549456075137975}
2022-12-05 20:04:15,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:15,702 INFO:     Epoch: 16
2022-12-05 20:04:16,497 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41007940809835086, 'Total loss': 0.41007940809835086} | train loss {'Reaction outcome loss': 0.24875972027681312, 'Total loss': 0.24875972027681312}
2022-12-05 20:04:16,497 INFO:     Found new best model at epoch 16
2022-12-05 20:04:16,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:16,498 INFO:     Epoch: 17
2022-12-05 20:04:17,294 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41817019134759903, 'Total loss': 0.41817019134759903} | train loss {'Reaction outcome loss': 0.24079041500784912, 'Total loss': 0.24079041500784912}
2022-12-05 20:04:17,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:17,294 INFO:     Epoch: 18
2022-12-05 20:04:18,087 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41368553855202417, 'Total loss': 0.41368553855202417} | train loss {'Reaction outcome loss': 0.2336606504357591, 'Total loss': 0.2336606504357591}
2022-12-05 20:04:18,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:18,087 INFO:     Epoch: 19
2022-12-05 20:04:18,880 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41127226467836986, 'Total loss': 0.41127226467836986} | train loss {'Reaction outcome loss': 0.23081732523076387, 'Total loss': 0.23081732523076387}
2022-12-05 20:04:18,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:18,880 INFO:     Epoch: 20
2022-12-05 20:04:19,673 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4168195091187954, 'Total loss': 0.4168195091187954} | train loss {'Reaction outcome loss': 0.2202234942998205, 'Total loss': 0.2202234942998205}
2022-12-05 20:04:19,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:19,674 INFO:     Epoch: 21
2022-12-05 20:04:20,468 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41197705404324964, 'Total loss': 0.41197705404324964} | train loss {'Reaction outcome loss': 0.21885494492491897, 'Total loss': 0.21885494492491897}
2022-12-05 20:04:20,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:20,468 INFO:     Epoch: 22
2022-12-05 20:04:21,262 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42392873323776503, 'Total loss': 0.42392873323776503} | train loss {'Reaction outcome loss': 0.21483450030185738, 'Total loss': 0.21483450030185738}
2022-12-05 20:04:21,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:21,262 INFO:     Epoch: 23
2022-12-05 20:04:22,056 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4078230000503192, 'Total loss': 0.4078230000503192} | train loss {'Reaction outcome loss': 0.20980849608170743, 'Total loss': 0.20980849608170743}
2022-12-05 20:04:22,056 INFO:     Found new best model at epoch 23
2022-12-05 20:04:22,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:22,057 INFO:     Epoch: 24
2022-12-05 20:04:22,855 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41607633233070374, 'Total loss': 0.41607633233070374} | train loss {'Reaction outcome loss': 0.20731447491110588, 'Total loss': 0.20731447491110588}
2022-12-05 20:04:22,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:22,856 INFO:     Epoch: 25
2022-12-05 20:04:23,657 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41171279128386895, 'Total loss': 0.41171279128386895} | train loss {'Reaction outcome loss': 0.19980228275668865, 'Total loss': 0.19980228275668865}
2022-12-05 20:04:23,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:23,657 INFO:     Epoch: 26
2022-12-05 20:04:24,456 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4439921829510819, 'Total loss': 0.4439921829510819} | train loss {'Reaction outcome loss': 0.19519189959582017, 'Total loss': 0.19519189959582017}
2022-12-05 20:04:24,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:24,457 INFO:     Epoch: 27
2022-12-05 20:04:25,255 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43572320111773233, 'Total loss': 0.43572320111773233} | train loss {'Reaction outcome loss': 0.1933754460696055, 'Total loss': 0.1933754460696055}
2022-12-05 20:04:25,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:25,255 INFO:     Epoch: 28
2022-12-05 20:04:26,052 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4190230049531568, 'Total loss': 0.4190230049531568} | train loss {'Reaction outcome loss': 0.1931142606601423, 'Total loss': 0.1931142606601423}
2022-12-05 20:04:26,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:26,052 INFO:     Epoch: 29
2022-12-05 20:04:26,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.434665034101768, 'Total loss': 0.434665034101768} | train loss {'Reaction outcome loss': 0.18858994630222417, 'Total loss': 0.18858994630222417}
2022-12-05 20:04:26,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:26,846 INFO:     Epoch: 30
2022-12-05 20:04:27,635 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4390991347079927, 'Total loss': 0.4390991347079927} | train loss {'Reaction outcome loss': 0.18106407789247378, 'Total loss': 0.18106407789247378}
2022-12-05 20:04:27,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:27,635 INFO:     Epoch: 31
2022-12-05 20:04:28,425 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43882819095795805, 'Total loss': 0.43882819095795805} | train loss {'Reaction outcome loss': 0.18178040584435268, 'Total loss': 0.18178040584435268}
2022-12-05 20:04:28,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:28,426 INFO:     Epoch: 32
2022-12-05 20:04:29,217 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4454095329750668, 'Total loss': 0.4454095329750668} | train loss {'Reaction outcome loss': 0.17682827711105348, 'Total loss': 0.17682827711105348}
2022-12-05 20:04:29,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:29,218 INFO:     Epoch: 33
2022-12-05 20:04:30,007 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43791625513271853, 'Total loss': 0.43791625513271853} | train loss {'Reaction outcome loss': 0.17693193950215164, 'Total loss': 0.17693193950215164}
2022-12-05 20:04:30,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:30,007 INFO:     Epoch: 34
2022-12-05 20:04:30,797 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4607058536599983, 'Total loss': 0.4607058536599983} | train loss {'Reaction outcome loss': 0.17234970534942587, 'Total loss': 0.17234970534942587}
2022-12-05 20:04:30,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:30,797 INFO:     Epoch: 35
2022-12-05 20:04:31,591 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43397885552522814, 'Total loss': 0.43397885552522814} | train loss {'Reaction outcome loss': 0.17084794576678958, 'Total loss': 0.17084794576678958}
2022-12-05 20:04:31,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:31,591 INFO:     Epoch: 36
2022-12-05 20:04:32,382 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4475136599080129, 'Total loss': 0.4475136599080129} | train loss {'Reaction outcome loss': 0.16766607694479885, 'Total loss': 0.16766607694479885}
2022-12-05 20:04:32,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:32,382 INFO:     Epoch: 37
2022-12-05 20:04:33,175 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45380777967247093, 'Total loss': 0.45380777967247093} | train loss {'Reaction outcome loss': 0.16740748501401775, 'Total loss': 0.16740748501401775}
2022-12-05 20:04:33,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:33,175 INFO:     Epoch: 38
2022-12-05 20:04:33,968 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4677377851171927, 'Total loss': 0.4677377851171927} | train loss {'Reaction outcome loss': 0.16289208098029603, 'Total loss': 0.16289208098029603}
2022-12-05 20:04:33,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:33,968 INFO:     Epoch: 39
2022-12-05 20:04:34,762 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46056257747113705, 'Total loss': 0.46056257747113705} | train loss {'Reaction outcome loss': 0.16344042107158777, 'Total loss': 0.16344042107158777}
2022-12-05 20:04:34,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:34,763 INFO:     Epoch: 40
2022-12-05 20:04:35,553 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.438097737560218, 'Total loss': 0.438097737560218} | train loss {'Reaction outcome loss': 0.16187066481429704, 'Total loss': 0.16187066481429704}
2022-12-05 20:04:35,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:35,553 INFO:     Epoch: 41
2022-12-05 20:04:36,342 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4518201578069817, 'Total loss': 0.4518201578069817} | train loss {'Reaction outcome loss': 0.1567489373364619, 'Total loss': 0.1567489373364619}
2022-12-05 20:04:36,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:36,342 INFO:     Epoch: 42
2022-12-05 20:04:37,134 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45593933608721604, 'Total loss': 0.45593933608721604} | train loss {'Reaction outcome loss': 0.15798336710704833, 'Total loss': 0.15798336710704833}
2022-12-05 20:04:37,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:37,134 INFO:     Epoch: 43
2022-12-05 20:04:37,922 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4628583707592704, 'Total loss': 0.4628583707592704} | train loss {'Reaction outcome loss': 0.1552075588505487, 'Total loss': 0.1552075588505487}
2022-12-05 20:04:37,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:37,922 INFO:     Epoch: 44
2022-12-05 20:04:38,713 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4685680002651431, 'Total loss': 0.4685680002651431} | train loss {'Reaction outcome loss': 0.15662833740364532, 'Total loss': 0.15662833740364532}
2022-12-05 20:04:38,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:38,713 INFO:     Epoch: 45
2022-12-05 20:04:39,505 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48444832929156045, 'Total loss': 0.48444832929156045} | train loss {'Reaction outcome loss': 0.15350007267326723, 'Total loss': 0.15350007267326723}
2022-12-05 20:04:39,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:39,505 INFO:     Epoch: 46
2022-12-05 20:04:40,298 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45959542962637817, 'Total loss': 0.45959542962637817} | train loss {'Reaction outcome loss': 0.14973550663918864, 'Total loss': 0.14973550663918864}
2022-12-05 20:04:40,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:40,298 INFO:     Epoch: 47
2022-12-05 20:04:41,088 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4596534378149293, 'Total loss': 0.4596534378149293} | train loss {'Reaction outcome loss': 0.1477114193749671, 'Total loss': 0.1477114193749671}
2022-12-05 20:04:41,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:41,089 INFO:     Epoch: 48
2022-12-05 20:04:41,878 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46901797130703926, 'Total loss': 0.46901797130703926} | train loss {'Reaction outcome loss': 0.1475849912026707, 'Total loss': 0.1475849912026707}
2022-12-05 20:04:41,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:41,879 INFO:     Epoch: 49
2022-12-05 20:04:42,667 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4646285384819335, 'Total loss': 0.4646285384819335} | train loss {'Reaction outcome loss': 0.1476865726998266, 'Total loss': 0.1476865726998266}
2022-12-05 20:04:42,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:42,667 INFO:     Epoch: 50
2022-12-05 20:04:43,456 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4700900119814006, 'Total loss': 0.4700900119814006} | train loss {'Reaction outcome loss': 0.1460208147992285, 'Total loss': 0.1460208147992285}
2022-12-05 20:04:43,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:43,456 INFO:     Epoch: 51
2022-12-05 20:04:44,245 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45344496704638004, 'Total loss': 0.45344496704638004} | train loss {'Reaction outcome loss': 0.14984329431792912, 'Total loss': 0.14984329431792912}
2022-12-05 20:04:44,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:44,245 INFO:     Epoch: 52
2022-12-05 20:04:45,034 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47529224441810086, 'Total loss': 0.47529224441810086} | train loss {'Reaction outcome loss': 0.14330353074688085, 'Total loss': 0.14330353074688085}
2022-12-05 20:04:45,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:45,034 INFO:     Epoch: 53
2022-12-05 20:04:45,824 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45015111516907136, 'Total loss': 0.45015111516907136} | train loss {'Reaction outcome loss': 0.14682245502362445, 'Total loss': 0.14682245502362445}
2022-12-05 20:04:45,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:45,824 INFO:     Epoch: 54
2022-12-05 20:04:46,618 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4904662069271911, 'Total loss': 0.4904662069271911} | train loss {'Reaction outcome loss': 0.14041383917994646, 'Total loss': 0.14041383917994646}
2022-12-05 20:04:46,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:46,618 INFO:     Epoch: 55
2022-12-05 20:04:47,407 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45359197157350456, 'Total loss': 0.45359197157350456} | train loss {'Reaction outcome loss': 0.14166942837134916, 'Total loss': 0.14166942837134916}
2022-12-05 20:04:47,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:47,408 INFO:     Epoch: 56
2022-12-05 20:04:48,197 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46381316892802715, 'Total loss': 0.46381316892802715} | train loss {'Reaction outcome loss': 0.14131445492408715, 'Total loss': 0.14131445492408715}
2022-12-05 20:04:48,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:48,197 INFO:     Epoch: 57
2022-12-05 20:04:48,987 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45135916803370824, 'Total loss': 0.45135916803370824} | train loss {'Reaction outcome loss': 0.13954752439594997, 'Total loss': 0.13954752439594997}
2022-12-05 20:04:48,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:48,987 INFO:     Epoch: 58
2022-12-05 20:04:49,779 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4614313368431546, 'Total loss': 0.4614313368431546} | train loss {'Reaction outcome loss': 0.13740034104153817, 'Total loss': 0.13740034104153817}
2022-12-05 20:04:49,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:49,779 INFO:     Epoch: 59
2022-12-05 20:04:50,569 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.476136370816014, 'Total loss': 0.476136370816014} | train loss {'Reaction outcome loss': 0.13945173857619567, 'Total loss': 0.13945173857619567}
2022-12-05 20:04:50,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:50,570 INFO:     Epoch: 60
2022-12-05 20:04:51,359 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4516159367154945, 'Total loss': 0.4516159367154945} | train loss {'Reaction outcome loss': 0.13639360641186335, 'Total loss': 0.13639360641186335}
2022-12-05 20:04:51,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:51,359 INFO:     Epoch: 61
2022-12-05 20:04:52,149 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48558023876764556, 'Total loss': 0.48558023876764556} | train loss {'Reaction outcome loss': 0.13853558382893705, 'Total loss': 0.13853558382893705}
2022-12-05 20:04:52,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:52,149 INFO:     Epoch: 62
2022-12-05 20:04:52,939 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4933793768286705, 'Total loss': 0.4933793768286705} | train loss {'Reaction outcome loss': 0.1368335586231278, 'Total loss': 0.1368335586231278}
2022-12-05 20:04:52,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:52,939 INFO:     Epoch: 63
2022-12-05 20:04:53,729 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4706427669999274, 'Total loss': 0.4706427669999274} | train loss {'Reaction outcome loss': 0.13551304040058534, 'Total loss': 0.13551304040058534}
2022-12-05 20:04:53,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:53,730 INFO:     Epoch: 64
2022-12-05 20:04:54,520 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4669237228279764, 'Total loss': 0.4669237228279764} | train loss {'Reaction outcome loss': 0.13839577992959898, 'Total loss': 0.13839577992959898}
2022-12-05 20:04:54,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:54,520 INFO:     Epoch: 65
2022-12-05 20:04:55,314 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48676336590539326, 'Total loss': 0.48676336590539326} | train loss {'Reaction outcome loss': 0.13416609451630895, 'Total loss': 0.13416609451630895}
2022-12-05 20:04:55,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:55,314 INFO:     Epoch: 66
2022-12-05 20:04:56,105 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4648199643601071, 'Total loss': 0.4648199643601071} | train loss {'Reaction outcome loss': 0.1321133761533669, 'Total loss': 0.1321133761533669}
2022-12-05 20:04:56,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:56,105 INFO:     Epoch: 67
2022-12-05 20:04:56,900 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48443050953474914, 'Total loss': 0.48443050953474914} | train loss {'Reaction outcome loss': 0.13243208312410482, 'Total loss': 0.13243208312410482}
2022-12-05 20:04:56,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:56,900 INFO:     Epoch: 68
2022-12-05 20:04:57,690 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4677012257955291, 'Total loss': 0.4677012257955291} | train loss {'Reaction outcome loss': 0.1305394709566418, 'Total loss': 0.1305394709566418}
2022-12-05 20:04:57,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:57,690 INFO:     Epoch: 69
2022-12-05 20:04:58,479 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48473669622432103, 'Total loss': 0.48473669622432103} | train loss {'Reaction outcome loss': 0.13177974945580473, 'Total loss': 0.13177974945580473}
2022-12-05 20:04:58,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:58,480 INFO:     Epoch: 70
2022-12-05 20:04:59,272 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4655266485430978, 'Total loss': 0.4655266485430978} | train loss {'Reaction outcome loss': 0.1311772928706237, 'Total loss': 0.1311772928706237}
2022-12-05 20:04:59,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:04:59,273 INFO:     Epoch: 71
2022-12-05 20:05:00,064 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4761017213829539, 'Total loss': 0.4761017213829539} | train loss {'Reaction outcome loss': 0.13023672551296803, 'Total loss': 0.13023672551296803}
2022-12-05 20:05:00,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:00,064 INFO:     Epoch: 72
2022-12-05 20:05:00,861 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4712286066602577, 'Total loss': 0.4712286066602577} | train loss {'Reaction outcome loss': 0.12943815153320226, 'Total loss': 0.12943815153320226}
2022-12-05 20:05:00,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:00,861 INFO:     Epoch: 73
2022-12-05 20:05:01,652 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4734320615164258, 'Total loss': 0.4734320615164258} | train loss {'Reaction outcome loss': 0.13107159989600886, 'Total loss': 0.13107159989600886}
2022-12-05 20:05:01,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:01,652 INFO:     Epoch: 74
2022-12-05 20:05:02,442 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47894969616423955, 'Total loss': 0.47894969616423955} | train loss {'Reaction outcome loss': 0.12828836651252848, 'Total loss': 0.12828836651252848}
2022-12-05 20:05:02,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:02,442 INFO:     Epoch: 75
2022-12-05 20:05:03,234 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48583206127990375, 'Total loss': 0.48583206127990375} | train loss {'Reaction outcome loss': 0.1294673946096885, 'Total loss': 0.1294673946096885}
2022-12-05 20:05:03,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:03,234 INFO:     Epoch: 76
2022-12-05 20:05:04,025 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46392340026795864, 'Total loss': 0.46392340026795864} | train loss {'Reaction outcome loss': 0.12933376139333966, 'Total loss': 0.12933376139333966}
2022-12-05 20:05:04,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:04,025 INFO:     Epoch: 77
2022-12-05 20:05:04,814 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46159510568461637, 'Total loss': 0.46159510568461637} | train loss {'Reaction outcome loss': 0.12850396332083916, 'Total loss': 0.12850396332083916}
2022-12-05 20:05:04,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:04,815 INFO:     Epoch: 78
2022-12-05 20:05:05,606 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4948046017776836, 'Total loss': 0.4948046017776836} | train loss {'Reaction outcome loss': 0.12746133552674127, 'Total loss': 0.12746133552674127}
2022-12-05 20:05:05,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:05,607 INFO:     Epoch: 79
2022-12-05 20:05:06,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46812318434769457, 'Total loss': 0.46812318434769457} | train loss {'Reaction outcome loss': 0.12879789540049982, 'Total loss': 0.12879789540049982}
2022-12-05 20:05:06,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:06,402 INFO:     Epoch: 80
2022-12-05 20:05:07,192 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4776069112122059, 'Total loss': 0.4776069112122059} | train loss {'Reaction outcome loss': 0.12740736721577692, 'Total loss': 0.12740736721577692}
2022-12-05 20:05:07,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:07,192 INFO:     Epoch: 81
2022-12-05 20:05:07,982 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4672158414667303, 'Total loss': 0.4672158414667303} | train loss {'Reaction outcome loss': 0.1277122608252934, 'Total loss': 0.1277122608252934}
2022-12-05 20:05:07,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:07,982 INFO:     Epoch: 82
2022-12-05 20:05:08,771 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46685061586851423, 'Total loss': 0.46685061586851423} | train loss {'Reaction outcome loss': 0.12406567645316222, 'Total loss': 0.12406567645316222}
2022-12-05 20:05:08,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:08,772 INFO:     Epoch: 83
2022-12-05 20:05:09,564 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47252608226104215, 'Total loss': 0.47252608226104215} | train loss {'Reaction outcome loss': 0.12365247470383742, 'Total loss': 0.12365247470383742}
2022-12-05 20:05:09,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:09,564 INFO:     Epoch: 84
2022-12-05 20:05:10,360 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46946251447397197, 'Total loss': 0.46946251447397197} | train loss {'Reaction outcome loss': 0.1241165872321141, 'Total loss': 0.1241165872321141}
2022-12-05 20:05:10,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:10,360 INFO:     Epoch: 85
2022-12-05 20:05:11,155 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4677344530990178, 'Total loss': 0.4677344530990178} | train loss {'Reaction outcome loss': 0.12329866969767882, 'Total loss': 0.12329866969767882}
2022-12-05 20:05:11,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:11,155 INFO:     Epoch: 86
2022-12-05 20:05:11,949 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48506619154729624, 'Total loss': 0.48506619154729624} | train loss {'Reaction outcome loss': 0.1211444372197195, 'Total loss': 0.1211444372197195}
2022-12-05 20:05:11,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:11,950 INFO:     Epoch: 87
2022-12-05 20:05:12,742 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46373767575079744, 'Total loss': 0.46373767575079744} | train loss {'Reaction outcome loss': 0.1241440101507671, 'Total loss': 0.1241440101507671}
2022-12-05 20:05:12,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:12,742 INFO:     Epoch: 88
2022-12-05 20:05:13,531 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4688415884632956, 'Total loss': 0.4688415884632956} | train loss {'Reaction outcome loss': 0.12402415955629276, 'Total loss': 0.12402415955629276}
2022-12-05 20:05:13,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:13,531 INFO:     Epoch: 89
2022-12-05 20:05:14,319 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4609922494379465, 'Total loss': 0.4609922494379465} | train loss {'Reaction outcome loss': 0.12230941844077743, 'Total loss': 0.12230941844077743}
2022-12-05 20:05:14,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:14,320 INFO:     Epoch: 90
2022-12-05 20:05:15,109 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47115960039875726, 'Total loss': 0.47115960039875726} | train loss {'Reaction outcome loss': 0.1229057702673029, 'Total loss': 0.1229057702673029}
2022-12-05 20:05:15,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:15,109 INFO:     Epoch: 91
2022-12-05 20:05:15,897 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4792246449400078, 'Total loss': 0.4792246449400078} | train loss {'Reaction outcome loss': 0.11962363447765914, 'Total loss': 0.11962363447765914}
2022-12-05 20:05:15,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:15,897 INFO:     Epoch: 92
2022-12-05 20:05:16,690 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4598358537663113, 'Total loss': 0.4598358537663113} | train loss {'Reaction outcome loss': 0.12193976364725706, 'Total loss': 0.12193976364725706}
2022-12-05 20:05:16,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:16,691 INFO:     Epoch: 93
2022-12-05 20:05:17,488 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47993216528133914, 'Total loss': 0.47993216528133914} | train loss {'Reaction outcome loss': 0.12243150832625677, 'Total loss': 0.12243150832625677}
2022-12-05 20:05:17,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:17,488 INFO:     Epoch: 94
2022-12-05 20:05:18,280 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4830296390943907, 'Total loss': 0.4830296390943907} | train loss {'Reaction outcome loss': 0.12064130091849638, 'Total loss': 0.12064130091849638}
2022-12-05 20:05:18,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:18,280 INFO:     Epoch: 95
2022-12-05 20:05:19,074 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4852226149629463, 'Total loss': 0.4852226149629463} | train loss {'Reaction outcome loss': 0.11906470960120158, 'Total loss': 0.11906470960120158}
2022-12-05 20:05:19,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:19,074 INFO:     Epoch: 96
2022-12-05 20:05:19,862 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46894192119890993, 'Total loss': 0.46894192119890993} | train loss {'Reaction outcome loss': 0.11806187246146858, 'Total loss': 0.11806187246146858}
2022-12-05 20:05:19,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:19,862 INFO:     Epoch: 97
2022-12-05 20:05:20,653 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.478569529611956, 'Total loss': 0.478569529611956} | train loss {'Reaction outcome loss': 0.12079996566231153, 'Total loss': 0.12079996566231153}
2022-12-05 20:05:20,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:20,653 INFO:     Epoch: 98
2022-12-05 20:05:21,443 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47074822133237665, 'Total loss': 0.47074822133237665} | train loss {'Reaction outcome loss': 0.11797882601504728, 'Total loss': 0.11797882601504728}
2022-12-05 20:05:21,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:21,444 INFO:     Epoch: 99
2022-12-05 20:05:22,234 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4869946227832274, 'Total loss': 0.4869946227832274} | train loss {'Reaction outcome loss': 0.12192896289788947, 'Total loss': 0.12192896289788947}
2022-12-05 20:05:22,234 INFO:     Best model found after epoch 24 of 100.
2022-12-05 20:05:22,234 INFO:   Done with stage: TRAINING
2022-12-05 20:05:22,234 INFO:   Starting stage: EVALUATION
2022-12-05 20:05:22,366 INFO:   Done with stage: EVALUATION
2022-12-05 20:05:22,367 INFO:   Leaving out SEQ value Fold_4
2022-12-05 20:05:22,379 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:05:22,379 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:05:23,025 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:05:23,025 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:05:23,096 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:05:23,096 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:05:23,096 INFO:     No hyperparam tuning for this model
2022-12-05 20:05:23,096 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:05:23,096 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:05:23,097 INFO:     None feature selector for col prot
2022-12-05 20:05:23,097 INFO:     None feature selector for col prot
2022-12-05 20:05:23,097 INFO:     None feature selector for col prot
2022-12-05 20:05:23,097 INFO:     None feature selector for col chem
2022-12-05 20:05:23,098 INFO:     None feature selector for col chem
2022-12-05 20:05:23,098 INFO:     None feature selector for col chem
2022-12-05 20:05:23,098 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:05:23,098 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:05:23,099 INFO:     Number of params in model 215821
2022-12-05 20:05:23,103 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:05:23,103 INFO:   Starting stage: TRAINING
2022-12-05 20:05:23,164 INFO:     Val loss before train {'Reaction outcome loss': 1.0038111507892609, 'Total loss': 1.0038111507892609}
2022-12-05 20:05:23,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:23,165 INFO:     Epoch: 0
2022-12-05 20:05:23,965 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6115240742537108, 'Total loss': 0.6115240742537108} | train loss {'Reaction outcome loss': 0.8264543445486772, 'Total loss': 0.8264543445486772}
2022-12-05 20:05:23,966 INFO:     Found new best model at epoch 0
2022-12-05 20:05:23,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:23,967 INFO:     Epoch: 1
2022-12-05 20:05:24,764 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5253069184043191, 'Total loss': 0.5253069184043191} | train loss {'Reaction outcome loss': 0.5638178818621616, 'Total loss': 0.5638178818621616}
2022-12-05 20:05:24,764 INFO:     Found new best model at epoch 1
2022-12-05 20:05:24,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:24,765 INFO:     Epoch: 2
2022-12-05 20:05:25,566 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47795685109767044, 'Total loss': 0.47795685109767044} | train loss {'Reaction outcome loss': 0.48567977077836694, 'Total loss': 0.48567977077836694}
2022-12-05 20:05:25,566 INFO:     Found new best model at epoch 2
2022-12-05 20:05:25,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:25,567 INFO:     Epoch: 3
2022-12-05 20:05:26,367 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4709591973911632, 'Total loss': 0.4709591973911632} | train loss {'Reaction outcome loss': 0.4457790242877566, 'Total loss': 0.4457790242877566}
2022-12-05 20:05:26,367 INFO:     Found new best model at epoch 3
2022-12-05 20:05:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:26,368 INFO:     Epoch: 4
2022-12-05 20:05:27,167 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4531124613501809, 'Total loss': 0.4531124613501809} | train loss {'Reaction outcome loss': 0.41678889072405906, 'Total loss': 0.41678889072405906}
2022-12-05 20:05:27,167 INFO:     Found new best model at epoch 4
2022-12-05 20:05:27,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:27,168 INFO:     Epoch: 5
2022-12-05 20:05:27,966 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45125814053145324, 'Total loss': 0.45125814053145324} | train loss {'Reaction outcome loss': 0.39257669149471924, 'Total loss': 0.39257669149471924}
2022-12-05 20:05:27,966 INFO:     Found new best model at epoch 5
2022-12-05 20:05:27,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:27,967 INFO:     Epoch: 6
2022-12-05 20:05:28,761 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43404603139920667, 'Total loss': 0.43404603139920667} | train loss {'Reaction outcome loss': 0.3741899395007112, 'Total loss': 0.3741899395007112}
2022-12-05 20:05:28,761 INFO:     Found new best model at epoch 6
2022-12-05 20:05:28,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:28,762 INFO:     Epoch: 7
2022-12-05 20:05:29,573 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4249137689105489, 'Total loss': 0.4249137689105489} | train loss {'Reaction outcome loss': 0.3550311723942699, 'Total loss': 0.3550311723942699}
2022-12-05 20:05:29,573 INFO:     Found new best model at epoch 7
2022-12-05 20:05:29,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:29,574 INFO:     Epoch: 8
2022-12-05 20:05:30,389 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41601091013713315, 'Total loss': 0.41601091013713315} | train loss {'Reaction outcome loss': 0.34401322391472366, 'Total loss': 0.34401322391472366}
2022-12-05 20:05:30,389 INFO:     Found new best model at epoch 8
2022-12-05 20:05:30,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:30,390 INFO:     Epoch: 9
2022-12-05 20:05:31,206 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43203624574975535, 'Total loss': 0.43203624574975535} | train loss {'Reaction outcome loss': 0.32788059311477763, 'Total loss': 0.32788059311477763}
2022-12-05 20:05:31,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:31,207 INFO:     Epoch: 10
2022-12-05 20:05:32,020 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41926981474865566, 'Total loss': 0.41926981474865566} | train loss {'Reaction outcome loss': 0.3185290937455228, 'Total loss': 0.3185290937455228}
2022-12-05 20:05:32,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:32,020 INFO:     Epoch: 11
2022-12-05 20:05:32,838 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42530281164429407, 'Total loss': 0.42530281164429407} | train loss {'Reaction outcome loss': 0.3059886533178781, 'Total loss': 0.3059886533178781}
2022-12-05 20:05:32,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:32,838 INFO:     Epoch: 12
2022-12-05 20:05:33,653 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42844302308830345, 'Total loss': 0.42844302308830345} | train loss {'Reaction outcome loss': 0.29525811525499107, 'Total loss': 0.29525811525499107}
2022-12-05 20:05:33,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:33,653 INFO:     Epoch: 13
2022-12-05 20:05:34,468 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4237451394173232, 'Total loss': 0.4237451394173232} | train loss {'Reaction outcome loss': 0.28556467906424876, 'Total loss': 0.28556467906424876}
2022-12-05 20:05:34,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:34,469 INFO:     Epoch: 14
2022-12-05 20:05:35,288 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42495727708393877, 'Total loss': 0.42495727708393877} | train loss {'Reaction outcome loss': 0.2770007193118696, 'Total loss': 0.2770007193118696}
2022-12-05 20:05:35,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:35,288 INFO:     Epoch: 15
2022-12-05 20:05:36,106 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4258629141206091, 'Total loss': 0.4258629141206091} | train loss {'Reaction outcome loss': 0.2641978275920698, 'Total loss': 0.2641978275920698}
2022-12-05 20:05:36,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:36,107 INFO:     Epoch: 16
2022-12-05 20:05:36,926 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4145650699396025, 'Total loss': 0.4145650699396025} | train loss {'Reaction outcome loss': 0.2547311502898127, 'Total loss': 0.2547311502898127}
2022-12-05 20:05:36,926 INFO:     Found new best model at epoch 16
2022-12-05 20:05:36,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:36,927 INFO:     Epoch: 17
2022-12-05 20:05:37,749 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4190301072191108, 'Total loss': 0.4190301072191108} | train loss {'Reaction outcome loss': 0.250442022472801, 'Total loss': 0.250442022472801}
2022-12-05 20:05:37,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:37,750 INFO:     Epoch: 18
2022-12-05 20:05:38,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4233356941152703, 'Total loss': 0.4233356941152703} | train loss {'Reaction outcome loss': 0.2436477840587738, 'Total loss': 0.2436477840587738}
2022-12-05 20:05:38,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:38,567 INFO:     Epoch: 19
2022-12-05 20:05:39,382 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4457442933185534, 'Total loss': 0.4457442933185534} | train loss {'Reaction outcome loss': 0.23702488886380968, 'Total loss': 0.23702488886380968}
2022-12-05 20:05:39,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:39,382 INFO:     Epoch: 20
2022-12-05 20:05:40,200 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4248298941688104, 'Total loss': 0.4248298941688104} | train loss {'Reaction outcome loss': 0.23002864062401507, 'Total loss': 0.23002864062401507}
2022-12-05 20:05:40,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:40,200 INFO:     Epoch: 21
2022-12-05 20:05:41,012 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4352400993758982, 'Total loss': 0.4352400993758982} | train loss {'Reaction outcome loss': 0.22308425684666888, 'Total loss': 0.22308425684666888}
2022-12-05 20:05:41,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:41,012 INFO:     Epoch: 22
2022-12-05 20:05:41,824 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42128038372505794, 'Total loss': 0.42128038372505794} | train loss {'Reaction outcome loss': 0.22293418860025252, 'Total loss': 0.22293418860025252}
2022-12-05 20:05:41,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:41,824 INFO:     Epoch: 23
2022-12-05 20:05:42,637 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4285130477087064, 'Total loss': 0.4285130477087064} | train loss {'Reaction outcome loss': 0.21965749341210253, 'Total loss': 0.21965749341210253}
2022-12-05 20:05:42,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:42,638 INFO:     Epoch: 24
2022-12-05 20:05:43,455 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4370136907832189, 'Total loss': 0.4370136907832189} | train loss {'Reaction outcome loss': 0.20941794986425624, 'Total loss': 0.20941794986425624}
2022-12-05 20:05:43,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:43,455 INFO:     Epoch: 25
2022-12-05 20:05:44,267 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4439833646809513, 'Total loss': 0.4439833646809513} | train loss {'Reaction outcome loss': 0.2128793864929483, 'Total loss': 0.2128793864929483}
2022-12-05 20:05:44,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:44,267 INFO:     Epoch: 26
2022-12-05 20:05:45,082 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43917103145610203, 'Total loss': 0.43917103145610203} | train loss {'Reaction outcome loss': 0.20319065982513582, 'Total loss': 0.20319065982513582}
2022-12-05 20:05:45,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:45,082 INFO:     Epoch: 27
2022-12-05 20:05:45,896 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4466617459600622, 'Total loss': 0.4466617459600622} | train loss {'Reaction outcome loss': 0.1979309255728566, 'Total loss': 0.1979309255728566}
2022-12-05 20:05:45,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:45,897 INFO:     Epoch: 28
2022-12-05 20:05:46,709 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46692248501560907, 'Total loss': 0.46692248501560907} | train loss {'Reaction outcome loss': 0.19214098429616525, 'Total loss': 0.19214098429616525}
2022-12-05 20:05:46,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:46,709 INFO:     Epoch: 29
2022-12-05 20:05:47,522 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4342626524581151, 'Total loss': 0.4342626524581151} | train loss {'Reaction outcome loss': 0.1912491654728347, 'Total loss': 0.1912491654728347}
2022-12-05 20:05:47,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:47,522 INFO:     Epoch: 30
2022-12-05 20:05:48,334 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4241521226411516, 'Total loss': 0.4241521226411516} | train loss {'Reaction outcome loss': 0.19597329706828362, 'Total loss': 0.19597329706828362}
2022-12-05 20:05:48,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:48,334 INFO:     Epoch: 31
2022-12-05 20:05:49,147 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44455238668756053, 'Total loss': 0.44455238668756053} | train loss {'Reaction outcome loss': 0.18866850290945184, 'Total loss': 0.18866850290945184}
2022-12-05 20:05:49,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:49,147 INFO:     Epoch: 32
2022-12-05 20:05:49,963 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.438809873028235, 'Total loss': 0.438809873028235} | train loss {'Reaction outcome loss': 0.1811903647301711, 'Total loss': 0.1811903647301711}
2022-12-05 20:05:49,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:49,963 INFO:     Epoch: 33
2022-12-05 20:05:50,768 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4289136715233326, 'Total loss': 0.4289136715233326} | train loss {'Reaction outcome loss': 0.17797403082794505, 'Total loss': 0.17797403082794505}
2022-12-05 20:05:50,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:50,769 INFO:     Epoch: 34
2022-12-05 20:05:51,572 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42234749922698195, 'Total loss': 0.42234749922698195} | train loss {'Reaction outcome loss': 0.17833919307360283, 'Total loss': 0.17833919307360283}
2022-12-05 20:05:51,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:51,573 INFO:     Epoch: 35
2022-12-05 20:05:52,376 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44815887781706726, 'Total loss': 0.44815887781706726} | train loss {'Reaction outcome loss': 0.1779323246345105, 'Total loss': 0.1779323246345105}
2022-12-05 20:05:52,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:52,377 INFO:     Epoch: 36
2022-12-05 20:05:53,177 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4481795999136838, 'Total loss': 0.4481795999136838} | train loss {'Reaction outcome loss': 0.1713401027625193, 'Total loss': 0.1713401027625193}
2022-12-05 20:05:53,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:53,178 INFO:     Epoch: 37
2022-12-05 20:05:53,978 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43873591043732385, 'Total loss': 0.43873591043732385} | train loss {'Reaction outcome loss': 0.17145634193853795, 'Total loss': 0.17145634193853795}
2022-12-05 20:05:53,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:53,979 INFO:     Epoch: 38
2022-12-05 20:05:54,782 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4337947036732327, 'Total loss': 0.4337947036732327} | train loss {'Reaction outcome loss': 0.16837083274566453, 'Total loss': 0.16837083274566453}
2022-12-05 20:05:54,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:54,783 INFO:     Epoch: 39
2022-12-05 20:05:55,593 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4439525577155026, 'Total loss': 0.4439525577155026} | train loss {'Reaction outcome loss': 0.16988377192251852, 'Total loss': 0.16988377192251852}
2022-12-05 20:05:55,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:55,593 INFO:     Epoch: 40
2022-12-05 20:05:56,390 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44460817528041924, 'Total loss': 0.44460817528041924} | train loss {'Reaction outcome loss': 0.16868116454737872, 'Total loss': 0.16868116454737872}
2022-12-05 20:05:56,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:56,391 INFO:     Epoch: 41
2022-12-05 20:05:57,187 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.431618268686262, 'Total loss': 0.431618268686262} | train loss {'Reaction outcome loss': 0.16716674599148001, 'Total loss': 0.16716674599148001}
2022-12-05 20:05:57,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:57,187 INFO:     Epoch: 42
2022-12-05 20:05:57,984 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43773347715085204, 'Total loss': 0.43773347715085204} | train loss {'Reaction outcome loss': 0.16645581325372824, 'Total loss': 0.16645581325372824}
2022-12-05 20:05:57,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:57,985 INFO:     Epoch: 43
2022-12-05 20:05:58,786 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.459668961099603, 'Total loss': 0.459668961099603} | train loss {'Reaction outcome loss': 0.16212565731634254, 'Total loss': 0.16212565731634254}
2022-12-05 20:05:58,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:58,786 INFO:     Epoch: 44
2022-12-05 20:05:59,586 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.457078123295849, 'Total loss': 0.457078123295849} | train loss {'Reaction outcome loss': 0.16020208462857857, 'Total loss': 0.16020208462857857}
2022-12-05 20:05:59,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:05:59,586 INFO:     Epoch: 45
2022-12-05 20:06:00,383 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4611895080994476, 'Total loss': 0.4611895080994476} | train loss {'Reaction outcome loss': 0.15923614569973607, 'Total loss': 0.15923614569973607}
2022-12-05 20:06:00,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:00,383 INFO:     Epoch: 46
2022-12-05 20:06:01,186 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4393953415141864, 'Total loss': 0.4393953415141864} | train loss {'Reaction outcome loss': 0.1591947332009492, 'Total loss': 0.1591947332009492}
2022-12-05 20:06:01,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:01,186 INFO:     Epoch: 47
2022-12-05 20:06:01,982 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4481354027309201, 'Total loss': 0.4481354027309201} | train loss {'Reaction outcome loss': 0.1561437978593987, 'Total loss': 0.1561437978593987}
2022-12-05 20:06:01,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:01,982 INFO:     Epoch: 48
2022-12-05 20:06:02,778 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4441128041256558, 'Total loss': 0.4441128041256558} | train loss {'Reaction outcome loss': 0.15995488065457056, 'Total loss': 0.15995488065457056}
2022-12-05 20:06:02,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:02,778 INFO:     Epoch: 49
2022-12-05 20:06:03,575 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4319691431115974, 'Total loss': 0.4319691431115974} | train loss {'Reaction outcome loss': 0.16224647480014123, 'Total loss': 0.16224647480014123}
2022-12-05 20:06:03,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:03,575 INFO:     Epoch: 50
2022-12-05 20:06:04,376 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46031042256138544, 'Total loss': 0.46031042256138544} | train loss {'Reaction outcome loss': 0.1496559208417349, 'Total loss': 0.1496559208417349}
2022-12-05 20:06:04,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:04,376 INFO:     Epoch: 51
2022-12-05 20:06:05,177 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4291174631904472, 'Total loss': 0.4291174631904472} | train loss {'Reaction outcome loss': 0.15300598073946803, 'Total loss': 0.15300598073946803}
2022-12-05 20:06:05,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:05,177 INFO:     Epoch: 52
2022-12-05 20:06:05,973 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4455510171299631, 'Total loss': 0.4455510171299631} | train loss {'Reaction outcome loss': 0.1496322166989086, 'Total loss': 0.1496322166989086}
2022-12-05 20:06:05,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:05,973 INFO:     Epoch: 53
2022-12-05 20:06:06,771 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44047166000713, 'Total loss': 0.44047166000713} | train loss {'Reaction outcome loss': 0.1456050543634877, 'Total loss': 0.1456050543634877}
2022-12-05 20:06:06,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:06,772 INFO:     Epoch: 54
2022-12-05 20:06:07,574 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45293585515835066, 'Total loss': 0.45293585515835066} | train loss {'Reaction outcome loss': 0.14948107287106727, 'Total loss': 0.14948107287106727}
2022-12-05 20:06:07,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:07,576 INFO:     Epoch: 55
2022-12-05 20:06:08,374 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4435923842882568, 'Total loss': 0.4435923842882568} | train loss {'Reaction outcome loss': 0.15146067034762337, 'Total loss': 0.15146067034762337}
2022-12-05 20:06:08,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:08,374 INFO:     Epoch: 56
2022-12-05 20:06:09,172 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4446860199624842, 'Total loss': 0.4446860199624842} | train loss {'Reaction outcome loss': 0.14606903929278436, 'Total loss': 0.14606903929278436}
2022-12-05 20:06:09,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:09,172 INFO:     Epoch: 57
2022-12-05 20:06:09,972 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4462733934210105, 'Total loss': 0.4462733934210105} | train loss {'Reaction outcome loss': 0.14515367256258785, 'Total loss': 0.14515367256258785}
2022-12-05 20:06:09,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:09,972 INFO:     Epoch: 58
2022-12-05 20:06:10,768 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4431180063296448, 'Total loss': 0.4431180063296448} | train loss {'Reaction outcome loss': 0.145055576450067, 'Total loss': 0.145055576450067}
2022-12-05 20:06:10,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:10,768 INFO:     Epoch: 59
2022-12-05 20:06:11,568 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4384511844678359, 'Total loss': 0.4384511844678359} | train loss {'Reaction outcome loss': 0.14465979713690186, 'Total loss': 0.14465979713690186}
2022-12-05 20:06:11,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:11,568 INFO:     Epoch: 60
2022-12-05 20:06:12,364 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44423676417632535, 'Total loss': 0.44423676417632535} | train loss {'Reaction outcome loss': 0.152806385491903, 'Total loss': 0.152806385491903}
2022-12-05 20:06:12,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:12,364 INFO:     Epoch: 61
2022-12-05 20:06:13,160 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45479858107864857, 'Total loss': 0.45479858107864857} | train loss {'Reaction outcome loss': 0.14696780146242908, 'Total loss': 0.14696780146242908}
2022-12-05 20:06:13,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:13,160 INFO:     Epoch: 62
2022-12-05 20:06:13,955 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4386423646726392, 'Total loss': 0.4386423646726392} | train loss {'Reaction outcome loss': 0.14146857459837126, 'Total loss': 0.14146857459837126}
2022-12-05 20:06:13,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:13,956 INFO:     Epoch: 63
2022-12-05 20:06:14,751 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44450511173768475, 'Total loss': 0.44450511173768475} | train loss {'Reaction outcome loss': 0.14085892265896324, 'Total loss': 0.14085892265896324}
2022-12-05 20:06:14,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:14,751 INFO:     Epoch: 64
2022-12-05 20:06:15,549 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4541353803466667, 'Total loss': 0.4541353803466667} | train loss {'Reaction outcome loss': 0.14374620104321706, 'Total loss': 0.14374620104321706}
2022-12-05 20:06:15,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:15,550 INFO:     Epoch: 65
2022-12-05 20:06:16,349 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44338141110810364, 'Total loss': 0.44338141110810364} | train loss {'Reaction outcome loss': 0.13810421307363852, 'Total loss': 0.13810421307363852}
2022-12-05 20:06:16,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:16,350 INFO:     Epoch: 66
2022-12-05 20:06:17,145 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4549571936103431, 'Total loss': 0.4549571936103431} | train loss {'Reaction outcome loss': 0.14030192986975315, 'Total loss': 0.14030192986975315}
2022-12-05 20:06:17,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:17,145 INFO:     Epoch: 67
2022-12-05 20:06:17,941 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4317483322864229, 'Total loss': 0.4317483322864229} | train loss {'Reaction outcome loss': 0.14274635982251, 'Total loss': 0.14274635982251}
2022-12-05 20:06:17,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:17,941 INFO:     Epoch: 68
2022-12-05 20:06:18,742 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44662243364886806, 'Total loss': 0.44662243364886806} | train loss {'Reaction outcome loss': 0.1403740071685092, 'Total loss': 0.1403740071685092}
2022-12-05 20:06:18,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:18,742 INFO:     Epoch: 69
2022-12-05 20:06:19,543 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4443760168823329, 'Total loss': 0.4443760168823329} | train loss {'Reaction outcome loss': 0.13601920501845569, 'Total loss': 0.13601920501845569}
2022-12-05 20:06:19,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:19,543 INFO:     Epoch: 70
2022-12-05 20:06:20,338 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4465005062520504, 'Total loss': 0.4465005062520504} | train loss {'Reaction outcome loss': 0.1364282613021825, 'Total loss': 0.1364282613021825}
2022-12-05 20:06:20,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:20,339 INFO:     Epoch: 71
2022-12-05 20:06:21,134 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4515645165335048, 'Total loss': 0.4515645165335048} | train loss {'Reaction outcome loss': 0.13344490981325205, 'Total loss': 0.13344490981325205}
2022-12-05 20:06:21,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:21,134 INFO:     Epoch: 72
2022-12-05 20:06:21,932 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.447873269631104, 'Total loss': 0.447873269631104} | train loss {'Reaction outcome loss': 0.1388788584257789, 'Total loss': 0.1388788584257789}
2022-12-05 20:06:21,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:21,932 INFO:     Epoch: 73
2022-12-05 20:06:22,728 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43428251231935894, 'Total loss': 0.43428251231935894} | train loss {'Reaction outcome loss': 0.13827379495150557, 'Total loss': 0.13827379495150557}
2022-12-05 20:06:22,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:22,728 INFO:     Epoch: 74
2022-12-05 20:06:23,523 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45229659432714636, 'Total loss': 0.45229659432714636} | train loss {'Reaction outcome loss': 0.13377388001151896, 'Total loss': 0.13377388001151896}
2022-12-05 20:06:23,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:23,523 INFO:     Epoch: 75
2022-12-05 20:06:24,323 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4614853289994327, 'Total loss': 0.4614853289994327} | train loss {'Reaction outcome loss': 0.1360483092316219, 'Total loss': 0.1360483092316219}
2022-12-05 20:06:24,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:24,323 INFO:     Epoch: 76
2022-12-05 20:06:25,121 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.456083380701867, 'Total loss': 0.456083380701867} | train loss {'Reaction outcome loss': 0.1299018456887167, 'Total loss': 0.1299018456887167}
2022-12-05 20:06:25,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:25,122 INFO:     Epoch: 77
2022-12-05 20:06:25,919 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44504847479137505, 'Total loss': 0.44504847479137505} | train loss {'Reaction outcome loss': 0.1332893476553774, 'Total loss': 0.1332893476553774}
2022-12-05 20:06:25,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:25,920 INFO:     Epoch: 78
2022-12-05 20:06:26,715 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45574588904326613, 'Total loss': 0.45574588904326613} | train loss {'Reaction outcome loss': 0.13346320324728683, 'Total loss': 0.13346320324728683}
2022-12-05 20:06:26,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:26,716 INFO:     Epoch: 79
2022-12-05 20:06:27,512 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42894205019216647, 'Total loss': 0.42894205019216647} | train loss {'Reaction outcome loss': 0.13314133495665514, 'Total loss': 0.13314133495665514}
2022-12-05 20:06:27,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:27,512 INFO:     Epoch: 80
2022-12-05 20:06:28,308 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4561656645753167, 'Total loss': 0.4561656645753167} | train loss {'Reaction outcome loss': 0.13575963537974156, 'Total loss': 0.13575963537974156}
2022-12-05 20:06:28,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:28,308 INFO:     Epoch: 81
2022-12-05 20:06:29,106 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4419437790797515, 'Total loss': 0.4419437790797515} | train loss {'Reaction outcome loss': 0.13330368921141844, 'Total loss': 0.13330368921141844}
2022-12-05 20:06:29,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:29,107 INFO:     Epoch: 82
2022-12-05 20:06:29,903 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4522863484241746, 'Total loss': 0.4522863484241746} | train loss {'Reaction outcome loss': 0.1293477806515298, 'Total loss': 0.1293477806515298}
2022-12-05 20:06:29,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:29,904 INFO:     Epoch: 83
2022-12-05 20:06:30,701 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43595346046442335, 'Total loss': 0.43595346046442335} | train loss {'Reaction outcome loss': 0.12944166003896096, 'Total loss': 0.12944166003896096}
2022-12-05 20:06:30,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:30,701 INFO:     Epoch: 84
2022-12-05 20:06:31,501 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45407610945403576, 'Total loss': 0.45407610945403576} | train loss {'Reaction outcome loss': 0.12834146644482727, 'Total loss': 0.12834146644482727}
2022-12-05 20:06:31,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:31,501 INFO:     Epoch: 85
2022-12-05 20:06:32,300 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.439344636333937, 'Total loss': 0.439344636333937} | train loss {'Reaction outcome loss': 0.12913354001713065, 'Total loss': 0.12913354001713065}
2022-12-05 20:06:32,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:32,300 INFO:     Epoch: 86
2022-12-05 20:06:33,098 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4538191262293946, 'Total loss': 0.4538191262293946} | train loss {'Reaction outcome loss': 0.13417484007986932, 'Total loss': 0.13417484007986932}
2022-12-05 20:06:33,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:33,099 INFO:     Epoch: 87
2022-12-05 20:06:33,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4419287856329571, 'Total loss': 0.4419287856329571} | train loss {'Reaction outcome loss': 0.12948898185866503, 'Total loss': 0.12948898185866503}
2022-12-05 20:06:33,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:33,897 INFO:     Epoch: 88
2022-12-05 20:06:34,699 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43608225970952347, 'Total loss': 0.43608225970952347} | train loss {'Reaction outcome loss': 0.13192774223254217, 'Total loss': 0.13192774223254217}
2022-12-05 20:06:34,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:34,699 INFO:     Epoch: 89
2022-12-05 20:06:35,497 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4521461102095517, 'Total loss': 0.4521461102095517} | train loss {'Reaction outcome loss': 0.12595749240715495, 'Total loss': 0.12595749240715495}
2022-12-05 20:06:35,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:35,497 INFO:     Epoch: 90
2022-12-05 20:06:36,294 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4450144784694368, 'Total loss': 0.4450144784694368} | train loss {'Reaction outcome loss': 0.12593670660886264, 'Total loss': 0.12593670660886264}
2022-12-05 20:06:36,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:36,294 INFO:     Epoch: 91
2022-12-05 20:06:37,092 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4374763477932323, 'Total loss': 0.4374763477932323} | train loss {'Reaction outcome loss': 0.12459480674156867, 'Total loss': 0.12459480674156867}
2022-12-05 20:06:37,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:37,092 INFO:     Epoch: 92
2022-12-05 20:06:37,887 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45550596866418014, 'Total loss': 0.45550596866418014} | train loss {'Reaction outcome loss': 0.12651274470812246, 'Total loss': 0.12651274470812246}
2022-12-05 20:06:37,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:37,887 INFO:     Epoch: 93
2022-12-05 20:06:38,686 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46239205314354465, 'Total loss': 0.46239205314354465} | train loss {'Reaction outcome loss': 0.1361673577699946, 'Total loss': 0.1361673577699946}
2022-12-05 20:06:38,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:38,687 INFO:     Epoch: 94
2022-12-05 20:06:39,486 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46272987364368007, 'Total loss': 0.46272987364368007} | train loss {'Reaction outcome loss': 0.125858739837825, 'Total loss': 0.125858739837825}
2022-12-05 20:06:39,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:39,486 INFO:     Epoch: 95
2022-12-05 20:06:40,282 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45861824635754933, 'Total loss': 0.45861824635754933} | train loss {'Reaction outcome loss': 0.12547470013863646, 'Total loss': 0.12547470013863646}
2022-12-05 20:06:40,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:40,283 INFO:     Epoch: 96
2022-12-05 20:06:41,080 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43873627026650036, 'Total loss': 0.43873627026650036} | train loss {'Reaction outcome loss': 0.12603006056445812, 'Total loss': 0.12603006056445812}
2022-12-05 20:06:41,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:41,080 INFO:     Epoch: 97
2022-12-05 20:06:41,875 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4595710736784068, 'Total loss': 0.4595710736784068} | train loss {'Reaction outcome loss': 0.1218999887002172, 'Total loss': 0.1218999887002172}
2022-12-05 20:06:41,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:41,875 INFO:     Epoch: 98
2022-12-05 20:06:42,671 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44811861420219595, 'Total loss': 0.44811861420219595} | train loss {'Reaction outcome loss': 0.12469285680546693, 'Total loss': 0.12469285680546693}
2022-12-05 20:06:42,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:42,671 INFO:     Epoch: 99
2022-12-05 20:06:43,471 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4529158503494479, 'Total loss': 0.4529158503494479} | train loss {'Reaction outcome loss': 0.12386739591502081, 'Total loss': 0.12386739591502081}
2022-12-05 20:06:43,471 INFO:     Best model found after epoch 17 of 100.
2022-12-05 20:06:43,471 INFO:   Done with stage: TRAINING
2022-12-05 20:06:43,471 INFO:   Starting stage: EVALUATION
2022-12-05 20:06:43,598 INFO:   Done with stage: EVALUATION
2022-12-05 20:06:43,598 INFO:   Leaving out SEQ value Fold_5
2022-12-05 20:06:43,610 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:06:43,611 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:06:44,257 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:06:44,257 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:06:44,325 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:06:44,325 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:06:44,325 INFO:     No hyperparam tuning for this model
2022-12-05 20:06:44,325 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:06:44,325 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:06:44,326 INFO:     None feature selector for col prot
2022-12-05 20:06:44,326 INFO:     None feature selector for col prot
2022-12-05 20:06:44,326 INFO:     None feature selector for col prot
2022-12-05 20:06:44,327 INFO:     None feature selector for col chem
2022-12-05 20:06:44,327 INFO:     None feature selector for col chem
2022-12-05 20:06:44,327 INFO:     None feature selector for col chem
2022-12-05 20:06:44,327 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:06:44,327 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:06:44,329 INFO:     Number of params in model 215821
2022-12-05 20:06:44,332 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:06:44,332 INFO:   Starting stage: TRAINING
2022-12-05 20:06:44,393 INFO:     Val loss before train {'Reaction outcome loss': 0.9872325171123851, 'Total loss': 0.9872325171123851}
2022-12-05 20:06:44,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:44,393 INFO:     Epoch: 0
2022-12-05 20:06:45,195 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6176452074538578, 'Total loss': 0.6176452074538578} | train loss {'Reaction outcome loss': 0.8040934974147428, 'Total loss': 0.8040934974147428}
2022-12-05 20:06:45,196 INFO:     Found new best model at epoch 0
2022-12-05 20:06:45,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:45,197 INFO:     Epoch: 1
2022-12-05 20:06:45,993 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5148841796273534, 'Total loss': 0.5148841796273534} | train loss {'Reaction outcome loss': 0.5388588850055972, 'Total loss': 0.5388588850055972}
2022-12-05 20:06:45,994 INFO:     Found new best model at epoch 1
2022-12-05 20:06:45,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:45,994 INFO:     Epoch: 2
2022-12-05 20:06:46,792 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47870172492482443, 'Total loss': 0.47870172492482443} | train loss {'Reaction outcome loss': 0.46712365848643167, 'Total loss': 0.46712365848643167}
2022-12-05 20:06:46,792 INFO:     Found new best model at epoch 2
2022-12-05 20:06:46,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:46,793 INFO:     Epoch: 3
2022-12-05 20:06:47,596 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4533121951601722, 'Total loss': 0.4533121951601722} | train loss {'Reaction outcome loss': 0.4295660899050774, 'Total loss': 0.4295660899050774}
2022-12-05 20:06:47,596 INFO:     Found new best model at epoch 3
2022-12-05 20:06:47,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:47,597 INFO:     Epoch: 4
2022-12-05 20:06:48,397 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45365260405973956, 'Total loss': 0.45365260405973956} | train loss {'Reaction outcome loss': 0.396337479893719, 'Total loss': 0.396337479893719}
2022-12-05 20:06:48,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:48,397 INFO:     Epoch: 5
2022-12-05 20:06:49,200 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44684551419182256, 'Total loss': 0.44684551419182256} | train loss {'Reaction outcome loss': 0.37229958483048026, 'Total loss': 0.37229958483048026}
2022-12-05 20:06:49,200 INFO:     Found new best model at epoch 5
2022-12-05 20:06:49,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:49,201 INFO:     Epoch: 6
2022-12-05 20:06:49,999 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4502628201788122, 'Total loss': 0.4502628201788122} | train loss {'Reaction outcome loss': 0.35456169327540743, 'Total loss': 0.35456169327540743}
2022-12-05 20:06:49,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:49,999 INFO:     Epoch: 7
2022-12-05 20:06:50,810 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4373936971480196, 'Total loss': 0.4373936971480196} | train loss {'Reaction outcome loss': 0.33499022537181455, 'Total loss': 0.33499022537181455}
2022-12-05 20:06:50,810 INFO:     Found new best model at epoch 7
2022-12-05 20:06:50,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:50,811 INFO:     Epoch: 8
2022-12-05 20:06:51,627 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43031133846803143, 'Total loss': 0.43031133846803143} | train loss {'Reaction outcome loss': 0.3200351941970087, 'Total loss': 0.3200351941970087}
2022-12-05 20:06:51,627 INFO:     Found new best model at epoch 8
2022-12-05 20:06:51,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:51,628 INFO:     Epoch: 9
2022-12-05 20:06:52,448 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41923501511866396, 'Total loss': 0.41923501511866396} | train loss {'Reaction outcome loss': 0.3067133442288445, 'Total loss': 0.3067133442288445}
2022-12-05 20:06:52,448 INFO:     Found new best model at epoch 9
2022-12-05 20:06:52,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:52,449 INFO:     Epoch: 10
2022-12-05 20:06:53,267 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41985371336340904, 'Total loss': 0.41985371336340904} | train loss {'Reaction outcome loss': 0.29582412978033384, 'Total loss': 0.29582412978033384}
2022-12-05 20:06:53,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:53,267 INFO:     Epoch: 11
2022-12-05 20:06:54,081 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.425315030596473, 'Total loss': 0.425315030596473} | train loss {'Reaction outcome loss': 0.28332516659171353, 'Total loss': 0.28332516659171353}
2022-12-05 20:06:54,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:54,082 INFO:     Epoch: 12
2022-12-05 20:06:54,896 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4163831753486937, 'Total loss': 0.4163831753486937} | train loss {'Reaction outcome loss': 0.27036552362504507, 'Total loss': 0.27036552362504507}
2022-12-05 20:06:54,896 INFO:     Found new best model at epoch 12
2022-12-05 20:06:54,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:54,897 INFO:     Epoch: 13
2022-12-05 20:06:55,712 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4122447087006135, 'Total loss': 0.4122447087006135} | train loss {'Reaction outcome loss': 0.26254605643841766, 'Total loss': 0.26254605643841766}
2022-12-05 20:06:55,712 INFO:     Found new best model at epoch 13
2022-12-05 20:06:55,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:55,713 INFO:     Epoch: 14
2022-12-05 20:06:56,522 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4093330621042035, 'Total loss': 0.4093330621042035} | train loss {'Reaction outcome loss': 0.254581491853441, 'Total loss': 0.254581491853441}
2022-12-05 20:06:56,523 INFO:     Found new best model at epoch 14
2022-12-05 20:06:56,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:56,523 INFO:     Epoch: 15
2022-12-05 20:06:57,315 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4080061824484305, 'Total loss': 0.4080061824484305} | train loss {'Reaction outcome loss': 0.24919490795582533, 'Total loss': 0.24919490795582533}
2022-12-05 20:06:57,316 INFO:     Found new best model at epoch 15
2022-12-05 20:06:57,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:57,317 INFO:     Epoch: 16
2022-12-05 20:06:58,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41299513083967293, 'Total loss': 0.41299513083967293} | train loss {'Reaction outcome loss': 0.2398653598352065, 'Total loss': 0.2398653598352065}
2022-12-05 20:06:58,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:58,111 INFO:     Epoch: 17
2022-12-05 20:06:58,901 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41868373345245014, 'Total loss': 0.41868373345245014} | train loss {'Reaction outcome loss': 0.23384921837057318, 'Total loss': 0.23384921837057318}
2022-12-05 20:06:58,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:58,902 INFO:     Epoch: 18
2022-12-05 20:06:59,694 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.410781094296412, 'Total loss': 0.410781094296412} | train loss {'Reaction outcome loss': 0.2284860865573489, 'Total loss': 0.2284860865573489}
2022-12-05 20:06:59,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:06:59,694 INFO:     Epoch: 19
2022-12-05 20:07:00,489 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4129000087691979, 'Total loss': 0.4129000087691979} | train loss {'Reaction outcome loss': 0.2216185757499789, 'Total loss': 0.2216185757499789}
2022-12-05 20:07:00,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:00,489 INFO:     Epoch: 20
2022-12-05 20:07:01,281 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41179882125421, 'Total loss': 0.41179882125421} | train loss {'Reaction outcome loss': 0.21822682970894441, 'Total loss': 0.21822682970894441}
2022-12-05 20:07:01,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:01,282 INFO:     Epoch: 21
2022-12-05 20:07:02,072 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4146924997595223, 'Total loss': 0.4146924997595223} | train loss {'Reaction outcome loss': 0.21279542932226772, 'Total loss': 0.21279542932226772}
2022-12-05 20:07:02,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:02,073 INFO:     Epoch: 22
2022-12-05 20:07:02,864 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40994804284789343, 'Total loss': 0.40994804284789343} | train loss {'Reaction outcome loss': 0.20850252591434024, 'Total loss': 0.20850252591434024}
2022-12-05 20:07:02,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:02,864 INFO:     Epoch: 23
2022-12-05 20:07:03,660 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40717929415404797, 'Total loss': 0.40717929415404797} | train loss {'Reaction outcome loss': 0.20626049654017534, 'Total loss': 0.20626049654017534}
2022-12-05 20:07:03,660 INFO:     Found new best model at epoch 23
2022-12-05 20:07:03,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:03,661 INFO:     Epoch: 24
2022-12-05 20:07:04,457 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39818677644837985, 'Total loss': 0.39818677644837985} | train loss {'Reaction outcome loss': 0.20185811096622097, 'Total loss': 0.20185811096622097}
2022-12-05 20:07:04,457 INFO:     Found new best model at epoch 24
2022-12-05 20:07:04,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:04,458 INFO:     Epoch: 25
2022-12-05 20:07:05,255 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41556386243213306, 'Total loss': 0.41556386243213306} | train loss {'Reaction outcome loss': 0.19721600308173126, 'Total loss': 0.19721600308173126}
2022-12-05 20:07:05,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:05,255 INFO:     Epoch: 26
2022-12-05 20:07:06,046 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41200625557791104, 'Total loss': 0.41200625557791104} | train loss {'Reaction outcome loss': 0.19304640976441723, 'Total loss': 0.19304640976441723}
2022-12-05 20:07:06,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:06,047 INFO:     Epoch: 27
2022-12-05 20:07:06,838 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43445401012220164, 'Total loss': 0.43445401012220164} | train loss {'Reaction outcome loss': 0.1881313424767746, 'Total loss': 0.1881313424767746}
2022-12-05 20:07:06,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:06,839 INFO:     Epoch: 28
2022-12-05 20:07:07,634 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4214684848080982, 'Total loss': 0.4214684848080982} | train loss {'Reaction outcome loss': 0.18579934418742214, 'Total loss': 0.18579934418742214}
2022-12-05 20:07:07,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:07,634 INFO:     Epoch: 29
2022-12-05 20:07:08,426 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41350842148742895, 'Total loss': 0.41350842148742895} | train loss {'Reaction outcome loss': 0.18092860182326648, 'Total loss': 0.18092860182326648}
2022-12-05 20:07:08,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:08,426 INFO:     Epoch: 30
2022-12-05 20:07:09,219 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4261924070729451, 'Total loss': 0.4261924070729451} | train loss {'Reaction outcome loss': 0.180303497315054, 'Total loss': 0.180303497315054}
2022-12-05 20:07:09,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:09,219 INFO:     Epoch: 31
2022-12-05 20:07:10,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41920618001710286, 'Total loss': 0.41920618001710286} | train loss {'Reaction outcome loss': 0.17857863904247362, 'Total loss': 0.17857863904247362}
2022-12-05 20:07:10,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:10,017 INFO:     Epoch: 32
2022-12-05 20:07:10,815 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4153849655254321, 'Total loss': 0.4153849655254321} | train loss {'Reaction outcome loss': 0.17464227456178877, 'Total loss': 0.17464227456178877}
2022-12-05 20:07:10,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:10,816 INFO:     Epoch: 33
2022-12-05 20:07:11,613 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41942314041609113, 'Total loss': 0.41942314041609113} | train loss {'Reaction outcome loss': 0.17420218126367656, 'Total loss': 0.17420218126367656}
2022-12-05 20:07:11,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:11,613 INFO:     Epoch: 34
2022-12-05 20:07:12,408 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41694255342537706, 'Total loss': 0.41694255342537706} | train loss {'Reaction outcome loss': 0.16851691022935894, 'Total loss': 0.16851691022935894}
2022-12-05 20:07:12,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:12,408 INFO:     Epoch: 35
2022-12-05 20:07:13,204 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4226466260681098, 'Total loss': 0.4226466260681098} | train loss {'Reaction outcome loss': 0.17038556098216964, 'Total loss': 0.17038556098216964}
2022-12-05 20:07:13,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:13,205 INFO:     Epoch: 36
2022-12-05 20:07:14,003 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4304677180268548, 'Total loss': 0.4304677180268548} | train loss {'Reaction outcome loss': 0.16718572731159867, 'Total loss': 0.16718572731159867}
2022-12-05 20:07:14,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:14,003 INFO:     Epoch: 37
2022-12-05 20:07:14,796 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4211327970366586, 'Total loss': 0.4211327970366586} | train loss {'Reaction outcome loss': 0.16735557252691396, 'Total loss': 0.16735557252691396}
2022-12-05 20:07:14,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:14,796 INFO:     Epoch: 38
2022-12-05 20:07:15,592 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4112449806522239, 'Total loss': 0.4112449806522239} | train loss {'Reaction outcome loss': 0.16329418230170925, 'Total loss': 0.16329418230170925}
2022-12-05 20:07:15,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:15,592 INFO:     Epoch: 39
2022-12-05 20:07:16,385 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41775666727599775, 'Total loss': 0.41775666727599775} | train loss {'Reaction outcome loss': 0.16182207731500028, 'Total loss': 0.16182207731500028}
2022-12-05 20:07:16,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:16,386 INFO:     Epoch: 40
2022-12-05 20:07:17,178 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41982329365882004, 'Total loss': 0.41982329365882004} | train loss {'Reaction outcome loss': 0.16172424694823642, 'Total loss': 0.16172424694823642}
2022-12-05 20:07:17,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:17,178 INFO:     Epoch: 41
2022-12-05 20:07:17,971 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4123088632794944, 'Total loss': 0.4123088632794944} | train loss {'Reaction outcome loss': 0.15858534585324027, 'Total loss': 0.15858534585324027}
2022-12-05 20:07:17,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:17,971 INFO:     Epoch: 42
2022-12-05 20:07:18,765 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4367193312130191, 'Total loss': 0.4367193312130191} | train loss {'Reaction outcome loss': 0.15287924105031114, 'Total loss': 0.15287924105031114}
2022-12-05 20:07:18,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:18,765 INFO:     Epoch: 43
2022-12-05 20:07:19,558 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4262348845262419, 'Total loss': 0.4262348845262419} | train loss {'Reaction outcome loss': 0.154042242643153, 'Total loss': 0.154042242643153}
2022-12-05 20:07:19,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:19,558 INFO:     Epoch: 44
2022-12-05 20:07:20,353 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42100970074534416, 'Total loss': 0.42100970074534416} | train loss {'Reaction outcome loss': 0.15448866106359468, 'Total loss': 0.15448866106359468}
2022-12-05 20:07:20,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:20,353 INFO:     Epoch: 45
2022-12-05 20:07:21,154 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4144779872149229, 'Total loss': 0.4144779872149229} | train loss {'Reaction outcome loss': 0.1505535603425796, 'Total loss': 0.1505535603425796}
2022-12-05 20:07:21,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:21,154 INFO:     Epoch: 46
2022-12-05 20:07:21,952 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44114611704241147, 'Total loss': 0.44114611704241147} | train loss {'Reaction outcome loss': 0.15384234750883713, 'Total loss': 0.15384234750883713}
2022-12-05 20:07:21,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:21,952 INFO:     Epoch: 47
2022-12-05 20:07:22,746 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4294566391882571, 'Total loss': 0.4294566391882571} | train loss {'Reaction outcome loss': 0.15071430013725354, 'Total loss': 0.15071430013725354}
2022-12-05 20:07:22,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:22,746 INFO:     Epoch: 48
2022-12-05 20:07:23,543 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4276817545972087, 'Total loss': 0.4276817545972087} | train loss {'Reaction outcome loss': 0.14758522143857855, 'Total loss': 0.14758522143857855}
2022-12-05 20:07:23,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:23,543 INFO:     Epoch: 49
2022-12-05 20:07:24,342 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4300256544216113, 'Total loss': 0.4300256544216113} | train loss {'Reaction outcome loss': 0.14660230819736758, 'Total loss': 0.14660230819736758}
2022-12-05 20:07:24,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:24,342 INFO:     Epoch: 50
2022-12-05 20:07:25,138 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4270413114943288, 'Total loss': 0.4270413114943288} | train loss {'Reaction outcome loss': 0.1473014240243262, 'Total loss': 0.1473014240243262}
2022-12-05 20:07:25,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:25,138 INFO:     Epoch: 51
2022-12-05 20:07:25,932 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4334935468028892, 'Total loss': 0.4334935468028892} | train loss {'Reaction outcome loss': 0.14367299480363727, 'Total loss': 0.14367299480363727}
2022-12-05 20:07:25,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:25,932 INFO:     Epoch: 52
2022-12-05 20:07:26,730 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43115585669875145, 'Total loss': 0.43115585669875145} | train loss {'Reaction outcome loss': 0.1435408085592151, 'Total loss': 0.1435408085592151}
2022-12-05 20:07:26,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:26,730 INFO:     Epoch: 53
2022-12-05 20:07:27,528 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.422173746438189, 'Total loss': 0.422173746438189} | train loss {'Reaction outcome loss': 0.14469686086710182, 'Total loss': 0.14469686086710182}
2022-12-05 20:07:27,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:27,529 INFO:     Epoch: 54
2022-12-05 20:07:28,327 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42699953473427077, 'Total loss': 0.42699953473427077} | train loss {'Reaction outcome loss': 0.1431150536293224, 'Total loss': 0.1431150536293224}
2022-12-05 20:07:28,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:28,327 INFO:     Epoch: 55
2022-12-05 20:07:29,121 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4219528775323521, 'Total loss': 0.4219528775323521} | train loss {'Reaction outcome loss': 0.1410071426484313, 'Total loss': 0.1410071426484313}
2022-12-05 20:07:29,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:29,122 INFO:     Epoch: 56
2022-12-05 20:07:29,920 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42829198559576814, 'Total loss': 0.42829198559576814} | train loss {'Reaction outcome loss': 0.1413892730582325, 'Total loss': 0.1413892730582325}
2022-12-05 20:07:29,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:29,920 INFO:     Epoch: 57
2022-12-05 20:07:30,716 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4096535048024221, 'Total loss': 0.4096535048024221} | train loss {'Reaction outcome loss': 0.1397155955914528, 'Total loss': 0.1397155955914528}
2022-12-05 20:07:30,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:30,717 INFO:     Epoch: 58
2022-12-05 20:07:31,511 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42178181863643904, 'Total loss': 0.42178181863643904} | train loss {'Reaction outcome loss': 0.13819917268870818, 'Total loss': 0.13819917268870818}
2022-12-05 20:07:31,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:31,511 INFO:     Epoch: 59
2022-12-05 20:07:32,308 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44144549627195706, 'Total loss': 0.44144549627195706} | train loss {'Reaction outcome loss': 0.13762416792733054, 'Total loss': 0.13762416792733054}
2022-12-05 20:07:32,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:32,308 INFO:     Epoch: 60
2022-12-05 20:07:33,109 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4269699850542979, 'Total loss': 0.4269699850542979} | train loss {'Reaction outcome loss': 0.13817568109821407, 'Total loss': 0.13817568109821407}
2022-12-05 20:07:33,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:33,109 INFO:     Epoch: 61
2022-12-05 20:07:33,909 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42413588105277583, 'Total loss': 0.42413588105277583} | train loss {'Reaction outcome loss': 0.13620127329692966, 'Total loss': 0.13620127329692966}
2022-12-05 20:07:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:33,909 INFO:     Epoch: 62
2022-12-05 20:07:34,708 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4219779409468174, 'Total loss': 0.4219779409468174} | train loss {'Reaction outcome loss': 0.13604723294866422, 'Total loss': 0.13604723294866422}
2022-12-05 20:07:34,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:34,708 INFO:     Epoch: 63
2022-12-05 20:07:35,508 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4231132597408511, 'Total loss': 0.4231132597408511} | train loss {'Reaction outcome loss': 0.1366844453563493, 'Total loss': 0.1366844453563493}
2022-12-05 20:07:35,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:35,508 INFO:     Epoch: 64
2022-12-05 20:07:36,304 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4354722774164243, 'Total loss': 0.4354722774164243} | train loss {'Reaction outcome loss': 0.1358727008900455, 'Total loss': 0.1358727008900455}
2022-12-05 20:07:36,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:36,304 INFO:     Epoch: 65
2022-12-05 20:07:37,102 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43221044658937235, 'Total loss': 0.43221044658937235} | train loss {'Reaction outcome loss': 0.13335863907723838, 'Total loss': 0.13335863907723838}
2022-12-05 20:07:37,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:37,102 INFO:     Epoch: 66
2022-12-05 20:07:37,897 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42618672448125755, 'Total loss': 0.42618672448125755} | train loss {'Reaction outcome loss': 0.13221481423674813, 'Total loss': 0.13221481423674813}
2022-12-05 20:07:37,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:37,897 INFO:     Epoch: 67
2022-12-05 20:07:38,690 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43305007910186594, 'Total loss': 0.43305007910186594} | train loss {'Reaction outcome loss': 0.1310972708104659, 'Total loss': 0.1310972708104659}
2022-12-05 20:07:38,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:38,690 INFO:     Epoch: 68
2022-12-05 20:07:39,489 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43832280012694275, 'Total loss': 0.43832280012694275} | train loss {'Reaction outcome loss': 0.1313340305801361, 'Total loss': 0.1313340305801361}
2022-12-05 20:07:39,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:39,490 INFO:     Epoch: 69
2022-12-05 20:07:40,289 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43216514451937244, 'Total loss': 0.43216514451937244} | train loss {'Reaction outcome loss': 0.13230451734195794, 'Total loss': 0.13230451734195794}
2022-12-05 20:07:40,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:40,289 INFO:     Epoch: 70
2022-12-05 20:07:41,093 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.439847778190266, 'Total loss': 0.439847778190266} | train loss {'Reaction outcome loss': 0.13030334149727657, 'Total loss': 0.13030334149727657}
2022-12-05 20:07:41,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:41,095 INFO:     Epoch: 71
2022-12-05 20:07:41,903 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4354495939544656, 'Total loss': 0.4354495939544656} | train loss {'Reaction outcome loss': 0.12991485929101584, 'Total loss': 0.12991485929101584}
2022-12-05 20:07:41,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:41,903 INFO:     Epoch: 72
2022-12-05 20:07:42,710 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4360931337895719, 'Total loss': 0.4360931337895719} | train loss {'Reaction outcome loss': 0.12865178755319287, 'Total loss': 0.12865178755319287}
2022-12-05 20:07:42,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:42,710 INFO:     Epoch: 73
2022-12-05 20:07:43,511 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4291733848777684, 'Total loss': 0.4291733848777684} | train loss {'Reaction outcome loss': 0.12871349856798206, 'Total loss': 0.12871349856798206}
2022-12-05 20:07:43,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:43,511 INFO:     Epoch: 74
2022-12-05 20:07:44,311 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43405037170106714, 'Total loss': 0.43405037170106714} | train loss {'Reaction outcome loss': 0.12753728432430617, 'Total loss': 0.12753728432430617}
2022-12-05 20:07:44,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:44,311 INFO:     Epoch: 75
2022-12-05 20:07:45,112 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42669927718287165, 'Total loss': 0.42669927718287165} | train loss {'Reaction outcome loss': 0.12864299646518643, 'Total loss': 0.12864299646518643}
2022-12-05 20:07:45,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:45,112 INFO:     Epoch: 76
2022-12-05 20:07:45,915 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.446413727985187, 'Total loss': 0.446413727985187} | train loss {'Reaction outcome loss': 0.1250444597286743, 'Total loss': 0.1250444597286743}
2022-12-05 20:07:45,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:45,915 INFO:     Epoch: 77
2022-12-05 20:07:46,717 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4428615492175926, 'Total loss': 0.4428615492175926} | train loss {'Reaction outcome loss': 0.12633669421437285, 'Total loss': 0.12633669421437285}
2022-12-05 20:07:46,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:46,717 INFO:     Epoch: 78
2022-12-05 20:07:47,519 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42786945250223984, 'Total loss': 0.42786945250223984} | train loss {'Reaction outcome loss': 0.1267295319121331, 'Total loss': 0.1267295319121331}
2022-12-05 20:07:47,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:47,520 INFO:     Epoch: 79
2022-12-05 20:07:48,327 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4337697022340514, 'Total loss': 0.4337697022340514} | train loss {'Reaction outcome loss': 0.12438168567455103, 'Total loss': 0.12438168567455103}
2022-12-05 20:07:48,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:48,328 INFO:     Epoch: 80
2022-12-05 20:07:49,139 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42445515824312513, 'Total loss': 0.42445515824312513} | train loss {'Reaction outcome loss': 0.12459441094524076, 'Total loss': 0.12459441094524076}
2022-12-05 20:07:49,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:49,139 INFO:     Epoch: 81
2022-12-05 20:07:49,950 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.436357662759044, 'Total loss': 0.436357662759044} | train loss {'Reaction outcome loss': 0.1246094958023018, 'Total loss': 0.1246094958023018}
2022-12-05 20:07:49,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:49,951 INFO:     Epoch: 82
2022-12-05 20:07:50,759 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4399992217394439, 'Total loss': 0.4399992217394439} | train loss {'Reaction outcome loss': 0.12384153242718669, 'Total loss': 0.12384153242718669}
2022-12-05 20:07:50,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:50,759 INFO:     Epoch: 83
2022-12-05 20:07:51,567 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42436827516013925, 'Total loss': 0.42436827516013925} | train loss {'Reaction outcome loss': 0.12214775992775216, 'Total loss': 0.12214775992775216}
2022-12-05 20:07:51,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:51,567 INFO:     Epoch: 84
2022-12-05 20:07:52,371 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41917677426880057, 'Total loss': 0.41917677426880057} | train loss {'Reaction outcome loss': 0.12436311039885867, 'Total loss': 0.12436311039885867}
2022-12-05 20:07:52,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:52,371 INFO:     Epoch: 85
2022-12-05 20:07:53,176 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.435011702505025, 'Total loss': 0.435011702505025} | train loss {'Reaction outcome loss': 0.12119939347218361, 'Total loss': 0.12119939347218361}
2022-12-05 20:07:53,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:53,176 INFO:     Epoch: 86
2022-12-05 20:07:53,981 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4375813271511685, 'Total loss': 0.4375813271511685} | train loss {'Reaction outcome loss': 0.12252124764716192, 'Total loss': 0.12252124764716192}
2022-12-05 20:07:53,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:53,982 INFO:     Epoch: 87
2022-12-05 20:07:54,780 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43436863442713564, 'Total loss': 0.43436863442713564} | train loss {'Reaction outcome loss': 0.11952443035026532, 'Total loss': 0.11952443035026532}
2022-12-05 20:07:54,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:54,780 INFO:     Epoch: 88
2022-12-05 20:07:55,580 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4379105716943741, 'Total loss': 0.4379105716943741} | train loss {'Reaction outcome loss': 0.1224545564280913, 'Total loss': 0.1224545564280913}
2022-12-05 20:07:55,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:55,580 INFO:     Epoch: 89
2022-12-05 20:07:56,377 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43508912284265866, 'Total loss': 0.43508912284265866} | train loss {'Reaction outcome loss': 0.12151612362433825, 'Total loss': 0.12151612362433825}
2022-12-05 20:07:56,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:56,377 INFO:     Epoch: 90
2022-12-05 20:07:57,174 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4373834783380682, 'Total loss': 0.4373834783380682} | train loss {'Reaction outcome loss': 0.12654834987235167, 'Total loss': 0.12654834987235167}
2022-12-05 20:07:57,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:57,174 INFO:     Epoch: 91
2022-12-05 20:07:57,982 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43256738273934886, 'Total loss': 0.43256738273934886} | train loss {'Reaction outcome loss': 0.12022099462563111, 'Total loss': 0.12022099462563111}
2022-12-05 20:07:57,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:57,982 INFO:     Epoch: 92
2022-12-05 20:07:58,785 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43287130343643104, 'Total loss': 0.43287130343643104} | train loss {'Reaction outcome loss': 0.12109791555051361, 'Total loss': 0.12109791555051361}
2022-12-05 20:07:58,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:58,785 INFO:     Epoch: 93
2022-12-05 20:07:59,586 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4363118474456397, 'Total loss': 0.4363118474456397} | train loss {'Reaction outcome loss': 0.11981916251487189, 'Total loss': 0.11981916251487189}
2022-12-05 20:07:59,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:07:59,587 INFO:     Epoch: 94
2022-12-05 20:08:00,389 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42603110894560814, 'Total loss': 0.42603110894560814} | train loss {'Reaction outcome loss': 0.1214683188891579, 'Total loss': 0.1214683188891579}
2022-12-05 20:08:00,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:00,389 INFO:     Epoch: 95
2022-12-05 20:08:01,197 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4380878245627338, 'Total loss': 0.4380878245627338} | train loss {'Reaction outcome loss': 0.11881012845157285, 'Total loss': 0.11881012845157285}
2022-12-05 20:08:01,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:01,197 INFO:     Epoch: 96
2022-12-05 20:08:01,999 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43153983405367896, 'Total loss': 0.43153983405367896} | train loss {'Reaction outcome loss': 0.11656851449140138, 'Total loss': 0.11656851449140138}
2022-12-05 20:08:01,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:01,999 INFO:     Epoch: 97
2022-12-05 20:08:02,802 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42958524552258576, 'Total loss': 0.42958524552258576} | train loss {'Reaction outcome loss': 0.11633139611747596, 'Total loss': 0.11633139611747596}
2022-12-05 20:08:02,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:02,802 INFO:     Epoch: 98
2022-12-05 20:08:03,604 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4363264140080322, 'Total loss': 0.4363264140080322} | train loss {'Reaction outcome loss': 0.11800191429774126, 'Total loss': 0.11800191429774126}
2022-12-05 20:08:03,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:03,604 INFO:     Epoch: 99
2022-12-05 20:08:04,409 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4293213794854554, 'Total loss': 0.4293213794854554} | train loss {'Reaction outcome loss': 0.11923707421350803, 'Total loss': 0.11923707421350803}
2022-12-05 20:08:04,409 INFO:     Best model found after epoch 25 of 100.
2022-12-05 20:08:04,409 INFO:   Done with stage: TRAINING
2022-12-05 20:08:04,409 INFO:   Starting stage: EVALUATION
2022-12-05 20:08:04,530 INFO:   Done with stage: EVALUATION
2022-12-05 20:08:04,530 INFO:   Leaving out SEQ value Fold_6
2022-12-05 20:08:04,543 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:08:04,543 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:08:05,190 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:08:05,190 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:08:05,258 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:08:05,258 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:08:05,258 INFO:     No hyperparam tuning for this model
2022-12-05 20:08:05,258 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:08:05,258 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:08:05,259 INFO:     None feature selector for col prot
2022-12-05 20:08:05,259 INFO:     None feature selector for col prot
2022-12-05 20:08:05,259 INFO:     None feature selector for col prot
2022-12-05 20:08:05,260 INFO:     None feature selector for col chem
2022-12-05 20:08:05,260 INFO:     None feature selector for col chem
2022-12-05 20:08:05,260 INFO:     None feature selector for col chem
2022-12-05 20:08:05,260 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:08:05,260 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:08:05,261 INFO:     Number of params in model 215821
2022-12-05 20:08:05,265 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:08:05,265 INFO:   Starting stage: TRAINING
2022-12-05 20:08:05,326 INFO:     Val loss before train {'Reaction outcome loss': 1.0070689117366618, 'Total loss': 1.0070689117366618}
2022-12-05 20:08:05,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:05,326 INFO:     Epoch: 0
2022-12-05 20:08:06,130 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6098755293271758, 'Total loss': 0.6098755293271758} | train loss {'Reaction outcome loss': 0.8039102404706391, 'Total loss': 0.8039102404706391}
2022-12-05 20:08:06,130 INFO:     Found new best model at epoch 0
2022-12-05 20:08:06,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:06,131 INFO:     Epoch: 1
2022-12-05 20:08:06,933 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5152481963688677, 'Total loss': 0.5152481963688677} | train loss {'Reaction outcome loss': 0.5442697733399356, 'Total loss': 0.5442697733399356}
2022-12-05 20:08:06,933 INFO:     Found new best model at epoch 1
2022-12-05 20:08:06,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:06,934 INFO:     Epoch: 2
2022-12-05 20:08:07,745 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4777092459526929, 'Total loss': 0.4777092459526929} | train loss {'Reaction outcome loss': 0.4670078415981671, 'Total loss': 0.4670078415981671}
2022-12-05 20:08:07,746 INFO:     Found new best model at epoch 2
2022-12-05 20:08:07,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:07,746 INFO:     Epoch: 3
2022-12-05 20:08:08,554 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4541581469503316, 'Total loss': 0.4541581469503316} | train loss {'Reaction outcome loss': 0.42283523342146084, 'Total loss': 0.42283523342146084}
2022-12-05 20:08:08,554 INFO:     Found new best model at epoch 3
2022-12-05 20:08:08,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:08,555 INFO:     Epoch: 4
2022-12-05 20:08:09,357 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43550569293173874, 'Total loss': 0.43550569293173874} | train loss {'Reaction outcome loss': 0.39867694235523704, 'Total loss': 0.39867694235523704}
2022-12-05 20:08:09,357 INFO:     Found new best model at epoch 4
2022-12-05 20:08:09,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:09,358 INFO:     Epoch: 5
2022-12-05 20:08:10,161 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4286827363751151, 'Total loss': 0.4286827363751151} | train loss {'Reaction outcome loss': 0.3715531802792781, 'Total loss': 0.3715531802792781}
2022-12-05 20:08:10,161 INFO:     Found new best model at epoch 5
2022-12-05 20:08:10,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:10,162 INFO:     Epoch: 6
2022-12-05 20:08:10,962 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4245066527615894, 'Total loss': 0.4245066527615894} | train loss {'Reaction outcome loss': 0.35277143660706545, 'Total loss': 0.35277143660706545}
2022-12-05 20:08:10,962 INFO:     Found new best model at epoch 6
2022-12-05 20:08:10,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:10,963 INFO:     Epoch: 7
2022-12-05 20:08:11,759 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4183111343194138, 'Total loss': 0.4183111343194138} | train loss {'Reaction outcome loss': 0.335648623615624, 'Total loss': 0.335648623615624}
2022-12-05 20:08:11,760 INFO:     Found new best model at epoch 7
2022-12-05 20:08:11,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:11,761 INFO:     Epoch: 8
2022-12-05 20:08:12,562 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40675549158318475, 'Total loss': 0.40675549158318475} | train loss {'Reaction outcome loss': 0.3233040553415835, 'Total loss': 0.3233040553415835}
2022-12-05 20:08:12,562 INFO:     Found new best model at epoch 8
2022-12-05 20:08:12,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:12,563 INFO:     Epoch: 9
2022-12-05 20:08:13,376 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40805111740800465, 'Total loss': 0.40805111740800465} | train loss {'Reaction outcome loss': 0.306645567736283, 'Total loss': 0.306645567736283}
2022-12-05 20:08:13,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:13,377 INFO:     Epoch: 10
2022-12-05 20:08:14,184 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39802756905555725, 'Total loss': 0.39802756905555725} | train loss {'Reaction outcome loss': 0.29563915518372647, 'Total loss': 0.29563915518372647}
2022-12-05 20:08:14,184 INFO:     Found new best model at epoch 10
2022-12-05 20:08:14,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:14,185 INFO:     Epoch: 11
2022-12-05 20:08:14,996 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39514908533204685, 'Total loss': 0.39514908533204685} | train loss {'Reaction outcome loss': 0.2957839284710556, 'Total loss': 0.2957839284710556}
2022-12-05 20:08:14,996 INFO:     Found new best model at epoch 11
2022-12-05 20:08:14,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:14,997 INFO:     Epoch: 12
2022-12-05 20:08:15,801 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3873364617201415, 'Total loss': 0.3873364617201415} | train loss {'Reaction outcome loss': 0.27325079671525765, 'Total loss': 0.27325079671525765}
2022-12-05 20:08:15,801 INFO:     Found new best model at epoch 12
2022-12-05 20:08:15,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:15,802 INFO:     Epoch: 13
2022-12-05 20:08:16,617 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3860204942863096, 'Total loss': 0.3860204942863096} | train loss {'Reaction outcome loss': 0.26447235257836127, 'Total loss': 0.26447235257836127}
2022-12-05 20:08:16,617 INFO:     Found new best model at epoch 13
2022-12-05 20:08:16,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:16,618 INFO:     Epoch: 14
2022-12-05 20:08:17,425 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38633859039030294, 'Total loss': 0.38633859039030294} | train loss {'Reaction outcome loss': 0.2548535109614493, 'Total loss': 0.2548535109614493}
2022-12-05 20:08:17,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:17,425 INFO:     Epoch: 15
2022-12-05 20:08:18,239 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39644602279771457, 'Total loss': 0.39644602279771457} | train loss {'Reaction outcome loss': 0.24662967944736422, 'Total loss': 0.24662967944736422}
2022-12-05 20:08:18,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:18,240 INFO:     Epoch: 16
2022-12-05 20:08:19,052 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38567834940146317, 'Total loss': 0.38567834940146317} | train loss {'Reaction outcome loss': 0.23908370674440735, 'Total loss': 0.23908370674440735}
2022-12-05 20:08:19,052 INFO:     Found new best model at epoch 16
2022-12-05 20:08:19,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:19,053 INFO:     Epoch: 17
2022-12-05 20:08:19,856 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40160284733230417, 'Total loss': 0.40160284733230417} | train loss {'Reaction outcome loss': 0.23447627635665147, 'Total loss': 0.23447627635665147}
2022-12-05 20:08:19,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:19,857 INFO:     Epoch: 18
2022-12-05 20:08:20,664 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38748332096094434, 'Total loss': 0.38748332096094434} | train loss {'Reaction outcome loss': 0.22219721715791746, 'Total loss': 0.22219721715791746}
2022-12-05 20:08:20,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:20,665 INFO:     Epoch: 19
2022-12-05 20:08:21,468 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3983181698078459, 'Total loss': 0.3983181698078459} | train loss {'Reaction outcome loss': 0.21795379304089527, 'Total loss': 0.21795379304089527}
2022-12-05 20:08:21,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:21,468 INFO:     Epoch: 20
2022-12-05 20:08:22,275 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3986901796676896, 'Total loss': 0.3986901796676896} | train loss {'Reaction outcome loss': 0.21362088852927752, 'Total loss': 0.21362088852927752}
2022-12-05 20:08:22,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:22,275 INFO:     Epoch: 21
2022-12-05 20:08:23,080 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4062167519534176, 'Total loss': 0.4062167519534176} | train loss {'Reaction outcome loss': 0.20994937451563866, 'Total loss': 0.20994937451563866}
2022-12-05 20:08:23,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:23,080 INFO:     Epoch: 22
2022-12-05 20:08:23,893 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.395063922486522, 'Total loss': 0.395063922486522} | train loss {'Reaction outcome loss': 0.20532036166985027, 'Total loss': 0.20532036166985027}
2022-12-05 20:08:23,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:23,893 INFO:     Epoch: 23
2022-12-05 20:08:24,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4133932390673594, 'Total loss': 0.4133932390673594} | train loss {'Reaction outcome loss': 0.20070819695468856, 'Total loss': 0.20070819695468856}
2022-12-05 20:08:24,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:24,697 INFO:     Epoch: 24
2022-12-05 20:08:25,503 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39657158675518905, 'Total loss': 0.39657158675518905} | train loss {'Reaction outcome loss': 0.19543515702498407, 'Total loss': 0.19543515702498407}
2022-12-05 20:08:25,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:25,503 INFO:     Epoch: 25
2022-12-05 20:08:26,305 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3998578449880535, 'Total loss': 0.3998578449880535} | train loss {'Reaction outcome loss': 0.1966375858496558, 'Total loss': 0.1966375858496558}
2022-12-05 20:08:26,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:26,305 INFO:     Epoch: 26
2022-12-05 20:08:27,107 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39817174134606664, 'Total loss': 0.39817174134606664} | train loss {'Reaction outcome loss': 0.18731414999337753, 'Total loss': 0.18731414999337753}
2022-12-05 20:08:27,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:27,107 INFO:     Epoch: 27
2022-12-05 20:08:27,912 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.404613719406453, 'Total loss': 0.404613719406453} | train loss {'Reaction outcome loss': 0.18343014211623895, 'Total loss': 0.18343014211623895}
2022-12-05 20:08:27,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:27,912 INFO:     Epoch: 28
2022-12-05 20:08:28,718 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3883080683987249, 'Total loss': 0.3883080683987249} | train loss {'Reaction outcome loss': 0.17856377733471665, 'Total loss': 0.17856377733471665}
2022-12-05 20:08:28,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:28,718 INFO:     Epoch: 29
2022-12-05 20:08:29,514 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3983405889435248, 'Total loss': 0.3983405889435248} | train loss {'Reaction outcome loss': 0.1799994310145436, 'Total loss': 0.1799994310145436}
2022-12-05 20:08:29,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:29,515 INFO:     Epoch: 30
2022-12-05 20:08:30,318 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4017327028242024, 'Total loss': 0.4017327028242024} | train loss {'Reaction outcome loss': 0.18577775709813665, 'Total loss': 0.18577775709813665}
2022-12-05 20:08:30,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:30,319 INFO:     Epoch: 31
2022-12-05 20:08:31,126 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4138105789368803, 'Total loss': 0.4138105789368803} | train loss {'Reaction outcome loss': 0.17407109565761408, 'Total loss': 0.17407109565761408}
2022-12-05 20:08:31,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:31,126 INFO:     Epoch: 32
2022-12-05 20:08:31,923 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39278231493451377, 'Total loss': 0.39278231493451377} | train loss {'Reaction outcome loss': 0.1676049480585406, 'Total loss': 0.1676049480585406}
2022-12-05 20:08:31,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:31,923 INFO:     Epoch: 33
2022-12-05 20:08:32,721 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4111810377375646, 'Total loss': 0.4111810377375646} | train loss {'Reaction outcome loss': 0.16476221159166518, 'Total loss': 0.16476221159166518}
2022-12-05 20:08:32,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:32,721 INFO:     Epoch: 34
2022-12-05 20:08:33,522 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4151866666295312, 'Total loss': 0.4151866666295312} | train loss {'Reaction outcome loss': 0.16462976706868437, 'Total loss': 0.16462976706868437}
2022-12-05 20:08:33,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:33,523 INFO:     Epoch: 35
2022-12-05 20:08:34,323 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.411173515021801, 'Total loss': 0.411173515021801} | train loss {'Reaction outcome loss': 0.16654248450418957, 'Total loss': 0.16654248450418957}
2022-12-05 20:08:34,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:34,323 INFO:     Epoch: 36
2022-12-05 20:08:35,125 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42192048410123045, 'Total loss': 0.42192048410123045} | train loss {'Reaction outcome loss': 0.16270599237229366, 'Total loss': 0.16270599237229366}
2022-12-05 20:08:35,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:35,125 INFO:     Epoch: 37
2022-12-05 20:08:35,919 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4156653620302677, 'Total loss': 0.4156653620302677} | train loss {'Reaction outcome loss': 0.15822869801572392, 'Total loss': 0.15822869801572392}
2022-12-05 20:08:35,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:35,920 INFO:     Epoch: 38
2022-12-05 20:08:36,716 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41482726112008095, 'Total loss': 0.41482726112008095} | train loss {'Reaction outcome loss': 0.15498500910629084, 'Total loss': 0.15498500910629084}
2022-12-05 20:08:36,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:36,716 INFO:     Epoch: 39
2022-12-05 20:08:37,516 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4096690480681983, 'Total loss': 0.4096690480681983} | train loss {'Reaction outcome loss': 0.15516241620245733, 'Total loss': 0.15516241620245733}
2022-12-05 20:08:37,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:37,516 INFO:     Epoch: 40
2022-12-05 20:08:38,320 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3988185765814375, 'Total loss': 0.3988185765814375} | train loss {'Reaction outcome loss': 0.15352601698234014, 'Total loss': 0.15352601698234014}
2022-12-05 20:08:38,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:38,321 INFO:     Epoch: 41
2022-12-05 20:08:39,122 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41248806481334294, 'Total loss': 0.41248806481334294} | train loss {'Reaction outcome loss': 0.1557381543055599, 'Total loss': 0.1557381543055599}
2022-12-05 20:08:39,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:39,122 INFO:     Epoch: 42
2022-12-05 20:08:39,927 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4085861786522649, 'Total loss': 0.4085861786522649} | train loss {'Reaction outcome loss': 0.1495387807134011, 'Total loss': 0.1495387807134011}
2022-12-05 20:08:39,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:39,928 INFO:     Epoch: 43
2022-12-05 20:08:40,740 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4194330772892995, 'Total loss': 0.4194330772892995} | train loss {'Reaction outcome loss': 0.14902235498191857, 'Total loss': 0.14902235498191857}
2022-12-05 20:08:40,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:40,740 INFO:     Epoch: 44
2022-12-05 20:08:41,540 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4125414578752084, 'Total loss': 0.4125414578752084} | train loss {'Reaction outcome loss': 0.14884661554890546, 'Total loss': 0.14884661554890546}
2022-12-05 20:08:41,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:41,540 INFO:     Epoch: 45
2022-12-05 20:08:42,350 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4153509431264617, 'Total loss': 0.4153509431264617} | train loss {'Reaction outcome loss': 0.1488759924623708, 'Total loss': 0.1488759924623708}
2022-12-05 20:08:42,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:42,350 INFO:     Epoch: 46
2022-12-05 20:08:43,154 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.420227896083485, 'Total loss': 0.420227896083485} | train loss {'Reaction outcome loss': 0.1462600283882758, 'Total loss': 0.1462600283882758}
2022-12-05 20:08:43,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:43,155 INFO:     Epoch: 47
2022-12-05 20:08:43,957 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40854695066809654, 'Total loss': 0.40854695066809654} | train loss {'Reaction outcome loss': 0.14136373875134808, 'Total loss': 0.14136373875134808}
2022-12-05 20:08:43,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:43,957 INFO:     Epoch: 48
2022-12-05 20:08:44,761 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42457033456726506, 'Total loss': 0.42457033456726506} | train loss {'Reaction outcome loss': 0.14695029901076667, 'Total loss': 0.14695029901076667}
2022-12-05 20:08:44,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:44,762 INFO:     Epoch: 49
2022-12-05 20:08:45,561 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41896265575831587, 'Total loss': 0.41896265575831587} | train loss {'Reaction outcome loss': 0.14226245622976347, 'Total loss': 0.14226245622976347}
2022-12-05 20:08:45,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:45,561 INFO:     Epoch: 50
2022-12-05 20:08:46,372 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4027978381650014, 'Total loss': 0.4027978381650014} | train loss {'Reaction outcome loss': 0.14552156813442707, 'Total loss': 0.14552156813442707}
2022-12-05 20:08:46,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:46,372 INFO:     Epoch: 51
2022-12-05 20:08:47,169 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40822032060135494, 'Total loss': 0.40822032060135494} | train loss {'Reaction outcome loss': 0.13902562838198565, 'Total loss': 0.13902562838198565}
2022-12-05 20:08:47,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:47,169 INFO:     Epoch: 52
2022-12-05 20:08:47,962 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40664240988818084, 'Total loss': 0.40664240988818084} | train loss {'Reaction outcome loss': 0.13417524098878658, 'Total loss': 0.13417524098878658}
2022-12-05 20:08:47,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:47,962 INFO:     Epoch: 53
2022-12-05 20:08:48,757 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.425684757869352, 'Total loss': 0.425684757869352} | train loss {'Reaction outcome loss': 0.13507813107889705, 'Total loss': 0.13507813107889705}
2022-12-05 20:08:48,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:48,757 INFO:     Epoch: 54
2022-12-05 20:08:49,550 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4247958157211542, 'Total loss': 0.4247958157211542} | train loss {'Reaction outcome loss': 0.1357904147386913, 'Total loss': 0.1357904147386913}
2022-12-05 20:08:49,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:49,551 INFO:     Epoch: 55
2022-12-05 20:08:50,346 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4304496515542269, 'Total loss': 0.4304496515542269} | train loss {'Reaction outcome loss': 0.13338282354447523, 'Total loss': 0.13338282354447523}
2022-12-05 20:08:50,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:50,346 INFO:     Epoch: 56
2022-12-05 20:08:51,140 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4231679883192886, 'Total loss': 0.4231679883192886} | train loss {'Reaction outcome loss': 0.13911667410736744, 'Total loss': 0.13911667410736744}
2022-12-05 20:08:51,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:51,140 INFO:     Epoch: 57
2022-12-05 20:08:51,946 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42602289298718626, 'Total loss': 0.42602289298718626} | train loss {'Reaction outcome loss': 0.1307281705961838, 'Total loss': 0.1307281705961838}
2022-12-05 20:08:51,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:51,947 INFO:     Epoch: 58
2022-12-05 20:08:52,744 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4125763177871704, 'Total loss': 0.4125763177871704} | train loss {'Reaction outcome loss': 0.13788620385563807, 'Total loss': 0.13788620385563807}
2022-12-05 20:08:52,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:52,745 INFO:     Epoch: 59
2022-12-05 20:08:53,542 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4243769720196724, 'Total loss': 0.4243769720196724} | train loss {'Reaction outcome loss': 0.1283449527057197, 'Total loss': 0.1283449527057197}
2022-12-05 20:08:53,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:53,542 INFO:     Epoch: 60
2022-12-05 20:08:54,344 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41085805286738003, 'Total loss': 0.41085805286738003} | train loss {'Reaction outcome loss': 0.13031265544959605, 'Total loss': 0.13031265544959605}
2022-12-05 20:08:54,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:54,344 INFO:     Epoch: 61
2022-12-05 20:08:55,142 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4276456365531141, 'Total loss': 0.4276456365531141} | train loss {'Reaction outcome loss': 0.1283112271662485, 'Total loss': 0.1283112271662485}
2022-12-05 20:08:55,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:55,142 INFO:     Epoch: 62
2022-12-05 20:08:55,943 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41406429423527286, 'Total loss': 0.41406429423527286} | train loss {'Reaction outcome loss': 0.12950989164163165, 'Total loss': 0.12950989164163165}
2022-12-05 20:08:55,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:55,943 INFO:     Epoch: 63
2022-12-05 20:08:56,746 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4226822406053543, 'Total loss': 0.4226822406053543} | train loss {'Reaction outcome loss': 0.12738517397705482, 'Total loss': 0.12738517397705482}
2022-12-05 20:08:56,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:56,746 INFO:     Epoch: 64
2022-12-05 20:08:57,540 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43056443469090894, 'Total loss': 0.43056443469090894} | train loss {'Reaction outcome loss': 0.12687717198284892, 'Total loss': 0.12687717198284892}
2022-12-05 20:08:57,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:57,541 INFO:     Epoch: 65
2022-12-05 20:08:58,337 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41445894488556817, 'Total loss': 0.41445894488556817} | train loss {'Reaction outcome loss': 0.12474807394151896, 'Total loss': 0.12474807394151896}
2022-12-05 20:08:58,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:58,338 INFO:     Epoch: 66
2022-12-05 20:08:59,134 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4377553989602761, 'Total loss': 0.4377553989602761} | train loss {'Reaction outcome loss': 0.12440464374899624, 'Total loss': 0.12440464374899624}
2022-12-05 20:08:59,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:59,135 INFO:     Epoch: 67
2022-12-05 20:08:59,929 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42685927653854544, 'Total loss': 0.42685927653854544} | train loss {'Reaction outcome loss': 0.12483469372321117, 'Total loss': 0.12483469372321117}
2022-12-05 20:08:59,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:08:59,929 INFO:     Epoch: 68
2022-12-05 20:09:00,724 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41360093196007336, 'Total loss': 0.41360093196007336} | train loss {'Reaction outcome loss': 0.1264182022180755, 'Total loss': 0.1264182022180755}
2022-12-05 20:09:00,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:00,725 INFO:     Epoch: 69
2022-12-05 20:09:01,530 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40939686819911003, 'Total loss': 0.40939686819911003} | train loss {'Reaction outcome loss': 0.12088503893502509, 'Total loss': 0.12088503893502509}
2022-12-05 20:09:01,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:01,530 INFO:     Epoch: 70
2022-12-05 20:09:02,325 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4358910024166107, 'Total loss': 0.4358910024166107} | train loss {'Reaction outcome loss': 0.12441482411147009, 'Total loss': 0.12441482411147009}
2022-12-05 20:09:02,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:02,326 INFO:     Epoch: 71
2022-12-05 20:09:03,120 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4268081814728, 'Total loss': 0.4268081814728} | train loss {'Reaction outcome loss': 0.12399337599468738, 'Total loss': 0.12399337599468738}
2022-12-05 20:09:03,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:03,120 INFO:     Epoch: 72
2022-12-05 20:09:03,920 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4245798692784526, 'Total loss': 0.4245798692784526} | train loss {'Reaction outcome loss': 0.12039316877315522, 'Total loss': 0.12039316877315522}
2022-12-05 20:09:03,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:03,920 INFO:     Epoch: 73
2022-12-05 20:09:04,713 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41689079508862714, 'Total loss': 0.41689079508862714} | train loss {'Reaction outcome loss': 0.11966856106029831, 'Total loss': 0.11966856106029831}
2022-12-05 20:09:04,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:04,713 INFO:     Epoch: 74
2022-12-05 20:09:05,509 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4286441389809955, 'Total loss': 0.4286441389809955} | train loss {'Reaction outcome loss': 0.12605762750693683, 'Total loss': 0.12605762750693683}
2022-12-05 20:09:05,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:05,509 INFO:     Epoch: 75
2022-12-05 20:09:06,304 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4257127652791413, 'Total loss': 0.4257127652791413} | train loss {'Reaction outcome loss': 0.11928519998726092, 'Total loss': 0.11928519998726092}
2022-12-05 20:09:06,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:06,304 INFO:     Epoch: 76
2022-12-05 20:09:07,104 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.431922663341869, 'Total loss': 0.431922663341869} | train loss {'Reaction outcome loss': 0.12250317312656385, 'Total loss': 0.12250317312656385}
2022-12-05 20:09:07,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:07,104 INFO:     Epoch: 77
2022-12-05 20:09:07,901 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42244880443269556, 'Total loss': 0.42244880443269556} | train loss {'Reaction outcome loss': 0.12360799192499958, 'Total loss': 0.12360799192499958}
2022-12-05 20:09:07,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:07,901 INFO:     Epoch: 78
2022-12-05 20:09:08,694 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4259884983978488, 'Total loss': 0.4259884983978488} | train loss {'Reaction outcome loss': 0.11730440799900999, 'Total loss': 0.11730440799900999}
2022-12-05 20:09:08,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:08,694 INFO:     Epoch: 79
2022-12-05 20:09:09,492 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4267324243079532, 'Total loss': 0.4267324243079532} | train loss {'Reaction outcome loss': 0.11618375961823381, 'Total loss': 0.11618375961823381}
2022-12-05 20:09:09,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:09,493 INFO:     Epoch: 80
2022-12-05 20:09:10,286 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42974041774868965, 'Total loss': 0.42974041774868965} | train loss {'Reaction outcome loss': 0.11485034425512922, 'Total loss': 0.11485034425512922}
2022-12-05 20:09:10,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:10,286 INFO:     Epoch: 81
2022-12-05 20:09:11,086 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41688846415755426, 'Total loss': 0.41688846415755426} | train loss {'Reaction outcome loss': 0.1170952233791291, 'Total loss': 0.1170952233791291}
2022-12-05 20:09:11,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:11,086 INFO:     Epoch: 82
2022-12-05 20:09:11,882 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43917076475918293, 'Total loss': 0.43917076475918293} | train loss {'Reaction outcome loss': 0.11725847757523239, 'Total loss': 0.11725847757523239}
2022-12-05 20:09:11,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:11,883 INFO:     Epoch: 83
2022-12-05 20:09:12,676 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4147610349411314, 'Total loss': 0.4147610349411314} | train loss {'Reaction outcome loss': 0.11928788120839519, 'Total loss': 0.11928788120839519}
2022-12-05 20:09:12,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:12,676 INFO:     Epoch: 84
2022-12-05 20:09:13,472 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4335122795944864, 'Total loss': 0.4335122795944864} | train loss {'Reaction outcome loss': 0.11590402019832298, 'Total loss': 0.11590402019832298}
2022-12-05 20:09:13,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:13,472 INFO:     Epoch: 85
2022-12-05 20:09:14,268 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4285428510470824, 'Total loss': 0.4285428510470824} | train loss {'Reaction outcome loss': 0.12088966880253844, 'Total loss': 0.12088966880253844}
2022-12-05 20:09:14,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:14,268 INFO:     Epoch: 86
2022-12-05 20:09:15,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4186524377966469, 'Total loss': 0.4186524377966469} | train loss {'Reaction outcome loss': 0.11612990531346455, 'Total loss': 0.11612990531346455}
2022-12-05 20:09:15,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:15,063 INFO:     Epoch: 87
2022-12-05 20:09:15,856 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4320343231612986, 'Total loss': 0.4320343231612986} | train loss {'Reaction outcome loss': 0.11305347388385897, 'Total loss': 0.11305347388385897}
2022-12-05 20:09:15,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:15,856 INFO:     Epoch: 88
2022-12-05 20:09:16,649 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4182502861050042, 'Total loss': 0.4182502861050042} | train loss {'Reaction outcome loss': 0.11568887292705325, 'Total loss': 0.11568887292705325}
2022-12-05 20:09:16,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:16,649 INFO:     Epoch: 89
2022-12-05 20:09:17,445 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42022850158338604, 'Total loss': 0.42022850158338604} | train loss {'Reaction outcome loss': 0.11598268197660866, 'Total loss': 0.11598268197660866}
2022-12-05 20:09:17,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:17,445 INFO:     Epoch: 90
2022-12-05 20:09:18,238 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4168428961526264, 'Total loss': 0.4168428961526264} | train loss {'Reaction outcome loss': 0.11394791184879297, 'Total loss': 0.11394791184879297}
2022-12-05 20:09:18,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:18,238 INFO:     Epoch: 91
2022-12-05 20:09:19,032 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4318778325210918, 'Total loss': 0.4318778325210918} | train loss {'Reaction outcome loss': 0.11158577518571576, 'Total loss': 0.11158577518571576}
2022-12-05 20:09:19,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:19,032 INFO:     Epoch: 92
2022-12-05 20:09:19,828 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43425229598175397, 'Total loss': 0.43425229598175397} | train loss {'Reaction outcome loss': 0.11248021665583496, 'Total loss': 0.11248021665583496}
2022-12-05 20:09:19,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:19,828 INFO:     Epoch: 93
2022-12-05 20:09:20,621 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42407051677053625, 'Total loss': 0.42407051677053625} | train loss {'Reaction outcome loss': 0.11146989559400299, 'Total loss': 0.11146989559400299}
2022-12-05 20:09:20,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:20,621 INFO:     Epoch: 94
2022-12-05 20:09:21,419 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4235066095875068, 'Total loss': 0.4235066095875068} | train loss {'Reaction outcome loss': 0.11285636466192572, 'Total loss': 0.11285636466192572}
2022-12-05 20:09:21,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:21,420 INFO:     Epoch: 95
2022-12-05 20:09:22,213 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4340658655220812, 'Total loss': 0.4340658655220812} | train loss {'Reaction outcome loss': 0.11128432904879151, 'Total loss': 0.11128432904879151}
2022-12-05 20:09:22,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:22,214 INFO:     Epoch: 96
2022-12-05 20:09:23,007 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4255329400978305, 'Total loss': 0.4255329400978305} | train loss {'Reaction outcome loss': 0.11137407416994363, 'Total loss': 0.11137407416994363}
2022-12-05 20:09:23,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:23,007 INFO:     Epoch: 97
2022-12-05 20:09:23,802 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4410524128258906, 'Total loss': 0.4410524128258906} | train loss {'Reaction outcome loss': 0.11109687478577544, 'Total loss': 0.11109687478577544}
2022-12-05 20:09:23,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:23,802 INFO:     Epoch: 98
2022-12-05 20:09:24,600 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42814807898618956, 'Total loss': 0.42814807898618956} | train loss {'Reaction outcome loss': 0.11392032458005767, 'Total loss': 0.11392032458005767}
2022-12-05 20:09:24,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:24,600 INFO:     Epoch: 99
2022-12-05 20:09:25,399 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4242632251910188, 'Total loss': 0.4242632251910188} | train loss {'Reaction outcome loss': 0.1180768454487922, 'Total loss': 0.1180768454487922}
2022-12-05 20:09:25,399 INFO:     Best model found after epoch 17 of 100.
2022-12-05 20:09:25,399 INFO:   Done with stage: TRAINING
2022-12-05 20:09:25,399 INFO:   Starting stage: EVALUATION
2022-12-05 20:09:25,525 INFO:   Done with stage: EVALUATION
2022-12-05 20:09:25,525 INFO:   Leaving out SEQ value Fold_7
2022-12-05 20:09:25,537 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:09:25,537 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:09:26,174 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:09:26,174 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:09:26,242 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:09:26,242 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:09:26,242 INFO:     No hyperparam tuning for this model
2022-12-05 20:09:26,242 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:09:26,242 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:09:26,243 INFO:     None feature selector for col prot
2022-12-05 20:09:26,243 INFO:     None feature selector for col prot
2022-12-05 20:09:26,243 INFO:     None feature selector for col prot
2022-12-05 20:09:26,244 INFO:     None feature selector for col chem
2022-12-05 20:09:26,244 INFO:     None feature selector for col chem
2022-12-05 20:09:26,244 INFO:     None feature selector for col chem
2022-12-05 20:09:26,244 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:09:26,244 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:09:26,246 INFO:     Number of params in model 215821
2022-12-05 20:09:26,249 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:09:26,249 INFO:   Starting stage: TRAINING
2022-12-05 20:09:26,309 INFO:     Val loss before train {'Reaction outcome loss': 1.037654691121795, 'Total loss': 1.037654691121795}
2022-12-05 20:09:26,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:26,309 INFO:     Epoch: 0
2022-12-05 20:09:27,100 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6609053936871615, 'Total loss': 0.6609053936871615} | train loss {'Reaction outcome loss': 0.7816100453558238, 'Total loss': 0.7816100453558238}
2022-12-05 20:09:27,100 INFO:     Found new best model at epoch 0
2022-12-05 20:09:27,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:27,101 INFO:     Epoch: 1
2022-12-05 20:09:27,892 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5547661530700597, 'Total loss': 0.5547661530700597} | train loss {'Reaction outcome loss': 0.5386502740354191, 'Total loss': 0.5386502740354191}
2022-12-05 20:09:27,892 INFO:     Found new best model at epoch 1
2022-12-05 20:09:27,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:27,893 INFO:     Epoch: 2
2022-12-05 20:09:28,687 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5168884667483243, 'Total loss': 0.5168884667483243} | train loss {'Reaction outcome loss': 0.46584448351068536, 'Total loss': 0.46584448351068536}
2022-12-05 20:09:28,687 INFO:     Found new best model at epoch 2
2022-12-05 20:09:28,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:28,688 INFO:     Epoch: 3
2022-12-05 20:09:29,485 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4973641281778162, 'Total loss': 0.4973641281778162} | train loss {'Reaction outcome loss': 0.4225206764693926, 'Total loss': 0.4225206764693926}
2022-12-05 20:09:29,485 INFO:     Found new best model at epoch 3
2022-12-05 20:09:29,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:29,486 INFO:     Epoch: 4
2022-12-05 20:09:30,277 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4954840395260941, 'Total loss': 0.4954840395260941} | train loss {'Reaction outcome loss': 0.3950170044474274, 'Total loss': 0.3950170044474274}
2022-12-05 20:09:30,277 INFO:     Found new best model at epoch 4
2022-12-05 20:09:30,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:30,278 INFO:     Epoch: 5
2022-12-05 20:09:31,069 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46945498341863806, 'Total loss': 0.46945498341863806} | train loss {'Reaction outcome loss': 0.3751715895859336, 'Total loss': 0.3751715895859336}
2022-12-05 20:09:31,070 INFO:     Found new best model at epoch 5
2022-12-05 20:09:31,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:31,070 INFO:     Epoch: 6
2022-12-05 20:09:31,863 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46882781420241704, 'Total loss': 0.46882781420241704} | train loss {'Reaction outcome loss': 0.352470495168738, 'Total loss': 0.352470495168738}
2022-12-05 20:09:31,863 INFO:     Found new best model at epoch 6
2022-12-05 20:09:31,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:31,864 INFO:     Epoch: 7
2022-12-05 20:09:32,660 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45223171247000044, 'Total loss': 0.45223171247000044} | train loss {'Reaction outcome loss': 0.3398166234314683, 'Total loss': 0.3398166234314683}
2022-12-05 20:09:32,660 INFO:     Found new best model at epoch 7
2022-12-05 20:09:32,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:32,661 INFO:     Epoch: 8
2022-12-05 20:09:33,454 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4520191868597811, 'Total loss': 0.4520191868597811} | train loss {'Reaction outcome loss': 0.3224317585287789, 'Total loss': 0.3224317585287789}
2022-12-05 20:09:33,455 INFO:     Found new best model at epoch 8
2022-12-05 20:09:33,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:33,456 INFO:     Epoch: 9
2022-12-05 20:09:34,249 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45079638639634306, 'Total loss': 0.45079638639634306} | train loss {'Reaction outcome loss': 0.30490030100953724, 'Total loss': 0.30490030100953724}
2022-12-05 20:09:34,249 INFO:     Found new best model at epoch 9
2022-12-05 20:09:34,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:34,250 INFO:     Epoch: 10
2022-12-05 20:09:35,043 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4629661776125431, 'Total loss': 0.4629661776125431} | train loss {'Reaction outcome loss': 0.2948476158097567, 'Total loss': 0.2948476158097567}
2022-12-05 20:09:35,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:35,043 INFO:     Epoch: 11
2022-12-05 20:09:35,836 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45640352537686174, 'Total loss': 0.45640352537686174} | train loss {'Reaction outcome loss': 0.291152157130753, 'Total loss': 0.291152157130753}
2022-12-05 20:09:35,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:35,836 INFO:     Epoch: 12
2022-12-05 20:09:36,626 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4557925354350697, 'Total loss': 0.4557925354350697} | train loss {'Reaction outcome loss': 0.27968099818900527, 'Total loss': 0.27968099818900527}
2022-12-05 20:09:36,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:36,627 INFO:     Epoch: 13
2022-12-05 20:09:37,418 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4372282378714193, 'Total loss': 0.4372282378714193} | train loss {'Reaction outcome loss': 0.2674980783657838, 'Total loss': 0.2674980783657838}
2022-12-05 20:09:37,418 INFO:     Found new best model at epoch 13
2022-12-05 20:09:37,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:37,419 INFO:     Epoch: 14
2022-12-05 20:09:38,220 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4447186826304956, 'Total loss': 0.4447186826304956} | train loss {'Reaction outcome loss': 0.2569080924102471, 'Total loss': 0.2569080924102471}
2022-12-05 20:09:38,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:38,220 INFO:     Epoch: 15
2022-12-05 20:09:39,019 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.443504293195226, 'Total loss': 0.443504293195226} | train loss {'Reaction outcome loss': 0.2502572401634112, 'Total loss': 0.2502572401634112}
2022-12-05 20:09:39,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:39,019 INFO:     Epoch: 16
2022-12-05 20:09:39,811 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44647800854661246, 'Total loss': 0.44647800854661246} | train loss {'Reaction outcome loss': 0.24854042298096393, 'Total loss': 0.24854042298096393}
2022-12-05 20:09:39,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:39,812 INFO:     Epoch: 17
2022-12-05 20:09:40,604 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4503923651169647, 'Total loss': 0.4503923651169647} | train loss {'Reaction outcome loss': 0.23796952307706903, 'Total loss': 0.23796952307706903}
2022-12-05 20:09:40,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:40,604 INFO:     Epoch: 18
2022-12-05 20:09:41,394 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4492295780642466, 'Total loss': 0.4492295780642466} | train loss {'Reaction outcome loss': 0.2290925116613809, 'Total loss': 0.2290925116613809}
2022-12-05 20:09:41,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:41,394 INFO:     Epoch: 19
2022-12-05 20:09:42,181 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44711472500454297, 'Total loss': 0.44711472500454297} | train loss {'Reaction outcome loss': 0.22626269598932644, 'Total loss': 0.22626269598932644}
2022-12-05 20:09:42,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:42,181 INFO:     Epoch: 20
2022-12-05 20:09:42,968 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44426229765469377, 'Total loss': 0.44426229765469377} | train loss {'Reaction outcome loss': 0.2231725717212266, 'Total loss': 0.2231725717212266}
2022-12-05 20:09:42,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:42,968 INFO:     Epoch: 21
2022-12-05 20:09:43,755 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4564427547156811, 'Total loss': 0.4564427547156811} | train loss {'Reaction outcome loss': 0.22175590982490978, 'Total loss': 0.22175590982490978}
2022-12-05 20:09:43,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:43,755 INFO:     Epoch: 22
2022-12-05 20:09:44,545 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4582513059404763, 'Total loss': 0.4582513059404763} | train loss {'Reaction outcome loss': 0.2073718022521178, 'Total loss': 0.2073718022521178}
2022-12-05 20:09:44,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:44,546 INFO:     Epoch: 23
2022-12-05 20:09:45,336 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4486483088271184, 'Total loss': 0.4486483088271184} | train loss {'Reaction outcome loss': 0.20374223434551042, 'Total loss': 0.20374223434551042}
2022-12-05 20:09:45,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:45,336 INFO:     Epoch: 24
2022-12-05 20:09:46,128 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4506556825204329, 'Total loss': 0.4506556825204329} | train loss {'Reaction outcome loss': 0.1986907480231784, 'Total loss': 0.1986907480231784}
2022-12-05 20:09:46,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:46,130 INFO:     Epoch: 25
2022-12-05 20:09:46,917 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44915254380215297, 'Total loss': 0.44915254380215297} | train loss {'Reaction outcome loss': 0.19939630834559197, 'Total loss': 0.19939630834559197}
2022-12-05 20:09:46,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:46,917 INFO:     Epoch: 26
2022-12-05 20:09:47,704 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4595177654515613, 'Total loss': 0.4595177654515613} | train loss {'Reaction outcome loss': 0.19328683957755416, 'Total loss': 0.19328683957755416}
2022-12-05 20:09:47,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:47,704 INFO:     Epoch: 27
2022-12-05 20:09:48,495 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45097078078172426, 'Total loss': 0.45097078078172426} | train loss {'Reaction outcome loss': 0.19048670653691177, 'Total loss': 0.19048670653691177}
2022-12-05 20:09:48,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:48,495 INFO:     Epoch: 28
2022-12-05 20:09:49,289 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4619928608563813, 'Total loss': 0.4619928608563813} | train loss {'Reaction outcome loss': 0.1895235172408795, 'Total loss': 0.1895235172408795}
2022-12-05 20:09:49,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:49,290 INFO:     Epoch: 29
2022-12-05 20:09:50,077 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4519692347808318, 'Total loss': 0.4519692347808318} | train loss {'Reaction outcome loss': 0.1832262032065797, 'Total loss': 0.1832262032065797}
2022-12-05 20:09:50,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:50,077 INFO:     Epoch: 30
2022-12-05 20:09:50,868 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4502133286812089, 'Total loss': 0.4502133286812089} | train loss {'Reaction outcome loss': 0.18207680737139725, 'Total loss': 0.18207680737139725}
2022-12-05 20:09:50,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:50,868 INFO:     Epoch: 31
2022-12-05 20:09:51,655 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4623227705332366, 'Total loss': 0.4623227705332366} | train loss {'Reaction outcome loss': 0.17644639674438398, 'Total loss': 0.17644639674438398}
2022-12-05 20:09:51,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:51,655 INFO:     Epoch: 32
2022-12-05 20:09:52,447 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4502647508951751, 'Total loss': 0.4502647508951751} | train loss {'Reaction outcome loss': 0.17563844614507637, 'Total loss': 0.17563844614507637}
2022-12-05 20:09:52,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:52,448 INFO:     Epoch: 33
2022-12-05 20:09:53,236 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4767405834387649, 'Total loss': 0.4767405834387649} | train loss {'Reaction outcome loss': 0.17210775514996726, 'Total loss': 0.17210775514996726}
2022-12-05 20:09:53,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:53,236 INFO:     Epoch: 34
2022-12-05 20:09:54,027 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46021683649583295, 'Total loss': 0.46021683649583295} | train loss {'Reaction outcome loss': 0.16973926766817024, 'Total loss': 0.16973926766817024}
2022-12-05 20:09:54,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:54,027 INFO:     Epoch: 35
2022-12-05 20:09:54,817 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45870411226695235, 'Total loss': 0.45870411226695235} | train loss {'Reaction outcome loss': 0.1648548690654971, 'Total loss': 0.1648548690654971}
2022-12-05 20:09:54,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:54,817 INFO:     Epoch: 36
2022-12-05 20:09:55,605 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46846318346532906, 'Total loss': 0.46846318346532906} | train loss {'Reaction outcome loss': 0.16625734618469049, 'Total loss': 0.16625734618469049}
2022-12-05 20:09:55,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:55,605 INFO:     Epoch: 37
2022-12-05 20:09:56,393 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4618652229281989, 'Total loss': 0.4618652229281989} | train loss {'Reaction outcome loss': 0.16230611487287983, 'Total loss': 0.16230611487287983}
2022-12-05 20:09:56,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:56,393 INFO:     Epoch: 38
2022-12-05 20:09:57,184 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46878545291044493, 'Total loss': 0.46878545291044493} | train loss {'Reaction outcome loss': 0.16743881202600747, 'Total loss': 0.16743881202600747}
2022-12-05 20:09:57,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:57,184 INFO:     Epoch: 39
2022-12-05 20:09:57,974 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45777975192124193, 'Total loss': 0.45777975192124193} | train loss {'Reaction outcome loss': 0.16819421709411464, 'Total loss': 0.16819421709411464}
2022-12-05 20:09:57,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:57,974 INFO:     Epoch: 40
2022-12-05 20:09:58,764 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4608582014387304, 'Total loss': 0.4608582014387304} | train loss {'Reaction outcome loss': 0.16519319833169582, 'Total loss': 0.16519319833169582}
2022-12-05 20:09:58,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:58,764 INFO:     Epoch: 41
2022-12-05 20:09:59,551 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4628038176081397, 'Total loss': 0.4628038176081397} | train loss {'Reaction outcome loss': 0.16436595889751004, 'Total loss': 0.16436595889751004}
2022-12-05 20:09:59,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:09:59,551 INFO:     Epoch: 42
2022-12-05 20:10:00,339 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46543107520450244, 'Total loss': 0.46543107520450244} | train loss {'Reaction outcome loss': 0.15583682142910718, 'Total loss': 0.15583682142910718}
2022-12-05 20:10:00,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:00,339 INFO:     Epoch: 43
2022-12-05 20:10:01,129 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4552391461012038, 'Total loss': 0.4552391461012038} | train loss {'Reaction outcome loss': 0.15405565592260495, 'Total loss': 0.15405565592260495}
2022-12-05 20:10:01,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:01,129 INFO:     Epoch: 44
2022-12-05 20:10:01,916 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47224367037415504, 'Total loss': 0.47224367037415504} | train loss {'Reaction outcome loss': 0.15356454142342937, 'Total loss': 0.15356454142342937}
2022-12-05 20:10:01,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:01,916 INFO:     Epoch: 45
2022-12-05 20:10:02,704 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47585097971287643, 'Total loss': 0.47585097971287643} | train loss {'Reaction outcome loss': 0.15212699021344725, 'Total loss': 0.15212699021344725}
2022-12-05 20:10:02,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:02,704 INFO:     Epoch: 46
2022-12-05 20:10:03,491 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4613372602246024, 'Total loss': 0.4613372602246024} | train loss {'Reaction outcome loss': 0.1586860524007847, 'Total loss': 0.1586860524007847}
2022-12-05 20:10:03,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:03,491 INFO:     Epoch: 47
2022-12-05 20:10:04,281 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46435304832729424, 'Total loss': 0.46435304832729424} | train loss {'Reaction outcome loss': 0.15072569448448084, 'Total loss': 0.15072569448448084}
2022-12-05 20:10:04,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:04,281 INFO:     Epoch: 48
2022-12-05 20:10:05,069 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45633084360848775, 'Total loss': 0.45633084360848775} | train loss {'Reaction outcome loss': 0.14691486078274893, 'Total loss': 0.14691486078274893}
2022-12-05 20:10:05,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:05,070 INFO:     Epoch: 49
2022-12-05 20:10:05,864 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4675466933033683, 'Total loss': 0.4675466933033683} | train loss {'Reaction outcome loss': 0.1458542046367157, 'Total loss': 0.1458542046367157}
2022-12-05 20:10:05,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:05,865 INFO:     Epoch: 50
2022-12-05 20:10:06,662 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45614871568977833, 'Total loss': 0.45614871568977833} | train loss {'Reaction outcome loss': 0.14517357102114525, 'Total loss': 0.14517357102114525}
2022-12-05 20:10:06,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:06,662 INFO:     Epoch: 51
2022-12-05 20:10:07,449 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47249296646226535, 'Total loss': 0.47249296646226535} | train loss {'Reaction outcome loss': 0.14405414278087345, 'Total loss': 0.14405414278087345}
2022-12-05 20:10:07,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:07,450 INFO:     Epoch: 52
2022-12-05 20:10:08,237 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47846835309808905, 'Total loss': 0.47846835309808905} | train loss {'Reaction outcome loss': 0.14605286162391848, 'Total loss': 0.14605286162391848}
2022-12-05 20:10:08,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:08,237 INFO:     Epoch: 53
2022-12-05 20:10:09,023 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47848481651056896, 'Total loss': 0.47848481651056896} | train loss {'Reaction outcome loss': 0.14888611922666492, 'Total loss': 0.14888611922666492}
2022-12-05 20:10:09,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:09,023 INFO:     Epoch: 54
2022-12-05 20:10:09,813 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46684485572305595, 'Total loss': 0.46684485572305595} | train loss {'Reaction outcome loss': 0.14487708308865968, 'Total loss': 0.14487708308865968}
2022-12-05 20:10:09,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:09,813 INFO:     Epoch: 55
2022-12-05 20:10:10,609 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47021246972409164, 'Total loss': 0.47021246972409164} | train loss {'Reaction outcome loss': 0.14105461661511587, 'Total loss': 0.14105461661511587}
2022-12-05 20:10:10,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:10,609 INFO:     Epoch: 56
2022-12-05 20:10:11,402 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46928888830271637, 'Total loss': 0.46928888830271637} | train loss {'Reaction outcome loss': 0.1464134531005131, 'Total loss': 0.1464134531005131}
2022-12-05 20:10:11,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:11,403 INFO:     Epoch: 57
2022-12-05 20:10:12,190 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4656061933121898, 'Total loss': 0.4656061933121898} | train loss {'Reaction outcome loss': 0.14992070430324145, 'Total loss': 0.14992070430324145}
2022-12-05 20:10:12,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:12,190 INFO:     Epoch: 58
2022-12-05 20:10:12,979 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47006405889987946, 'Total loss': 0.47006405889987946} | train loss {'Reaction outcome loss': 0.14044149882850135, 'Total loss': 0.14044149882850135}
2022-12-05 20:10:12,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:12,979 INFO:     Epoch: 59
2022-12-05 20:10:13,769 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.467056160623377, 'Total loss': 0.467056160623377} | train loss {'Reaction outcome loss': 0.13693510393163394, 'Total loss': 0.13693510393163394}
2022-12-05 20:10:13,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:13,769 INFO:     Epoch: 60
2022-12-05 20:10:14,558 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46975850381634454, 'Total loss': 0.46975850381634454} | train loss {'Reaction outcome loss': 0.13749586284794063, 'Total loss': 0.13749586284794063}
2022-12-05 20:10:14,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:14,558 INFO:     Epoch: 61
2022-12-05 20:10:15,348 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4732630310410803, 'Total loss': 0.4732630310410803} | train loss {'Reaction outcome loss': 0.141501903017372, 'Total loss': 0.141501903017372}
2022-12-05 20:10:15,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:15,348 INFO:     Epoch: 62
2022-12-05 20:10:16,139 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46287226338278165, 'Total loss': 0.46287226338278165} | train loss {'Reaction outcome loss': 0.13627509837253735, 'Total loss': 0.13627509837253735}
2022-12-05 20:10:16,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:16,139 INFO:     Epoch: 63
2022-12-05 20:10:16,925 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4804856071079319, 'Total loss': 0.4804856071079319} | train loss {'Reaction outcome loss': 0.13981789953795523, 'Total loss': 0.13981789953795523}
2022-12-05 20:10:16,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:16,927 INFO:     Epoch: 64
2022-12-05 20:10:17,714 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47254325584931806, 'Total loss': 0.47254325584931806} | train loss {'Reaction outcome loss': 0.14642675213425266, 'Total loss': 0.14642675213425266}
2022-12-05 20:10:17,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:17,715 INFO:     Epoch: 65
2022-12-05 20:10:18,502 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4524965174496174, 'Total loss': 0.4524965174496174} | train loss {'Reaction outcome loss': 0.13870849466867563, 'Total loss': 0.13870849466867563}
2022-12-05 20:10:18,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:18,502 INFO:     Epoch: 66
2022-12-05 20:10:19,295 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4814571257341992, 'Total loss': 0.4814571257341992} | train loss {'Reaction outcome loss': 0.13878597820607516, 'Total loss': 0.13878597820607516}
2022-12-05 20:10:19,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:19,295 INFO:     Epoch: 67
2022-12-05 20:10:20,083 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46782128004865214, 'Total loss': 0.46782128004865214} | train loss {'Reaction outcome loss': 0.1426924122238215, 'Total loss': 0.1426924122238215}
2022-12-05 20:10:20,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:20,083 INFO:     Epoch: 68
2022-12-05 20:10:20,871 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46869350580329244, 'Total loss': 0.46869350580329244} | train loss {'Reaction outcome loss': 0.1302928417197123, 'Total loss': 0.1302928417197123}
2022-12-05 20:10:20,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:20,871 INFO:     Epoch: 69
2022-12-05 20:10:21,660 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4736958674409173, 'Total loss': 0.4736958674409173} | train loss {'Reaction outcome loss': 0.1312318984569929, 'Total loss': 0.1312318984569929}
2022-12-05 20:10:21,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:21,660 INFO:     Epoch: 70
2022-12-05 20:10:22,452 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46486232192678884, 'Total loss': 0.46486232192678884} | train loss {'Reaction outcome loss': 0.1300991035494501, 'Total loss': 0.1300991035494501}
2022-12-05 20:10:22,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:22,452 INFO:     Epoch: 71
2022-12-05 20:10:23,240 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4905777231536128, 'Total loss': 0.4905777231536128} | train loss {'Reaction outcome loss': 0.12899346548431415, 'Total loss': 0.12899346548431415}
2022-12-05 20:10:23,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:23,240 INFO:     Epoch: 72
2022-12-05 20:10:24,029 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46049886637113313, 'Total loss': 0.46049886637113313} | train loss {'Reaction outcome loss': 0.13044979005037743, 'Total loss': 0.13044979005037743}
2022-12-05 20:10:24,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:24,030 INFO:     Epoch: 73
2022-12-05 20:10:24,821 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4790187278254466, 'Total loss': 0.4790187278254466} | train loss {'Reaction outcome loss': 0.12693305160503396, 'Total loss': 0.12693305160503396}
2022-12-05 20:10:24,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:24,821 INFO:     Epoch: 74
2022-12-05 20:10:25,612 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46802760220386763, 'Total loss': 0.46802760220386763} | train loss {'Reaction outcome loss': 0.13026605149059883, 'Total loss': 0.13026605149059883}
2022-12-05 20:10:25,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:25,613 INFO:     Epoch: 75
2022-12-05 20:10:26,405 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47492292963645677, 'Total loss': 0.47492292963645677} | train loss {'Reaction outcome loss': 0.12998794228864102, 'Total loss': 0.12998794228864102}
2022-12-05 20:10:26,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:26,406 INFO:     Epoch: 76
2022-12-05 20:10:27,195 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46671767600558023, 'Total loss': 0.46671767600558023} | train loss {'Reaction outcome loss': 0.12947523453332266, 'Total loss': 0.12947523453332266}
2022-12-05 20:10:27,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:27,195 INFO:     Epoch: 77
2022-12-05 20:10:27,983 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4676069197329608, 'Total loss': 0.4676069197329608} | train loss {'Reaction outcome loss': 0.1267941696607029, 'Total loss': 0.1267941696607029}
2022-12-05 20:10:27,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:27,984 INFO:     Epoch: 78
2022-12-05 20:10:28,770 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47013436461036856, 'Total loss': 0.47013436461036856} | train loss {'Reaction outcome loss': 0.12879508027904912, 'Total loss': 0.12879508027904912}
2022-12-05 20:10:28,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:28,771 INFO:     Epoch: 79
2022-12-05 20:10:29,558 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48255583440715616, 'Total loss': 0.48255583440715616} | train loss {'Reaction outcome loss': 0.12714758731409725, 'Total loss': 0.12714758731409725}
2022-12-05 20:10:29,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:29,559 INFO:     Epoch: 80
2022-12-05 20:10:30,350 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47058510475537996, 'Total loss': 0.47058510475537996} | train loss {'Reaction outcome loss': 0.12556851191327414, 'Total loss': 0.12556851191327414}
2022-12-05 20:10:30,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:30,350 INFO:     Epoch: 81
2022-12-05 20:10:31,146 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4826351952823726, 'Total loss': 0.4826351952823726} | train loss {'Reaction outcome loss': 0.12515657628897714, 'Total loss': 0.12515657628897714}
2022-12-05 20:10:31,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:31,146 INFO:     Epoch: 82
2022-12-05 20:10:31,940 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4697078974409537, 'Total loss': 0.4697078974409537} | train loss {'Reaction outcome loss': 0.1230945235659342, 'Total loss': 0.1230945235659342}
2022-12-05 20:10:31,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:31,941 INFO:     Epoch: 83
2022-12-05 20:10:32,729 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47353574565865775, 'Total loss': 0.47353574565865775} | train loss {'Reaction outcome loss': 0.1217917100024911, 'Total loss': 0.1217917100024911}
2022-12-05 20:10:32,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:32,729 INFO:     Epoch: 84
2022-12-05 20:10:33,518 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46176496148109436, 'Total loss': 0.46176496148109436} | train loss {'Reaction outcome loss': 0.12628155251821646, 'Total loss': 0.12628155251821646}
2022-12-05 20:10:33,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:33,518 INFO:     Epoch: 85
2022-12-05 20:10:34,307 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46859135918996553, 'Total loss': 0.46859135918996553} | train loss {'Reaction outcome loss': 0.12245120703825267, 'Total loss': 0.12245120703825267}
2022-12-05 20:10:34,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:34,307 INFO:     Epoch: 86
2022-12-05 20:10:35,094 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47162013771859085, 'Total loss': 0.47162013771859085} | train loss {'Reaction outcome loss': 0.12255317655953801, 'Total loss': 0.12255317655953801}
2022-12-05 20:10:35,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:35,095 INFO:     Epoch: 87
2022-12-05 20:10:35,882 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45585339855064044, 'Total loss': 0.45585339855064044} | train loss {'Reaction outcome loss': 0.12088897215157204, 'Total loss': 0.12088897215157204}
2022-12-05 20:10:35,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:35,882 INFO:     Epoch: 88
2022-12-05 20:10:36,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46492737057534134, 'Total loss': 0.46492737057534134} | train loss {'Reaction outcome loss': 0.12478812014012926, 'Total loss': 0.12478812014012926}
2022-12-05 20:10:36,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:36,670 INFO:     Epoch: 89
2022-12-05 20:10:37,456 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47269597988237033, 'Total loss': 0.47269597988237033} | train loss {'Reaction outcome loss': 0.12290687573063168, 'Total loss': 0.12290687573063168}
2022-12-05 20:10:37,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:37,457 INFO:     Epoch: 90
2022-12-05 20:10:38,247 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46546876193447545, 'Total loss': 0.46546876193447545} | train loss {'Reaction outcome loss': 0.12012707332405073, 'Total loss': 0.12012707332405073}
2022-12-05 20:10:38,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:38,247 INFO:     Epoch: 91
2022-12-05 20:10:39,042 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4808827398175543, 'Total loss': 0.4808827398175543} | train loss {'Reaction outcome loss': 0.1213966548171362, 'Total loss': 0.1213966548171362}
2022-12-05 20:10:39,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:39,042 INFO:     Epoch: 92
2022-12-05 20:10:39,835 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4794825447553938, 'Total loss': 0.4794825447553938} | train loss {'Reaction outcome loss': 0.12674824061694173, 'Total loss': 0.12674824061694173}
2022-12-05 20:10:39,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:39,836 INFO:     Epoch: 93
2022-12-05 20:10:40,628 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47806423191319813, 'Total loss': 0.47806423191319813} | train loss {'Reaction outcome loss': 0.12788413207118327, 'Total loss': 0.12788413207118327}
2022-12-05 20:10:40,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:40,628 INFO:     Epoch: 94
2022-12-05 20:10:41,419 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4653071263297038, 'Total loss': 0.4653071263297038} | train loss {'Reaction outcome loss': 0.11896162730856584, 'Total loss': 0.11896162730856584}
2022-12-05 20:10:41,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:41,419 INFO:     Epoch: 95
2022-12-05 20:10:42,208 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45799304578791966, 'Total loss': 0.45799304578791966} | train loss {'Reaction outcome loss': 0.12716939945814582, 'Total loss': 0.12716939945814582}
2022-12-05 20:10:42,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:42,208 INFO:     Epoch: 96
2022-12-05 20:10:42,996 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4611588665707545, 'Total loss': 0.4611588665707545} | train loss {'Reaction outcome loss': 0.11657409869541645, 'Total loss': 0.11657409869541645}
2022-12-05 20:10:42,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:42,996 INFO:     Epoch: 97
2022-12-05 20:10:43,791 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46571155332706193, 'Total loss': 0.46571155332706193} | train loss {'Reaction outcome loss': 0.11871070781277741, 'Total loss': 0.11871070781277741}
2022-12-05 20:10:43,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:43,791 INFO:     Epoch: 98
2022-12-05 20:10:44,579 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45978789776563644, 'Total loss': 0.45978789776563644} | train loss {'Reaction outcome loss': 0.11578273374741889, 'Total loss': 0.11578273374741889}
2022-12-05 20:10:44,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:44,579 INFO:     Epoch: 99
2022-12-05 20:10:45,368 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47234766761010344, 'Total loss': 0.47234766761010344} | train loss {'Reaction outcome loss': 0.11694996599635855, 'Total loss': 0.11694996599635855}
2022-12-05 20:10:45,368 INFO:     Best model found after epoch 14 of 100.
2022-12-05 20:10:45,368 INFO:   Done with stage: TRAINING
2022-12-05 20:10:45,368 INFO:   Starting stage: EVALUATION
2022-12-05 20:10:45,494 INFO:   Done with stage: EVALUATION
2022-12-05 20:10:45,494 INFO:   Leaving out SEQ value Fold_8
2022-12-05 20:10:45,507 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:10:45,507 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:10:46,135 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:10:46,135 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:10:46,203 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:10:46,203 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:10:46,203 INFO:     No hyperparam tuning for this model
2022-12-05 20:10:46,203 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:10:46,203 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:10:46,204 INFO:     None feature selector for col prot
2022-12-05 20:10:46,204 INFO:     None feature selector for col prot
2022-12-05 20:10:46,204 INFO:     None feature selector for col prot
2022-12-05 20:10:46,205 INFO:     None feature selector for col chem
2022-12-05 20:10:46,205 INFO:     None feature selector for col chem
2022-12-05 20:10:46,205 INFO:     None feature selector for col chem
2022-12-05 20:10:46,205 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:10:46,205 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:10:46,207 INFO:     Number of params in model 215821
2022-12-05 20:10:46,210 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:10:46,210 INFO:   Starting stage: TRAINING
2022-12-05 20:10:46,270 INFO:     Val loss before train {'Reaction outcome loss': 1.00199909334959, 'Total loss': 1.00199909334959}
2022-12-05 20:10:46,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:46,270 INFO:     Epoch: 0
2022-12-05 20:10:47,055 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.605232224907986, 'Total loss': 0.605232224907986} | train loss {'Reaction outcome loss': 0.7724248821862408, 'Total loss': 0.7724248821862408}
2022-12-05 20:10:47,055 INFO:     Found new best model at epoch 0
2022-12-05 20:10:47,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:47,056 INFO:     Epoch: 1
2022-12-05 20:10:47,838 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5203784967577735, 'Total loss': 0.5203784967577735} | train loss {'Reaction outcome loss': 0.5321021034825043, 'Total loss': 0.5321021034825043}
2022-12-05 20:10:47,839 INFO:     Found new best model at epoch 1
2022-12-05 20:10:47,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:47,840 INFO:     Epoch: 2
2022-12-05 20:10:48,622 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4901836029318876, 'Total loss': 0.4901836029318876} | train loss {'Reaction outcome loss': 0.4664418814001513, 'Total loss': 0.4664418814001513}
2022-12-05 20:10:48,622 INFO:     Found new best model at epoch 2
2022-12-05 20:10:48,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:48,623 INFO:     Epoch: 3
2022-12-05 20:10:49,403 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4745792940605518, 'Total loss': 0.4745792940605518} | train loss {'Reaction outcome loss': 0.4300093654482091, 'Total loss': 0.4300093654482091}
2022-12-05 20:10:49,403 INFO:     Found new best model at epoch 3
2022-12-05 20:10:49,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:49,404 INFO:     Epoch: 4
2022-12-05 20:10:50,184 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45697171500948974, 'Total loss': 0.45697171500948974} | train loss {'Reaction outcome loss': 0.4000545090949926, 'Total loss': 0.4000545090949926}
2022-12-05 20:10:50,184 INFO:     Found new best model at epoch 4
2022-12-05 20:10:50,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:50,185 INFO:     Epoch: 5
2022-12-05 20:10:50,969 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44695299829161445, 'Total loss': 0.44695299829161445} | train loss {'Reaction outcome loss': 0.37979283128849795, 'Total loss': 0.37979283128849795}
2022-12-05 20:10:50,969 INFO:     Found new best model at epoch 5
2022-12-05 20:10:50,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:50,970 INFO:     Epoch: 6
2022-12-05 20:10:51,749 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43697231037672174, 'Total loss': 0.43697231037672174} | train loss {'Reaction outcome loss': 0.3606313360152674, 'Total loss': 0.3606313360152674}
2022-12-05 20:10:51,749 INFO:     Found new best model at epoch 6
2022-12-05 20:10:51,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:51,750 INFO:     Epoch: 7
2022-12-05 20:10:52,530 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43446593367776204, 'Total loss': 0.43446593367776204} | train loss {'Reaction outcome loss': 0.33987980442823934, 'Total loss': 0.33987980442823934}
2022-12-05 20:10:52,530 INFO:     Found new best model at epoch 7
2022-12-05 20:10:52,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:52,531 INFO:     Epoch: 8
2022-12-05 20:10:53,311 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4365019150251566, 'Total loss': 0.4365019150251566} | train loss {'Reaction outcome loss': 0.32556040814054793, 'Total loss': 0.32556040814054793}
2022-12-05 20:10:53,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:53,311 INFO:     Epoch: 9
2022-12-05 20:10:54,091 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4317589589329653, 'Total loss': 0.4317589589329653} | train loss {'Reaction outcome loss': 0.3117025293654106, 'Total loss': 0.3117025293654106}
2022-12-05 20:10:54,092 INFO:     Found new best model at epoch 9
2022-12-05 20:10:54,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:54,093 INFO:     Epoch: 10
2022-12-05 20:10:54,875 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43168943080791206, 'Total loss': 0.43168943080791206} | train loss {'Reaction outcome loss': 0.29904793847169053, 'Total loss': 0.29904793847169053}
2022-12-05 20:10:54,875 INFO:     Found new best model at epoch 10
2022-12-05 20:10:54,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:54,876 INFO:     Epoch: 11
2022-12-05 20:10:55,659 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43940402636694353, 'Total loss': 0.43940402636694353} | train loss {'Reaction outcome loss': 0.28433755498196256, 'Total loss': 0.28433755498196256}
2022-12-05 20:10:55,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:55,659 INFO:     Epoch: 12
2022-12-05 20:10:56,442 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43660249751667646, 'Total loss': 0.43660249751667646} | train loss {'Reaction outcome loss': 0.271161203700133, 'Total loss': 0.271161203700133}
2022-12-05 20:10:56,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:56,442 INFO:     Epoch: 13
2022-12-05 20:10:57,224 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4375035333078961, 'Total loss': 0.4375035333078961} | train loss {'Reaction outcome loss': 0.2622853534937393, 'Total loss': 0.2622853534937393}
2022-12-05 20:10:57,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:57,224 INFO:     Epoch: 14
2022-12-05 20:10:58,006 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4348676464585371, 'Total loss': 0.4348676464585371} | train loss {'Reaction outcome loss': 0.25257842603032704, 'Total loss': 0.25257842603032704}
2022-12-05 20:10:58,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:58,007 INFO:     Epoch: 15
2022-12-05 20:10:58,787 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.433699996838736, 'Total loss': 0.433699996838736} | train loss {'Reaction outcome loss': 0.24503714124076678, 'Total loss': 0.24503714124076678}
2022-12-05 20:10:58,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:58,787 INFO:     Epoch: 16
2022-12-05 20:10:59,567 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4499002937660661, 'Total loss': 0.4499002937660661} | train loss {'Reaction outcome loss': 0.23420817026349364, 'Total loss': 0.23420817026349364}
2022-12-05 20:10:59,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:10:59,568 INFO:     Epoch: 17
2022-12-05 20:11:00,349 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4494987958392432, 'Total loss': 0.4494987958392432} | train loss {'Reaction outcome loss': 0.22876635134281192, 'Total loss': 0.22876635134281192}
2022-12-05 20:11:00,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:00,349 INFO:     Epoch: 18
2022-12-05 20:11:01,128 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44004509580689805, 'Total loss': 0.44004509580689805} | train loss {'Reaction outcome loss': 0.22400604247985806, 'Total loss': 0.22400604247985806}
2022-12-05 20:11:01,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:01,128 INFO:     Epoch: 19
2022-12-05 20:11:01,909 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4522275831117186, 'Total loss': 0.4522275831117186} | train loss {'Reaction outcome loss': 0.21739228417883155, 'Total loss': 0.21739228417883155}
2022-12-05 20:11:01,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:01,909 INFO:     Epoch: 20
2022-12-05 20:11:02,696 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4384862016453299, 'Total loss': 0.4384862016453299} | train loss {'Reaction outcome loss': 0.20863908257518635, 'Total loss': 0.20863908257518635}
2022-12-05 20:11:02,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:02,696 INFO:     Epoch: 21
2022-12-05 20:11:03,483 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44474322643390923, 'Total loss': 0.44474322643390923} | train loss {'Reaction outcome loss': 0.20562309783990265, 'Total loss': 0.20562309783990265}
2022-12-05 20:11:03,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:03,483 INFO:     Epoch: 22
2022-12-05 20:11:04,272 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4501253009535546, 'Total loss': 0.4501253009535546} | train loss {'Reaction outcome loss': 0.20395694338701298, 'Total loss': 0.20395694338701298}
2022-12-05 20:11:04,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:04,273 INFO:     Epoch: 23
2022-12-05 20:11:05,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4644455396851828, 'Total loss': 0.4644455396851828} | train loss {'Reaction outcome loss': 0.19607815641115922, 'Total loss': 0.19607815641115922}
2022-12-05 20:11:05,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:05,064 INFO:     Epoch: 24
2022-12-05 20:11:05,851 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4606421444305154, 'Total loss': 0.4606421444305154} | train loss {'Reaction outcome loss': 0.19146368090735108, 'Total loss': 0.19146368090735108}
2022-12-05 20:11:05,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:05,852 INFO:     Epoch: 25
2022-12-05 20:11:06,636 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4698534393033316, 'Total loss': 0.4698534393033316} | train loss {'Reaction outcome loss': 0.18801816763570073, 'Total loss': 0.18801816763570073}
2022-12-05 20:11:06,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:06,637 INFO:     Epoch: 26
2022-12-05 20:11:07,426 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.465931631797968, 'Total loss': 0.465931631797968} | train loss {'Reaction outcome loss': 0.18495911498721995, 'Total loss': 0.18495911498721995}
2022-12-05 20:11:07,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:07,426 INFO:     Epoch: 27
2022-12-05 20:11:08,222 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4769147660496623, 'Total loss': 0.4769147660496623} | train loss {'Reaction outcome loss': 0.1818128777744218, 'Total loss': 0.1818128777744218}
2022-12-05 20:11:08,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:08,222 INFO:     Epoch: 28
2022-12-05 20:11:09,016 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4564278676759365, 'Total loss': 0.4564278676759365} | train loss {'Reaction outcome loss': 0.1794276432607506, 'Total loss': 0.1794276432607506}
2022-12-05 20:11:09,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:09,017 INFO:     Epoch: 29
2022-12-05 20:11:09,804 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46954975017281464, 'Total loss': 0.46954975017281464} | train loss {'Reaction outcome loss': 0.17320659794829418, 'Total loss': 0.17320659794829418}
2022-12-05 20:11:09,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:09,804 INFO:     Epoch: 30
2022-12-05 20:11:10,600 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46745233757551324, 'Total loss': 0.46745233757551324} | train loss {'Reaction outcome loss': 0.1719579829788599, 'Total loss': 0.1719579829788599}
2022-12-05 20:11:10,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:10,600 INFO:     Epoch: 31
2022-12-05 20:11:11,397 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48180738334045853, 'Total loss': 0.48180738334045853} | train loss {'Reaction outcome loss': 0.17372193059990884, 'Total loss': 0.17372193059990884}
2022-12-05 20:11:11,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:11,397 INFO:     Epoch: 32
2022-12-05 20:11:12,194 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4809282818852469, 'Total loss': 0.4809282818852469} | train loss {'Reaction outcome loss': 0.1688940162449831, 'Total loss': 0.1688940162449831}
2022-12-05 20:11:12,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:12,194 INFO:     Epoch: 33
2022-12-05 20:11:12,987 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47003732032554096, 'Total loss': 0.47003732032554096} | train loss {'Reaction outcome loss': 0.16537632068741273, 'Total loss': 0.16537632068741273}
2022-12-05 20:11:12,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:12,987 INFO:     Epoch: 34
2022-12-05 20:11:13,787 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4687144978101863, 'Total loss': 0.4687144978101863} | train loss {'Reaction outcome loss': 0.16259274758459602, 'Total loss': 0.16259274758459602}
2022-12-05 20:11:13,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:13,787 INFO:     Epoch: 35
2022-12-05 20:11:14,581 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4848479254301204, 'Total loss': 0.4848479254301204} | train loss {'Reaction outcome loss': 0.1604264269918814, 'Total loss': 0.1604264269918814}
2022-12-05 20:11:14,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:14,581 INFO:     Epoch: 36
2022-12-05 20:11:15,374 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47870968698069105, 'Total loss': 0.47870968698069105} | train loss {'Reaction outcome loss': 0.16064924803241842, 'Total loss': 0.16064924803241842}
2022-12-05 20:11:15,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:15,374 INFO:     Epoch: 37
2022-12-05 20:11:16,164 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4691170512936836, 'Total loss': 0.4691170512936836} | train loss {'Reaction outcome loss': 0.15879312717951224, 'Total loss': 0.15879312717951224}
2022-12-05 20:11:16,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:16,165 INFO:     Epoch: 38
2022-12-05 20:11:16,953 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5067066021783407, 'Total loss': 0.5067066021783407} | train loss {'Reaction outcome loss': 0.15498038477523893, 'Total loss': 0.15498038477523893}
2022-12-05 20:11:16,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:16,954 INFO:     Epoch: 39
2022-12-05 20:11:17,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4825920552708382, 'Total loss': 0.4825920552708382} | train loss {'Reaction outcome loss': 0.15563393801786615, 'Total loss': 0.15563393801786615}
2022-12-05 20:11:17,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:17,745 INFO:     Epoch: 40
2022-12-05 20:11:18,534 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4908092645711677, 'Total loss': 0.4908092645711677} | train loss {'Reaction outcome loss': 0.15121449955326857, 'Total loss': 0.15121449955326857}
2022-12-05 20:11:18,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:18,535 INFO:     Epoch: 41
2022-12-05 20:11:19,326 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48332515896059747, 'Total loss': 0.48332515896059747} | train loss {'Reaction outcome loss': 0.14860998726159821, 'Total loss': 0.14860998726159821}
2022-12-05 20:11:19,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:19,327 INFO:     Epoch: 42
2022-12-05 20:11:20,118 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47996818534163543, 'Total loss': 0.47996818534163543} | train loss {'Reaction outcome loss': 0.15136567201297424, 'Total loss': 0.15136567201297424}
2022-12-05 20:11:20,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:20,119 INFO:     Epoch: 43
2022-12-05 20:11:20,910 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48870887555355247, 'Total loss': 0.48870887555355247} | train loss {'Reaction outcome loss': 0.14724163564502216, 'Total loss': 0.14724163564502216}
2022-12-05 20:11:20,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:20,911 INFO:     Epoch: 44
2022-12-05 20:11:21,700 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4766786815815194, 'Total loss': 0.4766786815815194} | train loss {'Reaction outcome loss': 0.14787317968553818, 'Total loss': 0.14787317968553818}
2022-12-05 20:11:21,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:21,700 INFO:     Epoch: 45
2022-12-05 20:11:22,495 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4698545766431232, 'Total loss': 0.4698545766431232} | train loss {'Reaction outcome loss': 0.14436306918543748, 'Total loss': 0.14436306918543748}
2022-12-05 20:11:22,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:22,495 INFO:     Epoch: 46
2022-12-05 20:11:23,288 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4782207327526669, 'Total loss': 0.4782207327526669} | train loss {'Reaction outcome loss': 0.14416254125535488, 'Total loss': 0.14416254125535488}
2022-12-05 20:11:23,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:23,288 INFO:     Epoch: 47
2022-12-05 20:11:24,083 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47298422975595605, 'Total loss': 0.47298422975595605} | train loss {'Reaction outcome loss': 0.1449200235551498, 'Total loss': 0.1449200235551498}
2022-12-05 20:11:24,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:24,083 INFO:     Epoch: 48
2022-12-05 20:11:24,879 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49434673612894015, 'Total loss': 0.49434673612894015} | train loss {'Reaction outcome loss': 0.14163118522980664, 'Total loss': 0.14163118522980664}
2022-12-05 20:11:24,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:24,880 INFO:     Epoch: 49
2022-12-05 20:11:25,672 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49291775652835534, 'Total loss': 0.49291775652835534} | train loss {'Reaction outcome loss': 0.14198976298641475, 'Total loss': 0.14198976298641475}
2022-12-05 20:11:25,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:25,672 INFO:     Epoch: 50
2022-12-05 20:11:26,465 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49739577846471655, 'Total loss': 0.49739577846471655} | train loss {'Reaction outcome loss': 0.13893728545240935, 'Total loss': 0.13893728545240935}
2022-12-05 20:11:26,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:26,466 INFO:     Epoch: 51
2022-12-05 20:11:27,259 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4828746441838353, 'Total loss': 0.4828746441838353} | train loss {'Reaction outcome loss': 0.13713392860363008, 'Total loss': 0.13713392860363008}
2022-12-05 20:11:27,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:27,259 INFO:     Epoch: 52
2022-12-05 20:11:28,058 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4805276189432588, 'Total loss': 0.4805276189432588} | train loss {'Reaction outcome loss': 0.13889082925027754, 'Total loss': 0.13889082925027754}
2022-12-05 20:11:28,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:28,059 INFO:     Epoch: 53
2022-12-05 20:11:28,846 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4910153656504875, 'Total loss': 0.4910153656504875} | train loss {'Reaction outcome loss': 0.13745036430382093, 'Total loss': 0.13745036430382093}
2022-12-05 20:11:28,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:28,846 INFO:     Epoch: 54
2022-12-05 20:11:29,634 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4833094332107278, 'Total loss': 0.4833094332107278} | train loss {'Reaction outcome loss': 0.13468191729950124, 'Total loss': 0.13468191729950124}
2022-12-05 20:11:29,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:29,634 INFO:     Epoch: 55
2022-12-05 20:11:30,426 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4925009481782137, 'Total loss': 0.4925009481782137} | train loss {'Reaction outcome loss': 0.1321972921093712, 'Total loss': 0.1321972921093712}
2022-12-05 20:11:30,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:30,426 INFO:     Epoch: 56
2022-12-05 20:11:31,218 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47591548118480415, 'Total loss': 0.47591548118480415} | train loss {'Reaction outcome loss': 0.1337170223285612, 'Total loss': 0.1337170223285612}
2022-12-05 20:11:31,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:31,218 INFO:     Epoch: 57
2022-12-05 20:11:32,003 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4848102677700131, 'Total loss': 0.4848102677700131} | train loss {'Reaction outcome loss': 0.13301733956809658, 'Total loss': 0.13301733956809658}
2022-12-05 20:11:32,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:32,003 INFO:     Epoch: 58
2022-12-05 20:11:32,791 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49193954121234806, 'Total loss': 0.49193954121234806} | train loss {'Reaction outcome loss': 0.13447108014379858, 'Total loss': 0.13447108014379858}
2022-12-05 20:11:32,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:32,791 INFO:     Epoch: 59
2022-12-05 20:11:33,583 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4898085025853889, 'Total loss': 0.4898085025853889} | train loss {'Reaction outcome loss': 0.13230396309470543, 'Total loss': 0.13230396309470543}
2022-12-05 20:11:33,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:33,583 INFO:     Epoch: 60
2022-12-05 20:11:34,369 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48353464156389236, 'Total loss': 0.48353464156389236} | train loss {'Reaction outcome loss': 0.12922590279753213, 'Total loss': 0.12922590279753213}
2022-12-05 20:11:34,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:34,369 INFO:     Epoch: 61
2022-12-05 20:11:35,149 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4799772303464801, 'Total loss': 0.4799772303464801} | train loss {'Reaction outcome loss': 0.12832453366765967, 'Total loss': 0.12832453366765967}
2022-12-05 20:11:35,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:35,149 INFO:     Epoch: 62
2022-12-05 20:11:35,932 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4899448010810586, 'Total loss': 0.4899448010810586} | train loss {'Reaction outcome loss': 0.13030879068967016, 'Total loss': 0.13030879068967016}
2022-12-05 20:11:35,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:35,932 INFO:     Epoch: 63
2022-12-05 20:11:36,711 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4703252509582874, 'Total loss': 0.4703252509582874} | train loss {'Reaction outcome loss': 0.12887889021992316, 'Total loss': 0.12887889021992316}
2022-12-05 20:11:36,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:36,711 INFO:     Epoch: 64
2022-12-05 20:11:37,491 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48485845708569814, 'Total loss': 0.48485845708569814} | train loss {'Reaction outcome loss': 0.1265876928924537, 'Total loss': 0.1265876928924537}
2022-12-05 20:11:37,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:37,492 INFO:     Epoch: 65
2022-12-05 20:11:38,277 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47807089915109235, 'Total loss': 0.47807089915109235} | train loss {'Reaction outcome loss': 0.12872810490414133, 'Total loss': 0.12872810490414133}
2022-12-05 20:11:38,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:38,278 INFO:     Epoch: 66
2022-12-05 20:11:39,065 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4913184226945389, 'Total loss': 0.4913184226945389} | train loss {'Reaction outcome loss': 0.12367914006358287, 'Total loss': 0.12367914006358287}
2022-12-05 20:11:39,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:39,066 INFO:     Epoch: 67
2022-12-05 20:11:39,851 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47436444288076357, 'Total loss': 0.47436444288076357} | train loss {'Reaction outcome loss': 0.12538164417396802, 'Total loss': 0.12538164417396802}
2022-12-05 20:11:39,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:39,851 INFO:     Epoch: 68
2022-12-05 20:11:40,637 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4955782332392626, 'Total loss': 0.4955782332392626} | train loss {'Reaction outcome loss': 0.12494638741214867, 'Total loss': 0.12494638741214867}
2022-12-05 20:11:40,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:40,637 INFO:     Epoch: 69
2022-12-05 20:11:41,419 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48232779738514925, 'Total loss': 0.48232779738514925} | train loss {'Reaction outcome loss': 0.1240598115856286, 'Total loss': 0.1240598115856286}
2022-12-05 20:11:41,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:41,419 INFO:     Epoch: 70
2022-12-05 20:11:42,201 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49473764816688937, 'Total loss': 0.49473764816688937} | train loss {'Reaction outcome loss': 0.12510295027912763, 'Total loss': 0.12510295027912763}
2022-12-05 20:11:42,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:42,201 INFO:     Epoch: 71
2022-12-05 20:11:42,986 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47190254164296525, 'Total loss': 0.47190254164296525} | train loss {'Reaction outcome loss': 0.12320139638881092, 'Total loss': 0.12320139638881092}
2022-12-05 20:11:42,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:42,987 INFO:     Epoch: 72
2022-12-05 20:11:43,773 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47423982239046764, 'Total loss': 0.47423982239046764} | train loss {'Reaction outcome loss': 0.12307686854505026, 'Total loss': 0.12307686854505026}
2022-12-05 20:11:43,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:43,773 INFO:     Epoch: 73
2022-12-05 20:11:44,553 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4900379191304362, 'Total loss': 0.4900379191304362} | train loss {'Reaction outcome loss': 0.12286360676736251, 'Total loss': 0.12286360676736251}
2022-12-05 20:11:44,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:44,553 INFO:     Epoch: 74
2022-12-05 20:11:45,337 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4675648288671361, 'Total loss': 0.4675648288671361} | train loss {'Reaction outcome loss': 0.12138039608806615, 'Total loss': 0.12138039608806615}
2022-12-05 20:11:45,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:45,337 INFO:     Epoch: 75
2022-12-05 20:11:46,118 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4702738565067912, 'Total loss': 0.4702738565067912} | train loss {'Reaction outcome loss': 0.12372360376213662, 'Total loss': 0.12372360376213662}
2022-12-05 20:11:46,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:46,118 INFO:     Epoch: 76
2022-12-05 20:11:46,899 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47355930611144664, 'Total loss': 0.47355930611144664} | train loss {'Reaction outcome loss': 0.1194429292923725, 'Total loss': 0.1194429292923725}
2022-12-05 20:11:46,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:46,899 INFO:     Epoch: 77
2022-12-05 20:11:47,681 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4706133756526681, 'Total loss': 0.4706133756526681} | train loss {'Reaction outcome loss': 0.11828006118856614, 'Total loss': 0.11828006118856614}
2022-12-05 20:11:47,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:47,681 INFO:     Epoch: 78
2022-12-05 20:11:48,468 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4590693048613016, 'Total loss': 0.4590693048613016} | train loss {'Reaction outcome loss': 0.11872524629179083, 'Total loss': 0.11872524629179083}
2022-12-05 20:11:48,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:48,468 INFO:     Epoch: 79
2022-12-05 20:11:49,255 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4667988930677259, 'Total loss': 0.4667988930677259} | train loss {'Reaction outcome loss': 0.11879273741048013, 'Total loss': 0.11879273741048013}
2022-12-05 20:11:49,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:49,256 INFO:     Epoch: 80
2022-12-05 20:11:50,037 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46736076196958853, 'Total loss': 0.46736076196958853} | train loss {'Reaction outcome loss': 0.1181943466558625, 'Total loss': 0.1181943466558625}
2022-12-05 20:11:50,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:50,037 INFO:     Epoch: 81
2022-12-05 20:11:50,819 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4732767721248228, 'Total loss': 0.4732767721248228} | train loss {'Reaction outcome loss': 0.11923260716187051, 'Total loss': 0.11923260716187051}
2022-12-05 20:11:50,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:50,820 INFO:     Epoch: 82
2022-12-05 20:11:51,604 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4699845144221949, 'Total loss': 0.4699845144221949} | train loss {'Reaction outcome loss': 0.11739943436438553, 'Total loss': 0.11739943436438553}
2022-12-05 20:11:51,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:51,604 INFO:     Epoch: 83
2022-12-05 20:11:52,385 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4739099084291347, 'Total loss': 0.4739099084291347} | train loss {'Reaction outcome loss': 0.11875965311497327, 'Total loss': 0.11875965311497327}
2022-12-05 20:11:52,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:52,385 INFO:     Epoch: 84
2022-12-05 20:11:53,167 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48732607690400853, 'Total loss': 0.48732607690400853} | train loss {'Reaction outcome loss': 0.11482592854557223, 'Total loss': 0.11482592854557223}
2022-12-05 20:11:53,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:53,167 INFO:     Epoch: 85
2022-12-05 20:11:53,951 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48502937444420746, 'Total loss': 0.48502937444420746} | train loss {'Reaction outcome loss': 0.11542902792971886, 'Total loss': 0.11542902792971886}
2022-12-05 20:11:53,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:53,952 INFO:     Epoch: 86
2022-12-05 20:11:54,736 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4792858514674874, 'Total loss': 0.4792858514674874} | train loss {'Reaction outcome loss': 0.11799201513182556, 'Total loss': 0.11799201513182556}
2022-12-05 20:11:54,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:54,736 INFO:     Epoch: 87
2022-12-05 20:11:55,523 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4738426128359035, 'Total loss': 0.4738426128359035} | train loss {'Reaction outcome loss': 0.11647407067786963, 'Total loss': 0.11647407067786963}
2022-12-05 20:11:55,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:55,524 INFO:     Epoch: 88
2022-12-05 20:11:56,316 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4645216939754264, 'Total loss': 0.4645216939754264} | train loss {'Reaction outcome loss': 0.11595416160636261, 'Total loss': 0.11595416160636261}
2022-12-05 20:11:56,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:56,316 INFO:     Epoch: 89
2022-12-05 20:11:57,102 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4770879003890725, 'Total loss': 0.4770879003890725} | train loss {'Reaction outcome loss': 0.11402602325437865, 'Total loss': 0.11402602325437865}
2022-12-05 20:11:57,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:57,102 INFO:     Epoch: 90
2022-12-05 20:11:57,887 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4722089556067489, 'Total loss': 0.4722089556067489} | train loss {'Reaction outcome loss': 0.11474427868627378, 'Total loss': 0.11474427868627378}
2022-12-05 20:11:57,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:57,887 INFO:     Epoch: 91
2022-12-05 20:11:58,668 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4731501236904499, 'Total loss': 0.4731501236904499} | train loss {'Reaction outcome loss': 0.1115335169797916, 'Total loss': 0.1115335169797916}
2022-12-05 20:11:58,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:58,668 INFO:     Epoch: 92
2022-12-05 20:11:59,448 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4788047151510106, 'Total loss': 0.4788047151510106} | train loss {'Reaction outcome loss': 0.11378859910258993, 'Total loss': 0.11378859910258993}
2022-12-05 20:11:59,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:11:59,449 INFO:     Epoch: 93
2022-12-05 20:12:00,231 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4710782859907594, 'Total loss': 0.4710782859907594} | train loss {'Reaction outcome loss': 0.11432227648061807, 'Total loss': 0.11432227648061807}
2022-12-05 20:12:00,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:00,231 INFO:     Epoch: 94
2022-12-05 20:12:01,007 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4716272004121958, 'Total loss': 0.4716272004121958} | train loss {'Reaction outcome loss': 0.11233089299544265, 'Total loss': 0.11233089299544265}
2022-12-05 20:12:01,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:01,007 INFO:     Epoch: 95
2022-12-05 20:12:01,791 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4819746367460073, 'Total loss': 0.4819746367460073} | train loss {'Reaction outcome loss': 0.11459415731188215, 'Total loss': 0.11459415731188215}
2022-12-05 20:12:01,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:01,791 INFO:     Epoch: 96
2022-12-05 20:12:02,581 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46830567717552185, 'Total loss': 0.46830567717552185} | train loss {'Reaction outcome loss': 0.1127166716328471, 'Total loss': 0.1127166716328471}
2022-12-05 20:12:02,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:02,581 INFO:     Epoch: 97
2022-12-05 20:12:03,365 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4719457269407982, 'Total loss': 0.4719457269407982} | train loss {'Reaction outcome loss': 0.1123680853223825, 'Total loss': 0.1123680853223825}
2022-12-05 20:12:03,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:03,366 INFO:     Epoch: 98
2022-12-05 20:12:04,147 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4574165493249893, 'Total loss': 0.4574165493249893} | train loss {'Reaction outcome loss': 0.11192378570463081, 'Total loss': 0.11192378570463081}
2022-12-05 20:12:04,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:04,148 INFO:     Epoch: 99
2022-12-05 20:12:04,933 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4645389058562212, 'Total loss': 0.4645389058562212} | train loss {'Reaction outcome loss': 0.1116504063562597, 'Total loss': 0.1116504063562597}
2022-12-05 20:12:04,933 INFO:     Best model found after epoch 11 of 100.
2022-12-05 20:12:04,933 INFO:   Done with stage: TRAINING
2022-12-05 20:12:04,934 INFO:   Starting stage: EVALUATION
2022-12-05 20:12:05,071 INFO:   Done with stage: EVALUATION
2022-12-05 20:12:05,072 INFO:   Leaving out SEQ value Fold_9
2022-12-05 20:12:05,084 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:12:05,084 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:12:05,731 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:12:05,731 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:12:05,801 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:12:05,801 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:12:05,801 INFO:     No hyperparam tuning for this model
2022-12-05 20:12:05,801 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:12:05,801 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:12:05,802 INFO:     None feature selector for col prot
2022-12-05 20:12:05,802 INFO:     None feature selector for col prot
2022-12-05 20:12:05,802 INFO:     None feature selector for col prot
2022-12-05 20:12:05,803 INFO:     None feature selector for col chem
2022-12-05 20:12:05,803 INFO:     None feature selector for col chem
2022-12-05 20:12:05,803 INFO:     None feature selector for col chem
2022-12-05 20:12:05,803 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:12:05,803 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:12:05,805 INFO:     Number of params in model 215821
2022-12-05 20:12:05,808 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:12:05,808 INFO:   Starting stage: TRAINING
2022-12-05 20:12:05,869 INFO:     Val loss before train {'Reaction outcome loss': 1.056966711174358, 'Total loss': 1.056966711174358}
2022-12-05 20:12:05,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:05,869 INFO:     Epoch: 0
2022-12-05 20:12:06,666 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5887370769950476, 'Total loss': 0.5887370769950476} | train loss {'Reaction outcome loss': 0.7914779181422492, 'Total loss': 0.7914779181422492}
2022-12-05 20:12:06,667 INFO:     Found new best model at epoch 0
2022-12-05 20:12:06,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:06,667 INFO:     Epoch: 1
2022-12-05 20:12:07,460 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48964342204007233, 'Total loss': 0.48964342204007233} | train loss {'Reaction outcome loss': 0.5288978335466462, 'Total loss': 0.5288978335466462}
2022-12-05 20:12:07,460 INFO:     Found new best model at epoch 1
2022-12-05 20:12:07,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:07,461 INFO:     Epoch: 2
2022-12-05 20:12:08,254 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4866066514091058, 'Total loss': 0.4866066514091058} | train loss {'Reaction outcome loss': 0.4593681127581414, 'Total loss': 0.4593681127581414}
2022-12-05 20:12:08,255 INFO:     Found new best model at epoch 2
2022-12-05 20:12:08,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:08,256 INFO:     Epoch: 3
2022-12-05 20:12:09,049 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.436474739827893, 'Total loss': 0.436474739827893} | train loss {'Reaction outcome loss': 0.41724077168746515, 'Total loss': 0.41724077168746515}
2022-12-05 20:12:09,049 INFO:     Found new best model at epoch 3
2022-12-05 20:12:09,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:09,050 INFO:     Epoch: 4
2022-12-05 20:12:09,841 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4483403251929717, 'Total loss': 0.4483403251929717} | train loss {'Reaction outcome loss': 0.3854977158831455, 'Total loss': 0.3854977158831455}
2022-12-05 20:12:09,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:09,842 INFO:     Epoch: 5
2022-12-05 20:12:10,635 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4273040694269267, 'Total loss': 0.4273040694269267} | train loss {'Reaction outcome loss': 0.36322158858602344, 'Total loss': 0.36322158858602344}
2022-12-05 20:12:10,635 INFO:     Found new best model at epoch 5
2022-12-05 20:12:10,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:10,636 INFO:     Epoch: 6
2022-12-05 20:12:11,429 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42407118732279, 'Total loss': 0.42407118732279} | train loss {'Reaction outcome loss': 0.3465671913343885, 'Total loss': 0.3465671913343885}
2022-12-05 20:12:11,429 INFO:     Found new best model at epoch 6
2022-12-05 20:12:11,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:11,430 INFO:     Epoch: 7
2022-12-05 20:12:12,215 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4233277416364713, 'Total loss': 0.4233277416364713} | train loss {'Reaction outcome loss': 0.32990846626068415, 'Total loss': 0.32990846626068415}
2022-12-05 20:12:12,215 INFO:     Found new best model at epoch 7
2022-12-05 20:12:12,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:12,216 INFO:     Epoch: 8
2022-12-05 20:12:13,004 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43187090856107796, 'Total loss': 0.43187090856107796} | train loss {'Reaction outcome loss': 0.3169553700970252, 'Total loss': 0.3169553700970252}
2022-12-05 20:12:13,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:13,004 INFO:     Epoch: 9
2022-12-05 20:12:13,798 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4111756411465732, 'Total loss': 0.4111756411465732} | train loss {'Reaction outcome loss': 0.30362885864640055, 'Total loss': 0.30362885864640055}
2022-12-05 20:12:13,798 INFO:     Found new best model at epoch 9
2022-12-05 20:12:13,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:13,799 INFO:     Epoch: 10
2022-12-05 20:12:14,588 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4255090467631817, 'Total loss': 0.4255090467631817} | train loss {'Reaction outcome loss': 0.29284574280715425, 'Total loss': 0.29284574280715425}
2022-12-05 20:12:14,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:14,588 INFO:     Epoch: 11
2022-12-05 20:12:15,376 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4289603419601917, 'Total loss': 0.4289603419601917} | train loss {'Reaction outcome loss': 0.282801449540173, 'Total loss': 0.282801449540173}
2022-12-05 20:12:15,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:15,376 INFO:     Epoch: 12
2022-12-05 20:12:16,160 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41207837618210097, 'Total loss': 0.41207837618210097} | train loss {'Reaction outcome loss': 0.2727430061350467, 'Total loss': 0.2727430061350467}
2022-12-05 20:12:16,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:16,161 INFO:     Epoch: 13
2022-12-05 20:12:16,949 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4135931259529157, 'Total loss': 0.4135931259529157} | train loss {'Reaction outcome loss': 0.26257222335736613, 'Total loss': 0.26257222335736613}
2022-12-05 20:12:16,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:16,950 INFO:     Epoch: 14
2022-12-05 20:12:17,740 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4231933362104676, 'Total loss': 0.4231933362104676} | train loss {'Reaction outcome loss': 0.256602578920874, 'Total loss': 0.256602578920874}
2022-12-05 20:12:17,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:17,741 INFO:     Epoch: 15
2022-12-05 20:12:18,527 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42458761449564586, 'Total loss': 0.42458761449564586} | train loss {'Reaction outcome loss': 0.2507744211748785, 'Total loss': 0.2507744211748785}
2022-12-05 20:12:18,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:18,527 INFO:     Epoch: 16
2022-12-05 20:12:19,316 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40727478536692535, 'Total loss': 0.40727478536692535} | train loss {'Reaction outcome loss': 0.24104854274495893, 'Total loss': 0.24104854274495893}
2022-12-05 20:12:19,316 INFO:     Found new best model at epoch 16
2022-12-05 20:12:19,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:19,317 INFO:     Epoch: 17
2022-12-05 20:12:20,103 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4167868948795579, 'Total loss': 0.4167868948795579} | train loss {'Reaction outcome loss': 0.23760228484929333, 'Total loss': 0.23760228484929333}
2022-12-05 20:12:20,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:20,105 INFO:     Epoch: 18
2022-12-05 20:12:20,894 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4230417368764227, 'Total loss': 0.4230417368764227} | train loss {'Reaction outcome loss': 0.22825100766080111, 'Total loss': 0.22825100766080111}
2022-12-05 20:12:20,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:20,894 INFO:     Epoch: 19
2022-12-05 20:12:21,681 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4215296401049603, 'Total loss': 0.4215296401049603} | train loss {'Reaction outcome loss': 0.22355447593427863, 'Total loss': 0.22355447593427863}
2022-12-05 20:12:21,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:21,681 INFO:     Epoch: 20
2022-12-05 20:12:22,469 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4184512553567236, 'Total loss': 0.4184512553567236} | train loss {'Reaction outcome loss': 0.21522866696805545, 'Total loss': 0.21522866696805545}
2022-12-05 20:12:22,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:22,469 INFO:     Epoch: 21
2022-12-05 20:12:23,257 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4295258897949349, 'Total loss': 0.4295258897949349} | train loss {'Reaction outcome loss': 0.21195555638205185, 'Total loss': 0.21195555638205185}
2022-12-05 20:12:23,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:23,257 INFO:     Epoch: 22
2022-12-05 20:12:24,047 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.433377684856003, 'Total loss': 0.433377684856003} | train loss {'Reaction outcome loss': 0.2055230865232375, 'Total loss': 0.2055230865232375}
2022-12-05 20:12:24,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:24,048 INFO:     Epoch: 23
2022-12-05 20:12:24,835 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4305270226164298, 'Total loss': 0.4305270226164298} | train loss {'Reaction outcome loss': 0.20571488965498774, 'Total loss': 0.20571488965498774}
2022-12-05 20:12:24,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:24,836 INFO:     Epoch: 24
2022-12-05 20:12:25,624 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41814014688134193, 'Total loss': 0.41814014688134193} | train loss {'Reaction outcome loss': 0.21916366097053536, 'Total loss': 0.21916366097053536}
2022-12-05 20:12:25,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:25,624 INFO:     Epoch: 25
2022-12-05 20:12:26,413 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4289500108835372, 'Total loss': 0.4289500108835372} | train loss {'Reaction outcome loss': 0.20506047075124165, 'Total loss': 0.20506047075124165}
2022-12-05 20:12:26,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:26,414 INFO:     Epoch: 26
2022-12-05 20:12:27,203 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4268553778529167, 'Total loss': 0.4268553778529167} | train loss {'Reaction outcome loss': 0.19592667337099792, 'Total loss': 0.19592667337099792}
2022-12-05 20:12:27,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:27,204 INFO:     Epoch: 27
2022-12-05 20:12:27,991 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4189845523373647, 'Total loss': 0.4189845523373647} | train loss {'Reaction outcome loss': 0.19201719867978018, 'Total loss': 0.19201719867978018}
2022-12-05 20:12:27,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:27,991 INFO:     Epoch: 28
2022-12-05 20:12:28,777 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4390586573969234, 'Total loss': 0.4390586573969234} | train loss {'Reaction outcome loss': 0.1865692125022532, 'Total loss': 0.1865692125022532}
2022-12-05 20:12:28,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:28,777 INFO:     Epoch: 29
2022-12-05 20:12:29,565 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44155750796198845, 'Total loss': 0.44155750796198845} | train loss {'Reaction outcome loss': 0.19123053508490204, 'Total loss': 0.19123053508490204}
2022-12-05 20:12:29,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:29,565 INFO:     Epoch: 30
2022-12-05 20:12:30,356 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4206090569496155, 'Total loss': 0.4206090569496155} | train loss {'Reaction outcome loss': 0.18735752808239295, 'Total loss': 0.18735752808239295}
2022-12-05 20:12:30,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:30,356 INFO:     Epoch: 31
2022-12-05 20:12:31,145 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4270639158891175, 'Total loss': 0.4270639158891175} | train loss {'Reaction outcome loss': 0.17988118700502131, 'Total loss': 0.17988118700502131}
2022-12-05 20:12:31,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:31,145 INFO:     Epoch: 32
2022-12-05 20:12:31,934 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4362630695104599, 'Total loss': 0.4362630695104599} | train loss {'Reaction outcome loss': 0.17471431783939662, 'Total loss': 0.17471431783939662}
2022-12-05 20:12:31,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:31,934 INFO:     Epoch: 33
2022-12-05 20:12:32,720 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44137977808713913, 'Total loss': 0.44137977808713913} | train loss {'Reaction outcome loss': 0.17570942011496868, 'Total loss': 0.17570942011496868}
2022-12-05 20:12:32,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:32,720 INFO:     Epoch: 34
2022-12-05 20:12:33,505 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4423859884793108, 'Total loss': 0.4423859884793108} | train loss {'Reaction outcome loss': 0.17112090313139744, 'Total loss': 0.17112090313139744}
2022-12-05 20:12:33,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:33,506 INFO:     Epoch: 35
2022-12-05 20:12:34,295 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43922143802046776, 'Total loss': 0.43922143802046776} | train loss {'Reaction outcome loss': 0.17321581287905272, 'Total loss': 0.17321581287905272}
2022-12-05 20:12:34,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:34,295 INFO:     Epoch: 36
2022-12-05 20:12:35,084 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44474901783872733, 'Total loss': 0.44474901783872733} | train loss {'Reaction outcome loss': 0.17554764143428822, 'Total loss': 0.17554764143428822}
2022-12-05 20:12:35,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:35,085 INFO:     Epoch: 37
2022-12-05 20:12:35,873 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4522259731523015, 'Total loss': 0.4522259731523015} | train loss {'Reaction outcome loss': 0.1749536653392409, 'Total loss': 0.1749536653392409}
2022-12-05 20:12:35,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:35,873 INFO:     Epoch: 38
2022-12-05 20:12:36,659 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4471061388877305, 'Total loss': 0.4471061388877305} | train loss {'Reaction outcome loss': 0.1679799944135975, 'Total loss': 0.1679799944135975}
2022-12-05 20:12:36,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:36,659 INFO:     Epoch: 39
2022-12-05 20:12:37,445 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44513919339938596, 'Total loss': 0.44513919339938596} | train loss {'Reaction outcome loss': 0.1612344658688495, 'Total loss': 0.1612344658688495}
2022-12-05 20:12:37,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:37,445 INFO:     Epoch: 40
2022-12-05 20:12:38,234 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.446050880307501, 'Total loss': 0.446050880307501} | train loss {'Reaction outcome loss': 0.163321342360726, 'Total loss': 0.163321342360726}
2022-12-05 20:12:38,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:38,235 INFO:     Epoch: 41
2022-12-05 20:12:39,023 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4394107559187846, 'Total loss': 0.4394107559187846} | train loss {'Reaction outcome loss': 0.16018104485258733, 'Total loss': 0.16018104485258733}
2022-12-05 20:12:39,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:39,024 INFO:     Epoch: 42
2022-12-05 20:12:39,813 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4426238384436477, 'Total loss': 0.4426238384436477} | train loss {'Reaction outcome loss': 0.15882538598754747, 'Total loss': 0.15882538598754747}
2022-12-05 20:12:39,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:39,813 INFO:     Epoch: 43
2022-12-05 20:12:40,600 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44302920675413177, 'Total loss': 0.44302920675413177} | train loss {'Reaction outcome loss': 0.16395173573994684, 'Total loss': 0.16395173573994684}
2022-12-05 20:12:40,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:40,600 INFO:     Epoch: 44
2022-12-05 20:12:41,393 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4454065518961711, 'Total loss': 0.4454065518961711} | train loss {'Reaction outcome loss': 0.15781067114564692, 'Total loss': 0.15781067114564692}
2022-12-05 20:12:41,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:41,393 INFO:     Epoch: 45
2022-12-05 20:12:42,188 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4400059027089314, 'Total loss': 0.4400059027089314} | train loss {'Reaction outcome loss': 0.15760636189009858, 'Total loss': 0.15760636189009858}
2022-12-05 20:12:42,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:42,188 INFO:     Epoch: 46
2022-12-05 20:12:42,974 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4393319824541157, 'Total loss': 0.4393319824541157} | train loss {'Reaction outcome loss': 0.1532564847419031, 'Total loss': 0.1532564847419031}
2022-12-05 20:12:42,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:42,975 INFO:     Epoch: 47
2022-12-05 20:12:43,760 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45117130977186287, 'Total loss': 0.45117130977186287} | train loss {'Reaction outcome loss': 0.15337060390017654, 'Total loss': 0.15337060390017654}
2022-12-05 20:12:43,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:43,760 INFO:     Epoch: 48
2022-12-05 20:12:44,549 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44211141765117645, 'Total loss': 0.44211141765117645} | train loss {'Reaction outcome loss': 0.15299314565142155, 'Total loss': 0.15299314565142155}
2022-12-05 20:12:44,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:44,549 INFO:     Epoch: 49
2022-12-05 20:12:45,336 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4459408602931283, 'Total loss': 0.4459408602931283} | train loss {'Reaction outcome loss': 0.15461976263626867, 'Total loss': 0.15461976263626867}
2022-12-05 20:12:45,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:45,336 INFO:     Epoch: 50
2022-12-05 20:12:46,123 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44363457235423004, 'Total loss': 0.44363457235423004} | train loss {'Reaction outcome loss': 0.14739615597332326, 'Total loss': 0.14739615597332326}
2022-12-05 20:12:46,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:46,123 INFO:     Epoch: 51
2022-12-05 20:12:46,915 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4440103244375099, 'Total loss': 0.4440103244375099} | train loss {'Reaction outcome loss': 0.14953464015126833, 'Total loss': 0.14953464015126833}
2022-12-05 20:12:46,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:46,915 INFO:     Epoch: 52
2022-12-05 20:12:47,708 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4398984983563423, 'Total loss': 0.4398984983563423} | train loss {'Reaction outcome loss': 0.1498004804357796, 'Total loss': 0.1498004804357796}
2022-12-05 20:12:47,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:47,708 INFO:     Epoch: 53
2022-12-05 20:12:48,502 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44893944466655905, 'Total loss': 0.44893944466655905} | train loss {'Reaction outcome loss': 0.14978032809520056, 'Total loss': 0.14978032809520056}
2022-12-05 20:12:48,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:48,502 INFO:     Epoch: 54
2022-12-05 20:12:49,292 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4608140103518963, 'Total loss': 0.4608140103518963} | train loss {'Reaction outcome loss': 0.15355876292505485, 'Total loss': 0.15355876292505485}
2022-12-05 20:12:49,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:49,292 INFO:     Epoch: 55
2022-12-05 20:12:50,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4509905587712472, 'Total loss': 0.4509905587712472} | train loss {'Reaction outcome loss': 0.14746036388070477, 'Total loss': 0.14746036388070477}
2022-12-05 20:12:50,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:50,082 INFO:     Epoch: 56
2022-12-05 20:12:50,872 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4442763389511542, 'Total loss': 0.4442763389511542} | train loss {'Reaction outcome loss': 0.15106090857988594, 'Total loss': 0.15106090857988594}
2022-12-05 20:12:50,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:50,873 INFO:     Epoch: 57
2022-12-05 20:12:51,661 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43727507814764977, 'Total loss': 0.43727507814764977} | train loss {'Reaction outcome loss': 0.14590095609486828, 'Total loss': 0.14590095609486828}
2022-12-05 20:12:51,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:51,661 INFO:     Epoch: 58
2022-12-05 20:12:52,451 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4502234607934952, 'Total loss': 0.4502234607934952} | train loss {'Reaction outcome loss': 0.1458881597679395, 'Total loss': 0.1458881597679395}
2022-12-05 20:12:52,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:52,451 INFO:     Epoch: 59
2022-12-05 20:12:53,236 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44165208258412103, 'Total loss': 0.44165208258412103} | train loss {'Reaction outcome loss': 0.14695177790576872, 'Total loss': 0.14695177790576872}
2022-12-05 20:12:53,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:53,237 INFO:     Epoch: 60
2022-12-05 20:12:54,026 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46264559403061867, 'Total loss': 0.46264559403061867} | train loss {'Reaction outcome loss': 0.1400616227569971, 'Total loss': 0.1400616227569971}
2022-12-05 20:12:54,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:54,026 INFO:     Epoch: 61
2022-12-05 20:12:54,816 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45936398106542503, 'Total loss': 0.45936398106542503} | train loss {'Reaction outcome loss': 0.13995703865551515, 'Total loss': 0.13995703865551515}
2022-12-05 20:12:54,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:54,817 INFO:     Epoch: 62
2022-12-05 20:12:55,611 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44954393499276857, 'Total loss': 0.44954393499276857} | train loss {'Reaction outcome loss': 0.14681836727795453, 'Total loss': 0.14681836727795453}
2022-12-05 20:12:55,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:55,612 INFO:     Epoch: 63
2022-12-05 20:12:56,400 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45310555974190886, 'Total loss': 0.45310555974190886} | train loss {'Reaction outcome loss': 0.13963055777314462, 'Total loss': 0.13963055777314462}
2022-12-05 20:12:56,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:56,400 INFO:     Epoch: 64
2022-12-05 20:12:57,187 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.455129618502476, 'Total loss': 0.455129618502476} | train loss {'Reaction outcome loss': 0.13945026167853158, 'Total loss': 0.13945026167853158}
2022-12-05 20:12:57,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:57,188 INFO:     Epoch: 65
2022-12-05 20:12:57,980 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.458318100056865, 'Total loss': 0.458318100056865} | train loss {'Reaction outcome loss': 0.13726756925343986, 'Total loss': 0.13726756925343986}
2022-12-05 20:12:57,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:57,980 INFO:     Epoch: 66
2022-12-05 20:12:58,767 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4484483144161376, 'Total loss': 0.4484483144161376} | train loss {'Reaction outcome loss': 0.13969752491123763, 'Total loss': 0.13969752491123763}
2022-12-05 20:12:58,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:58,767 INFO:     Epoch: 67
2022-12-05 20:12:59,555 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4579210157760165, 'Total loss': 0.4579210157760165} | train loss {'Reaction outcome loss': 0.13669901016014646, 'Total loss': 0.13669901016014646}
2022-12-05 20:12:59,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:12:59,555 INFO:     Epoch: 68
2022-12-05 20:13:00,349 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46358952739021997, 'Total loss': 0.46358952739021997} | train loss {'Reaction outcome loss': 0.13682255416972797, 'Total loss': 0.13682255416972797}
2022-12-05 20:13:00,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:00,349 INFO:     Epoch: 69
2022-12-05 20:13:01,141 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45480984347787773, 'Total loss': 0.45480984347787773} | train loss {'Reaction outcome loss': 0.13862654223645987, 'Total loss': 0.13862654223645987}
2022-12-05 20:13:01,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:01,142 INFO:     Epoch: 70
2022-12-05 20:13:01,931 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45756939002736047, 'Total loss': 0.45756939002736047} | train loss {'Reaction outcome loss': 0.13419598315654865, 'Total loss': 0.13419598315654865}
2022-12-05 20:13:01,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:01,931 INFO:     Epoch: 71
2022-12-05 20:13:02,723 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4563475745645436, 'Total loss': 0.4563475745645436} | train loss {'Reaction outcome loss': 0.13558060164197616, 'Total loss': 0.13558060164197616}
2022-12-05 20:13:02,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:02,723 INFO:     Epoch: 72
2022-12-05 20:13:03,511 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4454202171076428, 'Total loss': 0.4454202171076428} | train loss {'Reaction outcome loss': 0.13579798594629958, 'Total loss': 0.13579798594629958}
2022-12-05 20:13:03,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:03,511 INFO:     Epoch: 73
2022-12-05 20:13:04,298 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45472165468064224, 'Total loss': 0.45472165468064224} | train loss {'Reaction outcome loss': 0.1347374672669661, 'Total loss': 0.1347374672669661}
2022-12-05 20:13:04,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:04,298 INFO:     Epoch: 74
2022-12-05 20:13:05,085 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.443433941765265, 'Total loss': 0.443433941765265} | train loss {'Reaction outcome loss': 0.13487308566375572, 'Total loss': 0.13487308566375572}
2022-12-05 20:13:05,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:05,085 INFO:     Epoch: 75
2022-12-05 20:13:05,876 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4624070850285617, 'Total loss': 0.4624070850285617} | train loss {'Reaction outcome loss': 0.13546137099233474, 'Total loss': 0.13546137099233474}
2022-12-05 20:13:05,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:05,876 INFO:     Epoch: 76
2022-12-05 20:13:06,663 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45120269737460394, 'Total loss': 0.45120269737460394} | train loss {'Reaction outcome loss': 0.13304910411387078, 'Total loss': 0.13304910411387078}
2022-12-05 20:13:06,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:06,663 INFO:     Epoch: 77
2022-12-05 20:13:07,453 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4587572636929425, 'Total loss': 0.4587572636929425} | train loss {'Reaction outcome loss': 0.13220747769150415, 'Total loss': 0.13220747769150415}
2022-12-05 20:13:07,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:07,453 INFO:     Epoch: 78
2022-12-05 20:13:08,243 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4621514417231083, 'Total loss': 0.4621514417231083} | train loss {'Reaction outcome loss': 0.1314940417208049, 'Total loss': 0.1314940417208049}
2022-12-05 20:13:08,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:08,243 INFO:     Epoch: 79
2022-12-05 20:13:09,033 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45782149278304796, 'Total loss': 0.45782149278304796} | train loss {'Reaction outcome loss': 0.1307861776833954, 'Total loss': 0.1307861776833954}
2022-12-05 20:13:09,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:09,033 INFO:     Epoch: 80
2022-12-05 20:13:09,826 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4620312489569187, 'Total loss': 0.4620312489569187} | train loss {'Reaction outcome loss': 0.131184990046478, 'Total loss': 0.131184990046478}
2022-12-05 20:13:09,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:09,827 INFO:     Epoch: 81
2022-12-05 20:13:10,614 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45037559453736653, 'Total loss': 0.45037559453736653} | train loss {'Reaction outcome loss': 0.1317540250826054, 'Total loss': 0.1317540250826054}
2022-12-05 20:13:10,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:10,614 INFO:     Epoch: 82
2022-12-05 20:13:11,406 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4673979187553579, 'Total loss': 0.4673979187553579} | train loss {'Reaction outcome loss': 0.13176731452315685, 'Total loss': 0.13176731452315685}
2022-12-05 20:13:11,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:11,406 INFO:     Epoch: 83
2022-12-05 20:13:12,193 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.463440749455582, 'Total loss': 0.463440749455582} | train loss {'Reaction outcome loss': 0.12805692983512212, 'Total loss': 0.12805692983512212}
2022-12-05 20:13:12,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:12,193 INFO:     Epoch: 84
2022-12-05 20:13:12,988 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4592832550406456, 'Total loss': 0.4592832550406456} | train loss {'Reaction outcome loss': 0.13038408613635552, 'Total loss': 0.13038408613635552}
2022-12-05 20:13:12,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:12,988 INFO:     Epoch: 85
2022-12-05 20:13:13,785 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.467869007113305, 'Total loss': 0.467869007113305} | train loss {'Reaction outcome loss': 0.12938709689967848, 'Total loss': 0.12938709689967848}
2022-12-05 20:13:13,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:13,785 INFO:     Epoch: 86
2022-12-05 20:13:14,575 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4641909551891414, 'Total loss': 0.4641909551891414} | train loss {'Reaction outcome loss': 0.13247197597977603, 'Total loss': 0.13247197597977603}
2022-12-05 20:13:14,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:14,575 INFO:     Epoch: 87
2022-12-05 20:13:15,364 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4412289238111539, 'Total loss': 0.4412289238111539} | train loss {'Reaction outcome loss': 0.1350427335316715, 'Total loss': 0.1350427335316715}
2022-12-05 20:13:15,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:15,365 INFO:     Epoch: 88
2022-12-05 20:13:16,152 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44325277547944675, 'Total loss': 0.44325277547944675} | train loss {'Reaction outcome loss': 0.13021533582020203, 'Total loss': 0.13021533582020203}
2022-12-05 20:13:16,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:16,152 INFO:     Epoch: 89
2022-12-05 20:13:16,942 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4708691926842386, 'Total loss': 0.4708691926842386} | train loss {'Reaction outcome loss': 0.12740589669238217, 'Total loss': 0.12740589669238217}
2022-12-05 20:13:16,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:16,942 INFO:     Epoch: 90
2022-12-05 20:13:17,729 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4587647919966416, 'Total loss': 0.4587647919966416} | train loss {'Reaction outcome loss': 0.12638220336026162, 'Total loss': 0.12638220336026162}
2022-12-05 20:13:17,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:17,729 INFO:     Epoch: 91
2022-12-05 20:13:18,521 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4557520432228392, 'Total loss': 0.4557520432228392} | train loss {'Reaction outcome loss': 0.12759103813597006, 'Total loss': 0.12759103813597006}
2022-12-05 20:13:18,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:18,521 INFO:     Epoch: 92
2022-12-05 20:13:19,315 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4544031457467513, 'Total loss': 0.4544031457467513} | train loss {'Reaction outcome loss': 0.12581818638348702, 'Total loss': 0.12581818638348702}
2022-12-05 20:13:19,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:19,315 INFO:     Epoch: 93
2022-12-05 20:13:20,105 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4636651096357541, 'Total loss': 0.4636651096357541} | train loss {'Reaction outcome loss': 0.1268735020543988, 'Total loss': 0.1268735020543988}
2022-12-05 20:13:20,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:20,106 INFO:     Epoch: 94
2022-12-05 20:13:20,896 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46717526323416014, 'Total loss': 0.46717526323416014} | train loss {'Reaction outcome loss': 0.12630827342883988, 'Total loss': 0.12630827342883988}
2022-12-05 20:13:20,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:20,896 INFO:     Epoch: 95
2022-12-05 20:13:21,683 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4739606339823116, 'Total loss': 0.4739606339823116} | train loss {'Reaction outcome loss': 0.12579946256118266, 'Total loss': 0.12579946256118266}
2022-12-05 20:13:21,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:21,684 INFO:     Epoch: 96
2022-12-05 20:13:22,474 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4660050215368921, 'Total loss': 0.4660050215368921} | train loss {'Reaction outcome loss': 0.1255259750757804, 'Total loss': 0.1255259750757804}
2022-12-05 20:13:22,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:22,475 INFO:     Epoch: 97
2022-12-05 20:13:23,261 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45688472264869645, 'Total loss': 0.45688472264869645} | train loss {'Reaction outcome loss': 0.1279930078183199, 'Total loss': 0.1279930078183199}
2022-12-05 20:13:23,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:23,261 INFO:     Epoch: 98
2022-12-05 20:13:24,048 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46936409530991857, 'Total loss': 0.46936409530991857} | train loss {'Reaction outcome loss': 0.13252569788591823, 'Total loss': 0.13252569788591823}
2022-12-05 20:13:24,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:24,048 INFO:     Epoch: 99
2022-12-05 20:13:24,835 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46932414682074025, 'Total loss': 0.46932414682074025} | train loss {'Reaction outcome loss': 0.1289966140198804, 'Total loss': 0.1289966140198804}
2022-12-05 20:13:24,835 INFO:     Best model found after epoch 17 of 100.
2022-12-05 20:13:24,835 INFO:   Done with stage: TRAINING
2022-12-05 20:13:24,835 INFO:   Starting stage: EVALUATION
2022-12-05 20:13:24,961 INFO:   Done with stage: EVALUATION
2022-12-05 20:13:24,969 INFO:   Leaving out SEQ value Fold_0
2022-12-05 20:13:24,982 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:13:24,982 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:13:25,617 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:13:25,617 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:13:25,685 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:13:25,685 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:13:25,685 INFO:     No hyperparam tuning for this model
2022-12-05 20:13:25,685 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:13:25,685 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:13:25,686 INFO:     None feature selector for col prot
2022-12-05 20:13:25,686 INFO:     None feature selector for col prot
2022-12-05 20:13:25,686 INFO:     None feature selector for col prot
2022-12-05 20:13:25,687 INFO:     None feature selector for col chem
2022-12-05 20:13:25,687 INFO:     None feature selector for col chem
2022-12-05 20:13:25,687 INFO:     None feature selector for col chem
2022-12-05 20:13:25,687 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:13:25,687 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:13:25,689 INFO:     Number of params in model 215821
2022-12-05 20:13:25,692 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:13:25,692 INFO:   Starting stage: TRAINING
2022-12-05 20:13:25,752 INFO:     Val loss before train {'Reaction outcome loss': 0.9620958200909875, 'Total loss': 0.9620958200909875}
2022-12-05 20:13:25,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:25,753 INFO:     Epoch: 0
2022-12-05 20:13:26,543 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5880711142989722, 'Total loss': 0.5880711142989722} | train loss {'Reaction outcome loss': 0.8055329044096866, 'Total loss': 0.8055329044096866}
2022-12-05 20:13:26,543 INFO:     Found new best model at epoch 0
2022-12-05 20:13:26,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:26,544 INFO:     Epoch: 1
2022-12-05 20:13:27,334 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5274031406099146, 'Total loss': 0.5274031406099146} | train loss {'Reaction outcome loss': 0.5449837250748144, 'Total loss': 0.5449837250748144}
2022-12-05 20:13:27,334 INFO:     Found new best model at epoch 1
2022-12-05 20:13:27,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:27,335 INFO:     Epoch: 2
2022-12-05 20:13:28,121 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4811334430494092, 'Total loss': 0.4811334430494092} | train loss {'Reaction outcome loss': 0.47365763468238026, 'Total loss': 0.47365763468238026}
2022-12-05 20:13:28,121 INFO:     Found new best model at epoch 2
2022-12-05 20:13:28,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:28,122 INFO:     Epoch: 3
2022-12-05 20:13:28,907 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4615196677094156, 'Total loss': 0.4615196677094156} | train loss {'Reaction outcome loss': 0.42740449443250245, 'Total loss': 0.42740449443250245}
2022-12-05 20:13:28,908 INFO:     Found new best model at epoch 3
2022-12-05 20:13:28,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:28,909 INFO:     Epoch: 4
2022-12-05 20:13:29,697 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4572381776842204, 'Total loss': 0.4572381776842204} | train loss {'Reaction outcome loss': 0.3976996333492912, 'Total loss': 0.3976996333492912}
2022-12-05 20:13:29,697 INFO:     Found new best model at epoch 4
2022-12-05 20:13:29,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:29,698 INFO:     Epoch: 5
2022-12-05 20:13:30,484 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44545611773024907, 'Total loss': 0.44545611773024907} | train loss {'Reaction outcome loss': 0.3753102283608093, 'Total loss': 0.3753102283608093}
2022-12-05 20:13:30,484 INFO:     Found new best model at epoch 5
2022-12-05 20:13:30,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:30,485 INFO:     Epoch: 6
2022-12-05 20:13:31,272 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4277507911690257, 'Total loss': 0.4277507911690257} | train loss {'Reaction outcome loss': 0.3641766240963569, 'Total loss': 0.3641766240963569}
2022-12-05 20:13:31,272 INFO:     Found new best model at epoch 6
2022-12-05 20:13:31,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:31,273 INFO:     Epoch: 7
2022-12-05 20:13:32,066 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4245667240836404, 'Total loss': 0.4245667240836404} | train loss {'Reaction outcome loss': 0.33955591512836425, 'Total loss': 0.33955591512836425}
2022-12-05 20:13:32,066 INFO:     Found new best model at epoch 7
2022-12-05 20:13:32,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:32,067 INFO:     Epoch: 8
2022-12-05 20:13:32,858 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4220752902328968, 'Total loss': 0.4220752902328968} | train loss {'Reaction outcome loss': 0.3233154908063923, 'Total loss': 0.3233154908063923}
2022-12-05 20:13:32,859 INFO:     Found new best model at epoch 8
2022-12-05 20:13:32,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:32,860 INFO:     Epoch: 9
2022-12-05 20:13:33,645 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41874900460243225, 'Total loss': 0.41874900460243225} | train loss {'Reaction outcome loss': 0.3072081907739041, 'Total loss': 0.3072081907739041}
2022-12-05 20:13:33,645 INFO:     Found new best model at epoch 9
2022-12-05 20:13:33,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:33,646 INFO:     Epoch: 10
2022-12-05 20:13:34,436 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4189006354321133, 'Total loss': 0.4189006354321133} | train loss {'Reaction outcome loss': 0.2933383694291869, 'Total loss': 0.2933383694291869}
2022-12-05 20:13:34,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:34,436 INFO:     Epoch: 11
2022-12-05 20:13:35,221 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4125962553715164, 'Total loss': 0.4125962553715164} | train loss {'Reaction outcome loss': 0.28613730574305724, 'Total loss': 0.28613730574305724}
2022-12-05 20:13:35,221 INFO:     Found new best model at epoch 11
2022-12-05 20:13:35,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:35,222 INFO:     Epoch: 12
2022-12-05 20:13:36,013 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4223137701099569, 'Total loss': 0.4223137701099569} | train loss {'Reaction outcome loss': 0.278219778151044, 'Total loss': 0.278219778151044}
2022-12-05 20:13:36,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:36,014 INFO:     Epoch: 13
2022-12-05 20:13:36,800 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4140094511888244, 'Total loss': 0.4140094511888244} | train loss {'Reaction outcome loss': 0.26771504643113025, 'Total loss': 0.26771504643113025}
2022-12-05 20:13:36,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:36,800 INFO:     Epoch: 14
2022-12-05 20:13:37,589 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4162998033518141, 'Total loss': 0.4162998033518141} | train loss {'Reaction outcome loss': 0.25441956256142995, 'Total loss': 0.25441956256142995}
2022-12-05 20:13:37,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:37,589 INFO:     Epoch: 15
2022-12-05 20:13:38,375 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4196438626809554, 'Total loss': 0.4196438626809554} | train loss {'Reaction outcome loss': 0.2478465181106121, 'Total loss': 0.2478465181106121}
2022-12-05 20:13:38,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:38,375 INFO:     Epoch: 16
2022-12-05 20:13:39,161 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4165330166843804, 'Total loss': 0.4165330166843804} | train loss {'Reaction outcome loss': 0.24167584543406723, 'Total loss': 0.24167584543406723}
2022-12-05 20:13:39,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:39,161 INFO:     Epoch: 17
2022-12-05 20:13:39,950 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.423281423070214, 'Total loss': 0.423281423070214} | train loss {'Reaction outcome loss': 0.23803481534651297, 'Total loss': 0.23803481534651297}
2022-12-05 20:13:39,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:39,951 INFO:     Epoch: 18
2022-12-05 20:13:40,739 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42924320765516977, 'Total loss': 0.42924320765516977} | train loss {'Reaction outcome loss': 0.22872968073858907, 'Total loss': 0.22872968073858907}
2022-12-05 20:13:40,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:40,739 INFO:     Epoch: 19
2022-12-05 20:13:41,530 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4301677928729491, 'Total loss': 0.4301677928729491} | train loss {'Reaction outcome loss': 0.22820745189843872, 'Total loss': 0.22820745189843872}
2022-12-05 20:13:41,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:41,531 INFO:     Epoch: 20
2022-12-05 20:13:42,321 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4212545857510783, 'Total loss': 0.4212545857510783} | train loss {'Reaction outcome loss': 0.22500203887702, 'Total loss': 0.22500203887702}
2022-12-05 20:13:42,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:42,321 INFO:     Epoch: 21
2022-12-05 20:13:43,111 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43461212854493747, 'Total loss': 0.43461212854493747} | train loss {'Reaction outcome loss': 0.2176246906400692, 'Total loss': 0.2176246906400692}
2022-12-05 20:13:43,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:43,112 INFO:     Epoch: 22
2022-12-05 20:13:43,911 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43268271298571065, 'Total loss': 0.43268271298571065} | train loss {'Reaction outcome loss': 0.21244853645985426, 'Total loss': 0.21244853645985426}
2022-12-05 20:13:43,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:43,912 INFO:     Epoch: 23
2022-12-05 20:13:44,709 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41304340213537216, 'Total loss': 0.41304340213537216} | train loss {'Reaction outcome loss': 0.2068278397610675, 'Total loss': 0.2068278397610675}
2022-12-05 20:13:44,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:44,709 INFO:     Epoch: 24
2022-12-05 20:13:45,499 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4265261311084032, 'Total loss': 0.4265261311084032} | train loss {'Reaction outcome loss': 0.20145737817171613, 'Total loss': 0.20145737817171613}
2022-12-05 20:13:45,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:45,499 INFO:     Epoch: 25
2022-12-05 20:13:46,291 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42880746265026654, 'Total loss': 0.42880746265026654} | train loss {'Reaction outcome loss': 0.19818360003433472, 'Total loss': 0.19818360003433472}
2022-12-05 20:13:46,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:46,291 INFO:     Epoch: 26
2022-12-05 20:13:47,086 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4362572631375356, 'Total loss': 0.4362572631375356} | train loss {'Reaction outcome loss': 0.1939867486581508, 'Total loss': 0.1939867486581508}
2022-12-05 20:13:47,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:47,086 INFO:     Epoch: 27
2022-12-05 20:13:47,884 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41736888004974887, 'Total loss': 0.41736888004974887} | train loss {'Reaction outcome loss': 0.1891637540682547, 'Total loss': 0.1891637540682547}
2022-12-05 20:13:47,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:47,884 INFO:     Epoch: 28
2022-12-05 20:13:48,683 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4345097423277118, 'Total loss': 0.4345097423277118} | train loss {'Reaction outcome loss': 0.18556392051068396, 'Total loss': 0.18556392051068396}
2022-12-05 20:13:48,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:48,683 INFO:     Epoch: 29
2022-12-05 20:13:49,474 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4368916062468832, 'Total loss': 0.4368916062468832} | train loss {'Reaction outcome loss': 0.19054553259224424, 'Total loss': 0.19054553259224424}
2022-12-05 20:13:49,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:49,474 INFO:     Epoch: 30
2022-12-05 20:13:50,265 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4150596943429925, 'Total loss': 0.4150596943429925} | train loss {'Reaction outcome loss': 0.18621007763301795, 'Total loss': 0.18621007763301795}
2022-12-05 20:13:50,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:50,265 INFO:     Epoch: 31
2022-12-05 20:13:51,059 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4305537830699574, 'Total loss': 0.4305537830699574} | train loss {'Reaction outcome loss': 0.1829743689672667, 'Total loss': 0.1829743689672667}
2022-12-05 20:13:51,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:51,059 INFO:     Epoch: 32
2022-12-05 20:13:51,849 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42536933245983993, 'Total loss': 0.42536933245983993} | train loss {'Reaction outcome loss': 0.17842844740378289, 'Total loss': 0.17842844740378289}
2022-12-05 20:13:51,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:51,850 INFO:     Epoch: 33
2022-12-05 20:13:52,641 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45367265899072995, 'Total loss': 0.45367265899072995} | train loss {'Reaction outcome loss': 0.1741558694948069, 'Total loss': 0.1741558694948069}
2022-12-05 20:13:52,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:52,641 INFO:     Epoch: 34
2022-12-05 20:13:53,431 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4218424731357531, 'Total loss': 0.4218424731357531} | train loss {'Reaction outcome loss': 0.1756295533209798, 'Total loss': 0.1756295533209798}
2022-12-05 20:13:53,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:53,432 INFO:     Epoch: 35
2022-12-05 20:13:54,224 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4301043672656471, 'Total loss': 0.4301043672656471} | train loss {'Reaction outcome loss': 0.17348078915826703, 'Total loss': 0.17348078915826703}
2022-12-05 20:13:54,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:54,225 INFO:     Epoch: 36
2022-12-05 20:13:55,014 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41823517327958887, 'Total loss': 0.41823517327958887} | train loss {'Reaction outcome loss': 0.1747592407682164, 'Total loss': 0.1747592407682164}
2022-12-05 20:13:55,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:55,014 INFO:     Epoch: 37
2022-12-05 20:13:55,802 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44882283495231107, 'Total loss': 0.44882283495231107} | train loss {'Reaction outcome loss': 0.1684860790427397, 'Total loss': 0.1684860790427397}
2022-12-05 20:13:55,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:55,803 INFO:     Epoch: 38
2022-12-05 20:13:56,592 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4297893409701911, 'Total loss': 0.4297893409701911} | train loss {'Reaction outcome loss': 0.16913509496340626, 'Total loss': 0.16913509496340626}
2022-12-05 20:13:56,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:56,592 INFO:     Epoch: 39
2022-12-05 20:13:57,381 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44166460463946516, 'Total loss': 0.44166460463946516} | train loss {'Reaction outcome loss': 0.1628554944733256, 'Total loss': 0.1628554944733256}
2022-12-05 20:13:57,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:57,382 INFO:     Epoch: 40
2022-12-05 20:13:58,167 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41848741336302325, 'Total loss': 0.41848741336302325} | train loss {'Reaction outcome loss': 0.1644566738940323, 'Total loss': 0.1644566738940323}
2022-12-05 20:13:58,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:58,167 INFO:     Epoch: 41
2022-12-05 20:13:58,956 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.429644719443538, 'Total loss': 0.429644719443538} | train loss {'Reaction outcome loss': 0.16127598967011036, 'Total loss': 0.16127598967011036}
2022-12-05 20:13:58,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:58,957 INFO:     Epoch: 42
2022-12-05 20:13:59,750 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43906599367884075, 'Total loss': 0.43906599367884075} | train loss {'Reaction outcome loss': 0.16205657246383096, 'Total loss': 0.16205657246383096}
2022-12-05 20:13:59,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:13:59,751 INFO:     Epoch: 43
2022-12-05 20:14:00,543 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43155440874397755, 'Total loss': 0.43155440874397755} | train loss {'Reaction outcome loss': 0.15698268567966034, 'Total loss': 0.15698268567966034}
2022-12-05 20:14:00,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:00,543 INFO:     Epoch: 44
2022-12-05 20:14:01,334 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42956113400445745, 'Total loss': 0.42956113400445745} | train loss {'Reaction outcome loss': 0.15732558365715177, 'Total loss': 0.15732558365715177}
2022-12-05 20:14:01,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:01,334 INFO:     Epoch: 45
2022-12-05 20:14:02,124 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4424992960623719, 'Total loss': 0.4424992960623719} | train loss {'Reaction outcome loss': 0.1538701353421216, 'Total loss': 0.1538701353421216}
2022-12-05 20:14:02,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:02,125 INFO:     Epoch: 46
2022-12-05 20:14:02,914 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42690215090459044, 'Total loss': 0.42690215090459044} | train loss {'Reaction outcome loss': 0.15347699915895027, 'Total loss': 0.15347699915895027}
2022-12-05 20:14:02,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:02,915 INFO:     Epoch: 47
2022-12-05 20:14:03,702 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4469844400882721, 'Total loss': 0.4469844400882721} | train loss {'Reaction outcome loss': 0.15576971351708235, 'Total loss': 0.15576971351708235}
2022-12-05 20:14:03,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:03,703 INFO:     Epoch: 48
2022-12-05 20:14:04,489 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4293593909930099, 'Total loss': 0.4293593909930099} | train loss {'Reaction outcome loss': 0.1534248145923079, 'Total loss': 0.1534248145923079}
2022-12-05 20:14:04,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:04,489 INFO:     Epoch: 49
2022-12-05 20:14:05,275 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4224898202175444, 'Total loss': 0.4224898202175444} | train loss {'Reaction outcome loss': 0.15471637243619904, 'Total loss': 0.15471637243619904}
2022-12-05 20:14:05,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:05,275 INFO:     Epoch: 50
2022-12-05 20:14:06,061 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4343966492875056, 'Total loss': 0.4343966492875056} | train loss {'Reaction outcome loss': 0.15026637672744542, 'Total loss': 0.15026637672744542}
2022-12-05 20:14:06,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:06,061 INFO:     Epoch: 51
2022-12-05 20:14:06,851 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43967609547755937, 'Total loss': 0.43967609547755937} | train loss {'Reaction outcome loss': 0.14858308810785956, 'Total loss': 0.14858308810785956}
2022-12-05 20:14:06,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:06,851 INFO:     Epoch: 52
2022-12-05 20:14:07,640 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4359464535320347, 'Total loss': 0.4359464535320347} | train loss {'Reaction outcome loss': 0.1489030329156139, 'Total loss': 0.1489030329156139}
2022-12-05 20:14:07,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:07,640 INFO:     Epoch: 53
2022-12-05 20:14:08,430 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42095342481678183, 'Total loss': 0.42095342481678183} | train loss {'Reaction outcome loss': 0.14951355789829543, 'Total loss': 0.14951355789829543}
2022-12-05 20:14:08,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:08,430 INFO:     Epoch: 54
2022-12-05 20:14:09,221 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43209548091346567, 'Total loss': 0.43209548091346567} | train loss {'Reaction outcome loss': 0.14542890239039413, 'Total loss': 0.14542890239039413}
2022-12-05 20:14:09,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:09,221 INFO:     Epoch: 55
2022-12-05 20:14:10,011 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42838859219442715, 'Total loss': 0.42838859219442715} | train loss {'Reaction outcome loss': 0.14417684401163025, 'Total loss': 0.14417684401163025}
2022-12-05 20:14:10,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:10,011 INFO:     Epoch: 56
2022-12-05 20:14:10,801 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4124372632835399, 'Total loss': 0.4124372632835399} | train loss {'Reaction outcome loss': 0.14227423700032688, 'Total loss': 0.14227423700032688}
2022-12-05 20:14:10,801 INFO:     Found new best model at epoch 56
2022-12-05 20:14:10,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:10,802 INFO:     Epoch: 57
2022-12-05 20:14:11,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4348582381551916, 'Total loss': 0.4348582381551916} | train loss {'Reaction outcome loss': 0.14690415371164137, 'Total loss': 0.14690415371164137}
2022-12-05 20:14:11,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:11,593 INFO:     Epoch: 58
2022-12-05 20:14:12,387 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42544118416580284, 'Total loss': 0.42544118416580284} | train loss {'Reaction outcome loss': 0.14300516059505283, 'Total loss': 0.14300516059505283}
2022-12-05 20:14:12,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:12,388 INFO:     Epoch: 59
2022-12-05 20:14:13,178 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43277239748700097, 'Total loss': 0.43277239748700097} | train loss {'Reaction outcome loss': 0.13944851254162036, 'Total loss': 0.13944851254162036}
2022-12-05 20:14:13,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:13,178 INFO:     Epoch: 60
2022-12-05 20:14:13,967 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4390387660400434, 'Total loss': 0.4390387660400434} | train loss {'Reaction outcome loss': 0.1408045585248393, 'Total loss': 0.1408045585248393}
2022-12-05 20:14:13,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:13,968 INFO:     Epoch: 61
2022-12-05 20:14:14,754 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4401352253149856, 'Total loss': 0.4401352253149856} | train loss {'Reaction outcome loss': 0.1419382676301215, 'Total loss': 0.1419382676301215}
2022-12-05 20:14:14,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:14,755 INFO:     Epoch: 62
2022-12-05 20:14:15,543 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42031843841753225, 'Total loss': 0.42031843841753225} | train loss {'Reaction outcome loss': 0.14091571731123365, 'Total loss': 0.14091571731123365}
2022-12-05 20:14:15,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:15,543 INFO:     Epoch: 63
2022-12-05 20:14:16,329 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43138336593454535, 'Total loss': 0.43138336593454535} | train loss {'Reaction outcome loss': 0.1444932737515915, 'Total loss': 0.1444932737515915}
2022-12-05 20:14:16,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:16,329 INFO:     Epoch: 64
2022-12-05 20:14:17,115 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4280131112106822, 'Total loss': 0.4280131112106822} | train loss {'Reaction outcome loss': 0.1346433774760438, 'Total loss': 0.1346433774760438}
2022-12-05 20:14:17,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:17,115 INFO:     Epoch: 65
2022-12-05 20:14:17,903 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4400502428073775, 'Total loss': 0.4400502428073775} | train loss {'Reaction outcome loss': 0.135044046291169, 'Total loss': 0.135044046291169}
2022-12-05 20:14:17,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:17,903 INFO:     Epoch: 66
2022-12-05 20:14:18,690 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42684687301516533, 'Total loss': 0.42684687301516533} | train loss {'Reaction outcome loss': 0.13661599883183775, 'Total loss': 0.13661599883183775}
2022-12-05 20:14:18,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:18,690 INFO:     Epoch: 67
2022-12-05 20:14:19,476 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4242126955227418, 'Total loss': 0.4242126955227418} | train loss {'Reaction outcome loss': 0.1321438515121928, 'Total loss': 0.1321438515121928}
2022-12-05 20:14:19,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:19,476 INFO:     Epoch: 68
2022-12-05 20:14:20,262 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4152003228664398, 'Total loss': 0.4152003228664398} | train loss {'Reaction outcome loss': 0.13434007770366785, 'Total loss': 0.13434007770366785}
2022-12-05 20:14:20,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:20,263 INFO:     Epoch: 69
2022-12-05 20:14:21,051 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4224769774485718, 'Total loss': 0.4224769774485718} | train loss {'Reaction outcome loss': 0.13500574694546733, 'Total loss': 0.13500574694546733}
2022-12-05 20:14:21,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:21,051 INFO:     Epoch: 70
2022-12-05 20:14:21,841 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41747310156510636, 'Total loss': 0.41747310156510636} | train loss {'Reaction outcome loss': 0.1422219893363444, 'Total loss': 0.1422219893363444}
2022-12-05 20:14:21,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:21,841 INFO:     Epoch: 71
2022-12-05 20:14:22,630 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.428547855805267, 'Total loss': 0.428547855805267} | train loss {'Reaction outcome loss': 0.1378555088907269, 'Total loss': 0.1378555088907269}
2022-12-05 20:14:22,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:22,631 INFO:     Epoch: 72
2022-12-05 20:14:23,420 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41973034681921656, 'Total loss': 0.41973034681921656} | train loss {'Reaction outcome loss': 0.1319459493494468, 'Total loss': 0.1319459493494468}
2022-12-05 20:14:23,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:23,420 INFO:     Epoch: 73
2022-12-05 20:14:24,206 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44505103304982185, 'Total loss': 0.44505103304982185} | train loss {'Reaction outcome loss': 0.13901650157911696, 'Total loss': 0.13901650157911696}
2022-12-05 20:14:24,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:24,207 INFO:     Epoch: 74
2022-12-05 20:14:24,993 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42835040915418754, 'Total loss': 0.42835040915418754} | train loss {'Reaction outcome loss': 0.13417792810232715, 'Total loss': 0.13417792810232715}
2022-12-05 20:14:24,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:24,994 INFO:     Epoch: 75
2022-12-05 20:14:25,781 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4132647913965312, 'Total loss': 0.4132647913965312} | train loss {'Reaction outcome loss': 0.1319493504980134, 'Total loss': 0.1319493504980134}
2022-12-05 20:14:25,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:25,781 INFO:     Epoch: 76
2022-12-05 20:14:26,577 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4358345771377737, 'Total loss': 0.4358345771377737} | train loss {'Reaction outcome loss': 0.13215007263081155, 'Total loss': 0.13215007263081155}
2022-12-05 20:14:26,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:26,577 INFO:     Epoch: 77
2022-12-05 20:14:27,367 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42589508030902257, 'Total loss': 0.42589508030902257} | train loss {'Reaction outcome loss': 0.1290745830110572, 'Total loss': 0.1290745830110572}
2022-12-05 20:14:27,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:27,367 INFO:     Epoch: 78
2022-12-05 20:14:28,155 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42372739958492195, 'Total loss': 0.42372739958492195} | train loss {'Reaction outcome loss': 0.12888776003204, 'Total loss': 0.12888776003204}
2022-12-05 20:14:28,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:28,155 INFO:     Epoch: 79
2022-12-05 20:14:28,943 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4312747129323808, 'Total loss': 0.4312747129323808} | train loss {'Reaction outcome loss': 0.1273604412921346, 'Total loss': 0.1273604412921346}
2022-12-05 20:14:28,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:28,943 INFO:     Epoch: 80
2022-12-05 20:14:29,730 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4346833455968987, 'Total loss': 0.4346833455968987} | train loss {'Reaction outcome loss': 0.12825492622664478, 'Total loss': 0.12825492622664478}
2022-12-05 20:14:29,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:29,730 INFO:     Epoch: 81
2022-12-05 20:14:30,521 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4383804496716369, 'Total loss': 0.4383804496716369} | train loss {'Reaction outcome loss': 0.1285366493348892, 'Total loss': 0.1285366493348892}
2022-12-05 20:14:30,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:30,522 INFO:     Epoch: 82
2022-12-05 20:14:31,308 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4104569655927745, 'Total loss': 0.4104569655927745} | train loss {'Reaction outcome loss': 0.12919587314294778, 'Total loss': 0.12919587314294778}
2022-12-05 20:14:31,308 INFO:     Found new best model at epoch 82
2022-12-05 20:14:31,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:31,309 INFO:     Epoch: 83
2022-12-05 20:14:32,099 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4226286502724344, 'Total loss': 0.4226286502724344} | train loss {'Reaction outcome loss': 0.12885029134595097, 'Total loss': 0.12885029134595097}
2022-12-05 20:14:32,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:32,099 INFO:     Epoch: 84
2022-12-05 20:14:32,888 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43421842801299965, 'Total loss': 0.43421842801299965} | train loss {'Reaction outcome loss': 0.12767223536455438, 'Total loss': 0.12767223536455438}
2022-12-05 20:14:32,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:32,888 INFO:     Epoch: 85
2022-12-05 20:14:33,675 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4123911466449499, 'Total loss': 0.4123911466449499} | train loss {'Reaction outcome loss': 0.12350539688910792, 'Total loss': 0.12350539688910792}
2022-12-05 20:14:33,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:33,675 INFO:     Epoch: 86
2022-12-05 20:14:34,464 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4121321009641344, 'Total loss': 0.4121321009641344} | train loss {'Reaction outcome loss': 0.1249992880010638, 'Total loss': 0.1249992880010638}
2022-12-05 20:14:34,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:34,464 INFO:     Epoch: 87
2022-12-05 20:14:35,253 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4352490156888962, 'Total loss': 0.4352490156888962} | train loss {'Reaction outcome loss': 0.12524402588002595, 'Total loss': 0.12524402588002595}
2022-12-05 20:14:35,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:35,253 INFO:     Epoch: 88
2022-12-05 20:14:36,041 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4249872633002021, 'Total loss': 0.4249872633002021} | train loss {'Reaction outcome loss': 0.12574395003468403, 'Total loss': 0.12574395003468403}
2022-12-05 20:14:36,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:36,042 INFO:     Epoch: 89
2022-12-05 20:14:36,835 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4387115729464726, 'Total loss': 0.4387115729464726} | train loss {'Reaction outcome loss': 0.12315999920093945, 'Total loss': 0.12315999920093945}
2022-12-05 20:14:36,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:36,835 INFO:     Epoch: 90
2022-12-05 20:14:37,629 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4211553067646243, 'Total loss': 0.4211553067646243} | train loss {'Reaction outcome loss': 0.1234943962237432, 'Total loss': 0.1234943962237432}
2022-12-05 20:14:37,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:37,629 INFO:     Epoch: 91
2022-12-05 20:14:38,419 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4294769977304069, 'Total loss': 0.4294769977304069} | train loss {'Reaction outcome loss': 0.12213584648794966, 'Total loss': 0.12213584648794966}
2022-12-05 20:14:38,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:38,419 INFO:     Epoch: 92
2022-12-05 20:14:39,210 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4194896380332383, 'Total loss': 0.4194896380332383} | train loss {'Reaction outcome loss': 0.11992942913989668, 'Total loss': 0.11992942913989668}
2022-12-05 20:14:39,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:39,210 INFO:     Epoch: 93
2022-12-05 20:14:40,002 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.435009598901326, 'Total loss': 0.435009598901326} | train loss {'Reaction outcome loss': 0.127320765102893, 'Total loss': 0.127320765102893}
2022-12-05 20:14:40,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:40,002 INFO:     Epoch: 94
2022-12-05 20:14:40,793 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4251958169043064, 'Total loss': 0.4251958169043064} | train loss {'Reaction outcome loss': 0.12299078059673069, 'Total loss': 0.12299078059673069}
2022-12-05 20:14:40,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:40,793 INFO:     Epoch: 95
2022-12-05 20:14:41,586 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43567508391358634, 'Total loss': 0.43567508391358634} | train loss {'Reaction outcome loss': 0.12114926707376594, 'Total loss': 0.12114926707376594}
2022-12-05 20:14:41,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:41,586 INFO:     Epoch: 96
2022-12-05 20:14:42,372 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41482654048807244, 'Total loss': 0.41482654048807244} | train loss {'Reaction outcome loss': 0.12324882404094464, 'Total loss': 0.12324882404094464}
2022-12-05 20:14:42,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:42,372 INFO:     Epoch: 97
2022-12-05 20:14:43,166 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4392701323059472, 'Total loss': 0.4392701323059472} | train loss {'Reaction outcome loss': 0.12052954378187174, 'Total loss': 0.12052954378187174}
2022-12-05 20:14:43,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:43,167 INFO:     Epoch: 98
2022-12-05 20:14:43,958 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43587316234003415, 'Total loss': 0.43587316234003415} | train loss {'Reaction outcome loss': 0.12749962707150064, 'Total loss': 0.12749962707150064}
2022-12-05 20:14:43,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:43,959 INFO:     Epoch: 99
2022-12-05 20:14:44,751 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4267802143638784, 'Total loss': 0.4267802143638784} | train loss {'Reaction outcome loss': 0.11971880548335763, 'Total loss': 0.11971880548335763}
2022-12-05 20:14:44,751 INFO:     Best model found after epoch 83 of 100.
2022-12-05 20:14:44,751 INFO:   Done with stage: TRAINING
2022-12-05 20:14:44,751 INFO:   Starting stage: EVALUATION
2022-12-05 20:14:44,877 INFO:   Done with stage: EVALUATION
2022-12-05 20:14:44,878 INFO:   Leaving out SEQ value Fold_1
2022-12-05 20:14:44,891 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:14:44,891 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:14:45,526 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:14:45,526 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:14:45,596 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:14:45,596 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:14:45,596 INFO:     No hyperparam tuning for this model
2022-12-05 20:14:45,596 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:14:45,596 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:14:45,597 INFO:     None feature selector for col prot
2022-12-05 20:14:45,597 INFO:     None feature selector for col prot
2022-12-05 20:14:45,597 INFO:     None feature selector for col prot
2022-12-05 20:14:45,597 INFO:     None feature selector for col chem
2022-12-05 20:14:45,598 INFO:     None feature selector for col chem
2022-12-05 20:14:45,598 INFO:     None feature selector for col chem
2022-12-05 20:14:45,598 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:14:45,598 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:14:45,600 INFO:     Number of params in model 215821
2022-12-05 20:14:45,603 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:14:45,603 INFO:   Starting stage: TRAINING
2022-12-05 20:14:45,664 INFO:     Val loss before train {'Reaction outcome loss': 0.9713261425495148, 'Total loss': 0.9713261425495148}
2022-12-05 20:14:45,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:45,664 INFO:     Epoch: 0
2022-12-05 20:14:46,455 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5929077579216524, 'Total loss': 0.5929077579216524} | train loss {'Reaction outcome loss': 0.7934133353443281, 'Total loss': 0.7934133353443281}
2022-12-05 20:14:46,455 INFO:     Found new best model at epoch 0
2022-12-05 20:14:46,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:46,456 INFO:     Epoch: 1
2022-12-05 20:14:47,245 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5008844035592946, 'Total loss': 0.5008844035592946} | train loss {'Reaction outcome loss': 0.5381232069330177, 'Total loss': 0.5381232069330177}
2022-12-05 20:14:47,245 INFO:     Found new best model at epoch 1
2022-12-05 20:14:47,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:47,246 INFO:     Epoch: 2
2022-12-05 20:14:48,033 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.469874019311233, 'Total loss': 0.469874019311233} | train loss {'Reaction outcome loss': 0.47734108120806307, 'Total loss': 0.47734108120806307}
2022-12-05 20:14:48,033 INFO:     Found new best model at epoch 2
2022-12-05 20:14:48,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:48,034 INFO:     Epoch: 3
2022-12-05 20:14:48,829 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4633942998268388, 'Total loss': 0.4633942998268388} | train loss {'Reaction outcome loss': 0.43833423746742217, 'Total loss': 0.43833423746742217}
2022-12-05 20:14:48,829 INFO:     Found new best model at epoch 3
2022-12-05 20:14:48,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:48,830 INFO:     Epoch: 4
2022-12-05 20:14:49,618 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4594432193447243, 'Total loss': 0.4594432193447243} | train loss {'Reaction outcome loss': 0.40911137740983655, 'Total loss': 0.40911137740983655}
2022-12-05 20:14:49,618 INFO:     Found new best model at epoch 4
2022-12-05 20:14:49,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:49,619 INFO:     Epoch: 5
2022-12-05 20:14:50,410 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44911996817046945, 'Total loss': 0.44911996817046945} | train loss {'Reaction outcome loss': 0.3858088552046884, 'Total loss': 0.3858088552046884}
2022-12-05 20:14:50,410 INFO:     Found new best model at epoch 5
2022-12-05 20:14:50,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:50,411 INFO:     Epoch: 6
2022-12-05 20:14:51,200 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44202450120990927, 'Total loss': 0.44202450120990927} | train loss {'Reaction outcome loss': 0.36964835926347417, 'Total loss': 0.36964835926347417}
2022-12-05 20:14:51,200 INFO:     Found new best model at epoch 6
2022-12-05 20:14:51,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:51,201 INFO:     Epoch: 7
2022-12-05 20:14:51,989 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43023522062735126, 'Total loss': 0.43023522062735126} | train loss {'Reaction outcome loss': 0.35293300179877746, 'Total loss': 0.35293300179877746}
2022-12-05 20:14:51,989 INFO:     Found new best model at epoch 7
2022-12-05 20:14:51,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:51,990 INFO:     Epoch: 8
2022-12-05 20:14:52,779 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42524695938283746, 'Total loss': 0.42524695938283746} | train loss {'Reaction outcome loss': 0.33919225289271426, 'Total loss': 0.33919225289271426}
2022-12-05 20:14:52,780 INFO:     Found new best model at epoch 8
2022-12-05 20:14:52,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:52,780 INFO:     Epoch: 9
2022-12-05 20:14:53,573 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43051389909603377, 'Total loss': 0.43051389909603377} | train loss {'Reaction outcome loss': 0.3260030697593805, 'Total loss': 0.3260030697593805}
2022-12-05 20:14:53,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:53,574 INFO:     Epoch: 10
2022-12-05 20:14:54,362 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44600274854085664, 'Total loss': 0.44600274854085664} | train loss {'Reaction outcome loss': 0.31040756630632077, 'Total loss': 0.31040756630632077}
2022-12-05 20:14:54,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:54,362 INFO:     Epoch: 11
2022-12-05 20:14:55,156 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4245645190504464, 'Total loss': 0.4245645190504464} | train loss {'Reaction outcome loss': 0.30030010966018506, 'Total loss': 0.30030010966018506}
2022-12-05 20:14:55,157 INFO:     Found new best model at epoch 11
2022-12-05 20:14:55,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:55,158 INFO:     Epoch: 12
2022-12-05 20:14:55,957 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4231811904094436, 'Total loss': 0.4231811904094436} | train loss {'Reaction outcome loss': 0.29241379003534435, 'Total loss': 0.29241379003534435}
2022-12-05 20:14:55,957 INFO:     Found new best model at epoch 12
2022-12-05 20:14:55,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:55,958 INFO:     Epoch: 13
2022-12-05 20:14:56,751 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41934818571264093, 'Total loss': 0.41934818571264093} | train loss {'Reaction outcome loss': 0.2805374048589936, 'Total loss': 0.2805374048589936}
2022-12-05 20:14:56,751 INFO:     Found new best model at epoch 13
2022-12-05 20:14:56,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:56,752 INFO:     Epoch: 14
2022-12-05 20:14:57,540 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41597895899956877, 'Total loss': 0.41597895899956877} | train loss {'Reaction outcome loss': 0.2725674067190302, 'Total loss': 0.2725674067190302}
2022-12-05 20:14:57,540 INFO:     Found new best model at epoch 14
2022-12-05 20:14:57,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:57,541 INFO:     Epoch: 15
2022-12-05 20:14:58,332 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4243290729143403, 'Total loss': 0.4243290729143403} | train loss {'Reaction outcome loss': 0.2699188636955221, 'Total loss': 0.2699188636955221}
2022-12-05 20:14:58,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:58,332 INFO:     Epoch: 16
2022-12-05 20:14:59,124 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41843736645850266, 'Total loss': 0.41843736645850266} | train loss {'Reaction outcome loss': 0.2605998260968248, 'Total loss': 0.2605998260968248}
2022-12-05 20:14:59,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:59,124 INFO:     Epoch: 17
2022-12-05 20:14:59,913 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.426353512162512, 'Total loss': 0.426353512162512} | train loss {'Reaction outcome loss': 0.25013570584590555, 'Total loss': 0.25013570584590555}
2022-12-05 20:14:59,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:14:59,913 INFO:     Epoch: 18
2022-12-05 20:15:00,704 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42852450196038594, 'Total loss': 0.42852450196038594} | train loss {'Reaction outcome loss': 0.24385005287893932, 'Total loss': 0.24385005287893932}
2022-12-05 20:15:00,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:00,704 INFO:     Epoch: 19
2022-12-05 20:15:01,498 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.423803338019008, 'Total loss': 0.423803338019008} | train loss {'Reaction outcome loss': 0.2387983073529444, 'Total loss': 0.2387983073529444}
2022-12-05 20:15:01,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:01,499 INFO:     Epoch: 20
2022-12-05 20:15:02,289 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4402319707653739, 'Total loss': 0.4402319707653739} | train loss {'Reaction outcome loss': 0.23358258779579208, 'Total loss': 0.23358258779579208}
2022-12-05 20:15:02,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:02,290 INFO:     Epoch: 21
2022-12-05 20:15:03,076 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4225174506956881, 'Total loss': 0.4225174506956881} | train loss {'Reaction outcome loss': 0.2271071957831501, 'Total loss': 0.2271071957831501}
2022-12-05 20:15:03,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:03,077 INFO:     Epoch: 22
2022-12-05 20:15:03,868 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42296161367134616, 'Total loss': 0.42296161367134616} | train loss {'Reaction outcome loss': 0.21800963505197632, 'Total loss': 0.21800963505197632}
2022-12-05 20:15:03,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:03,868 INFO:     Epoch: 23
2022-12-05 20:15:04,658 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42477028139612893, 'Total loss': 0.42477028139612893} | train loss {'Reaction outcome loss': 0.2161375893061219, 'Total loss': 0.2161375893061219}
2022-12-05 20:15:04,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:04,658 INFO:     Epoch: 24
2022-12-05 20:15:05,454 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4312741504135457, 'Total loss': 0.4312741504135457} | train loss {'Reaction outcome loss': 0.21293581480269702, 'Total loss': 0.21293581480269702}
2022-12-05 20:15:05,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:05,454 INFO:     Epoch: 25
2022-12-05 20:15:06,246 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4307115619832819, 'Total loss': 0.4307115619832819} | train loss {'Reaction outcome loss': 0.20857163483978283, 'Total loss': 0.20857163483978283}
2022-12-05 20:15:06,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:06,247 INFO:     Epoch: 26
2022-12-05 20:15:07,036 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44825896553017874, 'Total loss': 0.44825896553017874} | train loss {'Reaction outcome loss': 0.2059959498788362, 'Total loss': 0.2059959498788362}
2022-12-05 20:15:07,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:07,036 INFO:     Epoch: 27
2022-12-05 20:15:07,824 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4270929138768803, 'Total loss': 0.4270929138768803} | train loss {'Reaction outcome loss': 0.20214080912351368, 'Total loss': 0.20214080912351368}
2022-12-05 20:15:07,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:07,825 INFO:     Epoch: 28
2022-12-05 20:15:08,616 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42054019766775047, 'Total loss': 0.42054019766775047} | train loss {'Reaction outcome loss': 0.1959025386253349, 'Total loss': 0.1959025386253349}
2022-12-05 20:15:08,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:08,616 INFO:     Epoch: 29
2022-12-05 20:15:09,404 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42596535045992245, 'Total loss': 0.42596535045992245} | train loss {'Reaction outcome loss': 0.19410604353134447, 'Total loss': 0.19410604353134447}
2022-12-05 20:15:09,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:09,404 INFO:     Epoch: 30
2022-12-05 20:15:10,196 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4361745962365107, 'Total loss': 0.4361745962365107} | train loss {'Reaction outcome loss': 0.1903958943170997, 'Total loss': 0.1903958943170997}
2022-12-05 20:15:10,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:10,196 INFO:     Epoch: 31
2022-12-05 20:15:10,989 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44106489182873204, 'Total loss': 0.44106489182873204} | train loss {'Reaction outcome loss': 0.1880317621144206, 'Total loss': 0.1880317621144206}
2022-12-05 20:15:10,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:10,989 INFO:     Epoch: 32
2022-12-05 20:15:11,781 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45977950570258225, 'Total loss': 0.45977950570258225} | train loss {'Reaction outcome loss': 0.17985662160844726, 'Total loss': 0.17985662160844726}
2022-12-05 20:15:11,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:11,781 INFO:     Epoch: 33
2022-12-05 20:15:12,570 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4427535184235735, 'Total loss': 0.4427535184235735} | train loss {'Reaction outcome loss': 0.18420840244785494, 'Total loss': 0.18420840244785494}
2022-12-05 20:15:12,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:12,571 INFO:     Epoch: 34
2022-12-05 20:15:13,359 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43379182842644776, 'Total loss': 0.43379182842644776} | train loss {'Reaction outcome loss': 0.1832744004695039, 'Total loss': 0.1832744004695039}
2022-12-05 20:15:13,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:13,359 INFO:     Epoch: 35
2022-12-05 20:15:14,148 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4642960161648013, 'Total loss': 0.4642960161648013} | train loss {'Reaction outcome loss': 0.1769990768426886, 'Total loss': 0.1769990768426886}
2022-12-05 20:15:14,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:14,149 INFO:     Epoch: 36
2022-12-05 20:15:14,937 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43203241750597954, 'Total loss': 0.43203241750597954} | train loss {'Reaction outcome loss': 0.17456801102575864, 'Total loss': 0.17456801102575864}
2022-12-05 20:15:14,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:14,937 INFO:     Epoch: 37
2022-12-05 20:15:15,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4331558201123368, 'Total loss': 0.4331558201123368} | train loss {'Reaction outcome loss': 0.16987681060724022, 'Total loss': 0.16987681060724022}
2022-12-05 20:15:15,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:15,726 INFO:     Epoch: 38
2022-12-05 20:15:16,521 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4428897767581723, 'Total loss': 0.4428897767581723} | train loss {'Reaction outcome loss': 0.16811821047925515, 'Total loss': 0.16811821047925515}
2022-12-05 20:15:16,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:16,521 INFO:     Epoch: 39
2022-12-05 20:15:17,314 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4430732937021689, 'Total loss': 0.4430732937021689} | train loss {'Reaction outcome loss': 0.16905412691652866, 'Total loss': 0.16905412691652866}
2022-12-05 20:15:17,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:17,315 INFO:     Epoch: 40
2022-12-05 20:15:18,103 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4726494885981083, 'Total loss': 0.4726494885981083} | train loss {'Reaction outcome loss': 0.16389215235534285, 'Total loss': 0.16389215235534285}
2022-12-05 20:15:18,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:18,103 INFO:     Epoch: 41
2022-12-05 20:15:18,891 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44149426383559, 'Total loss': 0.44149426383559} | train loss {'Reaction outcome loss': 0.16383427374068693, 'Total loss': 0.16383427374068693}
2022-12-05 20:15:18,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:18,891 INFO:     Epoch: 42
2022-12-05 20:15:19,678 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4705247503112663, 'Total loss': 0.4705247503112663} | train loss {'Reaction outcome loss': 0.16186887760333687, 'Total loss': 0.16186887760333687}
2022-12-05 20:15:19,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:19,679 INFO:     Epoch: 43
2022-12-05 20:15:20,468 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45407527837563644, 'Total loss': 0.45407527837563644} | train loss {'Reaction outcome loss': 0.1618805054814634, 'Total loss': 0.1618805054814634}
2022-12-05 20:15:20,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:20,469 INFO:     Epoch: 44
2022-12-05 20:15:21,258 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4609792312099175, 'Total loss': 0.4609792312099175} | train loss {'Reaction outcome loss': 0.15851015668467955, 'Total loss': 0.15851015668467955}
2022-12-05 20:15:21,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:21,258 INFO:     Epoch: 45
2022-12-05 20:15:22,050 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4628173749555241, 'Total loss': 0.4628173749555241} | train loss {'Reaction outcome loss': 0.15618373943032765, 'Total loss': 0.15618373943032765}
2022-12-05 20:15:22,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:22,050 INFO:     Epoch: 46
2022-12-05 20:15:22,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4594865786758336, 'Total loss': 0.4594865786758336} | train loss {'Reaction outcome loss': 0.15425656647666505, 'Total loss': 0.15425656647666505}
2022-12-05 20:15:22,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:22,838 INFO:     Epoch: 47
2022-12-05 20:15:23,626 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46480720219287003, 'Total loss': 0.46480720219287003} | train loss {'Reaction outcome loss': 0.15733059568835897, 'Total loss': 0.15733059568835897}
2022-12-05 20:15:23,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:23,626 INFO:     Epoch: 48
2022-12-05 20:15:24,414 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43489292839711363, 'Total loss': 0.43489292839711363} | train loss {'Reaction outcome loss': 0.1602498406566951, 'Total loss': 0.1602498406566951}
2022-12-05 20:15:24,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:24,414 INFO:     Epoch: 49
2022-12-05 20:15:25,202 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45958311076868663, 'Total loss': 0.45958311076868663} | train loss {'Reaction outcome loss': 0.15251337450284225, 'Total loss': 0.15251337450284225}
2022-12-05 20:15:25,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:25,202 INFO:     Epoch: 50
2022-12-05 20:15:25,993 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46851729474623094, 'Total loss': 0.46851729474623094} | train loss {'Reaction outcome loss': 0.1547745207724301, 'Total loss': 0.1547745207724301}
2022-12-05 20:15:25,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:25,994 INFO:     Epoch: 51
2022-12-05 20:15:26,790 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.439290331507271, 'Total loss': 0.439290331507271} | train loss {'Reaction outcome loss': 0.1579145226582342, 'Total loss': 0.1579145226582342}
2022-12-05 20:15:26,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:26,790 INFO:     Epoch: 52
2022-12-05 20:15:27,584 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4704462161118334, 'Total loss': 0.4704462161118334} | train loss {'Reaction outcome loss': 0.14979333053474966, 'Total loss': 0.14979333053474966}
2022-12-05 20:15:27,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:27,584 INFO:     Epoch: 53
2022-12-05 20:15:28,376 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4591779453171925, 'Total loss': 0.4591779453171925} | train loss {'Reaction outcome loss': 0.14855798247915047, 'Total loss': 0.14855798247915047}
2022-12-05 20:15:28,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:28,376 INFO:     Epoch: 54
2022-12-05 20:15:29,164 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4562231706540016, 'Total loss': 0.4562231706540016} | train loss {'Reaction outcome loss': 0.1486524655125462, 'Total loss': 0.1486524655125462}
2022-12-05 20:15:29,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:29,164 INFO:     Epoch: 55
2022-12-05 20:15:29,954 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.462454310872338, 'Total loss': 0.462454310872338} | train loss {'Reaction outcome loss': 0.14563522473739288, 'Total loss': 0.14563522473739288}
2022-12-05 20:15:29,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:29,954 INFO:     Epoch: 56
2022-12-05 20:15:30,750 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4557597135955637, 'Total loss': 0.4557597135955637} | train loss {'Reaction outcome loss': 0.14286862270386233, 'Total loss': 0.14286862270386233}
2022-12-05 20:15:30,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:30,750 INFO:     Epoch: 57
2022-12-05 20:15:31,542 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.462472816421227, 'Total loss': 0.462472816421227} | train loss {'Reaction outcome loss': 0.14481316752324583, 'Total loss': 0.14481316752324583}
2022-12-05 20:15:31,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:31,542 INFO:     Epoch: 58
2022-12-05 20:15:32,333 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4547437886622819, 'Total loss': 0.4547437886622819} | train loss {'Reaction outcome loss': 0.1464671535560718, 'Total loss': 0.1464671535560718}
2022-12-05 20:15:32,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:32,334 INFO:     Epoch: 59
2022-12-05 20:15:33,126 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4644607432525266, 'Total loss': 0.4644607432525266} | train loss {'Reaction outcome loss': 0.1506536614888834, 'Total loss': 0.1506536614888834}
2022-12-05 20:15:33,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:33,127 INFO:     Epoch: 60
2022-12-05 20:15:33,920 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.488610255447301, 'Total loss': 0.488610255447301} | train loss {'Reaction outcome loss': 0.1458805778444658, 'Total loss': 0.1458805778444658}
2022-12-05 20:15:33,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:33,921 INFO:     Epoch: 61
2022-12-05 20:15:34,710 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4677356310527433, 'Total loss': 0.4677356310527433} | train loss {'Reaction outcome loss': 0.14058692675641915, 'Total loss': 0.14058692675641915}
2022-12-05 20:15:34,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:34,710 INFO:     Epoch: 62
2022-12-05 20:15:35,502 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4476814938878471, 'Total loss': 0.4476814938878471} | train loss {'Reaction outcome loss': 0.1446325216472511, 'Total loss': 0.1446325216472511}
2022-12-05 20:15:35,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:35,502 INFO:     Epoch: 63
2022-12-05 20:15:36,292 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4945593430575999, 'Total loss': 0.4945593430575999} | train loss {'Reaction outcome loss': 0.13754000332817315, 'Total loss': 0.13754000332817315}
2022-12-05 20:15:36,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:36,292 INFO:     Epoch: 64
2022-12-05 20:15:37,080 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.452209854667837, 'Total loss': 0.452209854667837} | train loss {'Reaction outcome loss': 0.13775929186478075, 'Total loss': 0.13775929186478075}
2022-12-05 20:15:37,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:37,080 INFO:     Epoch: 65
2022-12-05 20:15:37,869 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45150145989927376, 'Total loss': 0.45150145989927376} | train loss {'Reaction outcome loss': 0.1377709775499487, 'Total loss': 0.1377709775499487}
2022-12-05 20:15:37,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:37,869 INFO:     Epoch: 66
2022-12-05 20:15:38,663 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46082356064157054, 'Total loss': 0.46082356064157054} | train loss {'Reaction outcome loss': 0.1372657159667628, 'Total loss': 0.1372657159667628}
2022-12-05 20:15:38,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:38,664 INFO:     Epoch: 67
2022-12-05 20:15:39,458 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45735016905448655, 'Total loss': 0.45735016905448655} | train loss {'Reaction outcome loss': 0.13533328358378066, 'Total loss': 0.13533328358378066}
2022-12-05 20:15:39,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:39,458 INFO:     Epoch: 68
2022-12-05 20:15:40,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45168798145922745, 'Total loss': 0.45168798145922745} | train loss {'Reaction outcome loss': 0.13466523251371829, 'Total loss': 0.13466523251371829}
2022-12-05 20:15:40,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:40,248 INFO:     Epoch: 69
2022-12-05 20:15:41,040 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4592808945612474, 'Total loss': 0.4592808945612474} | train loss {'Reaction outcome loss': 0.13442404407193423, 'Total loss': 0.13442404407193423}
2022-12-05 20:15:41,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:41,040 INFO:     Epoch: 70
2022-12-05 20:15:41,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48954753374511545, 'Total loss': 0.48954753374511545} | train loss {'Reaction outcome loss': 0.1370283363741419, 'Total loss': 0.1370283363741419}
2022-12-05 20:15:41,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:41,830 INFO:     Epoch: 71
2022-12-05 20:15:42,619 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4561222900043834, 'Total loss': 0.4561222900043834} | train loss {'Reaction outcome loss': 0.13685734379991346, 'Total loss': 0.13685734379991346}
2022-12-05 20:15:42,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:42,620 INFO:     Epoch: 72
2022-12-05 20:15:43,413 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47418979690833524, 'Total loss': 0.47418979690833524} | train loss {'Reaction outcome loss': 0.13297645223769078, 'Total loss': 0.13297645223769078}
2022-12-05 20:15:43,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:43,413 INFO:     Epoch: 73
2022-12-05 20:15:44,203 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.462751114402305, 'Total loss': 0.462751114402305} | train loss {'Reaction outcome loss': 0.1315951255012986, 'Total loss': 0.1315951255012986}
2022-12-05 20:15:44,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:44,204 INFO:     Epoch: 74
2022-12-05 20:15:44,999 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.469258842820471, 'Total loss': 0.469258842820471} | train loss {'Reaction outcome loss': 0.13133279624421465, 'Total loss': 0.13133279624421465}
2022-12-05 20:15:45,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:45,000 INFO:     Epoch: 75
2022-12-05 20:15:45,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46031983382999897, 'Total loss': 0.46031983382999897} | train loss {'Reaction outcome loss': 0.13237285688293246, 'Total loss': 0.13237285688293246}
2022-12-05 20:15:45,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:45,789 INFO:     Epoch: 76
2022-12-05 20:15:46,578 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4641777876425873, 'Total loss': 0.4641777876425873} | train loss {'Reaction outcome loss': 0.13207217018583767, 'Total loss': 0.13207217018583767}
2022-12-05 20:15:46,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:46,578 INFO:     Epoch: 77
2022-12-05 20:15:47,373 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46422576667232945, 'Total loss': 0.46422576667232945} | train loss {'Reaction outcome loss': 0.12890495706480637, 'Total loss': 0.12890495706480637}
2022-12-05 20:15:47,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:47,373 INFO:     Epoch: 78
2022-12-05 20:15:48,165 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4504119118844921, 'Total loss': 0.4504119118844921} | train loss {'Reaction outcome loss': 0.13070195767017995, 'Total loss': 0.13070195767017995}
2022-12-05 20:15:48,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:48,166 INFO:     Epoch: 79
2022-12-05 20:15:48,957 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4572078274054961, 'Total loss': 0.4572078274054961} | train loss {'Reaction outcome loss': 0.13115347896208648, 'Total loss': 0.13115347896208648}
2022-12-05 20:15:48,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:48,957 INFO:     Epoch: 80
2022-12-05 20:15:49,748 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47419020194898953, 'Total loss': 0.47419020194898953} | train loss {'Reaction outcome loss': 0.1325982473828351, 'Total loss': 0.1325982473828351}
2022-12-05 20:15:49,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:49,749 INFO:     Epoch: 81
2022-12-05 20:15:50,548 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45293458669700404, 'Total loss': 0.45293458669700404} | train loss {'Reaction outcome loss': 0.12882158594575488, 'Total loss': 0.12882158594575488}
2022-12-05 20:15:50,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:50,548 INFO:     Epoch: 82
2022-12-05 20:15:51,338 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46404253996231337, 'Total loss': 0.46404253996231337} | train loss {'Reaction outcome loss': 0.1283794491351978, 'Total loss': 0.1283794491351978}
2022-12-05 20:15:51,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:51,338 INFO:     Epoch: 83
2022-12-05 20:15:52,130 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45870749110525305, 'Total loss': 0.45870749110525305} | train loss {'Reaction outcome loss': 0.12495199578007314, 'Total loss': 0.12495199578007314}
2022-12-05 20:15:52,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:52,130 INFO:     Epoch: 84
2022-12-05 20:15:52,924 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46128565284677525, 'Total loss': 0.46128565284677525} | train loss {'Reaction outcome loss': 0.12478867374164493, 'Total loss': 0.12478867374164493}
2022-12-05 20:15:52,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:52,924 INFO:     Epoch: 85
2022-12-05 20:15:53,714 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4644845380363139, 'Total loss': 0.4644845380363139} | train loss {'Reaction outcome loss': 0.1278384147034694, 'Total loss': 0.1278384147034694}
2022-12-05 20:15:53,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:53,714 INFO:     Epoch: 86
2022-12-05 20:15:54,504 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44909393935548986, 'Total loss': 0.44909393935548986} | train loss {'Reaction outcome loss': 0.12630878379832394, 'Total loss': 0.12630878379832394}
2022-12-05 20:15:54,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:54,505 INFO:     Epoch: 87
2022-12-05 20:15:55,298 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4748639008876952, 'Total loss': 0.4748639008876952} | train loss {'Reaction outcome loss': 0.1248749655912732, 'Total loss': 0.1248749655912732}
2022-12-05 20:15:55,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:55,298 INFO:     Epoch: 88
2022-12-05 20:15:56,091 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4650324603373354, 'Total loss': 0.4650324603373354} | train loss {'Reaction outcome loss': 0.12441149091174607, 'Total loss': 0.12441149091174607}
2022-12-05 20:15:56,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:56,092 INFO:     Epoch: 89
2022-12-05 20:15:56,881 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5001272311942144, 'Total loss': 0.5001272311942144} | train loss {'Reaction outcome loss': 0.12394721462176396, 'Total loss': 0.12394721462176396}
2022-12-05 20:15:56,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:56,882 INFO:     Epoch: 90
2022-12-05 20:15:57,676 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48191251284019515, 'Total loss': 0.48191251284019515} | train loss {'Reaction outcome loss': 0.1283659937486113, 'Total loss': 0.1283659937486113}
2022-12-05 20:15:57,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:57,676 INFO:     Epoch: 91
2022-12-05 20:15:58,467 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4882105971601876, 'Total loss': 0.4882105971601876} | train loss {'Reaction outcome loss': 0.12445668470838413, 'Total loss': 0.12445668470838413}
2022-12-05 20:15:58,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:58,467 INFO:     Epoch: 92
2022-12-05 20:15:59,257 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4695872244509784, 'Total loss': 0.4695872244509784} | train loss {'Reaction outcome loss': 0.12199870662891912, 'Total loss': 0.12199870662891912}
2022-12-05 20:15:59,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:15:59,257 INFO:     Epoch: 93
2022-12-05 20:16:00,048 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4596136889674447, 'Total loss': 0.4596136889674447} | train loss {'Reaction outcome loss': 0.12421424810205273, 'Total loss': 0.12421424810205273}
2022-12-05 20:16:00,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:00,048 INFO:     Epoch: 94
2022-12-05 20:16:00,844 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4813731224699454, 'Total loss': 0.4813731224699454} | train loss {'Reaction outcome loss': 0.12501025353916562, 'Total loss': 0.12501025353916562}
2022-12-05 20:16:00,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:00,844 INFO:     Epoch: 95
2022-12-05 20:16:01,638 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4733378931202672, 'Total loss': 0.4733378931202672} | train loss {'Reaction outcome loss': 0.1276768477490315, 'Total loss': 0.1276768477490315}
2022-12-05 20:16:01,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:01,638 INFO:     Epoch: 96
2022-12-05 20:16:02,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46473925780843606, 'Total loss': 0.46473925780843606} | train loss {'Reaction outcome loss': 0.12745687289131422, 'Total loss': 0.12745687289131422}
2022-12-05 20:16:02,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:02,429 INFO:     Epoch: 97
2022-12-05 20:16:03,217 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4543844574893063, 'Total loss': 0.4543844574893063} | train loss {'Reaction outcome loss': 0.12108720853728683, 'Total loss': 0.12108720853728683}
2022-12-05 20:16:03,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:03,218 INFO:     Epoch: 98
2022-12-05 20:16:04,010 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45987113497473975, 'Total loss': 0.45987113497473975} | train loss {'Reaction outcome loss': 0.12204202398024348, 'Total loss': 0.12204202398024348}
2022-12-05 20:16:04,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:04,010 INFO:     Epoch: 99
2022-12-05 20:16:04,804 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4714130000634627, 'Total loss': 0.4714130000634627} | train loss {'Reaction outcome loss': 0.1217678372125115, 'Total loss': 0.1217678372125115}
2022-12-05 20:16:04,805 INFO:     Best model found after epoch 15 of 100.
2022-12-05 20:16:04,805 INFO:   Done with stage: TRAINING
2022-12-05 20:16:04,805 INFO:   Starting stage: EVALUATION
2022-12-05 20:16:04,932 INFO:   Done with stage: EVALUATION
2022-12-05 20:16:04,932 INFO:   Leaving out SEQ value Fold_2
2022-12-05 20:16:04,944 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-12-05 20:16:04,945 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:16:05,585 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:16:05,585 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:16:05,652 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:16:05,652 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:16:05,652 INFO:     No hyperparam tuning for this model
2022-12-05 20:16:05,652 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:16:05,652 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:16:05,653 INFO:     None feature selector for col prot
2022-12-05 20:16:05,653 INFO:     None feature selector for col prot
2022-12-05 20:16:05,653 INFO:     None feature selector for col prot
2022-12-05 20:16:05,654 INFO:     None feature selector for col chem
2022-12-05 20:16:05,654 INFO:     None feature selector for col chem
2022-12-05 20:16:05,654 INFO:     None feature selector for col chem
2022-12-05 20:16:05,654 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:16:05,654 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:16:05,656 INFO:     Number of params in model 215821
2022-12-05 20:16:05,659 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:16:05,659 INFO:   Starting stage: TRAINING
2022-12-05 20:16:05,718 INFO:     Val loss before train {'Reaction outcome loss': 1.0141176622967387, 'Total loss': 1.0141176622967387}
2022-12-05 20:16:05,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:05,718 INFO:     Epoch: 0
2022-12-05 20:16:06,495 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5735143540903579, 'Total loss': 0.5735143540903579} | train loss {'Reaction outcome loss': 0.7818782311010163, 'Total loss': 0.7818782311010163}
2022-12-05 20:16:06,495 INFO:     Found new best model at epoch 0
2022-12-05 20:16:06,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:06,496 INFO:     Epoch: 1
2022-12-05 20:16:07,267 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4901677584925363, 'Total loss': 0.4901677584925363} | train loss {'Reaction outcome loss': 0.5216632424177471, 'Total loss': 0.5216632424177471}
2022-12-05 20:16:07,267 INFO:     Found new best model at epoch 1
2022-12-05 20:16:07,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:07,268 INFO:     Epoch: 2
2022-12-05 20:16:08,043 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4708467732335246, 'Total loss': 0.4708467732335246} | train loss {'Reaction outcome loss': 0.4493673773351052, 'Total loss': 0.4493673773351052}
2022-12-05 20:16:08,043 INFO:     Found new best model at epoch 2
2022-12-05 20:16:08,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:08,044 INFO:     Epoch: 3
2022-12-05 20:16:08,818 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4498129767733951, 'Total loss': 0.4498129767733951} | train loss {'Reaction outcome loss': 0.41473158161422524, 'Total loss': 0.41473158161422524}
2022-12-05 20:16:08,818 INFO:     Found new best model at epoch 3
2022-12-05 20:16:08,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:08,819 INFO:     Epoch: 4
2022-12-05 20:16:09,595 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43412147254444833, 'Total loss': 0.43412147254444833} | train loss {'Reaction outcome loss': 0.389471876237897, 'Total loss': 0.389471876237897}
2022-12-05 20:16:09,595 INFO:     Found new best model at epoch 4
2022-12-05 20:16:09,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:09,596 INFO:     Epoch: 5
2022-12-05 20:16:10,369 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41559750396151873, 'Total loss': 0.41559750396151873} | train loss {'Reaction outcome loss': 0.36516975348668473, 'Total loss': 0.36516975348668473}
2022-12-05 20:16:10,369 INFO:     Found new best model at epoch 5
2022-12-05 20:16:10,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:10,370 INFO:     Epoch: 6
2022-12-05 20:16:11,145 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4124856584293898, 'Total loss': 0.4124856584293898} | train loss {'Reaction outcome loss': 0.34663928093009966, 'Total loss': 0.34663928093009966}
2022-12-05 20:16:11,145 INFO:     Found new best model at epoch 6
2022-12-05 20:16:11,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:11,146 INFO:     Epoch: 7
2022-12-05 20:16:11,919 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4116936234194179, 'Total loss': 0.4116936234194179} | train loss {'Reaction outcome loss': 0.33037401803796224, 'Total loss': 0.33037401803796224}
2022-12-05 20:16:11,919 INFO:     Found new best model at epoch 7
2022-12-05 20:16:11,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:11,920 INFO:     Epoch: 8
2022-12-05 20:16:12,695 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4098437369562859, 'Total loss': 0.4098437369562859} | train loss {'Reaction outcome loss': 0.31548944434066034, 'Total loss': 0.31548944434066034}
2022-12-05 20:16:12,695 INFO:     Found new best model at epoch 8
2022-12-05 20:16:12,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:12,696 INFO:     Epoch: 9
2022-12-05 20:16:13,467 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4157764322535936, 'Total loss': 0.4157764322535936} | train loss {'Reaction outcome loss': 0.30199181480155446, 'Total loss': 0.30199181480155446}
2022-12-05 20:16:13,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:13,467 INFO:     Epoch: 10
2022-12-05 20:16:14,242 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4263497405620508, 'Total loss': 0.4263497405620508} | train loss {'Reaction outcome loss': 0.2891972457905033, 'Total loss': 0.2891972457905033}
2022-12-05 20:16:14,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:14,242 INFO:     Epoch: 11
2022-12-05 20:16:15,017 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4224461946029996, 'Total loss': 0.4224461946029996} | train loss {'Reaction outcome loss': 0.2782537318858863, 'Total loss': 0.2782537318858863}
2022-12-05 20:16:15,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:15,017 INFO:     Epoch: 12
2022-12-05 20:16:15,791 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40562904678111855, 'Total loss': 0.40562904678111855} | train loss {'Reaction outcome loss': 0.2689054025592151, 'Total loss': 0.2689054025592151}
2022-12-05 20:16:15,792 INFO:     Found new best model at epoch 12
2022-12-05 20:16:15,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:15,792 INFO:     Epoch: 13
2022-12-05 20:16:16,571 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4116189098635385, 'Total loss': 0.4116189098635385} | train loss {'Reaction outcome loss': 0.25807340535880124, 'Total loss': 0.25807340535880124}
2022-12-05 20:16:16,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:16,572 INFO:     Epoch: 14
2022-12-05 20:16:17,347 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4096715415633002, 'Total loss': 0.4096715415633002} | train loss {'Reaction outcome loss': 0.24950766738086816, 'Total loss': 0.24950766738086816}
2022-12-05 20:16:17,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:17,347 INFO:     Epoch: 15
2022-12-05 20:16:18,122 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4086645240353983, 'Total loss': 0.4086645240353983} | train loss {'Reaction outcome loss': 0.24234558940242928, 'Total loss': 0.24234558940242928}
2022-12-05 20:16:18,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:18,122 INFO:     Epoch: 16
2022-12-05 20:16:18,902 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42478806681411213, 'Total loss': 0.42478806681411213} | train loss {'Reaction outcome loss': 0.23671077607640092, 'Total loss': 0.23671077607640092}
2022-12-05 20:16:18,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:18,903 INFO:     Epoch: 17
2022-12-05 20:16:19,676 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40758604435033574, 'Total loss': 0.40758604435033574} | train loss {'Reaction outcome loss': 0.2296613670916478, 'Total loss': 0.2296613670916478}
2022-12-05 20:16:19,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:19,676 INFO:     Epoch: 18
2022-12-05 20:16:20,450 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42527157172214153, 'Total loss': 0.42527157172214153} | train loss {'Reaction outcome loss': 0.2230840224880895, 'Total loss': 0.2230840224880895}
2022-12-05 20:16:20,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:20,450 INFO:     Epoch: 19
2022-12-05 20:16:21,227 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41913751460785087, 'Total loss': 0.41913751460785087} | train loss {'Reaction outcome loss': 0.2165665657750304, 'Total loss': 0.2165665657750304}
2022-12-05 20:16:21,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:21,227 INFO:     Epoch: 20
2022-12-05 20:16:22,008 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43649908796299336, 'Total loss': 0.43649908796299336} | train loss {'Reaction outcome loss': 0.21251175536376066, 'Total loss': 0.21251175536376066}
2022-12-05 20:16:22,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:22,008 INFO:     Epoch: 21
2022-12-05 20:16:22,782 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4438640045565228, 'Total loss': 0.4438640045565228} | train loss {'Reaction outcome loss': 0.20566775363819728, 'Total loss': 0.20566775363819728}
2022-12-05 20:16:22,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:22,782 INFO:     Epoch: 22
2022-12-05 20:16:23,555 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42127940821093185, 'Total loss': 0.42127940821093185} | train loss {'Reaction outcome loss': 0.20364949484336425, 'Total loss': 0.20364949484336425}
2022-12-05 20:16:23,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:23,555 INFO:     Epoch: 23
2022-12-05 20:16:24,328 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43047407269477844, 'Total loss': 0.43047407269477844} | train loss {'Reaction outcome loss': 0.19759445417193208, 'Total loss': 0.19759445417193208}
2022-12-05 20:16:24,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:24,328 INFO:     Epoch: 24
2022-12-05 20:16:25,103 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.425262808453205, 'Total loss': 0.425262808453205} | train loss {'Reaction outcome loss': 0.19459097470732645, 'Total loss': 0.19459097470732645}
2022-12-05 20:16:25,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:25,104 INFO:     Epoch: 25
2022-12-05 20:16:25,880 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43155230997606764, 'Total loss': 0.43155230997606764} | train loss {'Reaction outcome loss': 0.19012497262681421, 'Total loss': 0.19012497262681421}
2022-12-05 20:16:25,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:25,880 INFO:     Epoch: 26
2022-12-05 20:16:26,661 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42799969329390414, 'Total loss': 0.42799969329390414} | train loss {'Reaction outcome loss': 0.18797679934882525, 'Total loss': 0.18797679934882525}
2022-12-05 20:16:26,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:26,661 INFO:     Epoch: 27
2022-12-05 20:16:27,442 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42326397292835766, 'Total loss': 0.42326397292835766} | train loss {'Reaction outcome loss': 0.1831957290868789, 'Total loss': 0.1831957290868789}
2022-12-05 20:16:27,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:27,443 INFO:     Epoch: 28
2022-12-05 20:16:28,224 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4316006185010422, 'Total loss': 0.4316006185010422} | train loss {'Reaction outcome loss': 0.17983267703615283, 'Total loss': 0.17983267703615283}
2022-12-05 20:16:28,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:28,225 INFO:     Epoch: 29
2022-12-05 20:16:28,998 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4408321411803711, 'Total loss': 0.4408321411803711} | train loss {'Reaction outcome loss': 0.17667313410100602, 'Total loss': 0.17667313410100602}
2022-12-05 20:16:28,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:28,998 INFO:     Epoch: 30
2022-12-05 20:16:29,774 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43779548344224, 'Total loss': 0.43779548344224} | train loss {'Reaction outcome loss': 0.17621428405100875, 'Total loss': 0.17621428405100875}
2022-12-05 20:16:29,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:29,774 INFO:     Epoch: 31
2022-12-05 20:16:30,546 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4338680880014287, 'Total loss': 0.4338680880014287} | train loss {'Reaction outcome loss': 0.17204922879756238, 'Total loss': 0.17204922879756238}
2022-12-05 20:16:30,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:30,546 INFO:     Epoch: 32
2022-12-05 20:16:31,323 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41644241175679275, 'Total loss': 0.41644241175679275} | train loss {'Reaction outcome loss': 0.1680917778898695, 'Total loss': 0.1680917778898695}
2022-12-05 20:16:31,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:31,323 INFO:     Epoch: 33
2022-12-05 20:16:32,095 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4347258775040161, 'Total loss': 0.4347258775040161} | train loss {'Reaction outcome loss': 0.16363375936151786, 'Total loss': 0.16363375936151786}
2022-12-05 20:16:32,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:32,095 INFO:     Epoch: 34
2022-12-05 20:16:32,868 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43309067120385725, 'Total loss': 0.43309067120385725} | train loss {'Reaction outcome loss': 0.163026555290608, 'Total loss': 0.163026555290608}
2022-12-05 20:16:32,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:32,869 INFO:     Epoch: 35
2022-12-05 20:16:33,644 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43838504130064054, 'Total loss': 0.43838504130064054} | train loss {'Reaction outcome loss': 0.16021151689201965, 'Total loss': 0.16021151689201965}
2022-12-05 20:16:33,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:33,645 INFO:     Epoch: 36
2022-12-05 20:16:34,420 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44087840963241665, 'Total loss': 0.44087840963241665} | train loss {'Reaction outcome loss': 0.16080978819211614, 'Total loss': 0.16080978819211614}
2022-12-05 20:16:34,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:34,420 INFO:     Epoch: 37
2022-12-05 20:16:35,192 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4413276619689409, 'Total loss': 0.4413276619689409} | train loss {'Reaction outcome loss': 0.1568959055476169, 'Total loss': 0.1568959055476169}
2022-12-05 20:16:35,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:35,193 INFO:     Epoch: 38
2022-12-05 20:16:35,970 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43955868829128353, 'Total loss': 0.43955868829128353} | train loss {'Reaction outcome loss': 0.15454811306044275, 'Total loss': 0.15454811306044275}
2022-12-05 20:16:35,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:35,971 INFO:     Epoch: 39
2022-12-05 20:16:36,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4368747070778248, 'Total loss': 0.4368747070778248} | train loss {'Reaction outcome loss': 0.15297877198062002, 'Total loss': 0.15297877198062002}
2022-12-05 20:16:36,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:36,745 INFO:     Epoch: 40
2022-12-05 20:16:37,517 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4292397329280543, 'Total loss': 0.4292397329280543} | train loss {'Reaction outcome loss': 0.15173619678359926, 'Total loss': 0.15173619678359926}
2022-12-05 20:16:37,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:37,517 INFO:     Epoch: 41
2022-12-05 20:16:38,289 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4296915285116018, 'Total loss': 0.4296915285116018} | train loss {'Reaction outcome loss': 0.1505526973947079, 'Total loss': 0.1505526973947079}
2022-12-05 20:16:38,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:38,290 INFO:     Epoch: 42
2022-12-05 20:16:39,065 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4320941307516985, 'Total loss': 0.4320941307516985} | train loss {'Reaction outcome loss': 0.14861958911371922, 'Total loss': 0.14861958911371922}
2022-12-05 20:16:39,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:39,065 INFO:     Epoch: 43
2022-12-05 20:16:39,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4428247137125148, 'Total loss': 0.4428247137125148} | train loss {'Reaction outcome loss': 0.14485890320135103, 'Total loss': 0.14485890320135103}
2022-12-05 20:16:39,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:39,843 INFO:     Epoch: 44
2022-12-05 20:16:40,615 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4596098987169044, 'Total loss': 0.4596098987169044} | train loss {'Reaction outcome loss': 0.14452296200196774, 'Total loss': 0.14452296200196774}
2022-12-05 20:16:40,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:40,615 INFO:     Epoch: 45
2022-12-05 20:16:41,388 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42824621048084527, 'Total loss': 0.42824621048084527} | train loss {'Reaction outcome loss': 0.14179880719600996, 'Total loss': 0.14179880719600996}
2022-12-05 20:16:41,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:41,388 INFO:     Epoch: 46
2022-12-05 20:16:42,162 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43582777713620385, 'Total loss': 0.43582777713620385} | train loss {'Reaction outcome loss': 0.14296686313118925, 'Total loss': 0.14296686313118925}
2022-12-05 20:16:42,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:42,162 INFO:     Epoch: 47
2022-12-05 20:16:42,938 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42850043745928035, 'Total loss': 0.42850043745928035} | train loss {'Reaction outcome loss': 0.14182327912648932, 'Total loss': 0.14182327912648932}
2022-12-05 20:16:42,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:42,938 INFO:     Epoch: 48
2022-12-05 20:16:43,712 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45512970978784006, 'Total loss': 0.45512970978784006} | train loss {'Reaction outcome loss': 0.13970083251394547, 'Total loss': 0.13970083251394547}
2022-12-05 20:16:43,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:43,712 INFO:     Epoch: 49
2022-12-05 20:16:44,496 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.459891181005988, 'Total loss': 0.459891181005988} | train loss {'Reaction outcome loss': 0.13643579959436572, 'Total loss': 0.13643579959436572}
2022-12-05 20:16:44,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:44,496 INFO:     Epoch: 50
2022-12-05 20:16:45,272 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4455091436935026, 'Total loss': 0.4455091436935026} | train loss {'Reaction outcome loss': 0.13902764452845476, 'Total loss': 0.13902764452845476}
2022-12-05 20:16:45,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:45,272 INFO:     Epoch: 51
2022-12-05 20:16:46,049 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4326754739118177, 'Total loss': 0.4326754739118177} | train loss {'Reaction outcome loss': 0.13782429899943072, 'Total loss': 0.13782429899943072}
2022-12-05 20:16:46,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:46,049 INFO:     Epoch: 52
2022-12-05 20:16:46,826 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4455218734436257, 'Total loss': 0.4455218734436257} | train loss {'Reaction outcome loss': 0.13539901040533087, 'Total loss': 0.13539901040533087}
2022-12-05 20:16:46,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:46,826 INFO:     Epoch: 53
2022-12-05 20:16:47,607 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4540700233259866, 'Total loss': 0.4540700233259866} | train loss {'Reaction outcome loss': 0.13584333825933737, 'Total loss': 0.13584333825933737}
2022-12-05 20:16:47,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:47,607 INFO:     Epoch: 54
2022-12-05 20:16:48,385 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46390925694343654, 'Total loss': 0.46390925694343654} | train loss {'Reaction outcome loss': 0.1346721369541285, 'Total loss': 0.1346721369541285}
2022-12-05 20:16:48,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:48,386 INFO:     Epoch: 55
2022-12-05 20:16:49,167 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4508033214613449, 'Total loss': 0.4508033214613449} | train loss {'Reaction outcome loss': 0.133799413698281, 'Total loss': 0.133799413698281}
2022-12-05 20:16:49,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:49,168 INFO:     Epoch: 56
2022-12-05 20:16:49,943 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4483374291381171, 'Total loss': 0.4483374291381171} | train loss {'Reaction outcome loss': 0.12998690654009704, 'Total loss': 0.12998690654009704}
2022-12-05 20:16:49,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:49,944 INFO:     Epoch: 57
2022-12-05 20:16:50,721 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4506949952175451, 'Total loss': 0.4506949952175451} | train loss {'Reaction outcome loss': 0.13254517227163948, 'Total loss': 0.13254517227163948}
2022-12-05 20:16:50,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:50,721 INFO:     Epoch: 58
2022-12-05 20:16:51,499 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45113477041555006, 'Total loss': 0.45113477041555006} | train loss {'Reaction outcome loss': 0.13021957737884457, 'Total loss': 0.13021957737884457}
2022-12-05 20:16:51,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:51,500 INFO:     Epoch: 59
2022-12-05 20:16:52,280 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4480941166538139, 'Total loss': 0.4480941166538139} | train loss {'Reaction outcome loss': 0.13211519813311917, 'Total loss': 0.13211519813311917}
2022-12-05 20:16:52,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:52,280 INFO:     Epoch: 60
2022-12-05 20:16:53,058 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4356445226558419, 'Total loss': 0.4356445226558419} | train loss {'Reaction outcome loss': 0.12788185919345166, 'Total loss': 0.12788185919345166}
2022-12-05 20:16:53,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:53,058 INFO:     Epoch: 61
2022-12-05 20:16:53,831 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4531303193680076, 'Total loss': 0.4531303193680076} | train loss {'Reaction outcome loss': 0.12772612299971067, 'Total loss': 0.12772612299971067}
2022-12-05 20:16:53,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:53,831 INFO:     Epoch: 62
2022-12-05 20:16:54,604 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4432888795123544, 'Total loss': 0.4432888795123544} | train loss {'Reaction outcome loss': 0.12792753209881638, 'Total loss': 0.12792753209881638}
2022-12-05 20:16:54,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:54,604 INFO:     Epoch: 63
2022-12-05 20:16:55,383 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43878392996483073, 'Total loss': 0.43878392996483073} | train loss {'Reaction outcome loss': 0.12686203807375984, 'Total loss': 0.12686203807375984}
2022-12-05 20:16:55,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:55,383 INFO:     Epoch: 64
2022-12-05 20:16:56,166 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45644590137309804, 'Total loss': 0.45644590137309804} | train loss {'Reaction outcome loss': 0.12548316420438502, 'Total loss': 0.12548316420438502}
2022-12-05 20:16:56,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:56,166 INFO:     Epoch: 65
2022-12-05 20:16:56,943 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4540834565495336, 'Total loss': 0.4540834565495336} | train loss {'Reaction outcome loss': 0.12563620389852656, 'Total loss': 0.12563620389852656}
2022-12-05 20:16:56,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:56,943 INFO:     Epoch: 66
2022-12-05 20:16:57,720 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45373977599448934, 'Total loss': 0.45373977599448934} | train loss {'Reaction outcome loss': 0.12430628638760925, 'Total loss': 0.12430628638760925}
2022-12-05 20:16:57,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:57,720 INFO:     Epoch: 67
2022-12-05 20:16:58,496 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.441273933926294, 'Total loss': 0.441273933926294} | train loss {'Reaction outcome loss': 0.12425720835050483, 'Total loss': 0.12425720835050483}
2022-12-05 20:16:58,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:58,497 INFO:     Epoch: 68
2022-12-05 20:16:59,273 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44200795022554173, 'Total loss': 0.44200795022554173} | train loss {'Reaction outcome loss': 0.12442799327562706, 'Total loss': 0.12442799327562706}
2022-12-05 20:16:59,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:16:59,275 INFO:     Epoch: 69
2022-12-05 20:17:00,050 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4556382378173429, 'Total loss': 0.4556382378173429} | train loss {'Reaction outcome loss': 0.12173457534334534, 'Total loss': 0.12173457534334534}
2022-12-05 20:17:00,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:00,050 INFO:     Epoch: 70
2022-12-05 20:17:00,826 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44367776170026424, 'Total loss': 0.44367776170026424} | train loss {'Reaction outcome loss': 0.1215879111840579, 'Total loss': 0.1215879111840579}
2022-12-05 20:17:00,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:00,826 INFO:     Epoch: 71
2022-12-05 20:17:01,606 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4430394439503204, 'Total loss': 0.4430394439503204} | train loss {'Reaction outcome loss': 0.12182417081058396, 'Total loss': 0.12182417081058396}
2022-12-05 20:17:01,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:01,606 INFO:     Epoch: 72
2022-12-05 20:17:02,383 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4420438552665156, 'Total loss': 0.4420438552665156} | train loss {'Reaction outcome loss': 0.12154825174740488, 'Total loss': 0.12154825174740488}
2022-12-05 20:17:02,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:02,384 INFO:     Epoch: 73
2022-12-05 20:17:03,167 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4483536833594012, 'Total loss': 0.4483536833594012} | train loss {'Reaction outcome loss': 0.12128656108658838, 'Total loss': 0.12128656108658838}
2022-12-05 20:17:03,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:03,167 INFO:     Epoch: 74
2022-12-05 20:17:03,939 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45585806390573813, 'Total loss': 0.45585806390573813} | train loss {'Reaction outcome loss': 0.1180184783213057, 'Total loss': 0.1180184783213057}
2022-12-05 20:17:03,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:03,939 INFO:     Epoch: 75
2022-12-05 20:17:04,710 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4595695422139279, 'Total loss': 0.4595695422139279} | train loss {'Reaction outcome loss': 0.12298458460641105, 'Total loss': 0.12298458460641105}
2022-12-05 20:17:04,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:04,710 INFO:     Epoch: 76
2022-12-05 20:17:05,481 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46193548829056497, 'Total loss': 0.46193548829056497} | train loss {'Reaction outcome loss': 0.12135229596705852, 'Total loss': 0.12135229596705852}
2022-12-05 20:17:05,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:05,482 INFO:     Epoch: 77
2022-12-05 20:17:06,253 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4276124010252398, 'Total loss': 0.4276124010252398} | train loss {'Reaction outcome loss': 0.11901862086164011, 'Total loss': 0.11901862086164011}
2022-12-05 20:17:06,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:06,253 INFO:     Epoch: 78
2022-12-05 20:17:07,026 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4420104674821676, 'Total loss': 0.4420104674821676} | train loss {'Reaction outcome loss': 0.11790876701489647, 'Total loss': 0.11790876701489647}
2022-12-05 20:17:07,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:07,026 INFO:     Epoch: 79
2022-12-05 20:17:07,800 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4553696766149166, 'Total loss': 0.4553696766149166} | train loss {'Reaction outcome loss': 0.11845583086485562, 'Total loss': 0.11845583086485562}
2022-12-05 20:17:07,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:07,800 INFO:     Epoch: 80
2022-12-05 20:17:08,573 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.449436753988266, 'Total loss': 0.449436753988266} | train loss {'Reaction outcome loss': 0.11558334847440735, 'Total loss': 0.11558334847440735}
2022-12-05 20:17:08,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:08,573 INFO:     Epoch: 81
2022-12-05 20:17:09,348 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45013986250688864, 'Total loss': 0.45013986250688864} | train loss {'Reaction outcome loss': 0.1186611759650262, 'Total loss': 0.1186611759650262}
2022-12-05 20:17:09,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:09,348 INFO:     Epoch: 82
2022-12-05 20:17:10,118 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4345691179813341, 'Total loss': 0.4345691179813341} | train loss {'Reaction outcome loss': 0.11670464713559235, 'Total loss': 0.11670464713559235}
2022-12-05 20:17:10,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:10,119 INFO:     Epoch: 83
2022-12-05 20:17:10,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44825186840323517, 'Total loss': 0.44825186840323517} | train loss {'Reaction outcome loss': 0.11419187803826145, 'Total loss': 0.11419187803826145}
2022-12-05 20:17:10,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:10,895 INFO:     Epoch: 84
2022-12-05 20:17:11,675 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43876503286666646, 'Total loss': 0.43876503286666646} | train loss {'Reaction outcome loss': 0.11466906599978688, 'Total loss': 0.11466906599978688}
2022-12-05 20:17:11,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:11,676 INFO:     Epoch: 85
2022-12-05 20:17:12,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4507799999311913, 'Total loss': 0.4507799999311913} | train loss {'Reaction outcome loss': 0.11681923669805418, 'Total loss': 0.11681923669805418}
2022-12-05 20:17:12,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:12,464 INFO:     Epoch: 86
2022-12-05 20:17:13,246 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43767020556815833, 'Total loss': 0.43767020556815833} | train loss {'Reaction outcome loss': 0.11692177338131483, 'Total loss': 0.11692177338131483}
2022-12-05 20:17:13,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:13,247 INFO:     Epoch: 87
2022-12-05 20:17:14,028 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4306212693972643, 'Total loss': 0.4306212693972643} | train loss {'Reaction outcome loss': 0.11523616732449823, 'Total loss': 0.11523616732449823}
2022-12-05 20:17:14,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:14,028 INFO:     Epoch: 88
2022-12-05 20:17:14,803 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4543718676580939, 'Total loss': 0.4543718676580939} | train loss {'Reaction outcome loss': 0.11467440744390503, 'Total loss': 0.11467440744390503}
2022-12-05 20:17:14,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:14,803 INFO:     Epoch: 89
2022-12-05 20:17:15,581 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44418946636277573, 'Total loss': 0.44418946636277573} | train loss {'Reaction outcome loss': 0.1122301206402326, 'Total loss': 0.1122301206402326}
2022-12-05 20:17:15,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:15,582 INFO:     Epoch: 90
2022-12-05 20:17:16,358 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4350794363160466, 'Total loss': 0.4350794363160466} | train loss {'Reaction outcome loss': 0.11555098304022644, 'Total loss': 0.11555098304022644}
2022-12-05 20:17:16,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:16,359 INFO:     Epoch: 91
2022-12-05 20:17:17,134 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4306216312702312, 'Total loss': 0.4306216312702312} | train loss {'Reaction outcome loss': 0.11577698158262553, 'Total loss': 0.11577698158262553}
2022-12-05 20:17:17,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:17,135 INFO:     Epoch: 92
2022-12-05 20:17:17,913 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45045248886873557, 'Total loss': 0.45045248886873557} | train loss {'Reaction outcome loss': 0.11094377828275019, 'Total loss': 0.11094377828275019}
2022-12-05 20:17:17,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:17,914 INFO:     Epoch: 93
2022-12-05 20:17:18,688 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4384128842936006, 'Total loss': 0.4384128842936006} | train loss {'Reaction outcome loss': 0.11425219894352048, 'Total loss': 0.11425219894352048}
2022-12-05 20:17:18,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:18,688 INFO:     Epoch: 94
2022-12-05 20:17:19,465 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44923510939575906, 'Total loss': 0.44923510939575906} | train loss {'Reaction outcome loss': 0.11329625524132207, 'Total loss': 0.11329625524132207}
2022-12-05 20:17:19,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:19,466 INFO:     Epoch: 95
2022-12-05 20:17:20,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4477490727291551, 'Total loss': 0.4477490727291551} | train loss {'Reaction outcome loss': 0.111953332734244, 'Total loss': 0.111953332734244}
2022-12-05 20:17:20,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:20,244 INFO:     Epoch: 96
2022-12-05 20:17:21,018 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4430144221283669, 'Total loss': 0.4430144221283669} | train loss {'Reaction outcome loss': 0.1095639620617774, 'Total loss': 0.1095639620617774}
2022-12-05 20:17:21,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:21,018 INFO:     Epoch: 97
2022-12-05 20:17:21,793 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4486482081025146, 'Total loss': 0.4486482081025146} | train loss {'Reaction outcome loss': 0.11256269309128716, 'Total loss': 0.11256269309128716}
2022-12-05 20:17:21,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:21,793 INFO:     Epoch: 98
2022-12-05 20:17:22,574 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44935839328654975, 'Total loss': 0.44935839328654975} | train loss {'Reaction outcome loss': 0.10947658334321562, 'Total loss': 0.10947658334321562}
2022-12-05 20:17:22,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:22,574 INFO:     Epoch: 99
2022-12-05 20:17:23,347 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43360305352266443, 'Total loss': 0.43360305352266443} | train loss {'Reaction outcome loss': 0.11135806590395968, 'Total loss': 0.11135806590395968}
2022-12-05 20:17:23,347 INFO:     Best model found after epoch 13 of 100.
2022-12-05 20:17:23,347 INFO:   Done with stage: TRAINING
2022-12-05 20:17:23,347 INFO:   Starting stage: EVALUATION
2022-12-05 20:17:23,496 INFO:   Done with stage: EVALUATION
2022-12-05 20:17:23,496 INFO:   Leaving out SEQ value Fold_3
2022-12-05 20:17:23,509 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:17:23,509 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:17:24,144 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:17:24,144 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:17:24,212 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:17:24,213 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:17:24,213 INFO:     No hyperparam tuning for this model
2022-12-05 20:17:24,213 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:17:24,213 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:17:24,213 INFO:     None feature selector for col prot
2022-12-05 20:17:24,214 INFO:     None feature selector for col prot
2022-12-05 20:17:24,214 INFO:     None feature selector for col prot
2022-12-05 20:17:24,214 INFO:     None feature selector for col chem
2022-12-05 20:17:24,214 INFO:     None feature selector for col chem
2022-12-05 20:17:24,214 INFO:     None feature selector for col chem
2022-12-05 20:17:24,214 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:17:24,214 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:17:24,216 INFO:     Number of params in model 215821
2022-12-05 20:17:24,219 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:17:24,219 INFO:   Starting stage: TRAINING
2022-12-05 20:17:24,279 INFO:     Val loss before train {'Reaction outcome loss': 1.005360625510992, 'Total loss': 1.005360625510992}
2022-12-05 20:17:24,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:24,279 INFO:     Epoch: 0
2022-12-05 20:17:25,060 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6195568754229435, 'Total loss': 0.6195568754229435} | train loss {'Reaction outcome loss': 0.801836790975, 'Total loss': 0.801836790975}
2022-12-05 20:17:25,060 INFO:     Found new best model at epoch 0
2022-12-05 20:17:25,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:25,061 INFO:     Epoch: 1
2022-12-05 20:17:25,846 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5244721451471018, 'Total loss': 0.5244721451471018} | train loss {'Reaction outcome loss': 0.5607388936227462, 'Total loss': 0.5607388936227462}
2022-12-05 20:17:25,846 INFO:     Found new best model at epoch 1
2022-12-05 20:17:25,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:25,847 INFO:     Epoch: 2
2022-12-05 20:17:26,632 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4908326878104099, 'Total loss': 0.4908326878104099} | train loss {'Reaction outcome loss': 0.48440301961830406, 'Total loss': 0.48440301961830406}
2022-12-05 20:17:26,632 INFO:     Found new best model at epoch 2
2022-12-05 20:17:26,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:26,633 INFO:     Epoch: 3
2022-12-05 20:17:27,419 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46525976408359615, 'Total loss': 0.46525976408359615} | train loss {'Reaction outcome loss': 0.4383516201718909, 'Total loss': 0.4383516201718909}
2022-12-05 20:17:27,419 INFO:     Found new best model at epoch 3
2022-12-05 20:17:27,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:27,420 INFO:     Epoch: 4
2022-12-05 20:17:28,216 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4576962125855823, 'Total loss': 0.4576962125855823} | train loss {'Reaction outcome loss': 0.4073929099030182, 'Total loss': 0.4073929099030182}
2022-12-05 20:17:28,217 INFO:     Found new best model at epoch 4
2022-12-05 20:17:28,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:28,217 INFO:     Epoch: 5
2022-12-05 20:17:29,016 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4424415466397308, 'Total loss': 0.4424415466397308} | train loss {'Reaction outcome loss': 0.3803851156205427, 'Total loss': 0.3803851156205427}
2022-12-05 20:17:29,016 INFO:     Found new best model at epoch 5
2022-12-05 20:17:29,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:29,017 INFO:     Epoch: 6
2022-12-05 20:17:29,809 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4402621987947198, 'Total loss': 0.4402621987947198} | train loss {'Reaction outcome loss': 0.36025624758884556, 'Total loss': 0.36025624758884556}
2022-12-05 20:17:29,809 INFO:     Found new best model at epoch 6
2022-12-05 20:17:29,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:29,810 INFO:     Epoch: 7
2022-12-05 20:17:30,602 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4378201878348062, 'Total loss': 0.4378201878348062} | train loss {'Reaction outcome loss': 0.34273042813798443, 'Total loss': 0.34273042813798443}
2022-12-05 20:17:30,603 INFO:     Found new best model at epoch 7
2022-12-05 20:17:30,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:30,604 INFO:     Epoch: 8
2022-12-05 20:17:31,400 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43702043870160745, 'Total loss': 0.43702043870160745} | train loss {'Reaction outcome loss': 0.3257296487811159, 'Total loss': 0.3257296487811159}
2022-12-05 20:17:31,400 INFO:     Found new best model at epoch 8
2022-12-05 20:17:31,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:31,401 INFO:     Epoch: 9
2022-12-05 20:17:32,193 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4376446511163268, 'Total loss': 0.4376446511163268} | train loss {'Reaction outcome loss': 0.31259224289020554, 'Total loss': 0.31259224289020554}
2022-12-05 20:17:32,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:32,193 INFO:     Epoch: 10
2022-12-05 20:17:32,985 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43080485802750257, 'Total loss': 0.43080485802750257} | train loss {'Reaction outcome loss': 0.3012793982004533, 'Total loss': 0.3012793982004533}
2022-12-05 20:17:32,985 INFO:     Found new best model at epoch 10
2022-12-05 20:17:32,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:32,986 INFO:     Epoch: 11
2022-12-05 20:17:33,779 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4256841737863629, 'Total loss': 0.4256841737863629} | train loss {'Reaction outcome loss': 0.28739111751440116, 'Total loss': 0.28739111751440116}
2022-12-05 20:17:33,779 INFO:     Found new best model at epoch 11
2022-12-05 20:17:33,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:33,780 INFO:     Epoch: 12
2022-12-05 20:17:34,572 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42342160434223886, 'Total loss': 0.42342160434223886} | train loss {'Reaction outcome loss': 0.277003427387261, 'Total loss': 0.277003427387261}
2022-12-05 20:17:34,572 INFO:     Found new best model at epoch 12
2022-12-05 20:17:34,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:34,573 INFO:     Epoch: 13
2022-12-05 20:17:35,362 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43945405753545985, 'Total loss': 0.43945405753545985} | train loss {'Reaction outcome loss': 0.26721616696993833, 'Total loss': 0.26721616696993833}
2022-12-05 20:17:35,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:35,362 INFO:     Epoch: 14
2022-12-05 20:17:36,146 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42510045787622763, 'Total loss': 0.42510045787622763} | train loss {'Reaction outcome loss': 0.2629430973444317, 'Total loss': 0.2629430973444317}
2022-12-05 20:17:36,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:36,146 INFO:     Epoch: 15
2022-12-05 20:17:36,932 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4206082786238471, 'Total loss': 0.4206082786238471} | train loss {'Reaction outcome loss': 0.25171809988554383, 'Total loss': 0.25171809988554383}
2022-12-05 20:17:36,933 INFO:     Found new best model at epoch 15
2022-12-05 20:17:36,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:36,934 INFO:     Epoch: 16
2022-12-05 20:17:37,719 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43116112018740455, 'Total loss': 0.43116112018740455} | train loss {'Reaction outcome loss': 0.24439872157011852, 'Total loss': 0.24439872157011852}
2022-12-05 20:17:37,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:37,719 INFO:     Epoch: 17
2022-12-05 20:17:38,508 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4230400760506475, 'Total loss': 0.4230400760506475} | train loss {'Reaction outcome loss': 0.23872682268990844, 'Total loss': 0.23872682268990844}
2022-12-05 20:17:38,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:38,508 INFO:     Epoch: 18
2022-12-05 20:17:39,303 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4366514506035073, 'Total loss': 0.4366514506035073} | train loss {'Reaction outcome loss': 0.23419486981679183, 'Total loss': 0.23419486981679183}
2022-12-05 20:17:39,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:39,303 INFO:     Epoch: 19
2022-12-05 20:17:40,092 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4571586791859117, 'Total loss': 0.4571586791859117} | train loss {'Reaction outcome loss': 0.229781142176419, 'Total loss': 0.229781142176419}
2022-12-05 20:17:40,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:40,092 INFO:     Epoch: 20
2022-12-05 20:17:40,877 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4325659223074137, 'Total loss': 0.4325659223074137} | train loss {'Reaction outcome loss': 0.22428373879462968, 'Total loss': 0.22428373879462968}
2022-12-05 20:17:40,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:40,877 INFO:     Epoch: 21
2022-12-05 20:17:41,663 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4306270161340403, 'Total loss': 0.4306270161340403} | train loss {'Reaction outcome loss': 0.21907584124901255, 'Total loss': 0.21907584124901255}
2022-12-05 20:17:41,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:41,663 INFO:     Epoch: 22
2022-12-05 20:17:42,446 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4356593077265939, 'Total loss': 0.4356593077265939} | train loss {'Reaction outcome loss': 0.2133621623525854, 'Total loss': 0.2133621623525854}
2022-12-05 20:17:42,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:42,446 INFO:     Epoch: 23
2022-12-05 20:17:43,236 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4427284064681031, 'Total loss': 0.4427284064681031} | train loss {'Reaction outcome loss': 0.21124265738381226, 'Total loss': 0.21124265738381226}
2022-12-05 20:17:43,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:43,237 INFO:     Epoch: 24
2022-12-05 20:17:44,023 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4309686647598134, 'Total loss': 0.4309686647598134} | train loss {'Reaction outcome loss': 0.20691918054992547, 'Total loss': 0.20691918054992547}
2022-12-05 20:17:44,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:44,023 INFO:     Epoch: 25
2022-12-05 20:17:44,805 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44046105790969936, 'Total loss': 0.44046105790969936} | train loss {'Reaction outcome loss': 0.20007545839934077, 'Total loss': 0.20007545839934077}
2022-12-05 20:17:44,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:44,806 INFO:     Epoch: 26
2022-12-05 20:17:45,589 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4373598275489585, 'Total loss': 0.4373598275489585} | train loss {'Reaction outcome loss': 0.19719884353766187, 'Total loss': 0.19719884353766187}
2022-12-05 20:17:45,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:45,589 INFO:     Epoch: 27
2022-12-05 20:17:46,366 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4451776586992796, 'Total loss': 0.4451776586992796} | train loss {'Reaction outcome loss': 0.19427065655100542, 'Total loss': 0.19427065655100542}
2022-12-05 20:17:46,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:46,366 INFO:     Epoch: 28
2022-12-05 20:17:47,143 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45424217540164324, 'Total loss': 0.45424217540164324} | train loss {'Reaction outcome loss': 0.19072510979947496, 'Total loss': 0.19072510979947496}
2022-12-05 20:17:47,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:47,143 INFO:     Epoch: 29
2022-12-05 20:17:47,919 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4412928722625555, 'Total loss': 0.4412928722625555} | train loss {'Reaction outcome loss': 0.18984162957850295, 'Total loss': 0.18984162957850295}
2022-12-05 20:17:47,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:47,919 INFO:     Epoch: 30
2022-12-05 20:17:48,695 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4525366040856339, 'Total loss': 0.4525366040856339} | train loss {'Reaction outcome loss': 0.18876998030321032, 'Total loss': 0.18876998030321032}
2022-12-05 20:17:48,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:48,696 INFO:     Epoch: 31
2022-12-05 20:17:49,474 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4675175852553789, 'Total loss': 0.4675175852553789} | train loss {'Reaction outcome loss': 0.18445597550847004, 'Total loss': 0.18445597550847004}
2022-12-05 20:17:49,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:49,475 INFO:     Epoch: 32
2022-12-05 20:17:50,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4568139692378599, 'Total loss': 0.4568139692378599} | train loss {'Reaction outcome loss': 0.1852177814656838, 'Total loss': 0.1852177814656838}
2022-12-05 20:17:50,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:50,254 INFO:     Epoch: 33
2022-12-05 20:17:51,030 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46317574000635814, 'Total loss': 0.46317574000635814} | train loss {'Reaction outcome loss': 0.17720745349699846, 'Total loss': 0.17720745349699846}
2022-12-05 20:17:51,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:51,030 INFO:     Epoch: 34
2022-12-05 20:17:51,810 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46317086212856823, 'Total loss': 0.46317086212856823} | train loss {'Reaction outcome loss': 0.17590585004416157, 'Total loss': 0.17590585004416157}
2022-12-05 20:17:51,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:51,811 INFO:     Epoch: 35
2022-12-05 20:17:52,587 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46411052380883416, 'Total loss': 0.46411052380883416} | train loss {'Reaction outcome loss': 0.17397646733452796, 'Total loss': 0.17397646733452796}
2022-12-05 20:17:52,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:52,587 INFO:     Epoch: 36
2022-12-05 20:17:53,362 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4628156725923682, 'Total loss': 0.4628156725923682} | train loss {'Reaction outcome loss': 0.16733393666990956, 'Total loss': 0.16733393666990956}
2022-12-05 20:17:53,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:53,363 INFO:     Epoch: 37
2022-12-05 20:17:54,141 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46076653135377305, 'Total loss': 0.46076653135377305} | train loss {'Reaction outcome loss': 0.1676517939958416, 'Total loss': 0.1676517939958416}
2022-12-05 20:17:54,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:54,141 INFO:     Epoch: 38
2022-12-05 20:17:54,921 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4615445303362469, 'Total loss': 0.4615445303362469} | train loss {'Reaction outcome loss': 0.16709092496817962, 'Total loss': 0.16709092496817962}
2022-12-05 20:17:54,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:54,921 INFO:     Epoch: 39
2022-12-05 20:17:55,698 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45226050254910494, 'Total loss': 0.45226050254910494} | train loss {'Reaction outcome loss': 0.1642044813326392, 'Total loss': 0.1642044813326392}
2022-12-05 20:17:55,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:55,698 INFO:     Epoch: 40
2022-12-05 20:17:56,478 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46893297239791515, 'Total loss': 0.46893297239791515} | train loss {'Reaction outcome loss': 0.16188611716917548, 'Total loss': 0.16188611716917548}
2022-12-05 20:17:56,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:56,478 INFO:     Epoch: 41
2022-12-05 20:17:57,258 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4680074938507967, 'Total loss': 0.4680074938507967} | train loss {'Reaction outcome loss': 0.16180505539428014, 'Total loss': 0.16180505539428014}
2022-12-05 20:17:57,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:57,258 INFO:     Epoch: 42
2022-12-05 20:17:58,041 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48391176621581233, 'Total loss': 0.48391176621581233} | train loss {'Reaction outcome loss': 0.16166309484082167, 'Total loss': 0.16166309484082167}
2022-12-05 20:17:58,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:58,041 INFO:     Epoch: 43
2022-12-05 20:17:58,823 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4684542202672293, 'Total loss': 0.4684542202672293} | train loss {'Reaction outcome loss': 0.15921148616576292, 'Total loss': 0.15921148616576292}
2022-12-05 20:17:58,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:58,823 INFO:     Epoch: 44
2022-12-05 20:17:59,601 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45386712114478267, 'Total loss': 0.45386712114478267} | train loss {'Reaction outcome loss': 0.15423291579621737, 'Total loss': 0.15423291579621737}
2022-12-05 20:17:59,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:17:59,601 INFO:     Epoch: 45
2022-12-05 20:18:00,377 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48775341309780296, 'Total loss': 0.48775341309780296} | train loss {'Reaction outcome loss': 0.15552320654244453, 'Total loss': 0.15552320654244453}
2022-12-05 20:18:00,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:00,378 INFO:     Epoch: 46
2022-12-05 20:18:01,155 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4654159549363824, 'Total loss': 0.4654159549363824} | train loss {'Reaction outcome loss': 0.15361652494270783, 'Total loss': 0.15361652494270783}
2022-12-05 20:18:01,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:01,156 INFO:     Epoch: 47
2022-12-05 20:18:01,937 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4786455211944358, 'Total loss': 0.4786455211944358} | train loss {'Reaction outcome loss': 0.15130011871701382, 'Total loss': 0.15130011871701382}
2022-12-05 20:18:01,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:01,938 INFO:     Epoch: 48
2022-12-05 20:18:02,719 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4782465523065523, 'Total loss': 0.4782465523065523} | train loss {'Reaction outcome loss': 0.14933509886509083, 'Total loss': 0.14933509886509083}
2022-12-05 20:18:02,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:02,719 INFO:     Epoch: 49
2022-12-05 20:18:03,498 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48042483523834584, 'Total loss': 0.48042483523834584} | train loss {'Reaction outcome loss': 0.1493540372638429, 'Total loss': 0.1493540372638429}
2022-12-05 20:18:03,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:03,498 INFO:     Epoch: 50
2022-12-05 20:18:04,275 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.468866333711979, 'Total loss': 0.468866333711979} | train loss {'Reaction outcome loss': 0.14779174729387778, 'Total loss': 0.14779174729387778}
2022-12-05 20:18:04,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:04,275 INFO:     Epoch: 51
2022-12-05 20:18:05,055 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48396274135556333, 'Total loss': 0.48396274135556333} | train loss {'Reaction outcome loss': 0.14692605504399683, 'Total loss': 0.14692605504399683}
2022-12-05 20:18:05,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:05,055 INFO:     Epoch: 52
2022-12-05 20:18:05,833 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49628868179265845, 'Total loss': 0.49628868179265845} | train loss {'Reaction outcome loss': 0.1429269948562027, 'Total loss': 0.1429269948562027}
2022-12-05 20:18:05,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:05,834 INFO:     Epoch: 53
2022-12-05 20:18:06,614 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47258096985345666, 'Total loss': 0.47258096985345666} | train loss {'Reaction outcome loss': 0.14335724325911675, 'Total loss': 0.14335724325911675}
2022-12-05 20:18:06,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:06,614 INFO:     Epoch: 54
2022-12-05 20:18:07,392 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48094244439934575, 'Total loss': 0.48094244439934575} | train loss {'Reaction outcome loss': 0.14650735727770894, 'Total loss': 0.14650735727770894}
2022-12-05 20:18:07,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:07,393 INFO:     Epoch: 55
2022-12-05 20:18:08,172 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4750144117793372, 'Total loss': 0.4750144117793372} | train loss {'Reaction outcome loss': 0.1420396595552075, 'Total loss': 0.1420396595552075}
2022-12-05 20:18:08,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:08,172 INFO:     Epoch: 56
2022-12-05 20:18:08,949 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4839067892279736, 'Total loss': 0.4839067892279736} | train loss {'Reaction outcome loss': 0.13883012804187467, 'Total loss': 0.13883012804187467}
2022-12-05 20:18:08,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:08,950 INFO:     Epoch: 57
2022-12-05 20:18:09,731 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48523723490016407, 'Total loss': 0.48523723490016407} | train loss {'Reaction outcome loss': 0.14332154448922785, 'Total loss': 0.14332154448922785}
2022-12-05 20:18:09,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:09,731 INFO:     Epoch: 58
2022-12-05 20:18:10,514 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4922317510773969, 'Total loss': 0.4922317510773969} | train loss {'Reaction outcome loss': 0.14138086945902495, 'Total loss': 0.14138086945902495}
2022-12-05 20:18:10,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:10,515 INFO:     Epoch: 59
2022-12-05 20:18:11,301 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4844449030798535, 'Total loss': 0.4844449030798535} | train loss {'Reaction outcome loss': 0.13940301944013136, 'Total loss': 0.13940301944013136}
2022-12-05 20:18:11,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:11,301 INFO:     Epoch: 60
2022-12-05 20:18:12,082 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4922827094100242, 'Total loss': 0.4922827094100242} | train loss {'Reaction outcome loss': 0.13708298991541149, 'Total loss': 0.13708298991541149}
2022-12-05 20:18:12,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:12,082 INFO:     Epoch: 61
2022-12-05 20:18:12,859 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47716587539329086, 'Total loss': 0.47716587539329086} | train loss {'Reaction outcome loss': 0.13848780421158452, 'Total loss': 0.13848780421158452}
2022-12-05 20:18:12,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:12,859 INFO:     Epoch: 62
2022-12-05 20:18:13,634 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48920885906663053, 'Total loss': 0.48920885906663053} | train loss {'Reaction outcome loss': 0.13580209009166136, 'Total loss': 0.13580209009166136}
2022-12-05 20:18:13,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:13,635 INFO:     Epoch: 63
2022-12-05 20:18:14,412 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49404471488886104, 'Total loss': 0.49404471488886104} | train loss {'Reaction outcome loss': 0.1364365660845012, 'Total loss': 0.1364365660845012}
2022-12-05 20:18:14,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:14,412 INFO:     Epoch: 64
2022-12-05 20:18:15,189 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4849306379639825, 'Total loss': 0.4849306379639825} | train loss {'Reaction outcome loss': 0.1351413686691066, 'Total loss': 0.1351413686691066}
2022-12-05 20:18:15,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:15,189 INFO:     Epoch: 65
2022-12-05 20:18:15,965 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4867502922235533, 'Total loss': 0.4867502922235533} | train loss {'Reaction outcome loss': 0.13346174987964332, 'Total loss': 0.13346174987964332}
2022-12-05 20:18:15,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:15,965 INFO:     Epoch: 66
2022-12-05 20:18:16,743 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48210244608479874, 'Total loss': 0.48210244608479874} | train loss {'Reaction outcome loss': 0.13453431903064006, 'Total loss': 0.13453431903064006}
2022-12-05 20:18:16,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:16,743 INFO:     Epoch: 67
2022-12-05 20:18:17,522 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4809115612229636, 'Total loss': 0.4809115612229636} | train loss {'Reaction outcome loss': 0.13434657138833378, 'Total loss': 0.13434657138833378}
2022-12-05 20:18:17,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:17,522 INFO:     Epoch: 68
2022-12-05 20:18:18,304 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5049123663541882, 'Total loss': 0.5049123663541882} | train loss {'Reaction outcome loss': 0.13081133656478564, 'Total loss': 0.13081133656478564}
2022-12-05 20:18:18,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:18,305 INFO:     Epoch: 69
2022-12-05 20:18:19,085 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4962608280570008, 'Total loss': 0.4962608280570008} | train loss {'Reaction outcome loss': 0.13383160394494284, 'Total loss': 0.13383160394494284}
2022-12-05 20:18:19,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:19,085 INFO:     Epoch: 70
2022-12-05 20:18:19,861 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48726700904757475, 'Total loss': 0.48726700904757475} | train loss {'Reaction outcome loss': 0.13031959535981544, 'Total loss': 0.13031959535981544}
2022-12-05 20:18:19,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:19,862 INFO:     Epoch: 71
2022-12-05 20:18:20,647 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4859317246564599, 'Total loss': 0.4859317246564599} | train loss {'Reaction outcome loss': 0.13054187353853075, 'Total loss': 0.13054187353853075}
2022-12-05 20:18:20,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:20,648 INFO:     Epoch: 72
2022-12-05 20:18:21,441 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4876706946727841, 'Total loss': 0.4876706946727841} | train loss {'Reaction outcome loss': 0.1299902867968576, 'Total loss': 0.1299902867968576}
2022-12-05 20:18:21,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:21,442 INFO:     Epoch: 73
2022-12-05 20:18:22,234 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4884888626808344, 'Total loss': 0.4884888626808344} | train loss {'Reaction outcome loss': 0.1291529758199744, 'Total loss': 0.1291529758199744}
2022-12-05 20:18:22,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:22,234 INFO:     Epoch: 74
2022-12-05 20:18:23,028 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5107845670955126, 'Total loss': 0.5107845670955126} | train loss {'Reaction outcome loss': 0.12923230732730057, 'Total loss': 0.12923230732730057}
2022-12-05 20:18:23,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:23,029 INFO:     Epoch: 75
2022-12-05 20:18:23,825 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4857083850128706, 'Total loss': 0.4857083850128706} | train loss {'Reaction outcome loss': 0.12825092785518433, 'Total loss': 0.12825092785518433}
2022-12-05 20:18:23,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:23,825 INFO:     Epoch: 76
2022-12-05 20:18:24,620 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4919934234646864, 'Total loss': 0.4919934234646864} | train loss {'Reaction outcome loss': 0.12955078152084692, 'Total loss': 0.12955078152084692}
2022-12-05 20:18:24,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:24,620 INFO:     Epoch: 77
2022-12-05 20:18:25,412 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48680887007436086, 'Total loss': 0.48680887007436086} | train loss {'Reaction outcome loss': 0.12675941773675015, 'Total loss': 0.12675941773675015}
2022-12-05 20:18:25,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:25,412 INFO:     Epoch: 78
2022-12-05 20:18:26,204 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4931686402753342, 'Total loss': 0.4931686402753342} | train loss {'Reaction outcome loss': 0.12673530801100139, 'Total loss': 0.12673530801100139}
2022-12-05 20:18:26,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:26,204 INFO:     Epoch: 79
2022-12-05 20:18:26,998 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49580588936805725, 'Total loss': 0.49580588936805725} | train loss {'Reaction outcome loss': 0.12614732559724542, 'Total loss': 0.12614732559724542}
2022-12-05 20:18:26,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:26,998 INFO:     Epoch: 80
2022-12-05 20:18:27,789 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49177342861197715, 'Total loss': 0.49177342861197715} | train loss {'Reaction outcome loss': 0.12764106366829184, 'Total loss': 0.12764106366829184}
2022-12-05 20:18:27,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:27,790 INFO:     Epoch: 81
2022-12-05 20:18:28,582 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49466805749161297, 'Total loss': 0.49466805749161297} | train loss {'Reaction outcome loss': 0.12444356669763439, 'Total loss': 0.12444356669763439}
2022-12-05 20:18:28,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:28,582 INFO:     Epoch: 82
2022-12-05 20:18:29,374 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48598265786503636, 'Total loss': 0.48598265786503636} | train loss {'Reaction outcome loss': 0.12524242251806084, 'Total loss': 0.12524242251806084}
2022-12-05 20:18:29,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:29,374 INFO:     Epoch: 83
2022-12-05 20:18:30,165 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4838167571051176, 'Total loss': 0.4838167571051176} | train loss {'Reaction outcome loss': 0.1230559752887634, 'Total loss': 0.1230559752887634}
2022-12-05 20:18:30,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:30,165 INFO:     Epoch: 84
2022-12-05 20:18:30,963 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5052212393561075, 'Total loss': 0.5052212393561075} | train loss {'Reaction outcome loss': 0.12140967801106392, 'Total loss': 0.12140967801106392}
2022-12-05 20:18:30,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:30,964 INFO:     Epoch: 85
2022-12-05 20:18:31,759 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5014670584783998, 'Total loss': 0.5014670584783998} | train loss {'Reaction outcome loss': 0.12139326023304316, 'Total loss': 0.12139326023304316}
2022-12-05 20:18:31,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:31,759 INFO:     Epoch: 86
2022-12-05 20:18:32,554 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.501997099366299, 'Total loss': 0.501997099366299} | train loss {'Reaction outcome loss': 0.1231164945419267, 'Total loss': 0.1231164945419267}
2022-12-05 20:18:32,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:32,555 INFO:     Epoch: 87
2022-12-05 20:18:33,347 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4801581827707069, 'Total loss': 0.4801581827707069} | train loss {'Reaction outcome loss': 0.12326162795108728, 'Total loss': 0.12326162795108728}
2022-12-05 20:18:33,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:33,347 INFO:     Epoch: 88
2022-12-05 20:18:34,141 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4932650261840155, 'Total loss': 0.4932650261840155} | train loss {'Reaction outcome loss': 0.12119706821643182, 'Total loss': 0.12119706821643182}
2022-12-05 20:18:34,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:34,141 INFO:     Epoch: 89
2022-12-05 20:18:34,934 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4855067553215249, 'Total loss': 0.4855067553215249} | train loss {'Reaction outcome loss': 0.12105947777964786, 'Total loss': 0.12105947777964786}
2022-12-05 20:18:34,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:34,934 INFO:     Epoch: 90
2022-12-05 20:18:35,728 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4975770795068076, 'Total loss': 0.4975770795068076} | train loss {'Reaction outcome loss': 0.12156977871677181, 'Total loss': 0.12156977871677181}
2022-12-05 20:18:35,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:35,728 INFO:     Epoch: 91
2022-12-05 20:18:36,520 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49424533996471137, 'Total loss': 0.49424533996471137} | train loss {'Reaction outcome loss': 0.12182188852781765, 'Total loss': 0.12182188852781765}
2022-12-05 20:18:36,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:36,520 INFO:     Epoch: 92
2022-12-05 20:18:37,315 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47965116694916127, 'Total loss': 0.47965116694916127} | train loss {'Reaction outcome loss': 0.12148828863941102, 'Total loss': 0.12148828863941102}
2022-12-05 20:18:37,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:37,315 INFO:     Epoch: 93
2022-12-05 20:18:38,106 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5091073114511578, 'Total loss': 0.5091073114511578} | train loss {'Reaction outcome loss': 0.12017484723407103, 'Total loss': 0.12017484723407103}
2022-12-05 20:18:38,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:38,106 INFO:     Epoch: 94
2022-12-05 20:18:38,901 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5120573061150174, 'Total loss': 0.5120573061150174} | train loss {'Reaction outcome loss': 0.1220776752690922, 'Total loss': 0.1220776752690922}
2022-12-05 20:18:38,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:38,902 INFO:     Epoch: 95
2022-12-05 20:18:39,693 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4922822426224864, 'Total loss': 0.4922822426224864} | train loss {'Reaction outcome loss': 0.12069321697058737, 'Total loss': 0.12069321697058737}
2022-12-05 20:18:39,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:39,693 INFO:     Epoch: 96
2022-12-05 20:18:40,486 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5046104806107145, 'Total loss': 0.5046104806107145} | train loss {'Reaction outcome loss': 0.11933291512617811, 'Total loss': 0.11933291512617811}
2022-12-05 20:18:40,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:40,486 INFO:     Epoch: 97
2022-12-05 20:18:41,278 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49884640927924667, 'Total loss': 0.49884640927924667} | train loss {'Reaction outcome loss': 0.11927125520515637, 'Total loss': 0.11927125520515637}
2022-12-05 20:18:41,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:41,279 INFO:     Epoch: 98
2022-12-05 20:18:42,070 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5120579704295757, 'Total loss': 0.5120579704295757} | train loss {'Reaction outcome loss': 0.11726220032261288, 'Total loss': 0.11726220032261288}
2022-12-05 20:18:42,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:42,070 INFO:     Epoch: 99
2022-12-05 20:18:42,864 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5072213605392811, 'Total loss': 0.5072213605392811} | train loss {'Reaction outcome loss': 0.12124016746634343, 'Total loss': 0.12124016746634343}
2022-12-05 20:18:42,865 INFO:     Best model found after epoch 16 of 100.
2022-12-05 20:18:42,865 INFO:   Done with stage: TRAINING
2022-12-05 20:18:42,865 INFO:   Starting stage: EVALUATION
2022-12-05 20:18:43,002 INFO:   Done with stage: EVALUATION
2022-12-05 20:18:43,003 INFO:   Leaving out SEQ value Fold_4
2022-12-05 20:18:43,015 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:18:43,015 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:18:43,652 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:18:43,652 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:18:43,720 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:18:43,720 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:18:43,720 INFO:     No hyperparam tuning for this model
2022-12-05 20:18:43,720 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:18:43,720 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:18:43,721 INFO:     None feature selector for col prot
2022-12-05 20:18:43,721 INFO:     None feature selector for col prot
2022-12-05 20:18:43,721 INFO:     None feature selector for col prot
2022-12-05 20:18:43,722 INFO:     None feature selector for col chem
2022-12-05 20:18:43,722 INFO:     None feature selector for col chem
2022-12-05 20:18:43,722 INFO:     None feature selector for col chem
2022-12-05 20:18:43,722 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:18:43,722 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:18:43,724 INFO:     Number of params in model 215821
2022-12-05 20:18:43,727 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:18:43,727 INFO:   Starting stage: TRAINING
2022-12-05 20:18:43,787 INFO:     Val loss before train {'Reaction outcome loss': 0.9723613939502023, 'Total loss': 0.9723613939502023}
2022-12-05 20:18:43,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:43,787 INFO:     Epoch: 0
2022-12-05 20:18:44,589 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5903424925424836, 'Total loss': 0.5903424925424836} | train loss {'Reaction outcome loss': 0.7855828982072803, 'Total loss': 0.7855828982072803}
2022-12-05 20:18:44,589 INFO:     Found new best model at epoch 0
2022-12-05 20:18:44,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:44,590 INFO:     Epoch: 1
2022-12-05 20:18:45,394 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5192987812174992, 'Total loss': 0.5192987812174992} | train loss {'Reaction outcome loss': 0.5336468008607023, 'Total loss': 0.5336468008607023}
2022-12-05 20:18:45,394 INFO:     Found new best model at epoch 1
2022-12-05 20:18:45,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:45,395 INFO:     Epoch: 2
2022-12-05 20:18:46,198 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47269115901806136, 'Total loss': 0.47269115901806136} | train loss {'Reaction outcome loss': 0.4705027413030385, 'Total loss': 0.4705027413030385}
2022-12-05 20:18:46,198 INFO:     Found new best model at epoch 2
2022-12-05 20:18:46,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:46,199 INFO:     Epoch: 3
2022-12-05 20:18:47,003 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4553046961399642, 'Total loss': 0.4553046961399642} | train loss {'Reaction outcome loss': 0.43207472387837015, 'Total loss': 0.43207472387837015}
2022-12-05 20:18:47,003 INFO:     Found new best model at epoch 3
2022-12-05 20:18:47,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:47,004 INFO:     Epoch: 4
2022-12-05 20:18:47,808 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4490444114939733, 'Total loss': 0.4490444114939733} | train loss {'Reaction outcome loss': 0.4044747049147301, 'Total loss': 0.4044747049147301}
2022-12-05 20:18:47,808 INFO:     Found new best model at epoch 4
2022-12-05 20:18:47,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:47,809 INFO:     Epoch: 5
2022-12-05 20:18:48,614 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43031307783993805, 'Total loss': 0.43031307783993805} | train loss {'Reaction outcome loss': 0.3794263197403205, 'Total loss': 0.3794263197403205}
2022-12-05 20:18:48,614 INFO:     Found new best model at epoch 5
2022-12-05 20:18:48,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:48,615 INFO:     Epoch: 6
2022-12-05 20:18:49,419 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43553806672042067, 'Total loss': 0.43553806672042067} | train loss {'Reaction outcome loss': 0.3572238673067648, 'Total loss': 0.3572238673067648}
2022-12-05 20:18:49,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:49,419 INFO:     Epoch: 7
2022-12-05 20:18:50,223 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42927136339924554, 'Total loss': 0.42927136339924554} | train loss {'Reaction outcome loss': 0.340657053304165, 'Total loss': 0.340657053304165}
2022-12-05 20:18:50,224 INFO:     Found new best model at epoch 7
2022-12-05 20:18:50,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:50,224 INFO:     Epoch: 8
2022-12-05 20:18:51,030 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4301069690422578, 'Total loss': 0.4301069690422578} | train loss {'Reaction outcome loss': 0.32225348007476884, 'Total loss': 0.32225348007476884}
2022-12-05 20:18:51,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:51,030 INFO:     Epoch: 9
2022-12-05 20:18:51,834 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4214167097075419, 'Total loss': 0.4214167097075419} | train loss {'Reaction outcome loss': 0.3106014187700353, 'Total loss': 0.3106014187700353}
2022-12-05 20:18:51,835 INFO:     Found new best model at epoch 9
2022-12-05 20:18:51,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:51,835 INFO:     Epoch: 10
2022-12-05 20:18:52,640 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4200818779116327, 'Total loss': 0.4200818779116327} | train loss {'Reaction outcome loss': 0.30043378620133226, 'Total loss': 0.30043378620133226}
2022-12-05 20:18:52,640 INFO:     Found new best model at epoch 10
2022-12-05 20:18:52,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:52,641 INFO:     Epoch: 11
2022-12-05 20:18:53,447 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4230345595966686, 'Total loss': 0.4230345595966686} | train loss {'Reaction outcome loss': 0.28531558763495973, 'Total loss': 0.28531558763495973}
2022-12-05 20:18:53,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:53,447 INFO:     Epoch: 12
2022-12-05 20:18:54,248 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42246425422755157, 'Total loss': 0.42246425422755157} | train loss {'Reaction outcome loss': 0.27781166379779615, 'Total loss': 0.27781166379779615}
2022-12-05 20:18:54,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:54,248 INFO:     Epoch: 13
2022-12-05 20:18:55,054 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42133167216723616, 'Total loss': 0.42133167216723616} | train loss {'Reaction outcome loss': 0.2680285651065213, 'Total loss': 0.2680285651065213}
2022-12-05 20:18:55,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:55,054 INFO:     Epoch: 14
2022-12-05 20:18:55,855 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4062914005057378, 'Total loss': 0.4062914005057378} | train loss {'Reaction outcome loss': 0.26118484516496115, 'Total loss': 0.26118484516496115}
2022-12-05 20:18:55,856 INFO:     Found new best model at epoch 14
2022-12-05 20:18:55,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:55,856 INFO:     Epoch: 15
2022-12-05 20:18:56,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39933728257363493, 'Total loss': 0.39933728257363493} | train loss {'Reaction outcome loss': 0.26081006298301673, 'Total loss': 0.26081006298301673}
2022-12-05 20:18:56,658 INFO:     Found new best model at epoch 15
2022-12-05 20:18:56,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:56,659 INFO:     Epoch: 16
2022-12-05 20:18:57,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41505309532989154, 'Total loss': 0.41505309532989154} | train loss {'Reaction outcome loss': 0.24558211516151543, 'Total loss': 0.24558211516151543}
2022-12-05 20:18:57,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:57,467 INFO:     Epoch: 17
2022-12-05 20:18:58,272 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41064856946468353, 'Total loss': 0.41064856946468353} | train loss {'Reaction outcome loss': 0.24086828949118433, 'Total loss': 0.24086828949118433}
2022-12-05 20:18:58,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:58,272 INFO:     Epoch: 18
2022-12-05 20:18:59,077 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4033070638437163, 'Total loss': 0.4033070638437163} | train loss {'Reaction outcome loss': 0.2341204523919565, 'Total loss': 0.2341204523919565}
2022-12-05 20:18:59,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:59,078 INFO:     Epoch: 19
2022-12-05 20:18:59,883 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39713974872773344, 'Total loss': 0.39713974872773344} | train loss {'Reaction outcome loss': 0.23070805292078841, 'Total loss': 0.23070805292078841}
2022-12-05 20:18:59,884 INFO:     Found new best model at epoch 19
2022-12-05 20:18:59,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:18:59,885 INFO:     Epoch: 20
2022-12-05 20:19:00,686 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.412234001877633, 'Total loss': 0.412234001877633} | train loss {'Reaction outcome loss': 0.2245706949337774, 'Total loss': 0.2245706949337774}
2022-12-05 20:19:00,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:00,687 INFO:     Epoch: 21
2022-12-05 20:19:01,488 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41372873168438673, 'Total loss': 0.41372873168438673} | train loss {'Reaction outcome loss': 0.2193563440776909, 'Total loss': 0.2193563440776909}
2022-12-05 20:19:01,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:01,488 INFO:     Epoch: 22
2022-12-05 20:19:02,289 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4107501535591754, 'Total loss': 0.4107501535591754} | train loss {'Reaction outcome loss': 0.2093785775878169, 'Total loss': 0.2093785775878169}
2022-12-05 20:19:02,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:02,289 INFO:     Epoch: 23
2022-12-05 20:19:03,091 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4173348139632832, 'Total loss': 0.4173348139632832} | train loss {'Reaction outcome loss': 0.21259003972657298, 'Total loss': 0.21259003972657298}
2022-12-05 20:19:03,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:03,091 INFO:     Epoch: 24
2022-12-05 20:19:03,895 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4177061967890371, 'Total loss': 0.4177061967890371} | train loss {'Reaction outcome loss': 0.20105999334515468, 'Total loss': 0.20105999334515468}
2022-12-05 20:19:03,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:03,896 INFO:     Epoch: 25
2022-12-05 20:19:04,697 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4032025963745334, 'Total loss': 0.4032025963745334} | train loss {'Reaction outcome loss': 0.20051311365204302, 'Total loss': 0.20051311365204302}
2022-12-05 20:19:04,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:04,697 INFO:     Epoch: 26
2022-12-05 20:19:05,500 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4239699473096566, 'Total loss': 0.4239699473096566} | train loss {'Reaction outcome loss': 0.19528106386728042, 'Total loss': 0.19528106386728042}
2022-12-05 20:19:05,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:05,501 INFO:     Epoch: 27
2022-12-05 20:19:06,303 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42306445572863927, 'Total loss': 0.42306445572863927} | train loss {'Reaction outcome loss': 0.18963831622409916, 'Total loss': 0.18963831622409916}
2022-12-05 20:19:06,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:06,303 INFO:     Epoch: 28
2022-12-05 20:19:07,108 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4231285805051977, 'Total loss': 0.4231285805051977} | train loss {'Reaction outcome loss': 0.18811946724228532, 'Total loss': 0.18811946724228532}
2022-12-05 20:19:07,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:07,109 INFO:     Epoch: 29
2022-12-05 20:19:07,917 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4295956079255451, 'Total loss': 0.4295956079255451} | train loss {'Reaction outcome loss': 0.18355642041938025, 'Total loss': 0.18355642041938025}
2022-12-05 20:19:07,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:07,918 INFO:     Epoch: 30
2022-12-05 20:19:08,724 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41828181442211976, 'Total loss': 0.41828181442211976} | train loss {'Reaction outcome loss': 0.18106520830970332, 'Total loss': 0.18106520830970332}
2022-12-05 20:19:08,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:08,724 INFO:     Epoch: 31
2022-12-05 20:19:09,526 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4262688495218754, 'Total loss': 0.4262688495218754} | train loss {'Reaction outcome loss': 0.1800312303856905, 'Total loss': 0.1800312303856905}
2022-12-05 20:19:09,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:09,526 INFO:     Epoch: 32
2022-12-05 20:19:10,327 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42503126947717235, 'Total loss': 0.42503126947717235} | train loss {'Reaction outcome loss': 0.17561407199483892, 'Total loss': 0.17561407199483892}
2022-12-05 20:19:10,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:10,328 INFO:     Epoch: 33
2022-12-05 20:19:11,130 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4356668042865666, 'Total loss': 0.4356668042865666} | train loss {'Reaction outcome loss': 0.17091814044727247, 'Total loss': 0.17091814044727247}
2022-12-05 20:19:11,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:11,131 INFO:     Epoch: 34
2022-12-05 20:19:11,933 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42925022169947624, 'Total loss': 0.42925022169947624} | train loss {'Reaction outcome loss': 0.17266389485524009, 'Total loss': 0.17266389485524009}
2022-12-05 20:19:11,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:11,934 INFO:     Epoch: 35
2022-12-05 20:19:12,740 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4233502312140031, 'Total loss': 0.4233502312140031} | train loss {'Reaction outcome loss': 0.16601372413103457, 'Total loss': 0.16601372413103457}
2022-12-05 20:19:12,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:12,741 INFO:     Epoch: 36
2022-12-05 20:19:13,548 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4332591280002486, 'Total loss': 0.4332591280002486} | train loss {'Reaction outcome loss': 0.16353334695372262, 'Total loss': 0.16353334695372262}
2022-12-05 20:19:13,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:13,548 INFO:     Epoch: 37
2022-12-05 20:19:14,350 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42006312615492125, 'Total loss': 0.42006312615492125} | train loss {'Reaction outcome loss': 0.1640378491809735, 'Total loss': 0.1640378491809735}
2022-12-05 20:19:14,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:14,350 INFO:     Epoch: 38
2022-12-05 20:19:15,153 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4254938827996904, 'Total loss': 0.4254938827996904} | train loss {'Reaction outcome loss': 0.1624518838156814, 'Total loss': 0.1624518838156814}
2022-12-05 20:19:15,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:15,153 INFO:     Epoch: 39
2022-12-05 20:19:15,954 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43253337761217897, 'Total loss': 0.43253337761217897} | train loss {'Reaction outcome loss': 0.16792270655815417, 'Total loss': 0.16792270655815417}
2022-12-05 20:19:15,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:15,955 INFO:     Epoch: 40
2022-12-05 20:19:16,757 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44018644196065987, 'Total loss': 0.44018644196065987} | train loss {'Reaction outcome loss': 0.16152225875178813, 'Total loss': 0.16152225875178813}
2022-12-05 20:19:16,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:16,757 INFO:     Epoch: 41
2022-12-05 20:19:17,560 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42885123836723243, 'Total loss': 0.42885123836723243} | train loss {'Reaction outcome loss': 0.1605199230269261, 'Total loss': 0.1605199230269261}
2022-12-05 20:19:17,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:17,560 INFO:     Epoch: 42
2022-12-05 20:19:18,366 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4310854734344916, 'Total loss': 0.4310854734344916} | train loss {'Reaction outcome loss': 0.156125505579266, 'Total loss': 0.156125505579266}
2022-12-05 20:19:18,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:18,366 INFO:     Epoch: 43
2022-12-05 20:19:19,170 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4310024863278324, 'Total loss': 0.4310024863278324} | train loss {'Reaction outcome loss': 0.15583899339118046, 'Total loss': 0.15583899339118046}
2022-12-05 20:19:19,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:19,170 INFO:     Epoch: 44
2022-12-05 20:19:19,972 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45034414986995136, 'Total loss': 0.45034414986995136} | train loss {'Reaction outcome loss': 0.14930633511318853, 'Total loss': 0.14930633511318853}
2022-12-05 20:19:19,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:19,972 INFO:     Epoch: 45
2022-12-05 20:19:20,778 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.447097973390059, 'Total loss': 0.447097973390059} | train loss {'Reaction outcome loss': 0.14840327429505978, 'Total loss': 0.14840327429505978}
2022-12-05 20:19:20,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:20,778 INFO:     Epoch: 46
2022-12-05 20:19:21,586 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4299903471361507, 'Total loss': 0.4299903471361507} | train loss {'Reaction outcome loss': 0.14785575320348446, 'Total loss': 0.14785575320348446}
2022-12-05 20:19:21,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:21,586 INFO:     Epoch: 47
2022-12-05 20:19:22,389 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43836120854724536, 'Total loss': 0.43836120854724536} | train loss {'Reaction outcome loss': 0.1479346866489422, 'Total loss': 0.1479346866489422}
2022-12-05 20:19:22,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:22,390 INFO:     Epoch: 48
2022-12-05 20:19:23,192 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4323914633555846, 'Total loss': 0.4323914633555846} | train loss {'Reaction outcome loss': 0.1495876972410858, 'Total loss': 0.1495876972410858}
2022-12-05 20:19:23,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:23,193 INFO:     Epoch: 49
2022-12-05 20:19:23,997 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43885583574460313, 'Total loss': 0.43885583574460313} | train loss {'Reaction outcome loss': 0.14378099388778512, 'Total loss': 0.14378099388778512}
2022-12-05 20:19:23,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:23,998 INFO:     Epoch: 50
2022-12-05 20:19:24,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43780153278600087, 'Total loss': 0.43780153278600087} | train loss {'Reaction outcome loss': 0.1440765473931304, 'Total loss': 0.1440765473931304}
2022-12-05 20:19:24,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:24,802 INFO:     Epoch: 51
2022-12-05 20:19:25,605 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45084156874905934, 'Total loss': 0.45084156874905934} | train loss {'Reaction outcome loss': 0.14398646383331373, 'Total loss': 0.14398646383331373}
2022-12-05 20:19:25,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:25,605 INFO:     Epoch: 52
2022-12-05 20:19:26,407 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43865464864806697, 'Total loss': 0.43865464864806697} | train loss {'Reaction outcome loss': 0.1404078101215183, 'Total loss': 0.1404078101215183}
2022-12-05 20:19:26,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:26,407 INFO:     Epoch: 53
2022-12-05 20:19:27,210 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4414038631049069, 'Total loss': 0.4414038631049069} | train loss {'Reaction outcome loss': 0.13875484811179792, 'Total loss': 0.13875484811179792}
2022-12-05 20:19:27,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:27,210 INFO:     Epoch: 54
2022-12-05 20:19:28,012 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44691314988515596, 'Total loss': 0.44691314988515596} | train loss {'Reaction outcome loss': 0.13752091984049633, 'Total loss': 0.13752091984049633}
2022-12-05 20:19:28,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:28,013 INFO:     Epoch: 55
2022-12-05 20:19:28,816 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4426268640566956, 'Total loss': 0.4426268640566956} | train loss {'Reaction outcome loss': 0.1404839720810775, 'Total loss': 0.1404839720810775}
2022-12-05 20:19:28,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:28,816 INFO:     Epoch: 56
2022-12-05 20:19:29,626 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44890750402754004, 'Total loss': 0.44890750402754004} | train loss {'Reaction outcome loss': 0.13839939290559605, 'Total loss': 0.13839939290559605}
2022-12-05 20:19:29,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:29,626 INFO:     Epoch: 57
2022-12-05 20:19:30,433 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4404105754061179, 'Total loss': 0.4404105754061179} | train loss {'Reaction outcome loss': 0.13714327155574704, 'Total loss': 0.13714327155574704}
2022-12-05 20:19:30,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:30,433 INFO:     Epoch: 58
2022-12-05 20:19:31,236 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44194511307234113, 'Total loss': 0.44194511307234113} | train loss {'Reaction outcome loss': 0.1364737484426905, 'Total loss': 0.1364737484426905}
2022-12-05 20:19:31,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:31,237 INFO:     Epoch: 59
2022-12-05 20:19:32,044 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44784265011548996, 'Total loss': 0.44784265011548996} | train loss {'Reaction outcome loss': 0.13477099341479873, 'Total loss': 0.13477099341479873}
2022-12-05 20:19:32,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:32,044 INFO:     Epoch: 60
2022-12-05 20:19:32,865 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4441023018549789, 'Total loss': 0.4441023018549789} | train loss {'Reaction outcome loss': 0.13502144115234194, 'Total loss': 0.13502144115234194}
2022-12-05 20:19:32,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:32,865 INFO:     Epoch: 61
2022-12-05 20:19:33,680 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4486171118915081, 'Total loss': 0.4486171118915081} | train loss {'Reaction outcome loss': 0.1350458396013321, 'Total loss': 0.1350458396013321}
2022-12-05 20:19:33,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:33,681 INFO:     Epoch: 62
2022-12-05 20:19:34,493 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45284431105987594, 'Total loss': 0.45284431105987594} | train loss {'Reaction outcome loss': 0.131929583975721, 'Total loss': 0.131929583975721}
2022-12-05 20:19:34,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:34,493 INFO:     Epoch: 63
2022-12-05 20:19:35,308 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4522735974328084, 'Total loss': 0.4522735974328084} | train loss {'Reaction outcome loss': 0.12994112709333538, 'Total loss': 0.12994112709333538}
2022-12-05 20:19:35,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:35,309 INFO:     Epoch: 64
2022-12-05 20:19:36,116 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45437873832204123, 'Total loss': 0.45437873832204123} | train loss {'Reaction outcome loss': 0.1299158425319201, 'Total loss': 0.1299158425319201}
2022-12-05 20:19:36,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:36,116 INFO:     Epoch: 65
2022-12-05 20:19:36,926 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44249720905314793, 'Total loss': 0.44249720905314793} | train loss {'Reaction outcome loss': 0.12997310562200678, 'Total loss': 0.12997310562200678}
2022-12-05 20:19:36,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:36,926 INFO:     Epoch: 66
2022-12-05 20:19:37,734 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44855786402794445, 'Total loss': 0.44855786402794445} | train loss {'Reaction outcome loss': 0.13098840870204484, 'Total loss': 0.13098840870204484}
2022-12-05 20:19:37,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:37,734 INFO:     Epoch: 67
2022-12-05 20:19:38,546 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4311043949035758, 'Total loss': 0.4311043949035758} | train loss {'Reaction outcome loss': 0.12988298848603178, 'Total loss': 0.12988298848603178}
2022-12-05 20:19:38,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:38,546 INFO:     Epoch: 68
2022-12-05 20:19:39,361 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4381341436369853, 'Total loss': 0.4381341436369853} | train loss {'Reaction outcome loss': 0.1309636375689615, 'Total loss': 0.1309636375689615}
2022-12-05 20:19:39,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:39,362 INFO:     Epoch: 69
2022-12-05 20:19:40,183 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45116407898339356, 'Total loss': 0.45116407898339356} | train loss {'Reaction outcome loss': 0.12704838534085616, 'Total loss': 0.12704838534085616}
2022-12-05 20:19:40,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:40,183 INFO:     Epoch: 70
2022-12-05 20:19:41,004 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4629277775741436, 'Total loss': 0.4629277775741436} | train loss {'Reaction outcome loss': 0.13462372014074805, 'Total loss': 0.13462372014074805}
2022-12-05 20:19:41,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:41,005 INFO:     Epoch: 71
2022-12-05 20:19:41,816 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45930383185094054, 'Total loss': 0.45930383185094054} | train loss {'Reaction outcome loss': 0.12759448116200295, 'Total loss': 0.12759448116200295}
2022-12-05 20:19:41,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:41,817 INFO:     Epoch: 72
2022-12-05 20:19:42,637 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4414361735636538, 'Total loss': 0.4414361735636538} | train loss {'Reaction outcome loss': 0.12518953302119168, 'Total loss': 0.12518953302119168}
2022-12-05 20:19:42,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:42,638 INFO:     Epoch: 73
2022-12-05 20:19:43,450 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45375546406615863, 'Total loss': 0.45375546406615863} | train loss {'Reaction outcome loss': 0.1263911339307302, 'Total loss': 0.1263911339307302}
2022-12-05 20:19:43,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:43,450 INFO:     Epoch: 74
2022-12-05 20:19:44,257 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4552284221757542, 'Total loss': 0.4552284221757542} | train loss {'Reaction outcome loss': 0.12295303049946, 'Total loss': 0.12295303049946}
2022-12-05 20:19:44,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:44,257 INFO:     Epoch: 75
2022-12-05 20:19:45,061 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4530000649392605, 'Total loss': 0.4530000649392605} | train loss {'Reaction outcome loss': 0.12599365876964952, 'Total loss': 0.12599365876964952}
2022-12-05 20:19:45,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:45,061 INFO:     Epoch: 76
2022-12-05 20:19:45,873 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4607374979691072, 'Total loss': 0.4607374979691072} | train loss {'Reaction outcome loss': 0.12782805748585507, 'Total loss': 0.12782805748585507}
2022-12-05 20:19:45,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:45,874 INFO:     Epoch: 77
2022-12-05 20:19:46,685 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4606632614000277, 'Total loss': 0.4606632614000277} | train loss {'Reaction outcome loss': 0.1261675116881306, 'Total loss': 0.1261675116881306}
2022-12-05 20:19:46,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:46,685 INFO:     Epoch: 78
2022-12-05 20:19:47,501 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4491499811410904, 'Total loss': 0.4491499811410904} | train loss {'Reaction outcome loss': 0.12400308313217723, 'Total loss': 0.12400308313217723}
2022-12-05 20:19:47,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:47,502 INFO:     Epoch: 79
2022-12-05 20:19:48,314 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45834194936535577, 'Total loss': 0.45834194936535577} | train loss {'Reaction outcome loss': 0.12256753673166157, 'Total loss': 0.12256753673166157}
2022-12-05 20:19:48,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:48,314 INFO:     Epoch: 80
2022-12-05 20:19:49,128 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44689044915139675, 'Total loss': 0.44689044915139675} | train loss {'Reaction outcome loss': 0.12931293011963488, 'Total loss': 0.12931293011963488}
2022-12-05 20:19:49,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:49,128 INFO:     Epoch: 81
2022-12-05 20:19:49,938 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44743478865447367, 'Total loss': 0.44743478865447367} | train loss {'Reaction outcome loss': 0.12456273856249483, 'Total loss': 0.12456273856249483}
2022-12-05 20:19:49,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:49,939 INFO:     Epoch: 82
2022-12-05 20:19:50,747 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4480454053052447, 'Total loss': 0.4480454053052447} | train loss {'Reaction outcome loss': 0.12136233142513013, 'Total loss': 0.12136233142513013}
2022-12-05 20:19:50,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:50,747 INFO:     Epoch: 83
2022-12-05 20:19:51,550 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44430584054101596, 'Total loss': 0.44430584054101596} | train loss {'Reaction outcome loss': 0.12397081431341715, 'Total loss': 0.12397081431341715}
2022-12-05 20:19:51,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:51,550 INFO:     Epoch: 84
2022-12-05 20:19:52,357 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4508458071134307, 'Total loss': 0.4508458071134307} | train loss {'Reaction outcome loss': 0.11907632263218947, 'Total loss': 0.11907632263218947}
2022-12-05 20:19:52,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:52,357 INFO:     Epoch: 85
2022-12-05 20:19:53,161 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.442452860488133, 'Total loss': 0.442452860488133} | train loss {'Reaction outcome loss': 0.11861688472982873, 'Total loss': 0.11861688472982873}
2022-12-05 20:19:53,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:53,161 INFO:     Epoch: 86
2022-12-05 20:19:53,978 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4558401114561341, 'Total loss': 0.4558401114561341} | train loss {'Reaction outcome loss': 0.11826275632837373, 'Total loss': 0.11826275632837373}
2022-12-05 20:19:53,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:53,979 INFO:     Epoch: 87
2022-12-05 20:19:54,790 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44751349023797293, 'Total loss': 0.44751349023797293} | train loss {'Reaction outcome loss': 0.12109365526903496, 'Total loss': 0.12109365526903496}
2022-12-05 20:19:54,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:54,790 INFO:     Epoch: 88
2022-12-05 20:19:55,603 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4621961480853232, 'Total loss': 0.4621961480853232} | train loss {'Reaction outcome loss': 0.1210600561386932, 'Total loss': 0.1210600561386932}
2022-12-05 20:19:55,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:55,603 INFO:     Epoch: 89
2022-12-05 20:19:56,414 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44131060046228493, 'Total loss': 0.44131060046228493} | train loss {'Reaction outcome loss': 0.1194745194702315, 'Total loss': 0.1194745194702315}
2022-12-05 20:19:56,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:56,415 INFO:     Epoch: 90
2022-12-05 20:19:57,227 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46085252341899, 'Total loss': 0.46085252341899} | train loss {'Reaction outcome loss': 0.12734494480466554, 'Total loss': 0.12734494480466554}
2022-12-05 20:19:57,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:57,227 INFO:     Epoch: 91
2022-12-05 20:19:58,042 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45261352170597424, 'Total loss': 0.45261352170597424} | train loss {'Reaction outcome loss': 0.12000020494616707, 'Total loss': 0.12000020494616707}
2022-12-05 20:19:58,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:58,042 INFO:     Epoch: 92
2022-12-05 20:19:58,858 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46503122472627595, 'Total loss': 0.46503122472627595} | train loss {'Reaction outcome loss': 0.11766513610100336, 'Total loss': 0.11766513610100336}
2022-12-05 20:19:58,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:58,859 INFO:     Epoch: 93
2022-12-05 20:19:59,665 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4739068716087125, 'Total loss': 0.4739068716087125} | train loss {'Reaction outcome loss': 0.11771848116839222, 'Total loss': 0.11771848116839222}
2022-12-05 20:19:59,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:19:59,665 INFO:     Epoch: 94
2022-12-05 20:20:00,472 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4552333592013879, 'Total loss': 0.4552333592013879} | train loss {'Reaction outcome loss': 0.11600017063281978, 'Total loss': 0.11600017063281978}
2022-12-05 20:20:00,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:00,472 INFO:     Epoch: 95
2022-12-05 20:20:01,283 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45596173050051386, 'Total loss': 0.45596173050051386} | train loss {'Reaction outcome loss': 0.11451251047704866, 'Total loss': 0.11451251047704866}
2022-12-05 20:20:01,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:01,283 INFO:     Epoch: 96
2022-12-05 20:20:02,099 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45781137963587587, 'Total loss': 0.45781137963587587} | train loss {'Reaction outcome loss': 0.11689375840534687, 'Total loss': 0.11689375840534687}
2022-12-05 20:20:02,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:02,100 INFO:     Epoch: 97
2022-12-05 20:20:02,911 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46903112225911836, 'Total loss': 0.46903112225911836} | train loss {'Reaction outcome loss': 0.11530824438838462, 'Total loss': 0.11530824438838462}
2022-12-05 20:20:02,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:02,912 INFO:     Epoch: 98
2022-12-05 20:20:03,722 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46111072159626265, 'Total loss': 0.46111072159626265} | train loss {'Reaction outcome loss': 0.11845291853478924, 'Total loss': 0.11845291853478924}
2022-12-05 20:20:03,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:03,722 INFO:     Epoch: 99
2022-12-05 20:20:04,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47636168145320634, 'Total loss': 0.47636168145320634} | train loss {'Reaction outcome loss': 0.12155058658549842, 'Total loss': 0.12155058658549842}
2022-12-05 20:20:04,540 INFO:     Best model found after epoch 20 of 100.
2022-12-05 20:20:04,540 INFO:   Done with stage: TRAINING
2022-12-05 20:20:04,540 INFO:   Starting stage: EVALUATION
2022-12-05 20:20:04,667 INFO:   Done with stage: EVALUATION
2022-12-05 20:20:04,667 INFO:   Leaving out SEQ value Fold_5
2022-12-05 20:20:04,680 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:20:04,680 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:20:05,330 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:20:05,330 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:20:05,399 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:20:05,399 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:20:05,399 INFO:     No hyperparam tuning for this model
2022-12-05 20:20:05,399 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:20:05,399 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:20:05,400 INFO:     None feature selector for col prot
2022-12-05 20:20:05,400 INFO:     None feature selector for col prot
2022-12-05 20:20:05,400 INFO:     None feature selector for col prot
2022-12-05 20:20:05,401 INFO:     None feature selector for col chem
2022-12-05 20:20:05,401 INFO:     None feature selector for col chem
2022-12-05 20:20:05,401 INFO:     None feature selector for col chem
2022-12-05 20:20:05,401 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:20:05,401 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:20:05,403 INFO:     Number of params in model 215821
2022-12-05 20:20:05,406 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:20:05,406 INFO:   Starting stage: TRAINING
2022-12-05 20:20:05,467 INFO:     Val loss before train {'Reaction outcome loss': 1.0223861512812702, 'Total loss': 1.0223861512812702}
2022-12-05 20:20:05,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:05,467 INFO:     Epoch: 0
2022-12-05 20:20:06,277 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.652783914045854, 'Total loss': 0.652783914045854} | train loss {'Reaction outcome loss': 0.7892628648141136, 'Total loss': 0.7892628648141136}
2022-12-05 20:20:06,277 INFO:     Found new best model at epoch 0
2022-12-05 20:20:06,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:06,278 INFO:     Epoch: 1
2022-12-05 20:20:07,087 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5647587234323675, 'Total loss': 0.5647587234323675} | train loss {'Reaction outcome loss': 0.5440415169304682, 'Total loss': 0.5440415169304682}
2022-12-05 20:20:07,088 INFO:     Found new best model at epoch 1
2022-12-05 20:20:07,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:07,089 INFO:     Epoch: 2
2022-12-05 20:20:07,897 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5256253765387968, 'Total loss': 0.5256253765387968} | train loss {'Reaction outcome loss': 0.48145190026113377, 'Total loss': 0.48145190026113377}
2022-12-05 20:20:07,897 INFO:     Found new best model at epoch 2
2022-12-05 20:20:07,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:07,898 INFO:     Epoch: 3
2022-12-05 20:20:08,700 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49752469191497023, 'Total loss': 0.49752469191497023} | train loss {'Reaction outcome loss': 0.44510363235406064, 'Total loss': 0.44510363235406064}
2022-12-05 20:20:08,701 INFO:     Found new best model at epoch 3
2022-12-05 20:20:08,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:08,701 INFO:     Epoch: 4
2022-12-05 20:20:09,504 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4835647300563075, 'Total loss': 0.4835647300563075} | train loss {'Reaction outcome loss': 0.4156455506498997, 'Total loss': 0.4156455506498997}
2022-12-05 20:20:09,504 INFO:     Found new best model at epoch 4
2022-12-05 20:20:09,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:09,505 INFO:     Epoch: 5
2022-12-05 20:20:10,313 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47108009085059166, 'Total loss': 0.47108009085059166} | train loss {'Reaction outcome loss': 0.4006624671249737, 'Total loss': 0.4006624671249737}
2022-12-05 20:20:10,313 INFO:     Found new best model at epoch 5
2022-12-05 20:20:10,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:10,314 INFO:     Epoch: 6
2022-12-05 20:20:11,127 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4598897065628659, 'Total loss': 0.4598897065628659} | train loss {'Reaction outcome loss': 0.37237939844850587, 'Total loss': 0.37237939844850587}
2022-12-05 20:20:11,127 INFO:     Found new best model at epoch 6
2022-12-05 20:20:11,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:11,128 INFO:     Epoch: 7
2022-12-05 20:20:11,942 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44862705773927947, 'Total loss': 0.44862705773927947} | train loss {'Reaction outcome loss': 0.3557157250128777, 'Total loss': 0.3557157250128777}
2022-12-05 20:20:11,942 INFO:     Found new best model at epoch 7
2022-12-05 20:20:11,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:11,943 INFO:     Epoch: 8
2022-12-05 20:20:12,756 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4530965042385188, 'Total loss': 0.4530965042385188} | train loss {'Reaction outcome loss': 0.34706117668253206, 'Total loss': 0.34706117668253206}
2022-12-05 20:20:12,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:12,757 INFO:     Epoch: 9
2022-12-05 20:20:13,567 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.431206980550831, 'Total loss': 0.431206980550831} | train loss {'Reaction outcome loss': 0.32647482483734486, 'Total loss': 0.32647482483734486}
2022-12-05 20:20:13,568 INFO:     Found new best model at epoch 9
2022-12-05 20:20:13,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:13,569 INFO:     Epoch: 10
2022-12-05 20:20:14,380 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44139793007211253, 'Total loss': 0.44139793007211253} | train loss {'Reaction outcome loss': 0.31346282008342513, 'Total loss': 0.31346282008342513}
2022-12-05 20:20:14,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:14,380 INFO:     Epoch: 11
2022-12-05 20:20:15,185 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4302362437275323, 'Total loss': 0.4302362437275323} | train loss {'Reaction outcome loss': 0.30217140297658046, 'Total loss': 0.30217140297658046}
2022-12-05 20:20:15,185 INFO:     Found new best model at epoch 11
2022-12-05 20:20:15,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:15,186 INFO:     Epoch: 12
2022-12-05 20:20:15,994 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42393548651175067, 'Total loss': 0.42393548651175067} | train loss {'Reaction outcome loss': 0.29323044024136385, 'Total loss': 0.29323044024136385}
2022-12-05 20:20:15,994 INFO:     Found new best model at epoch 12
2022-12-05 20:20:15,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:15,995 INFO:     Epoch: 13
2022-12-05 20:20:16,807 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43763476474718616, 'Total loss': 0.43763476474718616} | train loss {'Reaction outcome loss': 0.27804028438894374, 'Total loss': 0.27804028438894374}
2022-12-05 20:20:16,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:16,808 INFO:     Epoch: 14
2022-12-05 20:20:17,620 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43633146346970036, 'Total loss': 0.43633146346970036} | train loss {'Reaction outcome loss': 0.2716714584453386, 'Total loss': 0.2716714584453386}
2022-12-05 20:20:17,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:17,620 INFO:     Epoch: 15
2022-12-05 20:20:18,428 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42590729824521323, 'Total loss': 0.42590729824521323} | train loss {'Reaction outcome loss': 0.2605236587435128, 'Total loss': 0.2605236587435128}
2022-12-05 20:20:18,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:18,429 INFO:     Epoch: 16
2022-12-05 20:20:19,237 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4251514920456843, 'Total loss': 0.4251514920456843} | train loss {'Reaction outcome loss': 0.2585255885081977, 'Total loss': 0.2585255885081977}
2022-12-05 20:20:19,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:19,237 INFO:     Epoch: 17
2022-12-05 20:20:20,050 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4345696900378574, 'Total loss': 0.4345696900378574} | train loss {'Reaction outcome loss': 0.2507291142282035, 'Total loss': 0.2507291142282035}
2022-12-05 20:20:20,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:20,050 INFO:     Epoch: 18
2022-12-05 20:20:20,860 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42992829192768445, 'Total loss': 0.42992829192768445} | train loss {'Reaction outcome loss': 0.2392720491116346, 'Total loss': 0.2392720491116346}
2022-12-05 20:20:20,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:20,861 INFO:     Epoch: 19
2022-12-05 20:20:21,668 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4395456984639168, 'Total loss': 0.4395456984639168} | train loss {'Reaction outcome loss': 0.23197721177146502, 'Total loss': 0.23197721177146502}
2022-12-05 20:20:21,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:21,668 INFO:     Epoch: 20
2022-12-05 20:20:22,471 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.424672799015587, 'Total loss': 0.424672799015587} | train loss {'Reaction outcome loss': 0.23035648400303324, 'Total loss': 0.23035648400303324}
2022-12-05 20:20:22,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:22,471 INFO:     Epoch: 21
2022-12-05 20:20:23,273 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4421422610228712, 'Total loss': 0.4421422610228712} | train loss {'Reaction outcome loss': 0.22464297549716133, 'Total loss': 0.22464297549716133}
2022-12-05 20:20:23,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:23,273 INFO:     Epoch: 22
2022-12-05 20:20:24,075 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43267967077818786, 'Total loss': 0.43267967077818786} | train loss {'Reaction outcome loss': 0.21939330492244075, 'Total loss': 0.21939330492244075}
2022-12-05 20:20:24,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:24,075 INFO:     Epoch: 23
2022-12-05 20:20:24,880 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4440429031171582, 'Total loss': 0.4440429031171582} | train loss {'Reaction outcome loss': 0.21630754695473775, 'Total loss': 0.21630754695473775}
2022-12-05 20:20:24,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:24,881 INFO:     Epoch: 24
2022-12-05 20:20:25,683 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4497745128517801, 'Total loss': 0.4497745128517801} | train loss {'Reaction outcome loss': 0.20758426398687396, 'Total loss': 0.20758426398687396}
2022-12-05 20:20:25,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:25,684 INFO:     Epoch: 25
2022-12-05 20:20:26,494 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43542968786575575, 'Total loss': 0.43542968786575575} | train loss {'Reaction outcome loss': 0.2046111447666866, 'Total loss': 0.2046111447666866}
2022-12-05 20:20:26,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:26,495 INFO:     Epoch: 26
2022-12-05 20:20:27,298 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43321720527654345, 'Total loss': 0.43321720527654345} | train loss {'Reaction outcome loss': 0.2025628046694434, 'Total loss': 0.2025628046694434}
2022-12-05 20:20:27,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:27,299 INFO:     Epoch: 27
2022-12-05 20:20:28,103 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4418246651237661, 'Total loss': 0.4418246651237661} | train loss {'Reaction outcome loss': 0.20010971477036535, 'Total loss': 0.20010971477036535}
2022-12-05 20:20:28,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:28,103 INFO:     Epoch: 28
2022-12-05 20:20:28,914 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4381854222579436, 'Total loss': 0.4381854222579436} | train loss {'Reaction outcome loss': 0.1937317273123303, 'Total loss': 0.1937317273123303}
2022-12-05 20:20:28,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:28,914 INFO:     Epoch: 29
2022-12-05 20:20:29,724 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4435801986096935, 'Total loss': 0.4435801986096935} | train loss {'Reaction outcome loss': 0.1913231011284025, 'Total loss': 0.1913231011284025}
2022-12-05 20:20:29,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:29,725 INFO:     Epoch: 30
2022-12-05 20:20:30,538 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4429507865147157, 'Total loss': 0.4429507865147157} | train loss {'Reaction outcome loss': 0.1836517517952633, 'Total loss': 0.1836517517952633}
2022-12-05 20:20:30,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:30,539 INFO:     Epoch: 31
2022-12-05 20:20:31,353 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4437954026189717, 'Total loss': 0.4437954026189717} | train loss {'Reaction outcome loss': 0.1839763528916246, 'Total loss': 0.1839763528916246}
2022-12-05 20:20:31,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:31,353 INFO:     Epoch: 32
2022-12-05 20:20:32,163 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4359080833806233, 'Total loss': 0.4359080833806233} | train loss {'Reaction outcome loss': 0.18074234009452678, 'Total loss': 0.18074234009452678}
2022-12-05 20:20:32,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:32,163 INFO:     Epoch: 33
2022-12-05 20:20:32,972 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.444958625191992, 'Total loss': 0.444958625191992} | train loss {'Reaction outcome loss': 0.18268540138114803, 'Total loss': 0.18268540138114803}
2022-12-05 20:20:32,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:32,972 INFO:     Epoch: 34
2022-12-05 20:20:33,784 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46576985716819763, 'Total loss': 0.46576985716819763} | train loss {'Reaction outcome loss': 0.17638023520126064, 'Total loss': 0.17638023520126064}
2022-12-05 20:20:33,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:33,784 INFO:     Epoch: 35
2022-12-05 20:20:34,581 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4468995759432966, 'Total loss': 0.4468995759432966} | train loss {'Reaction outcome loss': 0.17409961014563738, 'Total loss': 0.17409961014563738}
2022-12-05 20:20:34,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:34,581 INFO:     Epoch: 36
2022-12-05 20:20:35,373 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45315171642736957, 'Total loss': 0.45315171642736957} | train loss {'Reaction outcome loss': 0.1724045145172656, 'Total loss': 0.1724045145172656}
2022-12-05 20:20:35,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:35,374 INFO:     Epoch: 37
2022-12-05 20:20:36,170 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4392852708697319, 'Total loss': 0.4392852708697319} | train loss {'Reaction outcome loss': 0.16825179294928125, 'Total loss': 0.16825179294928125}
2022-12-05 20:20:36,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:36,170 INFO:     Epoch: 38
2022-12-05 20:20:36,968 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4661900072612546, 'Total loss': 0.4661900072612546} | train loss {'Reaction outcome loss': 0.16665324183776672, 'Total loss': 0.16665324183776672}
2022-12-05 20:20:36,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:36,968 INFO:     Epoch: 39
2022-12-05 20:20:37,766 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4621154486455701, 'Total loss': 0.4621154486455701} | train loss {'Reaction outcome loss': 0.1669510354510384, 'Total loss': 0.1669510354510384}
2022-12-05 20:20:37,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:37,768 INFO:     Epoch: 40
2022-12-05 20:20:38,564 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46214002201502974, 'Total loss': 0.46214002201502974} | train loss {'Reaction outcome loss': 0.16297251297781237, 'Total loss': 0.16297251297781237}
2022-12-05 20:20:38,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:38,564 INFO:     Epoch: 41
2022-12-05 20:20:39,361 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44617297263308003, 'Total loss': 0.44617297263308003} | train loss {'Reaction outcome loss': 0.1623131093844349, 'Total loss': 0.1623131093844349}
2022-12-05 20:20:39,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:39,361 INFO:     Epoch: 42
2022-12-05 20:20:40,156 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4609574458815835, 'Total loss': 0.4609574458815835} | train loss {'Reaction outcome loss': 0.166909453198917, 'Total loss': 0.166909453198917}
2022-12-05 20:20:40,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:40,157 INFO:     Epoch: 43
2022-12-05 20:20:40,953 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4527527494356036, 'Total loss': 0.4527527494356036} | train loss {'Reaction outcome loss': 0.16060519604217866, 'Total loss': 0.16060519604217866}
2022-12-05 20:20:40,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:40,954 INFO:     Epoch: 44
2022-12-05 20:20:41,749 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44522644410079176, 'Total loss': 0.44522644410079176} | train loss {'Reaction outcome loss': 0.15829372271774753, 'Total loss': 0.15829372271774753}
2022-12-05 20:20:41,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:41,749 INFO:     Epoch: 45
2022-12-05 20:20:42,547 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4711108813908967, 'Total loss': 0.4711108813908967} | train loss {'Reaction outcome loss': 0.15473849796181025, 'Total loss': 0.15473849796181025}
2022-12-05 20:20:42,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:42,547 INFO:     Epoch: 46
2022-12-05 20:20:43,345 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45510836656798015, 'Total loss': 0.45510836656798015} | train loss {'Reaction outcome loss': 0.1577619424972095, 'Total loss': 0.1577619424972095}
2022-12-05 20:20:43,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:43,345 INFO:     Epoch: 47
2022-12-05 20:20:44,141 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46973917430097406, 'Total loss': 0.46973917430097406} | train loss {'Reaction outcome loss': 0.16133073237743456, 'Total loss': 0.16133073237743456}
2022-12-05 20:20:44,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:44,142 INFO:     Epoch: 48
2022-12-05 20:20:44,939 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4625590176067569, 'Total loss': 0.4625590176067569} | train loss {'Reaction outcome loss': 0.15535721084035117, 'Total loss': 0.15535721084035117}
2022-12-05 20:20:44,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:44,939 INFO:     Epoch: 49
2022-12-05 20:20:45,733 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47518638453700324, 'Total loss': 0.47518638453700324} | train loss {'Reaction outcome loss': 0.15795773905532262, 'Total loss': 0.15795773905532262}
2022-12-05 20:20:45,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:45,733 INFO:     Epoch: 50
2022-12-05 20:20:46,524 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4533118969358673, 'Total loss': 0.4533118969358673} | train loss {'Reaction outcome loss': 0.15036614022032935, 'Total loss': 0.15036614022032935}
2022-12-05 20:20:46,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:46,524 INFO:     Epoch: 51
2022-12-05 20:20:47,320 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4594605195928704, 'Total loss': 0.4594605195928704} | train loss {'Reaction outcome loss': 0.1497885364570621, 'Total loss': 0.1497885364570621}
2022-12-05 20:20:47,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:47,320 INFO:     Epoch: 52
2022-12-05 20:20:48,117 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4628024880181659, 'Total loss': 0.4628024880181659} | train loss {'Reaction outcome loss': 0.1486745571514011, 'Total loss': 0.1486745571514011}
2022-12-05 20:20:48,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:48,117 INFO:     Epoch: 53
2022-12-05 20:20:48,914 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4626850462095304, 'Total loss': 0.4626850462095304} | train loss {'Reaction outcome loss': 0.14377005452745942, 'Total loss': 0.14377005452745942}
2022-12-05 20:20:48,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:48,914 INFO:     Epoch: 54
2022-12-05 20:20:49,713 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4530677819116549, 'Total loss': 0.4530677819116549} | train loss {'Reaction outcome loss': 0.1456786177864841, 'Total loss': 0.1456786177864841}
2022-12-05 20:20:49,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:49,713 INFO:     Epoch: 55
2022-12-05 20:20:50,514 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44735959070650017, 'Total loss': 0.44735959070650017} | train loss {'Reaction outcome loss': 0.14621926511558686, 'Total loss': 0.14621926511558686}
2022-12-05 20:20:50,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:50,515 INFO:     Epoch: 56
2022-12-05 20:20:51,318 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4587756303901022, 'Total loss': 0.4587756303901022} | train loss {'Reaction outcome loss': 0.14671424673002983, 'Total loss': 0.14671424673002983}
2022-12-05 20:20:51,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:51,318 INFO:     Epoch: 57
2022-12-05 20:20:52,115 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45072371715849097, 'Total loss': 0.45072371715849097} | train loss {'Reaction outcome loss': 0.15245697058375307, 'Total loss': 0.15245697058375307}
2022-12-05 20:20:52,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:52,116 INFO:     Epoch: 58
2022-12-05 20:20:52,919 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45380627550184727, 'Total loss': 0.45380627550184727} | train loss {'Reaction outcome loss': 0.1468326949819862, 'Total loss': 0.1468326949819862}
2022-12-05 20:20:52,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:52,919 INFO:     Epoch: 59
2022-12-05 20:20:53,717 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43355703218416736, 'Total loss': 0.43355703218416736} | train loss {'Reaction outcome loss': 0.14038187831919263, 'Total loss': 0.14038187831919263}
2022-12-05 20:20:53,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:53,717 INFO:     Epoch: 60
2022-12-05 20:20:54,517 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45251025225628505, 'Total loss': 0.45251025225628505} | train loss {'Reaction outcome loss': 0.14126819110501873, 'Total loss': 0.14126819110501873}
2022-12-05 20:20:54,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:54,517 INFO:     Epoch: 61
2022-12-05 20:20:55,316 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4482216973873702, 'Total loss': 0.4482216973873702} | train loss {'Reaction outcome loss': 0.14168608208235942, 'Total loss': 0.14168608208235942}
2022-12-05 20:20:55,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:55,316 INFO:     Epoch: 62
2022-12-05 20:20:56,112 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46342331916093826, 'Total loss': 0.46342331916093826} | train loss {'Reaction outcome loss': 0.14335768062787257, 'Total loss': 0.14335768062787257}
2022-12-05 20:20:56,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:56,112 INFO:     Epoch: 63
2022-12-05 20:20:56,915 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45683229579166934, 'Total loss': 0.45683229579166934} | train loss {'Reaction outcome loss': 0.1384028068664465, 'Total loss': 0.1384028068664465}
2022-12-05 20:20:56,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:56,916 INFO:     Epoch: 64
2022-12-05 20:20:57,711 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44253940270705655, 'Total loss': 0.44253940270705655} | train loss {'Reaction outcome loss': 0.1406506160825589, 'Total loss': 0.1406506160825589}
2022-12-05 20:20:57,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:57,711 INFO:     Epoch: 65
2022-12-05 20:20:58,508 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45952533405612817, 'Total loss': 0.45952533405612817} | train loss {'Reaction outcome loss': 0.13950919806259696, 'Total loss': 0.13950919806259696}
2022-12-05 20:20:58,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:58,509 INFO:     Epoch: 66
2022-12-05 20:20:59,304 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4545899785377763, 'Total loss': 0.4545899785377763} | train loss {'Reaction outcome loss': 0.14139236847262995, 'Total loss': 0.14139236847262995}
2022-12-05 20:20:59,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:20:59,305 INFO:     Epoch: 67
2022-12-05 20:21:00,102 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45375925641168247, 'Total loss': 0.45375925641168247} | train loss {'Reaction outcome loss': 0.14102545289251095, 'Total loss': 0.14102545289251095}
2022-12-05 20:21:00,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:00,102 INFO:     Epoch: 68
2022-12-05 20:21:00,896 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4550869519060308, 'Total loss': 0.4550869519060308} | train loss {'Reaction outcome loss': 0.13691611391179234, 'Total loss': 0.13691611391179234}
2022-12-05 20:21:00,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:00,896 INFO:     Epoch: 69
2022-12-05 20:21:01,700 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44735437259078026, 'Total loss': 0.44735437259078026} | train loss {'Reaction outcome loss': 0.14038362140250712, 'Total loss': 0.14038362140250712}
2022-12-05 20:21:01,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:01,700 INFO:     Epoch: 70
2022-12-05 20:21:02,497 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4481885616074909, 'Total loss': 0.4481885616074909} | train loss {'Reaction outcome loss': 0.13564775806855456, 'Total loss': 0.13564775806855456}
2022-12-05 20:21:02,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:02,498 INFO:     Epoch: 71
2022-12-05 20:21:03,295 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45835744217038155, 'Total loss': 0.45835744217038155} | train loss {'Reaction outcome loss': 0.13596392566571955, 'Total loss': 0.13596392566571955}
2022-12-05 20:21:03,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:03,296 INFO:     Epoch: 72
2022-12-05 20:21:04,090 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44512988525358116, 'Total loss': 0.44512988525358116} | train loss {'Reaction outcome loss': 0.13906348486495043, 'Total loss': 0.13906348486495043}
2022-12-05 20:21:04,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:04,090 INFO:     Epoch: 73
2022-12-05 20:21:04,886 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4573812212117694, 'Total loss': 0.4573812212117694} | train loss {'Reaction outcome loss': 0.13385936319978856, 'Total loss': 0.13385936319978856}
2022-12-05 20:21:04,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:04,886 INFO:     Epoch: 74
2022-12-05 20:21:05,681 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4580013115297664, 'Total loss': 0.4580013115297664} | train loss {'Reaction outcome loss': 0.12881992730549593, 'Total loss': 0.12881992730549593}
2022-12-05 20:21:05,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:05,681 INFO:     Epoch: 75
2022-12-05 20:21:06,475 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.449888089671731, 'Total loss': 0.449888089671731} | train loss {'Reaction outcome loss': 0.13045581083401644, 'Total loss': 0.13045581083401644}
2022-12-05 20:21:06,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:06,475 INFO:     Epoch: 76
2022-12-05 20:21:07,265 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4536179873076352, 'Total loss': 0.4536179873076352} | train loss {'Reaction outcome loss': 0.12792304429218082, 'Total loss': 0.12792304429218082}
2022-12-05 20:21:07,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:07,265 INFO:     Epoch: 77
2022-12-05 20:21:08,062 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46495348621498456, 'Total loss': 0.46495348621498456} | train loss {'Reaction outcome loss': 0.13014734273980022, 'Total loss': 0.13014734273980022}
2022-12-05 20:21:08,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:08,062 INFO:     Epoch: 78
2022-12-05 20:21:08,858 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4535827287896113, 'Total loss': 0.4535827287896113} | train loss {'Reaction outcome loss': 0.13016795118147062, 'Total loss': 0.13016795118147062}
2022-12-05 20:21:08,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:08,859 INFO:     Epoch: 79
2022-12-05 20:21:09,648 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4621957442299886, 'Total loss': 0.4621957442299886} | train loss {'Reaction outcome loss': 0.13169784228193013, 'Total loss': 0.13169784228193013}
2022-12-05 20:21:09,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:09,649 INFO:     Epoch: 80
2022-12-05 20:21:10,445 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4547270136800679, 'Total loss': 0.4547270136800679} | train loss {'Reaction outcome loss': 0.12786605933809328, 'Total loss': 0.12786605933809328}
2022-12-05 20:21:10,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:10,445 INFO:     Epoch: 81
2022-12-05 20:21:11,237 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44894600727341394, 'Total loss': 0.44894600727341394} | train loss {'Reaction outcome loss': 0.12907407219382191, 'Total loss': 0.12907407219382191}
2022-12-05 20:21:11,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:11,237 INFO:     Epoch: 82
2022-12-05 20:21:12,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47341657328334724, 'Total loss': 0.47341657328334724} | train loss {'Reaction outcome loss': 0.13414805674329702, 'Total loss': 0.13414805674329702}
2022-12-05 20:21:12,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:12,036 INFO:     Epoch: 83
2022-12-05 20:21:12,835 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4575480795042081, 'Total loss': 0.4575480795042081} | train loss {'Reaction outcome loss': 0.13399317150422738, 'Total loss': 0.13399317150422738}
2022-12-05 20:21:12,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:12,835 INFO:     Epoch: 84
2022-12-05 20:21:13,629 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4578102115880359, 'Total loss': 0.4578102115880359} | train loss {'Reaction outcome loss': 0.12818953307036327, 'Total loss': 0.12818953307036327}
2022-12-05 20:21:13,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:13,629 INFO:     Epoch: 85
2022-12-05 20:21:14,423 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45665256526659836, 'Total loss': 0.45665256526659836} | train loss {'Reaction outcome loss': 0.12797728250074664, 'Total loss': 0.12797728250074664}
2022-12-05 20:21:14,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:14,423 INFO:     Epoch: 86
2022-12-05 20:21:15,238 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47490955178033223, 'Total loss': 0.47490955178033223} | train loss {'Reaction outcome loss': 0.12908685394008512, 'Total loss': 0.12908685394008512}
2022-12-05 20:21:15,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:15,238 INFO:     Epoch: 87
2022-12-05 20:21:16,055 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4639669473875653, 'Total loss': 0.4639669473875653} | train loss {'Reaction outcome loss': 0.1267728918535552, 'Total loss': 0.1267728918535552}
2022-12-05 20:21:16,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:16,055 INFO:     Epoch: 88
2022-12-05 20:21:16,868 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4656925265761939, 'Total loss': 0.4656925265761939} | train loss {'Reaction outcome loss': 0.12525561142492256, 'Total loss': 0.12525561142492256}
2022-12-05 20:21:16,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:16,869 INFO:     Epoch: 89
2022-12-05 20:21:17,677 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.450410820543766, 'Total loss': 0.450410820543766} | train loss {'Reaction outcome loss': 0.12491165189381674, 'Total loss': 0.12491165189381674}
2022-12-05 20:21:17,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:17,678 INFO:     Epoch: 90
2022-12-05 20:21:18,494 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4568433426320553, 'Total loss': 0.4568433426320553} | train loss {'Reaction outcome loss': 0.12676041272962804, 'Total loss': 0.12676041272962804}
2022-12-05 20:21:18,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:18,494 INFO:     Epoch: 91
2022-12-05 20:21:19,304 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45987679877064447, 'Total loss': 0.45987679877064447} | train loss {'Reaction outcome loss': 0.12276945339877776, 'Total loss': 0.12276945339877776}
2022-12-05 20:21:19,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:19,305 INFO:     Epoch: 92
2022-12-05 20:21:20,118 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45363299548625946, 'Total loss': 0.45363299548625946} | train loss {'Reaction outcome loss': 0.12359556226580129, 'Total loss': 0.12359556226580129}
2022-12-05 20:21:20,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:20,119 INFO:     Epoch: 93
2022-12-05 20:21:20,927 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46842552721500397, 'Total loss': 0.46842552721500397} | train loss {'Reaction outcome loss': 0.12378121471703656, 'Total loss': 0.12378121471703656}
2022-12-05 20:21:20,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:20,927 INFO:     Epoch: 94
2022-12-05 20:21:21,739 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4560747661373832, 'Total loss': 0.4560747661373832} | train loss {'Reaction outcome loss': 0.1265836391477329, 'Total loss': 0.1265836391477329}
2022-12-05 20:21:21,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:21,739 INFO:     Epoch: 95
2022-12-05 20:21:22,547 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4707024839114059, 'Total loss': 0.4707024839114059} | train loss {'Reaction outcome loss': 0.13060675334441757, 'Total loss': 0.13060675334441757}
2022-12-05 20:21:22,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:22,547 INFO:     Epoch: 96
2022-12-05 20:21:23,357 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4462995065206831, 'Total loss': 0.4462995065206831} | train loss {'Reaction outcome loss': 0.12363268166727684, 'Total loss': 0.12363268166727684}
2022-12-05 20:21:23,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:23,357 INFO:     Epoch: 97
2022-12-05 20:21:24,170 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46379634619436483, 'Total loss': 0.46379634619436483} | train loss {'Reaction outcome loss': 0.12198494244291473, 'Total loss': 0.12198494244291473}
2022-12-05 20:21:24,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:24,170 INFO:     Epoch: 98
2022-12-05 20:21:24,987 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4526338722895492, 'Total loss': 0.4526338722895492} | train loss {'Reaction outcome loss': 0.12284994197760517, 'Total loss': 0.12284994197760517}
2022-12-05 20:21:24,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:24,987 INFO:     Epoch: 99
2022-12-05 20:21:25,800 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46937724338336423, 'Total loss': 0.46937724338336423} | train loss {'Reaction outcome loss': 0.11870995244607027, 'Total loss': 0.11870995244607027}
2022-12-05 20:21:25,800 INFO:     Best model found after epoch 13 of 100.
2022-12-05 20:21:25,801 INFO:   Done with stage: TRAINING
2022-12-05 20:21:25,801 INFO:   Starting stage: EVALUATION
2022-12-05 20:21:25,928 INFO:   Done with stage: EVALUATION
2022-12-05 20:21:25,928 INFO:   Leaving out SEQ value Fold_6
2022-12-05 20:21:25,941 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:21:25,941 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:21:26,594 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:21:26,594 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:21:26,662 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:21:26,663 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:21:26,663 INFO:     No hyperparam tuning for this model
2022-12-05 20:21:26,663 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:21:26,663 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:21:26,663 INFO:     None feature selector for col prot
2022-12-05 20:21:26,664 INFO:     None feature selector for col prot
2022-12-05 20:21:26,664 INFO:     None feature selector for col prot
2022-12-05 20:21:26,664 INFO:     None feature selector for col chem
2022-12-05 20:21:26,664 INFO:     None feature selector for col chem
2022-12-05 20:21:26,664 INFO:     None feature selector for col chem
2022-12-05 20:21:26,664 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:21:26,665 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:21:26,666 INFO:     Number of params in model 215821
2022-12-05 20:21:26,669 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:21:26,669 INFO:   Starting stage: TRAINING
2022-12-05 20:21:26,731 INFO:     Val loss before train {'Reaction outcome loss': 1.0251389118758114, 'Total loss': 1.0251389118758114}
2022-12-05 20:21:26,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:26,731 INFO:     Epoch: 0
2022-12-05 20:21:27,534 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6129366829991341, 'Total loss': 0.6129366829991341} | train loss {'Reaction outcome loss': 0.7857530622588478, 'Total loss': 0.7857530622588478}
2022-12-05 20:21:27,534 INFO:     Found new best model at epoch 0
2022-12-05 20:21:27,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:27,535 INFO:     Epoch: 1
2022-12-05 20:21:28,354 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5273567482151769, 'Total loss': 0.5273567482151769} | train loss {'Reaction outcome loss': 0.5384343162721951, 'Total loss': 0.5384343162721951}
2022-12-05 20:21:28,355 INFO:     Found new best model at epoch 1
2022-12-05 20:21:28,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:28,356 INFO:     Epoch: 2
2022-12-05 20:21:29,158 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4838924672115933, 'Total loss': 0.4838924672115933} | train loss {'Reaction outcome loss': 0.4708283079056605, 'Total loss': 0.4708283079056605}
2022-12-05 20:21:29,158 INFO:     Found new best model at epoch 2
2022-12-05 20:21:29,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:29,159 INFO:     Epoch: 3
2022-12-05 20:21:29,961 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.462927157567306, 'Total loss': 0.462927157567306} | train loss {'Reaction outcome loss': 0.4291701702333172, 'Total loss': 0.4291701702333172}
2022-12-05 20:21:29,961 INFO:     Found new best model at epoch 3
2022-12-05 20:21:29,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:29,962 INFO:     Epoch: 4
2022-12-05 20:21:30,770 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46313033760948613, 'Total loss': 0.46313033760948613} | train loss {'Reaction outcome loss': 0.40571205854898523, 'Total loss': 0.40571205854898523}
2022-12-05 20:21:30,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:30,770 INFO:     Epoch: 5
2022-12-05 20:21:31,578 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43780221112749795, 'Total loss': 0.43780221112749795} | train loss {'Reaction outcome loss': 0.38136801533853476, 'Total loss': 0.38136801533853476}
2022-12-05 20:21:31,578 INFO:     Found new best model at epoch 5
2022-12-05 20:21:31,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:31,579 INFO:     Epoch: 6
2022-12-05 20:21:32,387 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43811400268565526, 'Total loss': 0.43811400268565526} | train loss {'Reaction outcome loss': 0.3627588310343051, 'Total loss': 0.3627588310343051}
2022-12-05 20:21:32,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:32,387 INFO:     Epoch: 7
2022-12-05 20:21:33,194 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4266811812465841, 'Total loss': 0.4266811812465841} | train loss {'Reaction outcome loss': 0.34608587173948646, 'Total loss': 0.34608587173948646}
2022-12-05 20:21:33,195 INFO:     Found new best model at epoch 7
2022-12-05 20:21:33,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:33,195 INFO:     Epoch: 8
2022-12-05 20:21:33,997 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4247540845112367, 'Total loss': 0.4247540845112367} | train loss {'Reaction outcome loss': 0.33438116625735637, 'Total loss': 0.33438116625735637}
2022-12-05 20:21:33,997 INFO:     Found new best model at epoch 8
2022-12-05 20:21:33,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:33,998 INFO:     Epoch: 9
2022-12-05 20:21:34,794 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43422474238005554, 'Total loss': 0.43422474238005554} | train loss {'Reaction outcome loss': 0.3153267360560083, 'Total loss': 0.3153267360560083}
2022-12-05 20:21:34,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:34,794 INFO:     Epoch: 10
2022-12-05 20:21:35,590 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42791387608105486, 'Total loss': 0.42791387608105486} | train loss {'Reaction outcome loss': 0.3071549882742799, 'Total loss': 0.3071549882742799}
2022-12-05 20:21:35,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:35,590 INFO:     Epoch: 11
2022-12-05 20:21:36,389 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4347528276795691, 'Total loss': 0.4347528276795691} | train loss {'Reaction outcome loss': 0.3008406057591863, 'Total loss': 0.3008406057591863}
2022-12-05 20:21:36,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:36,389 INFO:     Epoch: 12
2022-12-05 20:21:37,191 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43258891661058774, 'Total loss': 0.43258891661058774} | train loss {'Reaction outcome loss': 0.28658121272257947, 'Total loss': 0.28658121272257947}
2022-12-05 20:21:37,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:37,191 INFO:     Epoch: 13
2022-12-05 20:21:37,992 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42940299212932587, 'Total loss': 0.42940299212932587} | train loss {'Reaction outcome loss': 0.2774973432062126, 'Total loss': 0.2774973432062126}
2022-12-05 20:21:37,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:37,993 INFO:     Epoch: 14
2022-12-05 20:21:38,790 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42752731151201506, 'Total loss': 0.42752731151201506} | train loss {'Reaction outcome loss': 0.26275660127763323, 'Total loss': 0.26275660127763323}
2022-12-05 20:21:38,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:38,790 INFO:     Epoch: 15
2022-12-05 20:21:39,590 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4180467636747794, 'Total loss': 0.4180467636747794} | train loss {'Reaction outcome loss': 0.25978594894713236, 'Total loss': 0.25978594894713236}
2022-12-05 20:21:39,591 INFO:     Found new best model at epoch 15
2022-12-05 20:21:39,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:39,592 INFO:     Epoch: 16
2022-12-05 20:21:40,396 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42030664939772, 'Total loss': 0.42030664939772} | train loss {'Reaction outcome loss': 0.25142896805818266, 'Total loss': 0.25142896805818266}
2022-12-05 20:21:40,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:40,397 INFO:     Epoch: 17
2022-12-05 20:21:41,198 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4229833090847189, 'Total loss': 0.4229833090847189} | train loss {'Reaction outcome loss': 0.24404483467249977, 'Total loss': 0.24404483467249977}
2022-12-05 20:21:41,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:41,198 INFO:     Epoch: 18
2022-12-05 20:21:41,996 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43636041100729595, 'Total loss': 0.43636041100729595} | train loss {'Reaction outcome loss': 0.23577534313867932, 'Total loss': 0.23577534313867932}
2022-12-05 20:21:41,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:41,996 INFO:     Epoch: 19
2022-12-05 20:21:42,797 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43368547511371697, 'Total loss': 0.43368547511371697} | train loss {'Reaction outcome loss': 0.22824650727446202, 'Total loss': 0.22824650727446202}
2022-12-05 20:21:42,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:42,797 INFO:     Epoch: 20
2022-12-05 20:21:43,604 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40795804881914094, 'Total loss': 0.40795804881914094} | train loss {'Reaction outcome loss': 0.22439209546946623, 'Total loss': 0.22439209546946623}
2022-12-05 20:21:43,605 INFO:     Found new best model at epoch 20
2022-12-05 20:21:43,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:43,605 INFO:     Epoch: 21
2022-12-05 20:21:44,406 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4290627779608423, 'Total loss': 0.4290627779608423} | train loss {'Reaction outcome loss': 0.22132405643219408, 'Total loss': 0.22132405643219408}
2022-12-05 20:21:44,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:44,406 INFO:     Epoch: 22
2022-12-05 20:21:45,207 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4348765408450907, 'Total loss': 0.4348765408450907} | train loss {'Reaction outcome loss': 0.21921359626991063, 'Total loss': 0.21921359626991063}
2022-12-05 20:21:45,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:45,208 INFO:     Epoch: 23
2022-12-05 20:21:46,006 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4478705386546525, 'Total loss': 0.4478705386546525} | train loss {'Reaction outcome loss': 0.21779922887622585, 'Total loss': 0.21779922887622585}
2022-12-05 20:21:46,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:46,007 INFO:     Epoch: 24
2022-12-05 20:21:46,804 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44610794565894385, 'Total loss': 0.44610794565894385} | train loss {'Reaction outcome loss': 0.20853461038607818, 'Total loss': 0.20853461038607818}
2022-12-05 20:21:46,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:46,804 INFO:     Epoch: 25
2022-12-05 20:21:47,597 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4402501327408986, 'Total loss': 0.4402501327408986} | train loss {'Reaction outcome loss': 0.20061752849224548, 'Total loss': 0.20061752849224548}
2022-12-05 20:21:47,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:47,597 INFO:     Epoch: 26
2022-12-05 20:21:48,388 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4370358267968351, 'Total loss': 0.4370358267968351} | train loss {'Reaction outcome loss': 0.19434662596869323, 'Total loss': 0.19434662596869323}
2022-12-05 20:21:48,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:48,388 INFO:     Epoch: 27
2022-12-05 20:21:49,180 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.442281459542838, 'Total loss': 0.442281459542838} | train loss {'Reaction outcome loss': 0.1966173247422887, 'Total loss': 0.1966173247422887}
2022-12-05 20:21:49,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:49,180 INFO:     Epoch: 28
2022-12-05 20:21:49,977 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44785151969302783, 'Total loss': 0.44785151969302783} | train loss {'Reaction outcome loss': 0.19062124317896512, 'Total loss': 0.19062124317896512}
2022-12-05 20:21:49,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:49,977 INFO:     Epoch: 29
2022-12-05 20:21:50,774 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4580725516107949, 'Total loss': 0.4580725516107949} | train loss {'Reaction outcome loss': 0.1874061990453888, 'Total loss': 0.1874061990453888}
2022-12-05 20:21:50,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:50,774 INFO:     Epoch: 30
2022-12-05 20:21:51,567 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4376931403848258, 'Total loss': 0.4376931403848258} | train loss {'Reaction outcome loss': 0.1942396823482716, 'Total loss': 0.1942396823482716}
2022-12-05 20:21:51,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:51,568 INFO:     Epoch: 31
2022-12-05 20:21:52,356 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4397959607568654, 'Total loss': 0.4397959607568654} | train loss {'Reaction outcome loss': 0.18456214738006776, 'Total loss': 0.18456214738006776}
2022-12-05 20:21:52,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:52,356 INFO:     Epoch: 32
2022-12-05 20:21:53,144 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44243538041006436, 'Total loss': 0.44243538041006436} | train loss {'Reaction outcome loss': 0.18134748687221092, 'Total loss': 0.18134748687221092}
2022-12-05 20:21:53,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:53,144 INFO:     Epoch: 33
2022-12-05 20:21:53,933 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44229235110635107, 'Total loss': 0.44229235110635107} | train loss {'Reaction outcome loss': 0.1752601313038997, 'Total loss': 0.1752601313038997}
2022-12-05 20:21:53,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:53,933 INFO:     Epoch: 34
2022-12-05 20:21:54,722 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43724049390716985, 'Total loss': 0.43724049390716985} | train loss {'Reaction outcome loss': 0.1714382656488892, 'Total loss': 0.1714382656488892}
2022-12-05 20:21:54,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:54,722 INFO:     Epoch: 35
2022-12-05 20:21:55,510 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4496490762315013, 'Total loss': 0.4496490762315013} | train loss {'Reaction outcome loss': 0.1696407187330397, 'Total loss': 0.1696407187330397}
2022-12-05 20:21:55,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:55,510 INFO:     Epoch: 36
2022-12-05 20:21:56,306 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44323672591285274, 'Total loss': 0.44323672591285274} | train loss {'Reaction outcome loss': 0.16691137358229532, 'Total loss': 0.16691137358229532}
2022-12-05 20:21:56,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:56,307 INFO:     Epoch: 37
2022-12-05 20:21:57,096 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45226886800744315, 'Total loss': 0.45226886800744315} | train loss {'Reaction outcome loss': 0.1669759305593697, 'Total loss': 0.1669759305593697}
2022-12-05 20:21:57,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:57,096 INFO:     Epoch: 38
2022-12-05 20:21:57,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4617297056723725, 'Total loss': 0.4617297056723725} | train loss {'Reaction outcome loss': 0.16611984418139525, 'Total loss': 0.16611984418139525}
2022-12-05 20:21:57,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:57,884 INFO:     Epoch: 39
2022-12-05 20:21:58,671 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4528121831403537, 'Total loss': 0.4528121831403537} | train loss {'Reaction outcome loss': 0.16538929569757418, 'Total loss': 0.16538929569757418}
2022-12-05 20:21:58,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:58,672 INFO:     Epoch: 40
2022-12-05 20:21:59,466 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4374102818017656, 'Total loss': 0.4374102818017656} | train loss {'Reaction outcome loss': 0.16644482128322124, 'Total loss': 0.16644482128322124}
2022-12-05 20:21:59,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:21:59,466 INFO:     Epoch: 41
2022-12-05 20:22:00,254 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43601517260751943, 'Total loss': 0.43601517260751943} | train loss {'Reaction outcome loss': 0.16552309213801916, 'Total loss': 0.16552309213801916}
2022-12-05 20:22:00,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:00,255 INFO:     Epoch: 42
2022-12-05 20:22:01,045 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4495875049721111, 'Total loss': 0.4495875049721111} | train loss {'Reaction outcome loss': 0.16014112712370482, 'Total loss': 0.16014112712370482}
2022-12-05 20:22:01,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:01,046 INFO:     Epoch: 43
2022-12-05 20:22:01,835 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45043562928384, 'Total loss': 0.45043562928384} | train loss {'Reaction outcome loss': 0.16501546801192316, 'Total loss': 0.16501546801192316}
2022-12-05 20:22:01,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:01,835 INFO:     Epoch: 44
2022-12-05 20:22:02,628 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4525902003727176, 'Total loss': 0.4525902003727176} | train loss {'Reaction outcome loss': 0.15514934911823414, 'Total loss': 0.15514934911823414}
2022-12-05 20:22:02,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:02,629 INFO:     Epoch: 45
2022-12-05 20:22:03,419 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4556874290786006, 'Total loss': 0.4556874290786006} | train loss {'Reaction outcome loss': 0.15373200155523142, 'Total loss': 0.15373200155523142}
2022-12-05 20:22:03,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:03,419 INFO:     Epoch: 46
2022-12-05 20:22:04,207 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4598876071924513, 'Total loss': 0.4598876071924513} | train loss {'Reaction outcome loss': 0.15459670504245923, 'Total loss': 0.15459670504245923}
2022-12-05 20:22:04,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:04,207 INFO:     Epoch: 47
2022-12-05 20:22:04,997 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46765548261729156, 'Total loss': 0.46765548261729156} | train loss {'Reaction outcome loss': 0.16066243102856975, 'Total loss': 0.16066243102856975}
2022-12-05 20:22:04,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:04,997 INFO:     Epoch: 48
2022-12-05 20:22:05,791 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45093954693187366, 'Total loss': 0.45093954693187366} | train loss {'Reaction outcome loss': 0.1541306190569753, 'Total loss': 0.1541306190569753}
2022-12-05 20:22:05,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:05,791 INFO:     Epoch: 49
2022-12-05 20:22:06,584 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4583396908234466, 'Total loss': 0.4583396908234466} | train loss {'Reaction outcome loss': 0.15059363498137548, 'Total loss': 0.15059363498137548}
2022-12-05 20:22:06,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:06,584 INFO:     Epoch: 50
2022-12-05 20:22:07,374 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46375876157121226, 'Total loss': 0.46375876157121226} | train loss {'Reaction outcome loss': 0.14851032432756925, 'Total loss': 0.14851032432756925}
2022-12-05 20:22:07,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:07,374 INFO:     Epoch: 51
2022-12-05 20:22:08,172 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4469313384457068, 'Total loss': 0.4469313384457068} | train loss {'Reaction outcome loss': 0.14600551144223706, 'Total loss': 0.14600551144223706}
2022-12-05 20:22:08,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:08,172 INFO:     Epoch: 52
2022-12-05 20:22:08,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47310528870333324, 'Total loss': 0.47310528870333324} | train loss {'Reaction outcome loss': 0.14758685958168286, 'Total loss': 0.14758685958168286}
2022-12-05 20:22:08,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:08,965 INFO:     Epoch: 53
2022-12-05 20:22:09,753 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4535023837604306, 'Total loss': 0.4535023837604306} | train loss {'Reaction outcome loss': 0.14309553721347476, 'Total loss': 0.14309553721347476}
2022-12-05 20:22:09,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:09,753 INFO:     Epoch: 54
2022-12-05 20:22:10,545 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45789011906493793, 'Total loss': 0.45789011906493793} | train loss {'Reaction outcome loss': 0.14385799466545585, 'Total loss': 0.14385799466545585}
2022-12-05 20:22:10,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:10,545 INFO:     Epoch: 55
2022-12-05 20:22:11,334 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4621051468632438, 'Total loss': 0.4621051468632438} | train loss {'Reaction outcome loss': 0.1457957415596435, 'Total loss': 0.1457957415596435}
2022-12-05 20:22:11,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:11,336 INFO:     Epoch: 56
2022-12-05 20:22:12,135 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45684190958061, 'Total loss': 0.45684190958061} | train loss {'Reaction outcome loss': 0.14387163623926127, 'Total loss': 0.14387163623926127}
2022-12-05 20:22:12,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:12,135 INFO:     Epoch: 57
2022-12-05 20:22:12,934 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4597927314991301, 'Total loss': 0.4597927314991301} | train loss {'Reaction outcome loss': 0.14008837712830619, 'Total loss': 0.14008837712830619}
2022-12-05 20:22:12,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:12,934 INFO:     Epoch: 58
2022-12-05 20:22:13,724 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4560783059251579, 'Total loss': 0.4560783059251579} | train loss {'Reaction outcome loss': 0.14306335352542188, 'Total loss': 0.14306335352542188}
2022-12-05 20:22:13,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:13,724 INFO:     Epoch: 59
2022-12-05 20:22:14,519 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4661713168025017, 'Total loss': 0.4661713168025017} | train loss {'Reaction outcome loss': 0.14097486864322956, 'Total loss': 0.14097486864322956}
2022-12-05 20:22:14,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:14,519 INFO:     Epoch: 60
2022-12-05 20:22:15,307 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4570597323843024, 'Total loss': 0.4570597323843024} | train loss {'Reaction outcome loss': 0.14079872290660375, 'Total loss': 0.14079872290660375}
2022-12-05 20:22:15,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:15,307 INFO:     Epoch: 61
2022-12-05 20:22:16,095 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4617690725082701, 'Total loss': 0.4617690725082701} | train loss {'Reaction outcome loss': 0.1412942237126441, 'Total loss': 0.1412942237126441}
2022-12-05 20:22:16,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:16,095 INFO:     Epoch: 62
2022-12-05 20:22:16,883 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44895245642824605, 'Total loss': 0.44895245642824605} | train loss {'Reaction outcome loss': 0.13941490320396432, 'Total loss': 0.13941490320396432}
2022-12-05 20:22:16,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:16,883 INFO:     Epoch: 63
2022-12-05 20:22:17,671 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46512536924671044, 'Total loss': 0.46512536924671044} | train loss {'Reaction outcome loss': 0.13623208269808698, 'Total loss': 0.13623208269808698}
2022-12-05 20:22:17,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:17,672 INFO:     Epoch: 64
2022-12-05 20:22:18,461 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4677222970534455, 'Total loss': 0.4677222970534455} | train loss {'Reaction outcome loss': 0.14067775365493077, 'Total loss': 0.14067775365493077}
2022-12-05 20:22:18,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:18,461 INFO:     Epoch: 65
2022-12-05 20:22:19,249 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4523340135135434, 'Total loss': 0.4523340135135434} | train loss {'Reaction outcome loss': 0.13647592180551818, 'Total loss': 0.13647592180551818}
2022-12-05 20:22:19,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:19,250 INFO:     Epoch: 66
2022-12-05 20:22:20,043 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47489599680358713, 'Total loss': 0.47489599680358713} | train loss {'Reaction outcome loss': 0.13308457581529975, 'Total loss': 0.13308457581529975}
2022-12-05 20:22:20,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:20,043 INFO:     Epoch: 67
2022-12-05 20:22:20,834 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46086485108191316, 'Total loss': 0.46086485108191316} | train loss {'Reaction outcome loss': 0.13612643621465087, 'Total loss': 0.13612643621465087}
2022-12-05 20:22:20,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:20,834 INFO:     Epoch: 68
2022-12-05 20:22:21,625 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4671104001727971, 'Total loss': 0.4671104001727971} | train loss {'Reaction outcome loss': 0.13656690571200752, 'Total loss': 0.13656690571200752}
2022-12-05 20:22:21,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:21,625 INFO:     Epoch: 69
2022-12-05 20:22:22,414 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4551322368735617, 'Total loss': 0.4551322368735617} | train loss {'Reaction outcome loss': 0.1324311693647673, 'Total loss': 0.1324311693647673}
2022-12-05 20:22:22,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:22,414 INFO:     Epoch: 70
2022-12-05 20:22:23,205 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45596239749680867, 'Total loss': 0.45596239749680867} | train loss {'Reaction outcome loss': 0.13476778886578827, 'Total loss': 0.13476778886578827}
2022-12-05 20:22:23,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:23,205 INFO:     Epoch: 71
2022-12-05 20:22:23,993 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4721651663157073, 'Total loss': 0.4721651663157073} | train loss {'Reaction outcome loss': 0.1371500939130783, 'Total loss': 0.1371500939130783}
2022-12-05 20:22:23,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:23,993 INFO:     Epoch: 72
2022-12-05 20:22:24,782 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4631016809831966, 'Total loss': 0.4631016809831966} | train loss {'Reaction outcome loss': 0.13326238701072887, 'Total loss': 0.13326238701072887}
2022-12-05 20:22:24,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:24,783 INFO:     Epoch: 73
2022-12-05 20:22:25,573 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4648601121523164, 'Total loss': 0.4648601121523164} | train loss {'Reaction outcome loss': 0.13477326432612502, 'Total loss': 0.13477326432612502}
2022-12-05 20:22:25,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:25,573 INFO:     Epoch: 74
2022-12-05 20:22:26,365 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44528612680733204, 'Total loss': 0.44528612680733204} | train loss {'Reaction outcome loss': 0.13613792812745823, 'Total loss': 0.13613792812745823}
2022-12-05 20:22:26,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:26,366 INFO:     Epoch: 75
2022-12-05 20:22:27,154 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45556385815143585, 'Total loss': 0.45556385815143585} | train loss {'Reaction outcome loss': 0.1310747577714534, 'Total loss': 0.1310747577714534}
2022-12-05 20:22:27,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:27,154 INFO:     Epoch: 76
2022-12-05 20:22:27,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44963117045435036, 'Total loss': 0.44963117045435036} | train loss {'Reaction outcome loss': 0.13205719094813956, 'Total loss': 0.13205719094813956}
2022-12-05 20:22:27,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:27,945 INFO:     Epoch: 77
2022-12-05 20:22:28,736 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47052343596111645, 'Total loss': 0.47052343596111645} | train loss {'Reaction outcome loss': 0.1301833198797938, 'Total loss': 0.1301833198797938}
2022-12-05 20:22:28,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:28,736 INFO:     Epoch: 78
2022-12-05 20:22:29,534 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4627973376349969, 'Total loss': 0.4627973376349969} | train loss {'Reaction outcome loss': 0.1293231633412633, 'Total loss': 0.1293231633412633}
2022-12-05 20:22:29,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:29,535 INFO:     Epoch: 79
2022-12-05 20:22:30,334 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45766537331722, 'Total loss': 0.45766537331722} | train loss {'Reaction outcome loss': 0.13160313721953587, 'Total loss': 0.13160313721953587}
2022-12-05 20:22:30,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:30,335 INFO:     Epoch: 80
2022-12-05 20:22:31,134 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45937295020981267, 'Total loss': 0.45937295020981267} | train loss {'Reaction outcome loss': 0.1310507844613209, 'Total loss': 0.1310507844613209}
2022-12-05 20:22:31,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:31,134 INFO:     Epoch: 81
2022-12-05 20:22:31,936 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49839668246832763, 'Total loss': 0.49839668246832763} | train loss {'Reaction outcome loss': 0.1298701325016707, 'Total loss': 0.1298701325016707}
2022-12-05 20:22:31,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:31,936 INFO:     Epoch: 82
2022-12-05 20:22:32,736 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4576262564144351, 'Total loss': 0.4576262564144351} | train loss {'Reaction outcome loss': 0.12728801324420613, 'Total loss': 0.12728801324420613}
2022-12-05 20:22:32,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:32,736 INFO:     Epoch: 83
2022-12-05 20:22:33,538 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48105067827484826, 'Total loss': 0.48105067827484826} | train loss {'Reaction outcome loss': 0.13314066452694387, 'Total loss': 0.13314066452694387}
2022-12-05 20:22:33,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:33,538 INFO:     Epoch: 84
2022-12-05 20:22:34,342 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47509157014164055, 'Total loss': 0.47509157014164055} | train loss {'Reaction outcome loss': 0.12514935873886232, 'Total loss': 0.12514935873886232}
2022-12-05 20:22:34,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:34,343 INFO:     Epoch: 85
2022-12-05 20:22:35,142 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4665285345505584, 'Total loss': 0.4665285345505584} | train loss {'Reaction outcome loss': 0.12631894267250893, 'Total loss': 0.12631894267250893}
2022-12-05 20:22:35,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:35,142 INFO:     Epoch: 86
2022-12-05 20:22:35,939 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44829921424388885, 'Total loss': 0.44829921424388885} | train loss {'Reaction outcome loss': 0.13185469268515768, 'Total loss': 0.13185469268515768}
2022-12-05 20:22:35,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:35,939 INFO:     Epoch: 87
2022-12-05 20:22:36,736 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47619536078789015, 'Total loss': 0.47619536078789015} | train loss {'Reaction outcome loss': 0.13323871420341948, 'Total loss': 0.13323871420341948}
2022-12-05 20:22:36,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:36,737 INFO:     Epoch: 88
2022-12-05 20:22:37,540 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47672250121831894, 'Total loss': 0.47672250121831894} | train loss {'Reaction outcome loss': 0.12549125132252753, 'Total loss': 0.12549125132252753}
2022-12-05 20:22:37,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:37,540 INFO:     Epoch: 89
2022-12-05 20:22:38,340 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4666385176506909, 'Total loss': 0.4666385176506909} | train loss {'Reaction outcome loss': 0.12515348227702172, 'Total loss': 0.12515348227702172}
2022-12-05 20:22:38,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:38,340 INFO:     Epoch: 90
2022-12-05 20:22:39,140 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45704638585448265, 'Total loss': 0.45704638585448265} | train loss {'Reaction outcome loss': 0.12358163167469897, 'Total loss': 0.12358163167469897}
2022-12-05 20:22:39,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:39,140 INFO:     Epoch: 91
2022-12-05 20:22:39,939 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4647567499090325, 'Total loss': 0.4647567499090325} | train loss {'Reaction outcome loss': 0.12458805965357705, 'Total loss': 0.12458805965357705}
2022-12-05 20:22:39,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:39,940 INFO:     Epoch: 92
2022-12-05 20:22:40,744 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4599471354687756, 'Total loss': 0.4599471354687756} | train loss {'Reaction outcome loss': 0.12437124652524105, 'Total loss': 0.12437124652524105}
2022-12-05 20:22:40,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:40,744 INFO:     Epoch: 93
2022-12-05 20:22:41,548 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46959674527699297, 'Total loss': 0.46959674527699297} | train loss {'Reaction outcome loss': 0.12382086751009772, 'Total loss': 0.12382086751009772}
2022-12-05 20:22:41,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:41,548 INFO:     Epoch: 94
2022-12-05 20:22:42,349 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.462798633697358, 'Total loss': 0.462798633697358} | train loss {'Reaction outcome loss': 0.12527026766666063, 'Total loss': 0.12527026766666063}
2022-12-05 20:22:42,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:42,350 INFO:     Epoch: 95
2022-12-05 20:22:43,150 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4607769338922067, 'Total loss': 0.4607769338922067} | train loss {'Reaction outcome loss': 0.1225858615779201, 'Total loss': 0.1225858615779201}
2022-12-05 20:22:43,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:43,150 INFO:     Epoch: 96
2022-12-05 20:22:43,953 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46934539756991644, 'Total loss': 0.46934539756991644} | train loss {'Reaction outcome loss': 0.12662577786886317, 'Total loss': 0.12662577786886317}
2022-12-05 20:22:43,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:43,953 INFO:     Epoch: 97
2022-12-05 20:22:44,757 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4764324700967832, 'Total loss': 0.4764324700967832} | train loss {'Reaction outcome loss': 0.12577737045855175, 'Total loss': 0.12577737045855175}
2022-12-05 20:22:44,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:44,757 INFO:     Epoch: 98
2022-12-05 20:22:45,554 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47070487622510304, 'Total loss': 0.47070487622510304} | train loss {'Reaction outcome loss': 0.1249343572855599, 'Total loss': 0.1249343572855599}
2022-12-05 20:22:45,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:45,554 INFO:     Epoch: 99
2022-12-05 20:22:46,352 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46297128193757753, 'Total loss': 0.46297128193757753} | train loss {'Reaction outcome loss': 0.1250202516998779, 'Total loss': 0.1250202516998779}
2022-12-05 20:22:46,352 INFO:     Best model found after epoch 21 of 100.
2022-12-05 20:22:46,352 INFO:   Done with stage: TRAINING
2022-12-05 20:22:46,352 INFO:   Starting stage: EVALUATION
2022-12-05 20:22:46,479 INFO:   Done with stage: EVALUATION
2022-12-05 20:22:46,479 INFO:   Leaving out SEQ value Fold_7
2022-12-05 20:22:46,491 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:22:46,491 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:22:47,147 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:22:47,148 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:22:47,216 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:22:47,216 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:22:47,216 INFO:     No hyperparam tuning for this model
2022-12-05 20:22:47,216 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:22:47,216 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:22:47,217 INFO:     None feature selector for col prot
2022-12-05 20:22:47,217 INFO:     None feature selector for col prot
2022-12-05 20:22:47,217 INFO:     None feature selector for col prot
2022-12-05 20:22:47,218 INFO:     None feature selector for col chem
2022-12-05 20:22:47,218 INFO:     None feature selector for col chem
2022-12-05 20:22:47,218 INFO:     None feature selector for col chem
2022-12-05 20:22:47,218 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:22:47,218 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:22:47,220 INFO:     Number of params in model 215821
2022-12-05 20:22:47,223 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:22:47,223 INFO:   Starting stage: TRAINING
2022-12-05 20:22:47,284 INFO:     Val loss before train {'Reaction outcome loss': 0.9498823677951639, 'Total loss': 0.9498823677951639}
2022-12-05 20:22:47,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:47,284 INFO:     Epoch: 0
2022-12-05 20:22:48,086 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5733070129697974, 'Total loss': 0.5733070129697974} | train loss {'Reaction outcome loss': 0.7933682533762147, 'Total loss': 0.7933682533762147}
2022-12-05 20:22:48,086 INFO:     Found new best model at epoch 0
2022-12-05 20:22:48,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:48,087 INFO:     Epoch: 1
2022-12-05 20:22:48,890 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4888343093070117, 'Total loss': 0.4888343093070117} | train loss {'Reaction outcome loss': 0.5282602775841951, 'Total loss': 0.5282602775841951}
2022-12-05 20:22:48,891 INFO:     Found new best model at epoch 1
2022-12-05 20:22:48,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:48,892 INFO:     Epoch: 2
2022-12-05 20:22:49,692 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4510747776790099, 'Total loss': 0.4510747776790099} | train loss {'Reaction outcome loss': 0.45968056992898065, 'Total loss': 0.45968056992898065}
2022-12-05 20:22:49,692 INFO:     Found new best model at epoch 2
2022-12-05 20:22:49,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:49,693 INFO:     Epoch: 3
2022-12-05 20:22:50,497 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42438129403374414, 'Total loss': 0.42438129403374414} | train loss {'Reaction outcome loss': 0.41966074386671665, 'Total loss': 0.41966074386671665}
2022-12-05 20:22:50,497 INFO:     Found new best model at epoch 3
2022-12-05 20:22:50,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:50,498 INFO:     Epoch: 4
2022-12-05 20:22:51,304 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4186143380674449, 'Total loss': 0.4186143380674449} | train loss {'Reaction outcome loss': 0.3919629385214179, 'Total loss': 0.3919629385214179}
2022-12-05 20:22:51,304 INFO:     Found new best model at epoch 4
2022-12-05 20:22:51,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:51,305 INFO:     Epoch: 5
2022-12-05 20:22:52,109 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42141914333809505, 'Total loss': 0.42141914333809505} | train loss {'Reaction outcome loss': 0.3693506689141354, 'Total loss': 0.3693506689141354}
2022-12-05 20:22:52,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:52,109 INFO:     Epoch: 6
2022-12-05 20:22:52,915 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41327035799622536, 'Total loss': 0.41327035799622536} | train loss {'Reaction outcome loss': 0.3462146507395852, 'Total loss': 0.3462146507395852}
2022-12-05 20:22:52,915 INFO:     Found new best model at epoch 6
2022-12-05 20:22:52,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:52,916 INFO:     Epoch: 7
2022-12-05 20:22:53,722 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42187342792749405, 'Total loss': 0.42187342792749405} | train loss {'Reaction outcome loss': 0.3293374180192909, 'Total loss': 0.3293374180192909}
2022-12-05 20:22:53,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:53,722 INFO:     Epoch: 8
2022-12-05 20:22:54,526 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40532517636364157, 'Total loss': 0.40532517636364157} | train loss {'Reaction outcome loss': 0.31483582342644373, 'Total loss': 0.31483582342644373}
2022-12-05 20:22:54,526 INFO:     Found new best model at epoch 8
2022-12-05 20:22:54,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:54,527 INFO:     Epoch: 9
2022-12-05 20:22:55,326 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4028214653107253, 'Total loss': 0.4028214653107253} | train loss {'Reaction outcome loss': 0.30012224163980256, 'Total loss': 0.30012224163980256}
2022-12-05 20:22:55,327 INFO:     Found new best model at epoch 9
2022-12-05 20:22:55,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:55,327 INFO:     Epoch: 10
2022-12-05 20:22:56,128 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4052767113528468, 'Total loss': 0.4052767113528468} | train loss {'Reaction outcome loss': 0.2901936668241697, 'Total loss': 0.2901936668241697}
2022-12-05 20:22:56,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:56,129 INFO:     Epoch: 11
2022-12-05 20:22:56,932 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40191798555580055, 'Total loss': 0.40191798555580055} | train loss {'Reaction outcome loss': 0.2756727327322287, 'Total loss': 0.2756727327322287}
2022-12-05 20:22:56,932 INFO:     Found new best model at epoch 11
2022-12-05 20:22:56,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:56,933 INFO:     Epoch: 12
2022-12-05 20:22:57,734 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41028989919207315, 'Total loss': 0.41028989919207315} | train loss {'Reaction outcome loss': 0.2666581913738722, 'Total loss': 0.2666581913738722}
2022-12-05 20:22:57,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:57,734 INFO:     Epoch: 13
2022-12-05 20:22:58,536 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4044270683079958, 'Total loss': 0.4044270683079958} | train loss {'Reaction outcome loss': 0.2557051560030349, 'Total loss': 0.2557051560030349}
2022-12-05 20:22:58,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:58,536 INFO:     Epoch: 14
2022-12-05 20:22:59,337 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.409177074378187, 'Total loss': 0.409177074378187} | train loss {'Reaction outcome loss': 0.24717545818777814, 'Total loss': 0.24717545818777814}
2022-12-05 20:22:59,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:22:59,337 INFO:     Epoch: 15
2022-12-05 20:23:00,145 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4081996672532775, 'Total loss': 0.4081996672532775} | train loss {'Reaction outcome loss': 0.238542923944131, 'Total loss': 0.238542923944131}
2022-12-05 20:23:00,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:00,145 INFO:     Epoch: 16
2022-12-05 20:23:00,945 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41329460726542905, 'Total loss': 0.41329460726542905} | train loss {'Reaction outcome loss': 0.23237375335227098, 'Total loss': 0.23237375335227098}
2022-12-05 20:23:00,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:00,946 INFO:     Epoch: 17
2022-12-05 20:23:01,747 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4278501939367164, 'Total loss': 0.4278501939367164} | train loss {'Reaction outcome loss': 0.22662466620245286, 'Total loss': 0.22662466620245286}
2022-12-05 20:23:01,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:01,747 INFO:     Epoch: 18
2022-12-05 20:23:02,548 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41066673736680637, 'Total loss': 0.41066673736680637} | train loss {'Reaction outcome loss': 0.21778158380860282, 'Total loss': 0.21778158380860282}
2022-12-05 20:23:02,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:02,548 INFO:     Epoch: 19
2022-12-05 20:23:03,350 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42854762517593126, 'Total loss': 0.42854762517593126} | train loss {'Reaction outcome loss': 0.21423520786207048, 'Total loss': 0.21423520786207048}
2022-12-05 20:23:03,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:03,350 INFO:     Epoch: 20
2022-12-05 20:23:04,153 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41128121282566676, 'Total loss': 0.41128121282566676} | train loss {'Reaction outcome loss': 0.20773893877893926, 'Total loss': 0.20773893877893926}
2022-12-05 20:23:04,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:04,154 INFO:     Epoch: 21
2022-12-05 20:23:04,958 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3991348944096403, 'Total loss': 0.3991348944096403} | train loss {'Reaction outcome loss': 0.2003666533818168, 'Total loss': 0.2003666533818168}
2022-12-05 20:23:04,958 INFO:     Found new best model at epoch 21
2022-12-05 20:23:04,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:04,959 INFO:     Epoch: 22
2022-12-05 20:23:05,767 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43279108235781844, 'Total loss': 0.43279108235781844} | train loss {'Reaction outcome loss': 0.19814134517969983, 'Total loss': 0.19814134517969983}
2022-12-05 20:23:05,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:05,767 INFO:     Epoch: 23
2022-12-05 20:23:06,588 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4152123846791007, 'Total loss': 0.4152123846791007} | train loss {'Reaction outcome loss': 0.1929235584102571, 'Total loss': 0.1929235584102571}
2022-12-05 20:23:06,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:06,589 INFO:     Epoch: 24
2022-12-05 20:23:07,411 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42656019363890996, 'Total loss': 0.42656019363890996} | train loss {'Reaction outcome loss': 0.19016699215036728, 'Total loss': 0.19016699215036728}
2022-12-05 20:23:07,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:07,412 INFO:     Epoch: 25
2022-12-05 20:23:08,232 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4162049684673548, 'Total loss': 0.4162049684673548} | train loss {'Reaction outcome loss': 0.18367404867744735, 'Total loss': 0.18367404867744735}
2022-12-05 20:23:08,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:08,232 INFO:     Epoch: 26
2022-12-05 20:23:09,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4309337352487174, 'Total loss': 0.4309337352487174} | train loss {'Reaction outcome loss': 0.18330761481587204, 'Total loss': 0.18330761481587204}
2022-12-05 20:23:09,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:09,052 INFO:     Epoch: 27
2022-12-05 20:23:09,872 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4190537172623656, 'Total loss': 0.4190537172623656} | train loss {'Reaction outcome loss': 0.18040189590124833, 'Total loss': 0.18040189590124833}
2022-12-05 20:23:09,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:09,873 INFO:     Epoch: 28
2022-12-05 20:23:10,695 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.420889307490804, 'Total loss': 0.420889307490804} | train loss {'Reaction outcome loss': 0.17494592989133972, 'Total loss': 0.17494592989133972}
2022-12-05 20:23:10,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:10,695 INFO:     Epoch: 29
2022-12-05 20:23:11,517 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4292400943284685, 'Total loss': 0.4292400943284685} | train loss {'Reaction outcome loss': 0.17299280052764282, 'Total loss': 0.17299280052764282}
2022-12-05 20:23:11,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:11,517 INFO:     Epoch: 30
2022-12-05 20:23:12,341 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43832074672999705, 'Total loss': 0.43832074672999705} | train loss {'Reaction outcome loss': 0.1707785186477967, 'Total loss': 0.1707785186477967}
2022-12-05 20:23:12,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:12,341 INFO:     Epoch: 31
2022-12-05 20:23:13,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44485313445329666, 'Total loss': 0.44485313445329666} | train loss {'Reaction outcome loss': 0.1657256474568238, 'Total loss': 0.1657256474568238}
2022-12-05 20:23:13,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:13,160 INFO:     Epoch: 32
2022-12-05 20:23:13,980 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4561118581755595, 'Total loss': 0.4561118581755595} | train loss {'Reaction outcome loss': 0.16881794827960192, 'Total loss': 0.16881794827960192}
2022-12-05 20:23:13,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:13,980 INFO:     Epoch: 33
2022-12-05 20:23:14,803 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44104996154254134, 'Total loss': 0.44104996154254134} | train loss {'Reaction outcome loss': 0.16368804275689106, 'Total loss': 0.16368804275689106}
2022-12-05 20:23:14,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:14,803 INFO:     Epoch: 34
2022-12-05 20:23:15,622 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4271046973087571, 'Total loss': 0.4271046973087571} | train loss {'Reaction outcome loss': 0.16397060927063709, 'Total loss': 0.16397060927063709}
2022-12-05 20:23:15,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:15,623 INFO:     Epoch: 35
2022-12-05 20:23:16,444 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44989445907148445, 'Total loss': 0.44989445907148445} | train loss {'Reaction outcome loss': 0.1567480544890127, 'Total loss': 0.1567480544890127}
2022-12-05 20:23:16,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:16,444 INFO:     Epoch: 36
2022-12-05 20:23:17,264 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45337267829613254, 'Total loss': 0.45337267829613254} | train loss {'Reaction outcome loss': 0.15913106152607548, 'Total loss': 0.15913106152607548}
2022-12-05 20:23:17,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:17,264 INFO:     Epoch: 37
2022-12-05 20:23:18,085 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4406306225467812, 'Total loss': 0.4406306225467812} | train loss {'Reaction outcome loss': 0.15559590222584385, 'Total loss': 0.15559590222584385}
2022-12-05 20:23:18,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:18,085 INFO:     Epoch: 38
2022-12-05 20:23:18,904 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4483509422703223, 'Total loss': 0.4483509422703223} | train loss {'Reaction outcome loss': 0.15577957445695514, 'Total loss': 0.15577957445695514}
2022-12-05 20:23:18,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:18,904 INFO:     Epoch: 39
2022-12-05 20:23:19,726 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4577783661132509, 'Total loss': 0.4577783661132509} | train loss {'Reaction outcome loss': 0.15166986472303828, 'Total loss': 0.15166986472303828}
2022-12-05 20:23:19,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:19,727 INFO:     Epoch: 40
2022-12-05 20:23:20,545 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43537607247179205, 'Total loss': 0.43537607247179205} | train loss {'Reaction outcome loss': 0.1510171123044265, 'Total loss': 0.1510171123044265}
2022-12-05 20:23:20,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:20,545 INFO:     Epoch: 41
2022-12-05 20:23:21,365 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42908670262179593, 'Total loss': 0.42908670262179593} | train loss {'Reaction outcome loss': 0.15070781735102495, 'Total loss': 0.15070781735102495}
2022-12-05 20:23:21,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:21,365 INFO:     Epoch: 42
2022-12-05 20:23:22,186 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4415392183106054, 'Total loss': 0.4415392183106054} | train loss {'Reaction outcome loss': 0.1479244381264453, 'Total loss': 0.1479244381264453}
2022-12-05 20:23:22,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:22,186 INFO:     Epoch: 43
2022-12-05 20:23:23,007 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43671424043449486, 'Total loss': 0.43671424043449486} | train loss {'Reaction outcome loss': 0.14925966821160289, 'Total loss': 0.14925966821160289}
2022-12-05 20:23:23,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:23,007 INFO:     Epoch: 44
2022-12-05 20:23:23,828 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4516516158526594, 'Total loss': 0.4516516158526594} | train loss {'Reaction outcome loss': 0.14589902645938338, 'Total loss': 0.14589902645938338}
2022-12-05 20:23:23,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:23,829 INFO:     Epoch: 45
2022-12-05 20:23:24,651 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4496257941831242, 'Total loss': 0.4496257941831242} | train loss {'Reaction outcome loss': 0.14614722778975603, 'Total loss': 0.14614722778975603}
2022-12-05 20:23:24,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:24,651 INFO:     Epoch: 46
2022-12-05 20:23:25,472 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44605212015184487, 'Total loss': 0.44605212015184487} | train loss {'Reaction outcome loss': 0.14341946243638953, 'Total loss': 0.14341946243638953}
2022-12-05 20:23:25,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:25,472 INFO:     Epoch: 47
2022-12-05 20:23:26,291 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44609079899435694, 'Total loss': 0.44609079899435694} | train loss {'Reaction outcome loss': 0.14336092778361373, 'Total loss': 0.14336092778361373}
2022-12-05 20:23:26,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:26,291 INFO:     Epoch: 48
2022-12-05 20:23:27,108 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4476618492467837, 'Total loss': 0.4476618492467837} | train loss {'Reaction outcome loss': 0.1404842575523822, 'Total loss': 0.1404842575523822}
2022-12-05 20:23:27,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:27,109 INFO:     Epoch: 49
2022-12-05 20:23:27,926 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4496853378686038, 'Total loss': 0.4496853378686038} | train loss {'Reaction outcome loss': 0.14094384234668988, 'Total loss': 0.14094384234668988}
2022-12-05 20:23:27,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:27,926 INFO:     Epoch: 50
2022-12-05 20:23:28,746 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45470957390286704, 'Total loss': 0.45470957390286704} | train loss {'Reaction outcome loss': 0.1380470143555994, 'Total loss': 0.1380470143555994}
2022-12-05 20:23:28,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:28,746 INFO:     Epoch: 51
2022-12-05 20:23:29,567 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44276650927283545, 'Total loss': 0.44276650927283545} | train loss {'Reaction outcome loss': 0.13954159603904812, 'Total loss': 0.13954159603904812}
2022-12-05 20:23:29,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:29,568 INFO:     Epoch: 52
2022-12-05 20:23:30,387 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4450138878415931, 'Total loss': 0.4450138878415931} | train loss {'Reaction outcome loss': 0.1378087140995288, 'Total loss': 0.1378087140995288}
2022-12-05 20:23:30,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:30,388 INFO:     Epoch: 53
2022-12-05 20:23:31,205 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4480754230171442, 'Total loss': 0.4480754230171442} | train loss {'Reaction outcome loss': 0.13654688181686064, 'Total loss': 0.13654688181686064}
2022-12-05 20:23:31,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:31,206 INFO:     Epoch: 54
2022-12-05 20:23:32,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.446678490801291, 'Total loss': 0.446678490801291} | train loss {'Reaction outcome loss': 0.13662702211689565, 'Total loss': 0.13662702211689565}
2022-12-05 20:23:32,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:32,029 INFO:     Epoch: 55
2022-12-05 20:23:32,851 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4540993622080846, 'Total loss': 0.4540993622080846} | train loss {'Reaction outcome loss': 0.13509442181807133, 'Total loss': 0.13509442181807133}
2022-12-05 20:23:32,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:32,851 INFO:     Epoch: 56
2022-12-05 20:23:33,673 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44169407710433006, 'Total loss': 0.44169407710433006} | train loss {'Reaction outcome loss': 0.1350545078298197, 'Total loss': 0.1350545078298197}
2022-12-05 20:23:33,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:33,673 INFO:     Epoch: 57
2022-12-05 20:23:34,494 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4493153610012748, 'Total loss': 0.4493153610012748} | train loss {'Reaction outcome loss': 0.13447805022400233, 'Total loss': 0.13447805022400233}
2022-12-05 20:23:34,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:34,494 INFO:     Epoch: 58
2022-12-05 20:23:35,312 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4574222744188525, 'Total loss': 0.4574222744188525} | train loss {'Reaction outcome loss': 0.13404985119198118, 'Total loss': 0.13404985119198118}
2022-12-05 20:23:35,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:35,312 INFO:     Epoch: 59
2022-12-05 20:23:36,133 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4640985412353819, 'Total loss': 0.4640985412353819} | train loss {'Reaction outcome loss': 0.13247336331199133, 'Total loss': 0.13247336331199133}
2022-12-05 20:23:36,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:36,133 INFO:     Epoch: 60
2022-12-05 20:23:36,953 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45195611532438884, 'Total loss': 0.45195611532438884} | train loss {'Reaction outcome loss': 0.13138025911194423, 'Total loss': 0.13138025911194423}
2022-12-05 20:23:36,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:36,954 INFO:     Epoch: 61
2022-12-05 20:23:37,774 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44875236973166466, 'Total loss': 0.44875236973166466} | train loss {'Reaction outcome loss': 0.1325613855564546, 'Total loss': 0.1325613855564546}
2022-12-05 20:23:37,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:37,774 INFO:     Epoch: 62
2022-12-05 20:23:38,597 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45247105847705493, 'Total loss': 0.45247105847705493} | train loss {'Reaction outcome loss': 0.13345087182167317, 'Total loss': 0.13345087182167317}
2022-12-05 20:23:38,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:38,597 INFO:     Epoch: 63
2022-12-05 20:23:39,417 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46808526648039167, 'Total loss': 0.46808526648039167} | train loss {'Reaction outcome loss': 0.13096855654035724, 'Total loss': 0.13096855654035724}
2022-12-05 20:23:39,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:39,417 INFO:     Epoch: 64
2022-12-05 20:23:40,235 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4593957754021341, 'Total loss': 0.4593957754021341} | train loss {'Reaction outcome loss': 0.13050629839962047, 'Total loss': 0.13050629839962047}
2022-12-05 20:23:40,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:40,236 INFO:     Epoch: 65
2022-12-05 20:23:41,053 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47278815270824864, 'Total loss': 0.47278815270824864} | train loss {'Reaction outcome loss': 0.12927281100963872, 'Total loss': 0.12927281100963872}
2022-12-05 20:23:41,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:41,054 INFO:     Epoch: 66
2022-12-05 20:23:41,872 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4654218618842689, 'Total loss': 0.4654218618842689} | train loss {'Reaction outcome loss': 0.127718020684927, 'Total loss': 0.127718020684927}
2022-12-05 20:23:41,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:41,872 INFO:     Epoch: 67
2022-12-05 20:23:42,692 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45329137112606654, 'Total loss': 0.45329137112606654} | train loss {'Reaction outcome loss': 0.12491237963249366, 'Total loss': 0.12491237963249366}
2022-12-05 20:23:42,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:42,692 INFO:     Epoch: 68
2022-12-05 20:23:43,515 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44460842182690447, 'Total loss': 0.44460842182690447} | train loss {'Reaction outcome loss': 0.12732547221915616, 'Total loss': 0.12732547221915616}
2022-12-05 20:23:43,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:43,515 INFO:     Epoch: 69
2022-12-05 20:23:44,335 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44163551554083824, 'Total loss': 0.44163551554083824} | train loss {'Reaction outcome loss': 0.12755039725602874, 'Total loss': 0.12755039725602874}
2022-12-05 20:23:44,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:44,337 INFO:     Epoch: 70
2022-12-05 20:23:45,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.449510358273983, 'Total loss': 0.449510358273983} | train loss {'Reaction outcome loss': 0.1271959274815726, 'Total loss': 0.1271959274815726}
2022-12-05 20:23:45,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:45,157 INFO:     Epoch: 71
2022-12-05 20:23:45,982 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4522968584840948, 'Total loss': 0.4522968584840948} | train loss {'Reaction outcome loss': 0.12830311044554918, 'Total loss': 0.12830311044554918}
2022-12-05 20:23:45,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:45,982 INFO:     Epoch: 72
2022-12-05 20:23:46,795 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46536845138127153, 'Total loss': 0.46536845138127153} | train loss {'Reaction outcome loss': 0.12608754904114552, 'Total loss': 0.12608754904114552}
2022-12-05 20:23:46,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:46,795 INFO:     Epoch: 73
2022-12-05 20:23:47,595 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46101337569681083, 'Total loss': 0.46101337569681083} | train loss {'Reaction outcome loss': 0.1261793500818913, 'Total loss': 0.1261793500818913}
2022-12-05 20:23:47,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:47,595 INFO:     Epoch: 74
2022-12-05 20:23:48,395 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4414932228286158, 'Total loss': 0.4414932228286158} | train loss {'Reaction outcome loss': 0.12644708511464658, 'Total loss': 0.12644708511464658}
2022-12-05 20:23:48,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:48,395 INFO:     Epoch: 75
2022-12-05 20:23:49,191 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44503897411579435, 'Total loss': 0.44503897411579435} | train loss {'Reaction outcome loss': 0.12364048238152699, 'Total loss': 0.12364048238152699}
2022-12-05 20:23:49,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:49,191 INFO:     Epoch: 76
2022-12-05 20:23:49,993 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47057579999620264, 'Total loss': 0.47057579999620264} | train loss {'Reaction outcome loss': 0.12308355788099429, 'Total loss': 0.12308355788099429}
2022-12-05 20:23:49,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:49,994 INFO:     Epoch: 77
2022-12-05 20:23:50,795 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4483413306826895, 'Total loss': 0.4483413306826895} | train loss {'Reaction outcome loss': 0.12573866335855377, 'Total loss': 0.12573866335855377}
2022-12-05 20:23:50,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:50,796 INFO:     Epoch: 78
2022-12-05 20:23:51,600 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45437885143540124, 'Total loss': 0.45437885143540124} | train loss {'Reaction outcome loss': 0.12704194884844905, 'Total loss': 0.12704194884844905}
2022-12-05 20:23:51,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:51,600 INFO:     Epoch: 79
2022-12-05 20:23:52,405 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4536611476743763, 'Total loss': 0.4536611476743763} | train loss {'Reaction outcome loss': 0.12407730094855651, 'Total loss': 0.12407730094855651}
2022-12-05 20:23:52,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:52,406 INFO:     Epoch: 80
2022-12-05 20:23:53,210 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4693086982112039, 'Total loss': 0.4693086982112039} | train loss {'Reaction outcome loss': 0.12244341662904669, 'Total loss': 0.12244341662904669}
2022-12-05 20:23:53,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:53,210 INFO:     Epoch: 81
2022-12-05 20:23:54,013 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4613211402161555, 'Total loss': 0.4613211402161555} | train loss {'Reaction outcome loss': 0.1219516123660029, 'Total loss': 0.1219516123660029}
2022-12-05 20:23:54,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:54,013 INFO:     Epoch: 82
2022-12-05 20:23:54,814 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4338202659379352, 'Total loss': 0.4338202659379352} | train loss {'Reaction outcome loss': 0.12177923319095205, 'Total loss': 0.12177923319095205}
2022-12-05 20:23:54,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:54,814 INFO:     Epoch: 83
2022-12-05 20:23:55,617 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45778303051536734, 'Total loss': 0.45778303051536734} | train loss {'Reaction outcome loss': 0.12184088266334467, 'Total loss': 0.12184088266334467}
2022-12-05 20:23:55,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:55,617 INFO:     Epoch: 84
2022-12-05 20:23:56,416 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4496081718666987, 'Total loss': 0.4496081718666987} | train loss {'Reaction outcome loss': 0.12325268758520964, 'Total loss': 0.12325268758520964}
2022-12-05 20:23:56,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:56,417 INFO:     Epoch: 85
2022-12-05 20:23:57,220 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4654235789044337, 'Total loss': 0.4654235789044337} | train loss {'Reaction outcome loss': 0.11950600989944031, 'Total loss': 0.11950600989944031}
2022-12-05 20:23:57,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:57,220 INFO:     Epoch: 86
2022-12-05 20:23:58,022 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4519991380247203, 'Total loss': 0.4519991380247203} | train loss {'Reaction outcome loss': 0.12381745276657204, 'Total loss': 0.12381745276657204}
2022-12-05 20:23:58,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:58,022 INFO:     Epoch: 87
2022-12-05 20:23:58,820 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4495685263113542, 'Total loss': 0.4495685263113542} | train loss {'Reaction outcome loss': 0.12095620130534254, 'Total loss': 0.12095620130534254}
2022-12-05 20:23:58,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:58,820 INFO:     Epoch: 88
2022-12-05 20:23:59,623 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4474215724251487, 'Total loss': 0.4474215724251487} | train loss {'Reaction outcome loss': 0.12179716919819193, 'Total loss': 0.12179716919819193}
2022-12-05 20:23:59,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:23:59,624 INFO:     Epoch: 89
2022-12-05 20:24:00,424 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4607073383575136, 'Total loss': 0.4607073383575136} | train loss {'Reaction outcome loss': 0.11932427571680877, 'Total loss': 0.11932427571680877}
2022-12-05 20:24:00,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:00,424 INFO:     Epoch: 90
2022-12-05 20:24:01,225 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4606675671582872, 'Total loss': 0.4606675671582872} | train loss {'Reaction outcome loss': 0.1183975916205635, 'Total loss': 0.1183975916205635}
2022-12-05 20:24:01,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:01,226 INFO:     Epoch: 91
2022-12-05 20:24:02,023 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48350378024307167, 'Total loss': 0.48350378024307167} | train loss {'Reaction outcome loss': 0.12184136111905138, 'Total loss': 0.12184136111905138}
2022-12-05 20:24:02,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:02,023 INFO:     Epoch: 92
2022-12-05 20:24:02,827 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47608677501028235, 'Total loss': 0.47608677501028235} | train loss {'Reaction outcome loss': 0.1220483028953294, 'Total loss': 0.1220483028953294}
2022-12-05 20:24:02,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:02,828 INFO:     Epoch: 93
2022-12-05 20:24:03,629 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45307345722209325, 'Total loss': 0.45307345722209325} | train loss {'Reaction outcome loss': 0.11995349103029096, 'Total loss': 0.11995349103029096}
2022-12-05 20:24:03,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:03,629 INFO:     Epoch: 94
2022-12-05 20:24:04,428 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45560346442190086, 'Total loss': 0.45560346442190086} | train loss {'Reaction outcome loss': 0.11664519041416145, 'Total loss': 0.11664519041416145}
2022-12-05 20:24:04,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:04,428 INFO:     Epoch: 95
2022-12-05 20:24:05,228 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44287630306048825, 'Total loss': 0.44287630306048825} | train loss {'Reaction outcome loss': 0.12065801406729847, 'Total loss': 0.12065801406729847}
2022-12-05 20:24:05,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:05,228 INFO:     Epoch: 96
2022-12-05 20:24:06,031 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4504249072210355, 'Total loss': 0.4504249072210355} | train loss {'Reaction outcome loss': 0.11784744377984034, 'Total loss': 0.11784744377984034}
2022-12-05 20:24:06,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:06,032 INFO:     Epoch: 97
2022-12-05 20:24:06,832 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45644214105877007, 'Total loss': 0.45644214105877007} | train loss {'Reaction outcome loss': 0.12201515031648019, 'Total loss': 0.12201515031648019}
2022-12-05 20:24:06,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:06,833 INFO:     Epoch: 98
2022-12-05 20:24:07,636 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4688348150388761, 'Total loss': 0.4688348150388761} | train loss {'Reaction outcome loss': 0.11589116419124748, 'Total loss': 0.11589116419124748}
2022-12-05 20:24:07,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:07,636 INFO:     Epoch: 99
2022-12-05 20:24:08,439 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45109915089878166, 'Total loss': 0.45109915089878166} | train loss {'Reaction outcome loss': 0.12032712147300763, 'Total loss': 0.12032712147300763}
2022-12-05 20:24:08,440 INFO:     Best model found after epoch 22 of 100.
2022-12-05 20:24:08,440 INFO:   Done with stage: TRAINING
2022-12-05 20:24:08,440 INFO:   Starting stage: EVALUATION
2022-12-05 20:24:08,561 INFO:   Done with stage: EVALUATION
2022-12-05 20:24:08,561 INFO:   Leaving out SEQ value Fold_8
2022-12-05 20:24:08,573 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:24:08,573 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:24:09,227 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:24:09,227 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:24:09,295 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:24:09,295 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:24:09,295 INFO:     No hyperparam tuning for this model
2022-12-05 20:24:09,295 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:24:09,295 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:24:09,296 INFO:     None feature selector for col prot
2022-12-05 20:24:09,296 INFO:     None feature selector for col prot
2022-12-05 20:24:09,296 INFO:     None feature selector for col prot
2022-12-05 20:24:09,297 INFO:     None feature selector for col chem
2022-12-05 20:24:09,297 INFO:     None feature selector for col chem
2022-12-05 20:24:09,297 INFO:     None feature selector for col chem
2022-12-05 20:24:09,297 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:24:09,297 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:24:09,299 INFO:     Number of params in model 215821
2022-12-05 20:24:09,302 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:24:09,302 INFO:   Starting stage: TRAINING
2022-12-05 20:24:09,363 INFO:     Val loss before train {'Reaction outcome loss': 1.038192012093284, 'Total loss': 1.038192012093284}
2022-12-05 20:24:09,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:09,363 INFO:     Epoch: 0
2022-12-05 20:24:10,175 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6286992193623022, 'Total loss': 0.6286992193623022} | train loss {'Reaction outcome loss': 0.8088857791116161, 'Total loss': 0.8088857791116161}
2022-12-05 20:24:10,176 INFO:     Found new best model at epoch 0
2022-12-05 20:24:10,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:10,177 INFO:     Epoch: 1
2022-12-05 20:24:10,978 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5205245553092523, 'Total loss': 0.5205245553092523} | train loss {'Reaction outcome loss': 0.559780573532466, 'Total loss': 0.559780573532466}
2022-12-05 20:24:10,979 INFO:     Found new best model at epoch 1
2022-12-05 20:24:10,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:10,979 INFO:     Epoch: 2
2022-12-05 20:24:11,784 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4735623388127847, 'Total loss': 0.4735623388127847} | train loss {'Reaction outcome loss': 0.4801279617653739, 'Total loss': 0.4801279617653739}
2022-12-05 20:24:11,784 INFO:     Found new best model at epoch 2
2022-12-05 20:24:11,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:11,785 INFO:     Epoch: 3
2022-12-05 20:24:12,585 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45363281362436036, 'Total loss': 0.45363281362436036} | train loss {'Reaction outcome loss': 0.4366843970792909, 'Total loss': 0.4366843970792909}
2022-12-05 20:24:12,585 INFO:     Found new best model at epoch 3
2022-12-05 20:24:12,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:12,586 INFO:     Epoch: 4
2022-12-05 20:24:13,382 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4435403617945584, 'Total loss': 0.4435403617945584} | train loss {'Reaction outcome loss': 0.4007631643044372, 'Total loss': 0.4007631643044372}
2022-12-05 20:24:13,382 INFO:     Found new best model at epoch 4
2022-12-05 20:24:13,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:13,383 INFO:     Epoch: 5
2022-12-05 20:24:14,181 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43761114505204285, 'Total loss': 0.43761114505204285} | train loss {'Reaction outcome loss': 0.3726717567131404, 'Total loss': 0.3726717567131404}
2022-12-05 20:24:14,181 INFO:     Found new best model at epoch 5
2022-12-05 20:24:14,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:14,182 INFO:     Epoch: 6
2022-12-05 20:24:14,982 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.422850753096017, 'Total loss': 0.422850753096017} | train loss {'Reaction outcome loss': 0.35503536270510766, 'Total loss': 0.35503536270510766}
2022-12-05 20:24:14,983 INFO:     Found new best model at epoch 6
2022-12-05 20:24:14,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:14,984 INFO:     Epoch: 7
2022-12-05 20:24:15,785 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4227594269270247, 'Total loss': 0.4227594269270247} | train loss {'Reaction outcome loss': 0.3335368621253198, 'Total loss': 0.3335368621253198}
2022-12-05 20:24:15,785 INFO:     Found new best model at epoch 7
2022-12-05 20:24:15,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:15,786 INFO:     Epoch: 8
2022-12-05 20:24:16,586 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4240021783519875, 'Total loss': 0.4240021783519875} | train loss {'Reaction outcome loss': 0.31968421473978986, 'Total loss': 0.31968421473978986}
2022-12-05 20:24:16,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:16,587 INFO:     Epoch: 9
2022-12-05 20:24:17,395 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42599108205600217, 'Total loss': 0.42599108205600217} | train loss {'Reaction outcome loss': 0.30009550856606615, 'Total loss': 0.30009550856606615}
2022-12-05 20:24:17,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:17,396 INFO:     Epoch: 10
2022-12-05 20:24:18,195 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4225235273214904, 'Total loss': 0.4225235273214904} | train loss {'Reaction outcome loss': 0.28663734505854305, 'Total loss': 0.28663734505854305}
2022-12-05 20:24:18,195 INFO:     Found new best model at epoch 10
2022-12-05 20:24:18,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:18,196 INFO:     Epoch: 11
2022-12-05 20:24:18,993 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4142282070084052, 'Total loss': 0.4142282070084052} | train loss {'Reaction outcome loss': 0.27521126242654936, 'Total loss': 0.27521126242654936}
2022-12-05 20:24:18,993 INFO:     Found new best model at epoch 11
2022-12-05 20:24:18,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:18,994 INFO:     Epoch: 12
2022-12-05 20:24:19,791 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4242566278712316, 'Total loss': 0.4242566278712316} | train loss {'Reaction outcome loss': 0.26462165037951163, 'Total loss': 0.26462165037951163}
2022-12-05 20:24:19,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:19,791 INFO:     Epoch: 13
2022-12-05 20:24:20,589 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42499252408742905, 'Total loss': 0.42499252408742905} | train loss {'Reaction outcome loss': 0.25952647455156813, 'Total loss': 0.25952647455156813}
2022-12-05 20:24:20,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:20,589 INFO:     Epoch: 14
2022-12-05 20:24:21,382 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.415397449311885, 'Total loss': 0.415397449311885} | train loss {'Reaction outcome loss': 0.2528367612751261, 'Total loss': 0.2528367612751261}
2022-12-05 20:24:21,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:21,383 INFO:     Epoch: 15
2022-12-05 20:24:22,177 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4101390134204518, 'Total loss': 0.4101390134204518} | train loss {'Reaction outcome loss': 0.2446271434216009, 'Total loss': 0.2446271434216009}
2022-12-05 20:24:22,177 INFO:     Found new best model at epoch 15
2022-12-05 20:24:22,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:22,178 INFO:     Epoch: 16
2022-12-05 20:24:22,976 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43160441534763033, 'Total loss': 0.43160441534763033} | train loss {'Reaction outcome loss': 0.23547755953885854, 'Total loss': 0.23547755953885854}
2022-12-05 20:24:22,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:22,976 INFO:     Epoch: 17
2022-12-05 20:24:23,771 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42619459093971684, 'Total loss': 0.42619459093971684} | train loss {'Reaction outcome loss': 0.22550712685070692, 'Total loss': 0.22550712685070692}
2022-12-05 20:24:23,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:23,771 INFO:     Epoch: 18
2022-12-05 20:24:24,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4233710318803787, 'Total loss': 0.4233710318803787} | train loss {'Reaction outcome loss': 0.22050824131996882, 'Total loss': 0.22050824131996882}
2022-12-05 20:24:24,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:24,567 INFO:     Epoch: 19
2022-12-05 20:24:25,364 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4273378208956935, 'Total loss': 0.4273378208956935} | train loss {'Reaction outcome loss': 0.2138851415666361, 'Total loss': 0.2138851415666361}
2022-12-05 20:24:25,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:25,364 INFO:     Epoch: 20
2022-12-05 20:24:26,159 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42177908833731304, 'Total loss': 0.42177908833731304} | train loss {'Reaction outcome loss': 0.21036720304419437, 'Total loss': 0.21036720304419437}
2022-12-05 20:24:26,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:26,159 INFO:     Epoch: 21
2022-12-05 20:24:26,952 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4274610828777606, 'Total loss': 0.4274610828777606} | train loss {'Reaction outcome loss': 0.20633397186775843, 'Total loss': 0.20633397186775843}
2022-12-05 20:24:26,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:26,952 INFO:     Epoch: 22
2022-12-05 20:24:27,748 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4221831878477877, 'Total loss': 0.4221831878477877} | train loss {'Reaction outcome loss': 0.20367879213224496, 'Total loss': 0.20367879213224496}
2022-12-05 20:24:27,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:27,748 INFO:     Epoch: 23
2022-12-05 20:24:28,545 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42677474360574374, 'Total loss': 0.42677474360574374} | train loss {'Reaction outcome loss': 0.19657418414980413, 'Total loss': 0.19657418414980413}
2022-12-05 20:24:28,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:28,545 INFO:     Epoch: 24
2022-12-05 20:24:29,340 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42433643679727207, 'Total loss': 0.42433643679727207} | train loss {'Reaction outcome loss': 0.1946419247486178, 'Total loss': 0.1946419247486178}
2022-12-05 20:24:29,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:29,340 INFO:     Epoch: 25
2022-12-05 20:24:30,133 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41657618805766106, 'Total loss': 0.41657618805766106} | train loss {'Reaction outcome loss': 0.18914558356177183, 'Total loss': 0.18914558356177183}
2022-12-05 20:24:30,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:30,134 INFO:     Epoch: 26
2022-12-05 20:24:30,926 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4230308654633435, 'Total loss': 0.4230308654633435} | train loss {'Reaction outcome loss': 0.1859115465664335, 'Total loss': 0.1859115465664335}
2022-12-05 20:24:30,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:30,926 INFO:     Epoch: 27
2022-12-05 20:24:31,719 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4258110485970974, 'Total loss': 0.4258110485970974} | train loss {'Reaction outcome loss': 0.1841358039828558, 'Total loss': 0.1841358039828558}
2022-12-05 20:24:31,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:31,719 INFO:     Epoch: 28
2022-12-05 20:24:32,512 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4417322599752383, 'Total loss': 0.4417322599752383} | train loss {'Reaction outcome loss': 0.1815283497224652, 'Total loss': 0.1815283497224652}
2022-12-05 20:24:32,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:32,513 INFO:     Epoch: 29
2022-12-05 20:24:33,310 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4331289841370149, 'Total loss': 0.4331289841370149} | train loss {'Reaction outcome loss': 0.17729800325187464, 'Total loss': 0.17729800325187464}
2022-12-05 20:24:33,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:33,310 INFO:     Epoch: 30
2022-12-05 20:24:34,108 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4272257807579907, 'Total loss': 0.4272257807579907} | train loss {'Reaction outcome loss': 0.17396434021723126, 'Total loss': 0.17396434021723126}
2022-12-05 20:24:34,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:34,109 INFO:     Epoch: 31
2022-12-05 20:24:34,908 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4266153099862012, 'Total loss': 0.4266153099862012} | train loss {'Reaction outcome loss': 0.17087856376723898, 'Total loss': 0.17087856376723898}
2022-12-05 20:24:34,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:34,908 INFO:     Epoch: 32
2022-12-05 20:24:35,704 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4371627796102654, 'Total loss': 0.4371627796102654} | train loss {'Reaction outcome loss': 0.16926114958140157, 'Total loss': 0.16926114958140157}
2022-12-05 20:24:35,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:35,704 INFO:     Epoch: 33
2022-12-05 20:24:36,498 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44044989957050845, 'Total loss': 0.44044989957050845} | train loss {'Reaction outcome loss': 0.16548993026146724, 'Total loss': 0.16548993026146724}
2022-12-05 20:24:36,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:36,498 INFO:     Epoch: 34
2022-12-05 20:24:37,295 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4224668548188426, 'Total loss': 0.4224668548188426} | train loss {'Reaction outcome loss': 0.1625347095992296, 'Total loss': 0.1625347095992296}
2022-12-05 20:24:37,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:37,295 INFO:     Epoch: 35
2022-12-05 20:24:38,091 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.429282856258479, 'Total loss': 0.429282856258479} | train loss {'Reaction outcome loss': 0.15923624633691244, 'Total loss': 0.15923624633691244}
2022-12-05 20:24:38,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:38,091 INFO:     Epoch: 36
2022-12-05 20:24:38,888 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44243909181518987, 'Total loss': 0.44243909181518987} | train loss {'Reaction outcome loss': 0.16146968273566134, 'Total loss': 0.16146968273566134}
2022-12-05 20:24:38,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:38,888 INFO:     Epoch: 37
2022-12-05 20:24:39,682 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43475077572194015, 'Total loss': 0.43475077572194015} | train loss {'Reaction outcome loss': 0.15557614347762277, 'Total loss': 0.15557614347762277}
2022-12-05 20:24:39,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:39,683 INFO:     Epoch: 38
2022-12-05 20:24:40,476 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4229708571325649, 'Total loss': 0.4229708571325649} | train loss {'Reaction outcome loss': 0.15745243679491744, 'Total loss': 0.15745243679491744}
2022-12-05 20:24:40,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:40,477 INFO:     Epoch: 39
2022-12-05 20:24:41,270 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4413338222286918, 'Total loss': 0.4413338222286918} | train loss {'Reaction outcome loss': 0.15209837170362833, 'Total loss': 0.15209837170362833}
2022-12-05 20:24:41,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:41,271 INFO:     Epoch: 40
2022-12-05 20:24:42,067 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43986900777302007, 'Total loss': 0.43986900777302007} | train loss {'Reaction outcome loss': 0.1524667182726966, 'Total loss': 0.1524667182726966}
2022-12-05 20:24:42,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:42,067 INFO:     Epoch: 41
2022-12-05 20:24:42,866 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46212584406814794, 'Total loss': 0.46212584406814794} | train loss {'Reaction outcome loss': 0.15223965284624888, 'Total loss': 0.15223965284624888}
2022-12-05 20:24:42,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:42,867 INFO:     Epoch: 42
2022-12-05 20:24:43,661 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4370259517295794, 'Total loss': 0.4370259517295794} | train loss {'Reaction outcome loss': 0.14889133379854744, 'Total loss': 0.14889133379854744}
2022-12-05 20:24:43,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:43,661 INFO:     Epoch: 43
2022-12-05 20:24:44,454 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4313791797242381, 'Total loss': 0.4313791797242381} | train loss {'Reaction outcome loss': 0.15103891024726532, 'Total loss': 0.15103891024726532}
2022-12-05 20:24:44,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:44,455 INFO:     Epoch: 44
2022-12-05 20:24:45,249 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4248710179870779, 'Total loss': 0.4248710179870779} | train loss {'Reaction outcome loss': 0.14838495936935708, 'Total loss': 0.14838495936935708}
2022-12-05 20:24:45,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:45,250 INFO:     Epoch: 45
2022-12-05 20:24:46,047 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4527909518642859, 'Total loss': 0.4527909518642859} | train loss {'Reaction outcome loss': 0.1465514817635619, 'Total loss': 0.1465514817635619}
2022-12-05 20:24:46,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:46,047 INFO:     Epoch: 46
2022-12-05 20:24:46,842 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.438925286416303, 'Total loss': 0.438925286416303} | train loss {'Reaction outcome loss': 0.1456565780174588, 'Total loss': 0.1456565780174588}
2022-12-05 20:24:46,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:46,843 INFO:     Epoch: 47
2022-12-05 20:24:47,636 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4427875398912213, 'Total loss': 0.4427875398912213} | train loss {'Reaction outcome loss': 0.14617480969266786, 'Total loss': 0.14617480969266786}
2022-12-05 20:24:47,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:47,636 INFO:     Epoch: 48
2022-12-05 20:24:48,433 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4344278834760189, 'Total loss': 0.4344278834760189} | train loss {'Reaction outcome loss': 0.14205997259986977, 'Total loss': 0.14205997259986977}
2022-12-05 20:24:48,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:48,433 INFO:     Epoch: 49
2022-12-05 20:24:49,228 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4478305175223134, 'Total loss': 0.4478305175223134} | train loss {'Reaction outcome loss': 0.14293237536725018, 'Total loss': 0.14293237536725018}
2022-12-05 20:24:49,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:49,229 INFO:     Epoch: 50
2022-12-05 20:24:50,025 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44027090817689896, 'Total loss': 0.44027090817689896} | train loss {'Reaction outcome loss': 0.14058018799856184, 'Total loss': 0.14058018799856184}
2022-12-05 20:24:50,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:50,025 INFO:     Epoch: 51
2022-12-05 20:24:50,821 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44991637427698483, 'Total loss': 0.44991637427698483} | train loss {'Reaction outcome loss': 0.1398274374171911, 'Total loss': 0.1398274374171911}
2022-12-05 20:24:50,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:50,822 INFO:     Epoch: 52
2022-12-05 20:24:51,616 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43896122175184166, 'Total loss': 0.43896122175184166} | train loss {'Reaction outcome loss': 0.1410826781329008, 'Total loss': 0.1410826781329008}
2022-12-05 20:24:51,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:51,616 INFO:     Epoch: 53
2022-12-05 20:24:52,409 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43705564026128163, 'Total loss': 0.43705564026128163} | train loss {'Reaction outcome loss': 0.1384429016766409, 'Total loss': 0.1384429016766409}
2022-12-05 20:24:52,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:52,409 INFO:     Epoch: 54
2022-12-05 20:24:53,203 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4418346434831619, 'Total loss': 0.4418346434831619} | train loss {'Reaction outcome loss': 0.13768887141298863, 'Total loss': 0.13768887141298863}
2022-12-05 20:24:53,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:53,204 INFO:     Epoch: 55
2022-12-05 20:24:53,997 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.450854996049946, 'Total loss': 0.450854996049946} | train loss {'Reaction outcome loss': 0.13647337382539146, 'Total loss': 0.13647337382539146}
2022-12-05 20:24:53,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:53,997 INFO:     Epoch: 56
2022-12-05 20:24:54,791 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4318282026797533, 'Total loss': 0.4318282026797533} | train loss {'Reaction outcome loss': 0.13346695524430083, 'Total loss': 0.13346695524430083}
2022-12-05 20:24:54,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:54,791 INFO:     Epoch: 57
2022-12-05 20:24:55,586 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43563314696604555, 'Total loss': 0.43563314696604555} | train loss {'Reaction outcome loss': 0.13460545231693335, 'Total loss': 0.13460545231693335}
2022-12-05 20:24:55,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:55,587 INFO:     Epoch: 58
2022-12-05 20:24:56,383 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44695511426437984, 'Total loss': 0.44695511426437984} | train loss {'Reaction outcome loss': 0.13442133839858034, 'Total loss': 0.13442133839858034}
2022-12-05 20:24:56,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:56,384 INFO:     Epoch: 59
2022-12-05 20:24:57,184 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.447638952088627, 'Total loss': 0.447638952088627} | train loss {'Reaction outcome loss': 0.13482747948728502, 'Total loss': 0.13482747948728502}
2022-12-05 20:24:57,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:57,184 INFO:     Epoch: 60
2022-12-05 20:24:57,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4407419426874681, 'Total loss': 0.4407419426874681} | train loss {'Reaction outcome loss': 0.13277578208925983, 'Total loss': 0.13277578208925983}
2022-12-05 20:24:57,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:57,978 INFO:     Epoch: 61
2022-12-05 20:24:58,772 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42819117924029176, 'Total loss': 0.42819117924029176} | train loss {'Reaction outcome loss': 0.13493908538422997, 'Total loss': 0.13493908538422997}
2022-12-05 20:24:58,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:58,772 INFO:     Epoch: 62
2022-12-05 20:24:59,572 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43615719879215414, 'Total loss': 0.43615719879215414} | train loss {'Reaction outcome loss': 0.12936200143679255, 'Total loss': 0.12936200143679255}
2022-12-05 20:24:59,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:24:59,572 INFO:     Epoch: 63
2022-12-05 20:25:00,365 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4328556352040984, 'Total loss': 0.4328556352040984} | train loss {'Reaction outcome loss': 0.1293120860730508, 'Total loss': 0.1293120860730508}
2022-12-05 20:25:00,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:00,365 INFO:     Epoch: 64
2022-12-05 20:25:01,158 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4527954662388021, 'Total loss': 0.4527954662388021} | train loss {'Reaction outcome loss': 0.12842326650335903, 'Total loss': 0.12842326650335903}
2022-12-05 20:25:01,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:01,158 INFO:     Epoch: 65
2022-12-05 20:25:01,950 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4630174372683872, 'Total loss': 0.4630174372683872} | train loss {'Reaction outcome loss': 0.1322011717505032, 'Total loss': 0.1322011717505032}
2022-12-05 20:25:01,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:01,950 INFO:     Epoch: 66
2022-12-05 20:25:02,747 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4432694160125472, 'Total loss': 0.4432694160125472} | train loss {'Reaction outcome loss': 0.1334493434387109, 'Total loss': 0.1334493434387109}
2022-12-05 20:25:02,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:02,747 INFO:     Epoch: 67
2022-12-05 20:25:03,540 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44114087538963015, 'Total loss': 0.44114087538963015} | train loss {'Reaction outcome loss': 0.1302395417287405, 'Total loss': 0.1302395417287405}
2022-12-05 20:25:03,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:03,540 INFO:     Epoch: 68
2022-12-05 20:25:04,339 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44969350048764184, 'Total loss': 0.44969350048764184} | train loss {'Reaction outcome loss': 0.12760846020894184, 'Total loss': 0.12760846020894184}
2022-12-05 20:25:04,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:04,339 INFO:     Epoch: 69
2022-12-05 20:25:05,137 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4420937381007455, 'Total loss': 0.4420937381007455} | train loss {'Reaction outcome loss': 0.12772878198959534, 'Total loss': 0.12772878198959534}
2022-12-05 20:25:05,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:05,137 INFO:     Epoch: 70
2022-12-05 20:25:05,930 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45542531917718326, 'Total loss': 0.45542531917718326} | train loss {'Reaction outcome loss': 0.12719140003525442, 'Total loss': 0.12719140003525442}
2022-12-05 20:25:05,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:05,930 INFO:     Epoch: 71
2022-12-05 20:25:06,726 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4550608697940003, 'Total loss': 0.4550608697940003} | train loss {'Reaction outcome loss': 0.12577929351133324, 'Total loss': 0.12577929351133324}
2022-12-05 20:25:06,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:06,726 INFO:     Epoch: 72
2022-12-05 20:25:07,518 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45372842252254486, 'Total loss': 0.45372842252254486} | train loss {'Reaction outcome loss': 0.12806279173556476, 'Total loss': 0.12806279173556476}
2022-12-05 20:25:07,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:07,518 INFO:     Epoch: 73
2022-12-05 20:25:08,313 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44893985614180565, 'Total loss': 0.44893985614180565} | train loss {'Reaction outcome loss': 0.12625888244609437, 'Total loss': 0.12625888244609437}
2022-12-05 20:25:08,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:08,313 INFO:     Epoch: 74
2022-12-05 20:25:09,106 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4308972521261735, 'Total loss': 0.4308972521261735} | train loss {'Reaction outcome loss': 0.12579408890169655, 'Total loss': 0.12579408890169655}
2022-12-05 20:25:09,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:09,106 INFO:     Epoch: 75
2022-12-05 20:25:09,901 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4546420530162074, 'Total loss': 0.4546420530162074} | train loss {'Reaction outcome loss': 0.12337322782484754, 'Total loss': 0.12337322782484754}
2022-12-05 20:25:09,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:09,901 INFO:     Epoch: 76
2022-12-05 20:25:10,695 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4504356767812913, 'Total loss': 0.4504356767812913} | train loss {'Reaction outcome loss': 0.12421613197488289, 'Total loss': 0.12421613197488289}
2022-12-05 20:25:10,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:10,695 INFO:     Epoch: 77
2022-12-05 20:25:11,492 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.450186299668117, 'Total loss': 0.450186299668117} | train loss {'Reaction outcome loss': 0.12619036746271436, 'Total loss': 0.12619036746271436}
2022-12-05 20:25:11,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:11,492 INFO:     Epoch: 78
2022-12-05 20:25:12,287 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43896408209746535, 'Total loss': 0.43896408209746535} | train loss {'Reaction outcome loss': 0.12516627000689867, 'Total loss': 0.12516627000689867}
2022-12-05 20:25:12,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:12,288 INFO:     Epoch: 79
2022-12-05 20:25:13,081 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4338634769347581, 'Total loss': 0.4338634769347581} | train loss {'Reaction outcome loss': 0.12461957622379545, 'Total loss': 0.12461957622379545}
2022-12-05 20:25:13,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:13,082 INFO:     Epoch: 80
2022-12-05 20:25:13,877 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44560874524441635, 'Total loss': 0.44560874524441635} | train loss {'Reaction outcome loss': 0.12175883494144786, 'Total loss': 0.12175883494144786}
2022-12-05 20:25:13,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:13,878 INFO:     Epoch: 81
2022-12-05 20:25:14,674 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4462043255228888, 'Total loss': 0.4462043255228888} | train loss {'Reaction outcome loss': 0.12223107217916197, 'Total loss': 0.12223107217916197}
2022-12-05 20:25:14,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:14,675 INFO:     Epoch: 82
2022-12-05 20:25:15,468 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45604957098310644, 'Total loss': 0.45604957098310644} | train loss {'Reaction outcome loss': 0.12100805598311126, 'Total loss': 0.12100805598311126}
2022-12-05 20:25:15,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:15,469 INFO:     Epoch: 83
2022-12-05 20:25:16,267 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44836959429085255, 'Total loss': 0.44836959429085255} | train loss {'Reaction outcome loss': 0.1206395278267953, 'Total loss': 0.1206395278267953}
2022-12-05 20:25:16,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:16,267 INFO:     Epoch: 84
2022-12-05 20:25:17,068 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43728421899405395, 'Total loss': 0.43728421899405395} | train loss {'Reaction outcome loss': 0.12045251521387047, 'Total loss': 0.12045251521387047}
2022-12-05 20:25:17,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:17,068 INFO:     Epoch: 85
2022-12-05 20:25:17,865 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.463992257009853, 'Total loss': 0.463992257009853} | train loss {'Reaction outcome loss': 0.12202689967929356, 'Total loss': 0.12202689967929356}
2022-12-05 20:25:17,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:17,867 INFO:     Epoch: 86
2022-12-05 20:25:18,664 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45862045156007464, 'Total loss': 0.45862045156007464} | train loss {'Reaction outcome loss': 0.12303822976912582, 'Total loss': 0.12303822976912582}
2022-12-05 20:25:18,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:18,665 INFO:     Epoch: 87
2022-12-05 20:25:19,465 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44457201642746275, 'Total loss': 0.44457201642746275} | train loss {'Reaction outcome loss': 0.1223642939697921, 'Total loss': 0.1223642939697921}
2022-12-05 20:25:19,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:19,465 INFO:     Epoch: 88
2022-12-05 20:25:20,265 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4425784908235073, 'Total loss': 0.4425784908235073} | train loss {'Reaction outcome loss': 0.12086762280593957, 'Total loss': 0.12086762280593957}
2022-12-05 20:25:20,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:20,265 INFO:     Epoch: 89
2022-12-05 20:25:21,063 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45412400568073447, 'Total loss': 0.45412400568073447} | train loss {'Reaction outcome loss': 0.12107056825451794, 'Total loss': 0.12107056825451794}
2022-12-05 20:25:21,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:21,063 INFO:     Epoch: 90
2022-12-05 20:25:21,860 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45725159550254996, 'Total loss': 0.45725159550254996} | train loss {'Reaction outcome loss': 0.11803313119021515, 'Total loss': 0.11803313119021515}
2022-12-05 20:25:21,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:21,861 INFO:     Epoch: 91
2022-12-05 20:25:22,658 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43600197475064884, 'Total loss': 0.43600197475064884} | train loss {'Reaction outcome loss': 0.1196786651740812, 'Total loss': 0.1196786651740812}
2022-12-05 20:25:22,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:22,658 INFO:     Epoch: 92
2022-12-05 20:25:23,456 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43966312604871666, 'Total loss': 0.43966312604871666} | train loss {'Reaction outcome loss': 0.11885823120152758, 'Total loss': 0.11885823120152758}
2022-12-05 20:25:23,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:23,457 INFO:     Epoch: 93
2022-12-05 20:25:24,254 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4577105702324347, 'Total loss': 0.4577105702324347} | train loss {'Reaction outcome loss': 0.11776343736076547, 'Total loss': 0.11776343736076547}
2022-12-05 20:25:24,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:24,255 INFO:     Epoch: 94
2022-12-05 20:25:25,056 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4509999609806321, 'Total loss': 0.4509999609806321} | train loss {'Reaction outcome loss': 0.11890577818755241, 'Total loss': 0.11890577818755241}
2022-12-05 20:25:25,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:25,056 INFO:     Epoch: 95
2022-12-05 20:25:25,853 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4532676119018685, 'Total loss': 0.4532676119018685} | train loss {'Reaction outcome loss': 0.11912076731753204, 'Total loss': 0.11912076731753204}
2022-12-05 20:25:25,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:25,853 INFO:     Epoch: 96
2022-12-05 20:25:26,649 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44244752248579805, 'Total loss': 0.44244752248579805} | train loss {'Reaction outcome loss': 0.11726844071545789, 'Total loss': 0.11726844071545789}
2022-12-05 20:25:26,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:26,649 INFO:     Epoch: 97
2022-12-05 20:25:27,447 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43905507908626035, 'Total loss': 0.43905507908626035} | train loss {'Reaction outcome loss': 0.11776352207732177, 'Total loss': 0.11776352207732177}
2022-12-05 20:25:27,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:27,448 INFO:     Epoch: 98
2022-12-05 20:25:28,245 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45625412023880263, 'Total loss': 0.45625412023880263} | train loss {'Reaction outcome loss': 0.11651203276837364, 'Total loss': 0.11651203276837364}
2022-12-05 20:25:28,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:28,245 INFO:     Epoch: 99
2022-12-05 20:25:29,043 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45577445829456503, 'Total loss': 0.45577445829456503} | train loss {'Reaction outcome loss': 0.11815071377843138, 'Total loss': 0.11815071377843138}
2022-12-05 20:25:29,043 INFO:     Best model found after epoch 16 of 100.
2022-12-05 20:25:29,043 INFO:   Done with stage: TRAINING
2022-12-05 20:25:29,043 INFO:   Starting stage: EVALUATION
2022-12-05 20:25:29,164 INFO:   Done with stage: EVALUATION
2022-12-05 20:25:29,164 INFO:   Leaving out SEQ value Fold_9
2022-12-05 20:25:29,177 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:25:29,177 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:25:29,818 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:25:29,818 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:25:29,887 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:25:29,887 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:25:29,887 INFO:     No hyperparam tuning for this model
2022-12-05 20:25:29,887 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:25:29,887 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:25:29,888 INFO:     None feature selector for col prot
2022-12-05 20:25:29,888 INFO:     None feature selector for col prot
2022-12-05 20:25:29,888 INFO:     None feature selector for col prot
2022-12-05 20:25:29,889 INFO:     None feature selector for col chem
2022-12-05 20:25:29,889 INFO:     None feature selector for col chem
2022-12-05 20:25:29,889 INFO:     None feature selector for col chem
2022-12-05 20:25:29,889 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:25:29,889 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:25:29,891 INFO:     Number of params in model 215821
2022-12-05 20:25:29,894 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:25:29,894 INFO:   Starting stage: TRAINING
2022-12-05 20:25:29,956 INFO:     Val loss before train {'Reaction outcome loss': 0.9897372844544324, 'Total loss': 0.9897372844544324}
2022-12-05 20:25:29,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:29,956 INFO:     Epoch: 0
2022-12-05 20:25:30,756 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5783807621760801, 'Total loss': 0.5783807621760801} | train loss {'Reaction outcome loss': 0.7885731359725057, 'Total loss': 0.7885731359725057}
2022-12-05 20:25:30,756 INFO:     Found new best model at epoch 0
2022-12-05 20:25:30,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:30,757 INFO:     Epoch: 1
2022-12-05 20:25:31,549 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48600688678297127, 'Total loss': 0.48600688678297127} | train loss {'Reaction outcome loss': 0.5507873004747306, 'Total loss': 0.5507873004747306}
2022-12-05 20:25:31,549 INFO:     Found new best model at epoch 1
2022-12-05 20:25:31,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:31,550 INFO:     Epoch: 2
2022-12-05 20:25:32,346 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4497144869105382, 'Total loss': 0.4497144869105382} | train loss {'Reaction outcome loss': 0.4808409750944207, 'Total loss': 0.4808409750944207}
2022-12-05 20:25:32,346 INFO:     Found new best model at epoch 2
2022-12-05 20:25:32,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:32,347 INFO:     Epoch: 3
2022-12-05 20:25:33,139 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4356285645203157, 'Total loss': 0.4356285645203157} | train loss {'Reaction outcome loss': 0.4425969766943078, 'Total loss': 0.4425969766943078}
2022-12-05 20:25:33,139 INFO:     Found new best model at epoch 3
2022-12-05 20:25:33,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:33,140 INFO:     Epoch: 4
2022-12-05 20:25:33,931 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44155818765813654, 'Total loss': 0.44155818765813654} | train loss {'Reaction outcome loss': 0.4124859962386158, 'Total loss': 0.4124859962386158}
2022-12-05 20:25:33,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:33,931 INFO:     Epoch: 5
2022-12-05 20:25:34,723 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41050842201167886, 'Total loss': 0.41050842201167886} | train loss {'Reaction outcome loss': 0.38519162078376723, 'Total loss': 0.38519162078376723}
2022-12-05 20:25:34,723 INFO:     Found new best model at epoch 5
2022-12-05 20:25:34,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:34,724 INFO:     Epoch: 6
2022-12-05 20:25:35,518 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40988812392408197, 'Total loss': 0.40988812392408197} | train loss {'Reaction outcome loss': 0.36465632885332533, 'Total loss': 0.36465632885332533}
2022-12-05 20:25:35,518 INFO:     Found new best model at epoch 6
2022-12-05 20:25:35,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:35,519 INFO:     Epoch: 7
2022-12-05 20:25:36,310 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4025304690003395, 'Total loss': 0.4025304690003395} | train loss {'Reaction outcome loss': 0.3460700473548309, 'Total loss': 0.3460700473548309}
2022-12-05 20:25:36,311 INFO:     Found new best model at epoch 7
2022-12-05 20:25:36,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:36,312 INFO:     Epoch: 8
2022-12-05 20:25:37,107 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4062798920680176, 'Total loss': 0.4062798920680176} | train loss {'Reaction outcome loss': 0.3311006718254855, 'Total loss': 0.3311006718254855}
2022-12-05 20:25:37,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:37,107 INFO:     Epoch: 9
2022-12-05 20:25:37,902 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4141938987780701, 'Total loss': 0.4141938987780701} | train loss {'Reaction outcome loss': 0.3284910948502149, 'Total loss': 0.3284910948502149}
2022-12-05 20:25:37,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:37,902 INFO:     Epoch: 10
2022-12-05 20:25:38,696 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40149867365306074, 'Total loss': 0.40149867365306074} | train loss {'Reaction outcome loss': 0.3196008548985126, 'Total loss': 0.3196008548985126}
2022-12-05 20:25:38,696 INFO:     Found new best model at epoch 10
2022-12-05 20:25:38,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:38,697 INFO:     Epoch: 11
2022-12-05 20:25:39,491 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39806351912292565, 'Total loss': 0.39806351912292565} | train loss {'Reaction outcome loss': 0.29694532756863334, 'Total loss': 0.29694532756863334}
2022-12-05 20:25:39,491 INFO:     Found new best model at epoch 11
2022-12-05 20:25:39,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:39,492 INFO:     Epoch: 12
2022-12-05 20:25:40,283 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40070169080387463, 'Total loss': 0.40070169080387463} | train loss {'Reaction outcome loss': 0.28554823017313413, 'Total loss': 0.28554823017313413}
2022-12-05 20:25:40,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:40,283 INFO:     Epoch: 13
2022-12-05 20:25:41,081 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3911254516040737, 'Total loss': 0.3911254516040737} | train loss {'Reaction outcome loss': 0.2757630415170299, 'Total loss': 0.2757630415170299}
2022-12-05 20:25:41,081 INFO:     Found new best model at epoch 13
2022-12-05 20:25:41,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:41,082 INFO:     Epoch: 14
2022-12-05 20:25:41,877 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39599363573572854, 'Total loss': 0.39599363573572854} | train loss {'Reaction outcome loss': 0.2643977229866135, 'Total loss': 0.2643977229866135}
2022-12-05 20:25:41,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:41,877 INFO:     Epoch: 15
2022-12-05 20:25:42,672 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.396154216744683, 'Total loss': 0.396154216744683} | train loss {'Reaction outcome loss': 0.2586032505701428, 'Total loss': 0.2586032505701428}
2022-12-05 20:25:42,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:42,673 INFO:     Epoch: 16
2022-12-05 20:25:43,469 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4069447341290387, 'Total loss': 0.4069447341290387} | train loss {'Reaction outcome loss': 0.25140354296085066, 'Total loss': 0.25140354296085066}
2022-12-05 20:25:43,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:43,469 INFO:     Epoch: 17
2022-12-05 20:25:44,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41480286250060255, 'Total loss': 0.41480286250060255} | train loss {'Reaction outcome loss': 0.24416817050532774, 'Total loss': 0.24416817050532774}
2022-12-05 20:25:44,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:44,261 INFO:     Epoch: 18
2022-12-05 20:25:45,058 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39235792647708545, 'Total loss': 0.39235792647708545} | train loss {'Reaction outcome loss': 0.23743461375784597, 'Total loss': 0.23743461375784597}
2022-12-05 20:25:45,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:45,058 INFO:     Epoch: 19
2022-12-05 20:25:45,852 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40374045277183707, 'Total loss': 0.40374045277183707} | train loss {'Reaction outcome loss': 0.23233002395206978, 'Total loss': 0.23233002395206978}
2022-12-05 20:25:45,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:45,853 INFO:     Epoch: 20
2022-12-05 20:25:46,644 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42147197015583515, 'Total loss': 0.42147197015583515} | train loss {'Reaction outcome loss': 0.2265878212958695, 'Total loss': 0.2265878212958695}
2022-12-05 20:25:46,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:46,644 INFO:     Epoch: 21
2022-12-05 20:25:47,436 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40345350034873595, 'Total loss': 0.40345350034873595} | train loss {'Reaction outcome loss': 0.2224761258946498, 'Total loss': 0.2224761258946498}
2022-12-05 20:25:47,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:47,436 INFO:     Epoch: 22
2022-12-05 20:25:48,226 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.428518030453812, 'Total loss': 0.428518030453812} | train loss {'Reaction outcome loss': 0.22310177021120725, 'Total loss': 0.22310177021120725}
2022-12-05 20:25:48,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:48,226 INFO:     Epoch: 23
2022-12-05 20:25:49,019 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41587364072488114, 'Total loss': 0.41587364072488114} | train loss {'Reaction outcome loss': 0.21760568145647463, 'Total loss': 0.21760568145647463}
2022-12-05 20:25:49,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:49,020 INFO:     Epoch: 24
2022-12-05 20:25:49,817 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40540399503978813, 'Total loss': 0.40540399503978813} | train loss {'Reaction outcome loss': 0.2110158766465269, 'Total loss': 0.2110158766465269}
2022-12-05 20:25:49,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:49,817 INFO:     Epoch: 25
2022-12-05 20:25:50,613 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41586959607560525, 'Total loss': 0.41586959607560525} | train loss {'Reaction outcome loss': 0.20226683316805102, 'Total loss': 0.20226683316805102}
2022-12-05 20:25:50,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:50,613 INFO:     Epoch: 26
2022-12-05 20:25:51,405 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40640618838369846, 'Total loss': 0.40640618838369846} | train loss {'Reaction outcome loss': 0.2039982916085947, 'Total loss': 0.2039982916085947}
2022-12-05 20:25:51,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:51,406 INFO:     Epoch: 27
2022-12-05 20:25:52,198 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4292744083160704, 'Total loss': 0.4292744083160704} | train loss {'Reaction outcome loss': 0.19871378352164257, 'Total loss': 0.19871378352164257}
2022-12-05 20:25:52,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:52,198 INFO:     Epoch: 28
2022-12-05 20:25:52,991 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4185280098833821, 'Total loss': 0.4185280098833821} | train loss {'Reaction outcome loss': 0.2002086009272197, 'Total loss': 0.2002086009272197}
2022-12-05 20:25:52,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:52,991 INFO:     Epoch: 29
2022-12-05 20:25:53,785 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4067965786565434, 'Total loss': 0.4067965786565434} | train loss {'Reaction outcome loss': 0.1936907280794522, 'Total loss': 0.1936907280794522}
2022-12-05 20:25:53,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:53,785 INFO:     Epoch: 30
2022-12-05 20:25:54,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40409118512814696, 'Total loss': 0.40409118512814696} | train loss {'Reaction outcome loss': 0.18699218583885233, 'Total loss': 0.18699218583885233}
2022-12-05 20:25:54,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:54,578 INFO:     Epoch: 31
2022-12-05 20:25:55,374 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4150848270139911, 'Total loss': 0.4150848270139911} | train loss {'Reaction outcome loss': 0.19122602659379423, 'Total loss': 0.19122602659379423}
2022-12-05 20:25:55,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:55,375 INFO:     Epoch: 32
2022-12-05 20:25:56,171 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41313213922760705, 'Total loss': 0.41313213922760705} | train loss {'Reaction outcome loss': 0.18795222618620888, 'Total loss': 0.18795222618620888}
2022-12-05 20:25:56,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:56,172 INFO:     Epoch: 33
2022-12-05 20:25:56,968 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42679074000228534, 'Total loss': 0.42679074000228534} | train loss {'Reaction outcome loss': 0.17639253427923057, 'Total loss': 0.17639253427923057}
2022-12-05 20:25:56,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:56,969 INFO:     Epoch: 34
2022-12-05 20:25:57,764 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4131467467681928, 'Total loss': 0.4131467467681928} | train loss {'Reaction outcome loss': 0.1774142358889464, 'Total loss': 0.1774142358889464}
2022-12-05 20:25:57,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:57,764 INFO:     Epoch: 35
2022-12-05 20:25:58,561 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43640934946862137, 'Total loss': 0.43640934946862137} | train loss {'Reaction outcome loss': 0.1717177690402699, 'Total loss': 0.1717177690402699}
2022-12-05 20:25:58,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:58,561 INFO:     Epoch: 36
2022-12-05 20:25:59,363 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4246445078064095, 'Total loss': 0.4246445078064095} | train loss {'Reaction outcome loss': 0.1758905122441198, 'Total loss': 0.1758905122441198}
2022-12-05 20:25:59,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:25:59,363 INFO:     Epoch: 37
2022-12-05 20:26:00,158 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.417325438762253, 'Total loss': 0.417325438762253} | train loss {'Reaction outcome loss': 0.1718204170013005, 'Total loss': 0.1718204170013005}
2022-12-05 20:26:00,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:00,158 INFO:     Epoch: 38
2022-12-05 20:26:00,950 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42033929987387225, 'Total loss': 0.42033929987387225} | train loss {'Reaction outcome loss': 0.17278259077867275, 'Total loss': 0.17278259077867275}
2022-12-05 20:26:00,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:00,951 INFO:     Epoch: 39
2022-12-05 20:26:01,746 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43054398047653114, 'Total loss': 0.43054398047653114} | train loss {'Reaction outcome loss': 0.16902430292769421, 'Total loss': 0.16902430292769421}
2022-12-05 20:26:01,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:01,746 INFO:     Epoch: 40
2022-12-05 20:26:02,543 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42864611406217923, 'Total loss': 0.42864611406217923} | train loss {'Reaction outcome loss': 0.16205653754489022, 'Total loss': 0.16205653754489022}
2022-12-05 20:26:02,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:02,543 INFO:     Epoch: 41
2022-12-05 20:26:03,337 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42620099132711237, 'Total loss': 0.42620099132711237} | train loss {'Reaction outcome loss': 0.16019637406867768, 'Total loss': 0.16019637406867768}
2022-12-05 20:26:03,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:03,338 INFO:     Epoch: 42
2022-12-05 20:26:04,130 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42154053192247043, 'Total loss': 0.42154053192247043} | train loss {'Reaction outcome loss': 0.16160256896726033, 'Total loss': 0.16160256896726033}
2022-12-05 20:26:04,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:04,131 INFO:     Epoch: 43
2022-12-05 20:26:04,927 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.429433961822228, 'Total loss': 0.429433961822228} | train loss {'Reaction outcome loss': 0.15741293203191237, 'Total loss': 0.15741293203191237}
2022-12-05 20:26:04,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:04,928 INFO:     Epoch: 44
2022-12-05 20:26:05,730 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.424299821596254, 'Total loss': 0.424299821596254} | train loss {'Reaction outcome loss': 0.1559176480374959, 'Total loss': 0.1559176480374959}
2022-12-05 20:26:05,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:05,730 INFO:     Epoch: 45
2022-12-05 20:26:06,532 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43149560554461047, 'Total loss': 0.43149560554461047} | train loss {'Reaction outcome loss': 0.15896683320523755, 'Total loss': 0.15896683320523755}
2022-12-05 20:26:06,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:06,532 INFO:     Epoch: 46
2022-12-05 20:26:07,328 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4374992908401923, 'Total loss': 0.4374992908401923} | train loss {'Reaction outcome loss': 0.15469240110936888, 'Total loss': 0.15469240110936888}
2022-12-05 20:26:07,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:07,328 INFO:     Epoch: 47
2022-12-05 20:26:08,121 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4322168207304044, 'Total loss': 0.4322168207304044} | train loss {'Reaction outcome loss': 0.14955108195848701, 'Total loss': 0.14955108195848701}
2022-12-05 20:26:08,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:08,122 INFO:     Epoch: 48
2022-12-05 20:26:08,919 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42884640175510536, 'Total loss': 0.42884640175510536} | train loss {'Reaction outcome loss': 0.14739304565096856, 'Total loss': 0.14739304565096856}
2022-12-05 20:26:08,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:08,919 INFO:     Epoch: 49
2022-12-05 20:26:09,713 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4283807467330586, 'Total loss': 0.4283807467330586} | train loss {'Reaction outcome loss': 0.1496025160063899, 'Total loss': 0.1496025160063899}
2022-12-05 20:26:09,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:09,713 INFO:     Epoch: 50
2022-12-05 20:26:10,508 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42706347290765156, 'Total loss': 0.42706347290765156} | train loss {'Reaction outcome loss': 0.147253171514403, 'Total loss': 0.147253171514403}
2022-12-05 20:26:10,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:10,509 INFO:     Epoch: 51
2022-12-05 20:26:11,301 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43736648017709906, 'Total loss': 0.43736648017709906} | train loss {'Reaction outcome loss': 0.14807863252968922, 'Total loss': 0.14807863252968922}
2022-12-05 20:26:11,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:11,301 INFO:     Epoch: 52
2022-12-05 20:26:12,099 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42908716709776357, 'Total loss': 0.42908716709776357} | train loss {'Reaction outcome loss': 0.14967161331039208, 'Total loss': 0.14967161331039208}
2022-12-05 20:26:12,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:12,099 INFO:     Epoch: 53
2022-12-05 20:26:12,892 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4363992955874313, 'Total loss': 0.4363992955874313} | train loss {'Reaction outcome loss': 0.14481129235802934, 'Total loss': 0.14481129235802934}
2022-12-05 20:26:12,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:12,892 INFO:     Epoch: 54
2022-12-05 20:26:13,684 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43235271153124893, 'Total loss': 0.43235271153124893} | train loss {'Reaction outcome loss': 0.1445340232825593, 'Total loss': 0.1445340232825593}
2022-12-05 20:26:13,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:13,685 INFO:     Epoch: 55
2022-12-05 20:26:14,477 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42744252153418283, 'Total loss': 0.42744252153418283} | train loss {'Reaction outcome loss': 0.14310040105386876, 'Total loss': 0.14310040105386876}
2022-12-05 20:26:14,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:14,478 INFO:     Epoch: 56
2022-12-05 20:26:15,272 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4228022938424891, 'Total loss': 0.4228022938424891} | train loss {'Reaction outcome loss': 0.14305494601983457, 'Total loss': 0.14305494601983457}
2022-12-05 20:26:15,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:15,272 INFO:     Epoch: 57
2022-12-05 20:26:16,071 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4102343422445384, 'Total loss': 0.4102343422445384} | train loss {'Reaction outcome loss': 0.13792701561931475, 'Total loss': 0.13792701561931475}
2022-12-05 20:26:16,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:16,071 INFO:     Epoch: 58
2022-12-05 20:26:16,866 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42370018430731515, 'Total loss': 0.42370018430731515} | train loss {'Reaction outcome loss': 0.1406108174472576, 'Total loss': 0.1406108174472576}
2022-12-05 20:26:16,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:16,866 INFO:     Epoch: 59
2022-12-05 20:26:17,662 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4343881449577483, 'Total loss': 0.4343881449577483} | train loss {'Reaction outcome loss': 0.13867964984298597, 'Total loss': 0.13867964984298597}
2022-12-05 20:26:17,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:17,662 INFO:     Epoch: 60
2022-12-05 20:26:18,460 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44103127311576495, 'Total loss': 0.44103127311576495} | train loss {'Reaction outcome loss': 0.14240944350462573, 'Total loss': 0.14240944350462573}
2022-12-05 20:26:18,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:18,461 INFO:     Epoch: 61
2022-12-05 20:26:19,254 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43007129125974397, 'Total loss': 0.43007129125974397} | train loss {'Reaction outcome loss': 0.14415922637289835, 'Total loss': 0.14415922637289835}
2022-12-05 20:26:19,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:19,254 INFO:     Epoch: 62
2022-12-05 20:26:20,050 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4292090761221268, 'Total loss': 0.4292090761221268} | train loss {'Reaction outcome loss': 0.14224262214322322, 'Total loss': 0.14224262214322322}
2022-12-05 20:26:20,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:20,051 INFO:     Epoch: 63
2022-12-05 20:26:20,850 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4281743223016912, 'Total loss': 0.4281743223016912} | train loss {'Reaction outcome loss': 0.14144935378963167, 'Total loss': 0.14144935378963167}
2022-12-05 20:26:20,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:20,851 INFO:     Epoch: 64
2022-12-05 20:26:21,644 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4331313222646713, 'Total loss': 0.4331313222646713} | train loss {'Reaction outcome loss': 0.13739701127444925, 'Total loss': 0.13739701127444925}
2022-12-05 20:26:21,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:21,644 INFO:     Epoch: 65
2022-12-05 20:26:22,438 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4423430846496062, 'Total loss': 0.4423430846496062} | train loss {'Reaction outcome loss': 0.13477152115797345, 'Total loss': 0.13477152115797345}
2022-12-05 20:26:22,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:22,439 INFO:     Epoch: 66
2022-12-05 20:26:23,235 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4344063565473665, 'Total loss': 0.4344063565473665} | train loss {'Reaction outcome loss': 0.13153205924150854, 'Total loss': 0.13153205924150854}
2022-12-05 20:26:23,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:23,235 INFO:     Epoch: 67
2022-12-05 20:26:24,036 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43560279651798983, 'Total loss': 0.43560279651798983} | train loss {'Reaction outcome loss': 0.13024453835765482, 'Total loss': 0.13024453835765482}
2022-12-05 20:26:24,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:24,036 INFO:     Epoch: 68
2022-12-05 20:26:24,832 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44636563474143093, 'Total loss': 0.44636563474143093} | train loss {'Reaction outcome loss': 0.13324130718268243, 'Total loss': 0.13324130718268243}
2022-12-05 20:26:24,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:24,833 INFO:     Epoch: 69
2022-12-05 20:26:25,632 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43788424743847415, 'Total loss': 0.43788424743847415} | train loss {'Reaction outcome loss': 0.13797872498073438, 'Total loss': 0.13797872498073438}
2022-12-05 20:26:25,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:25,632 INFO:     Epoch: 70
2022-12-05 20:26:26,429 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43950409950180486, 'Total loss': 0.43950409950180486} | train loss {'Reaction outcome loss': 0.13401471239774815, 'Total loss': 0.13401471239774815}
2022-12-05 20:26:26,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:26,430 INFO:     Epoch: 71
2022-12-05 20:26:27,229 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44056115401062096, 'Total loss': 0.44056115401062096} | train loss {'Reaction outcome loss': 0.1299340039461489, 'Total loss': 0.1299340039461489}
2022-12-05 20:26:27,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:27,229 INFO:     Epoch: 72
2022-12-05 20:26:28,030 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4307467316023328, 'Total loss': 0.4307467316023328} | train loss {'Reaction outcome loss': 0.13689213005546857, 'Total loss': 0.13689213005546857}
2022-12-05 20:26:28,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:28,031 INFO:     Epoch: 73
2022-12-05 20:26:28,826 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43591279875148425, 'Total loss': 0.43591279875148425} | train loss {'Reaction outcome loss': 0.12833203466209445, 'Total loss': 0.12833203466209445}
2022-12-05 20:26:28,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:28,827 INFO:     Epoch: 74
2022-12-05 20:26:29,620 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43879432569850574, 'Total loss': 0.43879432569850574} | train loss {'Reaction outcome loss': 0.12616355542229254, 'Total loss': 0.12616355542229254}
2022-12-05 20:26:29,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:29,621 INFO:     Epoch: 75
2022-12-05 20:26:30,417 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4378271119838411, 'Total loss': 0.4378271119838411} | train loss {'Reaction outcome loss': 0.13024417069073208, 'Total loss': 0.13024417069073208}
2022-12-05 20:26:30,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:30,417 INFO:     Epoch: 76
2022-12-05 20:26:31,217 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.427492192523046, 'Total loss': 0.427492192523046} | train loss {'Reaction outcome loss': 0.12611115641650641, 'Total loss': 0.12611115641650641}
2022-12-05 20:26:31,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:31,217 INFO:     Epoch: 77
2022-12-05 20:26:32,016 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41622536934234877, 'Total loss': 0.41622536934234877} | train loss {'Reaction outcome loss': 0.12715711211220093, 'Total loss': 0.12715711211220093}
2022-12-05 20:26:32,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:32,017 INFO:     Epoch: 78
2022-12-05 20:26:32,813 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4338578512384133, 'Total loss': 0.4338578512384133} | train loss {'Reaction outcome loss': 0.12615509823658447, 'Total loss': 0.12615509823658447}
2022-12-05 20:26:32,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:32,813 INFO:     Epoch: 79
2022-12-05 20:26:33,614 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4367039427161217, 'Total loss': 0.4367039427161217} | train loss {'Reaction outcome loss': 0.12650734436913177, 'Total loss': 0.12650734436913177}
2022-12-05 20:26:33,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:33,614 INFO:     Epoch: 80
2022-12-05 20:26:34,416 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42299606261605566, 'Total loss': 0.42299606261605566} | train loss {'Reaction outcome loss': 0.128527075120131, 'Total loss': 0.128527075120131}
2022-12-05 20:26:34,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:34,417 INFO:     Epoch: 81
2022-12-05 20:26:35,212 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44417437606237153, 'Total loss': 0.44417437606237153} | train loss {'Reaction outcome loss': 0.12200573969704027, 'Total loss': 0.12200573969704027}
2022-12-05 20:26:35,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:35,212 INFO:     Epoch: 82
2022-12-05 20:26:36,011 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4341573715209961, 'Total loss': 0.4341573715209961} | train loss {'Reaction outcome loss': 0.12419432755333451, 'Total loss': 0.12419432755333451}
2022-12-05 20:26:36,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:36,012 INFO:     Epoch: 83
2022-12-05 20:26:36,810 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42603229121728375, 'Total loss': 0.42603229121728375} | train loss {'Reaction outcome loss': 0.12710568386880372, 'Total loss': 0.12710568386880372}
2022-12-05 20:26:36,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:36,810 INFO:     Epoch: 84
2022-12-05 20:26:37,616 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44022498720071535, 'Total loss': 0.44022498720071535} | train loss {'Reaction outcome loss': 0.12468031396041153, 'Total loss': 0.12468031396041153}
2022-12-05 20:26:37,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:37,616 INFO:     Epoch: 85
2022-12-05 20:26:38,419 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4284878857433796, 'Total loss': 0.4284878857433796} | train loss {'Reaction outcome loss': 0.12289139579016307, 'Total loss': 0.12289139579016307}
2022-12-05 20:26:38,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:38,419 INFO:     Epoch: 86
2022-12-05 20:26:39,220 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4358311662958427, 'Total loss': 0.4358311662958427} | train loss {'Reaction outcome loss': 0.12041334837660013, 'Total loss': 0.12041334837660013}
2022-12-05 20:26:39,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:39,221 INFO:     Epoch: 87
2022-12-05 20:26:40,024 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42988140576265077, 'Total loss': 0.42988140576265077} | train loss {'Reaction outcome loss': 0.130424446939125, 'Total loss': 0.130424446939125}
2022-12-05 20:26:40,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:40,024 INFO:     Epoch: 88
2022-12-05 20:26:40,823 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4297059147872708, 'Total loss': 0.4297059147872708} | train loss {'Reaction outcome loss': 0.12984190815267896, 'Total loss': 0.12984190815267896}
2022-12-05 20:26:40,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:40,823 INFO:     Epoch: 89
2022-12-05 20:26:41,621 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42832062020897865, 'Total loss': 0.42832062020897865} | train loss {'Reaction outcome loss': 0.12101618779694986, 'Total loss': 0.12101618779694986}
2022-12-05 20:26:41,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:41,622 INFO:     Epoch: 90
2022-12-05 20:26:42,418 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4381571765989065, 'Total loss': 0.4381571765989065} | train loss {'Reaction outcome loss': 0.11939626998505612, 'Total loss': 0.11939626998505612}
2022-12-05 20:26:42,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:42,418 INFO:     Epoch: 91
2022-12-05 20:26:43,220 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.427648940038952, 'Total loss': 0.427648940038952} | train loss {'Reaction outcome loss': 0.11959239208942604, 'Total loss': 0.11959239208942604}
2022-12-05 20:26:43,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:43,220 INFO:     Epoch: 92
2022-12-05 20:26:44,016 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4401023934002627, 'Total loss': 0.4401023934002627} | train loss {'Reaction outcome loss': 0.11800568618883307, 'Total loss': 0.11800568618883307}
2022-12-05 20:26:44,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:44,016 INFO:     Epoch: 93
2022-12-05 20:26:44,814 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41526671922342345, 'Total loss': 0.41526671922342345} | train loss {'Reaction outcome loss': 0.1180403849999854, 'Total loss': 0.1180403849999854}
2022-12-05 20:26:44,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:44,815 INFO:     Epoch: 94
2022-12-05 20:26:45,613 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42775023373013193, 'Total loss': 0.42775023373013193} | train loss {'Reaction outcome loss': 0.1202220182319366, 'Total loss': 0.1202220182319366}
2022-12-05 20:26:45,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:45,613 INFO:     Epoch: 95
2022-12-05 20:26:46,412 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4235464815389026, 'Total loss': 0.4235464815389026} | train loss {'Reaction outcome loss': 0.11769315636215302, 'Total loss': 0.11769315636215302}
2022-12-05 20:26:46,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:46,412 INFO:     Epoch: 96
2022-12-05 20:26:47,206 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45224257998845796, 'Total loss': 0.45224257998845796} | train loss {'Reaction outcome loss': 0.11736748023580774, 'Total loss': 0.11736748023580774}
2022-12-05 20:26:47,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:47,207 INFO:     Epoch: 97
2022-12-05 20:26:48,005 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4184534407474778, 'Total loss': 0.4184534407474778} | train loss {'Reaction outcome loss': 0.11808409230611079, 'Total loss': 0.11808409230611079}
2022-12-05 20:26:48,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:48,005 INFO:     Epoch: 98
2022-12-05 20:26:48,805 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4441417975520546, 'Total loss': 0.4441417975520546} | train loss {'Reaction outcome loss': 0.11604219075737272, 'Total loss': 0.11604219075737272}
2022-12-05 20:26:48,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:26:48,805 INFO:     Epoch: 99
2022-12-05 20:26:49,606 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43663229010152543, 'Total loss': 0.43663229010152543} | train loss {'Reaction outcome loss': 0.11708447462709447, 'Total loss': 0.11708447462709447}
2022-12-05 20:26:49,606 INFO:     Best model found after epoch 14 of 100.
2022-12-05 20:26:49,606 INFO:   Done with stage: TRAINING
2022-12-05 20:26:49,606 INFO:   Starting stage: EVALUATION
2022-12-05 20:26:49,732 INFO:   Done with stage: EVALUATION
2022-12-05 20:26:49,732 INFO: Done with stage: RUNNING SPLITS
2022-12-05 20:26:49,732 INFO: Starting stage: COMPUTE METRICS
2022-12-05 20:26:50,907 INFO: Done with stage: COMPUTE METRICS
2022-12-05 20:26:50,908 INFO: Starting stage: EXPORT RESULTS
2022-12-05 20:26:50,926 INFO:   Final results averaged over 50 folds: 
2022-12-05 20:26:50,929 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.174413           NaN  0.304948       NaN
2022-12-05 20:26:52,593 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-05 20:26:52,605 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-05 20:26:52,606 DEBUG:   interactive is False
2022-12-05 20:26:52,606 DEBUG:   platform is linux
2022-12-05 20:26:52,606 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-05 20:26:52,779 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-05 20:26:52,784 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-05 20:26:53,227 DEBUG:   Loaded backend agg version unknown.
2022-12-05 20:26:53,229 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 20:26:53,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,232 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,232 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 20:26:53,268 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,271 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,271 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 20:26:53,280 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,280 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,281 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 20:26:53,282 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 20:26:53,283 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 20:26:53,675 INFO: Done with stage: EXPORT RESULTS
2022-12-05 20:26:53,675 INFO: Starting stage: SAVE MODEL
2022-12-05 20:26:53,764 INFO: Done with stage: SAVE MODEL
2022-12-05 20:26:53,764 INFO: Wall time for program:  4019.92 seconds
